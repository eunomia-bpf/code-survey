commit_id,commit_hash,author_name,author_email,author_date,committer_name,committer_email,commit_date_timestamp,tree_hash,parent_hashes,commit_message,refs,summary,keywords,commit_classification,commit_complexity,Major related component,program_types_related
b831f83e40a24f07c8dcba5be408d93beedc820f,b831f83e40a24f07c8dcba5be408d93beedc820f,Linus Torvalds,torvalds@linux-foundation.org,1725592253,Linus Torvalds,torvalds@linux-foundation.org,1725592253,45d37c24cbcde7ceb198bebd4ad8719b11a3c640,d759ee240d3c0c4a19f4d984eb21c36da76bc6ce 5390f315fc8c9b9f48105a0d88b56bc59fa2b3e0,"Merge tag 'bpf-6.11-rc7' of git://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Pull bpf fixes from Alexei Starovoitov:

 - Fix crash when btf_parse_base() returns an error (Martin Lau)

 - Fix out of bounds access in btf_name_valid_section() (Jeongjun Park)

* tag 'bpf-6.11-rc7' of git://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:
  selftests/bpf: Add a selftest to check for incorrect names
  bpf: add check for invalid name in btf_name_valid_section()
  bpf: Fix a crash when btf_parse_base() returns an error pointer
",,This commit is a merge containing bug fixes related to BTF parsing in the eBPF subsystem.,"BTF,crash,fix",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d759ee240d3c0c4a19f4d984eb21c36da76bc6ce,d759ee240d3c0c4a19f4d984eb21c36da76bc6ce,Linus Torvalds,torvalds@linux-foundation.org,1725581281,Linus Torvalds,torvalds@linux-foundation.org,1725581281,8fb0d7425b8516069f11128f32a869c395b21a1b,f95359996ac35206ff24e378052ce564d5bfdc94 031ae72825cef43e4650140b800ad58bf7a6a466,"Merge tag 'net-6.11-rc7' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Jakub Kicinski:
 ""Including fixes from can"," bluetooth and wireless.

  No known regressions at this point. Another calm week","[' but chances are\n  that has more to do with vacation season than the quality of our work.\n\n  Current release - new code bugs:\n\n   - smc: prevent NULL pointer dereference in txopt_get\n\n   - eth: ti: am65-cpsw: number of XDP-related fixes\n\n  Previous releases - regressions:\n\n   - Revert ""Bluetooth: MGMT/SMP: Fix address type when using SMP over\n     BREDR/LE""', "" it breaks existing user space\n\n   - Bluetooth: qca: if memdump doesn't work"", ' re-enable IBS to avoid\n     later problems with suspend\n\n   - can: mcp251x: fix deadlock if an interrupt occurs during\n     mcp251x_open\n\n   - eth: r8152: fix the firmware communication error due to use of bulk\n     write\n\n   - ptp: ocp: fix serial port information export\n\n   - eth: igb: fix not clearing TimeSync interrupts for 82580\n\n   - Revert ""wifi: ath11k: support hibernation""', ' fix suspend on Lenovo\n\n  Previous releases - always broken:\n\n   - eth: intel: fix crashes and bugs when reconfiguration and resets\n     happening in parallel\n\n   - wifi: ath11k: fix NULL dereference in ath11k_mac_get_eirp_power()\n\n  Misc:\n\n   - docs: netdev: document guidance on cleanup.h""\n\n* tag \'net-6.11-rc7\' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (61 commits)\n  ila: call nf_unregister_net_hooks() sooner\n  tools/net/ynl: fix cli.py --subscribe feature\n  MAINTAINERS: fix ptp ocp driver maintainers address\n  selftests: net: enable bind tests\n  net: dsa: vsc73xx: fix possible subblocks range of CAPT block\n  sched: sch_cake: fix bulk flow accounting logic for host fairness\n  docs: netdev: document guidance on cleanup.h\n  net: xilinx: axienet: Fix race in axienet_stop\n  net: bridge: br_fdb_external_learn_add(): always set EXT_LEARN\n  r8152: fix the firmware doesn\'t work\n  fou: Fix null-ptr-deref in GRO.\n  bareudp: Fix device stats updates.\n  net: mana: Fix error handling in mana_create_txq/rxq\'s NAPI cleanup\n  bpf', ' net: Fix a potential race in do_sock_getsockopt()\n  net: dqs: Do not use extern for unused dql_group\n  sch/netem: fix use after free in netem_dequeue\n  usbnet: modern method to get random MAC\n  MAINTAINERS: wifi: cw1200: add net-cw1200.h\n  ice: do not bring the VSI up', ' if it was down before the XDP setup\n  ice: remove ICE_CFG_BUSY locking from AF_XDP code\n  ...\n', '']",Merge networking fixes from Jakub Kicinski into Linux kernel by Linus Torvalds.,"networking, fixes, merge",It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
f0417c50fddd628e534c336d87932e7e1e883df3,f0417c50fddd628e534c336d87932e7e1e883df3,Jakub Kicinski,kuba@kernel.org,1725496657,Jakub Kicinski,kuba@kernel.org,1725496657,7b607a1a5f8adc6796cfc2771dc1f01fd62bde6e,2603d3152b1f646b0ef81a748fb703b799fcf9c3 04c7e14e5b0b6227e7b00d7a96ca2f2426ab9171,"Merge branch '100GbE' of git://git.kernel.org/pub/scm/linux/kernel/git/tnguy/net-queue

Tony Nguyen says:

====================
ice: fix synchronization between .ndo_bpf() and reset

Larysa Zaremba says:

PF reset can be triggered asynchronously"," by tx_timeout or by a user. With some
unfortunate timings both ice_vsi_rebuild() and .ndo_bpf will try to access and
modify XDP rings at the same time","["" causing system crash.\n\nThe first patch factors out rtnl-locked code from VSI rebuild code to avoid\ndeadlock. The following changes lock rebuild and .ndo_bpf() critical sections\nwith an internal mutex as well and provide complementary fixes.\n\n* '100GbE' of git://git.kernel.org/pub/scm/linux/kernel/git/tnguy/net-queue:\n  ice: do not bring the VSI up"", ' if it was down before the XDP setup\n  ice: remove ICE_CFG_BUSY locking from AF_XDP code\n  ice: check ICE_VSI_DOWN under rtnl_lock when preparing for reset\n  ice: check for XDP rings instead of bpf program when unconfiguring\n  ice: protect XDP configuration with a mutex\n  ice: move netif_queue_set_napi to rtnl-protected sections\n====================\n\nLink: https://patch.msgid.link/20240903183034.3530411-1-anthony.l.nguyen@intel.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Fix synchronization issue between .ndo_bpf() and reset in the ice driver due to async PF resets.,"synchronization, reset, ice",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['xdp like programs']
5390f315fc8c9b9f48105a0d88b56bc59fa2b3e0,5390f315fc8c9b9f48105a0d88b56bc59fa2b3e0,Alexei Starovoitov,ast@kernel.org,1725476194,Alexei Starovoitov,ast@kernel.org,1725478504,324cbb6757e625a5079894ce62f9c0e4bc0f4eb9,b408473ea01b2e499d23503e2bf898416da9d7ac 743070894724bf5ee0b2c77a28f838f6244d19bd,"Merge branch 'bpf-fix-incorrect-name-check-pass-logic-in-btf_name_valid_section'

Jeongjun Park says:

====================
bpf: fix incorrect name check pass logic in btf_name_valid_section

This patch was written to fix an issue where btf_name_valid_section() would
not properly check names with certain conditions and would throw an OOB vuln.
And selftest was added to verify this patch.
====================

Link: https://lore.kernel.org/r/20240831054525.364353-1-aha310510@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Fixes incorrect name check logic in btf_name_valid_section and adds a selftest.,"fix, name check, btf",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
743070894724bf5ee0b2c77a28f838f6244d19bd,743070894724bf5ee0b2c77a28f838f6244d19bd,Jeongjun Park,aha310510@gmail.com,1725083262,Alexei Starovoitov,ast@kernel.org,1725478459,324cbb6757e625a5079894ce62f9c0e4bc0f4eb9,bb6705c3f93bed2af03d43691743d4c43e3c8e6f,"selftests/bpf: Add a selftest to check for incorrect names

Add selftest for cases where btf_name_valid_section() does not properly
check for certain types of names.

Suggested-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Jeongjun Park <aha310510@gmail.com>
Link: https://lore.kernel.org/r/20240831054742.364585-1-aha310510@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
",,Added a selftest to verify btf_name_valid_section() function for incorrect names.,"selftest, btf_name_valid_section, names",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
bb6705c3f93bed2af03d43691743d4c43e3c8e6f,bb6705c3f93bed2af03d43691743d4c43e3c8e6f,Jeongjun Park,aha310510@gmail.com,1725083222,Alexei Starovoitov,ast@kernel.org,1725476194,930dce457cb48dc146e4fadd65db839cdb2487d4,b408473ea01b2e499d23503e2bf898416da9d7ac,"bpf: add check for invalid name in btf_name_valid_section()

If the length of the name string is 1 and the value of name[0] is NULL
byte"," an OOB vulnerability occurs in btf_name_valid_section() and the
return value is true","[' so the invalid name passes the check.\n\nTo solve this', ' you need to check if the first position is NULL byte and\nif the first character is printable.\n\nSuggested-by: Eduard Zingerman <eddyz87@gmail.com>\nFixes: bd70a8fb7ca4 (""bpf: Allow all printable characters in BTF DATASEC names"")\nSigned-off-by: Jeongjun Park <aha310510@gmail.com>\nLink: https://lore.kernel.org/r/20240831054702.364455-1-aha310510@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\n', '']",The commit adds a check for invalid names in btf_name_valid_section to prevent an OOB vulnerability.,"check, invalid, btf_name_valid_section",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
33f339a1ba54e56bba57ee9a77c71e385ab4825c,33f339a1ba54e56bba57ee9a77c71e385ab4825c,Tze-nan Wu,Tze-nan.Wu@mediatek.com,1725006317,Jakub Kicinski,kuba@kernel.org,1725390384,66713861c1b04e6459e0e652925f112e4bfafeb5,77461c10819103eaee7b33c744174b32a8c78b40,bpf," net: Fix a potential race in do_sock_getsockopt()

There's a potential race when `cgroup_bpf_enabled(CGROUP_GETSOCKOPT)` is
false during the execution of `BPF_CGROUP_GETSOCKOPT_MAX_OPTLEN`","[' but\nbecomes true when `BPF_CGROUP_RUN_PROG_GETSOCKOPT` is called.\nThis inconsistency can lead to `BPF_CGROUP_RUN_PROG_GETSOCKOPT` receiving\nan ""-EFAULT"" from `__cgroup_bpf_run_filter_getsockopt(max_optlen=0)`.\nScenario shown as below:\n\n           `process A`                      `process B`\n           -----------                      ------------\n  BPF_CGROUP_GETSOCKOPT_MAX_OPTLEN\n                                            enable CGROUP_GETSOCKOPT\n  BPF_CGROUP_RUN_PROG_GETSOCKOPT (-EFAULT)\n\nTo resolve this', ' remove the `BPF_CGROUP_GETSOCKOPT_MAX_OPTLEN` macro and\ndirectly uses `copy_from_sockptr` to ensure that `max_optlen` is always\nset before `BPF_CGROUP_RUN_PROG_GETSOCKOPT` is invoked.\n\nFixes: 0d01da6afc54 (""bpf: implement getsockopt and setsockopt hooks"")\nCo-developed-by: Yanghui Li <yanghui.li@mediatek.com>\nSigned-off-by: Yanghui Li <yanghui.li@mediatek.com>\nCo-developed-by: Cheng-Jui Wang <cheng-jui.wang@mediatek.com>\nSigned-off-by: Cheng-Jui Wang <cheng-jui.wang@mediatek.com>\nSigned-off-by: Tze-nan Wu <Tze-nan.Wu@mediatek.com>\nAcked-by: Stanislav Fomichev <sdf@fomichev.me>\nAcked-by: Alexei Starovoitov <ast@kernel.org>\nLink: https://patch.msgid.link/20240830082518.23243-1-Tze-nan.Wu@mediatek.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Fix potential race condition in do_sock_getsockopt when cgroup_bpf_enabled is false for CGROUP_GETSOCKOPT.,"race condition,cgroup_bpf_enabled,sock_getsockopt",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['cgroup like programs']
04c7e14e5b0b6227e7b00d7a96ca2f2426ab9171,04c7e14e5b0b6227e7b00d7a96ca2f2426ab9171,Larysa Zaremba,larysa.zaremba@intel.com,1724407171,Tony Nguyen,anthony.l.nguyen@intel.com,1725379540,c8aaeea8a842d3f1f39d548860fd0572a4566824,7e3b407ccbea3259b8583ccc34807622025e390f,ice: do not bring the VSI up," if it was down before the XDP setup

After XDP configuration is completed","[' we bring the interface up\nunconditionally', ' regardless of its state before the call to .ndo_bpf().\n\nPreserve the information whether the interface had to be brought down and\nlater bring it up only in such case.\n\nFixes: efc2214b6047 (""ice: Add support for XDP"")\nReviewed-by: Wojciech Drewek <wojciech.drewek@intel.com>\nReviewed-by: Jacob Keller <jacob.e.keller@intel.com>\nTested-by: Chandan Kumar Rout <chandanx.rout@intel.com>\nAcked-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>\nSigned-off-by: Larysa Zaremba <larysa.zaremba@intel.com>\nSigned-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>\n', '']",Prevent bringing up VSI if it was down before XDP setup.,"VSI,XDP,setup",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['xdp like programs']
d8c40b9d3a6cef61eb5a0c58c34a3090ea938d89,d8c40b9d3a6cef61eb5a0c58c34a3090ea938d89,Larysa Zaremba,larysa.zaremba@intel.com,1724407169,Tony Nguyen,anthony.l.nguyen@intel.com,1725379268,21dad620b2ca83810ec362edb35e0652991a24a1,f50c68763436bc8f805712a7c5ceaf58cfcf5f07,"ice: check ICE_VSI_DOWN under rtnl_lock when preparing for reset

Consider the following scenario:

.ndo_bpf()		| ice_prepare_for_reset()		|
________________________|_______________________________________|
rtnl_lock()		|					|
ice_down()		|					|
			| test_bit(ICE_VSI_DOWN) - true		|
			| ice_dis_vsi() returns			|
ice_up()		|					|
			| proceeds to rebuild a running VSI	|

.ndo_bpf() is not the only rtnl-locked callback that toggles the interface
to apply new configuration. Another example is .set_channels().

To avoid the race condition above"," act only after reading ICE_VSI_DOWN
under rtnl_lock.

Fixes: 0f9d5027a749 (""ice: Refactor VSI allocation","[' deletion and rebuild flow"")\nReviewed-by: Wojciech Drewek <wojciech.drewek@intel.com>\nReviewed-by: Jacob Keller <jacob.e.keller@intel.com>\nTested-by: Chandan Kumar Rout <chandanx.rout@intel.com>\nSigned-off-by: Larysa Zaremba <larysa.zaremba@intel.com>\nReviewed-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>\nSigned-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>\n', '']",The commit resolves a race condition by ensuring ICE_VSI_DOWN is checked under rtnl_lock before proceeding with reset preparation.,"race, rtnl_lock, ICE_VSI_DOWN",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['other']
f50c68763436bc8f805712a7c5ceaf58cfcf5f07,f50c68763436bc8f805712a7c5ceaf58cfcf5f07,Larysa Zaremba,larysa.zaremba@intel.com,1724407168,Tony Nguyen,anthony.l.nguyen@intel.com,1725379100,5647d47eedba407e96e30475e06fa1f54e33b823,2504b8405768a57a71e660dbfd5abd59f679a03f,"ice: check for XDP rings instead of bpf program when unconfiguring

If VSI rebuild is pending"," .ndo_bpf() can attach/detach the XDP program on
VSI without applying new ring configuration. When unconfiguring the VSI","[' we\ncan encounter the state in which there is an XDP program but no XDP rings\nto destroy or there will be XDP rings that need to be destroyed', ' but no XDP\nprogram to indicate their presence.\n\nWhen unconfiguring', ' rely on the presence of XDP rings rather then XDP\nprogram', ' as they better represent the current state that has to be\ndestroyed.\n\nReviewed-by: Wojciech Drewek <wojciech.drewek@intel.com>\nReviewed-by: Jacob Keller <jacob.e.keller@intel.com>\nTested-by: Chandan Kumar Rout <chandanx.rout@intel.com>\nAcked-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>\nSigned-off-by: Larysa Zaremba <larysa.zaremba@intel.com>\nSigned-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>\n', '']",The commit checks XDP rings presence instead of bpf program during unconfiguration if VSI rebuild is pending.,"XDP rings,VSI rebuild,unconfiguration",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['xdp like programs']
2a5dc090b92cfa5270e20056074241c6db5c9cdd,2a5dc090b92cfa5270e20056074241c6db5c9cdd,Larysa Zaremba,larysa.zaremba@intel.com,1724407166,Tony Nguyen,anthony.l.nguyen@intel.com,1725378496,4954f7521457bbb6625a630a5191b72016c75083,cfd433cecef929b4d92685f570f1a480762ec260,"ice: move netif_queue_set_napi to rtnl-protected sections

Currently"," netif_queue_set_napi() is called from ice_vsi_rebuild() that is
not rtnl-locked when called from the reset. This creates the need to take
the rtnl_lock just for a single function and complicates the
synchronization with .ndo_bpf. At the same time","[' there no actual need to\nfill napi-to-queue information at this exact point.\n\nFill napi-to-queue information when opening the VSI and clear it when the\nVSI is being closed. Those routines are already rtnl-locked.\n\nAlso', ' rewrite napi-to-queue assignment in a way that prevents inclusion of\nXDP queues', ' as this leads to out-of-bounds writes', ' such as one below.\n\n[  +0.000004] BUG: KASAN: slab-out-of-bounds in netif_queue_set_napi+0x1c2/0x1e0\n[  +0.000012] Write of size 8 at addr ffff889881727c80 by task bash/7047\n[  +0.000006] CPU: 24 PID: 7047 Comm: bash Not tainted 6.10.0-rc2+ #2\n[  +0.000004] Hardware name: Intel Corporation S2600WFT/S2600WFT', ' BIOS SE5C620.86B.02.01.0014.082620210524 08/26/2021\n[  +0.000003] Call Trace:\n[  +0.000003]  <TASK>\n[  +0.000002]  dump_stack_lvl+0x60/0x80\n[  +0.000007]  print_report+0xce/0x630\n[  +0.000007]  ? __pfx__raw_spin_lock_irqsave+0x10/0x10\n[  +0.000007]  ? __virt_addr_valid+0x1c9/0x2c0\n[  +0.000005]  ? netif_queue_set_napi+0x1c2/0x1e0\n[  +0.000003]  kasan_report+0xe9/0x120\n[  +0.000004]  ? netif_queue_set_napi+0x1c2/0x1e0\n[  +0.000004]  netif_queue_set_napi+0x1c2/0x1e0\n[  +0.000005]  ice_vsi_close+0x161/0x670 [ice]\n[  +0.000114]  ice_dis_vsi+0x22f/0x270 [ice]\n[  +0.000095]  ice_pf_dis_all_vsi.constprop.0+0xae/0x1c0 [ice]\n[  +0.000086]  ice_prepare_for_reset+0x299/0x750 [ice]\n[  +0.000087]  pci_dev_save_and_disable+0x82/0xd0\n[  +0.000006]  pci_reset_function+0x12d/0x230\n[  +0.000004]  reset_store+0xa0/0x100\n[  +0.000006]  ? __pfx_reset_store+0x10/0x10\n[  +0.000002]  ? __pfx_mutex_lock+0x10/0x10\n[  +0.000004]  ? __check_object_size+0x4c1/0x640\n[  +0.000007]  kernfs_fop_write_iter+0x30b/0x4a0\n[  +0.000006]  vfs_write+0x5d6/0xdf0\n[  +0.000005]  ? fd_install+0x180/0x350\n[  +0.000005]  ? __pfx_vfs_write+0x10/0xA10\n[  +0.000004]  ? do_fcntl+0x52c/0xcd0\n[  +0.000004]  ? kasan_save_track+0x13/0x60\n[  +0.000003]  ? kasan_save_free_info+0x37/0x60\n[  +0.000006]  ksys_write+0xfa/0x1d0\n[  +0.000003]  ? __pfx_ksys_write+0x10/0x10\n[  +0.000002]  ? __x64_sys_fcntl+0x121/0x180\n[  +0.000004]  ? _raw_spin_lock+0x87/0xe0\n[  +0.000005]  do_syscall_64+0x80/0x170\n[  +0.000007]  ? _raw_spin_lock+0x87/0xe0\n[  +0.000004]  ? __pfx__raw_spin_lock+0x10/0x10\n[  +0.000003]  ? file_close_fd_locked+0x167/0x230\n[  +0.000005]  ? syscall_exit_to_user_mode+0x7d/0x220\n[  +0.000005]  ? do_syscall_64+0x8c/0x170\n[  +0.000004]  ? do_syscall_64+0x8c/0x170\n[  +0.000003]  ? do_syscall_64+0x8c/0x170\n[  +0.000003]  ? fput+0x1a/0x2c0\n[  +0.000004]  ? filp_close+0x19/0x30\n[  +0.000004]  ? do_dup2+0x25a/0x4c0\n[  +0.000004]  ? __x64_sys_dup2+0x6e/0x2e0\n[  +0.000002]  ? syscall_exit_to_user_mode+0x7d/0x220\n[  +0.000004]  ? do_syscall_64+0x8c/0x170\n[  +0.000003]  ? __count_memcg_events+0x113/0x380\n[  +0.000005]  ? handle_mm_fault+0x136/0x820\n[  +0.000005]  ? do_user_addr_fault+0x444/0xa80\n[  +0.000004]  ? clear_bhb_loop+0x25/0x80\n[  +0.000004]  ? clear_bhb_loop+0x25/0x80\n[  +0.000002]  entry_SYSCALL_64_after_hwframe+0x76/0x7e\n[  +0.000005] RIP: 0033:0x7f2033593154\n\nFixes: 080b0c8d6d26 (""ice: Fix ASSERT_RTNL() warning during certain scenarios"")\nFixes: 91fdbce7e8d6 (""ice: Add support in the driver for associating queue with napi"")\nReviewed-by: Wojciech Drewek <wojciech.drewek@intel.com>\nReviewed-by: Jacob Keller <jacob.e.keller@intel.com>\nReviewed-by: Amritha Nambiar <amritha.nambiar@intel.com>\nSigned-off-by: Larysa Zaremba <larysa.zaremba@intel.com>\nReviewed-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>\nTested-by: George Kuruvinakunnel <george.kuruvinakunnel@intel.com>\nSigned-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>\n', '']",The commit moves netif_queue_set_napi to rtnl-protected sections for better synchronization.,"netif_queue_set_napi,rtnl_lock,synchronization",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
287bd5cf06e0f2c02293ce942777ad1f18059ed3,287bd5cf06e0f2c02293ce942777ad1f18059ed3,Namhyung Kim,namhyung@kernel.org,1724822993,Namhyung Kim,namhyung@kernel.org,1725303564,bb8bd6ad399b7b5dbf1e06024e44825d84bbdcbb,1c7fb536e899a2f66f9b1719a0234570dda2e634,"perf lock contention: Fix spinlock and rwlock accounting

The spinlock and rwlock use a single-element per-cpu array to track
current locks due to performance reason.  But this means the key is
always available and it cannot simply account lock stats in the array
because some of them are invalid.

In fact"," the contention_end() program in the BPF invalidates the entry
by setting the 'lock' value to 0 instead of deleting the entry for the
hashmap.  So it should skip entries with the lock value of 0 in the
account_end_timestamp().

Otherwise","["" it'd have spurious high contention on an idle machine:\n\n  $ sudo perf lock con -ab -Y spinlock sleep 3\n   contended   total wait     max wait     avg wait         type   caller\n\n           8      4.72 s       1.84 s     590.46 ms     spinlock   rcu_core+0xc7\n           8      1.87 s       1.87 s     233.48 ms     spinlock   process_one_work+0x1b5\n           2      1.87 s       1.87 s     933.92 ms     spinlock   worker_thread+0x1a2\n           3      1.81 s       1.81 s     603.93 ms     spinlock   tmigr_update_events+0x13c\n           2      1.72 s       1.72 s     861.98 ms     spinlock   tick_do_update_jiffies64+0x25\n           6     42.48 us     13.02 us      7.08 us     spinlock   futex_q_lock+0x2a\n           1     13.03 us     13.03 us     13.03 us     spinlock   futex_wake+0xce\n           1     11.61 us     11.61 us     11.61 us     spinlock   rcu_core+0xc7\n\nI don't believe it has contention on a spinlock longer than 1 second.\nAfter this change"", ' it only reports some small contentions.\n\n  $ sudo perf lock con -ab -Y spinlock sleep 3\n   contended   total wait     max wait     avg wait         type   caller\n\n           4    133.51 us     43.29 us     33.38 us     spinlock   tick_do_update_jiffies64+0x25\n           4     69.06 us     31.82 us     17.27 us     spinlock   process_one_work+0x1b5\n           2     50.66 us     25.77 us     25.33 us     spinlock   rcu_core+0xc7\n           1     28.45 us     28.45 us     28.45 us     spinlock   rcu_core+0xc7\n           1     24.77 us     24.77 us     24.77 us     spinlock   tmigr_update_events+0x13c\n           1     23.34 us     23.34 us     23.34 us     spinlock   raw_spin_rq_lock_nested+0x15\n\nFixes: b5711042a1c8 (""perf lock contention: Use per-cpu array map for spinlocks"")\nReported-by: Xi Wang <xii@google.com>\nCc: Song Liu <song@kernel.org>\nCc: bpf@vger.kernel.org\nLink: https://lore.kernel.org/r/20240828052953.1445862-1-namhyung@kernel.org\nSigned-off-by: Namhyung Kim <namhyung@kernel.org>\n', '']",Fixes accounting issues in spinlock and rwlock usage for perf lock contention related to BPF program.,spinlock rwlock accounting,It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
fe1910f9337bd46a9343967b547ccab26b4b2c6e,fe1910f9337bd46a9343967b547ccab26b4b2c6e,Cong Wang,cong.wang@bytedance.com,1724209664,Jakub Kicinski,kuba@kernel.org,1725041350,9818279ed57aba1c5e2ce6d018ea14f6d6620d50,98d4435efcbf37801a3246fb53856c4b934a2613,"tcp_bpf: fix return value of tcp_bpf_sendmsg()

When we cork messages in psock->cork"," the last message triggers the
flushing will result in sending a sk_msg larger than the current
message size. In this case","[' in tcp_bpf_send_verdict()', "" 'copied' becomes\nnegative at least in the following case:\n\n468         case __SK_DROP:\n469         default:\n470                 sk_msg_free_partial(sk"", ' msg', ' tosend);\n471                 sk_msg_apply_bytes(psock', ' tosend);\n472                 *copied -= (tosend + delta); // <==== HERE\n473                 return -EACCES;\n\nTherefore', "" it could lead to the following BUG with a proper value of\n'copied' (thanks to syzbot). We should not use negative 'copied' as a\nreturn value here.\n\n  ------------[ cut here ]------------\n  kernel BUG at net/socket.c:733!\n  Internal error: Oops - BUG: 00000000f2000800 [#1] PREEMPT SMP\n  Modules linked in:\n  CPU: 0 UID: 0 PID: 3265 Comm: syz-executor510 Not tainted 6.11.0-rc3-syzkaller-00060-gd07b43284ab3 #0\n  Hardware name: linux"", 'dummy-virt (DT)\n  pstate: 61400009 (nZCv daif +PAN -UAO -TCO +DIT -SSBS BTYPE=--)\n  pc : sock_sendmsg_nosec net/socket.c:733 [inline]\n  pc : sock_sendmsg_nosec net/socket.c:728 [inline]\n  pc : __sock_sendmsg+0x5c/0x60 net/socket.c:745\n  lr : sock_sendmsg_nosec net/socket.c:730 [inline]\n  lr : __sock_sendmsg+0x54/0x60 net/socket.c:745\n  sp : ffff800088ea3b30\n  x29: ffff800088ea3b30 x28: fbf00000062bc900 x27: 0000000000000000\n  x26: ffff800088ea3bc0 x25: ffff800088ea3bc0 x24: 0000000000000000\n  x23: f9f00000048dc000 x22: 0000000000000000 x21: ffff800088ea3d90\n  x20: f9f00000048dc000 x19: ffff800088ea3d90 x18: 0000000000000001\n  x17: 0000000000000000 x16: 0000000000000000 x15: 000000002002ffaf\n  x14: 0000000000000000 x13: 0000000000000000 x12: 0000000000000000\n  x11: 0000000000000000 x10: ffff8000815849c0 x9 : ffff8000815b49c0\n  x8 : 0000000000000000 x7 : 000000000000003f x6 : 0000000000000000\n  x5 : 00000000000007e0 x4 : fff07ffffd239000 x3 : fbf00000062bc900\n  x2 : 0000000000000000 x1 : 0000000000000000 x0 : 00000000fffffdef\n  Call trace:\n   sock_sendmsg_nosec net/socket.c:733 [inline]\n   __sock_sendmsg+0x5c/0x60 net/socket.c:745\n   ____sys_sendmsg+0x274/0x2ac net/socket.c:2597\n   ___sys_sendmsg+0xac/0x100 net/socket.c:2651\n   __sys_sendmsg+0x84/0xe0 net/socket.c:2680\n   __do_sys_sendmsg net/socket.c:2689 [inline]\n   __se_sys_sendmsg net/socket.c:2687 [inline]\n   __arm64_sys_sendmsg+0x24/0x30 net/socket.c:2687\n   __invoke_syscall arch/arm64/kernel/syscall.c:35 [inline]\n   invoke_syscall+0x48/0x110 arch/arm64/kernel/syscall.c:49\n   el0_svc_common.constprop.0+0x40/0xe0 arch/arm64/kernel/syscall.c:132\n   do_el0_svc+0x1c/0x28 arch/arm64/kernel/syscall.c:151\n   el0_svc+0x34/0xec arch/arm64/kernel/entry-common.c:712\n   el0t_64_sync_handler+0x100/0x12c arch/arm64/kernel/entry-common.c:730\n   el0t_64_sync+0x19c/0x1a0 arch/arm64/kernel/entry.S:598\n  Code: f9404463 d63f0060 3108441f 54fffe81 (d4210000)\n  ---[ end trace 0000000000000000 ]---\n\nFixes: 4f738adba30a (""bpf: create tcp_bpf_ulp allowing BPF to monitor socket TX/RX data"")\nReported-by: syzbot+58c03971700330ce14d8@syzkaller.appspotmail.com\nCc: Jakub Sitnicki <jakub@cloudflare.com>\nSigned-off-by: Cong Wang <cong.wang@bytedance.com>\nReviewed-by: John Fastabend <john.fastabend@gmail.com>\nAcked-by: Martin KaFai Lau <martin.lau@kernel.org>\nLink: https://patch.msgid.link/20240821030744.320934-1-xiyou.wangcong@gmail.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Fix return value issue in tcp_bpf_sendmsg function when corking messages.,"tcp_bpf,fix,sendmsg",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['socket like programs']
b408473ea01b2e499d23503e2bf898416da9d7ac,b408473ea01b2e499d23503e2bf898416da9d7ac,Martin KaFai Lau,martin.lau@kernel.org,1724980934,Andrii Nakryiko,andrii@kernel.org,1725039287,70c517cb3976788548d24c9af4d968f311166ac6,872cf28b8df9c5c3a1e71a88ee750df7c2513971,"bpf: Fix a crash when btf_parse_base() returns an error pointer

The pointer returned by btf_parse_base could be an error pointer.
IS_ERR() check is needed before calling btf_free(base_btf).

Fixes: 8646db238997 (""libbpf","bpf: Share BTF relocate-related code with kernel"")
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Reviewed-by: Alan Maguire <alan.maguire@oracle.com>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/bpf/20240830012214.1646005-1-martin.lau@linux.dev
",[''],Fixes a crash caused by error pointer returned from btf_parse_base by adding IS_ERR() check before calling btf_free.,"crash,error pointer,btf_parse_base",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2aeeef906d5a526dc60cf4af92eda69836c39b1f,2aeeef906d5a526dc60cf4af92eda69836c39b1f,Jianbo Liu,jianbol@nvidia.com,1724382656,Jakub Kicinski,kuba@kernel.org,1724789497,1843c88b7e4389cc5f9c255a14746df945419649,907ed83a7583e8ffede88c5ac088392701a7d458,"bonding: change ipsec_lock from spin lock to mutex

In the cited commit", bond->ipsec_lock is added to protect ipsec_list,"['\nhence xdo_dev_state_add and xdo_dev_state_delete are called inside\nthis lock. As ipsec_lock is a spin lock and such xfrmdev ops may sleep', '\n""scheduling while atomic"" will be triggered when changing bond\'s\nactive slave.\n\n[  101.055189] BUG: scheduling while atomic: bash/902/0x00000200\n[  101.055726] Modules linked in:\n[  101.058211] CPU: 3 PID: 902 Comm: bash Not tainted 6.9.0-rc4+ #1\n[  101.058760] Hardware name:\n[  101.059434] Call Trace:\n[  101.059436]  <TASK>\n[  101.060873]  dump_stack_lvl+0x51/0x60\n[  101.061275]  __schedule_bug+0x4e/0x60\n[  101.061682]  __schedule+0x612/0x7c0\n[  101.062078]  ? __mod_timer+0x25c/0x370\n[  101.062486]  schedule+0x25/0xd0\n[  101.062845]  schedule_timeout+0x77/0xf0\n[  101.063265]  ? asm_common_interrupt+0x22/0x40\n[  101.063724]  ? __bpf_trace_itimer_state+0x10/0x10\n[  101.064215]  __wait_for_common+0x87/0x190\n[  101.064648]  ? usleep_range_state+0x90/0x90\n[  101.065091]  cmd_exec+0x437/0xb20 [mlx5_core]\n[  101.065569]  mlx5_cmd_do+0x1e/0x40 [mlx5_core]\n[  101.066051]  mlx5_cmd_exec+0x18/0x30 [mlx5_core]\n[  101.066552]  mlx5_crypto_create_dek_key+0xea/0x120 [mlx5_core]\n[  101.067163]  ? bonding_sysfs_store_option+0x4d/0x80 [bonding]\n[  101.067738]  ? kmalloc_trace+0x4d/0x350\n[  101.068156]  mlx5_ipsec_create_sa_ctx+0x33/0x100 [mlx5_core]\n[  101.068747]  mlx5e_xfrm_add_state+0x47b/0xaa0 [mlx5_core]\n[  101.069312]  bond_change_active_slave+0x392/0x900 [bonding]\n[  101.069868]  bond_option_active_slave_set+0x1c2/0x240 [bonding]\n[  101.070454]  __bond_opt_set+0xa6/0x430 [bonding]\n[  101.070935]  __bond_opt_set_notify+0x2f/0x90 [bonding]\n[  101.071453]  bond_opt_tryset_rtnl+0x72/0xb0 [bonding]\n[  101.071965]  bonding_sysfs_store_option+0x4d/0x80 [bonding]\n[  101.072567]  kernfs_fop_write_iter+0x10c/0x1a0\n[  101.073033]  vfs_write+0x2d8/0x400\n[  101.073416]  ? alloc_fd+0x48/0x180\n[  101.073798]  ksys_write+0x5f/0xe0\n[  101.074175]  do_syscall_64+0x52/0x110\n[  101.074576]  entry_SYSCALL_64_after_hwframe+0x4b/0x53\n\nAs bond_ipsec_add_sa_all and bond_ipsec_del_sa_all are only called\nfrom bond_change_active_slave', ' which requires holding the RTNL lock.\nAnd bond_ipsec_add_sa and bond_ipsec_del_sa are xfrm state\nxdo_dev_state_add and xdo_dev_state_delete APIs', "" which are in user\ncontext. So ipsec_lock doesn't have to be spin lock"", ' change it to\nmutex', ' and thus the above issue can be resolved.\n\nFixes: 9a5605505d9c (""bonding: Add struct bond_ipesc to manage SA"")\nSigned-off-by: Jianbo Liu <jianbol@nvidia.com>\nSigned-off-by: Tariq Toukan <tariqt@nvidia.com>\nReviewed-by: Hangbin Liu <liuhangbin@gmail.com>\nAcked-by: Jay Vosburgh <jv@jvosburgh.net>\nLink: https://patch.msgid.link/20240823031056.110999-4-jianbol@nvidia.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",The commit changes the ipsec_lock from a spin lock to a mutex for better protection of ipsec_list.,"ipsec_lock, mutex, bonding",It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['other']
8baeef7616d5194045c5a6b97fd1246b87c55b13,8baeef7616d5194045c5a6b97fd1246b87c55b13,Somnath Kotur,somnath.kotur@broadcom.com,1724186055,Jakub Kicinski,kuba@kernel.org,1724287016,95a7a37cd3a4e43fc55f9add66c18ccc5dd2ec01,58652e2422a7407e77ee50fcaaf4bf1885de8753,"bnxt_en: Fix double DMA unmapping for XDP_REDIRECT

Remove the dma_unmap_page_attrs() call in the driver's XDP_REDIRECT
code path.  This should have been removed when we let the page pool
handle the DMA mapping.  This bug causes the warning:

WARNING: CPU: 7 PID: 59 at drivers/iommu/dma-iommu.c:1198 iommu_dma_unmap_page+0xd5/0x100
CPU: 7 PID: 59 Comm: ksoftirqd/7 Tainted: G        W          6.8.0-1010-gcp #11-Ubuntu
Hardware name: Dell Inc. PowerEdge R7525/0PYVT1"," BIOS 2.15.2 04/02/2024
RIP: 0010:iommu_dma_unmap_page+0xd5/0x100
Code: 89 ee 48 89 df e8 cb f2 69 ff 48 83 c4 08 5b 41 5c 41 5d 41 5e 41 5f 5d 31 c0 31 d2 31 c9 31 f6 31 ff 45 31 c0 e9 ab 17 71 00 <0f> 0b 48 83 c4 08 5b 41 5c 41 5d 41 5e 41 5f 5d 31 c0 31 d2 31 c9
RSP: 0018:ffffab1fc0597a48 EFLAGS: 00010246
RAX: 0000000000000000 RBX: ffff99ff838280c8 RCX: 0000000000000000
RDX: 0000000000000000 RSI: 0000000000000000 RDI: 0000000000000000
RBP: ffffab1fc0597a78 R08: 0000000000000002 R09: ffffab1fc0597c1c
R10: ffffab1fc0597cd3 R11: ffff99ffe375acd8 R12: 00000000e65b9000
R13: 0000000000000050 R14: 0000000000001000 R15: 0000000000000002
FS:  0000000000000000(0000) GS:ffff9a06efb80000(0000) knlGS:0000000000000000
CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
CR2: 0000565c34c37210 CR3: 00000005c7e3e000 CR4: 0000000000350ef0
? show_regs+0x6d/0x80
? __warn+0x89/0x150
? iommu_dma_unmap_page+0xd5/0x100
? report_bug+0x16a/0x190
? handle_bug+0x51/0xa0
? exc_invalid_op+0x18/0x80
? iommu_dma_unmap_page+0xd5/0x100
? iommu_dma_unmap_page+0x35/0x100
dma_unmap_page_attrs+0x55/0x220
? bpf_prog_4d7e87c0d30db711_xdp_dispatcher+0x64/0x9f
bnxt_rx_xdp+0x237/0x520 [bnxt_en]
bnxt_rx_pkt+0x640/0xdd0 [bnxt_en]
__bnxt_poll_work+0x1a1/0x3d0 [bnxt_en]
bnxt_poll+0xaa/0x1e0 [bnxt_en]
__napi_poll+0x33/0x1e0
net_rx_action+0x18a/0x2f0

Fixes: 578fcfd26e2a (""bnxt_en: Let the page pool manage the DMA mapping"")
Reviewed-by: Andy Gospodarek <andrew.gospodarek@broadcom.com>
Reviewed-by: Kalesh AP <kalesh-anakkur.purayil@broadcom.com>
Signed-off-by: Somnath Kotur <somnath.kotur@broadcom.com>
Signed-off-by: Michael Chan <michael.chan@broadcom.com>
Reviewed-by: Jacob Keller <jacob.e.keller@intel.com>
Link: https://patch.msgid.link/20240820203415.168178-1-michael.chan@broadcom.com
Signed-off-by: Jakub Kicinski <kuba@kernel.org>
",[''],Fix to remove unnecessary DMA unmapping in bnxt_en driver for XDP_REDIRECT.,"bnxt_en,DMA unmapping,XDP_REDIRECT",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.",['xdp like programs']
a069a22f391019e84390f4e8c1a9c531ba4fb28f,a069a22f391019e84390f4e8c1a9c531ba4fb28f,Masami Hiramatsu (Google),mhiramat@kernel.org,1723985283,Steven Rostedt (Google),rostedt@goodmis.org,1724262599,71783f4f8b8d11ba0ec2af9f7cea53511253b3c7,47ac09b91befbb6a235ab620c32af719f8208399,"tracing: fgraph: Fix to add new fgraph_ops to array after ftrace_startup_subops()

Since the register_ftrace_graph() assigns a new fgraph_ops to
fgraph_array before registring it by ftrace_startup_subops()"," the new
fgraph_ops can be used in function_graph_enter().

In most cases","["" it is still OK because those fgraph_ops's hashtable is\nalready initialized by ftrace_set_filter*() etc.\n\nBut if a user registers a new fgraph_ops which does not initialize the\nhash list"", "" ftrace_ops_test() in function_graph_enter() causes a NULL\npointer dereference BUG because fgraph_ops->ops.func_hash is NULL.\n\nThis can be reproduced by the below commands because function profiler's\nfgraph_ops does not initialize the hash list;\n\n # cd /sys/kernel/tracing\n # echo function_graph > current_tracer\n # echo 1 > function_profile_enabled\n\nTo fix this problem"", ' add a new fgraph_ops to fgraph_array after\nftrace_startup_subops(). Thus', ' until the new fgraph_ops is initialized', '\nwe will see fgraph_stub on the corresponding fgraph_array entry.\n\nCc: Alexei Starovoitov <alexei.starovoitov@gmail.com>\nCc: Florent Revest <revest@chromium.org>\nCc: Martin KaFai Lau <martin.lau@linux.dev>\nCc: bpf <bpf@vger.kernel.org>\nCc: Sven Schnelle <svens@linux.ibm.com>\nCc: Alexei Starovoitov <ast@kernel.org>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: Arnaldo Carvalho de Melo <acme@kernel.org>\nCc: Daniel Borkmann <daniel@iogearbox.net>\nCc: Alan Maguire <alan.maguire@oracle.com>\nCc: Mark Rutland <mark.rutland@arm.com>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Thomas Gleixner <tglx@linutronix.de>\nCc: Guo Ren <guoren@kernel.org>\nLink: https://lore.kernel.org/172398528350.293426.8347220120333730248.stgit@devnote2\nFixes: c132be2c4fcc (""function_graph: Have the instances use their own ftrace_ops for filtering"")\nSigned-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\nSigned-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>\n', '']",Fix the order of operations when adding new fgraph ops to the array for ftrace graph functionality.,"fgraph_ops,ftrace,tracing",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f8cde9805981c50d0c029063dc7d82821806fc44,f8cde9805981c50d0c029063dc7d82821806fc44,Nikolay Aleksandrov,razor@blackwall.org,1723808892,Paolo Abeni,pabeni@redhat.com,1724160569,7a9ee1dc199ede7f15683dbaa13d1c6967435e27,95c90e4ad89d493a7a14fa200082e466e2548f9d,"bonding: fix xfrm real_dev null pointer dereference

We shouldn't set real_dev to NULL because packets can be in transit and
xfrm might call xdo_dev_offload_ok() in parallel. All callbacks assume
real_dev is set.

 Example trace:
 kernel: BUG: unable to handle page fault for address: 0000000000001030
 kernel: bond0: (slave eni0np1): making interface the new active one
 kernel: #PF: supervisor write access in kernel mode
 kernel: #PF: error_code(0x0002) - not-present page
 kernel: PGD 0 P4D 0
 kernel: Oops: 0002 [#1] PREEMPT SMP
 kernel: CPU: 4 PID: 2237 Comm: ping Not tainted 6.7.7+ #12
 kernel: Hardware name: QEMU Standard PC (Q35 + ICH9", 2009),"[' BIOS 1.16.3-2.fc40 04/01/2014\n kernel: RIP: 0010:nsim_ipsec_offload_ok+0xc/0x20 [netdevsim]\n kernel: bond0: (slave eni0np1): bond_ipsec_add_sa_all: failed to add SA\n kernel: Code: e0 0f 0b 48 83 7f 38 00 74 de 0f 0b 48 8b 47 08 48 8b 37 48 8b 78 40 e9 b2 e5 9a d7 66 90 0f 1f 44 00 00 48 8b 86 80 02 00 00 <83> 80 30 10 00 00 01 b8 01 00 00 00 c3 0f 1f 80 00 00 00 00 0f 1f\n kernel: bond0: (slave eni0np1): making interface the new active one\n kernel: RSP: 0018:ffffabde81553b98 EFLAGS: 00010246\n kernel: bond0: (slave eni0np1): bond_ipsec_add_sa_all: failed to add SA\n kernel:\n kernel: RAX: 0000000000000000 RBX: ffff9eb404e74900 RCX: ffff9eb403d97c60\n kernel: RDX: ffffffffc090de10 RSI: ffff9eb404e74900 RDI: ffff9eb3c5de9e00\n kernel: RBP: ffff9eb3c0a42000 R08: 0000000000000010 R09: 0000000000000014\n kernel: R10: 7974203030303030 R11: 3030303030303030 R12: 0000000000000000\n kernel: R13: ffff9eb3c5de9e00 R14: ffffabde81553cc8 R15: ffff9eb404c53000\n kernel: FS:  00007f2a77a3ad00(0000) GS:ffff9eb43bd00000(0000) knlGS:0000000000000000\n kernel: CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n kernel: CR2: 0000000000001030 CR3: 00000001122ab000 CR4: 0000000000350ef0\n kernel: bond0: (slave eni0np1): making interface the new active one\n kernel: Call Trace:\n kernel:  <TASK>\n kernel:  ? __die+0x1f/0x60\n kernel: bond0: (slave eni0np1): bond_ipsec_add_sa_all: failed to add SA\n kernel:  ? page_fault_oops+0x142/0x4c0\n kernel:  ? do_user_addr_fault+0x65/0x670\n kernel:  ? kvm_read_and_reset_apf_flags+0x3b/0x50\n kernel: bond0: (slave eni0np1): making interface the new active one\n kernel:  ? exc_page_fault+0x7b/0x180\n kernel:  ? asm_exc_page_fault+0x22/0x30\n kernel:  ? nsim_bpf_uninit+0x50/0x50 [netdevsim]\n kernel: bond0: (slave eni0np1): bond_ipsec_add_sa_all: failed to add SA\n kernel:  ? nsim_ipsec_offload_ok+0xc/0x20 [netdevsim]\n kernel: bond0: (slave eni0np1): making interface the new active one\n kernel:  bond_ipsec_offload_ok+0x7b/0x90 [bonding]\n kernel:  xfrm_output+0x61/0x3b0\n kernel: bond0: (slave eni0np1): bond_ipsec_add_sa_all: failed to add SA\n kernel:  ip_push_pending_frames+0x56/0x80\n\nFixes: 18cb261afd7b (""bonding: support hardware encryption offload to slaves"")\nSigned-off-by: Nikolay Aleksandrov <razor@blackwall.org>\nReviewed-by: Hangbin Liu <liuhangbin@gmail.com>\nSigned-off-by: Paolo Abeni <pabeni@redhat.com>\n\n', '']",Fixes a null pointer dereference in bonding related to xfrm's real_dev setting during packet transit.,"bonding,null-pointer,xfrm",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
69139d2919dd4aa9a553c8245e7c63e82613e3fc,69139d2919dd4aa9a553c8245e7c63e82613e3fc,Cong Wang,cong.wang@bytedance.com,1723429313,Paolo Abeni,pabeni@redhat.com,1723716424,072eafbdd97a3d7ed4981ac2f89eef90974a8582,b2ca1661c7db9693095cee7991c55d67c3b5d346,"vsock: fix recursive ->recvmsg calls

After a vsock socket has been added to a BPF sockmap"," its prot->recvmsg
has been replaced with vsock_bpf_recvmsg(). Thus the following
recursiion could happen:

vsock_bpf_recvmsg()
 -> __vsock_recvmsg()
  -> vsock_connectible_recvmsg()
   -> prot->recvmsg()
    -> vsock_bpf_recvmsg() again

We need to fix it by calling the original ->recvmsg() without any BPF
sockmap logic in __vsock_recvmsg().

Fixes: 634f1a7110b4 (""vsock: support sockmap"")
Reported-by: syzbot+bdb4bd87b5e22058e2a4@syzkaller.appspotmail.com
Tested-by: syzbot+bdb4bd87b5e22058e2a4@syzkaller.appspotmail.com
Cc: Bobby Eshleman <bobby.eshleman@bytedance.com>
Cc: Michael S. Tsirkin <mst@redhat.com>
Cc: Stefano Garzarella <sgarzare@redhat.com>
Signed-off-by: Cong Wang <cong.wang@bytedance.com>
Acked-by: Michael S. Tsirkin <mst@redhat.com>
Link: https://patch.msgid.link/20240812022153.86512-1-xiyou.wangcong@gmail.com
Signed-off-by: Paolo Abeni <pabeni@redhat.com>

",[''],Fixes recursive calls in vsock recvmsg function after integration with BPF sockmap.,"vsock,BPF,recvmsg",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The syscall interface,"['socket like programs', 'tracepoints like programs']"
02f8ca3d49055788f112c17052a3da65feb01835,02f8ca3d49055788f112c17052a3da65feb01835,Linus Torvalds,torvalds@linux-foundation.org,1723651044,Linus Torvalds,torvalds@linux-foundation.org,1723651044,2a6deda6c8f5faac94fe4d0cc15ae13d972e8acd,6b0f8db921abf0520081d779876d3a41069dab95 100bff23818eb61751ed05d64a7df36ce9728a4d,"Merge tag 'bpf-6.11-rc4' of git://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Pull bpf fixes from Alexei Starovoitov:

 - Fix bpftrace regression from Kyle Huey.

   Tracing bpf prog was called with perf_event input arguments causing
   bpftrace produce garbage output.

 - Fix verifier crash in stacksafe() from Yonghong Song.

   Daniel Hodges reported verifier crash when playing with sched-ext.
   The stack depth in the known verifier state was larger than stack
   depth in being explored state causing out-of-bounds access.

 - Fix update of freplace prog in prog_array from Leon Hwang.

   freplace prog type wasn't recognized correctly.

* tag 'bpf-6.11-rc4' of git://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:
  perf/bpf: Don't call bpf_overflow_handler() for tracing events
  selftests/bpf: Add a test to verify previous stacksafe() fix
  bpf: Fix a kernel verifier crash in stacksafe()
  bpf: Fix updating attached freplace prog in prog_array map
",,"The commit merges bpf fixes including regression fixes, verifier crash fix, and update issues for the freplace prog in prog_array.","bpf, regression, verifier",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
100bff23818eb61751ed05d64a7df36ce9728a4d,100bff23818eb61751ed05d64a7df36ce9728a4d,Kyle Huey,me@kylehuey.com,1723562247,Alexei Starovoitov,ast@kernel.org,1723569928,0fd72c4af5e3f07407caffd2003617df180cdcbe,662c3e2db00f92e50c26e9dc4fe47c52223d9982,"perf/bpf: Don't call bpf_overflow_handler() for tracing events

The regressing commit is new in 6.10. It assumed that anytime event->prog
is set bpf_overflow_handler() should be invoked to execute the attached bpf
program. This assumption is false for tracing events"," and as a result the
regressing commit broke bpftrace by invoking the bpf handler with garbage
inputs on overflow.

Prior to the regression the overflow handlers formed a chain (of length 0","['\n1', ' or 2) and perf_event_set_bpf_handler() (the !tracing case) added\nbpf_overflow_handler() to that chain', ' while perf_event_attach_bpf_prog()\n(the tracing case) did not. Both set event->prog. The chain of overflow\nhandlers was replaced by a single overflow handler slot and a fixed call to\nbpf_overflow_handler() when appropriate. This modifies the condition there\nto check event->prog->type == BPF_PROG_TYPE_PERF_EVENT', ' restoring the\nprevious behavior and fixing bpftrace.\n\nSigned-off-by: Kyle Huey <khuey@kylehuey.com>\nSuggested-by: Andrii Nakryiko <andrii.nakryiko@gmail.com>\nReported-by: Joe Damato <jdamato@fastly.com>\nCloses: https://lore.kernel.org/lkml/ZpFfocvyF3KHaSzF@LQ3V64L9R2/\nFixes: f11f10bfa1ca (""perf/bpf: Call BPF handler directly', ' not through overflow machinery"")\nCc: stable@vger.kernel.org\nTested-by: Joe Damato <jdamato@fastly.com> # bpftrace\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240813151727.28797-1-jdamato@fastly.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes incorrect invocation of bpf_overflow_handler() for tracing events causing regression in bpftrace.,"perf,BPF,tracing",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['tracepoints like programs', 'kprobe/uprobe/ftrace like programs']"
6252690f7e1b173b86a4c27dfc046b351ab423e7,6252690f7e1b173b86a4c27dfc046b351ab423e7,Naohiro Aota,naohiro.aota@wdc.com,1723190062,David Sterba,dsterba@suse.com,1723556217,11f04900c6a0070aa13a5cf0515c58304e8de060,46a6e10a1ab16cc71d4a3cab73e79aabadd6b8ea,"btrfs: fix invalid mapping of extent xarray state

In __extent_writepage_io()"," we call btrfs_set_range_writeback() ->
folio_start_writeback()","[' which clears PAGECACHE_TAG_DIRTY mark from the\nmapping xarray if the folio is not dirty. This worked fine before commit\n97713b1a2ced (""btrfs: do not clear page dirty inside\nextent_write_locked_range()"").\n\nAfter the commit', ' however', ' the folio is still dirty at this point', ' so the\nmapping DIRTY tag is not cleared anymore. Then', ' __extent_writepage_io()\ncalls btrfs_folio_clear_dirty() to clear the folio\'s dirty flag. That\nresults in the page being unlocked with a ""strange"" state. The page is not\nPageDirty', "" but the mapping tag is set as PAGECACHE_TAG_DIRTY.\n\nThis strange state looks like causing a hang with a call trace below when\nrunning fstests generic/091 on a null_blk device. It is waiting for a folio\nlock.\n\nWhile I don't have an exact relation between this hang and the strange\nstate"", ' fixing the state also fixes the hang. And', ' that state is worth\nfixing anyway.\n\nThis commit reorders btrfs_folio_clear_dirty() and\nbtrfs_set_range_writeback() in __extent_writepage_io()', ' so that the\nPAGECACHE_TAG_DIRTY tag is properly removed from the xarray.\n\n  [464.274] task:fsx             state:D stack:0     pid:3034  tgid:3034  ppid:2853   flags:0x00004002\n  [464.286] Call Trace:\n  [464.291]  <TASK>\n  [464.295]  __schedule+0x10ed/0x6260\n  [464.301]  ? __pfx___blk_flush_plug+0x10/0x10\n  [464.308]  ? __submit_bio+0x37c/0x450\n  [464.314]  ? __pfx___schedule+0x10/0x10\n  [464.321]  ? lock_release+0x567/0x790\n  [464.327]  ? __pfx_lock_acquire+0x10/0x10\n  [464.334]  ? __pfx_lock_release+0x10/0x10\n  [464.340]  ? __pfx_lock_acquire+0x10/0x10\n  [464.347]  ? __pfx_lock_release+0x10/0x10\n  [464.353]  ? do_raw_spin_lock+0x12e/0x270\n  [464.360]  schedule+0xdf/0x3b0\n  [464.365]  io_schedule+0x8f/0xf0\n  [464.371]  folio_wait_bit_common+0x2ca/0x6d0\n  [464.378]  ? folio_wait_bit_common+0x1cc/0x6d0\n  [464.385]  ? __pfx_folio_wait_bit_common+0x10/0x10\n  [464.392]  ? __pfx_filemap_get_folios_tag+0x10/0x10\n  [464.400]  ? __pfx_wake_page_function+0x10/0x10\n  [464.407]  ? __pfx___might_resched+0x10/0x10\n  [464.414]  ? do_raw_spin_unlock+0x58/0x1f0\n  [464.420]  extent_write_cache_pages+0xe49/0x1620 [btrfs]\n  [464.428]  ? lock_acquire+0x435/0x500\n  [464.435]  ? __pfx_extent_write_cache_pages+0x10/0x10 [btrfs]\n  [464.443]  ? btrfs_do_write_iter+0x493/0x640 [btrfs]\n  [464.451]  ? orc_find.part.0+0x1d4/0x380\n  [464.457]  ? __pfx_lock_release+0x10/0x10\n  [464.464]  ? __pfx_lock_release+0x10/0x10\n  [464.471]  ? btrfs_do_write_iter+0x493/0x640 [btrfs]\n  [464.478]  btrfs_writepages+0x1cc/0x460 [btrfs]\n  [464.485]  ? __pfx_btrfs_writepages+0x10/0x10 [btrfs]\n  [464.493]  ? is_bpf_text_address+0x6e/0x100\n  [464.500]  ? kernel_text_address+0x145/0x160\n  [464.507]  ? unwind_get_return_address+0x5e/0xa0\n  [464.514]  ? arch_stack_walk+0xac/0x100\n  [464.521]  do_writepages+0x176/0x780\n  [464.527]  ? lock_release+0x567/0x790\n  [464.533]  ? __pfx_do_writepages+0x10/0x10\n  [464.540]  ? __pfx_lock_acquire+0x10/0x10\n  [464.546]  ? __pfx_stack_trace_save+0x10/0x10\n  [464.553]  ? do_raw_spin_lock+0x12e/0x270\n  [464.560]  ? do_raw_spin_unlock+0x58/0x1f0\n  [464.566]  ? _raw_spin_unlock+0x23/0x40\n  [464.573]  ? wbc_attach_and_unlock_inode+0x3da/0x7d0\n  [464.580]  filemap_fdatawrite_wbc+0x113/0x180\n  [464.587]  ? prepare_pages.constprop.0+0x13c/0x5c0 [btrfs]\n  [464.596]  __filemap_fdatawrite_range+0xaf/0xf0\n  [464.603]  ? __pfx___filemap_fdatawrite_range+0x10/0x10\n  [464.611]  ? trace_irq_enable.constprop.0+0xce/0x110\n  [464.618]  ? kasan_quarantine_put+0xd7/0x1e0\n  [464.625]  btrfs_start_ordered_extent+0x46f/0x570 [btrfs]\n  [464.633]  ? __pfx_btrfs_start_ordered_extent+0x10/0x10 [btrfs]\n  [464.642]  ? __clear_extent_bit+0x2c0/0x9d0 [btrfs]\n  [464.650]  btrfs_lock_and_flush_ordered_range+0xc6/0x180 [btrfs]\n  [464.659]  ? __pfx_btrfs_lock_and_flush_ordered_range+0x10/0x10 [btrfs]\n  [464.669]  btrfs_read_folio+0x12a/0x1d0 [btrfs]\n  [464.676]  ? __pfx_btrfs_read_folio+0x10/0x10 [btrfs]\n  [464.684]  ? __pfx_filemap_add_folio+0x10/0x10\n  [464.691]  ? __pfx___might_resched+0x10/0x10\n  [464.698]  ? __filemap_get_folio+0x1c5/0x450\n  [464.705]  prepare_uptodate_page+0x12e/0x4d0 [btrfs]\n  [464.713]  prepare_pages.constprop.0+0x13c/0x5c0 [btrfs]\n  [464.721]  ? fault_in_iov_iter_readable+0xd2/0x240\n  [464.729]  btrfs_buffered_write+0x5bd/0x12f0 [btrfs]\n  [464.737]  ? __pfx_btrfs_buffered_write+0x10/0x10 [btrfs]\n  [464.745]  ? __pfx_lock_release+0x10/0x10\n  [464.752]  ? generic_write_checks+0x275/0x400\n  [464.759]  ? down_write+0x118/0x1f0\n  [464.765]  ? up_write+0x19b/0x500\n  [464.770]  btrfs_direct_write+0x731/0xba0 [btrfs]\n  [464.778]  ? __pfx_btrfs_direct_write+0x10/0x10 [btrfs]\n  [464.785]  ? __pfx___might_resched+0x10/0x10\n  [464.792]  ? lock_acquire+0x435/0x500\n  [464.798]  ? lock_acquire+0x435/0x500\n  [464.804]  btrfs_do_write_iter+0x494/0x640 [btrfs]\n  [464.811]  ? __pfx_btrfs_do_write_iter+0x10/0x10 [btrfs]\n  [464.819]  ? __pfx___might_resched+0x10/0x10\n  [464.825]  ? rw_verify_area+0x6d/0x590\n  [464.831]  vfs_write+0x5d7/0xf50\n  [464.837]  ? __might_fault+0x9d/0x120\n  [464.843]  ? __pfx_vfs_write+0x10/0x10\n  [464.849]  ? btrfs_file_llseek+0xb1/0xfb0 [btrfs]\n  [464.856]  ? lock_release+0x567/0x790\n  [464.862]  ksys_write+0xfb/0x1d0\n  [464.867]  ? __pfx_ksys_write+0x10/0x10\n  [464.873]  ? _raw_spin_unlock+0x23/0x40\n  [464.879]  ? btrfs_getattr+0x4af/0x670 [btrfs]\n  [464.886]  ? vfs_getattr_nosec+0x79/0x340\n  [464.892]  do_syscall_64+0x95/0x180\n  [464.898]  ? __do_sys_newfstat+0xde/0xf0\n  [464.904]  ? __pfx___do_sys_newfstat+0x10/0x10\n  [464.911]  ? trace_irq_enable.constprop.0+0xce/0x110\n  [464.918]  ? syscall_exit_to_user_mode+0xac/0x2a0\n  [464.925]  ? do_syscall_64+0xa1/0x180\n  [464.931]  ? trace_irq_enable.constprop.0+0xce/0x110\n  [464.939]  ? trace_irq_enable.constprop.0+0xce/0x110\n  [464.946]  ? syscall_exit_to_user_mode+0xac/0x2a0\n  [464.953]  ? btrfs_file_llseek+0xb1/0xfb0 [btrfs]\n  [464.960]  ? do_syscall_64+0xa1/0x180\n  [464.966]  ? btrfs_file_llseek+0xb1/0xfb0 [btrfs]\n  [464.973]  ? trace_irq_enable.constprop.0+0xce/0x110\n  [464.980]  ? syscall_exit_to_user_mode+0xac/0x2a0\n  [464.987]  ? __pfx_btrfs_file_llseek+0x10/0x10 [btrfs]\n  [464.995]  ? trace_irq_enable.constprop.0+0xce/0x110\n  [465.002]  ? __pfx_btrfs_file_llseek+0x10/0x10 [btrfs]\n  [465.010]  ? do_syscall_64+0xa1/0x180\n  [465.016]  ? lock_release+0x567/0x790\n  [465.022]  ? __pfx_lock_acquire+0x10/0x10\n  [465.028]  ? __pfx_lock_release+0x10/0x10\n  [465.034]  ? trace_irq_enable.constprop.0+0xce/0x110\n  [465.042]  ? syscall_exit_to_user_mode+0xac/0x2a0\n  [465.049]  ? do_syscall_64+0xa1/0x180\n  [465.055]  ? syscall_exit_to_user_mode+0xac/0x2a0\n  [465.062]  ? do_syscall_64+0xa1/0x180\n  [465.068]  ? syscall_exit_to_user_mode+0xac/0x2a0\n  [465.075]  ? do_syscall_64+0xa1/0x180\n  [465.081]  ? clear_bhb_loop+0x25/0x80\n  [465.087]  ? clear_bhb_loop+0x25/0x80\n  [465.093]  ? clear_bhb_loop+0x25/0x80\n  [465.099]  entry_SYSCALL_64_after_hwframe+0x76/0x7e\n  [465.106] RIP: 0033:0x7f093b8ee784\n  [465.111] RSP: 002b:00007ffc29d31b28 EFLAGS: 00000202 ORIG_RAX: 0000000000000001\n  [465.122] RAX: ffffffffffffffda RBX: 0000000000006000 RCX: 00007f093b8ee784\n  [465.131] RDX: 000000000001de00 RSI: 00007f093b6ed200 RDI: 0000000000000003\n  [465.141] RBP: 000000000001de00 R08: 0000000000006000 R09: 0000000000000000\n  [465.150] R10: 0000000000023e00 R11: 0000000000000202 R12: 0000000000006000\n  [465.160] R13: 0000000000023e00 R14: 0000000000023e00 R15: 0000000000000001\n  [465.170]  </TASK>\n  [465.174] INFO: lockdep is turned off.\n\nReported-by: Shinichiro Kawasaki <shinichiro.kawasaki@wdc.com>\nFixes: 97713b1a2ced (""btrfs: do not clear page dirty inside extent_write_locked_range()"")\nReviewed-by: Qu Wenruo <wqu@suse.com>\nSigned-off-by: Naohiro Aota <naohiro.aota@wdc.com>\nSigned-off-by: David Sterba <dsterba@suse.com>\n', '']",Fixes invalid extent xarray state mapping in btrfs during writepage IO operation.,"btrfs,fix,xarray",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
662c3e2db00f92e50c26e9dc4fe47c52223d9982,662c3e2db00f92e50c26e9dc4fe47c52223d9982,Yonghong Song,yonghong.song@linux.dev,1723499332,Alexei Starovoitov,ast@kernel.org,1723511733,a60298d4cfa5f0ab4f10e081fc2fb31f28655b20,bed2eb964c70b780fb55925892a74f26cb590b25,"selftests/bpf: Add a test to verify previous stacksafe() fix

A selftest is added such that without the previous patch","
a crash can happen. With the previous patch","[' the test can\nrun successfully. The new test is written in a way which\nmimics original crash case:\n  main_prog\n    static_prog_1\n      static_prog_2\nwhere static_prog_1 has different paths to static_prog_2\nand some path has stack allocated and some other path\ndoes not. A stacksafe() checking in static_prog_2()\ntriggered the crash.\n\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240812214852.214037-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add selftest to verify the previous stacksafe() bug fix in bpf.,"selftest, stacksafe, verify",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
bed2eb964c70b780fb55925892a74f26cb590b25,bed2eb964c70b780fb55925892a74f26cb590b25,Yonghong Song,yonghong.song@linux.dev,1723499327,Alexei Starovoitov,ast@kernel.org,1723511388,6b3b06cd087a165a9985ba6a859f43b7684291f7,fdad456cbcca739bae1849549c7a999857c56f88,"bpf: Fix a kernel verifier crash in stacksafe()

Daniel Hodges reported a kernel verifier crash when playing with sched-ext.
Further investigation shows that the crash is due to invalid memory access
in stacksafe(). More specifically"," it is the following code:

    if (exact != NOT_EXACT &&
        old->stack[spi].slot_type[i % BPF_REG_SIZE] !=
        cur->stack[spi].slot_type[i % BPF_REG_SIZE])
            return false;

The 'i' iterates old->allocated_stack.
If cur->allocated_stack < old->allocated_stack the out-of-bound
access will happen.

To fix the issue add 'i >= cur->allocated_stack' check such that if
the condition is true","[' stacksafe() should fail. Otherwise', '\ncur->stack[spi].slot_type[i % BPF_REG_SIZE] memory access is legal.\n\nFixes: 2793a8b015f7 (""bpf: exact states comparison for iterator convergence checks"")\nCc: Eduard Zingerman <eddyz87@gmail.com>\nReported-by: Daniel Hodges <hodgesd@meta.com>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240812214847.213612-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes a kernel verifier crash caused by invalid memory access in the stacksafe function.,"kernel verifier, stacksafe, crash",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,['scheduler like programs']
fdad456cbcca739bae1849549c7a999857c56f88,fdad456cbcca739bae1849549c7a999857c56f88,Leon Hwang,leon.hwang@linux.dev,1722167171,Alexei Starovoitov,ast@kernel.org,1723501549,f6184a52a06eae30720b7bb1acc88997536c39c0,d74da846046aeec9333e802f5918bd3261fb5509,"bpf: Fix updating attached freplace prog in prog_array map

The commit f7866c358733 (""bpf: Fix null pointer dereference in resolve_prog_type() for BPF_PROG_TYPE_EXT"")
fixed a NULL pointer dereference panic"," but didn't fix the issue that
fails to update attached freplace prog to prog_array map.

Since commit 1c123c567fb1 (""bpf: Resolve fext program type when checking map compatibility"")","['\nfreplace prog and its target prog are able to tail call each other.\n\nAnd the commit 3aac1ead5eb6 (""bpf: Move prog->aux->linked_prog and trampoline into bpf_link on attach"")\nsets prog->aux->dst_prog as NULL after attaching freplace prog to its\ntarget prog.\n\nAfter loading freplace the prog_array\'s owner type is BPF_PROG_TYPE_SCHED_CLS.\nThen', ' after attaching freplace its prog->aux->dst_prog is NULL.\nThen', ' while updating freplace in prog_array the bpf_prog_map_compatible()\nincorrectly returns false because resolve_prog_type() returns\nBPF_PROG_TYPE_EXT instead of BPF_PROG_TYPE_SCHED_CLS.\nAfter this patch the resolve_prog_type() returns BPF_PROG_TYPE_SCHED_CLS\nand update to prog_array can succeed.\n\nFixes: f7866c358733 (""bpf: Fix null pointer dereference in resolve_prog_type() for BPF_PROG_TYPE_EXT"")\nCc: Toke Høiland-Jørgensen <toke@redhat.com>\nCc: Martin KaFai Lau <martin.lau@kernel.org>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Leon Hwang <leon.hwang@linux.dev>\nLink: https://lore.kernel.org/r/20240728114612.48486-2-leon.hwang@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix issue with updating attached freplace prog in prog_array map.,"bpf, fix, prog_array",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1fc2021941241bf32728a198bc0a7f38669e44a5,1fc2021941241bf32728a198bc0a7f38669e44a5,David S. Miller,davem@davemloft.net,1723459616,David S. Miller,davem@davemloft.net,1723459616,a51e036b9ac7d7908303f05b5ec5900bd449f66f,9ff2f816e2aa65ca9a1cdf0954842f8173c0f48d de7a670f8defe4ed2115552ad23dea0f432f7be4,"Merge branch 'vsc73xx-fix-mdio-and-phy'

Pawel Dembicki says:

====================
net: dsa: vsc73xx: fix MDIO bus access and PHY opera

This series are extracted patches from net-next series [0].

The VSC73xx driver has issues with PHY configuration. This patch series
fixes most of them.

The first patch synchronizes the register configuration routine with the
datasheet recommendations.

Patches 2-3 restore proper communication on the MDIO bus. Currently","
the write value isn't sent to the MDIO register","[' and without a busy check', '\ncommunication with the PHY can be interrupted. This causes the PHY to\nreceive improper configuration and autonegotiation could fail.\n\nThe fourth patch removes the PHY reset blockade', ' as it is no longer\nrequired.\n\nAfter fixing the MDIO operations', ' autonegotiation became possible.\nThe last patch removes the blockade', ' which became unnecessary after\nthe MDIO operations fix.\n\n[0] https://patchwork.kernel.org/project/netdevbpf/list/?series=874739&state=%2A&archive=both\n====================\n\nSigned-off-by: David S. Miller <davem@davemloft.net>\n', '']",Fixes issues in the VSC73xx driver for MDIO bus access and PHY operations.,"VSC73xx, MDIO, PHY",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
146430a0c26eb7b515abb04664e1a516078ec5c2,146430a0c26eb7b515abb04664e1a516078ec5c2,Linus Torvalds,torvalds@linux-foundation.org,1723221826,Linus Torvalds,torvalds@linux-foundation.org,1723221826,fb2e101fc6b771bf5d7eb38530d9debb2b62cc50,b7768c4881d1b69bd95dad149d3b558c8e7de91a 8c8acb8f26cbde665b233dd1b9bbcbb9b86822dc,"Merge tag 'probes-fixes-v6.11-rc2' of git://git.kernel.org/pub/scm/linux/kernel/git/trace/linux-trace

Pull kprobe fixes from Masami Hiramatsu:

 - Fix misusing str_has_prefix() parameter order to check symbol prefix
   correctly

 - bpf: remove unused declaring of bpf_kprobe_override

* tag 'probes-fixes-v6.11-rc2' of git://git.kernel.org/pub/scm/linux/kernel/git/trace/linux-trace:
  kprobes: Fix to check symbol prefixes correctly
  bpf: kprobe: remove unused declaring of bpf_kprobe_override
",,"Merge fixes for kprobes, including correcting symbol prefix checks and removing unused bpf_kprobe_override declaration.","kprobes, symbol prefix, bpf_kprobe_override",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
0e8b53979ac86eddb3fd76264025a70071a25574,0e8b53979ac86eddb3fd76264025a70071a25574,Menglong Dong,menglong8.dong@gmail.com,1722834081,Masami Hiramatsu (Google),mhiramat@kernel.org,1722834081,09f41d8841d2e4e3e39435726b7d26c74c05dc6c,de9c2c66ad8e787abec7c9d7eff4f8c3cdd28aed,"bpf: kprobe: remove unused declaring of bpf_kprobe_override

After the commit 66665ad2f102 (""tracing/kprobe: bpf: Compare instruction
pointer with original one"")"," ""bpf_kprobe_override"" is not used anywhere
anymore","[' and we can remove it now.\n\nLink: https://lore.kernel.org/all/20240710085939.11520-1-dongml2@chinatelecom.cn/\n\nFixes: 66665ad2f102 (""tracing/kprobe: bpf: Compare instruction pointer with original one"")\nSigned-off-by: Menglong Dong <dongml2@chinatelecom.cn>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\n', '']",The commit removes the unused declaration of bpf_kprobe_override after a related change.,"kprobe, unused, bpf",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
183d46ff422ef9f3d755b6808ef3faa6d009ba3a,183d46ff422ef9f3d755b6808ef3faa6d009ba3a,Linus Torvalds,torvalds@linux-foundation.org,1722530529,Linus Torvalds,torvalds@linux-foundation.org,1722530529,8405b88ef447994f3eafd40e8e3aa5f47d3fa33f,21b136cc63d2a9ddd60d4699552b69c214b32964 25010bfdf8bbedc64c5c04d18f846412f5367d26,"Merge tag 'net-6.11-rc2' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Paolo Abeni:
 ""Including fixes from wireless", bleutooth,"[' BPF and netfilter.\n\n  Current release - regressions:\n\n   - core: drop bad gso csum_start and offset in virtio_net_hdr\n\n   - wifi: mt76: fix null pointer access in mt792x_mac_link_bss_remove\n\n   - eth: tun: add missing bpf_net_ctx_clear() in do_xdp_generic()\n\n   - phy: aquantia: only poll GLOBAL_CFG regs on aqr113', ' aqr113c and\n     aqr115c\n\n  Current release - new code bugs:\n\n   - smc: prevent UAF in inet_create()\n\n   - bluetooth: btmtk: fix kernel crash when entering btmtk_usb_suspend\n\n   - eth: bnxt: reject unsupported hash functions\n\n  Previous releases - regressions:\n\n   - sched: act_ct: take care of padding in struct zones_ht_key\n\n   - netfilter: fix null-ptr-deref in iptable_nat_table_init().\n\n   - tcp: adjust clamping window for applications specifying SO_RCVBUF\n\n  Previous releases - always broken:\n\n   - ethtool: rss: small fixes to spec and GET\n\n   - mptcp:\n      - fix signal endpoint re-add\n      - pm: fix backup support in signal endpoints\n\n   - wifi: ath12k: fix soft lockup on suspend\n\n   - eth: bnxt_en: fix RSS logic in __bnxt_reserve_rings()\n\n   - eth: ice: fix AF_XDP ZC timeout and concurrency issues\n\n   - eth: mlx5:\n      - fix missing lock on sync reset reload\n      - fix error handling in irq_pool_request_irq""\n\n* tag \'net-6.11-rc2\' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (76 commits)\n  mptcp: fix duplicate data handling\n  mptcp: fix bad RCVPRUNED mib accounting\n  ipv6: fix ndisc_is_useropt() handling for PIO\n  igc: Fix double reset adapter triggered from a single taprio cmd\n  net: MAINTAINERS: Demote Qualcomm IPA to ""maintained""\n  net: wan: fsl_qmc_hdlc: Discard received CRC\n  net: wan: fsl_qmc_hdlc: Convert carrier_lock spinlock to a mutex\n  net/mlx5e: Add a check for the return value from mlx5_port_set_eth_ptys\n  net/mlx5e: Fix CT entry update leaks of modify header context\n  net/mlx5e: Require mlx5 tc classifier action support for IPsec prio capability\n  net/mlx5: Fix missing lock on sync reset reload\n  net/mlx5: Lag', "" don't use the hardcoded value of the first port\n  net/mlx5: DR"", "" Fix 'stack guard page was hit' error in dr_rule\n  net/mlx5: Fix error handling in irq_pool_request_irq\n  net/mlx5: Always drain health in shutdown callback\n  net: Add skbuff.h to MAINTAINERS\n  r8169: don't increment tx_dropped in case of NETDEV_TX_BUSY\n  netfilter: iptables: Fix potential null-ptr-deref in ip6table_nat_table_init().\n  netfilter: iptables: Fix null-ptr-deref in iptable_nat_table_init().\n  net: drop bad gso csum_start and offset in virtio_net_hdr\n  ...\n"", '']",Merge networking fixes from Paolo Abeni including wireless fixes for Linux kernel.,"networking, wireless, fixes",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
601df205896da88e654d7c97d4579fa4af0b4adf,601df205896da88e654d7c97d4579fa4af0b4adf,Jakub Kicinski,kuba@kernel.org,1722473340,Jakub Kicinski,kuba@kernel.org,1722473340,33ff821d073b60a589ff9dbf7289291845d328c1,0bf50cead4c4710d9f704778c32ab8af47ddf070 7764b9622db4382b2797b54a70f292c8da6ef417,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Daniel Borkmann says:

====================
pull-request: bpf 2024-07-31

We've added 2 non-merge commits during the last 2 day(s) which contain
a total of 2 files changed", 2 insertions(+),"[' 2 deletions(-).\n\nThe main changes are:\n\n1) Fix BPF selftest build after tree sync with regards to a _GNU_SOURCE\n   macro redefined compilation error', ' from Stanislav Fomichev.\n\n2) Fix a wrong test in the ASSERT_OK() check in uprobe_syscall BPF selftest', ""\n   from Jiri Olsa.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  bpf/selftests: Fix ASSERT_OK condition check in uprobe_syscall test\n  selftests/bpf: Filter out _GNU_SOURCE when compiling test_cpp\n====================\n\nLink: https://patch.msgid.link/20240731115706.19677-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n"", '']",Merge pull request for 'bpf' changes with 2 non-merge commits impacting 2 files.,"merge,pull request,commits",It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
5830aa863981d43560748aa93589c0695191d95d,5830aa863981d43560748aa93589c0695191d95d,Kuniyuki Iwashima,kuniyu@amazon.com,1721935700,Pablo Neira Ayuso,pablo@netfilter.org,1722460850,771314e701a319dbd17ee3069619662517c04d1b,0bf50cead4c4710d9f704778c32ab8af47ddf070,"netfilter: iptables: Fix null-ptr-deref in iptable_nat_table_init().

We had a report that iptables-restore sometimes triggered null-ptr-deref
at boot time. [0]

The problem is that iptable_nat_table_init() is exposed to user space
before the kernel fully initialises netns.

In the small race window"," a user could call iptable_nat_table_init()
that accesses net_generic(net","[' iptable_nat_net_id)', "" which is available\nonly after registering iptable_nat_net_ops.\n\nLet's call register_pernet_subsys() before xt_register_template().\n\n[0]:\nbpfilter: Loaded bpfilter_umh pid 11702\nStarted bpfilter\nBUG: kernel NULL pointer dereference"", ' address: 0000000000000013\n PF: supervisor write access in kernel mode\n PF: error_code(0x0002) - not-present page\nPGD 0 P4D 0\nPREEMPT SMP NOPTI\nCPU: 2 PID: 11879 Comm: iptables-restor Not tainted 6.1.92-99.174.amzn2023.x86_64 #1\nHardware name: Amazon EC2 c6i.4xlarge/', ' BIOS 1.0 10/16/2017\nRIP: 0010:iptable_nat_table_init (net/ipv4/netfilter/iptable_nat.c:87 net/ipv4/netfilter/iptable_nat.c:121) iptable_nat\nCode: 10 4c 89 f6 48 89 ef e8 0b 19 bb ff 41 89 c4 85 c0 75 38 41 83 c7 01 49 83 c6 28 41 83 ff 04 75 dc 48 8b 44 24 08 48 8b 0c 24 <48> 89 08 4c 89 ef e8 a2 3b a2 cf 48 83 c4 10 44 89 e0 5b 5d 41 5c\nRSP: 0018:ffffbef902843cd0 EFLAGS: 00010246\nRAX: 0000000000000013 RBX: ffff9f4b052caa20 RCX: ffff9f4b20988d80\nRDX: 0000000000000000 RSI: 0000000000000064 RDI: ffffffffc04201c0\nRBP: ffff9f4b29394000 R08: ffff9f4b07f77258 R09: ffff9f4b07f77240\nR10: 0000000000000000 R11: ffff9f4b09635388 R12: 0000000000000000\nR13: ffff9f4b1a3c6c00 R14: ffff9f4b20988e20 R15: 0000000000000004\nFS:  00007f6284340000(0000) GS:ffff9f51fe280000(0000) knlGS:0000000000000000\nCS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\nCR2: 0000000000000013 CR3: 00000001d10a6005 CR4: 00000000007706e0\nDR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\nDR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400\nPKRU: 55555554\nCall Trace:\n <TASK>\n ? show_trace_log_lvl (arch/x86/kernel/dumpstack.c:259)\n ? show_trace_log_lvl (arch/x86/kernel/dumpstack.c:259)\n ? xt_find_table_lock (net/netfilter/x_tables.c:1259)\n ? __die_body.cold (arch/x86/kernel/dumpstack.c:478 arch/x86/kernel/dumpstack.c:420)\n ? page_fault_oops (arch/x86/mm/fault.c:727)\n ? exc_page_fault (./arch/x86/include/asm/irqflags.h:40 ./arch/x86/include/asm/irqflags.h:75 arch/x86/mm/fault.c:1470 arch/x86/mm/fault.c:1518)\n ? asm_exc_page_fault (./arch/x86/include/asm/idtentry.h:570)\n ? iptable_nat_table_init (net/ipv4/netfilter/iptable_nat.c:87 net/ipv4/netfilter/iptable_nat.c:121) iptable_nat\n xt_find_table_lock (net/netfilter/x_tables.c:1259)\n xt_request_find_table_lock (net/netfilter/x_tables.c:1287)\n get_info (net/ipv4/netfilter/ip_tables.c:965)\n ? security_capable (security/security.c:809 (discriminator 13))\n ? ns_capable (kernel/capability.c:376 kernel/capability.c:397)\n ? do_ipt_get_ctl (net/ipv4/netfilter/ip_tables.c:1656)\n ? bpfilter_send_req (net/bpfilter/bpfilter_kern.c:52) bpfilter\n nf_getsockopt (net/netfilter/nf_sockopt.c:116)\n ip_getsockopt (net/ipv4/ip_sockglue.c:1827)\n __sys_getsockopt (net/socket.c:2327)\n __x64_sys_getsockopt (net/socket.c:2342 net/socket.c:2339 net/socket.c:2339)\n do_syscall_64 (arch/x86/entry/common.c:51 arch/x86/entry/common.c:81)\n entry_SYSCALL_64_after_hwframe (arch/x86/entry/entry_64.S:121)\nRIP: 0033:0x7f62844685ee\nCode: 48 8b 0d 45 28 0f 00 f7 d8 64 89 01 48 83 c8 ff c3 66 2e 0f 1f 84 00 00 00 00 00 90 f3 0f 1e fa 49 89 ca b8 37 00 00 00 0f 05 <48> 3d 00 f0 ff ff 77 0a c3 66 0f 1f 84 00 00 00 00 00 48 8b 15 09\nRSP: 002b:00007ffd1f83d638 EFLAGS: 00000246 ORIG_RAX: 0000000000000037\nRAX: ffffffffffffffda RBX: 00007ffd1f83d680 RCX: 00007f62844685ee\nRDX: 0000000000000040 RSI: 0000000000000000 RDI: 0000000000000004\nRBP: 0000000000000004 R08: 00007ffd1f83d670 R09: 0000558798ffa2a0\nR10: 00007ffd1f83d680 R11: 0000000000000246 R12: 00007ffd1f83e3b2\nR13: 00007f628455baa0 R14: 00007ffd1f83d7b0 R15: 00007f628457a008\n </TASK>\nModules linked in: iptable_nat(+) bpfilter rpcsec_gss_krb5 auth_rpcgss nfsv4 dns_resolver nfs lockd grace fscache veth xt_state xt_connmark xt_nat xt_statistic xt_MASQUERADE xt_mark xt_addrtype ipt_REJECT nf_reject_ipv4 nft_chain_nat nf_nat xt_conntrack nf_conntrack nf_defrag_ipv6 nf_defrag_ipv4 xt_comment nft_compat nf_tables nfnetlink overlay nls_ascii nls_cp437 vfat fat ghash_clmulni_intel aesni_intel ena crypto_simd ptp cryptd i8042 pps_core serio button sunrpc sch_fq_codel configfs loop dm_mod fuse dax dmi_sysfs crc32_pclmul crc32c_intel efivarfs\nCR2: 0000000000000013\n\nFixes: fdacd57c79b7 (""netfilter: x_tables: never register tables by default"")\nReported-by: Takahiro Kawahara <takawaha@amazon.co.jp>\nSigned-off-by: Kuniyuki Iwashima <kuniyu@amazon.com>\nReviewed-by: Florian Westphal <fw@strlen.de>\nSigned-off-by: Pablo Neira Ayuso <pablo@netfilter.org>\n', '']",Fix null pointer dereference issue in iptable_nat_table_init() during kernel initialization sequence.,"null-ptr-deref, iptables, netfilter",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
0bf50cead4c4710d9f704778c32ab8af47ddf070,0bf50cead4c4710d9f704778c32ab8af47ddf070,Jakub Kicinski,kuba@kernel.org,1722390070,Jakub Kicinski,kuba@kernel.org,1722390070,dc1ccc485a0d7f77dbafb9724dc23c2ca39d51e0,89add40066f9ed9abe5f7f886fe5789ff7e0c50e 963fb4612295a5c35b1b89c8bff3bdd4f9127af6,"Merge branch '100GbE' of git://git.kernel.org/pub/scm/linux/kernel/git/tnguy/net-queue

Tony Nguyen says:

====================
ice: fix AF_XDP ZC timeout and concurrency issues

Maciej Fijalkowski says:

Changes included in this patchset address an issue that customer has
been facing when AF_XDP ZC Tx sockets were used in combination with flow
control and regular Tx traffic.

After executing:
ethtool --set-priv-flags $dev link-down-on-close on
ethtool -A $dev rx on tx on

launching multiple ZC Tx sockets on $dev + pinging remote interface (so
that regular Tx traffic is present) and then going through down/up of
$dev"," Tx timeout occurred and then most of the time ice driver was unable
to recover from that state.

These patches combined together solve the described above issue on
customer side. Main focus here is to forbid producing Tx descriptors when
either carrier is not yet initialized or process of bringing interface
down has already started.

v1: https://lore.kernel.org/netdev/20240708221416.625850-1-anthony.l.nguyen@intel.com/

* '100GbE' of git://git.kernel.org/pub/scm/linux/kernel/git/tnguy/net-queue:
  ice: xsk: fix txq interrupt mapping
  ice: add missing WRITE_ONCE when clearing ice_rx_ring::xdp_prog
  ice: improve updating ice_{t","[""r}x_ring::xsk_pool\n  ice: toggle netif_carrier when setting up XSK pool\n  ice: modify error handling when setting XSK pool in ndo_bpf\n  ice: replace synchronize_rcu with synchronize_net\n  ice: don't busy wait for Rx queue disable in ice_qp_dis()\n  ice: respect netif readiness in AF_XDP ZC related ndo's\n====================\n\nLink: https://patch.msgid.link/20240729200716.681496-1-anthony.l.nguyen@intel.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n"", '']",Fixes concurrency and timeout issues for AF_XDP ZC in the ice driver during network interface up/down cycles.,"AF_XDP, ice driver, concurrency",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['socket like programs']
7764b9622db4382b2797b54a70f292c8da6ef417,7764b9622db4382b2797b54a70f292c8da6ef417,Jiri Olsa,jolsa@kernel.org,1722017327,Andrii Nakryiko,andrii@kernel.org,1722372144,849b01b4dc7b6094ed79beb752130f697dc24088,41c24102af7b6236277a214428b203d51a3462df,"bpf/selftests: Fix ASSERT_OK condition check in uprobe_syscall test

Fixing ASSERT_OK condition check in uprobe_syscall test","
otherwise we return from test on pipe success.

Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/bpf/20240726180847.684584-1-jolsa@kernel.org
",[''],Fixes the ASSERT_OK condition in the uprobe_syscall test of the bpf selftests.,"fix, ASSERT_OK, uprobe_syscall",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
41c24102af7b6236277a214428b203d51a3462df,41c24102af7b6236277a214428b203d51a3462df,Stanislav Fomichev,sdf@fomichev.me,1721943629,Andrii Nakryiko,andrii@kernel.org,1722285811,88899ab944af9bac21c481a0130ddc8277801cc2,039564d2fd37b122ec0d268e2ee6334e7169e225,"selftests/bpf: Filter out _GNU_SOURCE when compiling test_cpp

Jakub reports build failures when merging linux/master with net tree:

CXX      test_cpp
In file included from <built-in>:454:
<command line>:2:9: error: '_GNU_SOURCE' macro redefined [-Werror","-Wmacro-redefined]
    2 | #define _GNU_SOURCE
      |         ^
<built-in>:445:9: note: previous definition is here
  445 | #define _GNU_SOURCE 1

The culprit is commit cc937dad85ae (""selftests: centralize -D_GNU_SOURCE= to
CFLAGS in lib.mk"") which unconditionally added -D_GNU_SOUCE to CLFAGS.
Apparently clang++ also unconditionally adds it for the C++ targets [0]
which causes a conflict. Add small change in the selftests makefile
to filter it out for test_cpp.

Not sure which tree it should go via","[' targeting bpf for now', ' but net\nmight be better?\n\n0: https://stackoverflow.com/questions/11670581/why-is-gnu-source-defined-by-default-and-how-to-turn-it-off\n\nSigned-off-by: Stanislav Fomichev <sdf@fomichev.me>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/bpf/20240725214029.1760809-1-sdf@fomichev.me\n', '']",Fixes build failure by filtering out _GNU_SOURCE for test_cpp in selftests makefile.,"build failure, _GNU_SOURCE, makefile",It's a build system or CI/CD change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
6b5faec9f564ea627c66064a4a6a5904fe5a07dd,6b5faec9f564ea627c66064a4a6a5904fe5a07dd,Linus Torvalds,torvalds@linux-foundation.org,1722283625,Linus Torvalds,torvalds@linux-foundation.org,1722283625,a6981158a16b59d7effbac1fdb2c887a293a364a,10826505f52357c7c9e12358db97a3acbe82e958 facdbdfe0e6202d74758387ae9189c39f7b4b16c,"Merge tag 'for-linus-2024072901' of git://git.kernel.org/pub/scm/linux/kernel/git/hid/hid

Pull HID fixes from Benjamin Tissoires:

 - fixes for HID-BPF after the merge with the bpf tree (Arnd Bergmann
   and Benjamin Tissoires)

 - some tool type fix for the Wacom driver (Tatsunosuke Tobita)

 - a reorder of the sensor discovery to ensure the HID AMD SFH is
   removed when no sensors are available (Basavaraj Natikar)

* tag 'for-linus-2024072901' of git://git.kernel.org/pub/scm/linux/kernel/git/hid/hid:
  selftests/hid: add test for attaching multiple time the same struct_ops
  HID: bpf: prevent the same struct_ops to be attached more than once
  selftests/hid: disable struct_ops auto-attach
  selftests/hid: fix bpf_wq new API
  HID: amd_sfh: Move sensor discovery before HID device initialization
  hid: bpf: add BPF_JIT dependency
  HID: wacom: more appropriate tool type categorization
  HID: wacom: Modify pen IDs
",,"Merge of HID fixes including HID-BPF, sensor discovery reordering, and Wacom driver tool type update.","HID, fixes, HID-BPF",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['HID driver like programs']
478574370bef7951fbd9ef5155537d6cbed49472,478574370bef7951fbd9ef5155537d6cbed49472,Boris Burkov,boris@bur.io,1721692185,David Sterba,dsterba@suse.com,1722273651,c5c69d24a4b3a4db0e0910b88bf130c54bb1f806,de9f46cb0044a9b9f825d7695ae235863461dc00,"btrfs: make cow_file_range_inline() honor locked_page on error

The btrfs buffered write path runs through __extent_writepage() which
has some tricky return value handling for writepage_delalloc().
Specifically", when that returns 1,"[' we exit', ' but for other return values\nwe continue and end up calling btrfs_folio_end_all_writers(). If the\nfolio has been unlocked (note that we check the PageLocked bit at the\nstart of __extent_writepage())', ' this results in an assert panic like\nthis one from syzbot:\n\n  BTRFS: error (device loop0 state EAL) in free_log_tree:3267: errno=-5 IO failure\n  BTRFS warning (device loop0 state EAL): Skipping commit of aborted transaction.\n  BTRFS: error (device loop0 state EAL) in cleanup_transaction:2018: errno=-5 IO failure\n  assertion failed: folio_test_locked(folio)', ' in fs/btrfs/subpage.c:871\n  ------------[ cut here ]------------\n  kernel BUG at fs/btrfs/subpage.c:871!\n  Oops: invalid opcode: 0000 [#1] PREEMPT SMP KASAN PTI\n  CPU: 1 PID: 5090 Comm: syz-executor225 Not tainted\n  6.10.0-syzkaller-05505-gb1bc554e009e #0\n  Hardware name: Google Google Compute Engine/Google Compute Engine', ' BIOS\n  Google 06/27/2024\n  RIP: 0010:btrfs_folio_end_all_writers+0x55b/0x610 fs/btrfs/subpage.c:871\n  Code: e9 d3 fb ff ff e8 25 22 c2 fd 48 c7 c7 c0 3c 0e 8c 48 c7 c6 80 3d\n  0e 8c 48 c7 c2 60 3c 0e 8c b9 67 03 00 00 e8 66 47 ad 07 90 <0f> 0b e8\n  6e 45 b0 07 4c 89 ff be 08 00 00 00 e8 21 12 25 fe 4c 89\n  RSP: 0018:ffffc900033d72e0 EFLAGS: 00010246\n  RAX: 0000000000000045 RBX: 00fff0000000402c RCX: 663b7a08c50a0a00\n  RDX: 0000000000000000 RSI: 0000000080000000 RDI: 0000000000000000\n  RBP: ffffc900033d73b0 R08: ffffffff8176b98c R09: 1ffff9200067adfc\n  R10: dffffc0000000000 R11: fffff5200067adfd R12: 0000000000000001\n  R13: dffffc0000000000 R14: 0000000000000000 R15: ffffea0001cbee80\n  FS:  0000000000000000(0000) GS:ffff8880b9500000(0000)\n  knlGS:0000000000000000\n  CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n  CR2: 00007f5f076012f8 CR3: 000000000e134000 CR4: 00000000003506f0\n  DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\n  DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400\n  Call Trace:\n  <TASK>\n  __extent_writepage fs/btrfs/extent_io.c:1597 [inline]\n  extent_write_cache_pages fs/btrfs/extent_io.c:2251 [inline]\n  btrfs_writepages+0x14d7/0x2760 fs/btrfs/extent_io.c:2373\n  do_writepages+0x359/0x870 mm/page-writeback.c:2656\n  filemap_fdatawrite_wbc+0x125/0x180 mm/filemap.c:397\n  __filemap_fdatawrite_range mm/filemap.c:430 [inline]\n  __filemap_fdatawrite mm/filemap.c:436 [inline]\n  filemap_flush+0xdf/0x130 mm/filemap.c:463\n  btrfs_release_file+0x117/0x130 fs/btrfs/file.c:1547\n  __fput+0x24a/0x8a0 fs/file_table.c:422\n  task_work_run+0x24f/0x310 kernel/task_work.c:222\n  exit_task_work include/linux/task_work.h:40 [inline]\n  do_exit+0xa2f/0x27f0 kernel/exit.c:877\n  do_group_exit+0x207/0x2c0 kernel/exit.c:1026\n  __do_sys_exit_group kernel/exit.c:1037 [inline]\n  __se_sys_exit_group kernel/exit.c:1035 [inline]\n  __x64_sys_exit_group+0x3f/0x40 kernel/exit.c:1035\n  x64_sys_call+0x2634/0x2640\n  arch/x86/include/generated/asm/syscalls_64.h:232\n  do_syscall_x64 arch/x86/entry/common.c:52 [inline]\n  do_syscall_64+0xf3/0x230 arch/x86/entry/common.c:83\n  entry_SYSCALL_64_after_hwframe+0x77/0x7f\n  RIP: 0033:0x7f5f075b70c9\n  Code: Unable to access opcode bytes at\n  0x7f5f075b709f.\n\nI was hitting the same issue by doing hundreds of accelerated runs of\ngeneric/475', ' which also hits IO errors by design.\n\nI instrumented that reproducer with bpftrace and found that the\nundesirable folio_unlock was coming from the following callstack:\n\n  folio_unlock+5\n  __process_pages_contig+475\n  cow_file_range_inline.constprop.0+230\n  cow_file_range+803\n  btrfs_run_delalloc_range+566\n  writepage_delalloc+332\n  __extent_writepage # inlined in my stacktrace', ' but I added it here\n  extent_write_cache_pages+622\n\nLooking at the bisected-to patch in the syzbot report', ' Josef realized\nthat the logic of the cow_file_range_inline error path subtly changing.\nIn the past', ' on error', ' it jumped to out_unlock in cow_file_range()', '\nwhich honors the locked_page', ' so when we ultimately call\nfolio_end_all_writers()', ' the folio of interest is still locked. After\nthe change', ' we always unlocked ignoring the locked_page', ' on both success\nand error. On the success path', ' this all results in returning 1 to\n__extent_writepage()', ' which skips the folio_end_all_writers() call', '\nwhich makes it OK to have unlocked.\n\nFix the bug by wiring the locked_page into cow_file_range_inline() and\nonly setting locked_page to NULL on success.\n\nReported-by: syzbot+a14d8ac9af3a2a4fd0c8@syzkaller.appspotmail.com\nFixes: 0586d0a89e77 (""btrfs: move extent bit and page cleanup into cow_file_range_inline"")\nCC: stable@vger.kernel.org # 6.10+\nReviewed-by: Qu Wenruo <wqu@suse.com>\nSigned-off-by: Boris Burkov <boris@bur.io>\nSigned-off-by: David Sterba <dsterba@suse.com>\n', '']",This commit adjusts cow_file_range_inline() in btrfs to respect locked_page on errors in the buffered write path.,"btrfs,cow_file_range_inline,locked_page",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
ebc33a3f8d0aeddf19fd5827add24b82ae171829,ebc33a3f8d0aeddf19fd5827add24b82ae171829,Maciej Fijalkowski,maciej.fijalkowski@intel.com,1722017834,Tony Nguyen,anthony.l.nguyen@intel.com,1722268349,e8c1a5d320752997cc73df853be09098c04ef672,9da75a511c5558fa3da56759984fd1fa859186f0,ice: improve updating ice_{t,"r}x_ring::xsk_pool

xsk_buff_pool pointers that ice ring structs hold are updated via
ndo_bpf that is executed in process context while it can be read by
remote CPU at the same time within NAPI poll. Use synchronize_net()
after pointer update and {READ","['WRITE}_ONCE() when working with mentioned\npointer.\n\nFixes: 2d4238f55697 (""ice: Add support for AF_XDP"")\nReviewed-by: Shannon Nelson <shannon.nelson@amd.com>\nTested-by: Chandan Kumar Rout <chandanx.rout@intel.com> (A Contingent Worker at Intel)\nSigned-off-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>\nSigned-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>\n', '']",This commit improves pointer updating mechanism for ice ring structures to prevent issues during concurrent read operations.,"pointer, update, synchronize_net",It's a performance optimization.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tc/netfilter like programs']
d5922717994911e8f0eab736f3ba0d968c158823,d5922717994911e8f0eab736f3ba0d968c158823,Maciej Fijalkowski,maciej.fijalkowski@intel.com,1722017832,Tony Nguyen,anthony.l.nguyen@intel.com,1722268349,cbddecc20715a80cececc165701dbe35a1ce69ab,405d9999aa0b4ae467ef391d1d9c7e0d30ad0841,"ice: modify error handling when setting XSK pool in ndo_bpf

Don't bail out right when spotting an error within ice_qp_{dis","ena}()
but rather track error and go through whole flow of disabling and
enabling queue pair.

Fixes: 2d4238f55697 (""ice: Add support for AF_XDP"")
Reviewed-by: Shannon Nelson <shannon.nelson@amd.com>
Tested-by: Chandan Kumar Rout <chandanx.rout@intel.com> (A Contingent Worker at Intel)
Signed-off-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>
Signed-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>
",[''],Updates error handling to track errors and ensure full flow execution in setting XSK pool in ndo_bpf on ice driver.,"error, XSK pool, ice driver",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['xdp like programs']
1fd2c10acb7b35d72101a4619ee5b2cddb9efd3a,1fd2c10acb7b35d72101a4619ee5b2cddb9efd3a,Mikulas Patocka,mpatocka@redhat.com,1722075062,Helge Deller,deller@gmx.de,1722262747,196c73d9fd2a9da72ecdc355ef7755a57ce1aa09,8400291e289ee6b2bf9779ff1c83a291501f017b,"parisc: fix unaligned accesses in BPF

There were spurious unaligned access warnings when calling BPF code.
Sometimes", the warnings were triggered with any incoming packet,"[' making\nthe machine hard to use.\n\nThe reason for the warnings is this: on parisc64', ' pointers to functions\nare not really pointers to functions', ' they are pointers to 16-byte\ndescriptor. The first 8 bytes of the descriptor is a pointer to the\nfunction and the next 8 bytes of the descriptor is the content of the\n""dp"" register. This descriptor is generated in the function\nbpf_jit_build_prologue.\n\nThe problem is that the function bpf_int_jit_compile advertises 4-byte\nalignment when calling bpf_jit_binary_alloc', ' bpf_jit_binary_alloc\nrandomizes the returned array and if the array happens to be not aligned\non 8-byte boundary', ' the descriptor generated in bpf_jit_build_prologue is\nalso not aligned and this triggers the unaligned access warning.\n\nFix this by advertising 8-byte alignment on parisc64 when calling\nbpf_jit_binary_alloc.\n\nSigned-off-by: Mikulas Patocka <mpatocka@redhat.com>\nCc: stable@vger.kernel.org\nSigned-off-by: Helge Deller <deller@gmx.de>\n', '']",Fix unaligned access warnings in BPF on parisc architecture.,"unaligned,access,parisc",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9da49aa80d686582bc3a027112a30484c9be6b6e,9da49aa80d686582bc3a027112a30484c9be6b6e,Jeongjun Park,aha310510@gmail.com,1721943649,David S. Miller,davem@davemloft.net,1722246915,6ac72bf26a011a6d42b1fbba48233bb86bba59d3,301927d2d2eb8e541357ba850bc7a1a74dbbd670,"tun: Add missing bpf_net_ctx_clear() in do_xdp_generic()

There are cases where do_xdp_generic returns bpf_net_context without
clearing it. This causes various memory corruptions"," so the missing
bpf_net_ctx_clear must be added.

Reported-by: syzbot+44623300f057a28baf1e@syzkaller.appspotmail.com
Fixes: fecef4cd42c6 (""tun: Assign missing bpf_net_context."")
Signed-off-by: Jeongjun Park <aha310510@gmail.com>
Acked-by: Jason Wang <jasowang@redhat.com>
Reviewed-by: Willem de Bruijn <willemb@google.com>
Reported-by: syzbot+3c2b6d5d4bec3b904933@syzkaller.appspotmail.com
Reported-by: syzbot+707d98c8649695eaf329@syzkaller.appspotmail.com
Reported-by: syzbot+c226757eb784a9da3e8b@syzkaller.appspotmail.com
Reported-by: syzbot+61a1cfc2b6632363d319@syzkaller.appspotmail.com
Reported-by: syzbot+709e4c85c904bcd62735@syzkaller.appspotmail.com
Signed-off-by: David S. Miller <davem@davemloft.net>
",[''],Add missing bpf_net_ctx_clear() in do_xdp_generic to prevent memory corruption.,"bpf_net_ctx_clear, do_xdp_generic, memory corruption",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['xdp like programs']
6557a28f3e3a54cff4f0dcdd1dfa649b26557ab3,6557a28f3e3a54cff4f0dcdd1dfa649b26557ab3,Sean Wang,sean.wang@mediatek.com,1721346393,Johannes Berg,johannes.berg@intel.com,1721990060,1550b3dde9255235b01c853c9c73b2e8f76f3d14,189d7aae8f5a100b0db8b302debbd445475d01e6,"wifi: mt76: mt7921: fix null pointer access in mt792x_mac_link_bss_remove

Fix null pointer access in mt792x_mac_link_bss_remove.

To prevent null pointer access"," we should assign the vif to bss_conf in
mt7921_add_interface. This ensures that subsequent operations on the BSS
can properly reference the correct vif.

[  T843] Call Trace:
[  T843]  <TASK>
[  T843]  ? __die+0x1e/0x60
[  T843]  ? page_fault_oops+0x157/0x450
[  T843]  ? srso_alias_return_thunk+0x5/0xfbef5
[  T843]  ? srso_alias_return_thunk+0x5/0xfbef5
[  T843]  ? search_bpf_extables+0x5a/0x80
[  T843]  ? srso_alias_return_thunk+0x5/0xfbef5
[  T843]  ? exc_page_fault+0x2bb/0x670
[  T843]  ? srso_alias_return_thunk+0x5/0xfbef5
[  T843]  ? lock_timer_base+0x71/0x90
[  T843]  ? asm_exc_page_fault+0x26/0x30
[  T843]  ? mt792x_mac_link_bss_remove+0x24/0x110 [mt792x_lib]
[  T843]  ? mt792x_remove_interface+0x6e/0x90 [mt792x_lib]
[  T843]  ? ieee80211_do_stop+0x507/0x7e0 [mac80211]
[  T843]  ? ieee80211_stop+0x53/0x190 [mac80211]
[  T843]  ? __dev_close_many+0xa5/0x120
[  T843]  ? __dev_change_flags+0x18c/0x220
[  T843]  ? dev_change_flags+0x21/0x60
[  T843]  ? do_setlink+0xdf9/0x11d0
[  T843]  ? srso_alias_return_thunk+0x5/0xfbef5
[  T843]  ? srso_alias_return_thunk+0x5/0xfbef5
[  T843]  ? security_sock_rcv_skb+0x33/0x50
[  T843]  ? srso_alias_return_thunk+0x5/0xfbef5
[  T843]  ? srso_alias_return_thunk+0x5/0xfbef5
[  T843]  ? __nla_validate_parse+0x61/0xd10
[  T843]  ? srso_alias_return_thunk+0x5/0xfbef5
[  T843]  ? genl_done+0x53/0x80
[  T843]  ? srso_alias_return_thunk+0x5/0xfbef5
[  T843]  ? netlink_dump+0x357/0x410
[  T843]  ? __rtnl_newlink+0x5d6/0x980
[  T843]  ? srso_alias_return_thunk+0x5/0xfbef5
[  T843]  ? genl_family_rcv_msg_dumpit+0xdf/0xf0
[  T843]  ? srso_alias_return_thunk+0x5/0xfbef5
[  T843]  ? __kmalloc_cache_noprof+0x44/0x210
[  T843]  ? rtnl_newlink+0x42/0x60
[  T843]  ? rtnetlink_rcv_msg+0x152/0x3f0
[  T843]  ? mptcp_pm_nl_dump_addr+0x180/0x180
[  T843]  ? rtnl_calcit.isra.0+0x130/0x130
[  T843]  ? netlink_rcv_skb+0x56/0x100
[  T843]  ? netlink_unicast+0x199/0x290
[  T843]  ? netlink_sendmsg+0x21d/0x490
[  T843]  ? __sock_sendmsg+0x78/0x80
[  T843]  ? ____sys_sendmsg+0x23f/0x2e0
[  T843]  ? srso_alias_return_thunk+0x5/0xfbef5
[  T843]  ? copy_msghdr_from_user+0x68/0xa0
[  T843]  ? ___sys_sendmsg+0x81/0xd0
[  T843]  ? srso_alias_return_thunk+0x5/0xfbef5
[  T843]  ? crng_fast_key_erasure+0xbc/0xf0
[  T843]  ? srso_alias_return_thunk+0x5/0xfbef5
[  T843]  ? get_random_bytes_user+0x126/0x140
[  T843]  ? srso_alias_return_thunk+0x5/0xfbef5
[  T843]  ? __fdget+0xb1/0xe0
[  T843]  ? __sys_sendmsg+0x56/0xa0
[  T843]  ? srso_alias_return_thunk+0x5/0xfbef5
[  T843]  ? do_syscall_64+0x5f/0x170
[  T843]  ? entry_SYSCALL_64_after_hwframe+0x55/0x5d
[  T843]  </TASK>

Fixes: 1541d63c5fe2 (""wifi: mt76: mt7925: add mt7925_mac_link_bss_remove to remove per-link BSS"")
Reported-by: Bert Karwatzki <spasswolf@web.de>
Closes: https://lore.kernel.org/linux-wireless/2fee61f8c903d02a900ca3188c3742c7effd102e.camel@web.de/#b
Signed-off-by: Sean Wang <sean.wang@mediatek.com>
Tested-by: Bert Karwatzki <spasswolf@web.de>
Link: https://patch.msgid.link/20240718234633.12737-1-sean.wang@kernel.org
Signed-off-by: Johannes Berg <johannes.berg@intel.com>
",[''],Fix null pointer access issue in mt792x_mac_link_bss_remove in the wifi mt76 driver.,null pointer fix wifi,It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
1722389b0d863056d78287a120a1d6cadb8d4f7b,1722389b0d863056d78287a120a1d6cadb8d4f7b,Linus Torvalds,torvalds@linux-foundation.org,1721939545,Linus Torvalds,torvalds@linux-foundation.org,1721939545,95c3c3b1ca6213eecbfc584b58b7676673e3696e,8bf100092d60bf586bbc1a3a2cd833bb212d9d53 af65ea42bd1d28d818b74b9b3b4f8da7ada9f88b,"Merge tag 'net-6.11-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Jakub Kicinski:
 ""Including fixes from bpf and netfilter.

  A lot of networking people were at a conference last week"," busy
  catching COVID","[' so relatively short PR.\n\n  Current release - regressions:\n\n   - tcp: process the 3rd ACK with sk_socket for TFO and MPTCP\n\n  Current release - new code bugs:\n\n   - l2tp: protect session IDR and tunnel session list with one lock', '\n     make sure the state is coherent to avoid a warning\n\n   - eth: bnxt_en: update xdp_rxq_info in queue restart logic\n\n   - eth: airoha: fix location of the MBI_RX_AGE_SEL_MASK field\n\n  Previous releases - regressions:\n\n   - xsk: require XDP_UMEM_TX_METADATA_LEN to actuate tx_metadata_len', '\n     the field reuses previously un-validated pad\n\n  Previous releases - always broken:\n\n   - tap/tun: drop short frames to prevent crashes later in the stack\n\n   - eth: ice: add a per-VF limit on number of FDIR filters\n\n   - af_unix: disable MSG_OOB handling for sockets in sockmap/sockhash""\n\n* tag \'net-6.11-rc1\' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (34 commits)\n  tun: add missing verification for short frame\n  tap: add missing verification for short frame\n  mISDN: Fix a use after free in hfcmulti_tx()\n  gve: Fix an edge case for TSO skb validity check\n  bnxt_en: update xdp_rxq_info in queue restart logic\n  tcp: process the 3rd ACK with sk_socket for TFO/MPTCP\n  selftests/bpf: Add XDP_UMEM_TX_METADATA_LEN to XSK TX metadata test\n  xsk: Require XDP_UMEM_TX_METADATA_LEN to actuate tx_metadata_len\n  bpf: Fix a segment issue when downgrading gso_size\n  net: mediatek: Fix potential NULL pointer dereference in dummy net_device handling\n  MAINTAINERS: make Breno the netconsole maintainer\n  MAINTAINERS: Update bonding entry\n  net: nexthop: Initialize all fields in dumped nexthops\n  net: stmmac: Correct byte order of perfect_match\n  selftests: forwarding: skip if kernel not support setting bridge fdb learning limit\n  tipc: Return non-zero value from tipc_udp_addr2str() on error\n  netfilter: nft_set_pipapo_avx2: disable softinterrupts\n  ice: Fix recipe read procedure\n  ice: Add a per-VF limit on number of FDIR filters\n  net: bonding: correctly annotate RCU in bond_should_notify_peers()\n  ...\n', '']",Merge networking fixes from netdev including bpf and netfilter updates.,"networking, bpf, netfilter",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['tc/netfilter like programs', 'tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f7578df913041f08b680aac2c660ebd71f35af3a,f7578df913041f08b680aac2c660ebd71f35af3a,Jakub Kicinski,kuba@kernel.org,1721918424,Jakub Kicinski,kuba@kernel.org,1721918425,aabd7d57a3c183d3f391d8fa38c7d280d3524004,c1668292689ad2ee16c9c1750a8044b0b0aad663 9b9969c40b0d63a8fca434d4ea01c60a39699aa3,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Daniel Borkmann says:

====================
pull-request: bpf 2024-07-25

We've added 14 non-merge commits during the last 8 day(s) which contain
a total of 19 files changed", 177 insertions(+),"[' 70 deletions(-).\n\nThe main changes are:\n\n1) Fix af_unix to disable MSG_OOB handling for sockets in BPF sockmap and\n   BPF sockhash. Also add test coverage for this case', ' from Michal Luczaj.\n\n2) Fix a segmentation issue when downgrading gso_size in the BPF helper\n   bpf_skb_adjust_room()', ' from Fred Li.\n\n3) Fix a compiler warning in resolve_btfids due to a missing type cast', '\n   from Liwei Song.\n\n4) Fix stack allocation for arm64 to align the stack pointer at a 16 byte\n   boundary in the fexit_sleep BPF selftest', ' from Puranjay Mohan.\n\n5) Fix a xsk regression to require a flag when actuating tx_metadata_len', '\n   from Stanislav Fomichev.\n\n6) Fix function prototype BTF dumping in libbpf for prototypes that have\n   no input arguments', ' from Andrii Nakryiko.\n\n7) Fix stacktrace symbol resolution in perf script for BPF programs\n   containing subprograms', "" from Hou Tao.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  selftests/bpf: Add XDP_UMEM_TX_METADATA_LEN to XSK TX metadata test\n  xsk: Require XDP_UMEM_TX_METADATA_LEN to actuate tx_metadata_len\n  bpf: Fix a segment issue when downgrading gso_size\n  tools/resolve_btfids: Fix comparison of distinct pointer types warning in resolve_btfids\n  bpf"", ' events: Use prog to emit ksymbol event for main program\n  selftests/bpf: Test sockmap redirect for AF_UNIX MSG_OOB\n  selftests/bpf: Parametrize AF_UNIX redir functions to accept send() flags\n  selftests/bpf: Support SOCK_STREAM in unix_inet_redir_to_connected()\n  af_unix: Disable MSG_OOB handling for sockets in sockmap/sockhash\n  bpftool: Fix typo in usage help\n  libbpf: Fix no-args func prototype BTF dumping syntax\n  MAINTAINERS: Update powerpc BPF JIT maintainers\n  MAINTAINERS: Update email address of Naveen\n  selftests/bpf: fexit_sleep: Fix stack allocation for arm64\n====================\n\nLink: https://patch.msgid.link/20240725114312.32197-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Merged changes from 'for-netdev' branch in the Linux bpf repository.,"merge,for-netdev,bpf",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
9b9969c40b0d63a8fca434d4ea01c60a39699aa3,9b9969c40b0d63a8fca434d4ea01c60a39699aa3,Stanislav Fomichev,sdf@fomichev.me,1720835572,Daniel Borkmann,daniel@iogearbox.net,1721901453,e45ea5ac0de4581211d6f77b054faaf2accdb965,d5e726d9143c5624135f5dc9e4069799adeef734,"selftests/bpf: Add XDP_UMEM_TX_METADATA_LEN to XSK TX metadata test

This flag is now required to use tx_metadata_len.

Fixes: 40808a237d9c (""selftests/bpf: Add TX side to xdp_metadata"")
Reported-by: Julian Schindel <mail@arctic-alpaca.de>
Signed-off-by: Stanislav Fomichev <sdf@fomichev.me>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Reviewed-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>
Link: https://lore.kernel.org/bpf/20240713015253.121248-3-sdf@fomichev.me
",,Add XDP_UMEM_TX_METADATA_LEN flag to XSK TX metadata test for compliance.,"XDP_UMEM_TX_METADATA_LEN,XSK,metadata",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['xdp like programs']
d5e726d9143c5624135f5dc9e4069799adeef734,d5e726d9143c5624135f5dc9e4069799adeef734,Stanislav Fomichev,sdf@fomichev.me,1720835571,Daniel Borkmann,daniel@iogearbox.net,1721901447,d24f61de8cd5af48ecedeecac656669eb4a8019f,fa5ef655615a01533035c6139248c5b33aa27028,"xsk: Require XDP_UMEM_TX_METADATA_LEN to actuate tx_metadata_len

Julian reports that commit 341ac980eab9 (""xsk: Support tx_metadata_len"")
can break existing use cases which don't zero-initialize xdp_umem_reg
padding. Introduce new XDP_UMEM_TX_METADATA_LEN to make sure we
interpret the padding as tx_metadata_len only when being explicitly
asked.

Fixes: 341ac980eab9 (""xsk: Support tx_metadata_len"")
Reported-by: Julian Schindel <mail@arctic-alpaca.de>
Signed-off-by: Stanislav Fomichev <sdf@fomichev.me>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Reviewed-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>
Link: https://lore.kernel.org/bpf/20240713015253.121248-2-sdf@fomichev.me
",,Introduce XDP_UMEM_TX_METADATA_LEN to ensure explicit tx_metadata_len interpretation in XDP sockets.,"XDP, tx_metadata_len, xsk",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,['xdp like programs']
fa5ef655615a01533035c6139248c5b33aa27028,fa5ef655615a01533035c6139248c5b33aa27028,Fred Li,dracodingfly@gmail.com,1721357213,Daniel Borkmann,daniel@iogearbox.net,1721901014,66603a87fa8f8580a21a182af1da71adab1bc9b7,13c9b702e6cb8e406d5fa6b2dca422fa42d2f13e,"bpf: Fix a segment issue when downgrading gso_size

Linearize the skb when downgrading gso_size because it may trigger a
BUG_ON() later when the skb is segmented as described in [1","2].

Fixes: 2be7e212d5419 (""bpf: add bpf_skb_adjust_room helper"")
Signed-off-by: Fred Li <dracodingfly@gmail.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Reviewed-by: Willem de Bruijn <willemb@google.com>
Acked-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/all/20240626065555.35460-2-dracodingfly@gmail.com [1]
Link: https://lore.kernel.org/all/668d5cf1ec330_1c18c32947@willemb.c.googlers.com.notmuch [2]
Link: https://lore.kernel.org/bpf/20240719024653.77006-1-dracodingfly@gmail.com
",[''],Fixes a segment issue in eBPF by linearizing skb when downgrading gso_size to prevent potential BUG_ON errors.,"bpf, segment issue, gso_size",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
facdbdfe0e6202d74758387ae9189c39f7b4b16c,facdbdfe0e6202d74758387ae9189c39f7b4b16c,Benjamin Tissoires,bentiss@kernel.org,1721751714,Benjamin Tissoires,bentiss@kernel.org,1721838442,6f99efe47551af6644b5f81d5b9e6ea54bf9c7bf,acd34cfc48b3dd46e5e4c4bdc99cc0c15568bac0,"selftests/hid: add test for attaching multiple time the same struct_ops

Turns out that we would en up in a bad state if we attempt to attach
twice the same HID-BPF struct_ops"," so have a test for it.

Link: https://patch.msgid.link/20240723-fix-6-11-bpf-v1-4-b9d770346784@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Add selftests for attaching HID-BPF struct_ops multiple times to prevent bad state.,"selftests,HID-BPF,struct_ops",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['HID driver like programs']
acd34cfc48b3dd46e5e4c4bdc99cc0c15568bac0,acd34cfc48b3dd46e5e4c4bdc99cc0c15568bac0,Benjamin Tissoires,bentiss@kernel.org,1721751713,Benjamin Tissoires,bentiss@kernel.org,1721838441,849436a46a6031b01a8d3c212240e77e0010477e,f64c1a4593391c57accf32693a14ef45f8162b5c,"HID: bpf: prevent the same struct_ops to be attached more than once

If the struct_ops is already attached"," we should bail out or we will
end up in various locks and pointer issues while unregistering.

Link: https://patch.msgid.link/20240723-fix-6-11-bpf-v1-3-b9d770346784@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Prevent attaching the same struct_ops multiple times to avoid locks and pointer issues.,"HID,struct_ops,unregistering",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['HID driver like programs']
f64c1a4593391c57accf32693a14ef45f8162b5c,f64c1a4593391c57accf32693a14ef45f8162b5c,Benjamin Tissoires,bentiss@kernel.org,1721751712,Benjamin Tissoires,bentiss@kernel.org,1721838441,1934086f2f586eb84fd81be3997b10e1d22082e4,ff9fbcafbaf13346c742c0d672a22f5ac20b9d92,"selftests/hid: disable struct_ops auto-attach

Since commit 08ac454e258e (""libbpf: Auto-attach struct_ops BPF maps in
BPF skeleton"")"," libbpf automatically calls bpf_map__attach_struct_ops()
on every struct_ops it sees in the bpf object. The problem is that
our test bpf object has many of them but only one should be manually
loaded at a time","[' or we end up locking the syscall.\n\nLink: https://patch.msgid.link/20240723-fix-6-11-bpf-v1-2-b9d770346784@kernel.org\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']",Disable automatic struct_ops attachment in eBPF selftests for HID due to multiple struct_ops in a test bpf object.,"selftests,hid,struct_ops",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).', 'HID driver like programs']"
ff9fbcafbaf13346c742c0d672a22f5ac20b9d92,ff9fbcafbaf13346c742c0d672a22f5ac20b9d92,Benjamin Tissoires,bentiss@kernel.org,1721751711,Benjamin Tissoires,bentiss@kernel.org,1721838441,969db8dc0d41e2766a9f0a8fb6b39d0f7b1c2193,8031b001da700474c11d28629581480b12a0d8d4,"selftests/hid: fix bpf_wq new API

Since commit f56f4d541eab (""bpf: helpers: fix bpf_wq_set_callback_impl
signature"")"," the API for bpf_wq changed a bit.

We need to update the selftests/hid code to reflect that or the
bpf program will not load.

Link: https://patch.msgid.link/20240723-fix-6-11-bpf-v1-1-b9d770346784@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Update selftests/hid code for compatibility with new bpf_wq API changes.,"selftests, bpf_wq, API",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['HID driver like programs']
bacc15e010fc5a235fb2020b06a29a9961b5db82,bacc15e010fc5a235fb2020b06a29a9961b5db82,Arnd Bergmann,arnd@arndb.de,1721382667,Benjamin Tissoires,bentiss@kernel.org,1721659925,8d75d364e3501d3d4863efc3bcb2009dba9a80bf,9c2913b962daf3e5a947babf93f2125765eeca09,"hid: bpf: add BPF_JIT dependency

The module does not do anything when the JIT is disabled"," but instead
causes a warning:

In file included from include/linux/bpf_verifier.h:7","[""\n                 from drivers/hid/bpf/hid_bpf_struct_ops.c:10:\ndrivers/hid/bpf/hid_bpf_struct_ops.c: In function 'hid_bpf_struct_ops_init':\ninclude/linux/bpf.h:1853:50: error: statement with no effect [-Werror=unused-value]\n 1853 | #define register_bpf_struct_ops(st_ops"", "" type) ({ (void *)(st_ops); 0; })\n      |                                                  ^~~~~~~~~~~~~~~~\ndrivers/hid/bpf/hid_bpf_struct_ops.c:305:16: note: in expansion of macro 'register_bpf_struct_ops'\n  305 |         return register_bpf_struct_ops(&bpf_hid_bpf_ops"", ' hid_bpf_ops);\n      |                ^~~~~~~~~~~~~~~~~~~~~~~\n\nAdd a Kconfig dependency to only allow building the HID-BPF support\nwhen a JIT is enabled.\n\nFixes: ebc0d8093e8c (""HID: bpf: implement HID-BPF through bpf_struct_ops"")\nSigned-off-by: Arnd Bergmann <arnd@arndb.de>\nLink: https://patch.msgid.link/96a00b6f-eb81-4c67-8c4b-6b1f3f045034@app.fastmail.com\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']",The commit adds a BPF_JIT dependency to the HID module to prevent warnings when the JIT is disabled.,"BPF_JIT, HID, dependency",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['HID driver like programs']
13c9b702e6cb8e406d5fa6b2dca422fa42d2f13e,13c9b702e6cb8e406d5fa6b2dca422fa42d2f13e,Liwei Song,liwei.song.lsong@gmail.com,1721637179,Daniel Borkmann,daniel@iogearbox.net,1721658930,649319e8d9e842ebc8abe3b7041a81a0cd197fe9,0be9ae5486cd9e767138c13638820d240713f5f1,"tools/resolve_btfids: Fix comparison of distinct pointer types warning in resolve_btfids

Add a type cast for set8->pairs to fix below compile warning:

main.c: In function 'sets_patch':
main.c:699:50: warning: comparison of distinct pointer types lacks a cast
  699 |        BUILD_BUG_ON(set8->pairs != &set8->pairs[0].id);
      |                                 ^~

Fixes: 9707ac4fe2f5 (""tools/resolve_btfids: Refactor set sorting with types from btf_ids.h"")
Signed-off-by: Liwei Song <liwei.song.lsong@gmail.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Link: https://lore.kernel.org/bpf/20240722083305.4009723-1-liwei.song.lsong@gmail.com
",,This commit fixes a warning by adding a type cast in resolve_btfids for distinct pointer types comparison.,"type cast, pointer, warning",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
527eff227d4321c6ea453db1083bc4fdd4d3a3e8,527eff227d4321c6ea453db1083bc4fdd4d3a3e8,Linus Torvalds,torvalds@linux-foundation.org,1721609782,Linus Torvalds,torvalds@linux-foundation.org,1721609782,b8a3ac07f4ea34d19ef740487d06be6bfacaacf7,fbc90c042cd1dc7258ebfebe6d226017e5b5ac8c 67856f44da381973caf4eb692ad2cca1de7b2d37,"Merge tag 'mm-nonmm-stable-2024-07-21-15-07' of git://git.kernel.org/pub/scm/linux/kernel/git/akpm/mm

Pull non-MM updates from Andrew Morton:

 - In the series ""treewide: Refactor heap related implementation""","
   Kuan-Wei Chiu has significantly reworked the min_heap library code
   and has taught bcachefs to use the new more generic implementation.

 - Yury Norov's series ""Cleanup cpumask.h inclusion in core headers""
   reworks the cpumask and nodemask headers to make things generally
   more rational.

 - Kuan-Wei Chiu has sent along some maintenance work against our
   sorting library code in the series ""lib/sort: Optimizations and
   cleanups"".

 - More library maintainance work from Christophe Jaillet in the series
   ""Remove usage of the deprecated ida_simple_xx() API"".

 - Ryusuke Konishi continues with the nilfs2 fixes and clanups in the
   series ""nilfs2: eliminate the call to inode_attach_wb()"".

 - Kuan-Ying Lee has some fixes to the gdb scripts in the series ""Fix
   GDB command error"".

 - Plus the usual shower of singleton patches all over the place. Please
   see the relevant changelogs for details.

* tag 'mm-nonmm-stable-2024-07-21-15-07' of git://git.kernel.org/pub/scm/linux/kernel/git/akpm/mm: (98 commits)
  ia64: scrub ia64 from poison.h
  watchdog/perf: properly initialize the turbo mode timestamp and rearm counter
  tsacct: replace strncpy() with strscpy()
  lib/bch.c: use swap() to improve code
  test_bpf: convert comma to semicolon
  init/modpost: conditionally check section mismatch to __meminit*
  init: remove unused __MEMINIT* macros
  nilfs2: Constify struct kobj_type
  nilfs2: avoid undefined behavior in nilfs_cnt32_ge macro
  math: rational: add missing MODULE_DESCRIPTION() macro
  lib/zlib: add missing MODULE_DESCRIPTION() macro
  fs: ufs: add MODULE_DESCRIPTION()
  lib/rbtree.c: fix the example typo
  ocfs2: add bounds checking to ocfs2_check_dir_entry()
  fs: add kernel-doc comments to ocfs2_prepare_orphan_dir()
  coredump: simplify zap_process()
  selftests/fpu: add missing MODULE_DESCRIPTION() macro
  compiler.h: simplify data_race() macro
  build-id: require program headers to be right after ELF header
  resource: add missing MODULE_DESCRIPTION()
  ...
",[''],Merge non-MM updates including refactoring and maintenance work across various kernel components.,"refactor, maintenance, updates",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
7697a0fe0154468f5df35c23ebd7aa48994c2cdc,7697a0fe0154468f5df35c23ebd7aa48994c2cdc,Huacai Chen,chenhuacai@loongson.cn,1721486458,Huacai Chen,chenhuacai@loongson.cn,1721486458,ee025c756ca826b09b31d2bbd034d3fd7dda5829,256a6f430562c163f1fa07576c4cd4e996e953dd,"LoongArch: Define __ARCH_WANT_NEW_STAT in unistd.h

Chromium sandbox apparently wants to deny statx [1] so it could properly
inspect arguments after the sandboxed process later falls back to fstat.
Because there's currently not a ""fd-only"" version of statx"," so that the
sandbox has no way to ensure the path argument is empty without being
able to peek into the sandboxed process's memory. For architectures able
to do newfstatat though","[' glibc falls back to newfstatat after getting\n-ENOSYS for statx', ' then the respective SIGSYS handler [2] takes care of\ninspecting the path argument', "" transforming allowed newfstatat's into\nfstat instead which is allowed and has the same type of return value.\n\nBut"", ' as LoongArch is the first architecture to not have fstat nor\nnewfstatat', ' the LoongArch glibc does not attempt falling back at all\nwhen it gets -ENOSYS for statx -- and you see the problem there!\n\nActually', ' back when the LoongArch port was under review', ' people were\naware of the same problem with sandboxing clone3 [3]', ' so clone was\neventually kept. Unfortunately it seemed at that time no one had noticed\nstatx', ' so besides restoring fstat/newfstatat to LoongArch uapi (and\npostponing the problem further)', ' it seems inevitable that we would need\nto tackle seccomp deep argument inspection.\n\nHowever', "" this is obviously a decision that shouldn't be taken lightly"", '\nso we just restore fstat/newfstatat by defining __ARCH_WANT_NEW_STAT\nin unistd.h. This is the simplest solution for now', ' and so we hope the\ncommunity will tackle the long-standing problem of seccomp deep argument\ninspection in the future [4][5].\n\nAlso add ""newstat"" to syscall_abis_64 in Makefile.syscalls due to\nupstream asm-generic changes.\n\nMore infomation please reading this thread [6].\n\n[1] https://chromium-review.googlesource.com/c/chromium/src/+/2823150\n[2] https://chromium.googlesource.com/chromium/src/sandbox/+/c085b51940bd/linux/seccomp-bpf-helpers/sigsys_handlers.cc#355\n[3] https://lore.kernel.org/linux-arch/20220511211231.GG7074@brightrain.aerifal.cx/\n[4] https://lwn.net/Articles/799557/\n[5] https://lpc.events/event/4/contributions/560/attachments/397/640/deep-arg-inspection.pdf\n[6] https://lore.kernel.org/loongarch/20240226-granit-seilschaft-eccc2433014d@brauner/T/#t\n\nCc: stable@vger.kernel.org\nSigned-off-by: Huacai Chen <chenhuacai@loongson.cn>\n', '']",The commit defines __ARCH_WANT_NEW_STAT in unistd.h for LoongArch to address issues with Chromium sandbox and statx.,"LoongArch, statx, unistd.h",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
3c3ff7be9729959699eb6cbc7fd7303566d74069,3c3ff7be9729959699eb6cbc7fd7303566d74069,Linus Torvalds,torvalds@linux-foundation.org,1721448033,Linus Torvalds,torvalds@linux-foundation.org,1721448033,78bd6bd59acc53b47cb91883121b805f0e4fe8e7,3f386cb8ee9f04ff4be164ca7a1d0ef3f81f7374 9ff0251b2eb54d17fbe4f6aff50f6edfd837adb6,"Merge tag 'powerpc-6.11-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux

Pull powerpc updates from Michael Ellerman:

 - Remove support for 40x CPUs & platforms

 - Add support to the 64-bit BPF JIT for cpu v4 instructions

 - Fix PCI hotplug driver crash on powernv

 - Fix doorbell emulation for KVM on PAPR guests (nestedv2)

 - Fix KVM nested guest handling of some less used SPRs

 - Online NUMA nodes with no CPU/memory if they have a PCI device
   attached

 - Reduce memory overhead of enabling kfence on 64-bit Radix MMU kernels

 - Reimplement the iommu table_group_ops for pseries for VFIO SPAPR TCE

Thanks to: Anjali K", Artem Savkov,"[' Athira Rajeev', ' Breno Leitao', ' Brian\nKing', ' Celeste Liu', ' Christophe Leroy', ' Esben Haabendal', ' Gaurav Batra', '\nGautam Menghani', ' Haren Myneni', ' Hari Bathini', ' Jeff Johnson', ' Krishna\nKumar', ' Krzysztof Kozlowski', ' Nathan Lynch', ' Nicholas Piggin', ' Nick Bowler', '\nNilay Shroff', ' Rob Herring (Arm)', ' Shawn Anastasio', ' Shivaprasad G Bhat', '\nSourabh Jain', ' Srikar Dronamraju', ' Timothy Pearson', ' Uwe Kleine-König', "" and\nVaibhav Jain.\n\n* tag 'powerpc-6.11-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (57 commits)\n  Documentation/powerpc: Mention 40x is removed\n  powerpc: Remove 40x leftovers\n  macintosh/therm_windtunnel: fix module unload.\n  powerpc: Check only single values are passed to CPU/MMU feature checks\n  powerpc/xmon: Fix disassembly CPU feature checks\n  powerpc: Drop clang workaround for builtin constant checks\n  powerpc64/bpf: jit support for signed division and modulo\n  powerpc64/bpf: jit support for sign extended mov\n  powerpc64/bpf: jit support for sign extended load\n  powerpc64/bpf: jit support for unconditional byte swap\n  powerpc64/bpf: jit support for 32bit offset jmp instruction\n  powerpc/pci: Hotplug driver bridge support\n  pci/hotplug/pnv_php: Fix hotplug driver crash on Powernv\n  powerpc/configs: Update defconfig with now user-visible CONFIG_FSL_IFC\n  powerpc: add missing MODULE_DESCRIPTION() macros\n  macintosh/mac_hid: add MODULE_DESCRIPTION()\n  KVM: PPC: add missing MODULE_DESCRIPTION() macros\n  powerpc/kexec: Use of_property_read_reg()\n  powerpc/64s/radix/kfence: map __kfence_pool at page granularity\n  powerpc/pseries/iommu: Define spapr_tce_table_group_ops only with CONFIG_IOMMU_API\n  ...\n"", '']",Merge powerpc updates including removal of 40x support and improvements to 64-bit BPF JIT.,"powerpc,BPF JIT,40x CPUs",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0be9ae5486cd9e767138c13638820d240713f5f1,0be9ae5486cd9e767138c13638820d240713f5f1,Hou Tao,houtao1@huawei.com,1720940133,Daniel Borkmann,daniel@iogearbox.net,1721402796,a8578cf3b89c777270a45c0d89697ec1f3c550a5,6caf9efaa169faea10a369dd6b36806ae6842584,bpf," events: Use prog to emit ksymbol event for main program

Since commit 0108a4e9f358 (""bpf: ensure main program has an extable"")","['\nprog->aux->func[0]->kallsyms is left as uninitialized. For BPF programs\nwith subprogs', ' the symbol for the main program is missing just as shown\nin the output of perf script below:\n\n ffffffff81284b69 qp_trie_lookup_elem+0xb9 ([kernel.kallsyms])\n ffffffffc0011125 bpf_prog_a4a0eb0651e6af8b_lookup_qp_trie+0x5d (bpf...)\n ffffffff8127bc2b bpf_for_each_array_elem+0x7b ([kernel.kallsyms])\n ffffffffc00110a1 +0x25 ()\n ffffffff8121a89a trace_call_bpf+0xca ([kernel.kallsyms])\n\nFix it by always using prog instead prog->aux->func[0] to emit ksymbol\nevent for the main program. After the fix', ' the output of perf script\nwill be correct:\n\n ffffffff81284b96 qp_trie_lookup_elem+0xe6 ([kernel.kallsyms])\n ffffffffc001382d bpf_prog_a4a0eb0651e6af8b_lookup_qp_trie+0x5d (bpf...)\n ffffffff8127bc2b bpf_for_each_array_elem+0x7b ([kernel.kallsyms])\n ffffffffc0013779 bpf_prog_245c55ab25cfcf40_qp_trie_lookup+0x25 (bpf...)\n ffffffff8121a89a trace_call_bpf+0xca ([kernel.kallsyms])\n\nFixes: 0108a4e9f358 (""bpf: ensure main program has an extable"")\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Yonghong Song <yonghong.song@linux.dev>\nReviewed-by: Krister Johansen <kjlx@templeofstupid.com>\nReviewed-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/bpf/20240714065533.1112616-1-houtao@huaweicloud.com\n', '']",The commit ensures the main eBPF program emits ksymbol events using 'prog'.,"ksymbol, events, prog",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
91bd008d4e2b4962ecb9a10e40c2fb666b0aeb92,91bd008d4e2b4962ecb9a10e40c2fb666b0aeb92,Linus Torvalds,torvalds@linux-foundation.org,1721330360,Linus Torvalds,torvalds@linux-foundation.org,1721330360,c63456ce31eef7c07c1313715a0e24242bf4c92e,cb273eb7c8390c70a484db6c79a797e377db09b5 c26b1b89b8a9fd8665e79cd798bd970e233772b6,"Merge tag 'probes-v6.11' of git://git.kernel.org/pub/scm/linux/kernel/git/trace/linux-trace

Pull probes updates from Masami Hiramatsu:
 ""Uprobes:

   - x86/shstk: Make return uprobe work with shadow stack

   - Add uretprobe syscall which speeds up the uretprobe 10-30% faster.
     This syscall is automatically used from user-space trampolines
     which are generated by the uretprobe. If this syscall is used by
     normal user program"," it will cause SIGILL. Note that this is
     currently only implemented on x86_64.

     (This also has two fixes for adjusting the syscall number to avoid
     conflict with new *attrat syscalls.)

   - uprobes/perf: fix user stack traces in the presence of pending
     uretprobe. This corrects the uretprobe's trampoline address in the
     stacktrace with correct return address

   - selftests/x86: Add a return uprobe with shadow stack test

   - selftests/bpf: Add uretprobe syscall related tests.
      - test case for register integrity check
      - test case with register changing case
      - test case for uretprobe syscall without uprobes (expected to fail)
      - test case for uretprobe with shadow stack

   - selftests/bpf: add test validating uprobe/uretprobe stack traces

   - MAINTAINERS: Add uprobes entry. This does not specify the tree but
     to clarify who maintains and reviews the uprobes

  Kprobes:

   - tracing/kprobes: Test case cleanups.

     Replace redundant WARN_ON_ONCE() + pr_warn() with WARN_ONCE() and
     remove unnecessary code from selftest

   - tracing/kprobes: Add symbol counting check when module loads.

     This checks the uniqueness of the probed symbol on modules. The
     same check has already done for kernel symbols

     (This also has a fix for build error with CONFIG_MODULES=n)

  Cleanup:

   - Add MODULE_DESCRIPTION() macros for fprobe and kprobe examples""

* tag 'probes-v6.11' of git://git.kernel.org/pub/scm/linux/kernel/git/trace/linux-trace:
  MAINTAINERS: Add uprobes entry
  selftests/bpf: Change uretprobe syscall number in uprobe_syscall test
  uprobe: Change uretprobe syscall scope and number
  tracing/kprobes: Fix build error when find_module() is not available
  tracing/kprobes: Add symbol counting check when module loads
  selftests/bpf: add test validating uprobe/uretprobe stack traces
  perf","['uprobes: fix user stack traces in the presence of pending uretprobes\n  tracing/kprobe: Remove cleanup code unrelated to selftest\n  tracing/kprobe: Integrate test warnings into WARN_ONCE\n  selftests/bpf: Add uretprobe shadow stack test\n  selftests/bpf: Add uretprobe syscall call from user space test\n  selftests/bpf: Add uretprobe syscall test for regs changes\n  selftests/bpf: Add uretprobe syscall test for regs integrity\n  selftests/x86: Add return uprobe shadow stack test\n  uprobe: Add uretprobe syscall to speed up return probe\n  uprobe: Wire up uretprobe system call\n  x86/shstk: Make return uprobe work with shadow stack\n  samples: kprobes: add missing MODULE_DESCRIPTION() macros\n  fprobe: add missing MODULE_DESCRIPTION() macro\n', '']","Merge and update uprobes, including performance improvements and test cases, while fixing related issues on x86 architecture.","uprobes,x86_64,performance",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
120f1c857a73e52132e473dee89b340440cb692b,120f1c857a73e52132e473dee89b340440cb692b,Pablo Neira Ayuso,pablo@netfilter.org,1721052882,Paolo Abeni,pabeni@redhat.com,1721292737,5effe47ddb1dd2cd68e49b975b161347bdcb705a,c14112a5574ff5cf3de198ab6eeff53ac1234068,"net: flow_dissector: use DEBUG_NET_WARN_ON_ONCE

The following splat is easy to reproduce upstream as well as in -stable
kernels. Florian Westphal provided the following commit:

  d1dab4f71d37 (""net: add and use __skb_get_hash_symmetric_net"")

but this complementary fix has been also suggested by Willem de Bruijn
and it can be easily backported to -stable kernel which consists in
using DEBUG_NET_WARN_ON_ONCE instead to silence the following splat
given __skb_get_hash() is used by the nftables tracing infrastructure to
to identify packets in traces.

[69133.561393] ------------[ cut here ]------------
[69133.561404] WARNING: CPU: 0 PID: 43576 at net/core/flow_dissector.c:1104 __skb_flow_dissect+0x134f/
[...]
[69133.561944] CPU: 0 PID: 43576 Comm: socat Not tainted 6.10.0-rc7+ #379
[69133.561959] RIP: 0010:__skb_flow_dissect+0x134f/0x2ad0
[69133.561970] Code: 83 f9 04 0f 84 b3 00 00 00 45 85 c9 0f 84 aa 00 00 00 41 83 f9 02 0f 84 81 fc ff
ff 44 0f b7 b4 24 80 00 00 00 e9 8b f9 ff ff <0f> 0b e9 20 f3 ff ff 41 f6 c6 20 0f 84 e4 ef ff ff 48 8d 7b 12 e8
[69133.561979] RSP: 0018:ffffc90000006fc0 EFLAGS: 00010246
[69133.561988] RAX: 0000000000000000 RBX: ffffffff82f33e20 RCX: ffffffff81ab7e19
[69133.561994] RDX: dffffc0000000000 RSI: ffffc90000007388 RDI: ffff888103a1b418
[69133.562001] RBP: ffffc90000007310 R08: 0000000000000000 R09: 0000000000000000
[69133.562007] R10: ffffc90000007388 R11: ffffffff810cface R12: ffff888103a1b400
[69133.562013] R13: 0000000000000000 R14: ffffffff82f33e2a R15: ffffffff82f33e28
[69133.562020] FS:  00007f40f7131740(0000) GS:ffff888390800000(0000) knlGS:0000000000000000
[69133.562027] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
[69133.562033] CR2: 00007f40f7346ee0 CR3: 000000015d200001 CR4: 00000000001706f0
[69133.562040] Call Trace:
[69133.562044]  <IRQ>
[69133.562049]  ? __warn+0x9f/0x1a0
[ 1211.841384]  ? __skb_flow_dissect+0x107e/0x2860
[...]
[ 1211.841496]  ? bpf_flow_dissect+0x160/0x160
[ 1211.841753]  __skb_get_hash+0x97/0x280
[ 1211.841765]  ? __skb_get_hash_symmetric+0x230/0x230
[ 1211.841776]  ? mod_find+0xbf/0xe0
[ 1211.841786]  ? get_stack_info_noinstr+0x12/0xe0
[ 1211.841798]  ? bpf_ksym_find+0x56/0xe0
[ 1211.841807]  ? __rcu_read_unlock+0x2a/0x70
[ 1211.841819]  nft_trace_init+0x1b9/0x1c0 [nf_tables]
[ 1211.841895]  ? nft_trace_notify+0x830/0x830 [nf_tables]
[ 1211.841964]  ? get_stack_info+0x2b/0x80
[ 1211.841975]  ? nft_do_chain_arp+0x80/0x80 [nf_tables]
[ 1211.842044]  nft_do_chain+0x79c/0x850 [nf_tables]

Fixes: 9b52e3f267a6 (""flow_dissector: handle no-skb use case"")
Suggested-by: Willem de Bruijn <willemb@google.com>
Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
Reviewed-by: Willem de Bruijn <willemb@google.com>
Link: https://patch.msgid.link/20240715141442.43775-1-pablo@netfilter.org
Signed-off-by: Paolo Abeni <pabeni@redhat.com>

",,Fix net flow dissector to silence warnings by using DEBUG_NET_WARN_ON_ONCE.,"flow_dissector, DEBUG_NET_WARN_ON_ONCE, nftables",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['other']
a7526fe8b94eced7d82aa00b2bcca44e39ae0769,a7526fe8b94eced7d82aa00b2bcca44e39ae0769,Vlastimil Babka,vbabka@suse.cz,1720715730,Andrew Morton,akpm@linux-foundation.org,1721275518,9fc2d028248b9243902f34af6f5614d17f5f1e1f,7b7aca6d7c0f9b2d9400bfc57cb2b23cfbd5134d,mm," slab: put should_failslab() back behind CONFIG_SHOULD_FAILSLAB

Patch series ""revert unconditional slab and page allocator fault injection
calls"".

These two patches largely revert commits that added function call overhead
into slab and page allocation hotpaths and that cannot be currently
disabled even though related CONFIG_ options do exist.

A much more involved solution that can keep the callsites always existing
but hidden behind a static key if unused","["" is possible [1] and can be\npursued by anyone who believes it's necessary.  Meanwhile the fact the\nshould_failslab() error injection is already not functional on kernels\nbuilt with current gcc without anyone noticing [2]"", ' and lukewarm response\nto [1] suggests the need is not there.  I believe it will be more fair to\nhave the state after this series as a baseline for possible further\noptimisation', ' instead of the unconditional overhead.\n\nFor example a possible compromise for anyone who\'s fine with an empty\nfunction call overhead but not the full CONFIG_FAILSLAB /\nCONFIG_FAIL_PAGE_ALLOC overhead is to reuse patch 1 from [1] but insert a\nstatic key check only inside should_failslab() and\nshould_fail_alloc_page() before performing the more expensive checks.\n\n[1] https://lore.kernel.org/all/20240620-fault-injection-statickeys-v2-0-e23947d3d84b@suse.cz/#t\n[2] https://github.com/bpftrace/bpftrace/issues/3258\n\n\nThis patch (of 2):\n\nThis mostly reverts commit 4f6923fbb352 (""mm: make should_failslab always\navailable for fault injection"").  The commit made should_failslab() a\nnoinline function that\'s always called from the slab allocation hotpath', ""\neven if it's empty because CONFIG_SHOULD_FAILSLAB is not enabled"", ' and\nthere is no option to disable that call.  This is visible in profiles and\nthe function call overhead can be noticeable especially with cpu\nmitigations.\n\nMeanwhile the bpftrace program example in the commit silently does not\nwork without CONFIG_SHOULD_FAILSLAB anyway with a recent gcc', ' because the\nempty function gets a .constprop clone that is actually being called\n(uselessly) from the slab hotpath', "" while the error injection is hooked to\nthe original function that's not being called at all [1].\n\nThus put the whole should_failslab() function back behind\nCONFIG_SHOULD_FAILSLAB.  It's not a complete revert of 4f6923fbb352 - the\nint return type that returns -ENOMEM on failure is preserved"", ' as well\nALLOW_ERROR_INJECTION annotation.  The BTF_ID() record that was meanwhile\nadded is also guarded by CONFIG_SHOULD_FAILSLAB.\n\n[1] https://github.com/bpftrace/bpftrace/issues/3258\n\nLink: https://lkml.kernel.org/r/20240711-b4-fault-injection-reverts-v1-0-9e2651945d68@suse.cz\nLink: https://lkml.kernel.org/r/20240711-b4-fault-injection-reverts-v1-1-9e2651945d68@suse.cz\nSigned-off-by: Vlastimil Babka <vbabka@suse.cz>\nCc: Akinobu Mita <akinobu.mita@gmail.com>\nCc: Alexei Starovoitov <ast@kernel.org>\nCc: Andrii Nakryiko <andrii@kernel.org>\nCc: Christoph Lameter <cl@linux.com>\nCc: Daniel Borkmann <daniel@iogearbox.net>\nCc: David Rientjes <rientjes@google.com>\nCc: Eduard Zingerman <eddyz87@gmail.com>\nCc: Hao Luo <haoluo@google.com>\nCc: Hyeonggon Yoo <42.hyeyoo@gmail.com>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: John Fastabend <john.fastabend@gmail.com>\nCc: KP Singh <kpsingh@kernel.org>\nCc: Martin KaFai Lau <martin.lau@linux.dev>\nCc: Mateusz Guzik <mjguzik@gmail.com>\nCc: Roman Gushchin <roman.gushchin@linux.dev>\nCc: Song Liu <song@kernel.org>\nCc: Stanislav Fomichev <sdf@fomichev.me>\nCc: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\n', '']",Revert slab and page allocator fault injection function call overhead to improve performance by using static key solution.,"revert, allocator, static key",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
6e504d2c61244a01226c5100c835e44fb9b85ca8,6e504d2c61244a01226c5100c835e44fb9b85ca8,Linus Torvalds,torvalds@linux-foundation.org,1721262511,Linus Torvalds,torvalds@linux-foundation.org,1721262511,cc11be99475aa130e1081a4df2608e815fb9a6ef,221fd1e154ee533c529280bd3866570c086ec792 30b866413e7bdd507a79854b5931528d3f6f438f,"Merge tag 'for-linus-2024071601' of git://git.kernel.org/pub/scm/linux/kernel/git/hid/hid

Pull HID updates from Benjamin Tissoires:

 - rewrite of the HID-BPF internal implementation to use bpf struct_ops
   instead of a tracing endpoint (Benjamin Tissoires)

 - add two new HID-BPF hooks to be able to intercept userspace calls
   targeting a HID device and filtering them (Benjamin Tissoires)

 - add support for various new devices through HID-BPF filters (Benjamin
   Tissoires)

 - add support for the magic keyboard backlight (Orlando Chamberlain)

 - add the missing MODULE_DESCRIPTION() macros in HID drivers (Jeff
   Johnson)

 - use of kvzalloc in case memory gets too fragmented (Hailong Liu)

 - retrieve the device firmware node in the child HID device (Danny
   Kaehn)

 - some hid-uclogic improvements (José Expósito)

 - some more typos", trivial fixes,"[' kernel doctext and unused functions\n   cleanups\n\n* tag \'for-linus-2024071601\' of git://git.kernel.org/pub/scm/linux/kernel/git/hid/hid: (60 commits)\n  HID: hid-steam: Fix typo in goto label\n  HID: mcp2221: Remove unnecessary semicolon\n  HID: Fix spelling mistakes ""Kensigton"" -> ""Kensington""\n  HID: add more missing MODULE_DESCRIPTION() macros\n  HID: samples: fix the 2 struct_ops definitions\n  HID: fix for amples in for-6.11/bpf\n  HID: apple: Add support for magic keyboard backlight on T2 Macs\n  HID: bpf: Thrustmaster TCA Yoke Boeing joystick fix\n  HID: bpf: Add Huion Dial 2 bpf fixup\n  HID: bpf: Add support for the XP-PEN Deco Mini 4\n  HID: bpf: move the BIT() macro to hid_bpf_helpers.h\n  HID: bpf: add a driver for the Huion Inspiroy 2S (H641P)\n  HID: bpf: Add a HID report composition helper macros\n  HID: bpf: doc fixes for hid_hw_request() hooks\n  HID: bpf: doc fixes for hid_hw_request() hooks\n  HID: bpf: fix gcc warning and unify __u64 into u64\n  selftests/hid: ensure CKI can compile our new tests on old kernels\n  selftests/hid: add an infinite loop test for hid_bpf_try_input_report\n  selftests/hid: add another test for injecting an event from an event hook\n  HID: bpf: allow hid_device_event hooks to inject input reports on self\n  ...\n', '']",Merge HID updates including HID-BPF implementation changes and device support additions.,"HID-BPF, hooks, struct_ops",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['HID driver like programs']
6caf9efaa169faea10a369dd6b36806ae6842584,6caf9efaa169faea10a369dd6b36806ae6842584,Michal Luczaj,mhal@rbox.co,1720899701,Daniel Borkmann,daniel@iogearbox.net,1721249515,6f122634b50b53b7585557f080bd02946cb006b3,0befb349c4cdcc4e3c2f4aff81259a3a58c3b33e,"selftests/bpf: Test sockmap redirect for AF_UNIX MSG_OOB

Verify that out-of-band packets are silently dropped before they reach the
redirection logic.

The idea is to test with a 2 byte long send(). Should a MSG_OOB flag be in
use"," only the last byte will be treated as out-of-band. Test fails if
verd_mapfd indicates a wrong number of packets processed (e.g. if OOB
wasn't dropped at the source) or if it was possible to recv() MSG_OOB from
the mapped socket","[' or if any stale OOB data have been left reachable from\nthe unmapped socket.\n\nSigned-off-by: Michal Luczaj <mhal@rbox.co>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Jakub Sitnicki <jakub@cloudflare.com>\nReviewed-by: Jakub Sitnicki <jakub@cloudflare.com>\nLink: https://lore.kernel.org/bpf/20240713200218.2140950-5-mhal@rbox.co\n', '']",Add a test to verify MSG_OOB packet handling in sockmap redirection for AF_UNIX.,"sockmap, MSG_OOB, AF_UNIX",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
0befb349c4cdcc4e3c2f4aff81259a3a58c3b33e,0befb349c4cdcc4e3c2f4aff81259a3a58c3b33e,Michal Luczaj,mhal@rbox.co,1720899700,Daniel Borkmann,daniel@iogearbox.net,1721249510,73223992fce2ab03811538885eff6320e234a070,1b0ad43177c097d38b967b99c2b71d8be28b0223,"selftests/bpf: Parametrize AF_UNIX redir functions to accept send() flags

Extend pairs_redir_to_connected() and unix_inet_redir_to_connected() with a
send_flags parameter. Replace write() with send() allowing packets to be
sent as MSG_OOB.

Signed-off-by: Michal Luczaj <mhal@rbox.co>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Tested-by: Jakub Sitnicki <jakub@cloudflare.com>
Reviewed-by: Jakub Sitnicki <jakub@cloudflare.com>
Link: https://lore.kernel.org/bpf/20240713200218.2140950-4-mhal@rbox.co
",,"The commit parametrizes AF_UNIX redirection functions to accept send() flags, allowing packets to be sent as MSG_OOB.","AF_UNIX,send_flags,selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1b0ad43177c097d38b967b99c2b71d8be28b0223,1b0ad43177c097d38b967b99c2b71d8be28b0223,Michal Luczaj,mhal@rbox.co,1720899699,Daniel Borkmann,daniel@iogearbox.net,1721249505,d761807f5083c5ee76e7ade2d22fc81d146d8b0f,638f32604385fd23059985da8de918e9c18f0b98,"selftests/bpf: Support SOCK_STREAM in unix_inet_redir_to_connected()

Function ignores the AF_UNIX socket type argument"," SOCK_DGRAM is hardcoded.
Fix to respect the argument provided.

Fixes: 75e0e27db6cf (""selftest/bpf: Change udp to inet in some function names"")
Suggested-by: Jakub Sitnicki <jakub@cloudflare.com>
Signed-off-by: Michal Luczaj <mhal@rbox.co>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Tested-by: Jakub Sitnicki <jakub@cloudflare.com>
Reviewed-by: Jakub Sitnicki <jakub@cloudflare.com>
Link: https://lore.kernel.org/bpf/20240713200218.2140950-3-mhal@rbox.co
",[''],The commit modifies selftests to support both SOCK_STREAM and SOCK_DGRAM types in unix_inet_redir_to_connected().,"SOCK_STREAM, selftests, bpf",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
638f32604385fd23059985da8de918e9c18f0b98,638f32604385fd23059985da8de918e9c18f0b98,Michal Luczaj,mhal@rbox.co,1720899698,Daniel Borkmann,daniel@iogearbox.net,1721249340,0359b72764f0b588b15cf7f4d11bc0d89fb79ed1,3c870059e9f8897c032f4256f90c41ee822218a8,"af_unix: Disable MSG_OOB handling for sockets in sockmap/sockhash

AF_UNIX socket tracks the most recent OOB packet (in its receive queue)
with an `oob_skb` pointer. BPF redirecting does not account for that: when
an OOB packet is moved between sockets"," `oob_skb` is left outdated. This
results in a single skb that may be accessed from two different sockets.

Take the easy way out: silently drop MSG_OOB data targeting any socket that
is in a sockmap or a sockhash. Note that such silent drop is akin to the
fate of redirected skb's scm_fp_list (SCM_RIGHTS","[' SCM_CREDENTIALS).\n\nFor symmetry', ' forbid MSG_OOB in unix_bpf_recvmsg().\n\nFixes: 314001f0bf92 (""af_unix: Add OOB support"")\nSuggested-by: Kuniyuki Iwashima <kuniyu@amazon.com>\nSigned-off-by: Michal Luczaj <mhal@rbox.co>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Jakub Sitnicki <jakub@cloudflare.com>\nReviewed-by: Kuniyuki Iwashima <kuniyu@amazon.com>\nReviewed-by: Jakub Sitnicki <jakub@cloudflare.com>\nLink: https://lore.kernel.org/bpf/20240713200218.2140950-2-mhal@rbox.co\n', '']",The commit disables MSG_OOB handling for sockets in sockmap/sockhash to prevent outdated data issues.,"MSG_OOB, sockmap, sockhash",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,['socket like programs']
3c870059e9f8897c032f4256f90c41ee822218a8,3c870059e9f8897c032f4256f90c41ee822218a8,Donald Hunter,donald.hunter@gmail.com,1721223908,Daniel Borkmann,daniel@iogearbox.net,1721249158,47ea1aa6a40ff57e46f7ce300b2ae8bb545ae0cb,189f1a976e426011e6a5588f1d3ceedf71fe2965,"bpftool: Fix typo in usage help

The usage help for ""bpftool prog help"" contains a ° instead of the _
symbol for cgroup/sendmsg_unix. Fix the typo.

Fixes: 8b3cba987e6d (""bpftool: Add support for cgroup unix socket address hooks"")
Signed-off-by: Donald Hunter <donald.hunter@gmail.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Quentin Monnet <qmo@kernel.org>
Link: https://lore.kernel.org/bpf/20240717134508.77488-1-donald.hunter@gmail.com
",,Fix typo in bpftool usage help for cgroup/sendmsg_unix by replacing ° with _ symbol.,"bpftool, typo, cgroup",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
189f1a976e426011e6a5588f1d3ceedf71fe2965,189f1a976e426011e6a5588f1d3ceedf71fe2965,Andrii Nakryiko,andrii@kernel.org,1720824282,Daniel Borkmann,daniel@iogearbox.net,1721248967,80d4fa37a7984a61ed3911cf4e6043bc797b2c66,c638b130e83e4aa47031c0e51455ecc961dfdc3d,"libbpf: Fix no-args func prototype BTF dumping syntax

For all these years libbpf's BTF dumper has been emitting not strictly
valid syntax for function prototypes that have no input arguments.

Instead of `int (*blah)()` we should emit `int (*blah)(void)`.

This is not normally a problem"," but it manifests when we get kfuncs in
vmlinux.h that have no input arguments. Due to compiler internal
specifics","[' we get no BTF information for such kfuncs', ' if they are not\ndeclared with proper `(void)`.\n\nThe fix is trivial. We also need to adjust a few ancient tests that\nhappily assumed `()` is correct.\n\nFixes: 351131b51c7a (""libbpf: add btf_dump API for BTF-to-C conversion"")\nReported-by: Tejun Heo <tj@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Stanislav Fomichev <sdf@fomichev.me>\nLink: https://lore.kernel.org/bpf/20240712224442.282823-1-andrii@kernel.org\n', '']",Fixes BTF dumping syntax for no-args function prototypes in libbpf.,"BTF,idump,syntax",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c638b130e83e4aa47031c0e51455ecc961dfdc3d,c638b130e83e4aa47031c0e51455ecc961dfdc3d,Naveen N Rao,naveen@kernel.org,1720946064,Daniel Borkmann,daniel@iogearbox.net,1721237238,b7f7a41e935c6b888d92f9c3f4e528a1acf8f1e9,afcc8e1ef7bb5c14100ba3e6ccfd4baebc80242e,"MAINTAINERS: Update powerpc BPF JIT maintainers

Hari Bathini has been updating and maintaining the powerpc BPF JIT since
a while now. Christophe Leroy has been doing the same for 32-bit
powerpc. Add them as maintainers for the powerpc BPF JIT.

I am no longer actively looking into the powerpc BPF JIT. Change my role
to that of a reviewer so that I can help with the odd query.

Signed-off-by: Naveen N Rao <naveen@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Acked-by: Christophe Leroy <christophe.leroy@csgroup.eu>
Acked-by: Hari Bathini <hbathini@linux.ibm.com>
Link: https://lore.kernel.org/bpf/24fea21d9d4458973aadd6a02bb1bf558b8bd0b2.1720944897.git.naveen@kernel.org
",,The commit updates maintainers for the powerpc BPF JIT in the MAINTAINERS file.,"powerpc BPF JIT, maintainers, MAINTAINERS file",It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
afcc8e1ef7bb5c14100ba3e6ccfd4baebc80242e,afcc8e1ef7bb5c14100ba3e6ccfd4baebc80242e,Naveen N Rao,naveen@kernel.org,1720946063,Daniel Borkmann,daniel@iogearbox.net,1721237238,ba0f83a7d55ec71e46dd16ae07ccd0bfe1fb825b,e1ef78dce9b7b0fa7f9d88bb3554441d74d33b34,"MAINTAINERS: Update email address of Naveen

I have switched to using my @kernel.org id for my contributions. Update
MAINTAINERS and mailmap to reflect the same.

Signed-off-by: Naveen N Rao <naveen@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Link: https://lore.kernel.org/bpf/fb6ef126771c70538067709af69d960da3560ce7.1720944897.git.naveen@kernel.org
",,The commit updates the MAINTAINERS file with a new email address for Naveen N Rao.,email update MAINTAINERS,It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
e1ef78dce9b7b0fa7f9d88bb3554441d74d33b34,e1ef78dce9b7b0fa7f9d88bb3554441d74d33b34,Puranjay Mohan,puranjay@kernel.org,1721064807,Daniel Borkmann,daniel@iogearbox.net,1721236964,30d09e5eee781120345ae48d102d4980262b20d8,0e03c643dc9389e61fa484562dae58c8d6e96d63,"selftests/bpf: fexit_sleep: Fix stack allocation for arm64

On ARM64 the stack pointer should be aligned at a 16 byte boundary or
the SPAlignmentFault can occur. The fexit_sleep selftest allocates the
stack for the child process as a character array"," this is not guaranteed
to be aligned at 16 bytes.

Because of the SPAlignmentFault","[' the child process is killed before it\ncan do the nanosleep call and hence fentry_cnt remains as 0. This causes\nthe main thread to hang on the following line:\n\nwhile (READ_ONCE(fexit_skel->bss->fentry_cnt) != 2);\n\nFix this by allocating the stack using mmap() as described in the\nexample in the man page of clone().\n\nRemove the fexit_sleep test from the DENYLIST of arm64.\n\nFixes: eddbe8e65214 (""selftest/bpf: Add a test to check trampoline freeing logic."")\nSigned-off-by: Puranjay Mohan <puranjay@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240715173327.8657-1-puranjay@kernel.org\n', '']",Fixes stack alignment issue in fexit_sleep selftest on ARM64 to prevent SPAlignmentFault.,"fexit_sleep, ARM64, stack alignment",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tracepoints like programs']
51835949dda3783d4639cfa74ce13a3c9829de00,51835949dda3783d4639cfa74ce13a3c9829de00,Linus Torvalds,torvalds@linux-foundation.org,1721183314,Linus Torvalds,torvalds@linux-foundation.org,1721183314,2b593de5eba6ecc73f7c58fc65fdaffae45c7323,0434dbe32053d07d658165be681505120c6b1abc 77ae5e5b00720372af2860efdc4bc652ac682696,"Merge tag 'net-next-6.11' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net-next

Pull networking updates from Jakub Kicinski:
 ""Not much excitement - a handful of large patchsets (devmem among them)
  did not make it in time.

  Core & protocols:

   - Use local_lock in addition to local_bh_disable() to protect per-CPU
     resources in networking"," a step closer for local_bh_disable() not
     to act as a big lock on PREEMPT_RT

   - Use flex array for netdevice priv area","["" ensure its cache alignment\n\n   - Add a sysctl knob to allow user to specify a default rto_min at\n     socket init time. Bit of a big hammer but multiple companies were\n     independently carrying such patch downstream so clearly it's useful\n\n   - Support scheduling transmission of packets based on CLOCK_TAI\n\n   - Un-pin TCP TIMEWAIT timer to avoid it firing on CPUs later cordoned\n     off using cpusets\n\n   - Support multiple L2TPv3 UDP tunnels using the same 5-tuple address\n\n   - Allow configuration of multipath hash seed"", ' to both allow\n     synchronizing hashing of two routers', ' and preventing partial\n     accidental sync\n\n   - Improve TCP compliance with RFC 9293 for simultaneous connect()\n\n   - Support sending NAT keepalives in IPsec ESP in UDP states.\n     Userspace IKE daemon had to do this before', ' but the kernel can\n     better keep track of it\n\n   - Support sending supervision HSR frames with MAC addresses stored in\n     ProxyNodeTable when RedBox (i.e. HSR-SAN) is enabled\n\n   - Introduce IPPROTO_SMC for selecting SMC when socket is created\n\n   - Allow UDP GSO transmit from devices with no checksum offload\n\n   - openvswitch: add packet sampling via psample', ' separating the\n     sampled traffic from ""upcall"" packets sent to user space for\n     forwarding\n\n   - nf_tables: shrink memory consumption for transaction objects\n\n  Things we sprinkled into general kernel code:\n\n   - Power Sequencing subsystem (used by Qualcomm Bluetooth driver for\n     QCA6390)           [ Already merged separately - Linus ]\n\n   - Add IRQ information in sysfs for auxiliary bus\n\n   - Introduce guard definition for local_lock\n\n   - Add aligned flavor of __cacheline_group_{begin', ' end}() markings for\n     grouping fields in structures\n\n  BPF:\n\n   - Notify user space (via epoll) when a struct_ops object is getting\n     detached/unregistered\n\n   - Add new kfuncs for a generic', ' open-coded bits iterator\n\n   - Enable BPF programs to declare arrays of kptr', ' bpf_rb_root', ' and\n     bpf_list_head\n\n   - Support resilient split BTF which cuts down on duplication and\n     makes BTF as compact as possible WRT BTF from modules\n\n   - Add support for dumping kfunc prototypes from BTF which enables\n     both detecting as well as dumping compilable prototypes for kfuncs\n\n   - riscv64 BPF JIT improvements in particular to add 12-argument\n     support for BPF trampolines and to utilize bpf_prog_pack for the\n     latter\n\n   - Add the capability to offload the netfilter flowtable in XDP layer\n     through kfuncs\n\n  Driver API:\n\n   - Allow users to configure IRQ tresholds between which automatic IRQ\n     moderation can choose\n\n   - Expand Power Sourcing (PoE) status with power', ' class and failure\n     reason. Support setting power limits\n\n   - Track additional RSS contexts in the core', "" make sure configuration\n     changes don't break them\n\n   - Support IPsec crypto offload for IPv6 ESP and IPv4 UDP-encapsulated\n     ESP data paths\n\n   - Support updating firmware on SFP modules\n\n  Tests and tooling:\n\n   - mptcp: use net/lib.sh to manage netns\n\n   - TCP-AO and TCP-MD5: replace debug prints used by tests with\n     tracepoints\n\n   - openvswitch: make test self-contained (don't depend on OvS CLI\n     tools)\n\n  Drivers:\n\n   - Ethernet high-speed NICs:\n      - Broadcom (bnxt):\n         - increase the max total outstanding PTP TX packets to 4\n         - add timestamping statistics support\n         - implement netdev_queue_mgmt_ops\n         - support new RSS context API\n      - Intel (100G"", ' ice', ' idpf):\n         - implement FEC statistics and dumping signal quality indicators\n         - support E825C products (with 56Gbps PHYs)\n      - nVidia/Mellanox:\n         - support HW-GRO\n         - mlx4/mlx5: support per-queue statistics via netlink\n         - obey the max number of EQs setting in sub-functions\n      - AMD/Solarflare:\n         - support new RSS context API\n      - AMD/Pensando:\n         - ionic: rework fix for doorbell miss to lower overhead and\n           skip it on new HW\n      - Wangxun:\n         - txgbe: support Flow Director perfect filters\n\n   - Ethernet NICs consumer', "" embedded and virtual:\n      - Add driver for Tehuti Networks TN40xx chips\n      - Add driver for Meta's internal NIC chips\n      - Add driver for Ethernet MAC on Airoha EN7581 SoCs\n      - Add driver for Renesas Ethernet-TSN devices\n      - Google cloud vNIC:\n         - flow steering support\n      - Microsoft vNIC:\n         - support page sizes other than 4KB on ARM64\n      - vmware vNIC:\n         - support latency measurement (update to version 9)\n      - VirtIO net:\n         - support for Byte Queue Limits\n         - support configuring thresholds for automatic IRQ moderation\n         - support for AF_XDP Rx zero-copy\n      - Synopsys (stmmac):\n         - support for STM32MP13 SoC\n         - let platforms select the right PCS implementation\n      - TI:\n         - icssg-prueth: add multicast filtering support\n         - icssg-prueth: enable PTP timestamping and PPS\n      - Renesas:\n         - ravb: improve Rx performance 30-400% by using page pool"", ""\n           theaded NAPI and timer-based IRQ coalescing\n         - ravb: add MII support for R-Car V4M\n      - Cadence (macb):\n         - macb: add ARP support to Wake-On-LAN\n      - Cortina:\n         - use phylib for RX and TX pause configuration\n\n   - Ethernet switches:\n      - nVidia/Mellanox:\n         - support configuration of multipath hash seed\n         - report more accurate max MTU\n         - use page_pool to improve Rx performance\n      - MediaTek:\n         - mt7530: add support for bridge port isolation\n      - Qualcomm:\n         - qca8k: add support for bridge port isolation\n      - Microchip:\n         - lan9371/2: add 100BaseTX PHY support\n      - NXP:\n         - vsc73xx: implement VLAN operations\n\n   - Ethernet PHYs:\n      - aquantia: enable support for aqr115c\n      - aquantia: add support for PHY LEDs\n      - realtek: add support for rtl8224 2.5Gbps PHY\n      - xpcs: add memory-mapped device support\n      - add BroadR-Reach link mode and support in Broadcom's PHY driver\n\n   - CAN:\n      - add document for ISO 15765-2 protocol support\n      - mcp251xfd: workaround for erratum DS80000789E"", ' use timestamps to\n        catch when device returns incorrect FIFO status\n\n   - WiFi:\n      - mac80211/cfg80211:\n         - parse Transmit Power Envelope (TPE) data in mac80211 instead\n           of in drivers\n         - improvements for 6 GHz regulatory flexibility\n         - multi-link improvements\n         - support multiple radios per wiphy\n         - remove DEAUTH_NEED_MGD_TX_PREP flag\n      - Intel (iwlwifi):\n         - bump FW API to 91 for BZ/SC devices\n         - report 64-bit radiotap timestamp\n         - enable P2P low latency by default\n         - handle Transmit Power Envelope (TPE) advertised by AP\n         - remove support for older FW for new devices\n         - fast resume (keeping the device configured)\n         - mvm: re-enable Multi-Link Operation (MLO)\n         - aggregation (A-MSDU) optimizations\n      - MediaTek (mt76):\n         - mt7925 Multi-Link Operation (MLO) support\n      - Qualcomm (ath10k):\n         - LED support for various chipsets\n      - Qualcomm (ath12k):\n         - remove unsupported Tx monitor handling\n         - support channel 2 in 6 GHz band\n         - support Spatial Multiplexing Power Save (SMPS) in 6 GHz band\n         - supprt multiple BSSID (MBSSID) and Enhanced Multi-BSSID\n           Advertisements (EMA)\n         - support dynamic VLAN\n         - add panic handler for resetting the firmware state\n         - DebugFS support for datapath statistics\n         - WCN7850: support for Wake on WLAN\n      - Microchip (wilc1000):\n         - read MAC address during probe to make it visible to user space\n         - suspend/resume improvements\n      - TI (wl18xx):\n         - support newer firmware versions\n      - RealTek (rtw89):\n         - preparation for RTL8852BE-VT support\n         - Wake on WLAN support for WiFi 6 chips\n         - 36-bit PCI DMA support\n      - RealTek (rtlwifi):\n         - RTL8192DU support\n      - Broadcom (brcmfmac):\n         - Management Frame Protection support (to enable WPA3)\n\n   - Bluetooth:\n      - qualcomm: use the power sequencer for QCA6390\n      - btusb: mediatek: add ISO data transmission functions\n      - hci_bcm4377: add BCM4388 support\n      - btintel: add support for BlazarU core\n      - btintel: add support for Whale Peak2\n      - btnxpuart: add support for AW693 A1 chipset\n      - btnxpuart: add support for IW615 chipset\n      - btusb: add Realtek RTL8852BE support ID 0x13d3:0x3591""\n\n* tag \'net-next-6.11\' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net-next: (1589 commits)\n  eth: fbnic: Fix spelling mistake ""tiggerring"" -> ""triggering""\n  tcp: Replace strncpy() with strscpy()\n  wifi: ath12k: fix build vs old compiler\n  tcp: Don\'t access uninit tcp_rsk(req)->ao_keyid in tcp_create_openreq_child().\n  eth: fbnic: Write the TCAM tables used for RSS control and Rx to host\n  eth: fbnic: Add L2 address programming\n  eth: fbnic: Add basic Rx handling\n  eth: fbnic: Add basic Tx handling\n  eth: fbnic: Add link detection\n  eth: fbnic: Add initial messaging to notify FW of our presence\n  eth: fbnic: Implement Rx queue alloc/start/stop/free\n  eth: fbnic: Implement Tx queue alloc/start/stop/free\n  eth: fbnic: Allocate a netdevice and napi vectors with queues\n  eth: fbnic: Add FW communication mechanism\n  eth: fbnic: Add message parsing for FW messages\n  eth: fbnic: Add register init to set PCIe/Ethernet device config\n  eth: fbnic: Allocate core device specific structures and devlink interface\n  eth: fbnic: Add scaffolding for Meta\'s NIC driver\n  PCI: Add Meta Platforms vendor ID\n  net/sched: cls_flower: propagate tca[TCA_OPTIONS] to NL_REQ_ATTR_CHECK\n  ...\n', '']","Merge networking updates, including local_lock improvements for per-CPU resources and flex array usage for netdevice.","networking updates, local_lock, flex array",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
d80f2996b8502779c39221a9e7c9ea7e361c0ae4,d80f2996b8502779c39221a9e7c9ea7e361c0ae4,Linus Torvalds,torvalds@linux-foundation.org,1721156943,Linus Torvalds,torvalds@linux-foundation.org,1721156943,339db3f28a684bb7c674d32d62fc2c0f14f935f4,a5db8e4544a4dc7143f30a1438686a4d5fa6d775 1a7b7326d587c9a5e8ff067e70d6aaf0333f4bb3,"Merge tag 'asm-generic-6.11' of git://git.kernel.org/pub/scm/linux/kernel/git/arnd/asm-generic

Pull asm-generic updates from Arnd Bergmann:
 ""Most of this is part of my ongoing work to clean up the system call
  tables. In this bit"," all of the newer architectures are converted to
  use the machine readable syscall.tbl format instead in place of
  complex macros in include/uapi/asm-generic/unistd.h.

  This follows an earlier series that fixed various API mismatches and
  in turn is used as the base for planned simplifications.

  The other two patches are dead code removal and a warning fix""

* tag 'asm-generic-6.11' of git://git.kernel.org/pub/scm/linux/kernel/git/arnd/asm-generic:
  vmlinux.lds.h: catch .bss..L* sections into BSS"")
  fixmap: Remove unused set_fixmap_offset_io()
  riscv: convert to generic syscall table
  openrisc: convert to generic syscall table
  nios2: convert to generic syscall table
  loongarch: convert to generic syscall table
  hexagon: use new system call table
  csky: convert to generic syscall table
  arm64: rework compat syscall macros
  arm64: generate 64-bit syscall.tbl
  arm64: convert unistd_32.h to syscall.tbl format
  arc: convert to generic syscall table
  clone3: drop __ARCH_WANT_SYS_CLONE3 macro
  kbuild: add syscall table generation to scripts/Makefile.asm-headers
  kbuild: verify asm-generic header list
  loongarch: avoid generating extra header files
  um: don't generate asm/bpf_perf_event.h
  csky: drop asm/gpio.h wrapper
  syscalls: add generic scripts/syscall.tbl
",[''],Merge asm-generic updates for syscall table conversion and cleanup.,"asm-generic, syscall, cleanup",It's a build system or CI/CD change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
30b866413e7bdd507a79854b5931528d3f6f438f,30b866413e7bdd507a79854b5931528d3f6f438f,Benjamin Tissoires,bentiss@kernel.org,1721125646,Benjamin Tissoires,bentiss@kernel.org,1721125646,59013deb24680a3c0d34fb5163916c442c7b28b1,e518f368303d35017fe79f21f0fec7860ef71d0b a67a1deb11d9a692366100d9ba9fb3aeb0c7707b,"Merge branch 'for-6.11/bpf' into for-linus

- Rewrite of HID-BPF internal implementation to use bpf struct_ops
  instead of tracing (Benjamin Tissoires)
- Add new HID-BPF hooks to be able to intercept userspace calls
  targetting a HID device and filtering them (Benjamin Tissoires)
- Add support for various new devices through HID-BPF filters (Benjamin
  Tissoires)
",,Refactor HID-BPF implementation to use struct_ops and add hooks for intercepting userspace calls and supporting new devices.,"HID-BPF, struct_ops, hooks",It's a new feature.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",The helper and kfuncs,['HID driver like programs']
c49379dcda748adb8ba84d7a8eb3b02d4f1ebfcf,c49379dcda748adb8ba84d7a8eb3b02d4f1ebfcf,Jakub Kicinski,kuba@kernel.org,1721051719,Jakub Kicinski,kuba@kernel.org,1721051720,d10707048f34caa3105018b973e4dae679877ade,a8ea8d531d1edf7b29e559713fe1aaab3530d7d9 259a7061c2f14bbf5845598f69ac63cdb77d6346,"Merge branch 'net-dsa-vsc73xx-implement-vlan-operations'

Pawel Dembicki says:

====================
net: dsa: vsc73xx: Implement VLAN operations

This patch series is a result of splitting a larger patch series [0]","
where some parts was merged before.

The first patch implements port state configuration","[' which is required\nfor bridge functionality. STP frames are not forwarded at this moment.\nBPDU frames are only forwarded from/to the PI/SI interface.\nFor more information', ' see chapter 2.7.1 (CPU Forwarding) in the\ndatasheet.\n\nPatches 2', ' 7-9 and 11 provide a basic implementation of tag_8021q\nfunctionality with QinQ support', ' without VLAN filtering in\nthe bridge and simple VLAN awareness in VLAN filtering mode.\n\nPatches 3-6 came from Vladimir Oltean. They prepare for making\ntag8021q more common. VSC73XX uses very similar tag recognition', ""\nand some code from tag_sja1105 could be moved to tag_8021q for\ncommon use.\n\nPatch 10 is preparation for use tag_8021q bridge functions as generic\nimplementation of the 'ds->ops->port_bridge_*()'.\n\nPatch 12 is required to avoid problem with learning on standalone ports.\n\n[0] https://patchwork.kernel.org/project/netdevbpf/list/?series=841034&state=%2A&archive=both\n====================\n\nLink: https://patch.msgid.link/20240713211620.1125910-1-paweldembicki@gmail.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n"", '']",Merges branch 'net-dsa-vsc73xx-implement-vlan-operations' to add VLAN operations to VSC73XX.,"VLAN,DSA,VSC73XX",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
3e301b431b91e4b973dbc520e90e220acb5b91f5,3e301b431b91e4b973dbc520e90e220acb5b91f5,Jiri Olsa,jolsa@kernel.org,1720792348,Masami Hiramatsu (Google),mhiramat@kernel.org,1721022590,ea8407d298681c4e584e49031605ef35db224f0f,63ded110979bdd8741542ec66fb9e2d2074aed8c,"selftests/bpf: Change uretprobe syscall number in uprobe_syscall test

Fixing the syscall number value.

Link: https://lore.kernel.org/all/20240712135228.1619332-3-jolsa@kernel.org/

Fixes: 9e7f74e64ae5 (""selftests/bpf: Add uretprobe syscall call from user space test"")
Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
",,The commit updates the syscall number in the uprobe_syscall BPF self-test.,"syscall, uprobe, self-test",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
41d4a174201e62fc95562dc8e53097baf8568f24,41d4a174201e62fc95562dc8e53097baf8568f24,Xuan Zhuo,xuanzhuo@linux.alibaba.com,1720437928,Jakub Kicinski,kuba@kernel.org,1721014357,870f6d63337b2b36a3b663e7236866bee58948c6,e6c29506b2ec94e634819c03445ffe9eb350caed,"virtio_net: replace VIRTIO_XDP_HEADROOM by XDP_PACKET_HEADROOM

virtio net has VIRTIO_XDP_HEADROOM that is equal to
XDP_PACKET_HEADROOM to calculate the headroom for xdp.

But here we should use the macro XDP_PACKET_HEADROOM from bpf.h to
calculate the headroom for xdp. So here we remove the
VIRTIO_XDP_HEADROOM"," and use the XDP_PACKET_HEADROOM to replace it.

Signed-off-by: Xuan Zhuo <xuanzhuo@linux.alibaba.com>
Acked-by: Jason Wang <jasowang@redhat.com>
Acked-by: Michael S. Tsirkin <mst@redhat.com>
Link: https://patch.msgid.link/20240708112537.96291-2-xuanzhuo@linux.alibaba.com
Signed-off-by: Jakub Kicinski <kuba@kernel.org>
",[''],Replace VIRTIO_XDP_HEADROOM with XDP_PACKET_HEADROOM to calculate XDP headroom in virtio_net.,"virtio_net,XDP headroom,macro replacement",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['xdp like programs']
22767eecd62f7bb5c83541c291297cf24326a997,22767eecd62f7bb5c83541c291297cf24326a997,Jakub Kicinski,kuba@kernel.org,1720910658,Jakub Kicinski,kuba@kernel.org,1720910658,1a6ece592e84f79710f4fa50e8b0fe89116a784a,f7023b3d697c6a7dfe2d9c70e0d8c2c580ccbd76 4b66be76a6fbe16918a01439bb9023da154d7694,"Merge branch 'mlx5-misc-2023-07-08-sf-max-eq'

Saeed Mahameed says:

====================
mlx5 misc 2023-07-08 (sf max eq)

Link: https://patchwork.kernel.org/project/netdevbpf/patch/20240708080025.1593555-2-tariqt@nvidia.com/
====================

Link: https://patch.msgid.link/20240712003310.355106-1-saeed@kernel.org
Signed-off-by: Jakub Kicinski <kuba@kernel.org>
",,This commit merges the 'mlx5 misc 2023-07-08 sf max eq' branch into the main codebase.,"mlx5, merge, kernel",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
23e89e8ee7be73e21200947885a6d3a109a2c58d,23e89e8ee7be73e21200947885a6d3a109a2c58d,Kuniyuki Iwashima,kuniyu@amazon.com,1720631565,Jakub Kicinski,kuba@kernel.org,1720909189,0d83add45f01a57bad4865f978d3d88796230d97,42ffe242860c401c34c62aa369c2add341a6eece,"tcp: Don't drop SYN+ACK for simultaneous connect().

RFC 9293 states that in the case of simultaneous connect()"," the connection
gets established when SYN+ACK is received. [0]

      TCP Peer A                                       TCP Peer B

  1.  CLOSED                                           CLOSED
  2.  SYN-SENT     --> <SEQ=100><CTL=SYN>              ...
  3.  SYN-RECEIVED <-- <SEQ=300><CTL=SYN>              <-- SYN-SENT
  4.               ... <SEQ=100><CTL=SYN>              --> SYN-RECEIVED
  5.  SYN-RECEIVED --> <SEQ=100><ACK=301><CTL=SYN","['ACK> ...\n  6.  ESTABLISHED  <-- <SEQ=300><ACK=101><CTL=SYN', 'ACK> <-- SYN-RECEIVED\n  7.               ... <SEQ=100><ACK=301><CTL=SYN', 'ACK> --> ESTABLISHED\n\nHowever', ' since commit 0c24604b68fc (""tcp: implement RFC 5961 4.2"")', ' such a\nSYN+ACK is dropped in tcp_validate_incoming() and responded with Challenge\nACK.\n\nFor example', ' the write() syscall in the following packetdrill script fails\nwith -EAGAIN', ' and wrong SNMP stats get incremented.\n\n   0 socket(...', ' SOCK_STREAM|SOCK_NONBLOCK', ' IPPROTO_TCP) = 3\n  +0 connect(3', ' ...', ' ...) = -1 EINPROGRESS (Operation now in progress)\n\n  +0 > S  0:0(0) <mss 1460', 'sackOK', 'TS val 1000 ecr 0', 'nop', 'wscale 8>\n  +0 < S  0:0(0) win 1000 <mss 1000>\n  +0 > S. 0:0(0) ack 1 <mss 1460', 'sackOK', 'TS val 3308134035 ecr 0', 'nop', 'wscale 8>\n  +0 < S. 0:0(0) ack 1 win 1000\n\n  +0 write(3', ' ...', "" 100) = 100\n  +0 > P. 1:101(100) ack 1\n\n  --\n\n  # packetdrill cross-synack.pkt\n  cross-synack.pkt:13: runtime error in write call: Expected result 100 but got -1 with errno 11 (Resource temporarily unavailable)\n  # nstat\n  ...\n  TcpExtTCPChallengeACK           1                  0.0\n  TcpExtTCPSYNChallenge           1                  0.0\n\nThe problem is that bpf_skops_established() is triggered by the Challenge\nACK instead of SYN+ACK.  This causes the bpf prog to miss the chance to\ncheck if the peer supports a TCP option that is expected to be exchanged\nin SYN and SYN+ACK.\n\nLet's accept a bare SYN+ACK for active-open TCP_SYN_RECV sockets to avoid\nsuch a situation.\n\nNote that tcp_ack_snd_check() in tcp_rcv_state_process() is skipped not to\nsend an unnecessary ACK"", ' but this could be a bit risky for net.git', ' so this\ntargets for net-next.\n\nLink: https://www.rfc-editor.org/rfc/rfc9293.html#section-3.5-7 [0]\nSigned-off-by: Kuniyuki Iwashima <kuniyu@amazon.com>\nReviewed-by: Eric Dumazet <edumazet@google.com>\nLink: https://patch.msgid.link/20240710171246.87533-2-kuniyu@amazon.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Fix handling of SYN+ACK packets for simultaneous TCP connections to comply with RFC 9293.,"TCP,SYN+ACK,connect",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
26f453176a66bb36bf9e3a8abad808b144a94f6a,26f453176a66bb36bf9e3a8abad808b144a94f6a,Jakub Kicinski,kuba@kernel.org,1720848353,Jakub Kicinski,kuba@kernel.org,1720848354,e2e0ca6e5cd21466433600d5b8997fb628158b26,e5abd12f3df13e92e2fb3c02fe825aa6c57f8306 e435b043d89a267bd6eb3d5650d2319805d7924a,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next

Daniel Borkmann says:

====================
pull-request: bpf-next 2024-07-12

We've added 23 non-merge commits during the last 3 day(s) which contain
a total of 18 files changed", 234 insertions(+),"[' 243 deletions(-).\n\nThe main changes are:\n\n1) Improve BPF verifier by utilizing overflow.h helpers to check\n   for overflows', ' from Shung-Hsi Yu.\n\n2) Fix NULL pointer dereference in resolve_prog_type() for BPF_PROG_TYPE_EXT\n   when attr->attach_prog_fd was not specified', ' from Tengda Wu.\n\n3) Fix arm64 BPF JIT when generating code for BPF trampolines with\n   BPF_TRAMP_F_CALL_ORIG which corrupted upper address bits', '\n   from Puranjay Mohan.\n\n4) Remove test_run callback from lwt_seg6local_prog_ops which never worked\n   in the first place and caused syzbot reports', '\n   from Sebastian Andrzej Siewior.\n\n5) Relax BPF verifier to accept non-zero offset on KF_TRUSTED_ARGS/\n   /KF_RCU-typed BPF kfuncs', "" from Matt Bobrowski.\n\n6) Fix a long standing bug in libbpf with regards to handling of BPF\n   skeleton's forward and backward compatibility"", ' from Andrii Nakryiko.\n\n7) Annotate btf_{seq', 'snprintf}_show functions with __printf', '\n   from Alan Maguire.\n\n8) BPF selftest improvements to reuse common network helpers in sk_lookup\n   test and dropping the open-coded inetaddr_len() and make_socket() ones', '\n   from Geliang Tang.\n\n* tag \'for-netdev\' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next: (23 commits)\n  selftests/bpf: Test for null-pointer-deref bugfix in resolve_prog_type()\n  bpf: Fix null pointer dereference in resolve_prog_type() for BPF_PROG_TYPE_EXT\n  selftests/bpf: DENYLIST.aarch64: Skip fexit_sleep again\n  bpf: use check_sub_overflow() to check for subtraction overflows\n  bpf: use check_add_overflow() to check for addition overflows\n  bpf: fix overflow check in adjust_jmp_off()\n  bpf: Eliminate remaining ""make W=1"" warnings in kernel/bpf/btf.o\n  bpf: annotate BTF show functions with __printf\n  bpf', ' arm64: Fix trampoline for BPF_TRAMP_F_CALL_ORIG\n  selftests/bpf: Close obj in error path in xdp_adjust_tail\n  selftests/bpf: Null checks for links in bpf_tcp_ca\n  selftests/bpf: Use connect_fd_to_fd in sk_lookup\n  selftests/bpf: Use start_server_addr in sk_lookup\n  selftests/bpf: Use start_server_str in sk_lookup\n  selftests/bpf: Close fd in error path in drop_on_reuseport\n  selftests/bpf: Add ASSERT_OK_FD macro\n  selftests/bpf: Add backlog for network_helper_opts\n  selftests/bpf: fix compilation failure when CONFIG_NF_FLOW_TABLE=m\n  bpf: Remove tst_run from lwt_seg6local_prog_ops.\n  bpf: relax zero fixed offset constraint on KF_TRUSTED_ARGS/KF_RCU\n  ...\n====================\n\nLink: https://patch.msgid.link/20240712212448.5378-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']","This commit merges changes from the 'for-netdev' branch, including 23 non-merge commits affecting 18 files.","merge, netdev, bpf-next",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4f5d4a1ba7a1a23173e356186f3f8b7c27d2e948,4f5d4a1ba7a1a23173e356186f3f8b7c27d2e948,Chen Ni,nichen@iscas.ac.cn,1720496603,Andrew Morton,akpm@linux-foundation.org,1720827592,7baa019293b6d06f115830a073a7350a724bfc4d,73db3abdca58c8a014ec4c88cf5ef925cbf63669,"test_bpf: convert comma to semicolon

Replace commas between expression statements with semicolons.

Link: https://lkml.kernel.org/r/20240709034323.586185-1-nichen@iscas.ac.cn
Signed-off-by: Chen Ni <nichen@iscas.ac.cn>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Andrii Nakryiko <andrii@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Eduard Zingerman <eddyz87@gmail.com>
Cc: Hao Luo <haoluo@google.com>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: John Fastabend <john.fastabend@gmail.com>
Cc: KP Singh <kpsingh@kernel.org>
Cc: Martin KaFai Lau <martin.lau@linux.dev>
Cc: Song Liu <song@kernel.org>
Cc: Stanislav Fomichev <sdf@fomichev.me>
Cc: Yonghong Song <yonghong.song@linux.dev>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
",,Converted commas to semicolons in test_bpf expressions for correct syntax.,"convert,comma,semicolon",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
acd4b2ecf3bb24a781aad7f703243fa00eb7efbb,acd4b2ecf3bb24a781aad7f703243fa00eb7efbb,Andrii Nakryiko,andrii@kernel.org,1719508133,Andrew Morton,akpm@linux-foundation.org,1720824731,fbdc974d9a9e6f714682587af0ca6eed44422c90,8d42e2a91dcf86b34461cd7f709797805afa9f43,"fs/procfs: extract logic for getting VMA name constituents

Patch series ""ioctl()-based API to query VMAs from /proc/<pid>/maps"""," v6.

Implement binary ioctl()-based interface to /proc/<pid>/maps file to allow
applications to query VMA information more efficiently than reading *all*
VMAs nonselectively through text-based interface of /proc/<pid>/maps file.

Patch #2 goes into a lot of details and background on some common patterns
of using /proc/<pid>/maps in the area of performance profiling and
subsequent symbolization of captured stack traces.  As mentioned in that
patch","[' patterns of VMA querying can differ depending on specific use case', '\nbut can generally be grouped into two main categories: the need to query a\nsmall subset of VMAs covering a given batch of addresses', ' or\nreading/storing/caching all (typically', ' executable) VMAs upfront for later\nprocessing.\n\nThe new PROCMAP_QUERY ioctl() API added in this patch set was motivated by\nthe former pattern of usage.  Earlier revisions had a patch adding a tool\nthat faithfully reproduces an efficient VMA matching pass of a symbolizer', '\ncollecting a subset of covering VMAs for a given set of addresses as\nefficiently as possible.  This tool served both as a testing ground', ' as\nwell as a benchmarking tool.  It implements everything both for currently\nexisting text-based /proc/<pid>/maps interface', ' as well as for newly-added\nPROCMAP_QUERY ioctl().  This revision dropped the tool from the patch set\nand', ' once the API lands upstream', ' this tool might be added separately on\nGithub as an example.\n\nBased on discussion on earlier revisions of this patch set', ' it turned out\nthat this ioctl() API is competitive with highly-optimized text-based\npre-processing pattern that perf tool is using.  Based on perf discussion', ""\nthis revision adds more flexibility in specifying a subset of VMAs that\nare of interest.  Now it's possible to specify desired permissions of VMAs\n(e.g."", ' request only executable ones) and/or restrict to only a subset of\nVMAs that have file backing.  This further improves the efficiency when\nusing this new API thanks to more selective (executable VMAs only)\nquerying.\n\nIn addition to a custom benchmarking tool', ' and experimental perf\nintegration (available at [0])', ' Daniel Mueller has since also implemented\nan experimental integration into blazesym (see [1])', ' a library used for\nstack trace symbolization by our server fleet-wide profiler and another\non-device profiler agent that runs on weaker ARM devices.  The latter\nARM-based device profiler is especially sensitive to performance', ' and so\nwe benchmarked and compared text-based /proc/<pid>/maps solution to the\nequivalent one using PROCMAP_QUERY ioctl().\n\nResults are very encouraging', ' giving us 5x improvement for end-to-end\nso-called ""address normalization"" pass', ' which is the part of the\nsymbolization process that happens locally on ARM device', "" before being\nsent out for further heavier-weight processing on more powerful remote\nserver.  Note that this is not an artificial microbenchmark.  It's a full\nend-to-end API call being measured with real-world data on real-world\ndevice.\n\n  TEXT-BASED\n  ==========\n  Benchmarking main/normalize_process_no_build_ids_uncached_maps\n  main/normalize_process_no_build_ids_uncached_maps\n\t  time:   [49.777 µs 49.982 µs 50.250 µs]\n\n  IOCTL-BASED\n  ===========\n  Benchmarking main/normalize_process_no_build_ids_uncached_maps\n  main/normalize_process_no_build_ids_uncached_maps\n\t  time:   [10.328 µs 10.391 µs 10.457 µs]\n\t  change: [−79.453% −79.304% −79.166%] (p = 0.00 < 0.02)\n\t  Performance has improved.\n\nYou can see above that we see the drop from 50µs down to 10µs for\nexactly the same amount of work"", ' with the same data and target process.\n\nWith the aforementioned custom tool', ' we see about ~40x improvement (it\nmight vary a bit', "" depending on a specific captured set of addresses).  And\neven for perf-based benchmark it's on par or slightly ahead when using\npermission-based filtering (fetching only executable VMAs).\n\nEarlier revisions attempted to use per-VMA locking"", ' if kernel was compiled\nwith CONFIG_PER_VMA_LOCK=y', ' but it turned out that anon_vma_name() is not\nyet compatible with per-VMA locking and assumes mmap_lock to be taken', '\nwhich makes the use of per-VMA locking for this API premature.  It was\nagreed ([2]) to continue for now with just mmap_lock', ' but the code\nstructure is such that it should be easy to add per-VMA locking support\nonce all the pieces are ready.\n\nOne thing that did not change was basing this new API as an ioctl()\ncommand on /proc/<pid>/maps file.  An ioctl-based API on top of pidfd was\nconsidered', ' but has its own downsides.  Implementing ioctl() directly on\npidfd will cause access permission checks on every single ioctl()', ' which\nleads to performance concerns and potential spam of capable() audit\nmessages.  It also prevents a nice pattern', ' possible with\n/proc/<pid>/maps', ' in which application opens /proc/self/maps FD (requiring\nno additional capabilities) and passed this FD to profiling agent for\nquerying.  To achieve similar pattern', ' a new file would have to be created\nfrom pidf just for VMA querying', ' which is considered to be inferior to\njust querying /proc/<pid>/maps FD as proposed in current approach.  These\naspects were discussed in the hallway track at recent LSF/MM/BPF 2024 and\nsticking to procfs ioctl() was the final agreement we arrived at.\n\n  [0] https://github.com/anakryiko/linux/commits/procfs-proc-maps-ioctl-v2/\n  [1] https://github.com/libbpf/blazesym/pull/675\n  [2] https://lore.kernel.org/bpf/7rm3izyq2vjp5evdjc7c6z4crdd3oerpiknumdnmmemwyiwx7t@hleldw7iozi3/\n\n\nThis patch (of 6):\n\nExtract generic logic to fetch relevant pieces of data to describe VMA\nname.  This could be just some string (either special constant or\nuser-provided)', ' or a string with some formatted wrapping text (e.g.', '\n""[anon_shmem:<something>]"")', ' or', ' commonly', ' file path.  seq_file-based\nlogic has different methods to handle all three cases', ' but they are\ncurrently mixed in with extracting underlying sources of data.\n\nThis patch splits this into data fetching and data formatting', ' so that\ndata fetching can be reused later on.\n\nThere should be no functional changes.\n\nLink: https://lkml.kernel.org/r/20240627170900.1672542-1-andrii@kernel.org\nLink: https://lkml.kernel.org/r/20240627170900.1672542-2-andrii@kernel.org\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Liam R. Howlett <Liam.Howlett@Oracle.com>\nCc: Alexey Dobriyan <adobriyan@gmail.com>\nCc: Al Viro <viro@zeniv.linux.org.uk>\nCc: Christian Brauner <brauner@kernel.org>\nCc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>\nCc: Mike Rapoport (IBM) <rppt@kernel.org>\nCc: Suren Baghdasaryan <surenb@google.com>\nCc: Andi Kleen <ak@linux.intel.com>\nCc: Arnd Bergmann <arnd@arndb.de>\nCc: Stephen Rothwell <sfr@canb.auug.org.au>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\n', '']",Extract logic for acquiring VMA name elements in a patch for ioctl()-based API for querying VMAs through /proc/pid/maps.,"ioctl,VMA,procfs",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['tracepoints like programs']
e435b043d89a267bd6eb3d5650d2319805d7924a,e435b043d89a267bd6eb3d5650d2319805d7924a,Tengda Wu,wutengda@huaweicloud.com,1720709899,Daniel Borkmann,daniel@iogearbox.net,1720815261,130e78980e126458685412668fbdbb36cc8c0441,f7866c35873377313ff94398f17d425b28b71de1,"selftests/bpf: Test for null-pointer-deref bugfix in resolve_prog_type()

This test verifies that resolve_prog_type() works as expected when
`attach_prog_fd` is not passed in.

`prog->aux->dst_prog` in resolve_prog_type() is assigned by
`attach_prog_fd`"," and would be NULL if `attach_prog_fd` is not provided.

Loading EXT prog with bpf_dynptr_from_skb() kfunc call in this way will
lead to null-pointer-deref.

Verify that the null-pointer-deref bug in resolve_prog_type() is fixed.

Signed-off-by: Tengda Wu <wutengda@huaweicloud.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240711145819.254178-3-wutengda@huaweicloud.com
",[''],Add test case to verify fix for null-pointer dereference in resolve_prog_type for EXT progs.,"null-pointer-deref, resolve_prog_type, selftests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['other']
f7866c35873377313ff94398f17d425b28b71de1,f7866c35873377313ff94398f17d425b28b71de1,Tengda Wu,wutengda@huaweicloud.com,1720709898,Daniel Borkmann,daniel@iogearbox.net,1720815255,f1569be13de7520eb68b905cb653f4b571dbcc90,517125f6749402e579f715519147145944f12ad9,"bpf: Fix null pointer dereference in resolve_prog_type() for BPF_PROG_TYPE_EXT

When loading a EXT program without specifying `attr->attach_prog_fd`","
the `prog->aux->dst_prog` will be null. At this time","[' calling\nresolve_prog_type() anywhere will result in a null pointer dereference.\n\nExample stack trace:\n\n[    8.107863] Unable to handle kernel NULL pointer dereference at virtual address 0000000000000004\n[    8.108262] Mem abort info:\n[    8.108384]   ESR = 0x0000000096000004\n[    8.108547]   EC = 0x25: DABT (current EL)', ' IL = 32 bits\n[    8.108722]   SET = 0', ' FnV = 0\n[    8.108827]   EA = 0', ' S1PTW = 0\n[    8.108939]   FSC = 0x04: level 0 translation fault\n[    8.109102] Data abort info:\n[    8.109203]   ISV = 0', ' ISS = 0x00000004', ' ISS2 = 0x00000000\n[    8.109399]   CM = 0', ' WnR = 0', ' TnD = 0', ' TagAccess = 0\n[    8.109614]   GCS = 0', ' Overlay = 0', ' DirtyBit = 0', ' Xs = 0\n[    8.109836] user pgtable: 4k pages', ' 48-bit VAs', ' pgdp=0000000101354000\n[    8.110011] [0000000000000004] pgd=0000000000000000', ' p4d=0000000000000000\n[    8.112624] Internal error: Oops: 0000000096000004 [#1] PREEMPT SMP\n[    8.112783] Modules linked in:\n[    8.113120] CPU: 0 PID: 99 Comm: may_access_dire Not tainted 6.10.0-rc3-next-20240613-dirty #1\n[    8.113230] Hardware name: linux', 'dummy-virt (DT)\n[    8.113390] pstate: 60000005 (nZCv daif -PAN -UAO -TCO -DIT -SSBS BTYPE=--)\n[    8.113429] pc : may_access_direct_pkt_data+0x24/0xa0\n[    8.113746] lr : add_subprog_and_kfunc+0x634/0x8e8\n[    8.113798] sp : ffff80008283b9f0\n[    8.113813] x29: ffff80008283b9f0 x28: ffff800082795048 x27: 0000000000000001\n[    8.113881] x26: ffff0000c0bb2600 x25: 0000000000000000 x24: 0000000000000000\n[    8.113897] x23: ffff0000c1134000 x22: 000000000001864f x21: ffff0000c1138000\n[    8.113912] x20: 0000000000000001 x19: ffff0000c12b8000 x18: ffffffffffffffff\n[    8.113929] x17: 0000000000000000 x16: 0000000000000000 x15: 0720072007200720\n[    8.113944] x14: 0720072007200720 x13: 0720072007200720 x12: 0720072007200720\n[    8.113958] x11: 0720072007200720 x10: 0000000000f9fca4 x9 : ffff80008021f4e4\n[    8.113991] x8 : 0101010101010101 x7 : 746f72705f6d656d x6 : 000000001e0e0f5f\n[    8.114006] x5 : 000000000001864f x4 : ffff0000c12b8000 x3 : 000000000000001c\n[    8.114020] x2 : 0000000000000002 x1 : 0000000000000000 x0 : 0000000000000000\n[    8.114126] Call trace:\n[    8.114159]  may_access_direct_pkt_data+0x24/0xa0\n[    8.114202]  bpf_check+0x3bc/0x28c0\n[    8.114214]  bpf_prog_load+0x658/0xa58\n[    8.114227]  __sys_bpf+0xc50/0x2250\n[    8.114240]  __arm64_sys_bpf+0x28/0x40\n[    8.114254]  invoke_syscall.constprop.0+0x54/0xf0\n[    8.114273]  do_el0_svc+0x4c/0xd8\n[    8.114289]  el0_svc+0x3c/0x140\n[    8.114305]  el0t_64_sync_handler+0x134/0x150\n[    8.114331]  el0t_64_sync+0x168/0x170\n[    8.114477] Code: 7100707f 54000081 f9401c00 f9403800 (b9400403)\n[    8.118672] ---[ end trace 0000000000000000 ]---\n\nOne way to fix it is by forcing `attach_prog_fd` non-empty when\nbpf_prog_load(). But this will lead to `libbpf_probe_bpf_prog_type`\nAPI broken which use verifier log to probe prog type and will log\nnothing if we reject invalid EXT prog before bpf_check().\n\nAnother way is by adding null check in resolve_prog_type().\n\nThe issue was introduced by commit 4a9c7bbe2ed4 (""bpf: Resolve to\nprog->aux->dst_prog->type only for BPF_PROG_TYPE_EXT"") which wanted\nto correct type resolution for BPF_PROG_TYPE_TRACING programs. Before\nthat', ' the type resolution of BPF_PROG_TYPE_EXT prog actually follows\nthe logic below:\n\n  prog->aux->dst_prog ? prog->aux->dst_prog->type : prog->type;\n\nIt implies that when EXT program is not yet attached to `dst_prog`', '\nthe prog type should be EXT itself. This code worked fine in the past.\nSo just keep using it.\n\nFix this by returning `prog->type` for BPF_PROG_TYPE_EXT if `dst_prog`\nis not present in resolve_prog_type().\n\nFixes: 4a9c7bbe2ed4 (""bpf: Resolve to prog->aux->dst_prog->type only for BPF_PROG_TYPE_EXT"")\nSigned-off-by: Tengda Wu <wutengda@huaweicloud.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Daniel Borkmann <daniel@iogearbox.net>\nCc: Martin KaFai Lau <kafai@fb.com>\nLink: https://lore.kernel.org/bpf/20240711145819.254178-2-wutengda@huaweicloud.com\n', '']",Fixes a null pointer dereference in resolve_prog_type() for BPF_PROG_TYPE_EXT when attr->attach_prog_fd is not specified.,null pointer dereference,It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"[""It's not related to any of the above.""]"
7a2fb5619cc1fb53cb8784154d5ef2bd99997436,7a2fb5619cc1fb53cb8784154d5ef2bd99997436,Howard Chu,howardchu95@gmail.com,1720185651,Namhyung Kim,namhyung@kernel.org,1720802942,aea86f3d4d883dc666fdf5d05149e7d95072274c,1553419c3c10cf386496e68b90b5d0ce966ac614,"perf trace: Fix iteration of syscall ids in syscalltbl->entries

This is a bug found when implementing pretty-printing for the
landlock_add_rule system call"," I decided to send this patch separately
because this is a serious bug that should be fixed fast.

I wrote a test program to do landlock_add_rule syscall in a loop","['\nyet perf trace -e landlock_add_rule freezes', ' giving no output.\n\nThis bug is introduced by the false understanding of the variable ""key""\nbelow:\n```\nfor (key = 0; key < trace->sctbl->syscalls.nr_entries; ++key) {\n\tstruct syscall *sc = trace__syscall_info(trace', ' NULL', ' key);\n\t...\n}\n```\nThe code above seems right at the beginning', ' but when looking at\nsyscalltbl.c', ' I found these lines:\n\n```\nfor (i = 0; i <= syscalltbl_native_max_id; ++i)\n\tif (syscalltbl_native[i])\n\t\t++nr_entries;\n\nentries = tbl->syscalls.entries = malloc(sizeof(struct syscall) * nr_entries);\n...\n\nfor (i = 0', ' j = 0; i <= syscalltbl_native_max_id; ++i) {\n\tif (syscalltbl_native[i]) {\n\t\tentries[j].name = syscalltbl_native[i];\n\t\tentries[j].id = i;\n\t\t++j;\n\t}\n}\n```\n\nmeaning the key is merely an index to traverse the syscall table', '\ninstead of the actual syscall id for this particular syscall.\n\nSo if one uses key to do trace__syscall_info(trace', ' NULL', ' key)', ' because\nkey only goes up to trace->sctbl->syscalls.nr_entries', ' for example', ' on\nmy X86_64 machine', ' this number is 373', ' it will end up neglecting all\nthe rest of the syscall', ' in my case', ' everything after `rseq`', ' because\nthe traversal will stop at 373', ' and `rseq` is the last syscall whose id\nis lower than 373\n\nin tools/perf/arch/x86/include/generated/asm/syscalls_64.c:\n```\n\t...\n\t[334] = ""rseq""', '\n\t[424] = ""pidfd_send_signal""', '\n\t...\n```\n\nThe reason why the key is scrambled but perf trace works well is that\nkey is used in trace__syscall_info(trace', ' NULL', ' key) to do\ntrace->syscalls.table[id]', ' this makes sure that the struct syscall returned\nactually has an id the same value as key', ' making the later bpf_prog\nmatching all correct.\n\nAfter fixing this bug', ' I can do perf trace on 38 more syscalls', ' and\nbecause more syscalls are visible', ' we get 8 more syscalls that can be\naugmented.\n\nbefore:\n\nperf $ perf trace -vv --max-events=1 |& grep Reusing\nReusing ""open"" BPF sys_enter augmenter for ""stat""\nReusing ""open"" BPF sys_enter augmenter for ""lstat""\nReusing ""open"" BPF sys_enter augmenter for ""access""\nReusing ""connect"" BPF sys_enter augmenter for ""accept""\nReusing ""sendto"" BPF sys_enter augmenter for ""recvfrom""\nReusing ""connect"" BPF sys_enter augmenter for ""bind""\nReusing ""connect"" BPF sys_enter augmenter for ""getsockname""\nReusing ""connect"" BPF sys_enter augmenter for ""getpeername""\nReusing ""open"" BPF sys_enter augmenter for ""execve""\nReusing ""open"" BPF sys_enter augmenter for ""truncate""\nReusing ""open"" BPF sys_enter augmenter for ""chdir""\nReusing ""open"" BPF sys_enter augmenter for ""mkdir""\nReusing ""open"" BPF sys_enter augmenter for ""rmdir""\nReusing ""open"" BPF sys_enter augmenter for ""creat""\nReusing ""open"" BPF sys_enter augmenter for ""link""\nReusing ""open"" BPF sys_enter augmenter for ""unlink""\nReusing ""open"" BPF sys_enter augmenter for ""symlink""\nReusing ""open"" BPF sys_enter augmenter for ""readlink""\nReusing ""open"" BPF sys_enter augmenter for ""chmod""\nReusing ""open"" BPF sys_enter augmenter for ""chown""\nReusing ""open"" BPF sys_enter augmenter for ""lchown""\nReusing ""open"" BPF sys_enter augmenter for ""mknod""\nReusing ""open"" BPF sys_enter augmenter for ""statfs""\nReusing ""open"" BPF sys_enter augmenter for ""pivot_root""\nReusing ""open"" BPF sys_enter augmenter for ""chroot""\nReusing ""open"" BPF sys_enter augmenter for ""acct""\nReusing ""open"" BPF sys_enter augmenter for ""swapon""\nReusing ""open"" BPF sys_enter augmenter for ""swapoff""\nReusing ""open"" BPF sys_enter augmenter for ""delete_module""\nReusing ""open"" BPF sys_enter augmenter for ""setxattr""\nReusing ""open"" BPF sys_enter augmenter for ""lsetxattr""\nReusing ""openat"" BPF sys_enter augmenter for ""fsetxattr""\nReusing ""open"" BPF sys_enter augmenter for ""getxattr""\nReusing ""open"" BPF sys_enter augmenter for ""lgetxattr""\nReusing ""openat"" BPF sys_enter augmenter for ""fgetxattr""\nReusing ""open"" BPF sys_enter augmenter for ""listxattr""\nReusing ""open"" BPF sys_enter augmenter for ""llistxattr""\nReusing ""open"" BPF sys_enter augmenter for ""removexattr""\nReusing ""open"" BPF sys_enter augmenter for ""lremovexattr""\nReusing ""fsetxattr"" BPF sys_enter augmenter for ""fremovexattr""\nReusing ""open"" BPF sys_enter augmenter for ""mq_open""\nReusing ""open"" BPF sys_enter augmenter for ""mq_unlink""\nReusing ""fsetxattr"" BPF sys_enter augmenter for ""add_key""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""request_key""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""inotify_add_watch""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""mkdirat""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""mknodat""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""fchownat""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""futimesat""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""newfstatat""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""unlinkat""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""linkat""\nReusing ""open"" BPF sys_enter augmenter for ""symlinkat""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""readlinkat""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""fchmodat""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""faccessat""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""utimensat""\nReusing ""connect"" BPF sys_enter augmenter for ""accept4""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""name_to_handle_at""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""renameat2""\nReusing ""open"" BPF sys_enter augmenter for ""memfd_create""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""execveat""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""statx""\n\nafter\n\nperf $ perf trace -vv --max-events=1 |& grep Reusing\nReusing ""open"" BPF sys_enter augmenter for ""stat""\nReusing ""open"" BPF sys_enter augmenter for ""lstat""\nReusing ""open"" BPF sys_enter augmenter for ""access""\nReusing ""connect"" BPF sys_enter augmenter for ""accept""\nReusing ""sendto"" BPF sys_enter augmenter for ""recvfrom""\nReusing ""connect"" BPF sys_enter augmenter for ""bind""\nReusing ""connect"" BPF sys_enter augmenter for ""getsockname""\nReusing ""connect"" BPF sys_enter augmenter for ""getpeername""\nReusing ""open"" BPF sys_enter augmenter for ""execve""\nReusing ""open"" BPF sys_enter augmenter for ""truncate""\nReusing ""open"" BPF sys_enter augmenter for ""chdir""\nReusing ""open"" BPF sys_enter augmenter for ""mkdir""\nReusing ""open"" BPF sys_enter augmenter for ""rmdir""\nReusing ""open"" BPF sys_enter augmenter for ""creat""\nReusing ""open"" BPF sys_enter augmenter for ""link""\nReusing ""open"" BPF sys_enter augmenter for ""unlink""\nReusing ""open"" BPF sys_enter augmenter for ""symlink""\nReusing ""open"" BPF sys_enter augmenter for ""readlink""\nReusing ""open"" BPF sys_enter augmenter for ""chmod""\nReusing ""open"" BPF sys_enter augmenter for ""chown""\nReusing ""open"" BPF sys_enter augmenter for ""lchown""\nReusing ""open"" BPF sys_enter augmenter for ""mknod""\nReusing ""open"" BPF sys_enter augmenter for ""statfs""\nReusing ""open"" BPF sys_enter augmenter for ""pivot_root""\nReusing ""open"" BPF sys_enter augmenter for ""chroot""\nReusing ""open"" BPF sys_enter augmenter for ""acct""\nReusing ""open"" BPF sys_enter augmenter for ""swapon""\nReusing ""open"" BPF sys_enter augmenter for ""swapoff""\nReusing ""open"" BPF sys_enter augmenter for ""delete_module""\nReusing ""open"" BPF sys_enter augmenter for ""setxattr""\nReusing ""open"" BPF sys_enter augmenter for ""lsetxattr""\nReusing ""openat"" BPF sys_enter augmenter for ""fsetxattr""\nReusing ""open"" BPF sys_enter augmenter for ""getxattr""\nReusing ""open"" BPF sys_enter augmenter for ""lgetxattr""\nReusing ""openat"" BPF sys_enter augmenter for ""fgetxattr""\nReusing ""open"" BPF sys_enter augmenter for ""listxattr""\nReusing ""open"" BPF sys_enter augmenter for ""llistxattr""\nReusing ""open"" BPF sys_enter augmenter for ""removexattr""\nReusing ""open"" BPF sys_enter augmenter for ""lremovexattr""\nReusing ""fsetxattr"" BPF sys_enter augmenter for ""fremovexattr""\nReusing ""open"" BPF sys_enter augmenter for ""mq_open""\nReusing ""open"" BPF sys_enter augmenter for ""mq_unlink""\nReusing ""fsetxattr"" BPF sys_enter augmenter for ""add_key""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""request_key""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""inotify_add_watch""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""mkdirat""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""mknodat""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""fchownat""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""futimesat""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""newfstatat""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""unlinkat""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""linkat""\nReusing ""open"" BPF sys_enter augmenter for ""symlinkat""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""readlinkat""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""fchmodat""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""faccessat""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""utimensat""\nReusing ""connect"" BPF sys_enter augmenter for ""accept4""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""name_to_handle_at""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""renameat2""\nReusing ""open"" BPF sys_enter augmenter for ""memfd_create""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""execveat""\nReusing ""fremovexattr"" BPF sys_enter augmenter for ""statx""\n\nTL;DR:\n\nThese are the new syscalls that can be augmented\nReusing ""openat"" BPF sys_enter augmenter for ""open_tree""\nReusing ""openat"" BPF sys_enter augmenter for ""openat2""\nReusing ""openat"" BPF sys_enter augmenter for ""mount_setattr""\nReusing ""openat"" BPF sys_enter augmenter for ""move_mount""\nReusing ""open"" BPF sys_enter augmenter for ""fsopen""\nReusing ""openat"" BPF sys_enter augmenter for ""fspick""\nReusing ""openat"" BPF sys_enter augmenter for ""faccessat2""\nReusing ""openat"" BPF sys_enter augmenter for ""fchmodat2""\n\nas for the perf trace output:\n\nbefore\n\nperf $ perf trace -e faccessat2 --max-events=1\n[no output]\n\nafter\n\nperf $ ./perf trace -e faccessat2 --max-events=1\n     0.000 ( 0.037 ms): waybar/958 faccessat2(dfd: 40', ' filename: ""uevent"")                               = 0\n\nP.S. The reason why this bug was not found in the past five years is\nprobably because it only happens to the newer syscalls whose id is\ngreater', ' for instance', ' faccessat2 of id 439', ' which not a lot of people\ncare about when using perf trace.\n\n[Arnaldo]: notes\n\nThat and the fact that the BPF code was hidden before having to use -e', ""\nthat got changed kinda recently when we switched to using BPF skels for\naugmenting syscalls in 'perf trace':\n\n⬢[acme@toolbox perf-tools-next]$ git log --oneline tools/perf/util/bpf_skel/augmented_raw_syscalls.bpf.c\na9f4c6c999008c92 perf trace: Collect sys_nanosleep first argument\n29d16de26df17e94 perf augmented_raw_syscalls.bpf: Move 'struct timespec64' to vmlinux.h\n5069211e2f0b47e7 perf trace: Use the right bpf_probe_read(_str) variant for reading user data\n33b725ce7b988756 perf trace: Avoid compile error wrt redefining bool\n7d9642311b6d9d31 perf bpf augmented_raw_syscalls: Add an assert to make sure sizeof(augmented_arg->value) is a power of two.\n262b54b6c9396823 perf bpf augmented_raw_syscalls: Add an assert to make sure sizeof(saddr) is a power of two.\n1836480429d173c0 perf bpf_skel augmented_raw_syscalls: Cap the socklen parameter using &= sizeof(saddr)\ncd2cece61ac5f900 perf trace: Tidy comments related to BPF + syscall augmentation\n5e6da6be3082f77b perf trace: Migrate BPF augmentation to use a skeleton\n⬢[acme@toolbox perf-tools-next]$\n\n⬢[acme@toolbox perf-tools-next]$ git show --oneline --pretty=reference 5e6da6be3082f77b | head -1\n5e6da6be3082f77b (perf trace: Migrate BPF augmentation to use a skeleton"", ' 2023-08-10)\n⬢[acme@toolbox perf-tools-next]$\n\nI.e. from August', ' 2023.\n\nOne had as well to ask for BUILD_BPF_SKEL=1', "" which now is default if all\nit needs is available on the system.\n\nI simplified the code to not expose the 'struct syscall' outside of\ntools/perf/util/syscalltbl.c"", ' instead providing a function to go from\nthe index to the syscall id:\n\n  int syscalltbl__id_at_idx(struct syscalltbl *tbl', ' int idx);\n\nSigned-off-by: Howard Chu <howardchu95@gmail.com>\nTested-by: Arnaldo Carvalho de Melo <acme@redhat.com>\nLink: https://lore.kernel.org/lkml/ZmhlAxbVcAKoPTg8@x1\nLink: https://lore.kernel.org/r/20240705132059.853205-2-howardchu95@gmail.com\nSigned-off-by: Namhyung Kim <namhyung@kernel.org>\n', '']",Fix bug in iteration of syscall ids during landlock_add_rule syscall implementation.,"bug, syscall, iteration",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
517125f6749402e579f715519147145944f12ad9,517125f6749402e579f715519147145944f12ad9,Daniel Borkmann,daniel@iogearbox.net,1720800750,Daniel Borkmann,daniel@iogearbox.net,1720801070,9d865514cb3de90406b10b712a1260b9ee8d5365,a1010fce1c0c2ce3b305aa6e8ff70e86f99e3226,"selftests/bpf: DENYLIST.aarch64: Skip fexit_sleep again

Revert commit 90dc946059b7 (""selftests/bpf: DENYLIST.aarch64: Remove
fexit_sleep"") again. The fix in 19d3c179a377 (""bpf"," arm64: Fix trampoline
for BPF_TRAMP_F_CALL_ORIG"") does not address all of the issues and BPF
CI is still hanging and timing out:

   https://github.com/kernel-patches/bpf/actions/runs/9905842936/job/27366435436

   [...]
   #89/11   fexit_bpf2bpf/func_replace_global_func:OK
   #89/12   fexit_bpf2bpf/fentry_to_cgroup_bpf:OK
   #89/13   fexit_bpf2bpf/func_replace_progmap:OK
   #89      fexit_bpf2bpf:OK
   Error: The operation was canceled.

Thus more investigation work & fixing is needed before the test can be put
in place again.

Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Cc: Puranjay Mohan <puranjay@kernel.org>
Link: https://lore.kernel.org/bpf/20240705145009.32340-1-puranjay@kernel.org
",[''],Revert a selftest change for bpf on aarch64 due to unresolved issues causing BPF CI failures.,DENYLIST aarch64 fexit_sleep,It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
a1010fce1c0c2ce3b305aa6e8ff70e86f99e3226,a1010fce1c0c2ce3b305aa6e8ff70e86f99e3226,Alexei Starovoitov,ast@kernel.org,1720799648,Alexei Starovoitov,ast@kernel.org,1720799657,3cb546fadb550a330835ac90068f9626b4b4bb68,2454075f8e2915cebbe52a1195631bc7efe2b7e1 deac5871eb0751454cb80b3ff6b69e42a6c1bab2,"Merge branch 'use-overflow-h-helpers-to-check-for-overflows'

Shung-Hsi Yu says:

====================
Use overflow.h helpers to check for overflows

This patch set refactors kernel/bpf/verifier.c to use type-agnostic"," generic
overflow-check helpers defined in include/linux/overflow.h to check for addition
and subtraction overflow","[' and drop the signed_*_overflows() helpers we currently\nhave in kernel/bpf/verifier.c; with a fix for overflow check in adjust_jmp_off()\nin patch 1.\n\nThere should be no functional change in how the verifier works and  the main\nmotivation is to make future refactoring[1] easier.\n\nWhile check_mul_overflow() also exists and could potentially replace what\nwe have in scalar*_min_max_mul()', ' it does not help with refactoring and\nwould either change how the verifier works (e.g. lifting restriction on\numax<=U32_MAX and u32_max<=U16_MAX) or make the code slightly harder to\nread', ' so it is left for future endeavour.\n\nChanges from v2 <https://lore.kernel.org/r/20240701055907.82481-1-shung-hsi.yu@suse.com>\n- add fix for 5337ac4c9b80 (""bpf: Fix the corner case with may_goto and jump to\n  the 1st insn."") to correct the overflow check for general jump instructions\n- adapt to changes in commit 5337ac4c9b80 (""bpf: Fix the corner case with\n  may_goto and jump to the 1st insn."")\n  - refactor in adjust_jmp_off() as well and remove signed_add16_overflow()\n\nChanges from v1 <https://lore.kernel.org/r/20240623070324.12634-1-shung-hsi.yu@suse.com>:\n- use pointers to values in dst_reg directly as the sum/diff pointer and\n  remove the else branch (Jiri)\n- change local variables to be dst_reg pointers instead of src_reg values\n- include comparison of generated assembly before & after the change\n  (Alexei)\n\n1: https://github.com/kernel-patches/bpf/pull/7205/commits\n====================\n\nLink: https://lore.kernel.org/r/20240712080127.136608-1-shung-hsi.yu@suse.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Refactor eBPF verifier to use overflow.h helpers for checking arithmetic overflow.,"overflow, refactor, helpers",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
deac5871eb0751454cb80b3ff6b69e42a6c1bab2,deac5871eb0751454cb80b3ff6b69e42a6c1bab2,Shung-Hsi Yu,shung-hsi.yu@suse.com,1720771286,Alexei Starovoitov,ast@kernel.org,1720799648,3cb546fadb550a330835ac90068f9626b4b4bb68,28a4411076b254c67842348e3b25c2fb41a94cad,"bpf: use check_sub_overflow() to check for subtraction overflows

Similar to previous patch that drops signed_add*_overflows() and uses
(compiler) builtin-based check_add_overflow()"," do the same for
signed_sub*_overflows() and replace them with the generic
check_sub_overflow() to make future refactoring easier and have the
checks implemented more efficiently.

Unsigned overflow check for subtraction does not use helpers and are
simple enough already","["" so they're left untouched.\n\nAfter the change GCC 13.3.0 generates cleaner assembly on x86_64:\n\n\tif (check_sub_overflow(*dst_smin"", ' src_reg->smax_value', ' dst_smin) ||\n   139bf:\tmov    0x28(%r12)', '%rax\n   139c4:\tmov    %edx', '0x54(%r12)\n   139c9:\tsub    %r11', '%rax\n   139cc:\tmov    %rax', '0x28(%r12)\n   139d1:\tjo     14627 <adjust_reg_min_max_vals+0x1237>\n\t    check_sub_overflow(*dst_smax', ' src_reg->smin_value', ' dst_smax)) {\n   139d7:\tmov    0x30(%r12)', '%rax\n   139dc:\tsub    %r9', '%rax\n   139df:\tmov    %rax', '0x30(%r12)\n\tif (check_sub_overflow(*dst_smin', ' src_reg->smax_value', ' dst_smin) ||\n   139e4:\tjo     14627 <adjust_reg_min_max_vals+0x1237>\n   ...\n\t\t*dst_smin = S64_MIN;\n   14627:\tmovabs $0x8000000000000000', '%rax\n   14631:\tmov    %rax', '0x28(%r12)\n\t\t*dst_smax = S64_MAX;\n   14636:\tsub    $0x1', '%rax\n   1463a:\tmov    %rax', '0x30(%r12)\n\nBefore the change it gives:\n\n\tif (signed_sub_overflows(dst_reg->smin_value', ' smax_val) ||\n   13a50:\tmov    0x28(%r12)', '%rdi\n   13a55:\tmov    %edx', '0x54(%r12)\n\t\tdst_reg->smax_value = S64_MAX;\n   13a5a:\tmovabs $0x7fffffffffffffff', '%rdx\n   13a64:\tmov    %eax', '0x50(%r12)\n\t\tdst_reg->smin_value = S64_MIN;\n   13a69:\tmovabs $0x8000000000000000', '%rax\n\ts64 res = (s64)((u64)a - (u64)b);\n   13a73:\tmov    %rdi', '%rsi\n   13a76:\tsub    %rcx', '%rsi\n\tif (b < 0)\n   13a79:\ttest   %rcx', '%rcx\n   13a7c:\tjs     145ea <adjust_reg_min_max_vals+0x119a>\n\tif (signed_sub_overflows(dst_reg->smin_value', ' smax_val) ||\n   13a82:\tcmp    %rsi', '%rdi\n   13a85:\tjl     13ac7 <adjust_reg_min_max_vals+0x677>\n\t    signed_sub_overflows(dst_reg->smax_value', ' smin_val)) {\n   13a87:\tmov    0x30(%r12)', '%r8\n\ts64 res = (s64)((u64)a - (u64)b);\n   13a8c:\tmov    %r8', '%rax\n   13a8f:\tsub    %r9', '%rax\n\treturn res > a;\n   13a92:\tcmp    %rax', '%r8\n   13a95:\tsetl   %sil\n\tif (b < 0)\n   13a99:\ttest   %r9', '%r9\n   13a9c:\tjs     147d1 <adjust_reg_min_max_vals+0x1381>\n\t\tdst_reg->smax_value = S64_MAX;\n   13aa2:\tmovabs $0x7fffffffffffffff', '%rdx\n\t\tdst_reg->smin_value = S64_MIN;\n   13aac:\tmovabs $0x8000000000000000', '%rax\n\tif (signed_sub_overflows(dst_reg->smin_value', ' smax_val) ||\n   13ab6:\ttest   %sil', '%sil\n   13ab9:\tjne    13ac7 <adjust_reg_min_max_vals+0x677>\n\t\tdst_reg->smin_value -= smax_val;\n   13abb:\tmov    %rdi', '%rax\n\t\tdst_reg->smax_value -= smin_val;\n   13abe:\tmov    %r8', '%rdx\n\t\tdst_reg->smin_value -= smax_val;\n   13ac1:\tsub    %rcx', '%rax\n\t\tdst_reg->smax_value -= smin_val;\n   13ac4:\tsub    %r9', '%rdx\n   13ac7:\tmov    %rax', '0x28(%r12)\n   ...\n   13ad1:\tmov    %rdx', '0x30(%r12)\n   ...\n\tif (signed_sub_overflows(dst_reg->smin_value', ' smax_val) ||\n   145ea:\tcmp    %rsi', '%rdi\n   145ed:\tjg     13ac7 <adjust_reg_min_max_vals+0x677>\n   145f3:\tjmp    13a87 <adjust_reg_min_max_vals+0x637>\n\nSuggested-by: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/r/20240712080127.136608-4-shung-hsi.yu@suse.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Refactor subtraction overflow checks by replacing signed_sub*_overflows() with check_sub_overflow() for efficiency and easier future refactoring.,"overflow, subtraction, refactoring",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
28a4411076b254c67842348e3b25c2fb41a94cad,28a4411076b254c67842348e3b25c2fb41a94cad,Shung-Hsi Yu,shung-hsi.yu@suse.com,1720771285,Alexei Starovoitov,ast@kernel.org,1720799648,8f848cb9dfb0438cfa5d709cb559de66e8259c4f,4a04b4f0de59dd5c621e78f15803ee0b0544eeb8,"bpf: use check_add_overflow() to check for addition overflows

signed_add*_overflows() was added back when there was no overflow-check
helper. With the introduction of such helpers in commit f0907827a8a91
(""compiler.h: enable builtin overflow checkers and add fallback code"")"," we
can drop signed_add*_overflows() in kernel/bpf/verifier.c and use the
generic check_add_overflow() instead.

This will make future refactoring easier","[' and takes advantage of\ncompiler-emitted hardware instructions that efficiently implement these\nchecks.\n\nAfter the change GCC 13.3.0 generates cleaner assembly on x86_64:\n\n\terr = adjust_scalar_min_max_vals(env', ' insn', ' dst_reg', ' *src_reg);\n   13625:\tmov    0x28(%rbx)', '%r9  /*  r9 = src_reg->smin_value */\n   13629:\tmov    0x30(%rbx)', '%rcx /* rcx = src_reg->smax_value */\n   ...\n\tif (check_add_overflow(*dst_smin', ' src_reg->smin_value', ' dst_smin) ||\n   141c1:\tmov    %r9', '%rax\n   141c4:\tadd    0x28(%r12)', '%rax\n   141c9:\tmov    %rax', '0x28(%r12)\n   141ce:\tjo     146e4 <adjust_reg_min_max_vals+0x1294>\n\t    check_add_overflow(*dst_smax', ' src_reg->smax_value', ' dst_smax)) {\n   141d4:\tadd    0x30(%r12)', '%rcx\n   141d9:\tmov    %rcx', '0x30(%r12)\n\tif (check_add_overflow(*dst_smin', ' src_reg->smin_value', ' dst_smin) ||\n   141de:\tjo     146e4 <adjust_reg_min_max_vals+0x1294>\n   ...\n\t\t*dst_smin = S64_MIN;\n   146e4:\tmovabs $0x8000000000000000', '%rax\n   146ee:\tmov    %rax', '0x28(%r12)\n\t\t*dst_smax = S64_MAX;\n   146f3:\tsub    $0x1', '%rax\n   146f7:\tmov    %rax', '0x30(%r12)\n\nBefore the change it gives:\n\n\ts64 smin_val = src_reg->smin_value;\n     675:\tmov    0x28(%rsi)', '%r8\n\ts64 smax_val = src_reg->smax_value;\n\tu64 umin_val = src_reg->umin_value;\n\tu64 umax_val = src_reg->umax_value;\n     679:\tmov    %rdi', '%rax /* rax = dst_reg */\n\tif (signed_add_overflows(dst_reg->smin_value', ' smin_val) ||\n     67c:\tmov    0x28(%rdi)', '%rdi /* rdi = dst_reg->smin_value */\n\tu64 umin_val = src_reg->umin_value;\n     680:\tmov    0x38(%rsi)', '%rdx\n\tu64 umax_val = src_reg->umax_value;\n     684:\tmov    0x40(%rsi)', '%rcx\n\ts64 res = (s64)((u64)a + (u64)b);\n     688:\tlea    (%r8', '%rdi', '1)', '%r9 /* r9 = dst_reg->smin_value + src_reg->smin_value */\n\treturn res < a;\n     68c:\tcmp    %r9', '%rdi\n     68f:\tsetg   %r10b /* r10b = (dst_reg->smin_value + src_reg->smin_value) > dst_reg->smin_value */\n\tif (b < 0)\n     693:\ttest   %r8', '%r8\n     696:\tjs     72b <scalar_min_max_add+0xbb>\n\t    signed_add_overflows(dst_reg->smax_value', ' smax_val)) {\n\t\tdst_reg->smin_value = S64_MIN;\n\t\tdst_reg->smax_value = S64_MAX;\n     69c:\tmovabs $0x7fffffffffffffff', '%rdi\n\ts64 smax_val = src_reg->smax_value;\n     6a6:\tmov    0x30(%rsi)', '%r8\n\t\tdst_reg->smin_value = S64_MIN;\n     6aa:\t00 00 00 \tmovabs $0x8000000000000000', '%rsi\n\tif (signed_add_overflows(dst_reg->smin_value', ' smin_val) ||\n     6b4:\ttest   %r10b', '%r10b /* (dst_reg->smin_value + src_reg->smin_value) > dst_reg->smin_value ? goto 6cb */\n     6b7:\tjne    6cb <scalar_min_max_add+0x5b>\n\t    signed_add_overflows(dst_reg->smax_value', ' smax_val)) {\n     6b9:\tmov    0x30(%rax)', '%r10   /* r10 = dst_reg->smax_value */\n\ts64 res = (s64)((u64)a + (u64)b);\n     6bd:\tlea    (%r10', '%r8', '1)', '%r11 /* r11 = dst_reg->smax_value + src_reg->smax_value */\n\tif (b < 0)\n     6c1:\ttest   %r8', '%r8\n     6c4:\tjs     71e <scalar_min_max_add+0xae>\n\tif (signed_add_overflows(dst_reg->smin_value', ' smin_val) ||\n     6c6:\tcmp    %r11', '%r10 /* (dst_reg->smax_value + src_reg->smax_value) <= dst_reg->smax_value ? goto 723 */\n     6c9:\tjle    723 <scalar_min_max_add+0xb3>\n\t} else {\n\t\tdst_reg->smin_value += smin_val;\n\t\tdst_reg->smax_value += smax_val;\n\t}\n     6cb:\tmov    %rsi', '0x28(%rax)\n     ...\n     6d5:\tmov    %rdi', '0x30(%rax)\n     ...\n\tif (signed_add_overflows(dst_reg->smin_value', ' smin_val) ||\n     71e:\tcmp    %r11', '%r10\n     721:\tjl     6cb <scalar_min_max_add+0x5b>\n\t\tdst_reg->smin_value += smin_val;\n     723:\tmov    %r9', '%rsi\n\t\tdst_reg->smax_value += smax_val;\n     726:\tmov    %r11', '%rdi\n     729:\tjmp    6cb <scalar_min_max_add+0x5b>\n\t\treturn res > a;\n     72b:\tcmp    %r9', '%rdi\n     72e:\tsetl   %r10b\n     732:\tjmp    69c <scalar_min_max_add+0x2c>\n     737:\tnopw   0x0(%rax', '%rax', '1)\n\nNote: unlike adjust_ptr_min_max_vals() and scalar*_min_max_add()', ' it is\nnecessary to introduce intermediate variable in adjust_jmp_off() to keep\nthe functional behavior unchanged. Without an intermediate variable\nimm/off will be altered even on overflow.\n\nSuggested-by: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nLink: https://lore.kernel.org/r/20240712080127.136608-3-shung-hsi.yu@suse.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Refactor to use check_add_overflow() for addition overflow checking in eBPF verifier.,overflow refactoring verifier,It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4a04b4f0de59dd5c621e78f15803ee0b0544eeb8,4a04b4f0de59dd5c621e78f15803ee0b0544eeb8,Shung-Hsi Yu,shung-hsi.yu@suse.com,1720771284,Alexei Starovoitov,ast@kernel.org,1720799647,a269c2797c6ab33dc8e4849d77bac21b943a23f3,2454075f8e2915cebbe52a1195631bc7efe2b7e1,"bpf: fix overflow check in adjust_jmp_off()

adjust_jmp_off() incorrectly used the insn->imm field for all overflow check","
which is incorrect as that should only be done or the BPF_JMP32 | BPF_JA case","['\nnot the general jump instruction case. Fix it by using insn->off for overflow\ncheck in the general case.\n\nFixes: 5337ac4c9b80 (""bpf: Fix the corner case with may_goto and jump to the 1st insn."")\nSigned-off-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nLink: https://lore.kernel.org/r/20240712080127.136608-2-shung-hsi.yu@suse.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix incorrect overflow check in adjust_jmp_off() for BPF_JMP32 | BPF_JA case.,"overflow, adjust_jmp_off, BPF_JMP32",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2454075f8e2915cebbe52a1195631bc7efe2b7e1,2454075f8e2915cebbe52a1195631bc7efe2b7e1,Alan Maguire,alan.maguire@oracle.com,1720776539,Daniel Borkmann,daniel@iogearbox.net,1720796546,4e0126439dbaa60a7531e6916d2b0b91548d9789,b3470da314fd8018ee237e382000c4154a942420,"bpf: Eliminate remaining ""make W=1"" warnings in kernel/bpf/btf.o

As reported by Mirsad [1] we still see format warnings in kernel/bpf/btf.o
at W=1 warning level:

  CC      kernel/bpf/btf.o
./kernel/bpf/btf.c: In function ‘btf_type_seq_show_flags’:
./kernel/bpf/btf.c:7553:21: warning: assignment left-hand side might be a candidate for a format attribute [-Wsuggest-attribute=format]
 7553 |         sseq.showfn = btf_seq_show;
      |                     ^
./kernel/bpf/btf.c: In function ‘btf_type_snprintf_show’:
./kernel/bpf/btf.c:7604:31: warning: assignment left-hand side might be a candidate for a format attribute [-Wsuggest-attribute=format]
 7604 |         ssnprintf.show.showfn = btf_snprintf_show;
      |                               ^

Combined with CONFIG_WERROR=y these can halt the build.

The fix (annotating the structure field with __printf())
suggested by Mirsad resolves these. Apologies I missed this last time.
No other W=1 warnings were observed in kernel/bpf after this fix.

[1] https://lore.kernel.org/bpf/92c9d047-f058-400c-9c7d-81d4dc1ef71b@gmail.com/

Fixes: b3470da314fd (""bpf: annotate BTF show functions with __printf"")
Reported-by: Mirsad Todorovac <mtodorovac69@gmail.com>
Suggested-by: Mirsad Todorovac <mtodorovac69@gmail.com>
Signed-off-by: Alan Maguire <alan.maguire@oracle.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240712092859.1390960-1-alan.maguire@oracle.com
",,Fixes remaining W=1 format warnings in kernel/bpf/btf.o by adding __printf annotation.,"format warnings, __printf annotation, kernel bpf",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b3470da314fd8018ee237e382000c4154a942420,b3470da314fd8018ee237e382000c4154a942420,Alan Maguire,alan.maguire@oracle.com,1720722201,Alexei Starovoitov,ast@kernel.org,1720732517,5ad1e4998c29f1449123c7ca6e32ec6a27204acd,19d3c179a37730caf600a97fed3794feac2b197b,"bpf: annotate BTF show functions with __printf

-Werror=suggest-attribute=format warns about two functions
in kernel/bpf/btf.c [1]; add __printf() annotations to silence
these warnings since for CONFIG_WERROR=y they will trigger
build failures.

[1] https://lore.kernel.org/bpf/a8b20c72-6631-4404-9e1f-0410642d7d20@gmail.com/

Fixes: 31d0bc81637d (""bpf: Move to generic BTF show support"," apply it to seq files/strings"")
Reported-by: Mirsad Todorovac <mtodorovac69@gmail.com>
Signed-off-by: Alan Maguire <alan.maguire@oracle.com>
Tested-by: Mirsad Todorovac <mtodorovac69@yahoo.com>
Link: https://lore.kernel.org/r/20240711182321.963667-1-alan.maguire@oracle.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],This commit adds __printf annotations to silence warning for BTF show functions to prevent build failures.,"__printf, annotations, warnings",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
51df8e0cbaefd432f7029dde94e6c7e4e5b19465,51df8e0cbaefd432f7029dde94e6c7e4e5b19465,Linus Torvalds,torvalds@linux-foundation.org,1720715389,Linus Torvalds,torvalds@linux-foundation.org,1720715389,0bf175e0de508a8b493be2506dc6ccec1f188322,83ab4b461eb7bdf90984eb56d4954dbe11e926d4 d7c199e77ef2fe259ad5b1beca5ddd6c951fcba2,"Merge tag 'net-6.10-rc8' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Paolo Abeni:
 ""Including fixes from bpf and netfilter.

  Current release - regressions:

   - core: fix rc7's __skb_datagram_iter() regression

  Current release - new code bugs:

   - eth: bnxt: fix crashes when reducing ring count with active RSS
     contexts

  Previous releases - regressions:

   - sched: fix UAF when resolving a clash

   - skmsg: skip zero length skb in sk_msg_recvmsg2

   - sunrpc: fix kernel free on connection failure in
     xs_tcp_setup_socket

   - tcp: avoid too many retransmit packets

   - tcp: fix incorrect undo caused by DSACK of TLP retransmit

   - udp: Set SOCK_RCU_FREE earlier in udp_lib_get_port().

   - eth: ks8851: fix deadlock with the SPI chip variant

   - eth: i40e: fix XDP program unloading while removing the driver

  Previous releases - always broken:

   - bpf:
       - fix too early release of tcx_entry
       - fail bpf_timer_cancel when callback is being cancelled
       - bpf: fix order of args in call to bpf_map_kvcalloc

   - netfilter: nf_tables: prefer nft_chain_validate

   - ppp: reject claimed-as-LCP but actually malformed packets

   - wireguard: avoid unaligned 64-bit memory accesses""

* tag 'net-6.10-rc8' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (33 commits)
  net"," sunrpc: Remap EPERM in case of connection failure in xs_tcp_setup_socket
  net/sched: Fix UAF when resolving a clash
  net: ks8851: Fix potential TX stall after interface reopen
  udp: Set SOCK_RCU_FREE earlier in udp_lib_get_port().
  netfilter: nf_tables: prefer nft_chain_validate
  netfilter: nfnetlink_queue: drop bogus WARN_ON
  ethtool: netlink: do not return SQI value if link is down
  ppp: reject claimed-as-LCP but actually malformed packets
  selftests/bpf: Add timer lockup selftest
  net: ethernet: mtk-star-emac: set mac_managed_pm when probing
  e1000e: fix force smbus during suspend flow
  tcp: avoid too many retransmit packets
  bpf: Defer work in bpf_timer_cancel_and_free
  bpf: Fail bpf_timer_cancel when callback is being cancelled
  bpf: fix order of args in call to bpf_map_kvcalloc
  net: ethernet: lantiq_etop: fix double free in detach
  i40e: Fix XDP program unloading while removing the driver
  net: fix rc7's __skb_datagram_iter()
  net: ks8851: Fix deadlock with the SPI chip variant
  octeontx2-af: Fix incorrect value output on error path in rvu_check_rsrc_availability()
  ...
",[''],"Merge networking fixes related to bpf, netfilter, and other components for the 6.10-rc8 version.","networking, fixes, merge",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).', 'tc/netfilter like programs', ""It's not related to any of the above.""]"
19d3c179a37730caf600a97fed3794feac2b197b,19d3c179a37730caf600a97fed3794feac2b197b,Puranjay Mohan,puranjay@kernel.org,1720711118,Daniel Borkmann,daniel@iogearbox.net,1720713390,2f69641c999e9865b5d8d02efcf6823d5f65b4f1,18a8a4c88fb4c261f72a29b769c9463362d9687a,bpf," arm64: Fix trampoline for BPF_TRAMP_F_CALL_ORIG

When BPF_TRAMP_F_CALL_ORIG is set","[' the trampoline calls\n__bpf_tramp_enter() and __bpf_tramp_exit() functions', ' passing them\nthe struct bpf_tramp_image *im pointer as an argument in R0.\n\nThe trampoline generation code uses emit_addr_mov_i64() to emit\ninstructions for moving the bpf_tramp_image address into R0', ' but\nemit_addr_mov_i64() assumes the address to be in the vmalloc() space\nand uses only 48 bits. Because bpf_tramp_image is allocated using\nkzalloc()', ' its address can use more than 48-bits', ' in this case the\ntrampoline will pass an invalid address to __bpf_tramp_enter/exit()\ncausing a kernel crash.\n\nFix this by using emit_a64_mov_i64() in place of emit_addr_mov_i64()\nas it can work with addresses that are greater than 48-bits.\n\nFixes: efc9909fdce0 (""bpf', ' arm64: Add bpf trampoline for arm64"")\nSigned-off-by: Puranjay Mohan <puranjay@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nCloses: https://lore.kernel.org/all/SJ0PR15MB461564D3F7E7A763498CA6A8CBDB2@SJ0PR15MB4615.namprd15.prod.outlook.com/\nLink: https://lore.kernel.org/bpf/20240711151838.43469-1-puranjay@kernel.org\n', '']",Fix trampoline functionality for ARM64 architecture when BPF_TRAMP_F_CALL_ORIG is set.,"trampoline, ARM64, BPF_TRAMP_F_CALL_ORIG",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"[""It's not related to any of the above.""]"
a819ff0cf9fa166881a3781d32909257e2033e86,a819ff0cf9fa166881a3781d32909257e2033e86,Paolo Abeni,pabeni@redhat.com,1720694313,Paolo Abeni,pabeni@redhat.com,1720694313,4c5539b3d9edd528a93ae09bc8a0de98347e4ead,626dfed5fa3bfb41e0dffd796032b555b69f9cde 50bd5a0c658d132507673c4d59347c025dd149ed,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Daniel Borkmann says:

====================
pull-request: bpf 2024-07-11

The following pull-request contains BPF updates for your *net* tree.

We've added 4 non-merge commits during the last 2 day(s) which contain
a total of 4 files changed", 262 insertions(+),"[' 19 deletions(-).\n\nThe main changes are:\n\n1) Fixes for a BPF timer lockup and a use-after-free scenario when timers\n   are used concurrently', ' from Kumar Kartikeya Dwivedi.\n\n2) Fix the argument order in the call to bpf_map_kvcalloc() which could\n   otherwise lead to a compilation error', "" from Mohammad Shehar Yaar Tausif.\n\nbpf-for-netdev\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  selftests/bpf: Add timer lockup selftest\n  bpf: Defer work in bpf_timer_cancel_and_free\n  bpf: Fail bpf_timer_cancel when callback is being cancelled\n  bpf: fix order of args in call to bpf_map_kvcalloc\n====================\n\nLink: https://patch.msgid.link/20240711084016.25757-1-daniel@iogearbox.net\nSigned-off-by: Paolo Abeni <pabeni@redhat.com>\n"", '']",Merged BPF updates for net tree containing 4 non-merge commits with changes to 4 files.,"BPF, updates, net",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
626dfed5fa3bfb41e0dffd796032b555b69f9cde,626dfed5fa3bfb41e0dffd796032b555b69f9cde,Daniel Borkmann,daniel@iogearbox.net,1720075317,Paolo Abeni,pabeni@redhat.com,1720693065,d12cf6ffc238526a87a26deca2182788e38763b0,26488172b0292bed837b95a006a3f3431d1898c3,net," sunrpc: Remap EPERM in case of connection failure in xs_tcp_setup_socket

When using a BPF program on kernel_connect()","[' the call can return -EPERM. This\ncauses xs_tcp_setup_socket() to loop forever', ' filling up the syslog and causing\nthe kernel to potentially freeze up.\n\nNeil suggested:\n\n  This will propagate -EPERM up into other layers which might not be ready\n  to handle it. It might be safer to map EPERM to an error we would be more\n  likely to expect from the network system - such as ECONNREFUSED or ENETDOWN.\n\nECONNREFUSED as error seems reasonable. For programs setting a different error\ncan be out of reach (see handling in 4fbac77d2d09) in particular on kernels\nwhich do not have f10d05966196 (""bpf: Make BPF_PROG_RUN_ARRAY return -err\ninstead of allow boolean"")', ' thus given that it is better to simply remap for\nconsistent behavior. UDP does handle EPERM in xs_udp_send_request().\n\nFixes: d74bad4e74ee (""bpf: Hooks for sys_connect"")\nFixes: 4fbac77d2d09 (""bpf: Hooks for sys_bind"")\nCo-developed-by: Lex Siegel <usiegl00@gmail.com>\nSigned-off-by: Lex Siegel <usiegl00@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nCc: Neil Brown <neilb@suse.de>\nCc: Trond Myklebust <trondmy@kernel.org>\nCc: Anna Schumaker <anna@kernel.org>\nLink: https://github.com/cilium/cilium/issues/33395\nLink: https://lore.kernel.org/bpf/171374175513.12877.8993642908082014881@noble.neil.brown.name\nLink: https://patch.msgid.link/9069ec1d59e4b2129fc23433349fd5580ad43921.1720075070.git.daniel@iogearbox.net\nSigned-off-by: Paolo Abeni <pabeni@redhat.com>\n\n', '']",Remap EPERM error for tcp socket connection failure within sunrpc using a BPF program on kernel_connect.,"Remap, EPERM, kernel_connect",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The syscall interface,['socket like programs']
5c0b485a8c6116516f33925b9ce5b6104a6eadfd,5c0b485a8c6116516f33925b9ce5b6104a6eadfd,Kuniyuki Iwashima,kuniyu@amazon.com,1720552436,Paolo Abeni,pabeni@redhat.com,1720690107,a7057ed431435f8d8b7c6a45859e476dea334cab,c184cf94e73b04ff7048d045f5413899bc664788,"udp: Set SOCK_RCU_FREE earlier in udp_lib_get_port().

syzkaller triggered the warning [0] in udp_v4_early_demux().

In udp_v[46]_early_demux() and sk_lookup()"," we do not touch the refcount
of the looked-up sk and use sock_pfree() as skb->destructor","[' so we check\nSOCK_RCU_FREE to ensure that the sk is safe to access during the RCU grace\nperiod.\n\nCurrently', ' SOCK_RCU_FREE is flagged for a bound socket after being put\ninto the hash table.  Moreover', ' the SOCK_RCU_FREE check is done too early\nin udp_v[46]_early_demux() and sk_lookup()', ' so there could be a small race\nwindow:\n\n  CPU1                                 CPU2\n  ----                                 ----\n  udp_v4_early_demux()                 udp_lib_get_port()\n  |                                    |- hlist_add_head_rcu()\n  |- sk = __udp4_lib_demux_lookup()    |\n  |- DEBUG_NET_WARN_ON_ONCE(sk_is_refcounted(sk));\n                                       `- sock_set_flag(sk', ' SOCK_RCU_FREE)\n\nWe had the same bug in TCP and fixed it in commit 871019b22d1b (""net:\nset SOCK_RCU_FREE before inserting socket into hashtable"").\n\nLet\'s apply the same fix for UDP.\n\n[0]:\nWARNING: CPU: 0 PID: 11198 at net/ipv4/udp.c:2599 udp_v4_early_demux+0x481/0xb70 net/ipv4/udp.c:2599\nModules linked in:\nCPU: 0 PID: 11198 Comm: syz-executor.1 Not tainted 6.9.0-g93bda33046e7 #13\nHardware name: QEMU Standard PC (i440FX + PIIX', ' 1996)', ' BIOS rel-1.16.0-0-gd239552ce722-prebuilt.qemu.org 04/01/2014\nRIP: 0010:udp_v4_early_demux+0x481/0xb70 net/ipv4/udp.c:2599\nCode: c5 7a 15 fe bb 01 00 00 00 44 89 e9 31 ff d3 e3 81 e3 bf ef ff ff 89 de e8 2c 74 15 fe 85 db 0f 85 02 06 00 00 e8 9f 7a 15 fe <0f> 0b e8 98 7a 15 fe 49 8d 7e 60 e8 4f 39 2f fe 49 c7 46 60 20 52\nRSP: 0018:ffffc9000ce3fa58 EFLAGS: 00010293\nRAX: 0000000000000000 RBX: 0000000000000000 RCX: ffffffff8318c92c\nRDX: ffff888036ccde00 RSI: ffffffff8318c2f1 RDI: 0000000000000001\nRBP: ffff88805a2dd6e0 R08: 0000000000000001 R09: 0000000000000000\nR10: 0000000000000000 R11: 0001ffffffffffff R12: ffff88805a2dd680\nR13: 0000000000000007 R14: ffff88800923f900 R15: ffff88805456004e\nFS:  00007fc449127640(0000) GS:ffff88807dc00000(0000) knlGS:0000000000000000\nCS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\nCR2: 00007fc449126e38 CR3: 000000003de4b002 CR4: 0000000000770ef0\nDR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\nDR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000600\nPKRU: 55555554\nCall Trace:\n <TASK>\n ip_rcv_finish_core.constprop.0+0xbdd/0xd20 net/ipv4/ip_input.c:349\n ip_rcv_finish+0xda/0x150 net/ipv4/ip_input.c:447\n NF_HOOK include/linux/netfilter.h:314 [inline]\n NF_HOOK include/linux/netfilter.h:308 [inline]\n ip_rcv+0x16c/0x180 net/ipv4/ip_input.c:569\n __netif_receive_skb_one_core+0xb3/0xe0 net/core/dev.c:5624\n __netif_receive_skb+0x21/0xd0 net/core/dev.c:5738\n netif_receive_skb_internal net/core/dev.c:5824 [inline]\n netif_receive_skb+0x271/0x300 net/core/dev.c:5884\n tun_rx_batched drivers/net/tun.c:1549 [inline]\n tun_get_user+0x24db/0x2c50 drivers/net/tun.c:2002\n tun_chr_write_iter+0x107/0x1a0 drivers/net/tun.c:2048\n new_sync_write fs/read_write.c:497 [inline]\n vfs_write+0x76f/0x8d0 fs/read_write.c:590\n ksys_write+0xbf/0x190 fs/read_write.c:643\n __do_sys_write fs/read_write.c:655 [inline]\n __se_sys_write fs/read_write.c:652 [inline]\n __x64_sys_write+0x41/0x50 fs/read_write.c:652\n x64_sys_call+0xe66/0x1990 arch/x86/include/generated/asm/syscalls_64.h:2\n do_syscall_x64 arch/x86/entry/common.c:52 [inline]\n do_syscall_64+0x4b/0x110 arch/x86/entry/common.c:83\n entry_SYSCALL_64_after_hwframe+0x4b/0x53\nRIP: 0033:0x7fc44a68bc1f\nCode: 89 54 24 18 48 89 74 24 10 89 7c 24 08 e8 e9 cf f5 ff 48 8b 54 24 18 48 8b 74 24 10 41 89 c0 8b 7c 24 08 b8 01 00 00 00 0f 05 <48> 3d 00 f0 ff ff 77 31 44 89 c7 48 89 44 24 08 e8 3c d0 f5 ff 48\nRSP: 002b:00007fc449126c90 EFLAGS: 00000293 ORIG_RAX: 0000000000000001\nRAX: ffffffffffffffda RBX: 00000000004bc050 RCX: 00007fc44a68bc1f\nRDX: 0000000000000032 RSI: 00000000200000c0 RDI: 00000000000000c8\nRBP: 00000000004bc050 R08: 0000000000000000 R09: 0000000000000000\nR10: 0000000000000032 R11: 0000000000000293 R12: 0000000000000000\nR13: 000000000000000b R14: 00007fc44a5ec530 R15: 0000000000000000\n </TASK>\n\nFixes: 6acc9b432e67 (""bpf: Add helper to retrieve socket in BPF"")\nReported-by: syzkaller <syzkaller@googlegroups.com>\nSigned-off-by: Kuniyuki Iwashima <kuniyu@amazon.com>\nReviewed-by: Eric Dumazet <edumazet@google.com>\nLink: https://patch.msgid.link/20240709191356.24010-1-kuniyu@amazon.com\nSigned-off-by: Paolo Abeni <pabeni@redhat.com>\n\n', '']",The commit sets SOCK_RCU_FREE earlier in udp_lib_get_port to address a syzkaller-triggered warning.,"udp, SOCK_RCU_FREE, syzkaller",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
50bd5a0c658d132507673c4d59347c025dd149ed,50bd5a0c658d132507673c4d59347c025dd149ed,Kumar Kartikeya Dwivedi,memxor@gmail.com,1720675629,Daniel Borkmann,daniel@iogearbox.net,1720685911,065eafc4e3328e68157f744c675c1e6f749bd316,0c237341d994adbafed2a0d372275de39efa4a98,"selftests/bpf: Add timer lockup selftest

Add a selftest that tries to trigger a situation where two timer callbacks
are attempting to cancel each other's timer. By running them continuously","
we hit a condition where both run in parallel and cancel each other.

Without the fix in the previous patch","[' this would cause a lockup as\nhrtimer_cancel on either side will wait for forward progress from the\ncallback.\n\nEnsure that this situation leads to a EDEADLK error.\n\nSigned-off-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240711052709.2148616-1-memxor@gmail.com\n', '']",Add a selftest to trigger timer lockup by running conflicting timer callbacks.,"selftests,bpf,timer",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
fde318326daa48a4bb3ca8ee229bac4d14b5bc2a,fde318326daa48a4bb3ca8ee229bac4d14b5bc2a,Artem Savkov,asavkov@redhat.com,1715932610,Michael Ellerman,mpe@ellerman.id.au,1720676421,7c99b2a67cb7a15ab6ced905335734f58e0f65c1,597b1710982d10b8629697e4a548b30d0d93eeed,"powerpc64/bpf: jit support for signed division and modulo

Add jit support for sign division and modulo. Tested using test_bpf
module.

Signed-off-by: Artem Savkov <asavkov@redhat.com>
Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
Link: https://msgid.link/20240517075650.248801-6-asavkov@redhat.com

",,Add JIT support for signed division and modulo in powerpc64 architecture.,"JIT,signed division,modulo",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
597b1710982d10b8629697e4a548b30d0d93eeed,597b1710982d10b8629697e4a548b30d0d93eeed,Artem Savkov,asavkov@redhat.com,1715932609,Michael Ellerman,mpe@ellerman.id.au,1720676421,f705f2a02c67746b5d15f95c5297afcc64f2ee8b,717756c9c8ddad9f28389185bfb161d4d88e01a4,"powerpc64/bpf: jit support for sign extended mov

Add jit support for sign extended mov. Tested using test_bpf module.

Signed-off-by: Artem Savkov <asavkov@redhat.com>
Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
Link: https://msgid.link/20240517075650.248801-5-asavkov@redhat.com

",,Add JIT support for sign extended move on PowerPC64 architecture.,"jit support,powerpc64,sign extended",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
717756c9c8ddad9f28389185bfb161d4d88e01a4,717756c9c8ddad9f28389185bfb161d4d88e01a4,Artem Savkov,asavkov@redhat.com,1715932608,Michael Ellerman,mpe@ellerman.id.au,1720676421,38e19f3c3c6bdda7ad61d02b0df126825c8368ae,a71c0b09a14db72d59c48a8cda7a73032f4d418b,"powerpc64/bpf: jit support for sign extended load

Add jit support for sign extended load. Tested using test_bpf module.

Signed-off-by: Artem Savkov <asavkov@redhat.com>
Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
Link: https://msgid.link/20240517075650.248801-4-asavkov@redhat.com

",,Added JIT support for sign extended load on powerpc64 architecture.,"JIT,powerpc64,sign-extended",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a71c0b09a14db72d59c48a8cda7a73032f4d418b,a71c0b09a14db72d59c48a8cda7a73032f4d418b,Artem Savkov,asavkov@redhat.com,1715932607,Michael Ellerman,mpe@ellerman.id.au,1720676421,eadec4d61cd27bd13effbdfdfaa128179c3f78c7,3c086ce222cefcf16d412faa10d456161d076796,"powerpc64/bpf: jit support for unconditional byte swap

Add jit support for unconditional byte swap. Tested using BSWAP tests
from test_bpf module.

Signed-off-by: Artem Savkov <asavkov@redhat.com>
Reviewed-by: Hari Bathini <hbathini@linux.ibm.com>
Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
Link: https://msgid.link/20240517075650.248801-3-asavkov@redhat.com

",,Add JIT support for unconditional byte swap on powerpc64 architecture.,"JIT,support,byte swap",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3c086ce222cefcf16d412faa10d456161d076796,3c086ce222cefcf16d412faa10d456161d076796,Artem Savkov,asavkov@redhat.com,1715932606,Michael Ellerman,mpe@ellerman.id.au,1720676420,7319c0f53ef230d60374d1b20c82b1199600db42,20ce0c247b2500cb7060cb115274ba71abda2626,"powerpc64/bpf: jit support for 32bit offset jmp instruction

Add jit support for JMP32_JA instruction. Tested using test_bpf module.

Signed-off-by: Artem Savkov <asavkov@redhat.com>
Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
Link: https://msgid.link/20240517075650.248801-2-asavkov@redhat.com

",,Added JIT support for 32-bit JMP32_JA instruction on powerpc64 architecture.,"jit,powerpc64,instruction",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,['tracepoints like programs']
0c237341d994adbafed2a0d372275de39efa4a98,0c237341d994adbafed2a0d372275de39efa4a98,Alexei Starovoitov,ast@kernel.org,1720652385,Alexei Starovoitov,ast@kernel.org,1720653616,6d3e8d438b7174e4ab71c781642bc946d3a84752,af253aef183a31ce62d2e39fc520b0ebfb562bb9 a6fcd19d7eac1335eb76bc16b6a66b7f574d1d69,"Merge branch 'fixes-for-bpf-timer-lockup-and-uaf'

Kumar Kartikeya Dwivedi says:

====================
Fixes for BPF timer lockup and UAF

The following patches contain fixes for timer lockups and a
use-after-free scenario.

This set proposes to fix the following lockup situation for BPF timers.

CPU 1					CPU 2

bpf_timer_cb				bpf_timer_cb
  timer_cb1				  timer_cb2
    bpf_timer_cancel(timer_cb2)		    bpf_timer_cancel(timer_cb1)
      hrtimer_cancel			      hrtimer_cancel

In this case"," both callbacks will continue waiting for each other to
finish synchronously","[' causing a lockup.\n\nThe proposed fix adds support for tracking in-flight cancellations\n*begun by other timer callbacks* for a particular BPF timer.  Whenever\npreparing to call hrtimer_cancel', "" a callback will increment the target\ntimer's counter"", ' then inspect its in-flight cancellations', ' and if\nnon-zero', "" return -EDEADLK to avoid situations where the target timer's\ncallback is waiting for its completion.\n\nThis does mean that in cases where a callback is fired and cancelled"", ' it\nwill be unable to cancel any timers in that execution. This can be\nalleviated by maintaining the list of waiting callbacks in bpf_hrtimer\nand searching through it to avoid interdependencies', ' but this may\nintroduce additional delays in bpf_timer_cancel', ' in addition to\nrequiring extra state at runtime which may need to be allocated or\nreused from bpf_hrtimer storage. Moreover', ' extra synchronization is\nneeded to delete these elements from the list of waiting callbacks once\nhrtimer_cancel has finished.\n\nThe second patch is for a deadlock situation similar to above in\nbpf_timer_cancel_and_free', ' but also a UAF scenario that can occur if\ntimer is armed before entering it', ' if hrtimer_running check causes the\nhrtimer_cancel call to be skipped.\n\nAs seen above', ' synchronous hrtimer_cancel would lead to deadlock (if\nsame callback tries to free its timer', ' or two timers free each other)', '\ntherefore we queue work onto the global workqueue to ensure outstanding\ntimers are cancelled before bpf_hrtimer state is freed.\n\nFurther details are in the patches.\n====================\n\nLink: https://lore.kernel.org/r/20240709185440.1104957-1-memxor@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes for timer lockups and use-after-free issues in BPF timers.,"BPF,timer,lockup",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a6fcd19d7eac1335eb76bc16b6a66b7f574d1d69,a6fcd19d7eac1335eb76bc16b6a66b7f574d1d69,Kumar Kartikeya Dwivedi,memxor@gmail.com,1720551279,Alexei Starovoitov,ast@kernel.org,1720652384,6d3e8d438b7174e4ab71c781642bc946d3a84752,d4523831f07a267a943f0dde844bf8ead7495f13,"bpf: Defer work in bpf_timer_cancel_and_free

Currently"," the same case as previous patch (two timer callbacks trying
to cancel each other) can be invoked through bpf_map_update_elem as
well","[' or more precisely', ' freeing map elements containing timers. Since\nthis relies on hrtimer_cancel as well', ' it is prone to the same deadlock\nsituation as the previous patch.\n\nIt would be sufficient to use hrtimer_try_to_cancel to fix this problem', '\nas the timer cannot be enqueued after async_cancel_and_free. Once\nasync_cancel_and_free has been done', ' the timer must be reinitialized\nbefore it can be armed again. The callback running in parallel trying to\narm the timer will fail', ' and freeing bpf_hrtimer without waiting is\nsufficient (given kfree_rcu)', ' and bpf_timer_cb will return\nHRTIMER_NORESTART', ' preventing the timer from being rearmed again.\n\nHowever', ' there exists a UAF scenario where the callback arms the timer\nbefore entering this function', ' such that if cancellation fails (due to\ntimer callback invoking this routine', ' or the target timer callback\nrunning concurrently). In such a case', ' if the timer expiration is\nsignificantly far in the future', ' the RCU grace period expiration\nhappening before it will free the bpf_hrtimer state and along with it\nthe struct hrtimer', ' that is enqueued.\n\nHence', ' it is clear cancellation needs to occur after\nasync_cancel_and_free', ' and yet it cannot be done inline due to deadlock\nissues. We thus modify bpf_timer_cancel_and_free to defer work to the\nglobal workqueue', ' adding a work_struct alongside rcu_head (both used at\n_different_ points of time', ' so can share space).\n\nUpdate existing code comments to reflect the new state of affairs.\n\nFixes: b00628b1c7d5 (""bpf: Introduce bpf timers."")\nSigned-off-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nLink: https://lore.kernel.org/r/20240709185440.1104957-3-memxor@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit defers work in bpf_timer_cancel_and_free to handle timer callback conflicts through bpf_map_update_elem.,"bpf_timer,defer,callback",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d4523831f07a267a943f0dde844bf8ead7495f13,d4523831f07a267a943f0dde844bf8ead7495f13,Kumar Kartikeya Dwivedi,memxor@gmail.com,1720551278,Alexei Starovoitov,ast@kernel.org,1720652384,83d27006347ba36a310db5c375ca3e080aa900e7,af253aef183a31ce62d2e39fc520b0ebfb562bb9,"bpf: Fail bpf_timer_cancel when callback is being cancelled

Given a schedule:

timer1 cb			timer2 cb

bpf_timer_cancel(timer2);	bpf_timer_cancel(timer1);

Both bpf_timer_cancel calls would wait for the other callback to finish
executing"," introducing a lockup.

Add an atomic_t count named 'cancelling' in bpf_hrtimer. This keeps
track of all in-flight cancellation requests for a given BPF timer.
Whenever cancelling a BPF timer","[' we must check if we have outstanding\ncancellation requests', ' and if so', ' we must fail the operation with an\nerror (-EDEADLK) since cancellation is synchronous and waits for the\ncallback to finish executing. This implies that we can enter a deadlock\nsituation involving two or more timer callbacks executing in parallel\nand attempting to cancel one another.\n\nNote that we avoid incrementing the cancelling counter for the target\ntimer (the one being cancelled) if bpf_timer_cancel is not invoked from\na callback', ' to avoid spurious errors. The whole point of detecting\ncur->cancelling and returning -EDEADLK is to not enter a busy wait loop\n(which may or may not lead to a lockup). This does not apply in case the\ncaller is in a non-callback context', "" the other side can continue to\ncancel as it sees fit without running into errors.\n\nBackground on prior attempts:\n\nEarlier versions of this patch used a bool 'cancelling' bit and used the\nfollowing pattern under timer->lock to publish cancellation status.\n\nlock(t->lock);\nt->cancelling = true;\nmb();\nif (cur->cancelling)\n\treturn -EDEADLK;\nunlock(t->lock);\nhrtimer_cancel(t->timer);\nt->cancelling = false;\n\nThe store outside the critical section could overwrite a parallel\nrequests t->cancelling assignment to true"", ' to ensure the parallely\nexecuting callback observes its cancellation status.\n\nIt would be necessary to clear this cancelling bit once hrtimer_cancel\nis done', ' but lack of serialization introduced races. Another option was\nexplored where bpf_timer_start would clear the bit when (re)starting the\ntimer under timer->lock. This would ensure serialized access to the\ncancelling bit', ' but may allow it to be cleared before in-flight\nhrtimer_cancel has finished executing', ' such that lockups can occur\nagain.\n\nThus', ' we choose an atomic counter to keep track of all outstanding\ncancellation requests and use it to prevent lockups in case callbacks\nattempt to cancel each other while executing in parallel.\n\nReported-by: Dohyun Kim <dohyunkim@google.com>\nReported-by: Neel Natu <neelnatu@google.com>\nFixes: b00628b1c7d5 (""bpf: Introduce bpf timers."")\nSigned-off-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nLink: https://lore.kernel.org/r/20240709185440.1104957-2-memxor@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit addresses a race condition in bpf_timer_cancel by introducing an atomic count for cancellation requests.,"bpf_timer_cancel, atomic_t count, cancellation",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
af253aef183a31ce62d2e39fc520b0ebfb562bb9,af253aef183a31ce62d2e39fc520b0ebfb562bb9,Mohammad Shehar Yaar Tausif,sheharyaar48@gmail.com,1720605922,Alexei Starovoitov,ast@kernel.org,1720650679,6a534295d84092d9f9bc6f1d1bef7e5519fe25e0,e1533b6319ab9c3a97dad314dd88b3783bc41b69,"bpf: fix order of args in call to bpf_map_kvcalloc

The original function call passed size of smap->bucket before the number of
buckets which raises the error 'calloc-transposed-args' on compilation.

Vlastimil Babka added:

The order of parameters can be traced back all the way to 6ac99e8f23d4
(""bpf: Introduce bpf sk local storage"") accross several refactorings","
and that's why the commit is used as a Fixes: tag.

In v6.10-rc1","[' a different commit 2c321f3f70bc (""mm: change inlined\nallocation helpers to account at the call site"") however exposed the\norder of args in a way that gcc-14 has enough visibility to start\nwarning about it', ' because (in !CONFIG_MEMCG case) bpf_map_kvcalloc is\nthen a macro alias for kvcalloc instead of a static inline wrapper.\n\nTo sum up the warning happens when the following conditions are all met:\n\n- gcc-14 is used (didn\'t see it with gcc-13)\n- commit 2c321f3f70bc is present\n- CONFIG_MEMCG is not enabled in .config\n- CONFIG_WERROR turns this from a compiler warning to error\n\nFixes: 6ac99e8f23d4 (""bpf: Introduce bpf sk local storage"")\nReviewed-by: Andrii Nakryiko <andrii@kernel.org>\nTested-by: Christian Kujau <lists@nerdbynature.de>\nSigned-off-by: Mohammad Shehar Yaar Tausif <sheharyaar48@gmail.com>\nSigned-off-by: Vlastimil Babka <vbabka@suse.cz>\nLink: https://lore.kernel.org/r/20240710100521.15061-2-vbabka@suse.cz\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix incorrect argument order in bpf_map_kvcalloc call to resolve compilation error.,"bpf, kvcalloc, fix",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
18a8a4c88fb4c261f72a29b769c9463362d9687a,18a8a4c88fb4c261f72a29b769c9463362d9687a,Martin KaFai Lau,martin.lau@kernel.org,1720639412,Martin KaFai Lau,martin.lau@kernel.org,1720640708,e4ffff63ddf62529c15e0980cadfe67875d7ccae,ec5b8c76ab1c6d163762d60cfbedcd27e7527144 52b49ec1b2c78deb258596c3b231201445ef5380,"Merge branch 'BPF selftests misc fixes'

Geliang Tang says:

====================
v2:
 - only check the first ""link"" (link_nl) in test_mixed_links().
 - Drop patch 2 in v1.

This patchset fixes a segfault and a bpf object leak in test_progs.

It is a resend patch 1 out of ""skip ENOTSUPP BPF selftests"" set as Eduard
suggested. Together with another fix for xdp_adjust_tail.
====================

Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,The commit merges fixes for BPF selftests including a segfault and a BPF object leak issue.,"BPF selftests, segfault, object leak",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['xdp like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
52b49ec1b2c78deb258596c3b231201445ef5380,52b49ec1b2c78deb258596c3b231201445ef5380,Geliang Tang,tanggeliang@kylinos.cn,1720617017,Martin KaFai Lau,martin.lau@kernel.org,1720640570,e4ffff63ddf62529c15e0980cadfe67875d7ccae,eef0532e900c20a6760da829e82dac3ee18688c5,"selftests/bpf: Close obj in error path in xdp_adjust_tail

If bpf_object__load() fails in test_xdp_adjust_frags_tail_grow()"," ""obj""
opened before this should be closed. So use ""goto out"" to close it instead
of using ""return"" here.

Fixes: 110221081aac (""bpf: selftests: update xdp_adjust_tail selftest to include xdp frags"")
Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/f282a1ed2d0e3fb38cceefec8e81cabb69cab260.1720615848.git.tanggeliang@kylinos.cn
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Fixes error handling in xdp_adjust_tail selftest by ensuring proper closure of object in error path.,"selftests, xdp_adjust_tail, error",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['xdp like programs']
eef0532e900c20a6760da829e82dac3ee18688c5,eef0532e900c20a6760da829e82dac3ee18688c5,Geliang Tang,tanggeliang@kylinos.cn,1720617016,Martin KaFai Lau,martin.lau@kernel.org,1720640118,9a6519e43c3f9d0d2a4e4a2fd9cc38a3d2d120a6,ec5b8c76ab1c6d163762d60cfbedcd27e7527144,"selftests/bpf: Null checks for links in bpf_tcp_ca

Run bpf_tcp_ca selftests (./test_progs -t bpf_tcp_ca) on a Loongarch
platform"," some ""Segmentation fault"" errors occur:

'''
 test_dctcp:PASS:bpf_dctcp__open_and_load 0 nsec
 test_dctcp:FAIL:bpf_map__attach_struct_ops unexpected error: -524
 #29/1    bpf_tcp_ca/dctcp:FAIL
 test_cubic:PASS:bpf_cubic__open_and_load 0 nsec
 test_cubic:FAIL:bpf_map__attach_struct_ops unexpected error: -524
 #29/2    bpf_tcp_ca/cubic:FAIL
 test_dctcp_fallback:PASS:dctcp_skel 0 nsec
 test_dctcp_fallback:PASS:bpf_dctcp__load 0 nsec
 test_dctcp_fallback:FAIL:dctcp link unexpected error: -524
 #29/4    bpf_tcp_ca/dctcp_fallback:FAIL
 test_write_sk_pacing:PASS:open_and_load 0 nsec
 test_write_sk_pacing:FAIL:attach_struct_ops unexpected error: -524
 #29/6    bpf_tcp_ca/write_sk_pacing:FAIL
 test_update_ca:PASS:open 0 nsec
 test_update_ca:FAIL:attach_struct_ops unexpected error: -524
 settcpca:FAIL:setsockopt unexpected setsockopt: \
					actual -1 == expected -1
 (network_helpers.c:99: errno: No such file or directory) \
					Failed to call post_socket_cb
 start_test:FAIL:start_server_str unexpected start_server_str: \
					actual -1 == expected -1
 test_update_ca:FAIL:ca1_ca1_cnt unexpected ca1_ca1_cnt: \
					actual 0 <= expected 0
 #29/9    bpf_tcp_ca/update_ca:FAIL
 #29      bpf_tcp_ca:FAIL
 Caught signal #11!
 Stack trace:
 ./test_progs(crash_handler+0x28)[0x5555567ed91c]
 linux-vdso.so.1(__vdso_rt_sigreturn+0x0)[0x7ffffee408b0]
 ./test_progs(bpf_link__update_map+0x80)[0x555556824a78]
 ./test_progs(+0x94d68)[0x5555564c4d68]
 ./test_progs(test_bpf_tcp_ca+0xe8)[0x5555564c6a88]
 ./test_progs(+0x3bde54)[0x5555567ede54]
 ./test_progs(main+0x61c)[0x5555567efd54]
 /usr/lib64/libc.so.6(+0x22208)[0x7ffff2aaa208]
 /usr/lib64/libc.so.6(__libc_start_main+0xac)[0x7ffff2aaa30c]
 ./test_progs(_start+0x48)[0x55555646bca8]
 Segmentation fault
'''

This is because BPF trampoline is not implemented on Loongarch yet","['\n""link"" returned by bpf_map__attach_struct_ops() is NULL. test_progs\ncrashs when this NULL link passes to bpf_link__update_map(). This\npatch adds NULL checks for all links in bpf_tcp_ca to fix these errors.\nIf ""link"" is NULL', ' goto the newly added label ""out"" to destroy the skel.\n\nv2:\n - use ""goto out"" instead of ""return"" as Eduard suggested.\n\nFixes: 06da9f3bd641 (""selftests/bpf: Test switching TCP Congestion Control algorithms."")\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nReviewed-by: Alan Maguire <alan.maguire@oracle.com>\nLink: https://lore.kernel.org/r/b4c841492bd4ed97964e4e61e92827ce51bf1dc9.1720615848.git.tanggeliang@kylinos.cn\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Add null checks for links in bpf_tcp_ca selftests to address segmentation faults on Loongarch platform.,"null checks, segmentation fault, bpf_tcp_ca",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9004054b1629d481fedea2d92b880f79fc6fa81b,9004054b1629d481fedea2d92b880f79fc6fa81b,Geliang Tang,tanggeliang@kylinos.cn,1720516582,Martin KaFai Lau,martin.lau@kernel.org,1720637782,12b3e6845feb8f2fe2a2404a76dce3df324dddf1,d9810c43f660fd502c5003244a5e9c181aa7df99,"selftests/bpf: Use connect_fd_to_fd in sk_lookup

This patch uses public helper connect_fd_to_fd() exported in
network_helpers.h instead of using getsockname() + connect() in
run_lookup_prog() in prog_tests/sk_lookup.c. This can simplify
the code.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/7077c277cde5a1864cdc244727162fb75c8bb9c5.1720515893.git.tanggeliang@kylinos.cn
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Simplify sk_lookup test code by using connect_fd_to_fd helper.,"selftests,bpf,simplify",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
d9810c43f660fd502c5003244a5e9c181aa7df99,d9810c43f660fd502c5003244a5e9c181aa7df99,Geliang Tang,tanggeliang@kylinos.cn,1720516581,Martin KaFai Lau,martin.lau@kernel.org,1720637782,1719f50b8d553da3bec3cdce4164c6b27098f8d9,14fc6fcd35e7dde6d1de062b6711476b3050b22e,"selftests/bpf: Use start_server_addr in sk_lookup

This patch uses public helper start_server_addr() in udp_recv_send()
in prog_tests/sk_lookup.c to simplify the code.

And use ASSERT_OK_FD() to check fd returned by start_server_addr().

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/f11cabfef4a2170ecb66a1e8e2e72116d8f621b3.1720515893.git.tanggeliang@kylinos.cn
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Simplify sk_lookup test using start_server_addr helper in udp_recv_send function.,"selftests,bpf,start_server_addr",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
14fc6fcd35e7dde6d1de062b6711476b3050b22e,14fc6fcd35e7dde6d1de062b6711476b3050b22e,Geliang Tang,tanggeliang@kylinos.cn,1720516580,Martin KaFai Lau,martin.lau@kernel.org,1720637782,8750d217282a68aee7a2bf32b1d9c2b9eac8ace6,adae187ebedcd95d02f045bc37dfecfd5b29434b,"selftests/bpf: Use start_server_str in sk_lookup

This patch uses public helper start_server_str() to simplify make_server()
in prog_tests/sk_lookup.c.

Add a callback setsockopts() to do all sockopts"," set it to post_socket_cb
pointer of struct network_helper_opts. And add a new struct cb_opts to save
the data needed to pass to the callback. Then pass this network_helper_opts
to start_server_str().

Also use ASSERT_OK_FD() to check fd returned by start_server_str().

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/5981539f5591d2c4998c962ef2bf45f34c940548.1720515893.git.tanggeliang@kylinos.cn
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Simplified sk_lookup test by using start_server_str and added a callback for setsockopts.,"sk_lookup,selftests,callback",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['xdp like programs', 'socket like programs', 'tc/netfilter like programs']"
adae187ebedcd95d02f045bc37dfecfd5b29434b,adae187ebedcd95d02f045bc37dfecfd5b29434b,Geliang Tang,tanggeliang@kylinos.cn,1720516579,Martin KaFai Lau,martin.lau@kernel.org,1720637782,3ab1481259481e50f21d795c993963e829650550,7046345d48adcc3f519e7b6192184f6049908bdb,"selftests/bpf: Close fd in error path in drop_on_reuseport

In the error path when update_lookup_map() fails in drop_on_reuseport in
prog_tests/sk_lookup.c"," ""server1""","[' the fd of server 1', ' should be closed.\nThis patch fixes this by using ""goto close_srv1"" lable instead of ""detach""\nto close ""server1"" in this case.\n\nFixes: 0ab5539f8584 (""selftests/bpf: Tests for BPF_SK_LOOKUP attach point"")\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nLink: https://lore.kernel.org/r/86aed33b4b0ea3f04497c757845cff7e8e621a2d.1720515893.git.tanggeliang@kylinos.cn\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",This commit closes a file descriptor in the error path of drop_on_reuseport in selftests/bpf.,"fd, error path, drop_on_reuseport",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7046345d48adcc3f519e7b6192184f6049908bdb,7046345d48adcc3f519e7b6192184f6049908bdb,Geliang Tang,tanggeliang@kylinos.cn,1720516578,Martin KaFai Lau,martin.lau@kernel.org,1720637782,0a2353722c4176f2477d6502148c250855d955bd,a3016a27cea8e6d10b200b9e19c19961c402d106,"selftests/bpf: Add ASSERT_OK_FD macro

Add a new dedicated ASSERT macro ASSERT_OK_FD to test whether a socket
FD is valid or not. It can be used to replace macros ASSERT_GT(fd", 0,"[' """")', '\nASSERT_NEQ(fd', ' -1', ' """") or statements (fd < 0)', ' (fd != -1).\n\nSuggested-by: Martin KaFai Lau <martin.lau@kernel.org>\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nLink: https://lore.kernel.org/r/ded75be86ac630a3a5099739431854c1ec33f0ea.1720515893.git.tanggeliang@kylinos.cn\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Add ASSERT_OK_FD macro to validate socket file descriptors in BPF selftests.,"ASSERT_OK_FD,socket FD,selftests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
a3016a27cea8e6d10b200b9e19c19961c402d106,a3016a27cea8e6d10b200b9e19c19961c402d106,Geliang Tang,tanggeliang@kylinos.cn,1720516577,Martin KaFai Lau,martin.lau@kernel.org,1720637782,99c9cd6f12b6c9090379c6872f2930b108617f4e,eeb23b54e447ea62b247d89681f0140abab00d7f,"selftests/bpf: Add backlog for network_helper_opts

Some callers expect __start_server() helper to pass their own ""backlog""
value to listen() instead of the default of 1. So this patch adds struct
member ""backlog"" for network_helper_opts to allow callers to set ""backlog""
value via start_server_str() helper.

listen(fd"," 0 /* backlog */) can be used to enforce syncookie. Meaning
backlog 0 is a legit value.

Using 0 as a default and changing it to 1 here is fine. It makes the test
program easier to write for the common case. Enforcing syncookie mode by
using backlog 0 is a niche use case but it should at least have a way for
the caller to do that. Thus","[' -ve backlog value is used here for the\nsyncookie use case. Please see the comment in network_helpers.h for\nthe details.\n\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nLink: https://lore.kernel.org/r/1660229659b66eaad07aa2126e9c9fe217eba0dd.1720515893.git.tanggeliang@kylinos.cn\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Add 'backlog' member to network_helper_opts to allow custom 'backlog' settings via start_server_str() helper in selftests.,"selftests,backlog,network_helper_opts",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
eeb23b54e447ea62b247d89681f0140abab00d7f,eeb23b54e447ea62b247d89681f0140abab00d7f,Alan Maguire,alan.maguire@oracle.com,1720623651,Alexei Starovoitov,ast@kernel.org,1720636787,28585ec9c678fefd1bf61306ac24782ce77478b3,c13fda93aca118b8e5cd202e339046728ee7dddb,"selftests/bpf: fix compilation failure when CONFIG_NF_FLOW_TABLE=m

In many cases"," kernel netfilter functionality is built as modules.
If CONFIG_NF_FLOW_TABLE=m in particular","[' progs/xdp_flowtable.c\n(and hence selftests) will fail to compile', ' so add a ___local\nversion of ""struct flow_ports"".\n\nFixes: c77e572d3a8c (""selftests/bpf: Add selftest for bpf_xdp_flow_lookup kfunc"")\nSigned-off-by: Alan Maguire <alan.maguire@oracle.com>\nLink: https://lore.kernel.org/r/20240710150051.192598-1-alan.maguire@oracle.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixed compilation issue for selftests when CONFIG_NF_FLOW_TABLE is modular.,"compilation, selftests, fix",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c13fda93aca118b8e5cd202e339046728ee7dddb,c13fda93aca118b8e5cd202e339046728ee7dddb,Sebastian Andrzej Siewior,bigeasy@linutronix.de,1720620991,Martin KaFai Lau,martin.lau@kernel.org,1720630732,e9b50594237f91eac6a7372ed2509b514d7f599d,605c96997d89c01c11bbddb4db820ede570581c7,"bpf: Remove tst_run from lwt_seg6local_prog_ops.

The syzbot reported that the lwt_seg6 related BPF ops can be invoked
via bpf_test_run() without without entering input_action_end_bpf()
first.

Martin KaFai Lau said that self test for BPF_PROG_TYPE_LWT_SEG6LOCAL
probably didn't work since it was introduced in commit 04d4b274e2a
(""ipv6: sr: Add seg6local action End.BPF""). The reason is that the
per-CPU variable seg6_bpf_srh_states::srh is never assigned in the self
test case but each BPF function expects it.

Remove test_run for BPF_PROG_TYPE_LWT_SEG6LOCAL.

Suggested-by: Martin KaFai Lau <martin.lau@linux.dev>
Reported-by: syzbot+608a2acde8c5a101d07d@syzkaller.appspotmail.com
Fixes: d1542d4ae4df (""seg6: Use nested-BH locking for seg6_bpf_srh_states."")
Fixes: 004d4b274e2a (""ipv6: sr: Add seg6local action End.BPF"")
Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Acked-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/r/20240710141631.FbmHcQaX@linutronix.de
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Remove unsupported test run from lwt_seg6local BPF ops due to missing initialization.,"lwt_seg6local,BPF,remove",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
0dd0e9437f8e500a384f12ec16bb407a49676147,0dd0e9437f8e500a384f12ec16bb407a49676147,Arnd Bergmann,arnd@arndb.de,1715620435,Arnd Bergmann,arnd@arndb.de,1720614210,f06caeb67285b6f4cdfb258d42ea0da4306e6aa1,ed8023ae9d79eeebf694751d5c290b72ef871dc0,"um: don't generate asm/bpf_perf_event.h

If we start validating the existence of the asm-generic side of
generated headers"," this one causes a warning:

make[3]: *** No rule to make target 'arch/um/include/generated/asm/bpf_perf_event.h'","["" needed by 'all'.  Stop.\n\nThe problem is that the asm-generic header only exists for the uapi\nvariant"", ' but arch/um has no uapi headers and instead uses the x86\nuserspace API.\n\nAdd a custom file with an explicit redirect to avoid this.\n\nSigned-off-by: Arnd Bergmann <arnd@arndb.de>\n', '']",Prevent generation of asm/bpf_perf_event.h to avoid build errors in User Mode Linux.,"generate, bpf_perf_event, warning",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
605c96997d89c01c11bbddb4db820ede570581c7,605c96997d89c01c11bbddb4db820ede570581c7,Matt Bobrowski,mattbobrowski@google.com,1720559379,Alexei Starovoitov,ast@kernel.org,1720577507,24a3417677e3bb1f26bd9e9658eb65b3e9f37f2a,02779af2419a91f847c22e488f8d13ec301cf833,"bpf: relax zero fixed offset constraint on KF_TRUSTED_ARGS/KF_RCU

Currently"," BPF kfuncs which accept trusted pointer arguments
i.e. those flagged as KF_TRUSTED_ARGS","[' KF_RCU', ' or KF_RELEASE', ' all\nrequire an original/unmodified trusted pointer argument to be supplied\nto them. By original/unmodified', ' it means that the backing register\nholding the trusted pointer argument that is to be supplied to the BPF\nkfunc must have its fixed offset set to zero', ' or else the BPF verifier\nwill outright reject the BPF program load. However', ' this zero fixed\noffset constraint that is currently enforced by the BPF verifier onto\nBPF kfuncs specifically flagged to accept KF_TRUSTED_ARGS or KF_RCU\ntrusted pointer arguments is rather unnecessary', ' and can limit their\nusability in practice. Specifically', ' it completely eliminates the\npossibility of constructing a derived trusted pointer from an original\ntrusted pointer. To put it simply', ' a derived pointer is a pointer\nwhich points to one of the nested member fields of the object being\npointed to by the original trusted pointer.\n\nThis patch relaxes the zero fixed offset constraint that is enforced\nupon BPF kfuncs which specifically accept KF_TRUSTED_ARGS', ' or KF_RCU\narguments. Although', ' the zero fixed offset constraint technically also\napplies to BPF kfuncs accepting KF_RELEASE arguments', "" relaxing this\nconstraint for such BPF kfuncs has subtle and unwanted\nside-effects. This was discovered by experimenting a little further\nwith an initial version of this patch series [0]. The primary issue\nwith relaxing the zero fixed offset constraint on BPF kfuncs accepting\nKF_RELEASE arguments is that it'd would open up the opportunity for\nBPF programs to supply both trusted pointers and derived trusted\npointers to them. For KF_RELEASE BPF kfuncs specifically"", ' this could\nbe problematic as resources associated with the backing pointer could\nbe released by the backing BPF kfunc and cause instabilities for the\nrest of the kernel.\n\nWith this new fixed offset semantic in-place for BPF kfuncs accepting\nKF_TRUSTED_ARGS and KF_RCU arguments', "" we now have more flexibility\nwhen it comes to the BPF kfuncs that we're able to introduce moving\nforward.\n\nEarly discussions covering the possibility of relaxing the zero fixed\noffset constraint can be found using the link below. This will provide\nmore context on where all this has stemmed from [1].\n\nNotably"", ' pre-existing tests have been updated such that they provide\ncoverage for the updated zero fixed offset\nfunctionality. Specifically', ' the nested offset test was converted from\na negative to positive test as it was already designed to assert zero\nfixed offset semantics of a KF_TRUSTED_ARGS BPF kfunc.\n\n[0] https://lore.kernel.org/bpf/ZnA9ndnXKtHOuYMe@google.com/\n[1] https://lore.kernel.org/bpf/ZhkbrM55MKQ0KeIV@google.com/\n\nSigned-off-by: Matt Bobrowski <mattbobrowski@google.com>\nAcked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nLink: https://lore.kernel.org/r/20240709210939.1544011-1-mattbobrowski@google.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit relaxes the zero fixed offset constraint on KF_TRUSTED_ARGS and KF_RCU in eBPF kfuncs.,"KF_TRUSTED_ARGS,KF_RCU,eBPF",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
02779af2419a91f847c22e488f8d13ec301cf833,02779af2419a91f847c22e488f8d13ec301cf833,Alexei Starovoitov,ast@kernel.org,1720576825,Alexei Starovoitov,ast@kernel.org,1720577016,e4a4e77fe98c18d7efda89eabd3de9fd9d8bc962,746d684ea579927015cde53cff8fc365caaf93b7 a459f4bb27f2e2730039c57786b82288742c8c74,"Merge branch 'fix-libbpf-bpf-skeleton-forward-backward-compat'

Andrii Nakryiko says:

====================
Fix libbpf BPF skeleton forward/backward compat

Fix recently identified (but long standing) bug with handling BPF skeleton
forward and backward compatibility. On libbpf side"," even though BPF skeleton
was always designed to be forward and backwards compatible through recording
actual size of constrituents of BPF skeleton itself (map/prog/var skeleton
definitions)","[' libbpf implementation did implicitly hard-code those sizes by\nvirtue of using a trivial array access syntax.\n\nThis issue will only affect libbpf used as a shared library. Statically\ncompiled libbpfs will always be in sync with BPF skeleton', ' bypassing this\nproblem altogether.\n\nThis patch set fixes libbpf', ' but also mitigates the problem for old libbpf\nversions by teaching bpftool to generate more conservative BPF skeleton', '\nif possible (i.e.', ' if there are no struct_ops maps defined).\n\nv1->v2:\n  - fix SOB', ' add acks', ' typo fixes (Quentin', ' Eduard);\n  - improve reporting of skipped map auto-attachment (Alan', ' Eduard).\n====================\n\nLink: https://lore.kernel.org/r/20240708204540.4188946-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes a bug in libbpf for BPF skeleton forward and backward compatibility.,"libbpf, BPF skeleton, compatibility",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a459f4bb27f2e2730039c57786b82288742c8c74,a459f4bb27f2e2730039c57786b82288742c8c74,Andrii Nakryiko,andrii@kernel.org,1720471540,Alexei Starovoitov,ast@kernel.org,1720577016,e4a4e77fe98c18d7efda89eabd3de9fd9d8bc962,99fb9531886d8ffa0aa9a693089784c7338518a3,"libbpf: improve old BPF skeleton handling for map auto-attach

Improve how we handle old BPF skeletons when it comes to BPF map
auto-attachment. Emit one warn-level message per each struct_ops map
that could have been auto-attached"," if user provided recent enough BPF
skeleton version. Don't spam log if there are no relevant struct_ops
maps","[' though.\n\nThis should help users realize that they probably need to regenerate BPF\nskeleton header with more recent bpftool/libbpf-cargo (or whatever other\nmeans of BPF skeleton generation).\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20240708204540.4188946-4-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Improved handling of old BPF skeletons for map auto-attachment in libbpf.,"libbpf, BPF skeleton, auto-attachment",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['tc/netfilter like programs', 'tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
99fb9531886d8ffa0aa9a693089784c7338518a3,99fb9531886d8ffa0aa9a693089784c7338518a3,Andrii Nakryiko,andrii@kernel.org,1720471539,Alexei Starovoitov,ast@kernel.org,1720577004,a856c10798e8726c0240720567b40541be851b52,06e71ad534881d2a09ced7509d2ab0daedac4c96,"libbpf: fix BPF skeleton forward/backward compat handling

BPF skeleton was designed from day one to be extensible. Generated BPF
skeleton code specifies actual sizes of map/prog/variable skeletons for
that reason and libbpf is supposed to work with newer/older versions
correctly.

Unfortunately"," it was missed that we implicitly embed hard-coded most
up-to-date (according to libbpf's version of libbpf.h header used to
compile BPF skeleton header) sizes of those structs","[' which can differ\nfrom the actual sizes at runtime when libbpf is used as a shared\nlibrary.\n\nWe have a few places were we just index array of maps/progs/vars', ' which\nimplicitly uses these potentially invalid sizes of structs.\n\nThis patch aims to fix this problem going forward. Once this lands', '\nwe\'ll backport these changes in Github repo to create patched releases\nfor older libbpfs.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nReviewed-by: Alan Maguire <alan.maguire@oracle.com>\nFixes: d66562fba1ce (""libbpf: Add BPF object skeleton support"")\nFixes: 430025e5dca5 (""libbpf: Add subskeleton scaffolding"")\nFixes: 08ac454e258e (""libbpf: Auto-attach struct_ops BPF maps in BPF skeleton"")\nCo-developed-by: Mykyta Yatsenko <yatsenko@meta.com>\nSigned-off-by: Mykyta Yatsenko <yatsenko@meta.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240708204540.4188946-3-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix forward and backward compatibility handling in libbpf BPF skeleton structures.,"libbpf, BPF skeleton, compatibility",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
06e71ad534881d2a09ced7509d2ab0daedac4c96,06e71ad534881d2a09ced7509d2ab0daedac4c96,Andrii Nakryiko,andrii@kernel.org,1720471538,Alexei Starovoitov,ast@kernel.org,1720576985,741be1e6e1c2d9effb8ba4fb4dba933bc7e97e6c,746d684ea579927015cde53cff8fc365caaf93b7,"bpftool: improve skeleton backwards compat with old buggy libbpfs

Old versions of libbpf don't handle varying sizes of bpf_map_skeleton
struct correctly. As such"," BPF skeleton generated by newest bpftool
might not be compatible with older libbpf (though only when libbpf is
used as a shared library)","[' even though it', ' by design', ' should.\n\nGoing forward libbpf will be fixed', "" plus we'll release bug fixed\nversions of relevant old libbpfs"", ' but meanwhile try to mitigate from\nbpftool side by conservatively assuming older and smaller definition of\nbpf_map_skeleton', ' if possible. Meaning', ' if there are no struct_ops maps.\n\nIf there are struct_ops', ' then presumably user would like to have\nauto-attaching logic and struct_ops map link placeholders', ' so use the\nfull bpf_map_skeleton definition in that case.\n\nAcked-by: Quentin Monnet <qmo@kernel.org>\nCo-developed-by: Mykyta Yatsenko <yatsenko@meta.com>\nSigned-off-by: Mykyta Yatsenko <yatsenko@meta.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20240708204540.4188946-2-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']","Enhanced bpftool to improve compatibility with older, buggy versions of libbpf.","bpftool, compatibility, libbpf",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The bpftool utility,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
01fc5142ae6b06b61ed51a624f2732d6525d8ea3,01fc5142ae6b06b61ed51a624f2732d6525d8ea3,Michal Kubiak,michal.kubiak@intel.com,1720480069,Jakub Kicinski,kuba@kernel.org,1720574714,4f69acc7e2e318a4760b5e8017f0ebf9ea91cbfd,f153831097b4435f963e385304cc0f1acba1c657,"i40e: Fix XDP program unloading while removing the driver

The commit 6533e558c650 (""i40e: Fix reset path while removing
the driver"") introduced a new PF state ""__I40E_IN_REMOVE"" to block
modifying the XDP program while the driver is being removed.
Unfortunately"," such a change is useful only if the "".ndo_bpf()""
callback was called out of the rmmod context because unloading the
existing XDP program is also a part of driver removing procedure.
In other words","[' from the rmmod context the driver is expected to\nunload the XDP program without reporting any errors. Otherwise', '\nthe kernel warning with callstack is printed out to dmesg.\n\nExample failing scenario:\n 1. Load the i40e driver.\n 2. Load the XDP program.\n 3. Unload the i40e driver (using ""rmmod"" command).\n\nThe example kernel warning log:\n\n[  +0.004646] WARNING: CPU: 94 PID: 10395 at net/core/dev.c:9290 unregister_netdevice_many_notify+0x7a9/0x870\n[...]\n[  +0.010959] RIP: 0010:unregister_netdevice_many_notify+0x7a9/0x870\n[...]\n[  +0.002726] Call Trace:\n[  +0.002457]  <TASK>\n[  +0.002119]  ? __warn+0x80/0x120\n[  +0.003245]  ? unregister_netdevice_many_notify+0x7a9/0x870\n[  +0.005586]  ? report_bug+0x164/0x190\n[  +0.003678]  ? handle_bug+0x3c/0x80\n[  +0.003503]  ? exc_invalid_op+0x17/0x70\n[  +0.003846]  ? asm_exc_invalid_op+0x1a/0x20\n[  +0.004200]  ? unregister_netdevice_many_notify+0x7a9/0x870\n[  +0.005579]  ? unregister_netdevice_many_notify+0x3cc/0x870\n[  +0.005586]  unregister_netdevice_queue+0xf7/0x140\n[  +0.004806]  unregister_netdev+0x1c/0x30\n[  +0.003933]  i40e_vsi_release+0x87/0x2f0 [i40e]\n[  +0.004604]  i40e_remove+0x1a1/0x420 [i40e]\n[  +0.004220]  pci_device_remove+0x3f/0xb0\n[  +0.003943]  device_release_driver_internal+0x19f/0x200\n[  +0.005243]  driver_detach+0x48/0x90\n[  +0.003586]  bus_remove_driver+0x6d/0xf0\n[  +0.003939]  pci_unregister_driver+0x2e/0xb0\n[  +0.004278]  i40e_exit_module+0x10/0x5f0 [i40e]\n[  +0.004570]  __do_sys_delete_module.isra.0+0x197/0x310\n[  +0.005153]  do_syscall_64+0x85/0x170\n[  +0.003684]  ? syscall_exit_to_user_mode+0x69/0x220\n[  +0.004886]  ? do_syscall_64+0x95/0x170\n[  +0.003851]  ? exc_page_fault+0x7e/0x180\n[  +0.003932]  entry_SYSCALL_64_after_hwframe+0x71/0x79\n[  +0.005064] RIP: 0033:0x7f59dc9347cb\n[  +0.003648] Code: 73 01 c3 48 8b 0d 65 16 0c 00 f7 d8 64 89 01 48 83\nc8 ff c3 66 2e 0f 1f 84 00 00 00 00 00 90 f3 0f 1e fa b8 b0 00 00 00 0f\n05 <48> 3d 01 f0 ff ff 73 01 c3 48 8b 0d 35 16 0c 00 f7 d8 64 89 01 48\n[  +0.018753] RSP: 002b:00007ffffac99048 EFLAGS: 00000206 ORIG_RAX: 00000000000000b0\n[  +0.007577] RAX: ffffffffffffffda RBX: 0000559b9bb2f6e0 RCX: 00007f59dc9347cb\n[  +0.007140] RDX: 0000000000000000 RSI: 0000000000000800 RDI: 0000559b9bb2f748\n[  +0.007146] RBP: 00007ffffac99070 R08: 1999999999999999 R09: 0000000000000000\n[  +0.007133] R10: 00007f59dc9a5ac0 R11: 0000000000000206 R12: 0000000000000000\n[  +0.007141] R13: 00007ffffac992d8 R14: 0000559b9bb2f6e0 R15: 0000000000000000\n[  +0.007151]  </TASK>\n[  +0.002204] ---[ end trace 0000000000000000 ]---\n\nFix this by checking if the XDP program is being loaded or unloaded.\nThen', ' block only loading a new program while ""__I40E_IN_REMOVE"" is set.\nAlso', ' move testing ""__I40E_IN_REMOVE"" flag to the beginning of XDP_SETUP\ncallback to avoid unnecessary operations and checks.\n\nFixes: 6533e558c650 (""i40e: Fix reset path while removing the driver"")\nSigned-off-by: Michal Kubiak <michal.kubiak@intel.com>\nReviewed-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>\nTested-by: Chandan Kumar Rout <chandanx.rout@intel.com> (A Contingent Worker at Intel)\nSigned-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>\nLink: https://patch.msgid.link/20240708230750.625986-1-anthony.l.nguyen@intel.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Fixes issue with XDP program unloading during i40e driver removal process.,"i40e,XDP,driver",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['xdp like programs']
7b769adc2612b495d94a4b4537ffaa725861d763,7b769adc2612b495d94a4b4537ffaa725861d763,Paolo Abeni,pabeni@redhat.com,1720537306,Paolo Abeni,pabeni@redhat.com,1720537306,f11f24588ea1d6a4053123cbbca111f163353cdf,870a1dbcbc2ebd2114d5f18bb0bd88a7ff07540f 90dc946059b7d346f077b870a8d8aaf03b4d0772,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next

Daniel Borkmann says:

====================
pull-request: bpf-next 2024-07-08

The following pull-request contains BPF updates for your *net-next* tree.

We've added 102 non-merge commits during the last 28 day(s) which contain
a total of 127 files changed", 4606 insertions(+),"[' 980 deletions(-).\n\nThe main changes are:\n\n1) Support resilient split BTF which cuts down on duplication and makes BTF\n   as compact as possible wrt BTF from modules', ' from Alan Maguire & Eduard Zingerman.\n\n2) Add support for dumping kfunc prototypes from BTF which enables both detecting\n   as well as dumping compilable prototypes for kfuncs', ' from Daniel Xu.\n\n3) Batch of s390x BPF JIT improvements to add support for BPF arena and to implement\n   support for BPF exceptions', ' from Ilya Leoshkevich.\n\n4) Batch of riscv64 BPF JIT improvements in particular to add 12-argument support\n   for BPF trampolines and to utilize bpf_prog_pack for the latter', ' from Pu Lehui.\n\n5) Extend BPF test infrastructure to add a CHECKSUM_COMPLETE validation option\n   for skbs and add coverage along with it', ' from Vadim Fedorenko.\n\n6) Inline bpf_get_current_task/_btf() helpers in the arm64 BPF JIT which gives\n   a small 1% performance improvement in micro-benchmarks', ' from Puranjay Mohan.\n\n7) Extend the BPF verifier to track the delta between linked registers in order\n   to better deal with recent LLVM code optimizations', ' from Alexei Starovoitov.\n\n8) Fix bpf_wq_set_callback_impl() kfunc signature where the third argument should\n   have been a pointer to the map value', ' from Benjamin Tissoires.\n\n9) Extend BPF selftests to add regular expression support for test output matching\n   and adjust some of the selftest when compiled under gcc', ' from Cupertino Miranda.\n\n10) Simplify task_file_seq_get_next() and remove an unnecessary loop which always\n    iterates exactly once anyway', ' from Dan Carpenter.\n\n11) Add the capability to offload the netfilter flowtable in XDP layer through\n    kfuncs', ' from Florian Westphal & Lorenzo Bianconi.\n\n12) Various cleanups in networking helpers in BPF selftests to shave off a few\n    lines of open-coded functions on client/server handling', ' from Geliang Tang.\n\n13) Properly propagate prog->aux->tail_call_reachable out of BPF verifier', ' so\n    that x86 JIT does not need to implement detection', ' from Leon Hwang.\n\n14) Fix BPF verifier to add a missing check_func_arg_reg_off() to prevent an\n    out-of-bounds memory access for dynpointers', ' from Matt Bobrowski.\n\n15) Fix bpf_session_cookie() kfunc to return __u64 instead of long pointer as\n    it might lead to problems on 32-bit archs', ' from Jiri Olsa.\n\n16) Enhance traffic validation and dynamic batch size support in xsk selftests', ""\n    from Tushar Vyavahare.\n\nbpf-next-for-netdev\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next: (102 commits)\n  selftests/bpf: DENYLIST.aarch64: Remove fexit_sleep\n  selftests/bpf: amend for wrong bpf_wq_set_callback_impl signature\n  bpf: helpers: fix bpf_wq_set_callback_impl signature\n  libbpf: Add NULL checks to bpf_object__{prev_map"", 'next_map}\n  selftests/bpf: Remove exceptions tests from DENYLIST.s390x\n  s390/bpf: Implement exceptions\n  s390/bpf: Change seen_reg to a mask\n  bpf: Remove unnecessary loop in task_file_seq_get_next()\n  riscv', ' bpf: Optimize stack usage of trampoline\n  bpf', ' devmap: Add .map_alloc_check\n  selftests/bpf: Remove arena tests from DENYLIST.s390x\n  selftests/bpf: Add UAF tests for arena atomics\n  selftests/bpf: Introduce __arena_global\n  s390/bpf: Support arena atomics\n  s390/bpf: Enable arena\n  s390/bpf: Support address space cast instruction\n  s390/bpf: Support BPF_PROBE_MEM32\n  s390/bpf: Land on the next JITed instruction after exception\n  s390/bpf: Introduce pre- and post- probe functions\n  s390/bpf: Get rid of get_probe_mem_regno()\n  ...\n====================\n\nLink: https://patch.msgid.link/20240708221438.10974-1-daniel@iogearbox.net\nSigned-off-by: Paolo Abeni <pabeni@redhat.com>\n', '']",Merge multiple updates from the 'bpf-next' branch into the 'net-next' tree.,"merge, bpf-next, updates",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
528269fe117f3b19461733a0fa408c55a5270aff,528269fe117f3b19461733a0fa408c55a5270aff,Paolo Abeni,pabeni@redhat.com,1720534916,Paolo Abeni,pabeni@redhat.com,1720534916,b8f2ee433d92c0ab5a3525c128a6744ecbb40a1d,0913ec336a6c0c4a2b296bd9f74f8e41c4c83c8c f0c18025693707ec344a70b6887f7450bf4c826b,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Daniel Borkmann says:

====================
pull-request: bpf 2024-07-09

The following pull-request contains BPF updates for your *net* tree.

We've added 3 non-merge commits during the last 1 day(s) which contain
a total of 5 files changed", 81 insertions(+),"[' 11 deletions(-).\n\nThe main changes are:\n\n1) Fix a use-after-free in a corner case where tcx_entry got released too\n   early. Also add BPF test coverage along with the fix', ' from Daniel Borkmann.\n\n2) Fix a kernel panic on Loongarch in sk_msg_recvmsg() which got triggered\n   by running BPF sockmap selftests', "" from Geliang Tang.\n\nbpf-for-netdev\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  skmsg: Skip zero length skb in sk_msg_recvmsg\n  selftests/bpf: Extend tcx tests to cover late tcx_entry release\n  bpf: Fix too early release of tcx_entry\n====================\n\nLink: https://patch.msgid.link/20240709091452.27840-1-daniel@iogearbox.net\nSigned-off-by: Paolo Abeni <pabeni@redhat.com>\n"", '']",This commit merges BPF updates into the netdev tree.,"merge, BPF, netdev",It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
f0c18025693707ec344a70b6887f7450bf4c826b,f0c18025693707ec344a70b6887f7450bf4c826b,Geliang Tang,tanggeliang@kylinos.cn,1719995971,Daniel Borkmann,daniel@iogearbox.net,1720513490,3832de68e6f53388feab6beee278c9a0330642cf,5f1d18de79180deac2822c93e431bbe547f7d3ce,"skmsg: Skip zero length skb in sk_msg_recvmsg

When running BPF selftests (./test_progs -t sockmap_basic) on a Loongarch
platform"," the following kernel panic occurs:

  [...]
  Oops[#1]:
  CPU: 22 PID: 2824 Comm: test_progs Tainted: G           OE  6.10.0-rc2+ #18
  Hardware name: LOONGSON Dabieshan/Loongson-TC542F0","[' BIOS Loongson-UDK2018\n     ... ...\n     ra: 90000000048bf6c0 sk_msg_recvmsg+0x120/0x560\n    ERA: 9000000004162774 copy_page_to_iter+0x74/0x1c0\n   CRMD: 000000b0 (PLV0 -IE -DA +PG DACF=CC DACM=CC -WE)\n   PRMD: 0000000c (PPLV0 +PIE +PWE)\n   EUEN: 00000007 (+FPE +SXE +ASXE -BTE)\n   ECFG: 00071c1d (LIE=0', '2-4', '10-12 VS=7)\n  ESTAT: 00010000 [PIL] (IS= ECode=1 EsubCode=0)\n   BADV: 0000000000000040\n   PRID: 0014c011 (Loongson-64bit', ' Loongson-3C5000)\n  Modules linked in: bpf_testmod(OE) xt_CHECKSUM xt_MASQUERADE xt_conntrack\n  Process test_progs (pid: 2824', ' threadinfo=0000000000863a31', ' task=...)\n  Stack : ...\n  Call Trace:\n  [<9000000004162774>] copy_page_to_iter+0x74/0x1c0\n  [<90000000048bf6c0>] sk_msg_recvmsg+0x120/0x560\n  [<90000000049f2b90>] tcp_bpf_recvmsg_parser+0x170/0x4e0\n  [<90000000049aae34>] inet_recvmsg+0x54/0x100\n  [<900000000481ad5c>] sock_recvmsg+0x7c/0xe0\n  [<900000000481e1a8>] __sys_recvfrom+0x108/0x1c0\n  [<900000000481e27c>] sys_recvfrom+0x1c/0x40\n  [<9000000004c076ec>] do_syscall+0x8c/0xc0\n  [<9000000003731da4>] handle_syscall+0xc4/0x160\n  Code: ...\n  ---[ end trace 0000000000000000 ]---\n  Kernel panic - not syncing: Fatal exception\n  Kernel relocated by 0x3510000\n   .text @ 0x9000000003710000\n   .data @ 0x9000000004d70000\n   .bss  @ 0x9000000006469400\n  ---[ end Kernel panic - not syncing: Fatal exception ]---\n  [...]\n\nThis crash happens every time when running sockmap_skb_verdict_shutdown\nsubtest in sockmap_basic.\n\nThis crash is because a NULL pointer is passed to page_address() in the\nsk_msg_recvmsg(). Due to the different implementations depending on the\narchitecture', ' page_address(NULL) will trigger a panic on Loongarch\nplatform but not on x86 platform. So this bug was hidden on x86 platform\nfor a while', ' but now it is exposed on Loongarch platform. The root cause\nis that a zero length skb (skb->len == 0) was put on the queue.\n\nThis zero length skb is a TCP FIN packet', ' which was sent by shutdown()', '\ninvoked in test_sockmap_skb_verdict_shutdown():\n\n\tshutdown(p1', ' SHUT_WR);\n\nIn this case', ' in sk_psock_skb_ingress_enqueue()', ' num_sge is zero', ' and no\npage is put to this sge (see sg_set_page in sg_set_page)', ' but this empty\nsge is queued into ingress_msg list.\n\nAnd in sk_msg_recvmsg()', ' this empty sge is used', ' and a NULL page is got by\nsg_page(sge). Pass this NULL page to copy_page_to_iter()', ' which passes it\nto kmap_local_page() and to page_address()', ' then kernel panics.\n\nTo solve this', ' we should skip this zero length skb. So in sk_msg_recvmsg()', '\nif copy is zero', "" that means it's a zero length skb"", ' skip invoking\ncopy_page_to_iter(). We are using the EFAULT return triggered by\ncopy_page_to_iter to check for is_fin in tcp_bpf.c.\n\nFixes: 604326b41a6f (""bpf', ' sockmap: convert to generic sk_msg interface"")\nSuggested-by: John Fastabend <john.fastabend@gmail.com>\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: John Fastabend <john.fastabend@gmail.com>\nLink: https://lore.kernel.org/bpf/e3a16eacdc6740658ee02a33489b1b9d4912f378.1719992715.git.tanggeliang@kylinos.cn\n', '']",The commit fixes a kernel panic by skipping zero-length skb in sk_msg_recvmsg on Loongarch platform.,"skmsg, zero length, kernel panic",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['socket like programs']
5f1d18de79180deac2822c93e431bbe547f7d3ce,5f1d18de79180deac2822c93e431bbe547f7d3ce,Daniel Borkmann,daniel@iogearbox.net,1720445490,Martin KaFai Lau,martin.lau@kernel.org,1720472851,f01ffebd1413bd82a5ea2014360dbc40304f9aab,1cb6f0bae50441f4b4b32a28315853b279c7404e,"selftests/bpf: Extend tcx tests to cover late tcx_entry release

Add a test case which replaces an active ingress qdisc while keeping the
miniq in-tact during the transition period to the new clsact qdisc.

  # ./vmtest.sh -- ./test_progs -t tc_link
  [...]
  ./test_progs -t tc_link
  [    3.412871] bpf_testmod: loading out-of-tree module taints kernel.
  [    3.413343] bpf_testmod: module verification failed: signature and/or required key missing - tainting kernel
  #332     tc_links_after:OK
  #333     tc_links_append:OK
  #334     tc_links_basic:OK
  #335     tc_links_before:OK
  #336     tc_links_chain_classic:OK
  #337     tc_links_chain_mixed:OK
  #338     tc_links_dev_chain0:OK
  #339     tc_links_dev_cleanup:OK
  #340     tc_links_dev_mixed:OK
  #341     tc_links_ingress:OK
  #342     tc_links_invalid:OK
  #343     tc_links_prepend:OK
  #344     tc_links_replace:OK
  #345     tc_links_revision:OK
  Summary: 14/0 PASSED", 0 SKIPPED,"[' 0 FAILED\n\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nCc: Martin KaFai Lau <martin.lau@kernel.org>\nLink: https://lore.kernel.org/r/20240708133130.11609-2-daniel@iogearbox.net\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Extend selftests for tcx to ensure correct release during ingress qdisc replacement.,"tcx tests, ingress qdisc, test case",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tc/netfilter like programs']
1cb6f0bae50441f4b4b32a28315853b279c7404e,1cb6f0bae50441f4b4b32a28315853b279c7404e,Daniel Borkmann,daniel@iogearbox.net,1720445489,Martin KaFai Lau,martin.lau@kernel.org,1720472851,2a77853cb7254aed5df87823ba5a216b23c17158,83c36e7cfd74e41a5c145640dba581b38f12aa15,"bpf: Fix too early release of tcx_entry

Pedro Pinto and later independently also Hyunwoo Kim and Wongi Lee reported
an issue that the tcx_entry can be released too early leading to a use
after free (UAF) when an active old-style ingress or clsact qdisc with a
shared tc block is later replaced by another ingress or clsact instance.

Essentially"," the sequence to trigger the UAF (one example) can be as follows:

  1. A network namespace is created
  2. An ingress qdisc is created. This allocates a tcx_entry","["" and\n     &tcx_entry->miniq is stored in the qdisc's miniqp->p_miniq. At the\n     same time"", ' a tcf block with index 1 is created.\n  3. chain0 is attached to the tcf block. chain0 must be connected to\n     the block linked to the ingress qdisc to later reach the function\n     tcf_chain0_head_change_cb_del() which triggers the UAF.\n  4. Create and graft a clsact qdisc. This causes the ingress qdisc\n     created in step 1 to be removed', ' thus freeing the previously linked\n     tcx_entry:\n\n     rtnetlink_rcv_msg()\n       => tc_modify_qdisc()\n         => qdisc_create()\n           => clsact_init() [a]\n         => qdisc_graft()\n           => qdisc_destroy()\n             => __qdisc_destroy()\n               => ingress_destroy() [b]\n                 => tcx_entry_free()\n                   => kfree_rcu() // tcx_entry freed\n\n  5. Finally', ' the network namespace is closed. This registers the\n     cleanup_net worker', ' and during the process of releasing the\n     remaining clsact qdisc', ' it accesses the tcx_entry that was\n     already freed in step 4', ' causing the UAF to occur:\n\n     cleanup_net()\n       => ops_exit_list()\n         => default_device_exit_batch()\n           => unregister_netdevice_many()\n             => unregister_netdevice_many_notify()\n               => dev_shutdown()\n                 => qdisc_put()\n                   => clsact_destroy() [c]\n                     => tcf_block_put_ext()\n                       => tcf_chain0_head_change_cb_del()\n                         => tcf_chain_head_change_item()\n                           => clsact_chain_head_change()\n                             => mini_qdisc_pair_swap() // UAF\n\nThere are also other variants', ' the gist is to add an ingress (or clsact)\nqdisc with a specific shared block', ' then to replace that qdisc', "" waiting\nfor the tcx_entry kfree_rcu() to be executed and subsequently accessing\nthe current active qdisc's miniq one way or another.\n\nThe correct fix is to turn the miniq_active boolean into a counter. What\ncan be observed"", ' at step 2 above', ' the counter transitions from 0->1', ' at\nstep [a] from 1->2 (in order for the miniq object to remain active during\nthe replacement)', ' then in [b] from 2->1 and finally [c] 1->0 with the\neventual release. The reference counter in general ranges from [0', '2] and\nit does not need to be atomic since all access to the counter is protected\nby the rtnl mutex. With this in place', ' there is no longer a UAF happening\nand the tcx_entry is freed at the correct time.\n\nFixes: e420bed02507 (""bpf: Add fd-based tcx multi-prog infra with link support"")\nReported-by: Pedro Pinto <xten@osec.io>\nCo-developed-by: Pedro Pinto <xten@osec.io>\nSigned-off-by: Pedro Pinto <xten@osec.io>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nCc: Hyunwoo Kim <v4bel@theori.io>\nCc: Wongi Lee <qwerty@theori.io>\nCc: Martin KaFai Lau <martin.lau@kernel.org>\nLink: https://lore.kernel.org/r/20240708133130.11609-1-daniel@iogearbox.net\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Fixes an issue with premature release of tcx_entry causing use-after-free in tc block handling.,"tcx_entry,use-after-free,ingress",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tc/netfilter like programs']
90dc946059b7d346f077b870a8d8aaf03b4d0772,90dc946059b7d346f077b870a8d8aaf03b4d0772,Puranjay Mohan,puranjay@kernel.org,1720191009,Daniel Borkmann,daniel@iogearbox.net,1720470294,e2aa5725ddaa1472b908bf8117958fd9632032e3,06507c7536f747867d6d83d605af6bd753fec6d3,"selftests/bpf: DENYLIST.aarch64: Remove fexit_sleep

fexit_sleep test runs successfully now on the BPF CI so remove it
from the deny list. ftrace direct calls was blocking tracing programs
on arm64 but it has been resolved by now. For more details see also
discussion in [*].

Signed-off-by: Puranjay Mohan <puranjay@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240705145009.32340-1-puranjay@kernel.org [*]
",,Remove fexit_sleep from the deny list as it now runs successfully on arm64 after ftrace direct calls issue resolved.,"fexit_sleep,denylist,arm64",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['tracepoints like programs', 'kprobe/uprobe/ftrace like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
06507c7536f747867d6d83d605af6bd753fec6d3,06507c7536f747867d6d83d605af6bd753fec6d3,Alexei Starovoitov,ast@kernel.org,1720458108,Alexei Starovoitov,ast@kernel.org,1720458108,f411f868052894bcbab042447224918218fa6d30,cedc12c5b57f7efa6dbebfb2b140e8675f5a2616 16e86f2e8199cdb8789573c8784eb5c1cd478f13,"Merge branch 'small-api-fix-for-bpf_wq'

Benjamin Tissoires says:

====================
Small API fix for bpf_wq

I realized this while having a map containing both a struct bpf_timer and
a struct bpf_wq: the third argument provided to the bpf_wq callback is
not the struct bpf_wq pointer itself"," but the pointer to the value in
the map.

Which means that the users need to double cast the provided ""value"" as
this is not a struct bpf_wq *.

This is a change of API","["" but there doesn't seem to be much users of bpf_wq\nright now"", ' so we should be able to go with this right now.\n\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n---\nChanges in v2:\n- amended the selftests to retrieve something from the third argument of\n  the callback\n- Link to v1: https://lore.kernel.org/r/20240705-fix-wq-v1-0-91b4d82cd825@kernel.org\n\n---\n====================\n\nLink: https://lore.kernel.org/r/20240708-fix-wq-v2-0-667e5c9fbd99@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix for bpf_wq API to correctly handle callback arguments.,"API, bpf_wq, fix",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,['other']
16e86f2e8199cdb8789573c8784eb5c1cd478f13,16e86f2e8199cdb8789573c8784eb5c1cd478f13,Benjamin Tissoires,bentiss@kernel.org,1720432378,Alexei Starovoitov,ast@kernel.org,1720458108,f411f868052894bcbab042447224918218fa6d30,f56f4d541eab1ae060a46b56dd6ec9130d6e3a98,"selftests/bpf: amend for wrong bpf_wq_set_callback_impl signature

See the previous patch: the API was wrong"," we were provided the pointer
to the value","[' not the actual struct bpf_wq *.\n\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\nLink: https://lore.kernel.org/r/20240708-fix-wq-v2-2-667e5c9fbd99@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix the selftests for bpf by amending the incorrect bpf_wq_set_callback_impl signature.,"selftests, signature, amend",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f56f4d541eab1ae060a46b56dd6ec9130d6e3a98,f56f4d541eab1ae060a46b56dd6ec9130d6e3a98,Benjamin Tissoires,bentiss@kernel.org,1720432377,Alexei Starovoitov,ast@kernel.org,1720458108,d4597e7a4336c3472ef18a6ca6c6ef1eb7995328,cedc12c5b57f7efa6dbebfb2b140e8675f5a2616,"bpf: helpers: fix bpf_wq_set_callback_impl signature

I realized this while having a map containing both a struct bpf_timer and
a struct bpf_wq: the third argument provided to the bpf_wq callback is
not the struct bpf_wq pointer itself"," but the pointer to the value in
the map.

Which means that the users need to double cast the provided ""value"" as
this is not a struct bpf_wq *.

This is a change of API","["" but there doesn't seem to be much users of bpf_wq\nright now"", ' so we should be able to go with this right now.\n\nFixes: 81f1d7a583fa (""bpf: wq: add bpf_wq_set_callback_impl"")\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\nLink: https://lore.kernel.org/r/20240708-fix-wq-v2-1-667e5c9fbd99@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes the bpf_wq_set_callback_impl signature to correct argument handling for bpf_wq callbacks.,"bpf_wq, callback, API change",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
cedc12c5b57f7efa6dbebfb2b140e8675f5a2616,cedc12c5b57f7efa6dbebfb2b140e8675f5a2616,Andreas Ziegler,ziegler.andreas@siemens.com,1719995676,Daniel Borkmann,daniel@iogearbox.net,1720455187,3465b787ffaef87b551ab865061c932184ca5ab3,02480fe8a6a6d44c16900b1d3a2a66d140d0a005,libbpf: Add NULL checks to bpf_object__{prev_map,"next_map}

In the current state","[' an erroneous call to\nbpf_object__find_map_by_name(NULL', ' ...) leads to a segmentation\nfault through the following call chain:\n\n  bpf_object__find_map_by_name(obj = NULL', ' ...)\n  -> bpf_object__for_each_map(pos', ' obj = NULL)\n  -> bpf_object__next_map((obj = NULL)', ' NULL)\n  -> return (obj = NULL)->maps\n\nWhile calling bpf_object__find_map_by_name with obj = NULL is\nobviously incorrect', ' this should not lead to a segmentation\nfault but rather be handled gracefully.\n\nAs __bpf_map__iter already handles this situation correctly', ' we\ncan delegate the check for the regular case there and only add\na check in case the prev or next parameter is NULL.\n\nSigned-off-by: Andreas Ziegler <ziegler.andreas@siemens.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240703083436.505124-1-ziegler.andreas@siemens.com\n', '']",Add NULL checks to bpf_object__prev_map and bpf_object__next_map functions in libbpf.,"NULL checks, libbpf, functions",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
02480fe8a6a6d44c16900b1d3a2a66d140d0a005,02480fe8a6a6d44c16900b1d3a2a66d140d0a005,Ilya Leoshkevich,iii@linux.ibm.com,1719967729,Daniel Borkmann,daniel@iogearbox.net,1720449575,f92fdb381cc0acef181791a92a7a2a73c577487e,fa7bd4b000a7ae32eb6fc049125943561e5b46f3,"selftests/bpf: Remove exceptions tests from DENYLIST.s390x

Now that the s390x JIT supports exceptions"," remove the respective tests
from the denylist.

Signed-off-by: Ilya Leoshkevich <iii@linux.ibm.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240703005047.40915-4-iii@linux.ibm.com
",[''],Remove exception tests from s390x DENYLIST due to improved JIT support.,"exceptions,JIT,DENYLIST",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fa7bd4b000a7ae32eb6fc049125943561e5b46f3,fa7bd4b000a7ae32eb6fc049125943561e5b46f3,Ilya Leoshkevich,iii@linux.ibm.com,1719967728,Daniel Borkmann,daniel@iogearbox.net,1720449575,d734c917321b136d7066807f5dee84e7ea56e7ad,7ba4f43e16de351fe9821de80e15d88c884b2967,"s390/bpf: Implement exceptions

Implement the following three pieces required from the JIT:

- A ""top-level"" BPF prog (exception_boundary) must save all
  non-volatile registers"," and not only the ones that it clobbers.
- A ""handler"" BPF prog (exception_cb) must switch stack to that of
  exception_boundary","[' and restore the registers that exception_boundary\n  saved.\n- arch_bpf_stack_walk() must unwind the stack and provide the results\n  in a way that satisfies both bpf_throw() and exception_cb.\n\nSigned-off-by: Ilya Leoshkevich <iii@linux.ibm.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240703005047.40915-3-iii@linux.ibm.com\n', '']",This commit implements exceptions for s390 architecture in the BPF JIT compiler.,"s390, exceptions, JIT",It's a new feature.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7ba4f43e16de351fe9821de80e15d88c884b2967,7ba4f43e16de351fe9821de80e15d88c884b2967,Ilya Leoshkevich,iii@linux.ibm.com,1719967727,Daniel Borkmann,daniel@iogearbox.net,1720449575,0019f59ba154fd2eebb46705076a6a55c77225ed,bc239eb271e5f35fcade689c6782c962ef3704c8,"s390/bpf: Change seen_reg to a mask

Using a mask instead of an array saves a small amount of memory and
allows marking multiple registers as seen with a simple ""or"". Another
positive side-effect is that it speeds up verification with jitterbug.

Signed-off-by: Ilya Leoshkevich <iii@linux.ibm.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240703005047.40915-2-iii@linux.ibm.com
",,Optimization of register handling in s390 architecture by using a mask instead of an array.,"s390,bpf,mask",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
bc239eb271e5f35fcade689c6782c962ef3704c8,bc239eb271e5f35fcade689c6782c962ef3704c8,Dan Carpenter,dan.carpenter@linaro.org,1720106359,Daniel Borkmann,daniel@iogearbox.net,1720448599,b75f72c985bc8abe96bcd68c25d7321dedd73155,a5912c37faf723c0812a6a2c9dd18ffbd34a233b,"bpf: Remove unnecessary loop in task_file_seq_get_next()

After commit 0ede61d8589c (""file: convert to SLAB_TYPESAFE_BY_RCU"") this
loop always iterates exactly one time.  Delete the for statement and pull
the code in a tab.

Signed-off-by: Dan Carpenter <dan.carpenter@linaro.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Reviewed-by: Christian Brauner <brauner@kernel.org>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/bpf/ZoWJF51D4zWb6f5t@stanley.mountain
",,The commit removes an unnecessary loop in the task_file_seq_get_next function after a previous update.,"remove, unnecessary, loop",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
a5912c37faf723c0812a6a2c9dd18ffbd34a233b,a5912c37faf723c0812a6a2c9dd18ffbd34a233b,Puranjay Mohan,puranjay@kernel.org,1720439278,Daniel Borkmann,daniel@iogearbox.net,1720446248,03cb7edb8f866105dad4b46de6a812839a732c0e,fd8db07705c55a995c42b1e71afc42faad675b0b,riscv," bpf: Optimize stack usage of trampoline

When BPF_TRAMP_F_CALL_ORIG is not set","["" stack space for passing arguments\non stack doesn't need to be reserved because the original function is\nnot called.\n\nOnly reserve space for stacked arguments when BPF_TRAMP_F_CALL_ORIG is\nset.\n\nSigned-off-by: Puranjay Mohan <puranjay@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Pu Lehui <pulehui@huawei.com>\nLink: https://lore.kernel.org/bpf/20240708114758.64414-1-puranjay@kernel.org\n"", '']",Optimize stack usage of BPF trampoline when BPF_TRAMP_F_CALL_ORIG is not set.,"optimize, stack, trampoline",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fecef4cd42c689a200bdd39e6fffa71475904bc1,fecef4cd42c689a200bdd39e6fffa71475904bc1,Sebastian Andrzej Siewior,bigeasy@linutronix.de,1720104495,Jakub Kicinski,kuba@kernel.org,1720223977,77e6bcb7cb0d8cb5b656646e071fc92d1b13bf7a,3b2aef99221d395ce37efa426d7b50e7dcd621d6,"tun: Assign missing bpf_net_context.

During the introduction of struct bpf_net_context handling for
XDP-redirect"," the tun driver has been missed.
Jakub also pointed out that there is another call chain to
do_xdp_generic() originating from netif_receive_skb() and drivers may
use it outside from the NAPI context.

Set the bpf_net_context before invoking BPF XDP program within the TUN
driver. Set the bpf_net_context also in do_xdp_generic() if a xdp
program is available.

Reported-by: syzbot+0b5c75599f1d872bea6f@syzkaller.appspotmail.com
Reported-by: syzbot+5ae46b237278e2369cac@syzkaller.appspotmail.com
Reported-by: syzbot+c1e04a422bbc0f0f2921@syzkaller.appspotmail.com
Fixes: 401cb7dae8130 (""net: Reference bpf_redirect_info via task_struct on PREEMPT_RT."")
Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Link: https://patch.msgid.link/20240704144815.j8xQda5r@linutronix.de
Signed-off-by: Jakub Kicinski <kuba@kernel.org>
",[''],Assign missing bpf_net_context to the TUN driver for handling XDP-redirect use cases.,"bpf_net_context,XDP-redirect,TUN driver",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['xdp like programs']
a67a1deb11d9a692366100d9ba9fb3aeb0c7707b,a67a1deb11d9a692366100d9ba9fb3aeb0c7707b,Benjamin Tissoires,bentiss@kernel.org,1720181182,Benjamin Tissoires,bentiss@kernel.org,1720181311,82843007949c176c5b629cb9d70203af49101031,3a904d2c771115154380caaae7ffaaf0095fb88f,"HID: samples: fix the 2 struct_ops definitions

Turns out that this is not compiling anymore because the hid_bpf_ops
struct_ops definition had a change during the revisions.

Fixes: e342d6f6f7d8 (""HID: samples: convert the 2 HID-BPF samples into struct_ops"")
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",,Fix the struct_ops definitions in HID samples for compilation issues.,"HID,struct_ops,fix",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['HID driver like programs']
3a904d2c771115154380caaae7ffaaf0095fb88f,3a904d2c771115154380caaae7ffaaf0095fb88f,Benjamin Tissoires,bentiss@kernel.org,1720181226,Benjamin Tissoires,bentiss@kernel.org,1720181226,3f49ea1f04e284441927bd50ea0a785f68c080a7,f58e7f404da44c94e46bfe657b8707195aebd25a,"HID: fix for amples in for-6.11/bpf

To: Jiri Kosina <jikos@kernel.org>
Cc: linux-input@vger.kernel.org
Cc: linux-kernel@vger.kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>

---
Changes in v2:
- EDITME: describe what is new in this series revision.
- EDITME: use bulletpoints and terse descriptions.
- Link to v1: https://lore.kernel.org/r/20240705-for-6-11-bpf-v1-1-1960e3165c9e@kernel.org



--- b4-submit-tracking ---
# This section is used internally by b4 prep for tracking purposes.
{
  ""series"": {
    ""revision"": 2","
    ""change-id"": ""20240705-for-6-11-bpf-a349efc08df8""","['\n    ""prefixes"": []', '\n    ""history"": {\n      ""v1"": [\n        ""20240705-for-6-11-bpf-v1-1-1960e3165c9e@kernel.org""\n      ]\n    }\n  }\n}', '']",Fixes HID driver issues in the BPF subsystem for version 6.11.,"HID, fix, BPF",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['HID driver like programs']
3577dbb192419e37b6f54aced8777b6c81cd03d4,3577dbb192419e37b6f54aced8777b6c81cd03d4,Mateusz Guzik,mjguzik@gmail.com,1716335001,Andrew Morton,akpm@linux-foundation.org,1720060198,0debd41a85915375f2a82f3ad53796ac4efbfb19,1a3798dececa8cb26b9eee26840195ccc1a4d6c1,"mm: batch unlink_file_vma calls in free_pgd_range

Execs of dynamically linked binaries at 20-ish cores are bottlenecked on
the i_mmap_rwsem semaphore"," while the biggest singular contributor is
free_pgd_range inducing the lock acquire back-to-back for all consecutive
mappings of a given file.

Tracing the count of said acquires while building the kernel shows:
[1","[' 2)     799579 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|\n[2', ' 3)          0 |                                                    |\n[3', ' 4)       3009 |                                                    |\n[4', ' 5)       3009 |                                                    |\n[5', ' 6)     326442 |@@@@@@@@@@@@@@@@@@@@@                               |\n\nSo in particular there were 326442 opportunities to coalesce 5 acquires\ninto 1.\n\nDoing so increases execs per second by 4% (~50k to ~52k) when running\nthe benchmark linked below.\n\nThe lock remains the main bottleneck', ' I have not looked at other spots\nyet.\n\nBench can be found here:\nhttp://apollo.backplane.com/DFlyMisc/doexec.c\n\n$ cc -O2 -o shared-doexec doexec.c\n$ ./shared-doexec $(nproc)\n\nNote this particular test makes sure binaries are separate', ' but the\nloader is shared.\n\nStats collected on the patched kernel (+ ""noinline"") with:\nbpftrace -e \'kprobe:unlink_file_vma_batch_process\n{ @ = lhist(((struct unlink_vma_file_batch *)arg0)->count', ' 0', ' 8', "" 1); }'\n\nLink: https://lkml.kernel.org/r/20240521234321.359501-1-mjguzik@gmail.com\nSigned-off-by: Mateusz Guzik <mjguzik@gmail.com>\nReviewed-by: Liam R. Howlett <Liam.Howlett@oracle.com>\nCc: Lorenzo Stoakes <lstoakes@gmail.com>\nCc: Vlastimil Babka <vbabka@suse.cz>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\n"", '']",Optimize free_pgd_range to batch unlink_file_vma calls to reduce semaphore bottlenecks in execs of dynamically linked binaries.,"batch, semaphore, optimization",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
fd8db07705c55a995c42b1e71afc42faad675b0b,fd8db07705c55a995c42b1e71afc42faad675b0b,Florian Lehner,dev@der-flo.net,1718446318,Daniel Borkmann,daniel@iogearbox.net,1719939925,4d34c44961bff74ce51e3f587b2a680d958eb6dd,69716e44a74af464060faa68fa2b54f3af03c16a,bpf," devmap: Add .map_alloc_check

Use the .map_allock_check callback to perform allocation checks before
allocating memory for the devmap.

Signed-off-by: Florian Lehner <dev@der-flo.net>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240615101158.57889-1-dev@der-flo.net
",[''],Add .map_alloc_check callback for allocation checks in devmap memory allocation.,"map_alloc_check, allocation, devmap",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
69716e44a74af464060faa68fa2b54f3af03c16a,69716e44a74af464060faa68fa2b54f3af03c16a,Ilya Leoshkevich,iii@linux.ibm.com,1719877230,Daniel Borkmann,daniel@iogearbox.net,1719937912,34bddd4209cb4c8e3106b09fc37fcfb41c866c1f,490c99d4ed99bb01dac8bf2896e27941403549c4,"selftests/bpf: Remove arena tests from DENYLIST.s390x

Now that the s390x JIT supports arena"," remove the respective tests from
the denylist.

Signed-off-by: Ilya Leoshkevich <iii@linux.ibm.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240701234304.14336-13-iii@linux.ibm.com
",[''],Removed arena tests from the s390x BPF selftests denylist due to JIT support.,"s390x,JIT,denylist",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
490c99d4ed99bb01dac8bf2896e27941403549c4,490c99d4ed99bb01dac8bf2896e27941403549c4,Ilya Leoshkevich,iii@linux.ibm.com,1719877229,Daniel Borkmann,daniel@iogearbox.net,1719937912,7ae6854096191d17f8368bf5ce95fc8c658c48e9,b6349fd3448cf349af327f90585a712d60265429,"selftests/bpf: Add UAF tests for arena atomics

Check that __sync_*() functions don't cause kernel panics when handling
freed arena pages.

x86_64 does not support some arena atomics yet"," and aarch64 may or may
not support them","[' based on the availability of LSE atomics at run time.\nDo not enable this test for these architectures for simplicity.\n\nSigned-off-by: Ilya Leoshkevich <iii@linux.ibm.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240701234304.14336-12-iii@linux.ibm.com\n', '']",Introduce UAF tests for arena atomics in BPF selftests to ensure stability against kernel panics.,"UAF tests, arena atomics, kernel panics",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b6349fd3448cf349af327f90585a712d60265429,b6349fd3448cf349af327f90585a712d60265429,Ilya Leoshkevich,iii@linux.ibm.com,1719877228,Daniel Borkmann,daniel@iogearbox.net,1719937912,ac0830d54470402fb4b45bc8e2681988bce32bb0,2f9469484a3b52c66b799de73bd1ca75617bc8d5,"selftests/bpf: Introduce __arena_global

While clang uses __attribute__((address_space(1))) both for defining
arena pointers and arena globals"," GCC requires different syntax for
both. While __arena covers the first use case","[' introduce __arena_global\nto cover the second one.\n\nSigned-off-by: Ilya Leoshkevich <iii@linux.ibm.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240701234304.14336-11-iii@linux.ibm.com\n', '']",The commit introduces __arena_global for selftests in BPF to distinguish arena pointers and globals in GCC and clang.,"__arena_global,selftests,BPF",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2f9469484a3b52c66b799de73bd1ca75617bc8d5,2f9469484a3b52c66b799de73bd1ca75617bc8d5,Ilya Leoshkevich,iii@linux.ibm.com,1719877227,Daniel Borkmann,daniel@iogearbox.net,1719937912,a1315869ce478f7f481c2a87b31262b001c9ee46,1e36027e39b8b3fa567ce3d743dbda5954dc0a56,"s390/bpf: Support arena atomics

s390x supports most BPF atomics using single instructions"," which
makes implementing arena support a matter of adding arena address to
the base register (unfortunately atomics do not support index
registers)","[' and wrapping the respective native instruction in probing\nsequences.\n\nAn exception is BPF_XCHG', ' which is implemented using two different\nmemory accesses and a loop. Make sure there is enough extable entries\nfor both instructions. Compute the base address once for both memory\naccesses. Since on exception we need to land after the loop', ' emit the\nnops manually.\n\nSigned-off-by: Ilya Leoshkevich <iii@linux.ibm.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240701234304.14336-10-iii@linux.ibm.com\n', '']",The commit adds support for arena atomics in s390x BPF utilizing single instructions.,"arena, atomics, s390x",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
1e36027e39b8b3fa567ce3d743dbda5954dc0a56,1e36027e39b8b3fa567ce3d743dbda5954dc0a56,Ilya Leoshkevich,iii@linux.ibm.com,1719877226,Daniel Borkmann,daniel@iogearbox.net,1719937912,f1d52383ef117c0d3052f83886fe38f7ceb2bfe3,555469cc9be4a7f52c0ad07a4a237d63e8c5c5f4,"s390/bpf: Enable arena

Now that BPF_PROBE_MEM32 and address space cast instructions are
implemented"," tell the verifier that the JIT supports arena.

Signed-off-by: Ilya Leoshkevich <iii@linux.ibm.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240701234304.14336-9-iii@linux.ibm.com
",[''],Enabled arena support in s390 BPF by implementing BPF_PROBE_MEM32 and address space cast instructions.,"s390 BPF, arena, JIT",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
555469cc9be4a7f52c0ad07a4a237d63e8c5c5f4,555469cc9be4a7f52c0ad07a4a237d63e8c5c5f4,Ilya Leoshkevich,iii@linux.ibm.com,1719877225,Daniel Borkmann,daniel@iogearbox.net,1719937912,e13409b04a90a49a0e60fac91da2ede79ec54952,4d3a453b434fd2f389960890ae6d767f8d50c403,"s390/bpf: Support address space cast instruction

The new address cast instruction translates arena offsets to userspace
addresses. NULL pointers must not be translated.

The common code sets up the mappings in such a way that it's enough to
replace the higher 32 bits to achieve the desired result. s390x has
just an instruction for this: INSERT IMMEDIATE.

Implement the sequence using 3 instruction: LOAD AND TEST"," BRANCH
RELATIVE ON CONDITION and INSERT IMMEDIATE.

Signed-off-by: Ilya Leoshkevich <iii@linux.ibm.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240701234304.14336-8-iii@linux.ibm.com
",[''],Support for address space cast instruction added on s390 for eBPF.,"s390,bpf,address",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4d3a453b434fd2f389960890ae6d767f8d50c403,4d3a453b434fd2f389960890ae6d767f8d50c403,Ilya Leoshkevich,iii@linux.ibm.com,1719877224,Daniel Borkmann,daniel@iogearbox.net,1719937912,05ca7c02eff3e01621d9602e74f425ceb0e4cb7f,a1c04bcc41f9638460a9c68f894fb770596380de,"s390/bpf: Support BPF_PROBE_MEM32

BPF_PROBE_MEM32 is a new mode for LDX"," ST and STX instructions. The JIT
is supposed to add the start address of the kernel arena mapping to the
%dst register","[' and use a probing variant of the respective memory\naccess.\n\nReuse the existing probing infrastructure for that. Put the arena\naddress into the literal pool', ' load it into %r1 and use that as an\nindex register. Do not clear any registers in ex_handler_bpf() for\nfailing ST and STX instructions.\n\nSigned-off-by: Ilya Leoshkevich <iii@linux.ibm.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240701234304.14336-7-iii@linux.ibm.com\n', '']",Add support for BPF_PROBE_MEM32 mode in s390 BPF JIT,"BPF_PROBE_MEM32,s390,JIT",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a1c04bcc41f9638460a9c68f894fb770596380de,a1c04bcc41f9638460a9c68f894fb770596380de,Ilya Leoshkevich,iii@linux.ibm.com,1719877223,Daniel Borkmann,daniel@iogearbox.net,1719937912,8330aff9f78be2e20a012c4c71820e884833eba1,89b933a2013794d8272d432591a2a7a9c41f6351,"s390/bpf: Land on the next JITed instruction after exception

Currently we land on the nop"," which is unnecessary: we can just as well
begin executing the next instruction. Furthermore","[' the upcoming arena\nsupport for the loop-based BPF_XCHG implementation will require landing\non an instruction that comes after the loop.\n\nSo land on the next JITed instruction', ' which covers both cases.\n\nSigned-off-by: Ilya Leoshkevich <iii@linux.ibm.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240701234304.14336-6-iii@linux.ibm.com\n', '']",Optimize s390 JIT execution to continue from the next instruction after an exception.,"s390, JIT, exception",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
89b933a2013794d8272d432591a2a7a9c41f6351,89b933a2013794d8272d432591a2a7a9c41f6351,Ilya Leoshkevich,iii@linux.ibm.com,1719877222,Daniel Borkmann,daniel@iogearbox.net,1719937912,7073dac156d3202e6e105e930a9c992e7ec4fda2,9a048587269174f218e8d8d737ebfa628589358f,"s390/bpf: Introduce pre- and post- probe functions

Currently probe insns are handled by two ""if"" statements at the
beginning and at the end of bpf_jit_insn(). The first one needs to be
in sync with the huge insn->code statement that follows it"," which was
not a problem so far","[' since the check is small.\n\nThe introduction of arena will make it significantly larger', ' and it\nwill no longer be obvious whether it is in sync with the opcode switch.\n\nMove these statements to the new bpf_jit_probe_load_pre() and\nbpf_jit_probe_post() functions', ' and call them only from cases that need\nthem.\n\nSigned-off-by: Ilya Leoshkevich <iii@linux.ibm.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240701234304.14336-5-iii@linux.ibm.com\n', '']",The commit introduces pre- and post-probe functions to improve BPF JIT instruction handling on s390 architecture.,"probe, JIT, instruction",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9a048587269174f218e8d8d737ebfa628589358f,9a048587269174f218e8d8d737ebfa628589358f,Ilya Leoshkevich,iii@linux.ibm.com,1719877221,Daniel Borkmann,daniel@iogearbox.net,1719937911,008c28e1e95517c2996807d1a4d8f07e1c71e548,d0736d8c491ddc7d31c7f839d281c907366e2562,"s390/bpf: Get rid of get_probe_mem_regno()

Commit 7fc8c362e782 (""s390/bpf: encode register within extable entry"")
introduced explicit passing of the number of the register to be cleared
to ex_handler_bpf()"," which replaced deducing it from the respective
native load instruction using get_probe_mem_regno().

Replace the second and last usage in the same manner","[' and remove this\nfunction.\n\nSigned-off-by: Ilya Leoshkevich <iii@linux.ibm.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240701234304.14336-4-iii@linux.ibm.com\n', '']",Remove get_probe_mem_regno() function and update register encoding in s390/bpf architecture.,"s390,bpf,register",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
d0736d8c491ddc7d31c7f839d281c907366e2562,d0736d8c491ddc7d31c7f839d281c907366e2562,Ilya Leoshkevich,iii@linux.ibm.com,1719877220,Daniel Borkmann,daniel@iogearbox.net,1719937911,d6ff1e41a72d364e4af1f5e61af9cd8aa29560e0,df34ec9db6f521118895f22795da49f2ec01f8cf,"s390/bpf: Factor out emitting probe nops

The upcoming arena support for the loop-based BPF_XCHG implementation
requires emitting nop and extable entries separately. Move nop handling
into a separate function"," and keep track of the nop offset.

Signed-off-by: Ilya Leoshkevich <iii@linux.ibm.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240701234304.14336-3-iii@linux.ibm.com
",[''],Refactor s390 BPF code by moving NOP handling into a separate function for future BPF_XCHG changes.,"s390, nop, refactoring",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
df34ec9db6f521118895f22795da49f2ec01f8cf,df34ec9db6f521118895f22795da49f2ec01f8cf,Ilya Leoshkevich,iii@linux.ibm.com,1719877219,Daniel Borkmann,daniel@iogearbox.net,1719937895,5d37f1bd78b5e986b4e96a2e210622fa1d919267,da5f8fd1f0d393d5eaaba9ad8c22d1c26bb2bf9b,"bpf: Fix atomic probe zero-extension

Zero-extending results of atomic probe operations fails with:

    verifier bug. zext_dst is set"," but no reg is defined

The problem is that insn_def_regno() handles BPF_ATOMICs","[' but not\nBPF_PROBE_ATOMICs. Fix by adding the missing condition.\n\nFixes: d503a04f8bc0 (""bpf: Add support for certain atomics in bpf_arena to x86 JIT"")\nSigned-off-by: Ilya Leoshkevich <iii@linux.ibm.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240701234304.14336-2-iii@linux.ibm.com\n', '']",Fixes zero-extension issues in atomic probe operations within the eBPF verifier.,"atomic,probe,fails",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
da5f8fd1f0d393d5eaaba9ad8c22d1c26bb2bf9b,da5f8fd1f0d393d5eaaba9ad8c22d1c26bb2bf9b,Tao Chen,chen.dylane@gmail.com,1719925910,Daniel Borkmann,daniel@iogearbox.net,1719937232,83cbd2cfabaf5cad2a7579c3c8f9a3ace3116442,9474f72cd6573ee788013147e3590be4a28e085a,"bpftool: Mount bpffs when pinmaps path not under the bpffs

As Quentin said [0]"," BPF map pinning will fail if the pinmaps path is not
under the bpffs","[' like:\n\n  libbpf: specified path /home/ubuntu/test/sock_ops_map is not on BPF FS\n  Error: failed to pin all maps\n\n  [0] https://github.com/libbpf/bpftool/issues/146\n\nFixes: 3767a94b3253 (""bpftool: add pinmaps argument to the load/loadall"")\nSigned-off-by: Tao Chen <chen.dylane@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Quentin Monnet <qmo@kernel.org>\nReviewed-by: Quentin Monnet <qmo@kernel.org>\nLink: https://lore.kernel.org/bpf/20240702131150.15622-1-chen.dylane@gmail.com\n', '']",Mount bpffs in bpftool when pinmaps path is not under bpffs to prevent map pinning failures.,"bpftool, bpffs, pinmaps",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9474f72cd6573ee788013147e3590be4a28e085a,9474f72cd6573ee788013147e3590be4a28e085a,Pu Lehui,pulehui@huawei.com,1719922784,Daniel Borkmann,daniel@iogearbox.net,1719928922,dc157823e7c4ffbe50750f802c612765f76ac340,5d52ad36683af64f04da295d67fb943f94658929,"selftests/bpf: Add testcase where 7th argment is struct

Add testcase where 7th argument is struct for architectures with 8 argument
registers"," and increase the complexity of the struct.

Signed-off-by: Pu Lehui <pulehui@huawei.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Reviewed-by: Björn Töpel <bjorn@rivosinc.com>
Acked-by: Björn Töpel <bjorn@kernel.org>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Link: https://lore.kernel.org/bpf/20240702121944.1091530-4-pulehui@huaweicloud.com
",[''],Add a test case for architectures with 8 argument registers where the 7th argument is a struct.,"testcase, struct, architectures",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5d52ad36683af64f04da295d67fb943f94658929,5d52ad36683af64f04da295d67fb943f94658929,Pu Lehui,pulehui@huawei.com,1719922783,Daniel Borkmann,daniel@iogearbox.net,1719928913,ee0837692847b8e863157765b18734b69249544a,6801b0aef79db475591c3146a701ea373e4663b7,"selftests/bpf: Factor out many args tests from tracing_struct

Factor out many args tests from tracing_struct and rename some function names
to make more sense. Meanwhile"," remove unnecessary skeleton detach operation
as it will be covered by skeleton destroy operation.

Signed-off-by: Pu Lehui <pulehui@huawei.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Link: https://lore.kernel.org/bpf/20240702121944.1091530-3-pulehui@huaweicloud.com
",[''],The commit refactors many argument tests from tracing_struct and renames functions for clarity.,"refactor, tracing_struct, selftests",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tracepoints like programs']
6801b0aef79db475591c3146a701ea373e4663b7,6801b0aef79db475591c3146a701ea373e4663b7,Pu Lehui,pulehui@huawei.com,1719922782,Daniel Borkmann,daniel@iogearbox.net,1719928890,c4206e768f3df2d3ae3a2966101275a4813c2f56,e4a195e2b95e4602c667ed19a20f71218df138c2,riscv," bpf: Add 12-argument support for RV64 bpf trampoline

This patch adds 12 function arguments support for riscv64 bpf trampoline.
The current bpf trampoline supports <= sizeof(u64) bytes scalar arguments [0]
and <= 16 bytes struct arguments [1]. Therefore","[' we focus on the situation\nwhere scalars are at most XLEN bits and aggregates whose total size does not\nexceed 2×XLEN bits in the riscv calling convention [2].\n\nSigned-off-by: Pu Lehui <pulehui@huawei.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Björn Töpel <bjorn@rivosinc.com>\nAcked-by: Björn Töpel <bjorn@kernel.org>\nAcked-by: Puranjay Mohan <puranjay@kernel.org>\nLink: https://elixir.bootlin.com/linux/v6.8/source/kernel/bpf/btf.c#L6184 [0]\nLink: https://elixir.bootlin.com/linux/v6.8/source/kernel/bpf/btf.c#L6769 [1]\nLink: https://github.com/riscv-non-isa/riscv-elf-psabi-doc/releases/download/draft-20230929-e5c800e661a53efe3c2678d71a306323b60eb13b/riscv-abi.pdf [2]\nLink: https://lore.kernel.org/bpf/20240702121944.1091530-2-pulehui@huaweicloud.com\n', '']",Add support for 12 function arguments in RISC-V 64-bit BPF trampoline.,"riscv64,bpf,trampoline",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['tracepoints like programs', 'kprobe/uprobe/ftrace like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2a01a8895015ad479df7cfb8f127501d1c8da7c9,2a01a8895015ad479df7cfb8f127501d1c8da7c9,Paolo Abeni,pabeni@redhat.com,1719926819,Paolo Abeni,pabeni@redhat.com,1719926820,a822126b33b57d6d3abde8196612806e49545f3f,e27d7168f0c8c024344e9541513aa71d921402a5 e3d69f585d651aba877e18866de7e8cfa2476caa,"Merge branch 'net-bpf_net_context-cleanups'

Sebastian Andrzej Siewior says:

====================
net: bpf_net_context cleanups.

a small series with bpf_net_context cleanups/ improvements.
Jakub asked for #1 and #2 and while looking around I made #3.
====================

Link: https://patch.msgid.link/20240628103020.1766241-1-bigeasy@linutronix.de
Signed-off-by: Paolo Abeni <pabeni@redhat.com>
",,This commit performs cleanups and improvements on the bpf_net_context subsystem.,"bpf_net_context,cleanups,improvements",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
e3d69f585d651aba877e18866de7e8cfa2476caa,e3d69f585d651aba877e18866de7e8cfa2476caa,Sebastian Andrzej Siewior,bigeasy@linutronix.de,1719569936,Paolo Abeni,pabeni@redhat.com,1719926817,a822126b33b57d6d3abde8196612806e49545f3f,d839a73179ae91c07f5f2f97ccb9c69b2b7c3306,"net: Move flush list retrieval to where it is used.

The bpf_net_ctx_get_.*_flush_list() are used at the top of the function.
This means the variable is always assigned even if unused. By moving the
function to where it is used"," it is possible to delay the initialisation
until it is unavoidable.
Not sure how much this gains in reality but by looking at bq_enqueue()
(in devmap.c) gcc pushes one register less to the stack. \o/.

 Move flush list retrieval to where it is used.

Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Acked-by: Jesper Dangaard Brouer <hawk@kernel.org>
Reviewed-by: Jakub Kicinski <kuba@kernel.org>
Signed-off-by: Paolo Abeni <pabeni@redhat.com>
",[''],Move flush list retrieval to improve code efficiency by delaying initialization until necessary.,"flush list, efficiency, initialization",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF maps,['tc/netfilter like programs']
d839a73179ae91c07f5f2f97ccb9c69b2b7c3306,d839a73179ae91c07f5f2f97ccb9c69b2b7c3306,Sebastian Andrzej Siewior,bigeasy@linutronix.de,1719569935,Paolo Abeni,pabeni@redhat.com,1719926817,78ca317c579749b037de74a2a509e97b4cfbac89,2896624be30b049601ec3ef9b08df184d0c70495,"net: Optimize xdp_do_flush() with bpf_net_context infos.

Every NIC driver utilizing XDP should invoke xdp_do_flush() after
processing all packages. With the introduction of the bpf_net_context
logic the flush lists (for dev"," CPU-map and xsk) are lazy initialized
only if used. However xdp_do_flush() tries to flush all three of them so
all three lists are always initialized and the likely empty lists are
""iterated"".
Without the usage of XDP but with CONFIG_DEBUG_NET the lists are also
initialized due to xdp_do_check_flushed().

Jakub suggest to utilize the hints in bpf_net_context and avoid invoking
the flush function. This will also avoiding initializing the lists which
are otherwise unused.

Introduce bpf_net_ctx_get_all_used_flush_lists() to return the
individual list if not-empty. Use the logic in xdp_do_flush() and
xdp_do_check_flushed(). Remove the not needed .*_check_flush().

Suggested-by: Jakub Kicinski <kuba@kernel.org>
Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Reviewed-by: Jakub Kicinski <kuba@kernel.org>
Signed-off-by: Paolo Abeni <pabeni@redhat.com>
",[''],Optimize xdp_do_flush() using bpf_net_context to prevent unnecessary list initialization and improve performance.,xdp_do_flush bpf_net_context optimization,It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['xdp like programs']
2896624be30b049601ec3ef9b08df184d0c70495,2896624be30b049601ec3ef9b08df184d0c70495,Sebastian Andrzej Siewior,bigeasy@linutronix.de,1719569934,Paolo Abeni,pabeni@redhat.com,1719926817,d33b657120fd2e84f46fd1437ffe7751d2d9c754,e27d7168f0c8c024344e9541513aa71d921402a5,"net: Remove task_struct::bpf_net_context init on fork.

There is no clone() invocation within a bpf_net_ctx_…() block. Therefore
the task_struct::bpf_net_context has always to be NULL and an explicit
initialisation is not required.

Remove the NULL assignment in the clone() path.

Suggested-by: Jakub Kicinski <kuba@kernel.org>
Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Reviewed-by: Jakub Kicinski <kuba@kernel.org>
Signed-off-by: Paolo Abeni <pabeni@redhat.com>
",,Remove unnecessary NULL initialization of bpf_net_context on task_struct fork.,"bpf_net_context, task_struct, NULL",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['tc/netfilter like programs']
e4a195e2b95e4602c667ed19a20f71218df138c2,e4a195e2b95e4602c667ed19a20f71218df138c2,Tushar Vyavahare,tushar.vyavahare@intel.com,1719899956,Daniel Borkmann,daniel@iogearbox.net,1719925950,bc7c68f0934abe113ae48bf973f0bd2618601861,d80d61ab0609f7f7168d59ec82ee5f055a4b6be7,"selftests/xsk: Enhance batch size support with dynamic configurations

Introduce dynamic adjustment capabilities for fill_size and comp_size
parameters to support larger batch sizes beyond the previous 2K limit.

Update HW_SW_MAX_RING_SIZE test cases to evaluate AF_XDP's robustness by
pushing hardware and software ring sizes to their limits. This test
ensures AF_XDP's reliability amidst potential producer/consumer throttling
due to maximum ring utilization.

Signed-off-by: Tushar Vyavahare <tushar.vyavahare@intel.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Reviewed-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>
Link: https://lore.kernel.org/bpf/20240702055916.48071-3-tushar.vyavahare@intel.com
",,Enhance selftests for AF_XDP by adding dynamic configuration support for larger batch sizes in fill_size and comp_size parameters.,"AF_XDP, dynamic configuration, batch sizes",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
d80d61ab0609f7f7168d59ec82ee5f055a4b6be7,d80d61ab0609f7f7168d59ec82ee5f055a4b6be7,Tushar Vyavahare,tushar.vyavahare@intel.com,1719899955,Daniel Borkmann,daniel@iogearbox.net,1719925950,de7b370e9840bbcf7a6c1e17951b507a5367cf65,03922e97bc305c6b2e8bc4b7cc765959ca63b05d,"selftests/xsk: Ensure traffic validation proceeds after ring size adjustment in xskxceiver

Previously"," HW_SW_MIN_RING_SIZE and HW_SW_MAX_RING_SIZE test cases were
not validating Tx/Rx traffic at all due to early return after changing HW
ring size in testapp_validate_traffic().

Fix the flow by checking return value of set_ring_size() and act upon it
rather than terminating the test case there.

Signed-off-by: Tushar Vyavahare <tushar.vyavahare@intel.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Reviewed-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>
Link: https://lore.kernel.org/bpf/20240702055916.48071-2-tushar.vyavahare@intel.com
",[''],Fixes traffic validation issue after ring size adjustment in xskxceiver selftests.,"traffic,validation,ring",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
03922e97bc305c6b2e8bc4b7cc765959ca63b05d,03922e97bc305c6b2e8bc4b7cc765959ca63b05d,Zhu Jun,zhujun2@cmss.chinamobile.com,1719458345,Daniel Borkmann,daniel@iogearbox.net,1719846950,671288bd6b89cc0177a0d79fbb182ea96b095cd4,2382a405c581ae8f39f898055654e2000e7dd0d3,"selftests/bpf: Delete extra blank lines in test_sockmap

Delete extra blank lines inside of test_selftest().

Signed-off-by: Zhu Jun <zhujun2@cmss.chinamobile.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240627031905.7133-1-zhujun2@cmss.chinamobile.com
",,Clean up by removing extra blank lines in the BPF test_sockmap selftest.,"selftests,bpf,clean",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
2382a405c581ae8f39f898055654e2000e7dd0d3,2382a405c581ae8f39f898055654e2000e7dd0d3,Pu Lehui,pulehui@huawei.com,1719025477,Daniel Borkmann,daniel@iogearbox.net,1719846646,a4b02e470a6537ebfdadaf1bfa695a11b2f3db85,9f1e16fb1fc9826001c69e0551d51fbbcd2d74e9,riscv," bpf: Use bpf_prog_pack for RV64 bpf trampoline

We used bpf_prog_pack to aggregate bpf programs into huge page to
relieve the iTLB pressure on the system. We can apply it to bpf
trampoline","[' as Song had been implemented it in core and x86 [0]. This\npatch is going to use bpf_prog_pack to RV64 bpf trampoline. Since Song\nand Puranjay have done a lot of work for bpf_prog_pack on RV64', '\nimplementing this function will be easy.\n\nSigned-off-by: Pu Lehui <pulehui@huawei.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Björn Töpel <bjorn@rivosinc.com> #riscv\nLink: https://lore.kernel.org/all/20231206224054.492250-1-song@kernel.org [0]\nLink: https://lore.kernel.org/bpf/20240622030437.3973492-4-pulehui@huaweicloud.com\n', '']",The commit uses bpf_prog_pack to optimize RV64 bpf trampoline by aggregating programs into huge pages to reduce iTLB pressure.,"bpf_prog_pack, RV64, trampoline",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9f1e16fb1fc9826001c69e0551d51fbbcd2d74e9,9f1e16fb1fc9826001c69e0551d51fbbcd2d74e9,Pu Lehui,pulehui@huawei.com,1719025476,Daniel Borkmann,daniel@iogearbox.net,1719846646,f366bcd2adfc8d82678325158ee437a5889fcea7,d1a426171d76b2cdf3dea5d52f6266090e4aa254,riscv," bpf: Fix out-of-bounds issue when preparing trampoline image

We get the size of the trampoline image during the dry run phase and
allocate memory based on that size. The allocated image will then be
populated with instructions during the real patch phase. But after
commit 26ef208c209a (""bpf: Use arch_bpf_trampoline_size"")","["" the `im`\nargument is inconsistent in the dry run and real patch phase. This may\ncause emit_imm in RV64 to generate a different number of instructions\nwhen generating the 'im' address"", ' potentially causing out-of-bounds\nissues. Let\'s emit the maximum number of instructions for the ""im""\naddress during dry run to fix this problem.\n\nFixes: 26ef208c209a (""bpf: Use arch_bpf_trampoline_size"")\nSigned-off-by: Pu Lehui <pulehui@huawei.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240622030437.3973492-3-pulehui@huaweicloud.com\n', '']",Fix out-of-bounds issue in BPF trampoline image allocation for RISC-V platform.,"out-of-bounds, trampoline, RISC-V",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d1a426171d76b2cdf3dea5d52f6266090e4aa254,d1a426171d76b2cdf3dea5d52f6266090e4aa254,Pu Lehui,pulehui@huawei.com,1719025475,Daniel Borkmann,daniel@iogearbox.net,1719846646,a96c498ba0067e8966e1c9cc8ebb9cae0df7c829,5b747c23f17d791e08fdf4baa7e14b704625518c,"bpf: Use precise image size for struct_ops trampoline

For trampoline using bpf_prog_pack"," we need to generate a rw_image
buffer with size of (image_end - image). For regular trampoline","[' we use\nthe precise image size generated by arch_bpf_trampoline_size to allocate\nrw_image. But for struct_ops trampoline', ' we allocate rw_image directly\nusing close to PAGE_SIZE size. We do not need to allocate for that much', ""\nas the patch size is usually much smaller than PAGE_SIZE. Let's use\nprecise image size for it too.\n\nSigned-off-by: Pu Lehui <pulehui@huawei.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Björn Töpel <bjorn@rivosinc.com> #riscv\nAcked-by: Song Liu <song@kernel.org>\nLink: https://lore.kernel.org/bpf/20240622030437.3973492-2-pulehui@huaweicloud.com\n"", '']",The commit optimizes struct_ops trampoline by using a precise image size with bpf_prog_pack.,"struct_ops, trampoline, image",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5b747c23f17d791e08fdf4baa7e14b704625518c,5b747c23f17d791e08fdf4baa7e14b704625518c,Alan Maguire,alan.maguire@oracle.com,1719655258,Daniel Borkmann,daniel@iogearbox.net,1719846308,ab8242d6e3d89a3be472da66390204ad79e4d5f6,c77e572d3a8c0e21c5dca4cc2883c7cd8cbe981f,"libbpf: Fix error handling in btf__distill_base()

Coverity points out that after calling btf__new_empty_split() the wrong
value is checked for error.

Fixes: 58e185a0dc35 (""libbpf: Add btf__distill_base() creating split BTF with distilled base BTF"")
Reported-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Alan Maguire <alan.maguire@oracle.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240629100058.2866763-1-alan.maguire@oracle.com
",,Fix error handling in btf__distill_base() function in libbpf.,"libbpf,error handling,btf__distill_base",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c77e572d3a8c0e21c5dca4cc2883c7cd8cbe981f,c77e572d3a8c0e21c5dca4cc2883c7cd8cbe981f,Lorenzo Bianconi,lorenzo@kernel.org,1719700010,Daniel Borkmann,daniel@iogearbox.net,1719846191,2fcf594a3f8b5c161d8722d121fc5dc9233ccef7,391bb6594fd3a567efb1cd3efc8136c78c4c9e31,"selftests/bpf: Add selftest for bpf_xdp_flow_lookup kfunc

Introduce e2e selftest for bpf_xdp_flow_lookup kfunc through
xdp_flowtable utility.

Signed-off-by: Lorenzo Bianconi <lorenzo@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/b74393fb4539aecbbd5ac7883605f86a95fb0b6b.1719698275.git.lorenzo@kernel.org
",,Introduce an end-to-end selftest for bpf_xdp_flow_lookup kfunc using xdp_flowtable utility.,"selftest,bpf_xdp_flow_lookup,xdp_flowtable",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['xdp like programs']
391bb6594fd3a567efb1cd3efc8136c78c4c9e31,391bb6594fd3a567efb1cd3efc8136c78c4c9e31,Lorenzo Bianconi,lorenzo@kernel.org,1719700009,Daniel Borkmann,daniel@iogearbox.net,1719846181,39c9c0cacd23ea033ac3a003657abd91bc95d4c8,89cc8f1c5f22568142b7ad118c738204708e4207,"netfilter: Add bpf_xdp_flow_lookup kfunc

Introduce bpf_xdp_flow_lookup kfunc in order to perform the lookup
of a given flowtable entry based on a fib tuple of incoming traffic.
bpf_xdp_flow_lookup can be used as building block to offload in xdp
the processing of sw flowtable when hw flowtable is not available.

Signed-off-by: Lorenzo Bianconi <lorenzo@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>
Acked-by: Pablo Neira Ayuso <pablo@netfilter.org>
Link: https://lore.kernel.org/bpf/55d38a4e5856f6d1509d823ff4e98aaa6d356097.1719698275.git.lorenzo@kernel.org
",,This commit introduces the bpf_xdp_flow_lookup kfunc to facilitate flowtable entry lookup based on a FIB tuple in XDP programs.,"bpf_xdp_flow_lookup, netfilter, flowtable",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['xdp like programs', 'tc/netfilter like programs']"
89cc8f1c5f22568142b7ad118c738204708e4207,89cc8f1c5f22568142b7ad118c738204708e4207,Florian Westphal,fw@strlen.de,1719700008,Daniel Borkmann,daniel@iogearbox.net,1719846113,8fe95643954df3fe3f519fe20ab6c46c41c4ac52,a12978712d9001b060bcc10eaae42ad5102abe2b,"netfilter: nf_tables: Add flowtable map for xdp offload

This adds a small internal mapping table so that a new bpf (xdp) kfunc
can perform lookups in a flowtable.

As-is", xdp program has access to the device pointer,"[' but no way to do a\nlookup in a flowtable -- there is no way to obtain the needed struct\nwithout questionable stunts.\n\nThis allows to obtain an nf_flowtable pointer given a net_device\nstructure.\n\nIn order to keep backward compatibility', ' the infrastructure allows the\nuser to add a given device to multiple flowtables', ' but it will always\nreturn the first added mapping performing the lookup since it assumes\nthe right configuration is 1:1 mapping between flowtables and net_devices.\n\nCo-developed-by: Lorenzo Bianconi <lorenzo@kernel.org>\nSigned-off-by: Florian Westphal <fw@strlen.de>\nSigned-off-by: Lorenzo Bianconi <lorenzo@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Pablo Neira Ayuso <pablo@netfilter.org>\nLink: https://lore.kernel.org/bpf/9f20e2c36f494b3bf177328718367f636bb0b2ab.1719698275.git.lorenzo@kernel.org\n', '']",The commit adds a flowtable map for XDP offload in the nf_tables subsystem.,"flowtable,XDP,netfilter",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,['xdp like programs']
f58e7f404da44c94e46bfe657b8707195aebd25a,f58e7f404da44c94e46bfe657b8707195aebd25a,Benjamin Tissoires,bentiss@kernel.org,1719482062,Benjamin Tissoires,bentiss@kernel.org,1719838124,3f49ea1f04e284441927bd50ea0a785f68c080a7,9b52d81115db681efc1f83ded1d572e5b0b4fd49,"HID: bpf: Thrustmaster TCA Yoke Boeing joystick fix

This joystick's original HID descriptor is wrong & it shows a
ABS_MISC axis in Linux that doesn't exist on the hardware.

Link: https://gitlab.freedesktop.org/libevdev/udev-hid-bpf/-/merge_requests/82
Signed-off-by: K S Iyer <kumar.s.iyer65@gmail.com>
Link: https://patch.msgid.link/20240627-import-bpf-v1-6-0dbcda4a5b1f@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",,Fixes incorrect HID descriptor for the Thrustmaster TCA Yoke Boeing joystick.,"HID, joystick, fix",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['HID driver like programs']
9b52d81115db681efc1f83ded1d572e5b0b4fd49,9b52d81115db681efc1f83ded1d572e5b0b4fd49,Benjamin Tissoires,bentiss@kernel.org,1719482061,Benjamin Tissoires,bentiss@kernel.org,1719838119,85a17b193bdda031aa2bd305962d46bed3e64585,f03741540dbab48f8a65da44aaadbe04216d9a42,"HID: bpf: Add Huion Dial 2 bpf fixup

Pretty much similar to the Inspiroy 2"," but with 2 wheels and 8 buttons.

This bpf also works in both normal and vendor mode. If the device is
switched into vendor mode by huion-switcher","[' a udev property is set\nwhich is then retrieved by this bpf object. This allows to hide the now\nunused normal collections.\n\nLink: https://gitlab.freedesktop.org/libevdev/udev-hid-bpf/-/merge_requests/103\nLink: https://gitlab.freedesktop.org/libevdev/udev-hid-bpf/-/merge_requests/104\nLink: https://gitlab.freedesktop.org/libevdev/udev-hid-bpf/-/merge_requests/111\nLink: https://patch.msgid.link/20240627-import-bpf-v1-5-0dbcda4a5b1f@kernel.org\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']",Add bpf fixup for Huion Dial 2 devices to ensure compatibility with normal and vendor modes.,"HID, bpf, Huion",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['HID driver like programs']
f03741540dbab48f8a65da44aaadbe04216d9a42,f03741540dbab48f8a65da44aaadbe04216d9a42,Benjamin Tissoires,bentiss@kernel.org,1719482060,Benjamin Tissoires,bentiss@kernel.org,1719838117,778560cff2dfa020a07a851ce47b1635f2dba173,c4015aa7d8faa43ca53608dccad681eafc22db09,"HID: bpf: Add support for the XP-PEN Deco Mini 4

The XP-PEN Deco Mini 4 is a UGEE device with a frame with 6 buttons.
Its pen has 2 buttons and supports pressure reporting.

Fix their report descriptors and transform the frame button events to
support it.

Link: https://gitlab.freedesktop.org/libevdev/udev-hid-bpf/-/merge_requests/88
Signed-off-by: José Expósito <jose.exposito89@gmail.com>
Link: https://patch.msgid.link/20240627-import-bpf-v1-4-0dbcda4a5b1f@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",,Add support for XP-PEN Deco Mini 4 device in HID BPF framework.,"XP-PEN, HID, support",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['HID driver like programs']
c4015aa7d8faa43ca53608dccad681eafc22db09,c4015aa7d8faa43ca53608dccad681eafc22db09,Benjamin Tissoires,bentiss@kernel.org,1719482059,Benjamin Tissoires,bentiss@kernel.org,1719838113,54026980e7bee0d86e4c3e252b0c51e6caa52a9b,09c555faedb855b07d62503e0a4cd8cdf726da20,"HID: bpf: move the BIT() macro to hid_bpf_helpers.h

This macro can be useful in mopre than one place

Link: https://gitlab.freedesktop.org/libevdev/udev-hid-bpf/-/commit/7970a9c17aa0756bad63e89fccb6ee4f2ec83ccc
Signed-off-by: José Expósito <jose.exposito89@gmail.com>
Link: https://patch.msgid.link/20240627-import-bpf-v1-3-0dbcda4a5b1f@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",,The BIT() macro is moved to hid_bpf_helpers.h for broader utility.,"BIT macro, hid_bpf_helpers.h, utility",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['HID driver like programs']
09c555faedb855b07d62503e0a4cd8cdf726da20,09c555faedb855b07d62503e0a4cd8cdf726da20,Benjamin Tissoires,bentiss@kernel.org,1719482058,Benjamin Tissoires,bentiss@kernel.org,1719838103,9d61625764e7731d06cc37a78f0a3191b74ddb8e,8a89db51873ca574de45b25fce68103f34266459,"HID: bpf: add a driver for the Huion Inspiroy 2S (H641P)

This is a a driver for the Huion Inspiroy 2S in both modes (firmware mode
and tablet mode). This device has 6 buttons and a wheel"," all of which
send key combinations (see the comments for the defaults). Luckily the
device is quite limited in that it only supports one button down at a
time","[' so with this BPF we can simply remap the 8 possible report IDs to\nour own custom-built report descriptor.\n\nIf the device is in tablet mode (e.g. using huion-switcher it sends\neverything through the vendor report instead). This BPF program converts\nboth', "" depending which devices you attach to you get both. Or if you\nattach to all hid devices you get a duplicate device but it'll work\neither way.\n\nThis BPF should be mostly compatible for the M and L as well though they\nhave more buttons so the rdescs will need some minor rework.\n\nLink: https://gitlab.freedesktop.org/libevdev/udev-hid-bpf/-/merge_requests/85\nLink: https://gitlab.freedesktop.org/libevdev/udev-hid-bpf/-/merge_requests/109\nSigned-off-by: Peter Hutterer <peter.hutterer@who-t.net>\nLink: https://patch.msgid.link/20240627-import-bpf-v1-2-0dbcda4a5b1f@kernel.org\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n"", '']",This commit adds a driver for the Huion Inspiroy 2S tablet supporting firmware and tablet modes.,"driver, Huion, tablet",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['HID driver like programs']
8a89db51873ca574de45b25fce68103f34266459,8a89db51873ca574de45b25fce68103f34266459,Benjamin Tissoires,bentiss@kernel.org,1719482057,Benjamin Tissoires,bentiss@kernel.org,1719838098,950d448761d56272fceb7d76bd76ddcf87d9f6a4,c79de517a226b86419a5baa867e65e3f8118829f,"HID: bpf: Add a HID report composition helper macros

These macros make it slightly easier and more modular to create
a HID report descriptor from scratch. Since they carry the annotation
we don't need to comment it and they cannot get stale.

For comparison"," before we had this:

        0x15","[' 0x00', '                    //   Logical Minimum (0)\n        0x25', ' 0x01', '                    //   Logical Maximum (1)\n        0x95', ' 0x04', '                    //   Report Count (4)\n        0x75', ' 0x01', '                    //   Report Size (1)\n\nNow we can write this as:\n        LogicalRange_i8(0', ' 1)\n        ReportCount(4)\n        ReportSize(1)\n\nBecause these macros are for creating new report descriptors', ""\nsome bits aren't directly exposed. e.g in the example above:\nthere is a logical range as one macro that sets both min and max.\nThere is seldom a good use case for skipping either anyway.\n\nThese macros will need to be expanded over time.\n\nFor Usage Pages and Usage IDs"", ' we use a tool to parse the HUT JSON\n(attached to the HUT 1.5 PDF [1]) and generate all #defines for all\nusage pages and usages in the form:\n\n #define UsagePage_Foo_Bar\n #define Usage_FB_SomeOrOther\n\nWhere the FB is simply the acronym based on the capital letters in the\nUsage Page name or the first three letters', ' whichever makes slightly\nmore sense.\n\n[1] https://usb.org/document-library/hid-usage-tables-15\n\nLink: https://gitlab.freedesktop.org/libevdev/udev-hid-bpf/-/merge_requests/92\nLink: https://gitlab.freedesktop.org/libevdev/udev-hid-bpf/-/merge_requests/96\nSigned-off-by: Peter Hutterer <peter.hutterer@who-t.net>\nLink: https://patch.msgid.link/20240627-import-bpf-v1-1-0dbcda4a5b1f@kernel.org\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']",Added helper macros for easier and modular creation of HID report descriptors.,"HID,bpf,macros",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['HID driver like programs']
c79de517a226b86419a5baa867e65e3f8118829f,c79de517a226b86419a5baa867e65e3f8118829f,Benjamin Tissoires,bentiss@kernel.org,1719837592,Benjamin Tissoires,bentiss@kernel.org,1719838096,1b591c2fadeaae81ac923b2d2a7c8ee6637263ff,260ffc9676b635c2ededc39285bfa41f83536ee1,"HID: bpf: doc fixes for hid_hw_request() hooks

We had the following errors while doing make htmldocs:

Documentation/hid/hid-bpf:185: include/linux/hid_bpf.h:167:
	ERROR: Unexpected indentation.

Also ensure consistency with the rest of the __u64 vs u64.

Reported-by: Stephen Rothwell <sfr@canb.auug.org.au>
Fixes: 9286675a2aed (""HID: bpf: add HID-BPF hooks for hid_hw_output_report"")
Link: https://patch.msgid.link/20240701-fix-cki-v2-4-20564e2e1393@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",,Fixes documentation errors related to HID-BPF hooks in hid_hw_request().,"HID, BPF, documentation",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['HID driver like programs']
260ffc9676b635c2ededc39285bfa41f83536ee1,260ffc9676b635c2ededc39285bfa41f83536ee1,Benjamin Tissoires,bentiss@kernel.org,1719837591,Benjamin Tissoires,bentiss@kernel.org,1719838094,6be4c891f02e4fedbe4cf8ef355a72c146220db4,762ced1630a97a457ad2fd5f5a36849009808431,"HID: bpf: doc fixes for hid_hw_request() hooks

We had the following errors while doing make htmldocs:
Documentation/hid/hid-bpf:185: include/linux/hid_bpf.h:144:
	ERROR: Unexpected indentation.
Documentation/hid/hid-bpf:185: include/linux/hid_bpf.h:145:
	WARNING: Block quote ends without a blank line;
	unexpected unindent.
Documentation/hid/hid-bpf:185: include/linux/hid_bpf.h:147:
	ERROR: Unexpected indentation.

Reported-by: Stephen Rothwell <sfr@canb.auug.org.au>
Fixes: 8bd0488b5ea5 (""HID: bpf: add HID-BPF hooks for hid_hw_raw_requests"")
Link: https://patch.msgid.link/20240701-fix-cki-v2-3-20564e2e1393@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",,Fix documentation errors for HID-BPF related to hid_hw_request() hooks.,"HID,BPF,documentation",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['HID driver like programs']
762ced1630a97a457ad2fd5f5a36849009808431,762ced1630a97a457ad2fd5f5a36849009808431,Benjamin Tissoires,bentiss@kernel.org,1719837590,Benjamin Tissoires,bentiss@kernel.org,1719838091,d1811f6b035a46834633b6e46f629ed9cd298a72,fcdf830ea634cf0ee6543b6cd6a4932f92464fc7,"HID: bpf: fix gcc warning and unify __u64 into u64

I've got multiple reports of:
error: cast from pointer to integer of different size
[-Werror=pointer-to-int-cast].

Let's use the same trick than kernel/bpf/helpers.c to shut up that warning.

Even if we were on an architecture with addresses on more than 64 bits","
this isn't much of an issue as the address is not used as a pointer","['\nbut as an hash and the caller is not supposed to go back to the kernel\naddress ever.\n\nAnd while we change those', ' make sure we use u64 instead of __u64 for\nconsistency\n\nReported-by: Stephen Rothwell <sfr@canb.auug.org.au>\nReported-by: kernel test robot <lkp@intel.com>\nCloses: https://lore.kernel.org/oe-kbuild-all/202406280633.OPB5uIFj-lkp@intel.com/\nCloses: https://lore.kernel.org/oe-kbuild-all/202406282304.UydSVncq-lkp@intel.com/\nCloses: https://lore.kernel.org/oe-kbuild-all/202406282242.Fk738zzy-lkp@intel.com/\nReported-by: Mirsad Todorovac <mtodorovac69@gmail.com>\nFixes: 67eccf151d76 (""HID: add source argument to HID low level functions"")\nLink: https://patch.msgid.link/20240701-fix-cki-v2-2-20564e2e1393@kernel.org\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']",Fixes a gcc warning by unifying pointer casting to consistent u64 type in HID BPF implementation.,"gcc warning, unify u64, pointer casting",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,['HID driver like programs']
fcdf830ea634cf0ee6543b6cd6a4932f92464fc7,fcdf830ea634cf0ee6543b6cd6a4932f92464fc7,Benjamin Tissoires,bentiss@kernel.org,1719837589,Benjamin Tissoires,bentiss@kernel.org,1719838083,bd14a95f4b17f38a4ee2610f2d5348a82eba21ea,d3e15189bfd4d0a9d3a7ad8bd0e6ebb1c0419f93,"selftests/hid: ensure CKI can compile our new tests on old kernels

In the same way than commit ae7487d112cf (""selftests/hid: ensure we can
compile the tests on kernels pre-6.3"") we should expose struct hid_bpf_ops
when it's not available in vmlinux.h.

So unexpose an eventual struct hid_bpf_ops", include vmlinux.h,"[' and\nre-export struct hid_bpf_ops.\n\nFixes: d7696738d66b (""selftests/hid: convert the hid_bpf selftests with struct_ops"")\nReported-by: kernel test robot <lkp@intel.com>\nCloses: https://lore.kernel.org/r/202406270328.bscLN1IF-lkp@intel.com/\nLink: https://patch.msgid.link/20240701-fix-cki-v2-1-20564e2e1393@kernel.org\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']",Modify selftests to ensure compatibility with older kernels by managing the struct hid_bpf_ops exposure.,"selftests, compatibility, hid_bpf_ops",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['HID driver like programs']
d04bccd8c19d601232ed3e3c9e248c0040167d47,d04bccd8c19d601232ed3e3c9e248c0040167d47,Christian Brauner,brauner@kernel.org,1717772137,Christian Brauner,brauner@kernel.org,1719561209,31e4865f1831a61999cff6152362078f54fbf9ea,17e70161281bb66316e94e63a15d1a8498bf6f01,"listmount: allow listing in reverse order

util-linux is about to implement listmount() and statmount() support.
Karel requested the ability to scan the mount table in backwards order
because that's what libmount currently does in order to get the latest
mount first. We currently don't support this in listmount(). Add a new
LISTMOUNT_REVERSE flag to allow listing mounts in reverse order. For
example"," listing all child mounts of /sys without LISTMOUNT_REVERSE
gives:

    /sys/kernel/security @ mnt_id: 4294968369
    /sys/fs/cgroup @ mnt_id: 4294968370
    /sys/firmware/efi/efivars @ mnt_id: 4294968371
    /sys/fs/bpf @ mnt_id: 4294968372
    /sys/kernel/tracing @ mnt_id: 4294968373
    /sys/kernel/debug @ mnt_id: 4294968374
    /sys/fs/fuse/connections @ mnt_id: 4294968375
    /sys/kernel/config @ mnt_id: 4294968376

whereas with LISTMOUNT_REVERSE it gives:

    /sys/kernel/config @ mnt_id: 4294968376
    /sys/fs/fuse/connections @ mnt_id: 4294968375
    /sys/kernel/debug @ mnt_id: 4294968374
    /sys/kernel/tracing @ mnt_id: 4294968373
    /sys/fs/bpf @ mnt_id: 4294968372
    /sys/firmware/efi/efivars @ mnt_id: 4294968371
    /sys/fs/cgroup @ mnt_id: 4294968370
    /sys/kernel/security @ mnt_id: 4294968369

Link: https://lore.kernel.org/r/20240607-vfs-listmount-reverse-v1-4-7877a2bfa5e5@kernel.org
Reviewed-by: Josef Bacik <josef@toxicpanda.com>
Signed-off-by: Christian Brauner <brauner@kernel.org>
",[''],The commit adds a LISTMOUNT_REVERSE flag to support listing mount points in reverse order.,"listmount, reverse, mount",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
fd19d4a492af77b1e8fb0439781a3048d1d1f554,fd19d4a492af77b1e8fb0439781a3048d1d1f554,Linus Torvalds,torvalds@linux-foundation.org,1719507935,Linus Torvalds,torvalds@linux-foundation.org,1719507935,c293c1a1218fe87c4b6712938352dbc349d0b68e,3c1d29e53d34537063e60f5eafe0482780a1735a b62cb6a7e83622783100182d9b70e9c70393cfbe,"Merge tag 'net-6.10-rc6' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Paolo Abeni:
 ""Including fixes from can"," bpf and netfilter.

  There are a bunch of regressions addressed here","[' but hopefully nothing\n  spectacular. We are still waiting the driver fix from Intel', ' mentioned\n  by Jakub in the previous networking pull.\n\n  Current release - regressions:\n\n   - core: add softirq safety to netdev_rename_lock\n\n   - tcp: fix tcp_rcv_fastopen_synack() to enter TCP_CA_Loss for failed\n     TFO\n\n   - batman-adv: fix RCU race at module unload time\n\n  Previous releases - regressions:\n\n   - openvswitch: get related ct labels from its master if it is not\n     confirmed\n\n   - eth: bonding: fix incorrect software timestamping report\n\n   - eth: mlxsw: fix memory corruptions on spectrum-4 systems\n\n   - eth: ionic: use dev_consume_skb_any outside of napi\n\n  Previous releases - always broken:\n\n   - netfilter: fully validate NFT_DATA_VALUE on store to data registers\n\n   - unix: several fixes for OoB data\n\n   - tcp: fix race for duplicate reqsk on identical SYN\n\n   - bpf:\n       - fix may_goto with negative offset\n       - fix the corner case with may_goto and jump to the 1st insn\n       - fix overrunning reservations in ringbuf\n\n   - can:\n       - j1939: recover socket queue on CAN bus error during BAM\n         transmission\n       - mcp251xfd: fix infinite loop when xmit fails\n\n   - dsa: microchip: monitor potential faults in half-duplex mode\n\n   - eth: vxlan: pull inner IP header in vxlan_xmit_one()\n\n   - eth: ionic: fix kernel panic due to multi-buffer handling\n\n  Misc:\n\n   - selftest: unix tests refactor and a lot of new cases added""\n\n* tag \'net-6.10-rc6\' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (61 commits)\n  net: mana: Fix possible double free in error handling path\n  selftest: af_unix: Check SIOCATMARK after every send()/recv() in msg_oob.c.\n  af_unix: Fix wrong ioctl(SIOCATMARK) when consumed OOB skb is at the head.\n  selftest: af_unix: Check EPOLLPRI after every send()/recv() in msg_oob.c\n  selftest: af_unix: Check SIGURG after every send() in msg_oob.c\n  selftest: af_unix: Add SO_OOBINLINE test cases in msg_oob.c\n  af_unix: Don\'t stop recv() at consumed ex-OOB skb.\n  selftest: af_unix: Add non-TCP-compliant test cases in msg_oob.c.\n  af_unix: Don\'t stop recv(MSG_DONTWAIT) if consumed OOB skb is at the head.\n  af_unix: Stop recv(MSG_PEEK) at consumed OOB skb.\n  selftest: af_unix: Add msg_oob.c.\n  selftest: af_unix: Remove test_unix_oob.c.\n  tracing/net_sched: NULL pointer dereference in perf_trace_qdisc_reset()\n  netfilter: nf_tables: fully validate NFT_DATA_VALUE on store to data registers\n  net: usb: qmi_wwan: add Telit FN912 compositions\n  tcp: fix tcp_rcv_fastopen_synack() to enter TCP_CA_Loss for failed TFO\n  ionic: use dev_consume_skb_any outside of napi\n  net: dsa: microchip: fix wrong register write when masking interrupt\n  Fix race for duplicate reqsk on identical SYN\n  ibmvnic: Add tx check to prevent skb leak\n  ...\n', '']",This commit merges networking fixes addressing regressions in the kernel from the netdev and netfilter repositories.,"networking, fixes, regressions",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
7e1f4eb9a60d40dd17a97d9b76818682a024a127,7e1f4eb9a60d40dd17a97d9b76818682a024a127,Arnd Bergmann,arnd@arndb.de,1712225094,Arnd Bergmann,arnd@arndb.de,1719503020,3d0fcf4996760f07141da85cab2629edc2859cfd,0fa8ab5f3533b307a7d0e438ab08ecd92725dad7,"kallsyms: rework symbol lookup return codes

Building with W=1 in some configurations produces a false positive
warning for kallsyms:

kernel/kallsyms.c: In function '__sprint_symbol.isra':
kernel/kallsyms.c:503:17: error: 'strcpy' source argument is the same as destination [-Werror=restrict]
  503 |                 strcpy(buffer"," name);
      |                 ^~~~~~~~~~~~~~~~~~~~

This originally showed up while building with -O3","[' but later started\nhappening in other configurations as well', "" depending on inlining\ndecisions. The underlying issue is that the local 'name' variable is\nalways initialized to the be the same as 'buffer' in the called functions\nthat fill the buffer"", ' which gcc notices while inlining', ' though it could\nsee that the address check always skips the copy.\n\nThe calling conventions here are rather unusual', ' as all of the internal\nlookup functions (bpf_address_lookup', ' ftrace_mod_address_lookup', '\nftrace_func_address_lookup', ' module_address_lookup and\nkallsyms_lookup_buildid) already use the provided buffer and either return\nthe address of that buffer to indicate success', ' or NULL for failure', '\nbut the callers are written to also expect an arbitrary other buffer\nto be returned.\n\nRework the calling conventions to return the length of the filled buffer\ninstead of its address', ' which is simpler and easier to follow as well\nas avoiding the warning. Leave only the kallsyms_lookup() calling conventions\nunchanged', ' since that is called from 16 different functions and\nadapting this would be a much bigger change.\n\nLink: https://lore.kernel.org/lkml/20200107214042.855757-1-arnd@arndb.de/\nLink: https://lore.kernel.org/lkml/20240326130647.7bfb1d92@gandalf.local.home/\nTested-by: Geert Uytterhoeven <geert+renesas@glider.be>\nReviewed-by: Luis Chamberlain <mcgrof@kernel.org>\nAcked-by: Steven Rostedt (Google) <rostedt@goodmis.org>\nSigned-off-by: Arnd Bergmann <arnd@arndb.de>\n', '']",Reworked symbol lookup return codes to fix a false positive warning in kallsyms when built with W=1.,"kallsyms, symbol lookup, warning",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
d3e15189bfd4d0a9d3a7ad8bd0e6ebb1c0419f93,d3e15189bfd4d0a9d3a7ad8bd0e6ebb1c0419f93,Benjamin Tissoires,bentiss@kernel.org,1719409594,Benjamin Tissoires,bentiss@kernel.org,1719478849,45b1e0d1caf75a76d8681dfe160e53723a1f5924,62f2e1a096cd4380eca7e55fa4369d50a8536ab8,"selftests/hid: add an infinite loop test for hid_bpf_try_input_report

We don't want this call to allow an infinite loop in HID-BPF"," so let's
have some tests.

Link: https://patch.msgid.link/20240626-hid_hw_req_bpf-v2-13-cfd60fb6c79f@kernel.org
Acked-by: Jiri Kosina <jkosina@suse.com>
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Add infinite loop test case for hid_bpf_try_input_report in HID selftests.,"infinite loop, HID, tests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['HID driver like programs']
62f2e1a096cd4380eca7e55fa4369d50a8536ab8,62f2e1a096cd4380eca7e55fa4369d50a8536ab8,Benjamin Tissoires,bentiss@kernel.org,1719409593,Benjamin Tissoires,bentiss@kernel.org,1719478849,b4f4f85a90067429956836d040b6ba21ef7b3f4f,9acbb7ba4589d4715141d4e14230a828ddc95f3d,"selftests/hid: add another test for injecting an event from an event hook

Similar to test_multiply_events_wq: we receive one event and inject a
new one. But given that this time we are already in the event hook"," we
can use hid_bpf_try_input_report() directly as this function will not
sleep.

Note that the injected event gets processed before the original one this
way.

Link: https://patch.msgid.link/20240626-hid_hw_req_bpf-v2-12-cfd60fb6c79f@kernel.org
Acked-by: Jiri Kosina <jkosina@suse.com>
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Add a selftest for event injection in HID drivers using an event hook.,"selftest,HID,event injection",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['HID driver like programs']
9acbb7ba4589d4715141d4e14230a828ddc95f3d,9acbb7ba4589d4715141d4e14230a828ddc95f3d,Benjamin Tissoires,bentiss@kernel.org,1719409592,Benjamin Tissoires,bentiss@kernel.org,1719478848,f1abe2c3dd3329e90a07850a79c0cdf20466c8d1,fe8d561db3e82a1130c59ebc143d557b0bdb0cff,"HID: bpf: allow hid_device_event hooks to inject input reports on self

This is the same logic than hid_hw_raw_request or hid_hw_output_report:
we can allow hid_bpf_try_input_report to be called from a hook on
hid_input_report if we ensure that the call can not be made twice in a
row.

There is one extra subtlety in which there is a lock in hid_input_report.
But given that we can detect if we are already in the hook"," we can notify
hid_input_report to not take the lock. This is done by checking if
ctx_kern data is valid or null","[' and if it is equal to the dedicated\nincoming data buffer.\n\nIn order to have more control on whether the lock needs to be taken or not\nwe introduce a new kfunc for it: hid_bpf_try_input_report()\n\nLink: https://patch.msgid.link/20240626-hid_hw_req_bpf-v2-11-cfd60fb6c79f@kernel.org\nAcked-by: Jiri Kosina <jkosina@suse.com>\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']","The commit allows HID BPF hooks to inject input reports on the device itself, ensuring no repeated calls.","HID, input, hook",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['HID driver like programs']
fe8d561db3e82a1130c59ebc143d557b0bdb0cff,fe8d561db3e82a1130c59ebc143d557b0bdb0cff,Benjamin Tissoires,bentiss@kernel.org,1719409591,Benjamin Tissoires,bentiss@kernel.org,1719478848,8fe5ee74baf94901735e754336b6fd91b1cd1b2d,fa03f398a8ac46f46927e0b509b302ebe0ed7e8a,"selftests/hid: add wq test for hid_bpf_input_report()

Now that bpf_wq is available"," we can write a test with it. Having
hid_bpf_input_report() waiting for the device means that we can
directly call it","[' and we get that event when the device is ready.\n\nLink: https://patch.msgid.link/20240626-hid_hw_req_bpf-v2-10-cfd60fb6c79f@kernel.org\nAcked-by: Jiri Kosina <jkosina@suse.com>\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']",Add selftest for hid_bpf_input_report using bpf_wq in HID driver.,"selftests,hid_bpf_input_report,bpf_wq",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['HID driver like programs']
fa03f398a8ac46f46927e0b509b302ebe0ed7e8a,fa03f398a8ac46f46927e0b509b302ebe0ed7e8a,Benjamin Tissoires,bentiss@kernel.org,1719409590,Benjamin Tissoires,bentiss@kernel.org,1719478848,0a6577f9023e66ff6e8c01317775f865958fc781,3ac83fcd6e67c86d25040e6818972f2c36b51d23,"HID: bpf: make hid_bpf_input_report() sleep until the device is ready

hid_bpf_input_report() is already marked to be used in sleepable context
only. So instead of hammering with timers the device to hopefully get
an available slot where the device is not sending events"," we can make
that kfunc wait for the current event to be terminated before it goes in.

This allows to work with the following pseudo code:

in struct_ops/hid_device_event:
  - schedule a bpf_wq","[' which calls hid_bpf_input_report()\n  - once this struct_ops function terminates', ' hid_bpf_input_report()\n    immediately starts before the next event\n\nLink: https://patch.msgid.link/20240626-hid_hw_req_bpf-v2-9-cfd60fb6c79f@kernel.org\nAcked-by: Jiri Kosina <jkosina@suse.com>\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']",The commit modifies hid_bpf_input_report() to wait until the device is ready.,"HID,sleep,context",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['HID driver like programs']
3ac83fcd6e67c86d25040e6818972f2c36b51d23,3ac83fcd6e67c86d25040e6818972f2c36b51d23,Benjamin Tissoires,bentiss@kernel.org,1719409589,Benjamin Tissoires,bentiss@kernel.org,1719478848,d87be489e8b112eab85ead9ca28cd04df31fad3c,9286675a2aed40a517be8cc4e283a04f473275b5,"selftests/hid: add tests for hid_hw_output_report HID-BPF hooks

We add 3 new tests:
- first"," we make sure we can prevent the output_report to happen
- second","[' we make sure that we can detect that a given hidraw client\n  was actually doing the request', ' and for that client only', ' call ourself\n  hid_bpf_hw_output_report()', ' returning a custom value\n- last', ' we ensure that we can not loop between hooks for\n  hid_hw_output_report() and manual calls to hid_bpf_hw_output_report()\n  from that same hook\n\nLink: https://patch.msgid.link/20240626-hid_hw_req_bpf-v2-8-cfd60fb6c79f@kernel.org\nAcked-by: Jiri Kosina <jkosina@suse.com>\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']",Added three new selftests for hid_hw_output_report HID-BPF hooks.,"selftests,hid,BPF",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['HID driver like programs']
9286675a2aed40a517be8cc4e283a04f473275b5,9286675a2aed40a517be8cc4e283a04f473275b5,Benjamin Tissoires,bentiss@kernel.org,1719409588,Benjamin Tissoires,bentiss@kernel.org,1719478845,9d32d1f847856d770a8c7374cc278ea91b6dbb73,015a4a2a439b285943da471d38b2721bbe4d8b39,"HID: bpf: add HID-BPF hooks for hid_hw_output_report

Same story than hid_hw_raw_requests:

This allows to intercept and prevent or change the behavior of
hid_hw_output_report() from a bpf program.

The intent is to solve a couple of use case:
  - firewalling a HID device: a firewall can monitor who opens the hidraw
    nodes and then prevent or allow access to write operations on that
    hidraw node.
  - change the behavior of a device and emulate a new HID feature request

The hook is allowed to be run as sleepable so it can itself call
hid_hw_output_report()"," which allows to ""convert"" one feature request into
another or even call the feature request on a different HID device on the
same physical device.

Link: https://patch.msgid.link/20240626-hid_hw_req_bpf-v2-7-cfd60fb6c79f@kernel.org
Acked-by: Jiri Kosina <jkosina@suse.com>
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],The commit introduces HID-BPF hooks for intercepting and modifying hid_hw_output_report behaviors.,"HID-BPF, hooks, intercept",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['HID driver like programs']
015a4a2a439b285943da471d38b2721bbe4d8b39,015a4a2a439b285943da471d38b2721bbe4d8b39,Benjamin Tissoires,bentiss@kernel.org,1719409587,Benjamin Tissoires,bentiss@kernel.org,1719478812,a3d840ad28df57e4e9bab80e8b57ba6289863fb0,75839101ce52e319cb2154a027d14f1f0aa3be09,"selftests/hid: add tests for hid_hw_raw_request HID-BPF hooks

We add 3 new tests:
- first"," we make sure we can prevent the raw_request to happen
- second","[' we make sure that we can detect that a given hidraw client\n  was actually doing the request', ' and for that client only', ' call ourself\n  hid_bpf_hw_request()', ' returning a custom value\n- last', ' we ensure that we can not loop between hooks for\n  hid_hw_raw_request() and manual calls to hid_bpf_hw_request() from that\n  hook\n\nLink: https://patch.msgid.link/20240626-hid_hw_req_bpf-v2-6-cfd60fb6c79f@kernel.org\nAcked-by: Jiri Kosina <jkosina@suse.com>\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']",Added self-tests for HID-BPF hooks using hid_hw_raw_request.,"self-tests,HID-BPF,hooks",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['HID driver like programs']
75839101ce52e319cb2154a027d14f1f0aa3be09,75839101ce52e319cb2154a027d14f1f0aa3be09,Benjamin Tissoires,bentiss@kernel.org,1719409586,Benjamin Tissoires,bentiss@kernel.org,1719478812,37b05cb095474429cd80940e2c7b2e6d6d3a92a7,8bd0488b5ea58655ad6fdcbe0408ef49b16882b1,"HID: bpf: prevent infinite recursions with hid_hw_raw_requests hooks

When we attach a sleepable hook to hid_hw_raw_requests"," we can (and in
many cases should) call ourself hid_bpf_raw_request()","[' to actually fetch\ndata from the device itself.\n\nHowever', ' this means that we might enter an infinite loop between\nhid_hw_raw_requests hooks and hid_bpf_hw_request() call.\n\nTo prevent that', ' if a hid_bpf_hw_request() call is emitted', ' we prevent\nany new call of this kfunc by storing the information in the context.\nThis way we can always trace/monitor/filter the incoming bpf requests', '\nwhile preventing those loops to happen.\n\nI don\'t think exposing ""from_bpf"" is very interesting because while\nwriting such a bpf program', ' you need to match at least the report number\nand/or the source of the call. So a blind ""if there is a\nhid_hw_raw_request() call', ' I\'m emitting another one"" makes no real\nsense.\n\nLink: https://patch.msgid.link/20240626-hid_hw_req_bpf-v2-5-cfd60fb6c79f@kernel.org\nAcked-by: Jiri Kosina <jkosina@suse.com>\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']",Prevent infinite recursion in HID BPF raw requests with sleepable hooks.,"HID,BPF,infinite recursion",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['HID driver like programs']
8bd0488b5ea58655ad6fdcbe0408ef49b16882b1,8bd0488b5ea58655ad6fdcbe0408ef49b16882b1,Benjamin Tissoires,bentiss@kernel.org,1719409585,Benjamin Tissoires,bentiss@kernel.org,1719478807,490b7e0108d826a9711f6796881ac1ce5d350748,6cd735f0e57a6c8510ad92f5b63837a8d0cff3a7,"HID: bpf: add HID-BPF hooks for hid_hw_raw_requests

This allows to intercept and prevent or change the behavior of
hid_hw_raw_request() from a bpf program.

The intent is to solve a couple of use case:
- firewalling a HID device: a firewall can monitor who opens the hidraw
  nodes and then prevent or allow access to write operations on that
  hidraw node.
- change the behavior of a device and emulate a new HID feature request

The hook is allowed to be run as sleepable so it can itself call
hid_bpf_hw_request()"," which allows to ""convert"" one feature request into
another or even call the feature request on a different HID device on the
same physical device.

Link: https://patch.msgid.link/20240626-hid_hw_req_bpf-v2-4-cfd60fb6c79f@kernel.org
Acked-by: Jiri Kosina <jkosina@suse.com>
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Added HID-BPF hooks to intercept and modify hid_hw_raw_requests.,"HID-BPF,hooks,intercept",It's a new feature.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['HID driver like programs']
6cd735f0e57a6c8510ad92f5b63837a8d0cff3a7,6cd735f0e57a6c8510ad92f5b63837a8d0cff3a7,Benjamin Tissoires,bentiss@kernel.org,1719409584,Benjamin Tissoires,bentiss@kernel.org,1719478702,dcd4c66314d7a4fedf3438f199f34ddc24bcf3db,67eccf151d76a9939ad8a50c6db5cb486b01df24,"HID: bpf: protect HID-BPF prog_list access by a SRCU

We want to add sleepable callbacks for hid_hw_raw_request() and
hid_hw_output_report()"," but we can not use a plain RCU for those.

Prepare for a SRCU so we can extend HID-BPF.

This changes a little bit how hid_bpf_device_init() behaves","[' as it may\nnow fail', ' so there is a tiny hid-core.c change to accommodate for this.\n\nLink: https://patch.msgid.link/20240626-hid_hw_req_bpf-v2-3-cfd60fb6c79f@kernel.org\nAcked-by: Jiri Kosina <jkosina@suse.com>\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']",Introduce SRCU to protect HID-BPF prog_list access and enable sleepable callbacks for certain HID functions.,"SRCU,HID-BPF,callbacks",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['HID driver like programs']
67eccf151d76a9939ad8a50c6db5cb486b01df24,67eccf151d76a9939ad8a50c6db5cb486b01df24,Benjamin Tissoires,bentiss@kernel.org,1719409583,Benjamin Tissoires,bentiss@kernel.org,1719478699,1a2b0d02140df64b820dded3ccc511d38d47ee1d,ebae0b2a6f4b3b949f30f076fbc65d3b0bb04785,"HID: add source argument to HID low level functions

This allows to know who actually sent what when we process the request
to the device.
This will be useful for a BPF firewall program to allow or not requests
coming from a dedicated hidraw node client.

Link: https://patch.msgid.link/20240626-hid_hw_req_bpf-v2-2-cfd60fb6c79f@kernel.org
Acked-by: Jiri Kosina <jkosina@suse.com>
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",,Added a source argument to HID low-level functions for BPF firewall use in managing requests.,"HID,BPF,firewall",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['HID driver like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ebae0b2a6f4b3b949f30f076fbc65d3b0bb04785,ebae0b2a6f4b3b949f30f076fbc65d3b0bb04785,Benjamin Tissoires,bentiss@kernel.org,1719409582,Benjamin Tissoires,bentiss@kernel.org,1719478680,8ec96bb7ba7659ab7bb01c1c20f02c96547e3895,9e16bada9299d74fcce1f6b03606a08a2c16da81,"HID: bpf: fix dispatch_hid_bpf_device_event uninitialized ret value

Looks like if a bpf program gets inserted and then removed","
hdev->bpf.device_data is then allocated","[' but the loop iterating\nover the bpf program is never assigning ret.\n\nThis is a problem and also revealed another bug in which only the last\nvalue of ret was checked. This effectively meant than only the last\nprogram in the chain could change the size of the incoming buffer.\n\nReported-by: Dan Carpenter <dan.carpenter@linaro.org>\nLink: https://lore.kernel.org/all/00f7b624-219f-4a05-a7ad-5335f15a41c7@moroto.mountain\nFixes: 4a86220e046d (""HID: bpf: remove tracing HID-BPF capability"")\nLink: https://patch.msgid.link/20240626-hid_hw_req_bpf-v2-1-cfd60fb6c79f@kernel.org\nAcked-by: Jiri Kosina <jkosina@suse.com>\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']",Fixes uninitialized return value in dispatch_hid_bpf_device_event function.,"fix, HID, uninitialized",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['HID driver like programs']
9e16bada9299d74fcce1f6b03606a08a2c16da81,9e16bada9299d74fcce1f6b03606a08a2c16da81,Luis Felipe Hernandez,luis.hernandez093@gmail.com,1719312951,Benjamin Tissoires,bentiss@kernel.org,1719472900,2f62154f000db726b9b45ee5d696427cfdd8e98c,33c0fb85b571b0f1bbdbf466e770eebeb29e6f41,"hid: bpf: Fix grammar

* spelling fix: XBox -> Xbox"," lowercase 'b' as per Microsoft branding
* rephrase: paddle -> paddles","[' the controller itself has more than one paddle\n* rephrase: replace usage of ""those"" in favor of explicitly making reference\n  to the paddles\n* grammatical fix: report -> reports', ' use present tense verb.\n* spelling fix: interpret\n* consistency: capitalize the first word in bullet points\n\nSigned-off-by: Luis Felipe Hernandez <luis.hernandez093@gmail.com>\nLink: https://patch.msgid.link/20240625105553.50830-1-luis.hernandez093@gmail.com\n[bentiss: renamed the file into Xbox', ' not XBox]\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']","This commit fixes grammatical and spelling issues in the HID BPF documentation, including correct branding of Xbox.","grammar, spelling, Xbox",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,['HID driver like programs']
a12978712d9001b060bcc10eaae42ad5102abe2b,a12978712d9001b060bcc10eaae42ad5102abe2b,Jiri Olsa,jolsa@kernel.org,1719409639,Andrii Nakryiko,andrii@kernel.org,1719446923,f7cf650d7a7f376dbe77e64b7074670296a95006,0f31c2c61f6923747628c65a0fe36b2d4d7e21b0,"selftests/bpf: Move ARRAY_SIZE to bpf_misc.h

ARRAY_SIZE is used on multiple places"," move its definition in
bpf_misc.h header.

Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Reviewed-by: Alan Maguire <alan.maguire@oracle.com>
Link: https://lore.kernel.org/bpf/20240626134719.3893748-1-jolsa@kernel.org
",[''],The commit moves ARRAY_SIZE definition to bpf_misc.h to centralize its usage.,"ARRAY_SIZE, bpf_misc.h, selftests",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
0f31c2c61f6923747628c65a0fe36b2d4d7e21b0,0f31c2c61f6923747628c65a0fe36b2d4d7e21b0,Alan Maguire,alan.maguire@oracle.com,1719257343,Andrii Nakryiko,andrii@kernel.org,1719445139,12f2bebc7c7747f1b0c4a3f4e956c808bf1a22bd,d07980f7373b4c57c85478f8e815cc7b9b394c05,"libbpf: Fix clang compilation error in btf_relocate.c

When building with clang for ARCH=i386"," the following errors are
observed:

  CC      kernel/bpf/btf_relocate.o
./tools/lib/bpf/btf_relocate.c:206:23: error: implicit truncation from 'int' to a one-bit wide bit-field changes value from 1 to -1 [-Werror","[""-Wsingle-bit-bitfield-constant-conversion]\n  206 |                 info[id].needs_size = true;\n      |                                     ^ ~\n./tools/lib/bpf/btf_relocate.c:256:25: error: implicit truncation from 'int' to a one-bit wide bit-field changes value from 1 to -1 [-Werror"", '-Wsingle-bit-bitfield-constant-conversion]\n  256 |                         base_info.needs_size = true;\n      |                                              ^ ~\n2 errors generated.\n\nThe problem is we use 1-bit', ' 31-bit bitfields in a signed int.\nChanging to\n\n\tbool needs_size: 1;\n\tunsigned int size:31;\n\n...resolves the error and pahole reports that 4 bytes are used\nfor the underlying representation:\n\n$ pahole btf_name_info tools/lib/bpf/btf_relocate.o\nstruct btf_name_info {\n\tconst char  *              name;                 /*     0     8 */\n\tunsigned int               needs_size:1;         /*     8: 0  4 */\n\tunsigned int               size:31;              /*     8: 1  4 */\n\t__u32                      id;                   /*    12     4 */\n\n\t/* size: 16', ' cachelines: 1', ' members: 4 */\n\t/* last cacheline: 16 bytes */\n};\n\nSigned-off-by: Alan Maguire <alan.maguire@oracle.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240624192903.854261-1-alan.maguire@oracle.com\n', '']",Fixed a clang compilation error in btf_relocate.c for i386 architecture.,"clang, compilation, btf_relocate.c",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d07980f7373b4c57c85478f8e815cc7b9b394c05,d07980f7373b4c57c85478f8e815cc7b9b394c05,Ma Ke,make24@iscas.ac.cn,1719148673,Andrii Nakryiko,andrii@kernel.org,1719445019,ff6d8308e02da9c27c0e04ec2e8d4b2934ee74e0,aa293983d2020390e286544b120f3cd0a3d40749,"selftests/bpf: Don't close(-1) in serial_test_fexit_stress()

Guard close() with extra link_fd[i] > 0 and fexit_fd[i] > 0
check to prevent close(-1).

Signed-off-by: Ma Ke <make24@iscas.ac.cn>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240623131753.2133829-1-make24@iscas.ac.cn
",,Add checks to prevent closing file descriptors with invalid values in fexit_stress test.,"close, file descriptors, serial_test_fexit_stress",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['other']
aa293983d2020390e286544b120f3cd0a3d40749,aa293983d2020390e286544b120f3cd0a3d40749,Matt Bobrowski,mattbobrowski@google.com,1719296937,Alexei Starovoitov,ast@kernel.org,1719433052,a62f7dab25bae1f0f0ccd09e75b75c85ff97e2e7,ec2b9a5e11e51fea1bb04c1e7e471952e887e874,"bpf: add new negative selftests to cover missing check_func_arg_reg_off() and reg->type check

Add new negative selftests which are intended to cover the
out-of-bounds memory access that could be performed on a
CONST_PTR_TO_DYNPTR within functions taking a ARG_PTR_TO_DYNPTR |
MEM_RDONLY as an argument"," and acceptance of invalid register types
i.e. PTR_TO_BTF_ID within functions taking a ARG_PTR_TO_DYNPTR |
MEM_RDONLY.

Reported-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>
Acked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Matt Bobrowski <mattbobrowski@google.com>
Link: https://lore.kernel.org/r/20240625062857.92760-2-mattbobrowski@google.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Added new negative selftests to check out-of-bounds access and invalid register types in eBPF functions.,"negative selftests,bpf,eBPF",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ec2b9a5e11e51fea1bb04c1e7e471952e887e874,ec2b9a5e11e51fea1bb04c1e7e471952e887e874,Matt Bobrowski,mattbobrowski@google.com,1719296936,Alexei Starovoitov,ast@kernel.org,1719433052,caf0d8d6b39f99dd62c24f1551521599b779fc65,d65f3767de20782e75d8a665fdc54f822f344802,"bpf: add missing check_func_arg_reg_off() to prevent out-of-bounds memory accesses

Currently"," it's possible to pass in a modified CONST_PTR_TO_DYNPTR to
a global function as an argument. The adverse effects of this is that
BPF helpers can continue to make use of this modified
CONST_PTR_TO_DYNPTR from within the context of the global function","['\nwhich can unintentionally result in out-of-bounds memory accesses and\ntherefore compromise overall system stability i.e.\n\n[  244.157771] BUG: KASAN: slab-out-of-bounds in bpf_dynptr_data+0x137/0x140\n[  244.161345] Read of size 8 at addr ffff88810914be68 by task test_progs/302\n[  244.167151] CPU: 0 PID: 302 Comm: test_progs Tainted: G O E 6.10.0-rc3-00131-g66b586715063 #533\n[  244.174318] Call Trace:\n[  244.175787]  <TASK>\n[  244.177356]  dump_stack_lvl+0x66/0xa0\n[  244.179531]  print_report+0xce/0x670\n[  244.182314]  ? __virt_addr_valid+0x200/0x3e0\n[  244.184908]  kasan_report+0xd7/0x110\n[  244.187408]  ? bpf_dynptr_data+0x137/0x140\n[  244.189714]  ? bpf_dynptr_data+0x137/0x140\n[  244.192020]  bpf_dynptr_data+0x137/0x140\n[  244.194264]  bpf_prog_b02a02fdd2bdc5fa_global_call_bpf_dynptr_data+0x22/0x26\n[  244.198044]  bpf_prog_b0fe7b9d7dc3abde_callback_adjust_bpf_dynptr_reg_off+0x1f/0x23\n[  244.202136]  bpf_user_ringbuf_drain+0x2c7/0x570\n[  244.204744]  ? 0xffffffffc0009e58\n[  244.206593]  ? __pfx_bpf_user_ringbuf_drain+0x10/0x10\n[  244.209795]  bpf_prog_33ab33f6a804ba2d_user_ringbuf_callback_const_ptr_to_dynptr_reg_off+0x47/0x4b\n[  244.215922]  bpf_trampoline_6442502480+0x43/0xe3\n[  244.218691]  __x64_sys_prlimit64+0x9/0xf0\n[  244.220912]  do_syscall_64+0xc1/0x1d0\n[  244.223043]  entry_SYSCALL_64_after_hwframe+0x77/0x7f\n[  244.226458] RIP: 0033:0x7ffa3eb8f059\n[  244.228582] Code: 08 89 e8 5b 5d c3 66 2e 0f 1f 84 00 00 00 00 00 90 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 73 01 c3 48 8b 0d 8f 1d 0d 00 f7 d8 64 89 01 48\n[  244.241307] RSP: 002b:00007ffa3e9c6eb8 EFLAGS: 00000206 ORIG_RAX: 000000000000012e\n[  244.246474] RAX: ffffffffffffffda RBX: 00007ffa3e9c7cdc RCX: 00007ffa3eb8f059\n[  244.250478] RDX: 00007ffa3eb162b4 RSI: 0000000000000000 RDI: 00007ffa3e9c7fb0\n[  244.255396] RBP: 00007ffa3e9c6ed0 R08: 00007ffa3e9c76c0 R09: 0000000000000000\n[  244.260195] R10: 0000000000000000 R11: 0000000000000206 R12: ffffffffffffff80\n[  244.264201] R13: 000000000000001c R14: 00007ffc5d6b4260 R15: 00007ffa3e1c7000\n[  244.268303]  </TASK>\n\nAdd a check_func_arg_reg_off() to the path in which the BPF verifier\nverifies the arguments of global function arguments', ' specifically\nthose which take an argument of type ARG_PTR_TO_DYNPTR |\nMEM_RDONLY. Also', "" process_dynptr_func() doesn't appear to perform any\nexplicit and strict type matching on the supplied register type"", "" so\nlet's also enforce that a register either type PTR_TO_STACK or\nCONST_PTR_TO_DYNPTR is by the caller.\n\nReported-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nAcked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Matt Bobrowski <mattbobrowski@google.com>\nLink: https://lore.kernel.org/r/20240625062857.92760-1-mattbobrowski@google.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Add missing check in BPF to prevent out-of-bounds memory access with CONST_PTR_TO_DYNPTR.,check memory access,It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e8b86f0311a4b721663df8105a680e5968f21d4c,e8b86f0311a4b721663df8105a680e5968f21d4c,Veronika Molnarova,vmolnaro@redhat.com,1719307201,Namhyung Kim,namhyung@kernel.org,1719425458,6710d07c0320d4a045e58b993ee775ad5a706de4,e4b19e2cc3e5f9be8f159ba0b4ba6aed8d993abf,"perf test stat_bpf_counter.sh: Stabilize the test results

The test has been failing for some time when two separate runs of
perf benchmarks are recorded for cycles events and their counts are
compared"," while once the recording was done with option --bpf-counters
and once without it. It is expected that the count of the samples
should be within a certain range","[' firstly the difference was set to be\nwithin 10%', ' which was then later raised to 20%. However', ' the test case\nkeeps failing on certain architectures as recording the provided\nbenchmark can produce completely different counts based on the\ncurrent load of the system.\n\nSampling two separate runs on intel-eaglestream-spr-13 of ""perf stat\n--no-big-num -e cycles -- perf bench sched messaging -g 1 -l 100 -t"":\n\n Performance counter stats for \'perf bench sched messaging -g 1 -l 100 -t\':\n\n         396782898      cycles\n\n       0.010051983 seconds time elapsed\n\n       0.008664000 seconds user\n       0.097058000 seconds sys\n\n Performance counter stats for \'perf bench sched messaging -g 1 -l 100 -t\':\n\n        1431133032      cycles\n\n       0.021803714 seconds time elapsed\n\n       0.023377000 seconds user\n       0.349918000 seconds sys\n\n', ' which is ranging from 400mil to 1400mil samples.\n\nInstead of recording the cycles use instructions event', ' which provides\nmore stable values. At the same time change the tested workload to one\nof the provided testing workloads by perf that is not based on a\nscheduler', ' which can provide another dependency on the current load.\n\nSampling instructions event with the new workload provide much more\nstable results on intel-eaglestream-spr-13 of ""perf stat --no-big-num\n-e instructions -- perf test -w brstack"":\n\n Performance counter stats for \'perf test -w brstack\':\n\n          64584494      instructions\n\n       0.009173945 seconds time elapsed\n\n       0.007262000 seconds user\n       0.002071000 seconds sys\n\n Performance counter stats for \'perf test -w brstack\':\n\n          64672669      instructions\n\n       0.008888135 seconds time elapsed\n\n       0.005018000 seconds user\n       0.004018000 seconds sys\n\nSigned-off-by: Veronika Molnarova <vmolnaro@redhat.com>\nAcked-by: Namhyung Kim <namhyung@kernel.org>\nCc: mpetlan@redhat.com\nSigned-off-by: Namhyung Kim <namhyung@kernel.org>\nLink: https://lore.kernel.org/r/20240625092001.10909-1-vmolnaro@redhat.com\n', '']",The commit stabilizes test results for perf's stat_bpf_counter.sh by ensuring cycle event counts match expectations with and without --bpf-counters.,"stabilize,test results,perf",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tracepoints like programs']
9dabf4003423c8d3a2f4f8915c3ff2f1158302a0,9dabf4003423c8d3a2f4f8915c3ff2f1158302a0,Ian Rogers,irogers@google.com,1719351676,Namhyung Kim,namhyung@kernel.org,1719425280,70e4e86569bf3a9ee1b0ea1dd03a55e21546619c,e467705a9fb37f51595aa6deaca085ccb4005454,"perf python: Switch module to linking libraries from building source

setup.py was building most perf sources causing setup.py to mimic the
Makefile logic as well as flex/bison code to be stubbed out"," due to
complexity building. By using libraries fewer functions are stubbed
out","[' the build is faster and the Makefile logic is reused which should\nsimplify updating. The libraries are passed through LDFLAGS to avoid\ncomplexity in python.\n\nForce the -fPIC flag for libbpf.a to ensure it is suitable for linking\ninto the perf python module.\n\nSigned-off-by: Ian Rogers <irogers@google.com>\nReviewed-by: James Clark <james.clark@arm.com>\nCc: Suzuki K Poulose <suzuki.poulose@arm.com>\nCc: Kees Cook <keescook@chromium.org>\nCc: Palmer Dabbelt <palmer@dabbelt.com>\nCc: Albert Ou <aou@eecs.berkeley.edu>\nCc: Nick Terrell <terrelln@fb.com>\nCc: Gary Guo <gary@garyguo.net>\nCc: Alex Gaynor <alex.gaynor@gmail.com>\nCc: Boqun Feng <boqun.feng@gmail.com>\nCc: Wedson Almeida Filho <wedsonaf@gmail.com>\nCc: Ze Gao <zegao2021@gmail.com>\nCc: Alice Ryhl <aliceryhl@google.com>\nCc: Andrei Vagin <avagin@google.com>\nCc: Yicong Yang <yangyicong@hisilicon.com>\nCc: Jonathan Cameron <jonathan.cameron@huawei.com>\nCc: Guo Ren <guoren@kernel.org>\nCc: Miguel Ojeda <ojeda@kernel.org>\nCc: Will Deacon <will@kernel.org>\nCc: Mike Leach <mike.leach@linaro.org>\nCc: Leo Yan <leo.yan@linux.dev>\nCc: Oliver Upton <oliver.upton@linux.dev>\nCc: John Garry <john.g.garry@oracle.com>\nCc: Benno Lossin <benno.lossin@proton.me>\nCc: Björn Roy Baron <bjorn3_gh@protonmail.com>\nCc: Andreas Hindborg <a.hindborg@samsung.com>\nCc: Paul Walmsley <paul.walmsley@sifive.com>\nSigned-off-by: Namhyung Kim <namhyung@kernel.org>\nLink: https://lore.kernel.org/r/20240625214117.953777-8-irogers@google.com\n', '']",Switch perf Python module to link libraries instead of building from source for reduced complexity.,"perf, libraries, setup.py",It's a build system or CI/CD change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
60a6707f582ebbdfb6b378f45d7bf929106a1cd5,60a6707f582ebbdfb6b378f45d7bf929106a1cd5,Palmer Dabbelt,palmer@rivosinc.com,1719416587,Palmer Dabbelt,palmer@rivosinc.com,1719416587,390f5047c4d88299efa7b1b5c10fa68025cb1e5b,d6ecd188937fcddeffb37efc61b67a56809b266a 4705c1571ad39d9469321d2817faf4c4b78ddffb,"Merge patch series ""riscv: Memory Hot(Un)Plug support""

Björn Töpel <bjorn@kernel.org> says:

From: Björn Töpel <bjorn@rivosinc.com>

================================================================
Memory Hot(Un)Plug support (and ZONE_DEVICE) for the RISC-V port
================================================================

Introduction
============

To quote ""Documentation/admin-guide/mm/memory-hotplug.rst"": ""Memory
hot(un)plug allows for increasing and decreasing the size of physical
memory available to a machine at runtime.""

This series adds memory hot(un)plugging"," and ZONE_DEVICE support for
the RISC-V Linux port.

MM configuration
================

RISC-V MM has the following configuration:

 * Memory blocks are 128M","[' analogous to x86-64. It uses PMD\n   (""hugepage"") vmemmaps. From that follows that 2M (PMD) worth of\n   vmemmap spans 32768 pages á 4K which gets us 128M.\n\n * The pageblock size is the minimum minimum virtio_mem size', "" and on\n   RISC-V it's 2M (2^9 * 4K).\n\nImplementation\n==============\n\nThe PGD table on RISC-V is shared/copied between for all processes. To\navoid doing page table synchronization"", ' the first patch (patch 1)\npre-allocated the PGD entries for vmemmap/direct map. By doing that\nthe init_mm PGD will be fixed at kernel init', ' and synchronization can\nbe avoided all together.\n\nThe following two patches (patch 2-3) does some preparations', ' followed\nby the actual MHP implementation (patch 4-5). Then', ' MHP and virtio-mem\nare enabled (patch 6-7)', ' and finally ZONE_DEVICE support is added\n(patch 8).\n\nMHP and locking\n===============\n\nTL;DR: The MHP does not step on any toes', ' except for ptdump.\nAdditional locking is required for ptdump.\n\nLong version: For v2 I spent some time digging into init_mm\nsynchronization/update. Here are my findings', ' and I\'d love them to be\ncorrected if incorrect.\n\nIt\'s been a gnarly path...\n\nThe `init_mm` structure is a special mm (perhaps not a ""real"" one).\nIt\'s a ""lazy context"" that tracks kernel page table resources', ' e.g.', '\nthe kernel page table (swapper_pg_dir)', ' a kernel page_table_lock (more\nabout the usage below)', ' mmap_lock', ' and such.\n\n`init_mm` does not track/contain any VMAs. Having the `init_mm` is\nconvenient', ' so that the regular kernel page table walk/modify\nfunctions can be used.\n\nNow', ' `init_mm` being special means that the locking for kernel page\ntables are special as well.\n\nOn RISC-V the PGD (top-level page table structure)', ' similar to x86', ' is\nshared (copied) with user processes. If the kernel PGD is modified', ' it\nhas to be synched to user-mode processes PGDs. This is avoided by\npre-populating the PGD', "" so it'll be fixed from boot.\n\nThe in-kernel pgd regions are documented in\n`Documentation/arch/riscv/vm-layout.rst`.\n\nThe distinct regions are:\n * vmemmap\n * vmalloc/ioremap space\n * direct mapping of all physical memory\n * kasan\n * modules"", ' BPF\n * kernel\n\nMemory hotplug is the process of adding/removing memory to/from the\nkernel.\n\nAdding is done in two phases:\n 1. Add the memory to the kernel\n 2. Online memory', ' making it available to the page allocator.\n\nStep 1 is partially architecture dependent', ' and updates the init_mm\npage table:\n * Update the direct map page tables. The direct map is a linear map', '\n   representing all physical memory: `virt = phys + PAGE_OFFSET`\n * Add a `struct page` for each added page of memory. Update the\n   vmemmap (virtual mapping to the `struct page`', ' so we can easily\n   transform a kernel virtual address to a `struct page *` address.\n\nFrom an MHP perspective', ' there are two regions of the PGD that are\nupdated:\n * vmemmap\n * direct mapping of all physical memory\n\nThe `struct mm_struct` has a couple of locks in play:\n * `spinlock_t page_table_lock` protects the page table', "" and some\n    counters\n * `struct rw_semaphore mmap_lock` protect an mm's VMAs\n\nNote again that `init_mm` does not contain any VMAs"", ' but still uses\nthe mmap_lock in some places.\n\nThe `page_table_lock` was originally used to to protect all pages\ntables', ' but more recently a split page table lock has been introduced.\nThe split lock has a per-table lock for the PTE and PMD tables. If\nsplit lock is disabled', ' all tables are guarded by\n`mm->page_table_lock` (for user processes). Split page table locks are\nnot used for init_mm.\n\nMHP operations is typically synchronized using\n`DEFINE_STATIC_PERCPU_RWSEM(mem_hotplug_lock)`.\n\nActors\n------\n\nThe following non-MHP actors in the kernel traverses (read)', ' and/or\nmodifies the kernel PGD.\n\n * `ptdump`\n\n   Walks the entire `init_mm`', ' via `ptdump_walk_pgd()` with the\n   `mmap_write_lock(init_mm)` taken.\n\n   Observation: ptdump can race with MHP', ' and needs additional locking\n   to avoid crashes/races.\n\n * `set_direct_*` / `arch/riscv/mm/pageattr.c`\n\n   The `set_direct_*` functionality is used to ""synchronize"" the\n   direct map to other kernel mappings', ' e.g. modules/kernel text. The\n   direct map is using ""as large huge table mappings as possible""', '\n   which means that the `set_direct_*` might need to split the direct\n   map.\n\n  The `set_direct_*` functions operates with the\n  `mmap_write_lock(init_mm)` taken.\n\n  Observation: `set_direct_*` uses the direct map', ' but will never\n  modify the same entry as MHP. If there is a mapping', ' that entry will\n  never race with MHP. Further', ' MHP acts when memory is offline.\n\n * HVO / `mm/hugetlb_vmemmap`\n\n   HVO optimizes the backing `struct page` for hugetlb pages', ' which\n   means changing the ""vmemmap"" region. HVO can split (merge?) a\n   vmemmap pmd. However', ' it will never race with MHP', ' since HVO only\n   operates at online memory. HVO cannot touch memory being MHP added\n   or removed.\n\n * `apply_to_page_range`\n\n   Walks a range', ' creates pages and applies a callback (setting\n   permissions) for the page.\n\n   When creating a table', ' it might use `int __pte_alloc_kernel(pmd_t\n   *pmd)` which takes the `init_mm.page_table_lock` to synchronize pmd\n   populate.\n\n   Used by: `mm/vmalloc.c` and `mm/kasan/shadow.c`. The KASAN callback\n   takes the `init_mm.page_table_lock` to synchronize pte creation.\n\n   Observations: `apply_to_page_range` applies to the ""vmalloc/ioremap\n   space"" region', ' and ""kasan"" region. *Not* affected by MHP.\n\n * `apply_to_existing_page_range`\n\n   Walks a range', ' applies a callback (setting permissions) for the\n   page (no page creation).\n\n   Used by: `kernel/bpf/arena.c` and `mm/kasan/shadow.c`. The KASAN\n   callback takes the `init_mm.page_table_lock` to synchronize pte\n   creation. *Not* affected by MHP regions.\n\n * `apply_to_existing_page_range` applies to the ""vmalloc/ioremap\n   space"" region', ' and ""kasan"" region. *Not* affected by MHP regions.\n\n *  `ioremap_page_range` and `vmap_page_range`\n\n    Uses the same internal function', ' and might create table entries at\n    the ""vmalloc/ioremap space"" region. Can call\n    `__pte_alloc_kernel()` which takes the `init_mm.page_table_lock`\n    synchronizing pmd populate in the region. *Not* affected by MHP\n    regions.\n\nSummary:\n  * MHP add will never modify the same page table entries', ' as any of\n    the other actors.\n  * MHP remove is done when memory is offlined', ' and will not clash\n    with any of the actors.\n  * Functions that walk the entire kernel page table need\n    synchronization\n\n  * It\'s sufficient to add the MHP lock ptdump.\n\nTesting\n=======\n\nThis series adds basic DT supported hotplugging. There is a QEMU\nseries enabling MHP for the RISC-V ""virt"" machine here: [1]\n\nACPI/MSI support is still in the making for RISC-V', ' and prior proper\n(ACPI) PCI MSI support lands [2] and NUMA SRAT support [3]', "" it hard to\ntry it out.\n\nI've prepared a QEMU branch with proper ACPI GED/PC-DIMM support [4]"", '\nand a this series with the required prerequisites [5] (AIA', ' ACPI AIA\nMADT', ' ACPI NUMA SRAT).\n\nTo test with virtio-mem', ' e.g.:\n  | qemu-system-riscv64 \\\n  |     -machine virt', 'aia=aplic-imsic \\\n  |     -cpu rv64', 'v=true', 'vlen=256', 'elen=64', 'h=true', 'zbkb=on', 'zbkc=on', 'zbkx=on', 'zkr=on', 'zkt=on', 'svinval=on', 'svnapot=on', 'svpbmt=on \\\n  |     -nodefaults \\\n  |     -nographic -smp 8 -kernel rv64-u-boot.bin \\\n  |     -drive file=rootfs.img', 'format=raw', 'if=virtio \\\n  |     -device virtio-rng-pci \\\n  |     -m 16G', 'slots=3', 'maxmem=32G \\\n  |     -object memory-backend-ram', 'id=mem0', 'size=16G \\\n  |     -numa node', 'nodeid=0', 'memdev=mem0 \\\n  |     -serial chardev:char0 \\\n  |     -mon chardev=char0', 'mode=readline \\\n  |     -chardev stdio', 'mux=on', 'id=char0 \\\n  |     -device pci-serial', 'id=serial0', 'chardev=char0 \\\n  |     -object memory-backend-ram', 'id=vmem0', 'size=2G \\\n  |     -device virtio-mem-pci', 'id=vm0', 'memdev=vmem0', 'node=0\n\nwhere ""rv64-u-boot.bin"" is U-boot with EFI/ACPI-support (use [6] if\nyou\'re lazy).\n\nIn the QEMU monitor:\n  | (qemu) info memory-devices\n  | (qemu) qom-set vm0 requested-size 1G\n\n...to test DAX/KMEM', ' use the follow QEMU parameters:\n  |  -object memory-backend-file', 'id=mem1', 'share=on', 'mem-path=virtio_pmem.img', 'size=4G \\\n  |  -device virtio-pmem-pci', 'memdev=mem1', ""id=nv1\n\nand the regular ndctl/daxctl dance.\n\nIf you're brave to try the ACPI branch"", ' add ""acpi=on"" to ""-machine\nvirt""', ' and test PC-DIMM MHP (in addition to virtio-{p}', 'mem):\n\nIn the QEMU monitor:\n  | (qemu) object_add memory-backend-ram', 'id=mem1', 'size=1G\n  | (qemu) device_add pc-dimm', 'id=dimm1', 'memdev=mem1\n\nYou can also try hot-remove with some QEMU options', ' say:\n  | -object memory-backend-file', 'id=mem-1', 'size=256M', 'mem-path=/pagesize-2MB\n  | -device pc-dimm', 'id=mem1', 'memdev=mem-1\n  | -object memory-backend-file', 'id=mem-2', 'size=1G', 'mem-path=/pagesize-1GB\n  | -device pc-dimm', 'id=mem2', 'memdev=mem-2\n  | -object memory-backend-file', 'id=mem-3', 'size=256M', 'mem-path=/pagesize-2MB\n  | -device pc-dimm', 'id=mem3', 'memdev=mem-3\n\nRemove ""acpi=on"" to run with DT.\n\nThanks to Alex', ' Andrew', ' David', ' and Oscar for all\ncomments/tests/fixups.\n\nReferences\n==========\n\n[1] https://lore.kernel.org/qemu-devel/20240521105635.795211-1-bjorn@kernel.org/\n[2] https://lore.kernel.org/linux-riscv/20240501121742.1215792-1-sunilvl@ventanamicro.com/\n[3] https://lore.kernel.org/linux-riscv/cover.1713778236.git.haibo1.xu@intel.com/\n[4] https://github.com/bjoto/qemu/commits/virtio-mem-pc-dimm-mhp-acpi-v2/\n[5] https://github.com/bjoto/linux/commits/mhp-v4-acpi\n[6] https://github.com/bjoto/riscv-rootfs-utils/tree/acpi\n\n* b4-shazam-merge:\n  riscv: Enable DAX VMEMMAP optimization\n  riscv: mm: Add support for ZONE_DEVICE\n  virtio-mem: Enable virtio-mem for RISC-V\n  riscv: Enable memory hotplugging for RISC-V\n  riscv: mm: Take memory hotplug read-lock during kernel page table dump\n  riscv: mm: Add memory hotplugging support\n  riscv: mm: Add pfn_to_kaddr() implementation\n  riscv: mm: Refactor create_linear_mapping_range() for memory hot add\n  riscv: mm: Change attribute from __init to __meminit for page functions\n  riscv: mm: Pre-allocate vmemmap/direct map/kasan PGD entries\n  riscv: mm: Properly forward vmemmap_populate() altmap parameter\n\nLink: https://lore.kernel.org/r/20240605114100.315918-1-bjorn@kernel.org\nSigned-off-by: Palmer Dabbelt <palmer@rivosinc.com>\n', '']",Adds memory hot(un)plug and ZONE_DEVICE support for RISC-V in the Linux port.,"RISC-V, memory hotplug, ZONE_DEVICE",It's a new feature.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
66673099f734fd6512055fee353b5c81dafec216,66673099f734fd6512055fee353b5c81dafec216,Björn Töpel,bjorn@rivosinc.com,1717587645,Palmer Dabbelt,palmer@rivosinc.com,1719416559,9a7ce8a27f3a6e83febcfe02231813375a9bec4c,e3ecf2fdc8f39a898f9e06481e935b460a097e10,"riscv: mm: Pre-allocate vmemmap/direct map/kasan PGD entries

The RISC-V port copies the PGD table from init_mm/swapper_pg_dir to
all userland page tables"," which means that if the PGD level table is
changed","[' other page tables has to be updated as well.\n\nInstead of having the PGD changes ripple out to all tables', ' the\nsynchronization can be avoided by pre-allocating the PGD entries/pages\nat boot', ' avoiding the synchronization all together.\n\nThis is currently done for the bpf/modules', ' and vmalloc PGD regions.\nExtend this scheme for the PGD regions touched by memory hotplugging.\n\nPrepare the RISC-V port for memory hotplug by pre-allocate\nvmemmap/direct map/kasan entries at the PGD level. This will roughly\nwaste ~128 (plus 32 if KASAN is enabled) worth of 4K pages when memory\nhotplugging is enabled in the kernel configuration.\n\nReviewed-by: Alexandre Ghiti <alexghiti@rivosinc.com>\nSigned-off-by: Björn Töpel <bjorn@rivosinc.com>\nLink: https://lore.kernel.org/r/20240605114100.315918-3-bjorn@kernel.org\nSigned-off-by: Palmer Dabbelt <palmer@rivosinc.com>\n', '']",This commit pre-allocates vmemmap/direct map/kasan PGD entries for RISC-V architecture in Linux kernel.,"RISC-V, PGD, pre-allocate",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
d65f3767de20782e75d8a665fdc54f822f344802,d65f3767de20782e75d8a665fdc54f822f344802,Leon Hwang,hffilwlqm@gmail.com,1719327231,Alexei Starovoitov,ast@kernel.org,1719364364,30cffd652e5dc666719ff9492738c88cebc3f737,c73a9683cb21012b6c0f14217974837151c527a8,"bpf: Fix tailcall cases in test_bpf

Since f663a03c8e35 (""bpf"," x64: Remove tail call detection"")","[""\ntail_call_reachable won't be detected in x86 JIT. And"", ' tail_call_reachable\nis provided by verifier.\n\nTherefore', ' in test_bpf', ' the tail_call_reachable must be provided in test\ncases before running.\n\nFix and test:\n\n[  174.828662] test_bpf: #0 Tail call leaf jited:1 170 PASS\n[  174.829574] test_bpf: #1 Tail call 2 jited:1 244 PASS\n[  174.830363] test_bpf: #2 Tail call 3 jited:1 296 PASS\n[  174.830924] test_bpf: #3 Tail call 4 jited:1 719 PASS\n[  174.831863] test_bpf: #4 Tail call load/store leaf jited:1 197 PASS\n[  174.832240] test_bpf: #5 Tail call load/store jited:1 326 PASS\n[  174.832240] test_bpf: #6 Tail call error path', ' max count reached jited:1 2214 PASS\n[  174.835713] test_bpf: #7 Tail call count preserved across function calls jited:1 609751 PASS\n[  175.446098] test_bpf: #8 Tail call error path', ' NULL target jited:1 472 PASS\n[  175.447597] test_bpf: #9 Tail call error path', ' index out of range jited:1 206 PASS\n[  175.448833] test_bpf: test_tail_calls: Summary: 10 PASSED', ' 0 FAILED', ' [10/10 JIT\'ed]\n\nReported-by: kernel test robot <oliver.sang@intel.com>\nCloses: https://lore.kernel.org/oe-lkp/202406251415.c51865bc-oliver.sang@intel.com\nFixes: f663a03c8e35 (""bpf', ' x64: Remove tail call detection"")\nSigned-off-by: Leon Hwang <hffilwlqm@gmail.com>\nLink: https://lore.kernel.org/r/20240625145351.40072-1-hffilwlqm@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes issues with tailcall execution in BPF test cases.,"bpf, tailcall, test",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
637c26f9b02d9c72448fcd5c9c4e3b08015404fc,637c26f9b02d9c72448fcd5c9c4e3b08015404fc,Andrii Nakryiko,andrii@kernel.org,1716341925,Masami Hiramatsu (Google),mhiramat@kernel.org,1719278138,0840dc159e7415fe127ac0035d909480a7067c2c,4a365eb8a6d9940e838739935f1ce21f1ec8e33f,"selftests/bpf: add test validating uprobe/uretprobe stack traces

Add a set of tests to validate that stack traces captured from or in the
presence of active uprobes and uretprobes are valid and complete.

For this we use BPF program that are installed either on entry or exit
of user function"," plus deep-nested USDT. One of target funtions
(target_1) is recursive to generate two different entries in the stack
trace for the same uprobe/uretprobe","[' testing potential edge conditions.\n\nIf there is no fixes', ' we get something like this for one of the scenarios:\n\n caller: 0x758fff - 0x7595ab\n target_1: 0x758fd5 - 0x758fff\n target_2: 0x758fca - 0x758fd5\n target_3: 0x758fbf - 0x758fca\n target_4: 0x758fb3 - 0x758fbf\n ENTRY #0: 0x758fb3 (in target_4)\n ENTRY #1: 0x758fd3 (in target_2)\n ENTRY #2: 0x758ffd (in target_1)\n ENTRY #3: 0x7fffffffe000\n ENTRY #4: 0x7fffffffe000\n ENTRY #5: 0x6f8f39\n ENTRY #6: 0x6fa6f0\n ENTRY #7: 0x7f403f229590\n\nEntry #3 and #4 (0x7fffffffe000) are uretprobe trampoline addresses\nwhich obscure actual target_1 and another target_1 invocations. Also\nnote that between entry #0 and entry #1 we are missing an entry for\ntarget_3.\n\nWith fixes', ' we get desired full stack traces:\n\n caller: 0x758fff - 0x7595ab\n target_1: 0x758fd5 - 0x758fff\n target_2: 0x758fca - 0x758fd5\n target_3: 0x758fbf - 0x758fca\n target_4: 0x758fb3 - 0x758fbf\n ENTRY #0: 0x758fb7 (in target_4)\n ENTRY #1: 0x758fc8 (in target_3)\n ENTRY #2: 0x758fd3 (in target_2)\n ENTRY #3: 0x758ffd (in target_1)\n ENTRY #4: 0x758ff3 (in target_1)\n ENTRY #5: 0x75922c (in caller)\n ENTRY #6: 0x6f8f39\n ENTRY #7: 0x6fa6f0\n ENTRY #8: 0x7f986adc4cd0\n\nNow there is a logical and complete sequence of function calls.\n\nLink: https://lore.kernel.org/all/20240522013845.1631305-5-andrii@kernel.org/\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\n', '']",Add tests for validating stack traces with active uprobes and uretprobes in selftests.,"test,uprobes,stack traces",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
482000cf7fd5ff42214c0d71f30ed42c55bcb00a,482000cf7fd5ff42214c0d71f30ed42c55bcb00a,Jakub Kicinski,kuba@kernel.org,1719278121,Jakub Kicinski,kuba@kernel.org,1719278122,b71e5d0d51f24629a1228cffbbc1c352a3db4032,058722ee350c0bdd664e467156feb2bf5d9cc271 7e9f79428372c6eab92271390851be34ab26bfb4,"Merge tag 'for-netdev' of ssh://gitolite.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Daniel Borkmann says:

====================
pull-request: bpf 2024-06-24

We've added 12 non-merge commits during the last 10 day(s) which contain
a total of 10 files changed", 412 insertions(+),"[' 16 deletions(-).\n\nThe main changes are:\n\n1) Fix a BPF verifier issue validating may_goto with a negative offset', '\n   from Alexei Starovoitov.\n\n2) Fix a BPF verifier validation bug with may_goto combined with jump to\n   the first instruction', ' also from Alexei Starovoitov.\n\n3) Fix a bug with overrunning reservations in BPF ring buffer', '\n   from Daniel Borkmann.\n\n4) Fix a bug in BPF verifier due to missing proper var_off setting related\n   to movsx instruction', ' from Yonghong Song.\n\n5) Silence unnecessary syzkaller-triggered warning in __xdp_reg_mem_model()', ""\n   from Daniil Dulov.\n\n* tag 'for-netdev' of ssh://gitolite.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  xdp: Remove WARN() from __xdp_reg_mem_model()\n  selftests/bpf: Add tests for may_goto with negative offset.\n  bpf: Fix may_goto with negative offset.\n  selftests/bpf: Add more ring buffer test coverage\n  bpf: Fix overrunning reservations in ringbuf\n  selftests/bpf: Tests with may_goto and jumps to the 1st insn\n  bpf: Fix the corner case with may_goto and jump to the 1st insn.\n  bpf: Update BPF LSM maintainer list\n  bpf: Fix remap of arena.\n  selftests/bpf: Add a few tests to cover\n  bpf: Add missed var_off setting in coerce_subreg_to_size_sx()\n  bpf: Add missed var_off setting in set_sext32_default_val()\n====================\n\nLink: https://patch.msgid.link/20240624124330.8401-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n"", '']",Merge pull request for bpf branch containing 12 non-merge commits and 412 insertions over 10 days.,"merge, pull request, bpf",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
bf2468f9afba8001c7432d104756a5dd3537bc76,bf2468f9afba8001c7432d104756a5dd3537bc76,Jakub Kicinski,kuba@kernel.org,1719272485,Jakub Kicinski,kuba@kernel.org,1719272486,ec13e5174a4146e629e239f084b753d4fae4c162,568ebdaba6370c03360860f1524f646ddd5ca523 3f9fe37d9e16a6cfd5f4d1f536686ea71db3196f,"Merge branch 'locking-introduce-nested-bh-locking'

Sebastian Andrzej Siewior says:

====================
locking: Introduce nested-BH locking.

Disabling bottoms halves acts as per-CPU BKL. On PREEMPT_RT code within
local_bh_disable() section remains preemtible. As a result high prior
tasks (or threaded interrupts) will be blocked by lower-prio task (or
threaded interrupts) which are long running which includes softirq
sections.

The proposed way out is to introduce explicit per-CPU locks for
resources which are protected by local_bh_disable() and use those only
on PREEMPT_RT so there is no additional overhead for !PREEMPT_RT builds.

The series introduces the infrastructure and converts large parts of
networking which is largest stake holder here. Once this done the
per-CPU lock from local_bh_disable() on PREEMPT_RT can be lifted.

Performance testing. Baseline is net-next as of commit 93bda33046e7a
(""Merge branch'net-constify-ctl_table-arguments-of-utility-functions'"")
plus v6.10-rc1. A 10GiG link is used between two hosts. The command
   xdp-bench redirect-cpu --cpu 3 --remote-action drop eth1 -e

was invoked on the receiving side with a ixgbe. The sending side uses
pktgen_sample03_burst_single_flow.sh on i40e.

Baseline:
| eth1->?                 9",018,"['604 rx/s                  0 err', 'drop/s\n|   receive total         9', '018', '604 pkt/s                 0 drop/s                0 error/s\n|     cpu:7               9', '018', '604 pkt/s                 0 drop/s                0 error/s\n|   enqueue to cpu 3      9', '018', '602 pkt/s                 0 drop/s             7.00 bulk-avg\n|     cpu:7->3            9', '018', '602 pkt/s                 0 drop/s             7.00 bulk-avg\n|   kthread total         9', '018', '606 pkt/s                 0 drop/s          214', '698 sched\n|     cpu:3               9', '018', '606 pkt/s                 0 drop/s          214', '698 sched\n|     xdp_stats                   0 pass/s        9', '018', '606 drop/s                0 redir/s\n|       cpu:3                     0 pass/s        9', '018', '606 drop/s                0 redir/s\n|   redirect_err                  0 error/s\n|   xdp_exception                 0 hit/s\n\nperf top --sort cpu', 'symbol --no-children:\n|   18.14%  007  [k] bpf_prog_4f0ffbb35139c187_cpumap_l4_hash\n|   13.29%  007  [k] ixgbe_poll\n|   12.66%  003  [k] cpu_map_kthread_run\n|    7.23%  003  [k] page_frag_free\n|    6.76%  007  [k] xdp_do_redirect\n|    3.76%  007  [k] cpu_map_redirect\n|    3.13%  007  [k] bq_flush_to_queue\n|    2.51%  003  [k] xdp_return_frame\n|    1.93%  007  [k] try_to_wake_up\n|    1.78%  007  [k] _raw_spin_lock\n|    1.74%  007  [k] cpu_map_enqueue\n|    1.56%  003  [k] bpf_prog_57cd311f2e27366b_cpumap_drop\n\nWith this series applied:\n| eth1->?                10', '329', '340 rx/s                  0 err', 'drop/s\n|   receive total        10', '329', '340 pkt/s                 0 drop/s                0 error/s\n|     cpu:6              10', '329', '340 pkt/s                 0 drop/s                0 error/s\n|   enqueue to cpu 3     10', '329', '338 pkt/s                 0 drop/s             8.00 bulk-avg\n|     cpu:6->3           10', '329', '338 pkt/s                 0 drop/s             8.00 bulk-avg\n|   kthread total        10', '329', '321 pkt/s                 0 drop/s           96', '297 sched\n|     cpu:3              10', '329', '321 pkt/s                 0 drop/s           96', '297 sched\n|     xdp_stats                   0 pass/s       10', '329', '321 drop/s                0 redir/s\n|       cpu:3                     0 pass/s       10', '329', '321 drop/s                0 redir/s\n|   redirect_err                  0 error/s\n|   xdp_exception                 0 hit/s\n\nperf top --sort cpu', 'symbol --no-children:\n|   20.90%  006  [k] bpf_prog_4f0ffbb35139c187_cpumap_l4_hash\n|   12.62%  006  [k] ixgbe_poll\n|    9.82%  003  [k] page_frag_free\n|    8.73%  003  [k] cpu_map_bpf_prog_run_xdp\n|    6.63%  006  [k] xdp_do_redirect\n|    4.94%  003  [k] cpu_map_kthread_run\n|    4.28%  006  [k] cpu_map_redirect\n|    4.03%  006  [k] bq_flush_to_queue\n|    3.01%  003  [k] xdp_return_frame\n|    1.95%  006  [k] _raw_spin_lock\n|    1.94%  003  [k] bpf_prog_57cd311f2e27366b_cpumap_drop\n\nThis diff appears to be noise.\n\nv8: https://lore.kernel.org/all/20240619072253.504963-1-bigeasy@linutronix.de\nv7: https://lore.kernel.org/all/20240618072526.379909-1-bigeasy@linutronix.de\nv6: https://lore.kernel.org/all/20240612170303.3896084-1-bigeasy@linutronix.de\nv5: https://lore.kernel.org/all/20240607070427.1379327-1-bigeasy@linutronix.de\nv4: https://lore.kernel.org/all/20240604154425.878636-1-bigeasy@linutronix.de\nv3: https://lore.kernel.org/all/20240529162927.403425-1-bigeasy@linutronix.de\nv2: https://lore.kernel.org/all/20240503182957.1042122-1-bigeasy@linutronix.de\nv1: https://lore.kernel.org/all/20231215171020.687342-1-bigeasy@linutronix.de\n====================\n\nLink: https://patch.msgid.link/20240620132727.660738-1-bigeasy@linutronix.de\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Introduce nested bottom halves locking for improved task and interrupt handling on PREEMPT_RT systems.,"nested-BH locking, PREEMPT_RT, networking",It's a new feature.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3f9fe37d9e16a6cfd5f4d1f536686ea71db3196f,3f9fe37d9e16a6cfd5f4d1f536686ea71db3196f,Sebastian Andrzej Siewior,bigeasy@linutronix.de,1718889725,Jakub Kicinski,kuba@kernel.org,1719272484,ec13e5174a4146e629e239f084b753d4fae4c162,401cb7dae8130fd34eb84648e02ab4c506df7d5e,"net: Move per-CPU flush-lists to bpf_net_context on PREEMPT_RT.

The per-CPU flush lists"," which are accessed from within the NAPI callback
(xdp_do_flush() for instance)","[' are per-CPU. There are subject to the\nsame problem as struct bpf_redirect_info.\n\nAdd the per-CPU lists cpu_map_flush_list', ' dev_map_flush_list and\nxskmap_map_flush_list to struct bpf_net_context. Add wrappers for the\naccess. The lists initialized on first usage (similar to\nbpf_net_ctx_get_ri()).\n\nCc: ""Björn Töpel"" <bjorn@kernel.org>\nCc: Alexei Starovoitov <ast@kernel.org>\nCc: Andrii Nakryiko <andrii@kernel.org>\nCc: Eduard Zingerman <eddyz87@gmail.com>\nCc: Hao Luo <haoluo@google.com>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: John Fastabend <john.fastabend@gmail.com>\nCc: Jonathan Lemon <jonathan.lemon@gmail.com>\nCc: KP Singh <kpsingh@kernel.org>\nCc: Maciej Fijalkowski <maciej.fijalkowski@intel.com>\nCc: Magnus Karlsson <magnus.karlsson@intel.com>\nCc: Martin KaFai Lau <martin.lau@linux.dev>\nCc: Song Liu <song@kernel.org>\nCc: Stanislav Fomichev <sdf@google.com>\nCc: Yonghong Song <yonghong.song@linux.dev>\nAcked-by: Jesper Dangaard Brouer <hawk@kernel.org>\nReviewed-by: Toke Høiland-Jørgensen <toke@redhat.com>\nSigned-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>\nLink: https://patch.msgid.link/20240620132727.660738-16-bigeasy@linutronix.de\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Move per-CPU flush lists to bpf_net_context on PREEMPT_RT for improved performance.,"per-CPU, PREEMPT_RT, bpf_net_context",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['xdp like programs']
401cb7dae8130fd34eb84648e02ab4c506df7d5e,401cb7dae8130fd34eb84648e02ab4c506df7d5e,Sebastian Andrzej Siewior,bigeasy@linutronix.de,1718889724,Jakub Kicinski,kuba@kernel.org,1719272484,f551429eb47ddd58e2bfb13aff74aa894752a3d9,78f520b7bbe579438dfc202226b3dac5607d8c7f,"net: Reference bpf_redirect_info via task_struct on PREEMPT_RT.

The XDP redirect process is two staged:
- bpf_prog_run_xdp() is invoked to run a eBPF program which inspects the
  packet and makes decisions. While doing that"," the per-CPU variable
  bpf_redirect_info is used.

- Afterwards xdp_do_redirect() is invoked and accesses bpf_redirect_info
  and it may also access other per-CPU variables like xskmap_flush_list.

At the very end of the NAPI callback","[' xdp_do_flush() is invoked which\ndoes not access bpf_redirect_info but will touch the individual per-CPU\nlists.\n\nThe per-CPU variables are only used in the NAPI callback hence disabling\nbottom halves is the only protection mechanism. Users from preemptible\ncontext (like cpu_map_kthread_run()) explicitly disable bottom halves\nfor protections reasons.\nWithout locking in local_bh_disable() on PREEMPT_RT this data structure\nrequires explicit locking.\n\nPREEMPT_RT has forced-threaded interrupts enabled and every\nNAPI-callback runs in a thread. If each thread has its own data\nstructure then locking can be avoided.\n\nCreate a struct bpf_net_context which contains struct bpf_redirect_info.\nDefine the variable on stack', ' use bpf_net_ctx_set() to save a pointer to\nit', "" bpf_net_ctx_clear() removes it again.\nThe bpf_net_ctx_set() may nest. For instance a function can be used from\nwithin NET_RX_SOFTIRQ/ net_rx_action which uses bpf_net_ctx_set() and\nNET_TX_SOFTIRQ which does not. Therefore only the first invocations\nupdates the pointer.\nUse bpf_net_ctx_get_ri() as a wrapper to retrieve the current struct\nbpf_redirect_info. The returned data structure is zero initialized to\nensure nothing is leaked from stack. This is done on first usage of the\nstruct. bpf_net_ctx_set() sets bpf_redirect_info::kern_flags to 0 to\nnote that initialisation is required. First invocation of\nbpf_net_ctx_get_ri() will memset() the data structure and update\nbpf_redirect_info::kern_flags.\nbpf_redirect_info::nh is excluded from memset because it is only used\nonce BPF_F_NEIGH is set which also sets the nh member. The kern_flags is\nmoved past nh to exclude it from memset.\n\nThe pointer to bpf_net_context is saved task's task_struct. Using\nalways the bpf_net_context approach has the advantage that there is\nalmost zero differences between PREEMPT_RT and non-PREEMPT_RT builds.\n\nCc: Andrii Nakryiko <andrii@kernel.org>\nCc: Eduard Zingerman <eddyz87@gmail.com>\nCc: Hao Luo <haoluo@google.com>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: John Fastabend <john.fastabend@gmail.com>\nCc: KP Singh <kpsingh@kernel.org>\nCc: Martin KaFai Lau <martin.lau@linux.dev>\nCc: Song Liu <song@kernel.org>\nCc: Stanislav Fomichev <sdf@google.com>\nCc: Yonghong Song <yonghong.song@linux.dev>\nAcked-by: Alexei Starovoitov <ast@kernel.org>\nAcked-by: Jesper Dangaard Brouer <hawk@kernel.org>\nReviewed-by: Toke Høiland-Jørgensen <toke@redhat.com>\nSigned-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>\nLink: https://patch.msgid.link/20240620132727.660738-15-bigeasy@linutronix.de\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n"", '']",Enhance reference handling of bpf_redirect_info via task_struct in XDP for PREEMPT_RT.,"bpf_redirect_info, xdp, PREEMPT_RT",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['xdp like programs']
78f520b7bbe579438dfc202226b3dac5607d8c7f,78f520b7bbe579438dfc202226b3dac5607d8c7f,Sebastian Andrzej Siewior,bigeasy@linutronix.de,1718889723,Jakub Kicinski,kuba@kernel.org,1719272483,5153f67a77881d0cb30315535265f04093828146,d1542d4ae4dfdc47c9b3205ebe849ed23af213dd,"net: Use nested-BH locking for bpf_scratchpad.

bpf_scratchpad is a per-CPU variable and relies on disabled BH for its
locking. Without per-CPU locking in local_bh_disable() on PREEMPT_RT
this data structure requires explicit locking.

Add a local_lock_t to the data structure and use local_lock_nested_bh()
for locking. This change adds only lockdep coverage and does not alter
the functional behaviour for !PREEMPT_RT.

Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Andrii Nakryiko <andrii@kernel.org>
Cc: Hao Luo <haoluo@google.com>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: John Fastabend <john.fastabend@gmail.com>
Cc: KP Singh <kpsingh@kernel.org>
Cc: Martin KaFai Lau <martin.lau@linux.dev>
Cc: Song Liu <song@kernel.org>
Cc: Stanislav Fomichev <sdf@google.com>
Cc: Yonghong Song <yonghong.song@linux.dev>
Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Link: https://patch.msgid.link/20240620132727.660738-14-bigeasy@linutronix.de
Signed-off-by: Jakub Kicinski <kuba@kernel.org>
",,Introduce nested-BH locking for bpf_scratchpad for better lockdep coverage in PREEMPT_RT.,"nested-BH, bpf_scratchpad, locking",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d1542d4ae4dfdc47c9b3205ebe849ed23af213dd,d1542d4ae4dfdc47c9b3205ebe849ed23af213dd,Sebastian Andrzej Siewior,bigeasy@linutronix.de,1718889722,Jakub Kicinski,kuba@kernel.org,1719272483,7fbce24c9f46f850c4092a5595f3944c62a39d6a,3414adbd6a6ad3702d0bdc49081ee7c9e9e1c600,"seg6: Use nested-BH locking for seg6_bpf_srh_states.

The access to seg6_bpf_srh_states is protected by disabling preemption.
Based on the code"," the entry point is input_action_end_bpf() and
every other function (the bpf helper functions bpf_lwt_seg6_*())","[' that\nis accessing seg6_bpf_srh_states', "" should be called from within\ninput_action_end_bpf().\n\ninput_action_end_bpf() accesses seg6_bpf_srh_states first at the top of\nthe function and then disables preemption. This looks wrong because if\npreemption needs to be disabled as part of the locking mechanism then\nthe variable shouldn't be accessed beforehand.\n\nLooking at how it is used via test_lwt_seg6local.sh then\ninput_action_end_bpf() is always invoked from softirq context. If this\nis always the case then the preempt_disable() statement is superfluous.\nIf this is not always invoked from softirq then disabling only\npreemption is not sufficient.\n\nReplace the preempt_disable() statement with nested-BH locking. This is\nnot an equivalent replacement as it assumes that the invocation of\ninput_action_end_bpf() always occurs in softirq context and thus the\npreempt_disable() is superfluous.\nAdd a local_lock_t the data structure and use local_lock_nested_bh() for\nlocking. Add lockdep_assert_held() to ensure the lock is held while the\nper-CPU variable is referenced in the helper functions.\n\nCc: Alexei Starovoitov <ast@kernel.org>\nCc: Andrii Nakryiko <andrii@kernel.org>\nCc: David Ahern <dsahern@kernel.org>\nCc: Hao Luo <haoluo@google.com>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: John Fastabend <john.fastabend@gmail.com>\nCc: KP Singh <kpsingh@kernel.org>\nCc: Martin KaFai Lau <martin.lau@linux.dev>\nCc: Song Liu <song@kernel.org>\nCc: Stanislav Fomichev <sdf@google.com>\nCc: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>\nLink: https://patch.msgid.link/20240620132727.660738-13-bigeasy@linutronix.de\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n"", '']",Use nested-BH locking for seg6_bpf_srh_states to protect access by disabling preemption.,"nested-BH locking, seg6_bpf_srh_states, preemption",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
c73a9683cb21012b6c0f14217974837151c527a8,c73a9683cb21012b6c0f14217974837151c527a8,Antoine Tenart,atenart@kernel.org,1719220147,Andrii Nakryiko,andrii@kernel.org,1719245982,f5de59085d4b706dd8324c7167e9a9df7fefae03,5a532459aa919d055d822d8db4ea2c5c8d511568,"libbpf: Skip base btf sanity checks

When upgrading to libbpf 1.3 we noticed a big performance hit while
loading programs using CORE on non base-BTF symbols. This was tracked
down to the new BTF sanity check logic. The issue is the base BTF
definitions are checked first for the base BTF and then again for every
module BTF.

Loading 5 dummy programs (using libbpf-rs) that are using CORE on a
non-base BTF symbol on my system:
- Before this fix: 3s.
- With this fix: 0.1s.

Fix this by only checking the types starting at the BTF start id. This
should ensure the base BTF is still checked as expected but only once
(btf->start_id == 1 when creating the base BTF)"," and then only
additional types are checked for each module BTF.

Fixes: 3903802bb99a (""libbpf: Add basic BTF sanity validation"")
Signed-off-by: Antoine Tenart <atenart@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Reviewed-by: Alan Maguire <alan.maguire@oracle.com>
Link: https://lore.kernel.org/bpf/20240624090908.171231-1-atenart@kernel.org
",[''],The commit optimizes BTF sanity checks in libbpf to improve performance when loading programs using CORE on non-base BTF symbols.,"libbpf, BTF, performance",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7e9f79428372c6eab92271390851be34ab26bfb4,7e9f79428372c6eab92271390851be34ab26bfb4,Daniil Dulov,d.dulov@aladdin.ru,1719216467,Daniel Borkmann,daniel@iogearbox.net,1719229442,cb5279f0a4e1e750c0bf7a45581d9caf5ad41405,280e4ebffd16ea1b55dc09761448545e216f60a9,"xdp: Remove WARN() from __xdp_reg_mem_model()

syzkaller reports a warning in __xdp_reg_mem_model().

The warning occurs only if __mem_id_init_hash_table() returns an error. It
returns the error in two cases:

  1. memory allocation fails;
  2. rhashtable_init() fails when some fields of rhashtable_params
     struct are not initialized properly.

The second case cannot happen since there is a static const rhashtable_params
struct with valid fields. So"," warning is only triggered when there is a
problem with memory allocation.

Thus","[' there is no sense in using WARN() to handle this error and it can be\nsafely removed.\n\nWARNING: CPU: 0 PID: 5065 at net/core/xdp.c:299 __xdp_reg_mem_model+0x2d9/0x650 net/core/xdp.c:299\n\nCPU: 0 PID: 5065 Comm: syz-executor883 Not tainted 6.8.0-syzkaller-05271-gf99c5f563c17 #0\nHardware name: Google Google Compute Engine/Google Compute Engine', ' BIOS Google 03/27/2024\nRIP: 0010:__xdp_reg_mem_model+0x2d9/0x650 net/core/xdp.c:299\n\nCall Trace:\n xdp_reg_mem_model+0x22/0x40 net/core/xdp.c:344\n xdp_test_run_setup net/bpf/test_run.c:188 [inline]\n bpf_test_run_xdp_live+0x365/0x1e90 net/bpf/test_run.c:377\n bpf_prog_test_run_xdp+0x813/0x11b0 net/bpf/test_run.c:1267\n bpf_prog_test_run+0x33a/0x3b0 kernel/bpf/syscall.c:4240\n __sys_bpf+0x48d/0x810 kernel/bpf/syscall.c:5649\n __do_sys_bpf kernel/bpf/syscall.c:5738 [inline]\n __se_sys_bpf kernel/bpf/syscall.c:5736 [inline]\n __x64_sys_bpf+0x7c/0x90 kernel/bpf/syscall.c:5736\n do_syscall_64+0xfb/0x240\n entry_SYSCALL_64_after_hwframe+0x6d/0x75\n\nFound by Linux Verification Center (linuxtesting.org) with syzkaller.\n\nFixes: 8d5d88527587 (""xdp: rhashtable with allocator ID to pointer mapping"")\nSigned-off-by: Daniil Dulov <d.dulov@aladdin.ru>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Jesper Dangaard Brouer <hawk@kernel.org>\nLink: https://lore.kernel.org/all/20240617162708.492159-1-d.dulov@aladdin.ru\nLink: https://lore.kernel.org/bpf/20240624080747.36858-1-d.dulov@aladdin.ru\n', '']",Remove unnecessary warning in __xdp_reg_mem_model() related to memory allocation failures.,"WARN, xdp, memory",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF maps,['xdp like programs']
280e4ebffd16ea1b55dc09761448545e216f60a9,280e4ebffd16ea1b55dc09761448545e216f60a9,Alexei Starovoitov,ast@kernel.org,1718841235,Daniel Borkmann,daniel@iogearbox.net,1719229442,add4f9de750ad798adfe85644c9d1c0b3f822778,2b2efe1937ca9f8815884bd4dcd5b32733025103,"selftests/bpf: Add tests for may_goto with negative offset.

Add few tests with may_goto and negative offset.

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240619235355.85031-2-alexei.starovoitov@gmail.com
",,Add selftests for may_goto functionality with negative offset in BPF.,"selftests, may_goto, negative offset",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2b2efe1937ca9f8815884bd4dcd5b32733025103,2b2efe1937ca9f8815884bd4dcd5b32733025103,Alexei Starovoitov,ast@kernel.org,1718841234,Daniel Borkmann,daniel@iogearbox.net,1719229442,a48009516a3d43671f0380601a016fef79acb9c6,316930d06b92a2419d8e767193266e678545b31d,"bpf: Fix may_goto with negative offset.

Zac's syzbot crafted a bpf prog that exposed two bugs in may_goto.
The 1st bug is the way may_goto is patched. When offset is negative
it should be patched differently.
The 2nd bug is in the verifier:
when current state may_goto_depth is equal to visited state may_goto_depth
it means there is an actual infinite loop. It's not correct to prune
exploration of the program at this point.
Note", that this check doesn't limit the program to only one may_goto insn,"['\nsince 2nd and any further may_goto will increment may_goto_depth only\nin the queued state pushed for future exploration. The current state\nwill have may_goto_depth == 0 regardless of number of may_goto insns\nand the verifier has to explore the program until bpf_exit.\n\nFixes: 011832b97b31 (""bpf: Introduce may_goto instruction"")\nReported-by: Zac Ecob <zacecob@protonmail.com>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nCloses: https://lore.kernel.org/bpf/CAADnVQL-15aNp04-cyHRn47Yv61NXfYyhopyZtUyxNojUZUXpA@mail.gmail.com/\nLink: https://lore.kernel.org/bpf/20240619235355.85031-1-alexei.starovoitov@gmail.com\n', '']",This commit fixes two issues in the bpf verifier related to may_goto with negative offsets.,"bpf,may_goto,verifier",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
316930d06b92a2419d8e767193266e678545b31d,316930d06b92a2419d8e767193266e678545b31d,Daniel Borkmann,daniel@iogearbox.net,1718978908,Daniel Borkmann,daniel@iogearbox.net,1719229435,d498031afe82edab178a71249bc585611b9ebe88,cfa1a2329a691ffd991fcf7248a57d752e712881,"selftests/bpf: Add more ring buffer test coverage

Add test coverage for reservations beyond the ring buffer size in order
to validate that bpf_ringbuf_reserve() rejects the request with NULL"," all
other ring buffer tests keep passing as well:

  # ./vmtest.sh -- ./test_progs -t ringbuf
  [...]
  ./test_progs -t ringbuf
  [    1.165434] bpf_testmod: loading out-of-tree module taints kernel.
  [    1.165825] bpf_testmod: module verification failed: signature and/or required key missing - tainting kernel
  [    1.284001] tsc: Refined TSC clocksource calibration: 3407.982 MHz
  [    1.286871] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x311fc34e357","[' max_idle_ns: 440795379773 ns\n  [    1.289555] clocksource: Switched to clocksource tsc\n  #274/1   ringbuf/ringbuf:OK\n  #274/2   ringbuf/ringbuf_n:OK\n  #274/3   ringbuf/ringbuf_map_key:OK\n  #274/4   ringbuf/ringbuf_write:OK\n  #274     ringbuf:OK\n  #275     ringbuf_multi:OK\n  [...]\n\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n[ Test fixups for getting BPF CI back to work ]\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240621140828.18238-2-daniel@iogearbox.net\n', '']",Add additional test coverage for ring buffer reservations exceeding size to ensure proper rejection in bpf_ringbuf_reserve().,"ring buffer, test coverage, bpf_ringbuf_reserve",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5a532459aa919d055d822d8db4ea2c5c8d511568,5a532459aa919d055d822d8db4ea2c5c8d511568,Alan Maguire,alan.maguire@oracle.com,1719150744,Alexei Starovoitov,ast@kernel.org,1719172202,b5d96e2179b59d62a4a75d3b92e2b5c4dbcc4df5,04efaebd72d1d3d9991841051fafc6b195f3676d,"bpf: fix build when CONFIG_DEBUG_INFO_BTF[_MODULES] is undefined

Kernel test robot reports that kernel build fails with
resilient split BTF changes.

Examining the associated config and code we see that
btf_relocate_id() is defined under CONFIG_DEBUG_INFO_BTF_MODULES.
Moving it outside the #ifdef solves the issue.

Reported-by: kernel test robot <lkp@intel.com>
Closes: https://lore.kernel.org/oe-kbuild-all/202406221742.d2srFLVI-lkp@intel.com/
Signed-off-by: Alan Maguire <alan.maguire@oracle.com>
Link: https://lore.kernel.org/r/20240623135224.27981-1-alan.maguire@oracle.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Fix kernel build failure by relocating btf_relocate_id() outside the CONFIG_DEBUG_INFO_BTF_MODULES conditional compilation block.,"kernel,build,BTF",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
04efaebd72d1d3d9991841051fafc6b195f3676d,04efaebd72d1d3d9991841051fafc6b195f3676d,Dave Thaler,dthaler1968@googlemail.com,1719155093,Alexei Starovoitov,ast@kernel.org,1719159026,7d01c8f1bdcbf2d3199341d50e8eb3d1640c7a7f,93265a0b79e48fde8ee23fb6e1195d7d99717063,bpf," docs: Address comments from IETF Area Directors

This patch does the following to address IETF feedback:

* Remove mention of ""program type"" and reference future
  docs (and mention platform-specific docs exist) for
  helper functions and BTF. Addresses Roman Danyliw's
  comments based on GENART review from Ines Robles [0].

* Add reference for endianness as requested by John
  Scudder [1].

* Added bit numbers to top of 32-bit wide format diagrams
  as requested by Paul Wouters [2].

* Added more text about why BPF doesn't stand for anything","[' based\n  on text from ebpf.io [3]', ' as requested by Eric Vyncke and\n  Gunter Van de Velde [4].\n\n* Replaced ""htobe16"" (and similar) and the direction-specific\n  description with just ""be16"" (and similar) and a direction-agnostic\n  description', ' to match the direction-agnostic description in\n  the Byteswap Instructions section. Based on feedback from Eric\n  Vyncke [5].\n\n[0] https://mailarchive.ietf.org/arch/msg/bpf/DvDgDWOiwk05OyNlWlAmELZFPlM/\n\n[1] https://mailarchive.ietf.org/arch/msg/bpf/eKNXpU4jCLjsbZDSw8LjI29M3tM/\n\n[2] https://mailarchive.ietf.org/arch/msg/bpf/hGk8HkYxeZTpdu9qW_MvbGKj7WU/\n\n[3] https://ebpf.io/what-is-ebpf/#what-do-ebpf-and-bpf-stand-for\n\n[4] https://mailarchive.ietf.org/arch/msg/bpf/i93lzdN3ewnzzS_JMbinCIYxAIU/\n\n[5] https://mailarchive.ietf.org/arch/msg/bpf/KBWXbMeDcSrq4vsKR_KkBbV6hI4/\n\nAcked-by: David Vernet <void@manifault.com>\nSigned-off-by: Dave Thaler <dthaler1968@googlemail.com>\nLink: https://lore.kernel.org/r/20240623150453.10613-1-dthaler1968@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']","The commit addresses IETF feedback by modifying documentation, adding references, and updating diagrams related to BPF.","documentation, IETF, feedback",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),"[""It's not related to any of the above.""]"
93265a0b79e48fde8ee23fb6e1195d7d99717063,93265a0b79e48fde8ee23fb6e1195d7d99717063,Andrii Nakryiko,andrii@kernel.org,1719006308,Andrii Nakryiko,andrii@kernel.org,1719006393,4af832750443c5224152d4bdae82c8e69fc674c8,cd387ce54834bc7808082c471fd745ce85a0e21f 47a8cf0c5b3f6769b9d558301735c75119a0a165,"Merge branch 'bpf-resilient-split-btf-followups'

Alan Maguire says:

====================
bpf: resilient split BTF followups

Follow-up to resilient split BTF series [1]","

- cleaning up libbpf relocation code (patch 1);
- adding 'struct module' support for base BTF data (patch 2);
- splitting out field iteration code into separate file (patch 3);
- sharing libbpf relocation code with the kernel (patch 4);
- adding a kbuild --btf_features flag to generate distilled base
  BTF in the module-specific case where KBUILD_EXTMOD is true
  (patch 5); and
- adding test coverage for module-based kfunc dtor (patch 6)

Generation of distilled base BTF for modules requires the pahole patch
at [2]","["" but without it we just won't get distilled base BTF (and thus BTF\nrelocation on module load) for bpf_testmod.ko.\n\nChanges since v1 [3]:\n\n- fixed line lengths and made comparison an explicit == 0 (Andrii"", ' patch 1)\n- moved btf_iter.c changes to separate patch (Andrii', ' patch 3)\n- grouped common targets in kernel/bpf/Makefile (Andrii', ' patch 4)\n- updated bpf_testmod ctx alloc to use GFP_ATOMIC', ' and updated dtor\n  selftest to use map-based dtor cleanup (Eduard', ' patch 6)\n\n[1] https://lore.kernel.org/bpf/20240613095014.357981-1-alan.maguire@oracle.com/\n[2] https://lore.kernel.org/bpf/20240517102714.4072080-1-alan.maguire@oracle.com/\n[3] https://lore.kernel.org/bpf/20240618162449.809994-1-alan.maguire@oracle.com/\n====================\n\nLink: https://lore.kernel.org/r/20240620091733.1967885-1-alan.maguire@oracle.com\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n', '']",This commit introduces follow-ups to the resilient split BTF series focusing on libbpf improvements and test coverage additions.,"resilient,BTF,libbpf",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
47a8cf0c5b3f6769b9d558301735c75119a0a165,47a8cf0c5b3f6769b9d558301735c75119a0a165,Alan Maguire,alan.maguire@oracle.com,1718875053,Andrii Nakryiko,andrii@kernel.org,1719006389,4af832750443c5224152d4bdae82c8e69fc674c8,46fb0b62ea29c0dbcb3e44f1d67aafe79bc6e045,"selftests/bpf: Add kfunc_call test for simple dtor in bpf_testmod

add simple kfuncs to create/destroy a context type to bpf_testmod","
register them and add a kfunc_call test to use them.  This provides
test coverage for registration of dtor kfuncs from modules.

By transferring the context pointer to a map value as a __kptr
we also trigger the map-based dtor cleanup logic","[' improving test\ncoverage.\n\nSuggested-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Alan Maguire <alan.maguire@oracle.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240620091733.1967885-7-alan.maguire@oracle.com\n', '']",Added kfunc_call test for destructor logic in bpf_testmod selftests.,"kfuncs,selftests,destructor",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
46fb0b62ea29c0dbcb3e44f1d67aafe79bc6e045,46fb0b62ea29c0dbcb3e44f1d67aafe79bc6e045,Alan Maguire,alan.maguire@oracle.com,1718875052,Andrii Nakryiko,andrii@kernel.org,1719006307,ee099472310e53d874ad531b3747d3ea760a1293,8646db238997df36c6ad71a9d7e0b52ceee221b2,kbuild,"bpf: Add module-specific pahole flags for distilled base BTF

Support creation of module BTF along with distilled base BTF;
the latter is stored in a .BTF.base ELF section and supplements
split BTF references to base BTF with information about base types","['\nallowing for later relocation of split BTF with a (possibly\nchanged) base.  resolve_btfids detects the presence of a .BTF.base\nsection and will use it instead of the base BTF it is passed in\nBTF id resolution.\n\nModules will be built with a distilled .BTF.base section for external\nmodule build', ' i.e.\n\nmake -C. -M=path2/module\n\n...while in-tree module build as part of a normal kernel build will\nnot generate distilled base BTF; this is because in-tree modules\nchange with the kernel and do not require BTF relocation for the\nrunning vmlinux.\n\nSigned-off-by: Alan Maguire <alan.maguire@oracle.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nReviewed-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/bpf/20240620091733.1967885-6-alan.maguire@oracle.com\n', '']",The commit adds support for module BTF and distilled base BTF with corresponding pahole flags.,"module BTF, distilled BTF, pahole flags",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8646db238997df36c6ad71a9d7e0b52ceee221b2,8646db238997df36c6ad71a9d7e0b52ceee221b2,Alan Maguire,alan.maguire@oracle.com,1718875051,Andrii Nakryiko,andrii@kernel.org,1719006307,3968d9444fab7f563fc71f78ac0fb2fd5df188e0,e7ac331b30555cf1a0826784a346f36dbf800451,libbpf,"bpf: Share BTF relocate-related code with kernel

Share relocation implementation with the kernel.  As part of this","['\nwe also need the type/string iteration functions so also share\nbtf_iter.c file. Relocation code in kernel and userspace is identical\nsave for the impementation of the reparenting of split BTF to the\nrelocated base BTF and retrieval of the BTF header from ""struct btf"";\nthese small functions need separate user-space and kernel implementations\nfor the separate ""struct btf""s they operate upon.\n\nOne other wrinkle on the kernel side is we have to map .BTF.ids in\nmodules as they were generated with the type ids used at BTF encoding\ntime. btf_relocate() optionally returns an array mapping from old BTF\nids to relocated ids', ' so we use that to fix up these references where\nneeded for kfuncs.\n\nSigned-off-by: Alan Maguire <alan.maguire@oracle.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/bpf/20240620091733.1967885-5-alan.maguire@oracle.com\n', '']",Share BTF relocation implementation code between libbpf and the kernel for unified handling.,"BTF,relocation,kernel",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e7ac331b30555cf1a0826784a346f36dbf800451,e7ac331b30555cf1a0826784a346f36dbf800451,Alan Maguire,alan.maguire@oracle.com,1718875050,Andrii Nakryiko,andrii@kernel.org,1719006307,954e49699d647af7a1139b9d4879fc1a1ea52cd8,d4e48e3dd45017abdd69a19285d197de897ef44f,"libbpf: Split field iter code into its own file kernel

This will allow it to be shared with the kernel.  No functional change.

Suggested-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Alan Maguire <alan.maguire@oracle.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240620091733.1967885-4-alan.maguire@oracle.com
",,Refactor field iterator code in libbpf to a separate file for kernel sharing.,"libbpf, refactor, kernel",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d4e48e3dd45017abdd69a19285d197de897ef44f,d4e48e3dd45017abdd69a19285d197de897ef44f,Alan Maguire,alan.maguire@oracle.com,1718875049,Andrii Nakryiko,andrii@kernel.org,1719006307,a0f022a078e3faa261970df64601e3b446660f2e,d1cf840854bb603c0718a011bc993f69f2df014e,module," bpf: Store BTF base pointer in struct module

...as this will allow split BTF modules with a base BTF
representation (rather than the full vmlinux BTF at time of
BTF encoding) to resolve their references to kernel types in a
way that is more resilient to small changes in kernel types.

This will allow modules that are not built every time the kernel
is to provide more resilient BTF","[' rather than have it invalidated\nevery time BTF ids for core kernel types change.\n\nFields are ordered to avoid holes in struct module.\n\nSigned-off-by: Alan Maguire <alan.maguire@oracle.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nReviewed-by: Luis Chamberlain <mcgrof@kernel.org>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240620091733.1967885-3-alan.maguire@oracle.com\n', '']",The commit stores the BTF base pointer in struct module to improve BTF resilience in split BTF modules.,"BTF, module, resilience",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d1cf840854bb603c0718a011bc993f69f2df014e,d1cf840854bb603c0718a011bc993f69f2df014e,Alan Maguire,alan.maguire@oracle.com,1718875048,Andrii Nakryiko,andrii@kernel.org,1719006307,00e35f54f2c4eab841b444bc7352d1aa682d917a,cd387ce54834bc7808082c471fd745ce85a0e21f,libbpf: BTF relocation followup fixing naming," loop logic

Use less verbose names in BTF relocation code and fix off-by-one error
and typo in btf_relocate.c.  Simplify loop over matching distilled
types","[' moving from assigning a _next value in loop body to moving\nmatch check conditions into the guard.\n\nSuggested-by: Andrii Nakryiko <andrii.nakryiko@gmail.com>\nSigned-off-by: Alan Maguire <alan.maguire@oracle.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/bpf/20240620091733.1967885-2-alan.maguire@oracle.com\n', '']",Fix naming issues and simplify loop logic in BTF relocation code of libbpf.,"BTF relocation, naming, fix",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"[""It's not related to any of the above.""]"
cd387ce54834bc7808082c471fd745ce85a0e21f,cd387ce54834bc7808082c471fd745ce85a0e21f,Mykyta Yatsenko,yatsenko@meta.com,1718993004,Andrii Nakryiko,andrii@kernel.org,1719005663,369ff5d92a6d9fbdf74906d9ba35ad064f8ec406,2bb138cb20a6a347cfed84381430cd25e05f118e,"selftests/bpf: Test struct_ops bpf map auto-attach

Adding selftest to verify that struct_ops maps are auto attached by
bpf skeleton's `*__attach` function.

Signed-off-by: Mykyta Yatsenko <yatsenko@meta.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240621180324.238379-1-yatsenko@meta.com
",,Add selftest for verifying auto-attachment of struct_ops bpf maps by bpf skeleton.,"selftest, struct_ops, auto-attach",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2bb138cb20a6a347cfed84381430cd25e05f118e,2bb138cb20a6a347cfed84381430cd25e05f118e,Puranjay Mohan,puranjay@kernel.org,1718802814,Andrii Nakryiko,andrii@kernel.org,1719005313,a3e9841f3e93378a7db305fdfe5a3777b3f9142b,2807db78ab302eab2c86c5924e4079adb63fd7c8,bpf," arm64: Inline bpf_get_current_task/_btf() helpers

On ARM64","[' the pointer to task_struct is always available in the sp_el0\nregister and therefore the calls to bpf_get_current_task() and\nbpf_get_current_task_btf() can be inlined into a single MRS instruction.\n\nHere is the difference before and after this change:\n\nBefore:\n\n; struct task_struct *task = bpf_get_current_task_btf();\n  54:   mov     x10', ' #0xffffffffffff7978        // #-34440\n  58:   movk    x10', ' #0x802b', ' lsl #16\n  5c:   movk    x10', ' #0x8000', ' lsl #32\n  60:   blr     x10          -------------->    0xffff8000802b7978 <+0>:     mrs     x0', ' sp_el0\n  64:   add     x7', ' x0', ' #0x0 <--------------    0xffff8000802b797c <+4>:     ret\n\nAfter:\n\n; struct task_struct *task = bpf_get_current_task_btf();\n  54:   mrs     x7', ' sp_el0\n\nThis shows around 1% performance improvement in artificial microbenchmark.\n\nSigned-off-by: Puranjay Mohan <puranjay@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Xu Kuohai <xukuohai@huawei.com>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240619131334.4297-1-puranjay@kernel.org\n', '']",Inline bpf_get_current_task and bpf_get_current_btf helpers for ARM64 architecture.,"bpf, ARM64, helpers",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['other']
3e23c99764d465ae411f0729fd6d2e0e3edd0ade,3e23c99764d465ae411f0729fd6d2e0e3edd0ade,Cupertino Miranda,cupertino.miranda@oracle.com,1718633698,Andrii Nakryiko,andrii@kernel.org,1719003263,81295b6e2131a740e403fa22e4a373300c5d84b5,f06ae6194f278444201e0b041a00192d794f83b6,"selftests/bpf: Match tests against regular expression

This patch changes a few tests to make use of regular expressions.
Fixed tests otherwise fail when compiled with GCC.

Signed-off-by: Cupertino Miranda <cupertino.miranda@oracle.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/bpf/20240617141458.471620-3-cupertino.miranda@oracle.com
",,This patch updates selftests to use regular expressions to fix compatibility issues with GCC.,"selftests, regular expressions, GCC",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
f06ae6194f278444201e0b041a00192d794f83b6,f06ae6194f278444201e0b041a00192d794f83b6,Cupertino Miranda,cupertino.miranda@oracle.com,1718633697,Andrii Nakryiko,andrii@kernel.org,1719003263,3dfc649391aa0021a8e07a73225564436c139c0c,cc5083d1f3881624ad2de1f3cbb3a07e152cb254,"selftests/bpf: Support checks against a regular expression

Add support for __regex and __regex_unpriv macros to check the test
execution output against a regular expression. This is similar to __msg
and __msg_unpriv"," however those expect do substring matching.

Signed-off-by: Cupertino Miranda <cupertino.miranda@oracle.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/bpf/20240617141458.471620-2-cupertino.miranda@oracle.com
",[''],Added support for regex matching in selftests to verify test outputs against regular expressions.,"regex,selftests,macros",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
cfa1a2329a691ffd991fcf7248a57d752e712881,cfa1a2329a691ffd991fcf7248a57d752e712881,Daniel Borkmann,daniel@iogearbox.net,1718978907,Andrii Nakryiko,andrii@kernel.org,1719000261,1a983afbdfa114375ab712a5bb0a28e3fcd64e09,2673315947c9f3890ad34a8196f62142e4ddef5a,"bpf: Fix overrunning reservations in ringbuf

The BPF ring buffer internally is implemented as a power-of-2 sized circular
buffer"," with two logical and ever-increasing counters: consumer_pos is the
consumer counter to show which logical position the consumer consumed the
data","[' and producer_pos which is the producer counter denoting the amount of\ndata reserved by all producers.\n\nEach time a record is reserved', ' the producer that ""owns"" the record will\nsuccessfully advance producer counter. In user space each time a record is\nread', ' the consumer of the data advanced the consumer counter once it finished\nprocessing. Both counters are stored in separate pages so that from user\nspace', ' the producer counter is read-only and the consumer counter is read-write.\n\nOne aspect that simplifies and thus speeds up the implementation of both\nproducers and consumers is how the data area is mapped twice contiguously\nback-to-back in the virtual memory', ' allowing to not take any special measures\nfor samples that have to wrap around at the end of the circular buffer data\narea', ' because the next page after the last data page would be first data page\nagain', ' and thus the sample will still appear completely contiguous in virtual\nmemory.\n\nEach record has a struct bpf_ringbuf_hdr { u32 len; u32 pg_off; } header for\nbook-keeping the length and offset', ' and is inaccessible to the BPF program.\nHelpers like bpf_ringbuf_reserve() return `(void *)hdr + BPF_RINGBUF_HDR_SZ`\nfor the BPF program to use. Bing-Jhong and Muhammad reported that it is however\npossible to make a second allocated memory chunk overlapping with the first\nchunk and as a result', "" the BPF program is now able to edit first chunk's\nheader.\n\nFor example"", ' consider the creation of a BPF_MAP_TYPE_RINGBUF map with size\nof 0x4000. Next', ' the consumer_pos is modified to 0x3000 /before/ a call to\nbpf_ringbuf_reserve() is made. This will allocate a chunk A', ' which is in\n[0x0', '0x3008]', ' and the BPF program is able to edit [0x8', '0x3008]. Now', ' lets\nallocate a chunk B with size 0x3000. This will succeed because consumer_pos\nwas edited ahead of time to pass the `new_prod_pos - cons_pos > rb->mask`\ncheck. Chunk B will be in range [0x3008', '0x6010]', ' and the BPF program is able\nto edit [0x3010', '0x6010]. Due to the ring buffer memory layout mentioned\nearlier', ' the ranges [0x0', '0x4000] and [0x4000', '0x8000] point to the same data\npages. This means that chunk B at [0x4000', ""0x4008] is chunk A's header.\nbpf_ringbuf_submit() / bpf_ringbuf_discard() use the header's pg_off to then\nlocate the bpf_ringbuf itself via bpf_ringbuf_restore_from_rec(). Once chunk\nB modified chunk A's header"", ' then bpf_ringbuf_commit() refers to the wrong\npage and could cause a crash.\n\nFix it by calculating the oldest pending_pos and check whether the range\nfrom the oldest outstanding record to the newest would span beyond the ring\nbuffer size. If that is the case', "" then reject the request. We've tested with\nthe ring buffer benchmark in BPF selftests (./benchs/run_bench_ringbufs.sh)\nbefore/after the fix and while it seems a bit slower on some benchmarks"", ' it\nis still not significantly enough to matter.\n\nFixes: 457f44363a88 (""bpf: Implement BPF ring buffer and verifier support for it"")\nReported-by: Bing-Jhong Billy Jheng <billy@starlabs.sg>\nReported-by: Muhammad Ramdhan <ramdhan@starlabs.sg>\nCo-developed-by: Bing-Jhong Billy Jheng <billy@starlabs.sg>\nCo-developed-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Bing-Jhong Billy Jheng <billy@starlabs.sg>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240621140828.18238-1-daniel@iogearbox.net\n', '']",The commit fixes an issue of overrunning reservations in the eBPF ring buffer.,"bpf, ringbuf, fix",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2673315947c9f3890ad34a8196f62142e4ddef5a,2673315947c9f3890ad34a8196f62142e4ddef5a,Alexei Starovoitov,ast@kernel.org,1718759939,Daniel Borkmann,daniel@iogearbox.net,1718993929,0db77689f3fad96b70f2c84870b370bf2bedfe34,5337ac4c9b807bc46baa0713121a0afa8beacd70,"selftests/bpf: Tests with may_goto and jumps to the 1st insn

Add few tests with may_goto and jumps to the 1st insn.

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/bpf/20240619011859.79334-2-alexei.starovoitov@gmail.com
",,Add test cases for may_goto and jumps to the first instruction in selftests/bpf.,"tests,may_goto,jumps",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5337ac4c9b807bc46baa0713121a0afa8beacd70,5337ac4c9b807bc46baa0713121a0afa8beacd70,Alexei Starovoitov,ast@kernel.org,1718759938,Daniel Borkmann,daniel@iogearbox.net,1718993920,cfb42debac3f1aca052104d1b69c1e857f600dad,66b5867150630e8f9c9a2b7430e55a3beaa83a5b,"bpf: Fix the corner case with may_goto and jump to the 1st insn.

When the following program is processed by the verifier:
L1: may_goto L2
    goto L1
L2: w0 = 0
    exit

the may_goto insn is first converted to:
L1: r11 = *(u64 *)(r10 -8)
    if r11 == 0x0 goto L2
    r11 -= 1
    *(u64 *)(r10 -8) = r11
    goto L1
L2: w0 = 0
    exit

then later as the last step the verifier inserts:
  *(u64 *)(r10 -8) = BPF_MAX_LOOPS
as the first insn of the program to initialize loop count.

When the first insn happens to be a branch target of some jmp the
bpf_patch_insn_data() logic will produce:
L1: *(u64 *)(r10 -8) = BPF_MAX_LOOPS
    r11 = *(u64 *)(r10 -8)
    if r11 == 0x0 goto L2
    r11 -= 1
    *(u64 *)(r10 -8) = r11
    goto L1
L2: w0 = 0
    exit

because instruction patching adjusts all jmps and calls"," but for this
particular corner case it's incorrect and the L1 label should be one
instruction down","["" like:\n    *(u64 *)(r10 -8) = BPF_MAX_LOOPS\nL1: r11 = *(u64 *)(r10 -8)\n    if r11 == 0x0 goto L2\n    r11 -= 1\n    *(u64 *)(r10 -8) = r11\n    goto L1\nL2: w0 = 0\n    exit\n\nand that's what this patch is fixing.\nAfter bpf_patch_insn_data() call adjust_jmp_off() to adjust all jmps\nthat point to newly insert BPF_ST insn to point to insn after.\n\nNote that bpf_patch_insn_data() cannot easily be changed to accommodate\nthis logic"", ' since jumps that point before or after a sequence of patched\ninstructions have to be adjusted with the full length of the patch.\n\nConceptually it\'s somewhat similar to ""insert"" of instructions between other\ninstructions with weird semantics. Like ""insert"" before 1st insn would require\nadjustment of CALL insns to point to newly inserted 1st insn', ' but not an\nadjustment JMP insns that point to 1st', ' yet still adjusting JMP insns that\ncross over 1st insn (point to insn before or insn after)', "" hence use simple\nadjust_jmp_off() logic to fix this corner case. Ideally bpf_patch_insn_data()\nwould have an auxiliary info to say where 'the start of newly inserted patch\nis'"", ' but it would be too complex for backport.\n\nFixes: 011832b97b31 (""bpf: Introduce may_goto instruction"")\nReported-by: Zac Ecob <zacecob@protonmail.com>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nCloses: https://lore.kernel.org/bpf/CAADnVQJ_WWx8w4b=6Gc2EpzAjgv+6A0ridnMz2TvS2egj4r3Gw@mail.gmail.com/\nLink: https://lore.kernel.org/bpf/20240619011859.79334-1-alexei.starovoitov@gmail.com\n', '']",Fixes a corner case in the eBPF verifier related to jump target and loop initialization.,"verifier, jump, loop",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
cc5083d1f3881624ad2de1f3cbb3a07e152cb254,cc5083d1f3881624ad2de1f3cbb3a07e152cb254,Donglin Peng,dolinux.peng@gmail.com,1718799835,Daniel Borkmann,daniel@iogearbox.net,1718992817,f946efba13cc8cb24aa7229b10a77870e837c7a5,6ddf3a9abd9fdfdd63d8c906fc1393f7950c23f4,"libbpf: Checking the btf_type kind when fixing variable offsets

I encountered an issue when building the test_progs from the repository [1]:

  $ pwd
  /work/Qemu/x86_64/linux-6.10-rc2/tools/testing/selftests/bpf/

  $ make test_progs V=1
  [...]
  ./tools/sbin/bpftool gen object ./ip_check_defrag.bpf.linked2.o ./ip_check_defrag.bpf.linked1.o
  libbpf: failed to find symbol for variable 'bpf_dynptr_slice' in section '.ksyms'
  Error: failed to link './ip_check_defrag.bpf.linked1.o': No such file or directory (2)
  [...]

Upon investigation"," I discovered that the btf_types referenced in the '.ksyms'
section had a kind of BTF_KIND_FUNC instead of BTF_KIND_VAR:

  $ bpftool btf dump file ./ip_check_defrag.bpf.linked1.o
  [...]
  [2] DATASEC '.ksyms' size=0 vlen=2
        type_id=16 offset=0 size=0 (FUNC 'bpf_dynptr_from_skb')
        type_id=17 offset=0 size=0 (FUNC 'bpf_dynptr_slice')
  [...]
  [16] FUNC 'bpf_dynptr_from_skb' type_id=82 linkage=extern
  [17] FUNC 'bpf_dynptr_slice' type_id=85 linkage=extern
  [...]

For a detailed analysis","[' please refer to [2]. We can add a kind checking to\nfix the issue.\n\n  [1] https://github.com/eddyz87/bpf/tree/binsort-btf-dedup\n  [2] https://lore.kernel.org/all/0c0ef20c-c05e-4db9-bad7-2cbc0d6dfae7@oracle.com/\n\nFixes: 8fd27bf69b86 (""libbpf: Add BPF static linker BTF and BTF.ext support"")\nSigned-off-by: Donglin Peng <dolinux.peng@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Alan Maguire <alan.maguire@oracle.com>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/bpf/20240619122355.426405-1-dolinux.peng@gmail.com\n', '']",This commit addresses an issue with BTF_KIND_FUNC being incorrectly used instead of BTF_KIND_VAR in the libbpf component.,"btf_type, libbpf, variable",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6ddf3a9abd9fdfdd63d8c906fc1393f7950c23f4,6ddf3a9abd9fdfdd63d8c906fc1393f7950c23f4,Matt Bobrowski,mattbobrowski@google.com,1718738962,Daniel Borkmann,daniel@iogearbox.net,1718992557,9723bc5015ae8a0d3dfaa9672644523089f76fc4,651337c7ca82c259bf5c8fe9beda9673531a0031,"bpf: Add security_file_post_open() LSM hook to sleepable_lsm_hooks

The new generic LSM hook security_file_post_open() was recently added
to the LSM framework in commit 8f46ff5767b0b (""security: Introduce
file_post_open hook""). Let's proactively add this generic LSM hook to
the sleepable_lsm_hooks BTF ID set"," because I can't see there being
any strong reasons not to","["" and it's only a matter of time before\nsomeone else comes around and asks for it to be there.\n\nsecurity_file_post_open() is inherently sleepable as it's purposely\nsituated in the kernel that allows LSMs to directly read out the\ncontents of the backing file if need be. Additionally"", "" it's called\ndirectly after security_file_open()"", ' and that LSM hook in itself\nalready exists in the sleepable_lsm_hooks BTF ID set.\n\nSigned-off-by: Matt Bobrowski <mattbobrowski@google.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240618192923.379852-1-mattbobrowski@google.com\n', '']",Add security_file_post_open LSM hook to sleepable_lsm_hooks BTF ID set in eBPF.,"security,Lsm hook,sleepable_lsm_hooks",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),['LSM like programs']
651337c7ca82c259bf5c8fe9beda9673531a0031,651337c7ca82c259bf5c8fe9beda9673531a0031,Andrii Nakryiko,andrii@kernel.org,1718735912,Daniel Borkmann,daniel@iogearbox.net,1718992389,d97738b131d56d20f411fab0c0bb7fef77b2230a,717d6313bba1b3179f0bf1026aaec6b7e26f484e,"bpftool: Allow compile-time checks of BPF map auto-attach support in skeleton

New versions of bpftool now emit additional link placeholders for BPF
maps (struct_ops maps are the only maps right now that support
attachment)"," and set up BPF skeleton in such a way that libbpf will
auto-attach BPF maps automatically","["" assumming libbpf is recent enough\n(v1.5+). Old libbpf will do nothing with those links and won't attempt\nto auto-attach maps. This allows user code to handle both pre-v1.5 and\nv1.5+ versions of libbpf at runtime"", "" if necessary.\n\nBut if users don't have (or don't want to) control bpftool version that\ngenerates skeleton"", "" then they can't just assume that skeleton will have\nlink placeholders. To make this detection possible and easy"", "" let's add\nthe following to generated skeleton header file:\n\n  #define BPF_SKEL_SUPPORTS_MAP_AUTO_ATTACH 1\n\nThis can be used during compilation time to guard code that accesses\nskel->links.<map> slots.\n\nNote"", ' if auto-attachment is undesirable', ' libbpf allows to disable this\nthrough bpf_map__set_autoattach(map', ' false). This is necessary only on\nlibbpf v1.5+', "" older libbpf doesn't support map auto-attach anyways.\n\nLibbpf version can be detected at compilation time using\nLIBBPF_MAJOR_VERSION and LIBBPF_MINOR_VERSION macros"", ' or at runtime with\nlibbpf_major_version() and libbpf_minor_version() APIs.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Quentin Monnet <qmo@kernel.org>\nLink: https://lore.kernel.org/bpf/20240618183832.2535876-1-andrii@kernel.org\n', '']",The commit enhances bpftool to support compile-time checks for BPF map auto-attach in skeletons.,"bpftool,BPF map,auto-attach",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The bpftool utility,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
717d6313bba1b3179f0bf1026aaec6b7e26f484e,717d6313bba1b3179f0bf1026aaec6b7e26f484e,Jiri Olsa,jolsa@kernel.org,1718784984,Daniel Borkmann,daniel@iogearbox.net,1718991156,8d62e383d7a1c5b50b35979582e0d9bf16e16082,1ae7a19e37630d3235bc68cac9da4e032cad8136,"bpf: Change bpf_session_cookie return value to __u64 *

This reverts [1] and changes return value for bpf_session_cookie
in bpf selftests. Having long * might lead to problems on 32-bit
architectures.

Fixes: 2b8dd87332cd (""bpf: Make bpf_session_cookie() kfunc return long *"")
Suggested-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240619081624.1620152-1-jolsa@kernel.org
",,The commit reverts and modifies the return type of bpf_session_cookie to __u64 * for compatibility with 32-bit architectures.,"bpf, session_cookie, architectures",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c28947de2bed40217cf256c5d0d16880054fcf13,c28947de2bed40217cf256c5d0d16880054fcf13,Ido Schimmel,idosch@nvidia.com,1718954354,David S. Miller,davem@davemloft.net,1718976632,7b33393b52a3503889b7a99c0a42bcc438f1a5b8,0602697d6f4d72b0bc5edbc76afabf6aaa029a69,"mlxsw: spectrum_buffers: Fix memory corruptions on Spectrum-4 systems

The following two shared buffer operations make use of the Shared Buffer
Status Register (SBSR):

 # devlink sb occupancy snapshot pci/0000:01:00.0
 # devlink sb occupancy clearmax pci/0000:01:00.0

The register has two masks of 256 bits to denote on which ingress /
egress ports the register should operate on. Spectrum-4 has more than
256 ports"," so the register was extended by cited commit with a new
'port_page' field.

However","["" when filling the register's payload"", ' the driver specifies the\nports as absolute numbers and not relative to the first port of the port\npage', ' resulting in memory corruptions [1].\n\nFix by specifying the ports relative to the first port of the port page.\n\n[1]\nBUG: KASAN: slab-use-after-free in mlxsw_sp_sb_occ_snapshot+0xb6d/0xbc0\nRead of size 1 at addr ffff8881068cb00f by task devlink/1566\n[...]\nCall Trace:\n <TASK>\n dump_stack_lvl+0xc6/0x120\n print_report+0xce/0x670\n kasan_report+0xd7/0x110\n mlxsw_sp_sb_occ_snapshot+0xb6d/0xbc0\n mlxsw_devlink_sb_occ_snapshot+0x75/0xb0\n devlink_nl_sb_occ_snapshot_doit+0x1f9/0x2a0\n genl_family_rcv_msg_doit+0x20c/0x300\n genl_rcv_msg+0x567/0x800\n netlink_rcv_skb+0x170/0x450\n genl_rcv+0x2d/0x40\n netlink_unicast+0x547/0x830\n netlink_sendmsg+0x8d4/0xdb0\n __sys_sendto+0x49b/0x510\n __x64_sys_sendto+0xe5/0x1c0\n do_syscall_64+0xc1/0x1d0\n entry_SYSCALL_64_after_hwframe+0x77/0x7f\n[...]\nAllocated by task 1:\n kasan_save_stack+0x33/0x60\n kasan_save_track+0x14/0x30\n __kasan_kmalloc+0x8f/0xa0\n copy_verifier_state+0xbc2/0xfb0\n do_check_common+0x2c51/0xc7e0\n bpf_check+0x5107/0x9960\n bpf_prog_load+0xf0e/0x2690\n __sys_bpf+0x1a61/0x49d0\n __x64_sys_bpf+0x7d/0xc0\n do_syscall_64+0xc1/0x1d0\n entry_SYSCALL_64_after_hwframe+0x77/0x7f\n\nFreed by task 1:\n kasan_save_stack+0x33/0x60\n kasan_save_track+0x14/0x30\n kasan_save_free_info+0x3b/0x60\n poison_slab_object+0x109/0x170\n __kasan_slab_free+0x14/0x30\n kfree+0xca/0x2b0\n free_verifier_state+0xce/0x270\n do_check_common+0x4828/0xc7e0\n bpf_check+0x5107/0x9960\n bpf_prog_load+0xf0e/0x2690\n __sys_bpf+0x1a61/0x49d0\n __x64_sys_bpf+0x7d/0xc0\n do_syscall_64+0xc1/0x1d0\n entry_SYSCALL_64_after_hwframe+0x77/0x7f\n\nFixes: f8538aec88b4 (""mlxsw: Add support for more than 256 ports in SBSR register"")\nSigned-off-by: Ido Schimmel <idosch@nvidia.com>\nReviewed-by: Petr Machata <petrm@nvidia.com>\nReviewed-by: Simon Horman <horms@kernel.org>\nSigned-off-by: Petr Machata <petrm@nvidia.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>\n', '']",Fixed memory corruption issues on Spectrum-4 systems by adjusting shared buffer register operations.,"memory corruption,Spectrum-4,register",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['other']
8cab7cdcf5aebec354ede98bca28c08dd9df924c,8cab7cdcf5aebec354ede98bca28c08dd9df924c,Geliang Tang,tanggeliang@kylinos.cn,1718936163,Alexei Starovoitov,ast@kernel.org,1718941364,cc0e37cedfc96abfb9183b0878d6e782c132349a,fb69f71cf585aabb2f59c6d7958bccfaebe64f5d,"selftests/bpf: Use start_server_str in test_tcp_check_syncookie_user

Since start_server_str() is added now"," it can be used in script
test_tcp_check_syncookie_user.c instead of start_server_addr() to
simplify the code.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/5d2f442261d37cff16c1f1b21a2b188508ab67fa.1718932493.git.tanggeliang@kylinos.cn
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Refactor test_tcp_check_syncookie_user.c to use start_server_str for code simplification.,"selftests,bpf,simplify",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
fb69f71cf585aabb2f59c6d7958bccfaebe64f5d,fb69f71cf585aabb2f59c6d7958bccfaebe64f5d,Geliang Tang,tanggeliang@kylinos.cn,1718936162,Alexei Starovoitov,ast@kernel.org,1718941364,ca363cc0b4707c3d7d7591a966946bc1a6bd6b66,7f0d5140a6d69d3e63467a220a2a1e0c9ec1463a,"selftests/bpf: Use start_server_str in mptcp

Since start_server_str() is added now"," it can be used in mptcp.c in
start_mptcp_server() instead of using helpers make_sockaddr() and
start_server_addr() to simplify the code.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/16fb3e2cd60b64b5470b0e69f1aa233feaf2717c.1718932493.git.tanggeliang@kylinos.cn
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Simplify mptcp selftest code by using start_server_str function instead of additional helpers.,"mptcp,selftests,simplify",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['socket like programs', ""It's not related to any of the above.""]"
7f0d5140a6d69d3e63467a220a2a1e0c9ec1463a,7f0d5140a6d69d3e63467a220a2a1e0c9ec1463a,Geliang Tang,tanggeliang@kylinos.cn,1718936161,Alexei Starovoitov,ast@kernel.org,1718941364,1b6d9748d6add216e90b6161136506fef998c3ba,bbca57aa378b43d25af2ec360b3e8bc4185d65cf,"selftests/bpf: Drop noconnect from network_helper_opts

In test_bpf_ip_check_defrag_ok()"," the new helper client_socket() can be
used to replace connect_to_fd_opts() with ""noconnect"" opts","[' and the strcut\nmember ""noconnect"" of network_helper_opts can be dropped now', ' always\nconnect to server in connect_to_fd_opts().\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nLink: https://lore.kernel.org/r/f45760becce51986e4e08283c7df0f933eb0da14.1718932493.git.tanggeliang@kylinos.cn\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit removes 'noconnect' option from network_helper_opts in selftests/bpf.,"noconnect, network_helper_opts, selftests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
bbca57aa378b43d25af2ec360b3e8bc4185d65cf,bbca57aa378b43d25af2ec360b3e8bc4185d65cf,Geliang Tang,tanggeliang@kylinos.cn,1718936160,Alexei Starovoitov,ast@kernel.org,1718941364,94814a35d74d8f74e43765e3adc758d201a1d9dc,08a5206240d3763e0c6d91a9a4a9bfbb8fc9600c,"selftests/bpf: Add client_socket helper

This patch extracts a new helper client_socket() from connect_to_fd_opts()
to create the client socket"," but don't connect to the server. Then
connect_to_fd_opts() can be implemented using client_socket() and
connect_fd_to_addr(). This helper can be used in connect_to_addr() too","['\nand make ""noconnect"" opts useless.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nLink: https://lore.kernel.org/r/4169c554e1cee79223feea49a1adc459d55e1ffe.1718932493.git.tanggeliang@kylinos.cn\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit introduces a new client_socket helper function for socket management in selftests/bpf.,"helper, client_socket, selftests",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
08a5206240d3763e0c6d91a9a4a9bfbb8fc9600c,08a5206240d3763e0c6d91a9a4a9bfbb8fc9600c,Geliang Tang,tanggeliang@kylinos.cn,1718936159,Alexei Starovoitov,ast@kernel.org,1718941364,0cb06f343cabfca290a85b0a8efb4abb7791db0c,34ad6ec972525b903d4680202d7b8360f71d0d89,"selftests/bpf: Use connect_to_addr in connect_to_fd_opt

This patch moves ""post_socket_cb"" and ""noconnect"" into connect_to_addr()","
then connect_to_fd_opts() can be implemented by getsockname() and
connect_to_addr(). This change makes connect_to_* interfaces more unified.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/4569c30533e14c22fae6c05070aad809720551c1.1718932493.git.tanggeliang@kylinos.cn
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],"The commit unifies the connect_to_fd_opts and connect_to_addr interfaces in selftests/bpf by moving ""post_socket_cb"" and ""noconnect"" into connect_to_addr.","selftests,bpf,connect_to_addr",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
34ad6ec972525b903d4680202d7b8360f71d0d89,34ad6ec972525b903d4680202d7b8360f71d0d89,Geliang Tang,tanggeliang@kylinos.cn,1718936158,Alexei Starovoitov,ast@kernel.org,1718941364,476a2cb04e158fa6be0acc0711d12dd1368a53fb,bf977ee4a9e2ad8a41b3a2497aada5e7eb09eaea,"selftests/bpf: Drop type from network_helper_opts

The opts.{type"," noconnect} is at least a bit non intuitive or unnecessary.
The only use case now is in test_bpf_ip_check_defrag_ok which ends up
bypassing most (or at least some) of the connect_to_fd_opts() logic. It's
much better that test should have its own connect_to_fd_opts() instead.

This patch adds a new ""type"" parameter for connect_to_fd_opts()","[' then\nopts->type and getsockopt(SO_TYPE) can be replaced by ""type"" parameter in\nit.\n\nIn connect_to_fd()', ' use getsockopt(SO_TYPE) to get ""type"" value and pass\nit to connect_to_fd_opts().\n\nIn bpf_tcp_ca.c and cgroup_v1v2.c', ' ""SOCK_STREAM"" types are passed to\nconnect_to_fd_opts()', ' and in ip_check_defrag.c', ' different types ""SOCK_RAW""\nand ""SOCK_DGRAM"" are passed to it.\n\nWith these changes', ' the strcut member ""type"" of network_helper_opts can be\ndropped now.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nLink: https://lore.kernel.org/r/cfd20b5ad4085c1d1af5e79df3b09013a407199f.1718932493.git.tanggeliang@kylinos.cn\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit modifies test logic in connect_to_fd_opts for better functionality separation in selftests/bpf.,"selftests, network_helper_opts, connect_to_fd_opts",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
bf977ee4a9e2ad8a41b3a2497aada5e7eb09eaea,bf977ee4a9e2ad8a41b3a2497aada5e7eb09eaea,Alexei Starovoitov,ast@kernel.org,1718938227,Alexei Starovoitov,ast@kernel.org,1718938233,008909b701e35b7a7c65c468684f2e7ca18235fe,3b06304370931f90cd6f50ea9dd55603429b13dc 21ab4980e02d495174bc64c00ceb4d3cf87fadb1,"Merge branch 'fix-compiler-warnings-looking-for-suggestions'

Rafael Passos says:

====================
Fix compiler warnings"," looking for suggestions

Hi","['\nThis patchset has a few fixes to compiler warnings.\nI am studying the BPF subsystem and wish to bring more tangible contributions.\nI would appreciate receiving suggestions on things to investigate.\nI also documented a bit in my blog. I could help with docs here', ' too.\nhttps://rcpassos.me/post/linux-ebpf-understanding-kernel-level-mechanics\nThanks!\n\nChangelog V1 -> V2:\n- rebased all commits to updated for-next base\n- removes new cases of the extra parameter for bpf_jit_binary_pack_finalize\n- built and tested for ARM64\n- sent the series for the test workflow:\n  https://github.com/kernel-patches/bpf/pull/7198\n====================\n\nAcked-by: Puranjay Mohan <puranjay@kernel.org>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/r/20240615022641.210320-1-rafael@rcpassos.me\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit fixes compiler warnings by merging relevant changes.,"fix,compiler,warnings",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
21ab4980e02d495174bc64c00ceb4d3cf87fadb1,21ab4980e02d495174bc64c00ceb4d3cf87fadb1,Rafael Passos,rafael@rcpassos.me,1718418250,Alexei Starovoitov,ast@kernel.org,1718938226,008909b701e35b7a7c65c468684f2e7ca18235fe,ab224b9ef7c4eaa752752455ea79bd7022209d5d,"bpf: remove redeclaration of new_n in bpf_verifier_vlog

This new_n is defined in the start of this function.
Its value is overwritten by `new_n = min(n"," log->len_total);`
a couple lines before my change","['\nrendering the shadow declaration unnecessary.\n\nSigned-off-by: Rafael Passos <rafael@rcpassos.me>\nLink: https://lore.kernel.org/r/20240615022641.210320-4-rafael@rcpassos.me\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Removed redundant redeclaration of variable new_n in bpf_verifier_vlog function.,"redundant,declaration,bpf_verifier",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ab224b9ef7c4eaa752752455ea79bd7022209d5d,ab224b9ef7c4eaa752752455ea79bd7022209d5d,Rafael Passos,rafael@rcpassos.me,1718418249,Alexei Starovoitov,ast@kernel.org,1718938226,139b0f1b204218f294d7aeff9cc180616095bd2f,9919c5c98cb25dbf7e76aadb9beab55a2a25f830,"bpf: remove unused parameter in __bpf_free_used_btfs

Fixes a compiler warning. The __bpf_free_used_btfs function
was taking an extra unused struct bpf_prog_aux *aux param

Signed-off-by: Rafael Passos <rafael@rcpassos.me>
Link: https://lore.kernel.org/r/20240615022641.210320-3-rafael@rcpassos.me
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Remove unused parameter in __bpf_free_used_btfs function to fix compiler warning.,"unused parameter, compiler warning, bpf",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9919c5c98cb25dbf7e76aadb9beab55a2a25f830,9919c5c98cb25dbf7e76aadb9beab55a2a25f830,Rafael Passos,rafael@rcpassos.me,1718418248,Alexei Starovoitov,ast@kernel.org,1718938226,c399342992d107b9aa03abe120d9950ba635073d,3b06304370931f90cd6f50ea9dd55603429b13dc,"bpf: remove unused parameter in bpf_jit_binary_pack_finalize

Fixes a compiler warning. the bpf_jit_binary_pack_finalize function
was taking an extra bpf_prog parameter that went unused.
This removves it and updates the callers accordingly.

Signed-off-by: Rafael Passos <rafael@rcpassos.me>
Link: https://lore.kernel.org/r/20240615022641.210320-2-rafael@rcpassos.me
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Remove unused parameter from bpf_jit_binary_pack_finalize to fix compiler warning.,"unused parameter, compiler warning, bpf_jit_binary_pack_finalize",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3b06304370931f90cd6f50ea9dd55603429b13dc,3b06304370931f90cd6f50ea9dd55603429b13dc,Alexei Starovoitov,ast@kernel.org,1718938109,Alexei Starovoitov,ast@kernel.org,1718938109,bc2ef689e85ff2ba195560840d0171d8e3629887,f6afdaf72af7583d251bd569ded8d7d1eeb849c2 f663a03c8e35c5156bad073a4a8f5e673d656e3f,"Merge branch 'bpf-verifier-correct-tail_call_reachable-for-bpf-prog'

Leon Hwang says:

====================
bpf"," verifier: Correct tail_call_reachable for bpf prog

It's confusing to inspect 'prog->aux->tail_call_reachable' with drgn[0]","[""\nwhen bpf prog has tail call but 'tail_call_reachable' is false.\n\nThis patch corrects 'tail_call_reachable' when bpf prog has tail call.\n\nTherefore"", "" it's unnecessary to detect tail call in x86 jit. Let's remove\nit.\n\nChanges:\nv1 -> v2:\n* Address comment from Yonghong:\n  * Remove unnecessary tail call detection in x86 jit.\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\n---\n\nLinks:\n[0] https://github.com/osandov/drgn\n====================\n\nLink: https://lore.kernel.org/r/20240610124224.34673-1-hffilwlqm@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Merge branch to correct tail_call_reachable for BPF programs.,"merge, verifier, tail_call_reachable",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f663a03c8e35c5156bad073a4a8f5e673d656e3f,f663a03c8e35c5156bad073a4a8f5e673d656e3f,Leon Hwang,hffilwlqm@gmail.com,1718023344,Alexei Starovoitov,ast@kernel.org,1718938109,bc2ef689e85ff2ba195560840d0171d8e3629887,01793ed86b5d7df1e956520b5474940743eb7ed8,bpf," x64: Remove tail call detection

As 'prog->aux->tail_call_reachable' is correct for tail call present","[""\nit's unnecessary to detect tail call in x86 jit.\n\nTherefore"", "" let's remove it.\n\nSigned-off-by: Leon Hwang <hffilwlqm@gmail.com>\nLink: https://lore.kernel.org/r/20240610124224.34673-3-hffilwlqm@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']","The commit removes tail call detection from x64, relying on prog->aux->tail_call_reachable.","tail call detection, x64, prog->aux->tail_call_reachable",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
01793ed86b5d7df1e956520b5474940743eb7ed8,01793ed86b5d7df1e956520b5474940743eb7ed8,Leon Hwang,hffilwlqm@gmail.com,1718023343,Alexei Starovoitov,ast@kernel.org,1718938109,5bb94d5dd2a14c8b1eae910e77505e039c80880a,f6afdaf72af7583d251bd569ded8d7d1eeb849c2,bpf," verifier: Correct tail_call_reachable for bpf prog

It's confusing to inspect 'prog->aux->tail_call_reachable' with drgn[0]","[""\nwhen bpf prog has tail call but 'tail_call_reachable' is false.\n\nThis patch corrects 'tail_call_reachable' when bpf prog has tail call.\n\nSigned-off-by: Leon Hwang <hffilwlqm@gmail.com>\nLink: https://lore.kernel.org/r/20240610124224.34673-2-hffilwlqm@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Corrects faulty 'tail_call_reachable' inspection in eBPF verifier.,"verifier, tail_call_reachable, bpf",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d5a7fc58da039903b332041e8c67daae36f08b50,d5a7fc58da039903b332041e8c67daae36f08b50,Linus Torvalds,torvalds@linux-foundation.org,1718905790,Linus Torvalds,torvalds@linux-foundation.org,1718905790,4b75c04264857a6c4d3e31cd980976be1026127e,042742a1ff1f37ca88c303a9e61afc8c56b23657 fba383985354e83474f95f36d7c65feb75dba19d,"Merge tag 'net-6.10-rc5' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Jakub Kicinski:
 ""Including fixes from wireless"," bpf and netfilter.

  Happy summer solstice! The line count is a bit inflated by a selftest
  and update to a driver's FW interface header","[' in reality this is\n  slightly below average for us. We are expecting one driver fix from\n  Intel', ' but there are no big known issues.\n\n  Current release - regressions:\n\n   - ipv6: bring NLM_DONE out to a separate recv() again\n\n  Current release - new code bugs:\n\n   - wifi: cfg80211: wext: set ssids=NULL for passive scans via old wext API\n\n  Previous releases - regressions:\n\n   - wifi: mac80211: fix monitor channel setting with chanctx emulation\n     (probably most awaited of the fixes in this PR', ' tracked by Thorsten)\n\n   - usb: ax88179_178a: bring back reset on init', ' if PHY is disconnected\n\n   - bpf: fix UML x86_64 compile failure with BPF\n\n   - bpf: avoid splat in pskb_pull_reason()', ' sanity check added can be hit\n     with malicious BPF\n\n   - eth: mvpp2: use slab_build_skb() for packets in slab', ' driver was\n     missed during API refactoring\n\n   - wifi: iwlwifi: add missing unlock of mvm mutex\n\n  Previous releases - always broken:\n\n   - ipv6: add a number of missing null-checks for in6_dev_get()', ' in case\n     IPv6 disabling races with the datapath\n\n   - bpf: fix reg_set_min_max corruption of fake_reg\n\n   - sched: act_ct: add netns as part of the key of tcf_ct_flow_table""\n\n* tag \'net-6.10-rc5\' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (63 commits)\n  net: usb: rtl8150 fix unintiatilzed variables in rtl8150_get_link_ksettings\n  selftests: virtio_net: add forgotten config options\n  bnxt_en: Restore PTP tx_avail count in case of skb_pad() error\n  bnxt_en: Set TSO max segs on devices with limits\n  bnxt_en: Update firmware interface to 1.10.3.44\n  net: stmmac: Assign configured channel value to EXTTS event\n  net: do not leave a dangling sk pointer', "" when socket creation fails\n  net/tcp_ao: Don't leak ao_info on error-path\n  ice: Fix VSI list rule with ICE_SW_LKUP_LAST type\n  ipv6: bring NLM_DONE out to a separate recv() again\n  selftests: add selftest for the SRv6 End.DX6 behavior with netfilter\n  selftests: add selftest for the SRv6 End.DX4 behavior with netfilter\n  netfilter: move the sysctl nf_hooks_lwtunnel into the netfilter core\n  seg6: fix parameter passing when calling NF_HOOK() in End.DX4 and End.DX6 behaviors\n  netfilter: ipset: Fix suspicious rcu_dereference_protected()\n  selftests: openvswitch: Set value to nla flags.\n  octeontx2-pf: Fix linking objects into multiple modules\n  octeontx2-pf: Add error handling to VLAN unoffload handling\n  virtio_net: fixing XDP for fully checksummed packets handling\n  virtio_net: checksum offloading handling fix\n  ...\n"", '']",Merge networking fixes including wireless updates and selftest enhancements.,"networking, wireless, selftest",It's a bug fix.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
6cd4a78d962bebbaf8beb7d2ead3f34120e3f7b2,6cd4a78d962bebbaf8beb7d2ead3f34120e3f7b2,Ignat Korchagin,ignat@cloudflare.com,1718658125,Paolo Abeni,pabeni@redhat.com,1718872994,beb57e0cac5dc8498a2fea20db0c0df7a06e0a34,f9ae848904289ddb16c7c9e4553ed4c64300de49,net: do not leave a dangling sk pointer," when socket creation fails

It is possible to trigger a use-after-free by:
  * attaching an fentry probe to __sock_release() and the probe calling the
    bpf_get_socket_cookie() helper
  * running traceroute -I 1.1.1.1 on a freshly booted VM

A KASAN enabled kernel will log something like below (decoded and stripped):
==================================================================
BUG: KASAN: slab-use-after-free in __sock_gen_cookie (./arch/x86/include/asm/atomic64_64.h:15 ./include/linux/atomic/atomic-arch-fallback.h:2583 ./include/linux/atomic/atomic-instrumented.h:1611 net/core/sock_diag.c:29)
Read of size 8 at addr ffff888007110dd8 by task traceroute/299

CPU: 2 PID: 299 Comm: traceroute Tainted: G            E      6.10.0-rc2+ #2
Hardware name: QEMU Standard PC (i440FX + PIIX","[' 1996)', ' BIOS 1.16.2-debian-1.16.2-1 04/01/2014\nCall Trace:\n <TASK>\ndump_stack_lvl (lib/dump_stack.c:117 (discriminator 1))\nprint_report (mm/kasan/report.c:378 mm/kasan/report.c:488)\n? __sock_gen_cookie (./arch/x86/include/asm/atomic64_64.h:15 ./include/linux/atomic/atomic-arch-fallback.h:2583 ./include/linux/atomic/atomic-instrumented.h:1611 net/core/sock_diag.c:29)\nkasan_report (mm/kasan/report.c:603)\n? __sock_gen_cookie (./arch/x86/include/asm/atomic64_64.h:15 ./include/linux/atomic/atomic-arch-fallback.h:2583 ./include/linux/atomic/atomic-instrumented.h:1611 net/core/sock_diag.c:29)\nkasan_check_range (mm/kasan/generic.c:183 mm/kasan/generic.c:189)\n__sock_gen_cookie (./arch/x86/include/asm/atomic64_64.h:15 ./include/linux/atomic/atomic-arch-fallback.h:2583 ./include/linux/atomic/atomic-instrumented.h:1611 net/core/sock_diag.c:29)\nbpf_get_socket_ptr_cookie (./arch/x86/include/asm/preempt.h:94 ./include/linux/sock_diag.h:42 net/core/filter.c:5094 net/core/filter.c:5092)\nbpf_prog_875642cf11f1d139___sock_release+0x6e/0x8e\nbpf_trampoline_6442506592+0x47/0xaf\n__sock_release (net/socket.c:652)\n__sock_create (net/socket.c:1601)\n...\nAllocated by task 299 on cpu 2 at 78.328492s:\nkasan_save_stack (mm/kasan/common.c:48)\nkasan_save_track (mm/kasan/common.c:68)\n__kasan_slab_alloc (mm/kasan/common.c:312 mm/kasan/common.c:338)\nkmem_cache_alloc_noprof (mm/slub.c:3941 mm/slub.c:4000 mm/slub.c:4007)\nsk_prot_alloc (net/core/sock.c:2075)\nsk_alloc (net/core/sock.c:2134)\ninet_create (net/ipv4/af_inet.c:327 net/ipv4/af_inet.c:252)\n__sock_create (net/socket.c:1572)\n__sys_socket (net/socket.c:1660 net/socket.c:1644 net/socket.c:1706)\n__x64_sys_socket (net/socket.c:1718)\ndo_syscall_64 (arch/x86/entry/common.c:52 arch/x86/entry/common.c:83)\nentry_SYSCALL_64_after_hwframe (arch/x86/entry/entry_64.S:130)\n\nFreed by task 299 on cpu 2 at 78.328502s:\nkasan_save_stack (mm/kasan/common.c:48)\nkasan_save_track (mm/kasan/common.c:68)\nkasan_save_free_info (mm/kasan/generic.c:582)\npoison_slab_object (mm/kasan/common.c:242)\n__kasan_slab_free (mm/kasan/common.c:256)\nkmem_cache_free (mm/slub.c:4437 mm/slub.c:4511)\n__sk_destruct (net/core/sock.c:2117 net/core/sock.c:2208)\ninet_create (net/ipv4/af_inet.c:397 net/ipv4/af_inet.c:252)\n__sock_create (net/socket.c:1572)\n__sys_socket (net/socket.c:1660 net/socket.c:1644 net/socket.c:1706)\n__x64_sys_socket (net/socket.c:1718)\ndo_syscall_64 (arch/x86/entry/common.c:52 arch/x86/entry/common.c:83)\nentry_SYSCALL_64_after_hwframe (arch/x86/entry/entry_64.S:130)\n\nFix this by clearing the struct socket reference in sk_common_release() to cover\nall protocol families create functions', ' which may already attached the\nreference to the sk object with sock_init_data().\n\nFixes: c5dbb89fc2ac (""bpf: Expose bpf_get_socket_cookie to tracing programs"")\nSuggested-by: Kuniyuki Iwashima <kuniyu@amazon.com>\nSigned-off-by: Ignat Korchagin <ignat@cloudflare.com>\nCc: stable@vger.kernel.org\nLink: https://lore.kernel.org/netdev/20240613194047.36478-1-kuniyu@amazon.com/T/\nReviewed-by: Kuniyuki Iwashima <kuniyu@amazon.com>\nReviewed-by: D. Wythe <alibuda@linux.alibaba.com>\nLink: https://lore.kernel.org/r/20240617210205.67311-1-ignat@cloudflare.com\nSigned-off-by: Paolo Abeni <pabeni@redhat.com>\n\n', '']",Fix use-after-free vulnerability related to dangling socket pointer during certain network operations.,"use-after-free,dangling pointer,socket",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['tracepoints like programs']
66b5867150630e8f9c9a2b7430e55a3beaa83a5b,66b5867150630e8f9c9a2b7430e55a3beaa83a5b,Matt Bobrowski,mattbobrowski@google.com,1718632150,Daniel Borkmann,daniel@iogearbox.net,1718724886,45a2e55124ec7e153f5ed13ac32415eb37316ece,b90d77e5fd784ada62ddd714d15ee2400c28e1cf,"bpf: Update BPF LSM maintainer list

After catching up with KP recently"," we discussed that I will be now be
responsible for co-maintaining the BPF LSM. Adding myself as
designated maintainer of the BPF LSM","[' and specifying more files in\nwhich the BPF LSM maintenance responsibilities should now extend out\nto. This is at the back of all the BPF kfuncs that have been added\nrecently', ' which are fundamentally restricted to being used only from\nBPF LSM program types.\n\nSigned-off-by: Matt Bobrowski <mattbobrowski@google.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/ZnA-1qdtXS1TayD7@google.com\n', '']",Added Matt Bobrowski as a co-maintainer for the BPF LSM component.,"BPF LSM, maintainer, update",It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['LSM like programs']
b90d77e5fd784ada62ddd714d15ee2400c28e1cf,b90d77e5fd784ada62ddd714d15ee2400c28e1cf,Alexei Starovoitov,ast@kernel.org,1718644692,Daniel Borkmann,daniel@iogearbox.net,1718723986,9586302ff2733e360769a93f8e73cf34744475c6,bfbcb2c9d2978a28e9f0a77100170dc14fcf7c79,"bpf: Fix remap of arena.

The bpf arena logic didn't account for mremap operation. Add a refcnt for
multiple mmap events to prevent use-after-free in arena_vm_close.

Fixes: 317460317a02 (""bpf: Introduce bpf_arena."")
Reported-by: Pengfei Xu <pengfei.xu@intel.com>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Reviewed-by: Barret Rhoden <brho@google.com>
Tested-by: Pengfei Xu <pengfei.xu@intel.com>
Closes: https://lore.kernel.org/bpf/Zmuw29IhgyPNKnIM@xpf.sh.intel.com
Link: https://lore.kernel.org/bpf/20240617171812.76634-1-alexei.starovoitov@gmail.com
",,Fix use-after-free bug in bpf_arena by adding a refcnt for mremap operations.,"bpf, arena, refcnt",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f6afdaf72af7583d251bd569ded8d7d1eeb849c2,f6afdaf72af7583d251bd569ded8d7d1eeb849c2,Andrii Nakryiko,andrii@kernel.org,1718660312,Andrii Nakryiko,andrii@kernel.org,1718660505,9437b582fa99975de476fa3fec0f3ca0f395a5b9,dedf56d775c0bebbc3003bfb988dddaf0a583c28 6ba77385f386053cea2a1cad33717de74a26db4e,"Merge branch 'bpf-support-resilient-split-btf'

Alan Maguire says:

====================
bpf: support resilient split BTF

Split BPF Type Format (BTF) provides huge advantages in that kernel
modules only have to provide type information for types that they do not
share with the core kernel; for core kernel types"," split BTF refers to
core kernel BTF type ids.  So for a STRUCT sk_buff","[' a module that\nuses that structure (or a pointer to it) simply needs to refer to the\ncore kernel type id', ' saving the need to define the structure and its many\ndependents.  This cuts down on duplication and makes BTF as compact\nas possible.\n\nHowever', ' there is a downside.  This scheme requires the references from\nsplit BTF to base BTF to be valid not just at encoding time', ' but at use\ntime (when the module is loaded).  Even a small change in kernel types\ncan perturb the type ids in core kernel BTF', "" and - if the new reproducible\nBTF option is not used - pahole's parallel processing of compilation units\ncan lead to different type ids for the same kernel if the BTF is\nregenerated.\n\nSo we have a robustness problem for split BTF for cases where a module is\nnot always compiled at the same time as the kernel.  This problem is\nparticularly acute for distros which generally want module builders to be\nable to compile a module for the lifetime of a Linux stable-based release"", '\nand have it continue to be valid over the lifetime of that release', "" even\nas changes in data structures (and hence BTF types) accrue.  Today it's not\npossible to generate BTF for modules that works beyond the initial\nkernel it is compiled against - kernel bugfixes etc invalidate the split\nBTF references to vmlinux BTF"", ' and BTF is no longer usable for the\nmodule.\n\nThe goal of this series is to provide options to provide additional\ncontext for cases like this.  That context comes in the form of\ndistilled base BTF; it stands in for the base BTF', ' and contains\ninformation about the types referenced from split BTF', ' but not their\nfull descriptions.  The modified split BTF will refer to type ids in\nthis .BTF.base section', ' and when the kernel loads such modules it\nwill use that .BTF.base to map references from split BTF to the\nequivalent current vmlinux base BTF types.  Once this relocation\nprocess has succeeded', ' the module BTF available in /sys/kernel/btf\nwill look exactly as if it was built with the current vmlinux;\nreferences to base types will be fixed up etc.\n\nA module builder - using this series along with the pahole changes -\ncan then build a module with distilled base BTF via an out-of-tree\nmodule build', ' i.e.\n\nmake -C . M=path/2/module\n\nThe module will have a .BTF section (the split BTF) and a\n.BTF.base section.  The latter is small in size - distilled base\nBTF does not need full struct/union/enum information for named\ntypes for example.  For 2667 modules built with distilled base BTF', '\nthe average size observed was 1556 bytes (stddev 1563).  The overall\nsize added to this 2667 modules was 5.3Mb.\n\nNote that for the in-tree modules', "" this approach is not needed as\nsplit and base BTF in the case of in-tree modules are always built\nand re-built together.\n\nThe series first focuses on generating split BTF with distilled base\nBTF; then relocation support is added to allow split BTF with\nan associated distlled base to be relocated with a new base BTF.\n\nNext Eduard's patch allows BTF ELF parsing to work with both\n.BTF and .BTF.base sections; this ensures that bpftool will be\nable to dump BTF for a module with a .BTF.base section for example"", '\nor indeed dump relocated BTF where a module and a ""-B vmlinux""\nis supplied.\n\nThen we add support to resolve_btfids to ignore base BTF - i.e.\nto avoid relocation - if a .BTF.base section is found.  This ensures\nthe .BTF.ids section is populated with ids relative to the distilled\nbase (these will be relocated as part of module load).\n\nFinally the series supports storage of .BTF.base data/size in modules\nand supports sharing of relocation code with the kernel to allow\nrelocation of module BTF.  For the kernel', ' this relocation\nprocess happens at module load time', ' and we relocate split BTF\nreferences to point at types in the current vmlinux BTF.  As part of\nthis', ' .BTF.ids references need to be mapped also.\n\nSo concretely', ' what happens is\n\n- we generate split BTF in the .BTF section of a module that refers to\n  types in the .BTF.base section as base types; the latter are not full\n  type descriptions but provide information about the base type.  So\n  a STRUCT sk_buff would be represented as a FWD struct sk_buff in\n  distilled base BTF for example.\n- when the module is loaded', ' the split BTF is relocated with vmlinux\n  BTF; in the case of the FWD struct sk_buff', ' we find the STRUCT sk_buff\n  in vmlinux BTF and map all split BTF references to the distilled base\n  FWD sk_buff', ' replacing them with references to the vmlinux BTF\n  STRUCT sk_buff.\n\nA previous approach to this problem [1] utilized standalone BTF for such\ncases - where the BTF is not defined relative to base BTF so there is no\nrelocation required.  The problem with that approach is that from\nthe verifier perspective', ' some types are special', ' and having a custom\nrepresentation of a core kernel type that did not necessarily match the\ncurrent representation is not tenable.  So the approach taken here was\nto preserve the split BTF model while minimizing the representation of\nthe context needed to relocate split and current vmlinux BTF.\n\nTo generate distilled .BTF.base sections the associated dwarves\npatch (to be applied on the ""next"" branch there) is needed [3]\nWithout it', ' things will still work but modules will not be built\nwith a .BTF.base section.\n\nChanges since v5[4]:\n\n- Update search of distilled types to return the first occurrence\n  of a string (or a string+size pair); this allows us to iterate\n  over all matches in distilled base BTF (Andrii', ' patch 3)\n- Update to use BTF field iterators (Andrii', ' patches 1', ' 3 and 8)\n- Update tests to cover multiple match and associated error cases\n  (Eduard', ' patch 4)\n- Rename elf_sections_info to btf_elf_secs', ' remove use of\n  libbpf_get_error()', ' reset btf->owns_base when relocation\n  succeeds (Andrii', ' patch 5)\n\nChanges since v4[5]:\n\n- Moved embeddedness', ' duplicate name checks to relocation time\n  and record struct/union size for all distilled struct/unions\n  instead of using forwards.  This allows us to carry out\n  type compatibility checks based on the base BTF we want to\n  relocate with (Eduard', ' patches 1', ' 3)\n- Moved to using qsort() instead of qsort_r() as support for\n  qsort_r() appears to be missing in Android libc (Andrii', ' patch 3)\n- Sorting/searching now incorporates size matching depending\n  on BTF kind and embeddedness of struct/union (Eduard', ' Andrii', '\n  patch 3)\n- Improved naming of various types during relocation to avoid\n  confusion (Andrii', "" patch 3)\n- Incorporated Eduard's patch (patch 5) which handles .BTF.base\n  sections internally in btf_parse_elf().  This makes ELF parsing\n  work with split BTF"", ' split BTF with a distilled base', ' split\n  BTF with a distilled base _and_ base BTF (by relocating) etc.\n  Having this avoids the need for bpftool changes; it will work\n  as-is with .BTF.base sections (Eduard', ' patch 4)\n- Updated resolve_btfids to _not_ relocate BTF for modules\n  where a .BTF.base section is present; in that one case we\n  do not want to relocate BTF as the .BTF.ids section should\n  reflect ids in .BTF.base which will later be relocated on\n  module load (Eduard', ' Andrii', ' patch 5)\n\nChanges since v3[6]:\n\n- distill now checks for duplicate-named struct/unions and records\n  them as a sized struct/union to help identify which of the\n  multiple base BTF structs/unions it refers to (Eduard', ' patch 1)\n- added test support for multiple name handling (Eduard', ' patch 2)\n- simplified the string mapping when updating split BTF to use\n  base BTF instead of distilled base.  Since the only string\n  references split BTF can make to base BTF are the names of\n  the base types', ' create a string map from distilled string\n  offset -> base BTF string offset and update string offsets\n  by visiting all strings in split BTF; this saves having to\n  do costly searches of base BTF (Eduard', ' patch 7', '10)\n- fixed bpftool manpage and indentation issues (Quentin', "" patch 11)\n\nAlso explored Eduard's suggestion of doing an implicit fallback\nto checking for .BTF.base section in btf__parse() when it is\ncalled to get base BTF.  However while it is doable"", ' it turned\nout to be difficult operationally.  Since fallback is implicit\nwe do not know the source of the BTF - was it from .BTF or\n.BTF.base? In bpftool', ' we want to try first standalone BTF', '\nthen split', ' then split with distilled base.  Having a way\nto explicitly request .BTF.base via btf__parse_opts() fits\nthat model better.\n\nChanges since v2[7]:\n\n- submitted patch to use --btf_features in Makefile.btf for pahole\n  v1.26 and later separately (Andrii).  That has landed in bpf-next\n  now.\n- distilled base now encodes ENUM64 as fwd ENUM (size 8)', ' eliminating\n  the need for support for ENUM64 in btf__add_fwd (patch 1', ' Andrii)\n- moved to distilling only named types', ' augmenting split BTF with\n  associated reference types; this simplifies greatly the distilled\n  base BTF and the mapping operation between distilled and base\n  BTF when relocating (most of the series changes', ' Andrii)\n- relocation now iterates over base BTF', ' looking for matches based\n  on name in distilled BTF.  Distilled BTF is pre-sorted by name\n  (Andrii', ' patch 8)\n- removed most redundant compabitiliby checks aside from struct\n  size for base types/embedded structs and kind compatibility\n  (since we only match on name) (Andrii', ' patch 8)\n- btf__parse_opts() now replaces btf_parse() internally in libbpf\n  (Eduard', ' patch 3)\n\nChanges since RFC [8]:\n\n- updated terminology; we replace clunky ""base reference"" BTF with\n  distilling base BTF into a .BTF.base section. Similarly BTF\n  reconcilation becomes BTF relocation (Andrii', ' most patches)\n- add distilled base BTF by default for out-of-tree modules\n  (Alexei', ' patch 8)\n- distill algorithm updated to record size of embedded struct/union\n  by recording it as a 0-vlen STRUCT/UNION with size preserved\n  (Andrii', ' patch 2)\n- verify size match on relocation for such STRUCT/UNIONs (Andrii', '\n  patch 9)\n- with embedded STRUCT/UNION recording size', ' we can have bpftool\n  dump a header representation using .BTF.base + .BTF sections\n  rather than special-casing and refusing to use ""format c"" for\n  that case (patch 5)\n- match enum with enum64 and vice versa (Andrii', ' patch 9)\n- ensure that resolve_btfids works with BTF without .BTF.base\n  section (patch 7)\n- update tests to cover embedded types', ' arrays and function\n  prototypes (patches 3', ' 12)\n\n[1] https://lore.kernel.org/bpf/20231112124834.388735-14-alan.maguire@oracle.com/\n[2] https://lore.kernel.org/bpf/20240501175035.2476830-1-alan.maguire@oracle.com/\n[3] https://lore.kernel.org/bpf/20240517102714.4072080-1-alan.maguire@oracle.com/\n[4] https://lore.kernel.org/bpf/20240528122408.3154936-1-alan.maguire@oracle.com/\n[5] https://lore.kernel.org/bpf/20240517102246.4070184-1-alan.maguire@oracle.com/\n[6] https://lore.kernel.org/bpf/20240510103052.850012-1-alan.maguire@oracle.com/\n[7] https://lore.kernel.org/bpf/20240424154806.3417662-1-alan.maguire@oracle.com/\n[8] https://lore.kernel.org/bpf/20240322102455.98558-1-alan.maguire@oracle.com/\n====================\n\nLink: https://lore.kernel.org/r/20240613095014.357981-1-alan.maguire@oracle.com\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n', '']",The commit adds support for resilient split BPF Type Format (BTF) to improve kernel module type handling.,"resilient,BTF,kernel",It's a new feature.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6ba77385f386053cea2a1cad33717de74a26db4e,6ba77385f386053cea2a1cad33717de74a26db4e,Alan Maguire,alan.maguire@oracle.com,1718272211,Andrii Nakryiko,andrii@kernel.org,1718660311,9437b582fa99975de476fa3fec0f3ca0f395a5b9,c86f180ffc993975fed5907a869fc9b1555d0cfb,"resolve_btfids: Handle presence of .BTF.base section

Now that btf_parse_elf() handles .BTF.base section presence","
we need to ensure that resolve_btfids uses .BTF.base when present
rather than the vmlinux base BTF passed in via the -B option.
Detect .BTF.base section presence and unset the base BTF path
to ensure that BTF ELF parsing will do the right thing.

Signed-off-by: Alan Maguire <alan.maguire@oracle.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Reviewed-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/bpf/20240613095014.357981-7-alan.maguire@oracle.com
",[''],This commit ensures resolve_btfids uses the .BTF.base section when present for BTF ELF parsing.,"BTF base, resolve_btfids, BTF ELF parsing",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c86f180ffc993975fed5907a869fc9b1555d0cfb,c86f180ffc993975fed5907a869fc9b1555d0cfb,Eduard Zingerman,eddyz87@gmail.com,1718272210,Andrii Nakryiko,andrii@kernel.org,1718660311,1c5545c9dc0b385fc326588e4f247f6ba830cc8f,affdeb50616b190c3236cc2bf116e1b931a43be2,"libbpf: Make btf_parse_elf process .BTF.base transparently

Update btf_parse_elf() to check if .BTF.base section is present.
The logic is as follows:

  if .BTF.base section exists:
     distilled_base := btf_new(.BTF.base)
  if distilled_base:
     btf := btf_new(.BTF"," .base_btf=distilled_base)
     if base_btf:
        btf_relocate(btf","[' base_btf)\n  else:\n     btf := btf_new(.BTF)\n  return btf\n\nIn other words:\n- if .BTF.base section exists', ' load BTF from it and use it as a base\n  for .BTF load;\n- if base_btf is specified and .BTF.base section exist', ' relocate newly\n  loaded .BTF against base_btf.\n\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Alan Maguire <alan.maguire@oracle.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240613095014.357981-6-alan.maguire@oracle.com\n', '']",Enhance libbpf to handle .BTF.base section transparently in btf_parse_elf function.,"libbpf,BTF,parse_elf",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
affdeb50616b190c3236cc2bf116e1b931a43be2,affdeb50616b190c3236cc2bf116e1b931a43be2,Alan Maguire,alan.maguire@oracle.com,1718272209,Andrii Nakryiko,andrii@kernel.org,1718660311,65d78d11e30778924acbc175b3d463cfebe6bcc5,19e00c897d5031bed969dd79af28e899e038009f,"selftests/bpf: Extend distilled BTF tests to cover BTF relocation

Ensure relocated BTF looks as expected; in this case identical to
original split BTF"," with a few duplicate anonymous types added to
split BTF by the relocation process.  Also add relocation tests
for edge cases like missing type in base BTF and multiple types
of the same name.

Signed-off-by: Alan Maguire <alan.maguire@oracle.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/bpf/20240613095014.357981-5-alan.maguire@oracle.com
",[''],"Extend selftests for BPF to cover BTF relocation scenarios, ensuring consistency with original BTF.","BTF,relocation,selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
19e00c897d5031bed969dd79af28e899e038009f,19e00c897d5031bed969dd79af28e899e038009f,Alan Maguire,alan.maguire@oracle.com,1718272208,Andrii Nakryiko,andrii@kernel.org,1718660311,8860aa5eba5bd79594bd6cc5b68d25c82c72d8d6,eb20e727c4343ad591cff2bef243590c77f62cf1,"libbpf: Split BTF relocation

Map distilled base BTF type ids referenced in split BTF and their
references to the base BTF passed in", and if the mapping succeeds,"['\nreparent the split BTF to the base BTF.\n\nRelocation is done by first verifying that distilled base BTF\nonly consists of named INT', ' FLOAT', ' ENUM', ' FWD', ' STRUCT and\nUNION kinds; then we sort these to speed lookups.  Once sorted', '\nthe base BTF is iterated', ' and for each relevant kind we check\nfor an equivalent in distilled base BTF.  When found', ' the\nmapping from distilled -> base BTF id and string offset is recorded.\nIn establishing mappings', ' we need to ensure we check STRUCT/UNION\nsize when the STRUCT/UNION is embedded in a split BTF STRUCT/UNION', '\nand when duplicate names exist for the same STRUCT/UNION.  Otherwise\nsize is ignored in matching STRUCT/UNIONs.\n\nOnce all mappings are established', ' we can update type ids\nand string offsets in split BTF and reparent it to the new base.\n\nSigned-off-by: Alan Maguire <alan.maguire@oracle.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/bpf/20240613095014.357981-4-alan.maguire@oracle.com\n', '']",The commit refactors BTF relocation to map base BTF type ids in libbpf.,"BTF, libbpf, relocation",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
eb20e727c4343ad591cff2bef243590c77f62cf1,eb20e727c4343ad591cff2bef243590c77f62cf1,Alan Maguire,alan.maguire@oracle.com,1718272207,Andrii Nakryiko,andrii@kernel.org,1718660311,3c4518971b73f7cdf688f0e5a0d3476df233c964,58e185a0dc359a6c1c9eff348d7badfc9f722159,selftests/bpf: Test distilled base," split BTF generation

Test generation of split+distilled base BTF","[' ensuring that\n\n- named base BTF STRUCTs and UNIONs are represented as 0-vlen sized\n  STRUCT/UNIONs\n- named ENUM[64]s are represented as 0-vlen named ENUM[64]s\n- anonymous struct/unions are represented in full in split BTF\n- anonymous enums are represented in full in split BTF\n- types unreferenced from split BTF are not present in distilled\n  base BTF\n\nAlso test that with vmlinux BTF and split BTF based upon it', '\nwe only represent needed base types referenced from split BTF\nin distilled base.\n\nSigned-off-by: Alan Maguire <alan.maguire@oracle.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/bpf/20240613095014.357981-3-alan.maguire@oracle.com\n', '']",Test case added for generating split and distilled base BTF.,"selftests, BPF, BTF",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
58e185a0dc359a6c1c9eff348d7badfc9f722159,58e185a0dc359a6c1c9eff348d7badfc9f722159,Alan Maguire,alan.maguire@oracle.com,1718272206,Andrii Nakryiko,andrii@kernel.org,1718660311,06e55723ae41eb944249ec516d4fbebc2e6b65ed,dedf56d775c0bebbc3003bfb988dddaf0a583c28,"libbpf: Add btf__distill_base() creating split BTF with distilled base BTF

To support more robust split BTF"," adding supplemental context for the
base BTF type ids that split BTF refers to is required.  Without such
references","[' a simple shuffling of base BTF type ids (without any other\nsignificant change) invalidates the split BTF.  Here the attempt is made\nto store additional context to make split BTF more robust.\n\nThis context comes in the form of distilled base BTF providing minimal\ninformation (name and - in some cases - size) for base INTs', ' FLOATs', '\nSTRUCTs', ' UNIONs', ' ENUMs and ENUM64s along with modified split BTF that\npoints at that base and contains any additional types needed (such as\nTYPEDEF', ' PTR and anonymous STRUCT/UNION declarations).  This\ninformation constitutes the minimal BTF representation needed to\ndisambiguate or remove split BTF references to base BTF.  The rules\nare as follows:\n\n- INT', ' FLOAT', ' FWD are recorded in full.\n- if a named base BTF STRUCT or UNION is referred to from split BTF', ' it\n  will be encoded as a zero-member sized STRUCT/UNION (preserving\n  size for later relocation checks).  Only base BTF STRUCT/UNIONs\n  that are either embedded in split BTF STRUCT/UNIONs or that have\n  multiple STRUCT/UNION instances of the same name will _need_ size\n  checks at relocation time', ' but as it is possible a different set of\n  types will be duplicates in the later to-be-resolved base BTF', '\n  we preserve size information for all named STRUCT/UNIONs.\n- if an ENUM[64] is named', ' a ENUM forward representation (an ENUM\n  with no values) of the same size is used.\n- in all other cases', ' the type is added to the new split BTF.\n\nAvoiding struct/union/enum/enum64 expansion is important to keep the\ndistilled base BTF representation to a minimum size.\n\nWhen successful', ' new representations of the distilled base BTF and new\nsplit BTF that refers to it are returned.  Both need to be freed by the\ncaller.\n\nSo to take a simple example', ' with split BTF with a type referring\nto ""struct sk_buff""', ' we will generate distilled base BTF with a\n0-member STRUCT sk_buff of the appropriate size', ' and the split BTF\nwill refer to it instead.\n\nTools like pahole can utilize such split BTF to populate the .BTF\nsection (split BTF) and an additional .BTF.base section.  Then\nwhen the split BTF is loaded', ' the distilled base BTF can be used\nto relocate split BTF to reference the current (and possibly changed)\nbase BTF.\n\nSo for example if ""struct sk_buff"" was id 502 when the split BTF was\noriginally generated', '  we can use the distilled base BTF to see that\nid 502 refers to a ""struct sk_buff"" and replace instances of id 502\nwith the current (relocated) base BTF sk_buff type id.\n\nDistilled base BTF is small; when building a kernel with all modules\nusing distilled base BTF as a test', ' overall module size grew by only\n5.3Mb total across ~2700 modules.\n\nSigned-off-by: Alan Maguire <alan.maguire@oracle.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/bpf/20240613095014.357981-2-alan.maguire@oracle.com\n', '']",The commit introduces a new function btf__distill_base() to handle split BTF with distilled base BTF.,"libbpf, split, BTF",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
bfbcb2c9d2978a28e9f0a77100170dc14fcf7c79,bfbcb2c9d2978a28e9f0a77100170dc14fcf7c79,Alexei Starovoitov,ast@kernel.org,1718646347,Alexei Starovoitov,ast@kernel.org,1718646356,9bf05bfc8d552c7b5dff0f0698c96f25cf90009a,143492fce36161402fa2f45a0756de7ff69c366a a62293c33b058415237c55058a6d20de313a2e61,"Merge branch 'bpf-fix-missed-var_off-related-to-movsx-in-verifier'

Yonghong Song says:

====================
bpf: Fix missed var_off related to movsx in verifier

Zac reported a verification issue ([1]) where verification unexpectedly succeeded.
This is due to missing proper var_off setting in verifier related to
movsx insn. I found another similar issue as well. This patch set fixed
both problems and added three inline asm tests to test these fixes.

  [1] https://lore.kernel.org/bpf/CAADnVQLPU0Shz7dWV4bn2BgtGdxN3uFHPeobGBA72tpg5Xoykw@mail.gmail.com/
====================

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20240615174621.3994321-1-yonghong.song@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,This commit fixes a missed var_off issue related to movsx in the eBPF verifier and adds inline asm tests.,"fix, var_off, verifier",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a62293c33b058415237c55058a6d20de313a2e61,a62293c33b058415237c55058a6d20de313a2e61,Yonghong Song,yonghong.song@linux.dev,1718473597,Alexei Starovoitov,ast@kernel.org,1718646347,9bf05bfc8d552c7b5dff0f0698c96f25cf90009a,44b7f7151dfc2e0947f39ed4b9bc4b0c2ccd46fc,"selftests/bpf: Add a few tests to cover

Add three unit tests in verifier_movsx.c to cover
cases where missed var_off setting can cause
unexpected verification success or failure.

Signed-off-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20240615174637.3995589-1-yonghong.song@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add three unit tests in verifier_movsx.c to improve eBPF verifier coverage.,"unit tests, verifier, coverage",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
44b7f7151dfc2e0947f39ed4b9bc4b0c2ccd46fc,44b7f7151dfc2e0947f39ed4b9bc4b0c2ccd46fc,Yonghong Song,yonghong.song@linux.dev,1718473592,Alexei Starovoitov,ast@kernel.org,1718646346,0181cb307f55d367de032b260c53859c130d17aa,380d5f89a4815ff88461a45de2fb6f28533df708,"bpf: Add missed var_off setting in coerce_subreg_to_size_sx()

In coerce_subreg_to_size_sx()"," for the case where upper
sign extension bits are the same for smax32 and smin32
values","["" we missed to setup properly. This is especially\nproblematic if both smax32 and smin32's sign extension\nbits are 1.\n\nThe following is a simple example illustrating the inconsistent\nverifier states due to missed var_off:\n\n  0: (85) call bpf_get_prandom_u32#7    ; R0_w=scalar()\n  1: (bf) r3 = r0                       ; R0_w=scalar(id=1) R3_w=scalar(id=1)\n  2: (57) r3 &= 15                      ; R3_w=scalar(smin=smin32=0"", 'smax=umax=smax32=umax32=15', 'var_off=(0x0; 0xf))\n  3: (47) r3 |= 128                     ; R3_w=scalar(smin=umin=smin32=umin32=128', 'smax=umax=smax32=umax32=143', 'var_off=(0x80; 0xf))\n  4: (bc) w7 = (s8)w3\n  REG INVARIANTS VIOLATION (alu): range bounds violation u64=[0xffffff80', ' 0x8f] s64=[0xffffff80', ' 0x8f]\n    u32=[0xffffff80', ' 0x8f] s32=[0x80', ' 0xffffff8f] var_off=(0x80', ' 0xf)\n\nThe var_off=(0x80', ' 0xf) is not correct', ' and the correct one should\nbe var_off=(0xffffff80; 0xf) since from insn 3', ' we know that at\ninsn 4', ' the sign extension bits will be 1. This patch fixed this\nissue by setting var_off properly.\n\nFixes: 8100928c8814 (""bpf: Support new sign-extension mov insns"")\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240615174632.3995278-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit adds missing var_off setting in the coerce_subreg_to_size_sx() function for sign extension bits handling.,"var_off, sign extension, coerce_subreg_to_size_sx",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
380d5f89a4815ff88461a45de2fb6f28533df708,380d5f89a4815ff88461a45de2fb6f28533df708,Yonghong Song,yonghong.song@linux.dev,1718473586,Alexei Starovoitov,ast@kernel.org,1718646346,8fc35376dd61e36911dc5b5e03d5d791900c4432,143492fce36161402fa2f45a0756de7ff69c366a,"bpf: Add missed var_off setting in set_sext32_default_val()

Zac reported a verification failure and Alexei reproduced the issue
with a simple reproducer ([1]). The verification failure is due to missed
setting for var_off.

The following is the reproducer in [1]:
  0: R1=ctx() R10=fp0
  0: (71) r3 = *(u8 *)(r10 -387)        ;
     R3_w=scalar(smin=smin32=0",smax=umax=smax32=umax32=255,"['var_off=(0x0; 0xff)) R10=fp0\n  1: (bc) w7 = (s8)w3                   ;\n     R3_w=scalar(smin=smin32=0', 'smax=umax=smax32=umax32=255', 'var_off=(0x0; 0xff))\n     R7_w=scalar(smin=smin32=0', 'smax=umax=smax32=umax32=127', 'var_off=(0x0; 0x7f))\n  2: (36) if w7 >= 0x2533823b goto pc-3\n     mark_precise: frame0: last_idx 2 first_idx 0 subseq_idx -1\n     mark_precise: frame0: regs=r7 stack= before 1: (bc) w7 = (s8)w3\n     mark_precise: frame0: regs=r3 stack= before 0: (71) r3 = *(u8 *)(r10 -387)\n  2: R7_w=scalar(smin=smin32=0', 'smax=umax=smax32=umax32=127', 'var_off=(0x0; 0x7f))\n  3: (b4) w0 = 0                        ; R0_w=0\n  4: (95) exit\n\nNote that after insn 1', ' the var_off for R7 is (0x0; 0x7f). This is not correct\nsince upper 24 bits of w7 could be 0 or 1. So correct var_off should be\n(0x0; 0xffffffff). Missing var_off setting in set_sext32_default_val() caused later\nincorrect analysis in zext_32_to_64(dst_reg) and reg_bounds_sync(dst_reg).\n\nTo fix the issue', ' set var_off correctly in set_sext32_default_val(). The correct\nreg state after insn 1 becomes:\n  1: (bc) w7 = (s8)w3                   ;\n     R3_w=scalar(smin=smin32=0', 'smax=umax=smax32=umax32=255', 'var_off=(0x0; 0xff))\n     R7_w=scalar(smin=0', 'smax=umax=0xffffffff', 'smin32=-128', 'smax32=127', 'var_off=(0x0; 0xffffffff))\nand at insn 2', ' the verifier correctly determines either branch is possible.\n\n  [1] https://lore.kernel.org/bpf/CAADnVQLPU0Shz7dWV4bn2BgtGdxN3uFHPeobGBA72tpg5Xoykw@mail.gmail.com/\n\nFixes: 8100928c8814 (""bpf: Support new sign-extension mov insns"")\nReported-by: Zac Ecob <zacecob@protonmail.com>\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240615174626.3994813-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes a verification failure by adding a missed var_off setting in set_sext32_default_val function.,"verification, var_off, sext32",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4314175af49668ab20c0d60d7d7657986e1d0c7c,4314175af49668ab20c0d60d7d7657986e1d0c7c,David S. Miller,davem@davemloft.net,1718626449,David S. Miller,davem@davemloft.net,1718626449,d2648151ef19251c559aa1f6a6790b7759d08d50,f22b4b55edb507a2b30981e133b66b642be4d13f d25a92ccae6bed02327b63d138e12e7806830f78,"Merge branch 'net-smc-IPPROTO_SMC'

D. Wythe says:

====================
Introduce IPPROTO_SMC

This patch allows to create smc socket via AF_INET","
similar to the following code","['\n\n/* create v4 smc sock */\nv4 = socket(AF_INET', ' SOCK_STREAM', ' IPPROTO_SMC);\n\n/* create v6 smc sock */\nv6 = socket(AF_INET6', ' SOCK_STREAM', ' IPPROTO_SMC);\n\nThere are several reasons why we believe it is appropriate here:\n\n1. For smc sockets', ' it actually use IPv4 (AF-INET) or IPv6 (AF-INET6)\naddress. There is no AF_SMC address at all.\n\n2. Create smc socket in the AF_INET(6) path', ' which allows us to reuse\nthe infrastructure of AF_INET(6) path', ' such as common ebpf hooks.\nOtherwise', ' smc have to implement it again in AF_SMC path. Such as:\n  1. Replace IPPROTO_TCP with IPPROTO_SMC in the socket() syscall\n     initiated by the user', "" without the use of LD-PRELOAD.\n  2. Select whether immediate fallback is required based on peer's port/ip\n     before connect().\n\nA very significant result is that we can now use eBPF to implement smc_run\ninstead of LD_PRELOAD"", ' who is completely ineffective in scenarios of static\nlinking.\n\nAnother potential value is that we are attempting to optimize the\nperformance of fallback socks', ' where merging socks is an important part', '\nand it relies on the creation of SMC sockets under the AF_INET path.\n(More information :\nhttps://lore.kernel.org/netdev/1699442703-25015-1-git-send-email-alibuda@linux.alibaba.com/T/)\n\nv2 -> v1:\n\n- Code formatting', ' mainly including alignment and annotation repair.\n- move inet_smc proto ops to inet_smc.c', "" avoiding af_smc.c becoming too bulky.\n- Fix the issue where refactoring affects the initialization order.\n- Fix compile warning (unused out_inet_prot) while CONFIG_IPV6 was not set.\n\nv3 -> v2:\n\n- Add Alibaba's copyright information to the newfile\n\nv4 -> v3:\n\n- Fix some spelling errors\n- Align function naming style with smc_sock_init() to smc_sk_init()\n- Reversing the order of the conditional checks on clcsock to make the code more intuitive\n\nv5 -> v4:\n\n- Fix some spelling errors\n- Added comment"", ' ""/* CONFIG_IPV6 */""', ' after the final #endif directive.\n- Rename smc_inet.h and smc_inet.c to smc_inet.h and smc_inet.c\n- Encapsulate the initialization and destruction of inet_smc in inet_smc.c', '\n  rather than implementing it directly in af_smc.c.\n- Remove useless header files in smc_inet.h\n- Make smc_inet_prot_xxx and smc_inet_sock_init() to be static', "" since it's\n  only used in smc_inet.c\n\nv6 -> v5:\n\n- Wrapping lines to not exceed 80 characters\n- Combine initialization and error handling of smc_inet6 into the same #if\n  macro block.\n\nv7 -> v6:\n\n- Modify the value of IPPROTO_SMC to 256 so that it does not affect IPPROTO-MAX\n\nv8 -> v7:\n\n- Remove useless declarations.\n====================\n\nSigned-off-by: David S. Miller <davem@davemloft.net>\n"", '']",This commit introduces new support for creating sockets using the IPPROTO_SMC protocol in the AF_INET socket family.,"IPPROTO_SMC, smc socket, AF_INET",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['socket like programs']
d25a92ccae6bed02327b63d138e12e7806830f78,d25a92ccae6bed02327b63d138e12e7806830f78,D. Wythe,alibuda@linux.alibaba.com,1718301630,David S. Miller,davem@davemloft.net,1718626449,d2648151ef19251c559aa1f6a6790b7759d08d50,13543d02c90d6195b31bef8fb51dfeff77c0b368,"net/smc: Introduce IPPROTO_SMC

This patch allows to create smc socket via AF_INET","
similar to the following code","['\n\n/* create v4 smc sock */\nv4 = socket(AF_INET', ' SOCK_STREAM', ' IPPROTO_SMC);\n\n/* create v6 smc sock */\nv6 = socket(AF_INET6', ' SOCK_STREAM', ' IPPROTO_SMC);\n\nThere are several reasons why we believe it is appropriate here:\n\n1. For smc sockets', ' it actually use IPv4 (AF-INET) or IPv6 (AF-INET6)\naddress. There is no AF_SMC address at all.\n\n2. Create smc socket in the AF_INET(6) path', ' which allows us to reuse\nthe infrastructure of AF_INET(6) path', ' such as common ebpf hooks.\nOtherwise', ' smc have to implement it again in AF_SMC path.\n\nSigned-off-by: D. Wythe <alibuda@linux.alibaba.com>\nReviewed-by: Wenjia Zhang <wenjia@linux.ibm.com>\nReviewed-by: Dust Li <dust.li@linux.alibaba.com>\nTested-by: Niklas Schnelle <schnelle@linux.ibm.com>\nTested-by: Wenjia Zhang <wenjia@linux.ibm.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>\n', '']",This commit introduces IPPROTO_SMC to allow creating smc sockets via AF_INET.,"IPPROTO_SMC, smc, socket",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The syscall interface,['socket like programs']
c64da10adb57a135bf91e32202d7077931472533,c64da10adb57a135bf91e32202d7077931472533,Jakub Kicinski,kuba@kernel.org,1718413029,Jakub Kicinski,kuba@kernel.org,1718413030,4d3efb826a4d9f36357d01b725f7a2cbf0b6af99,1afe4a64379f65e7bd0c841e6ba7adf312b4c928 7bdcedd5c8fb88e7176b93812b139eca5fe0aa46,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Daniel Borkmann says:

====================
pull-request: bpf 2024-06-14

We've added 8 non-merge commits during the last 2 day(s) which contain
a total of 9 files changed", 92 insertions(+),"[' 11 deletions(-).\n\nThe main changes are:\n\n1) Silence a syzkaller splat under CONFIG_DEBUG_NET=y in pskb_pull_reason()\n   triggered via __bpf_try_make_writable()', ' from Florian Westphal.\n\n2) Fix removal of kfuncs during linking phase which then throws a kernel\n   build warning via resolve_btfids about unresolved symbols', '\n   from Tony Ambardar.\n\n3) Fix a UML x86_64 compilation failure from BPF as pcpu_hot symbol\n   is not available on User Mode Linux', ' from Maciej Żenczykowski.\n\n4) Fix a register corruption in reg_set_min_max triggering an invariant\n   violation in BPF verifier', "" from Daniel Borkmann.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  bpf: Harden __bpf_kfunc tag against linker kfunc removal\n  compiler_types.h: Define __retain for __attribute__((__retain__))\n  bpf: Avoid splat in pskb_pull_reason\n  bpf: fix UML x86_64 compile failure\n  selftests/bpf: Add test coverage for reg_set_min_max handling\n  bpf: Reduce stack consumption in check_stack_write_fixed_off\n  bpf: Fix reg_set_min_max corruption of fake_reg\n  MAINTAINERS: mailmap: Update Stanislav's email address\n====================\n\nLink: https://lore.kernel.org/r/20240614203223.26500-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n"", '']","Merge tag for-netdev from BPF repository, incorporating 8 non-merge commits affecting 9 files.","merge, non-merge, netdev",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
dedf56d775c0bebbc3003bfb988dddaf0a583c28,dedf56d775c0bebbc3003bfb988dddaf0a583c28,Alexei Starovoitov,ast@kernel.org,1718242695,Daniel Borkmann,daniel@iogearbox.net,1718394760,9b5db9431d4b9630956715796a7e1d7f9bfb255c,6870bdb3f4f2991193449f9de57109b3e263f55c,"selftests/bpf: Add tests for add_const

Improve arena based tests and add several C and asm tests
with specific pattern.
These tests would have failed without add_const verifier support.

Also add several loop_inside_iter*() tests that are not related to add_const","
but nice to have.

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240613013815.953-5-alexei.starovoitov@gmail.com
",[''],Add and improve eBPF selftests for the add_const verifier feature.,"selftests, add_const, verifier",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6870bdb3f4f2991193449f9de57109b3e263f55c,6870bdb3f4f2991193449f9de57109b3e263f55c,Alexei Starovoitov,ast@kernel.org,1718242694,Daniel Borkmann,daniel@iogearbox.net,1718394760,e7bc6dbe46f4e6c89ec64f572250d2856e63a8a4,98d7ca374ba4b39e7535613d40e159f09ca14da2,"bpf: Support can_loop/cond_break on big endian

Add big endian support for can_loop/cond_break macros.

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/bpf/20240613013815.953-4-alexei.starovoitov@gmail.com
",,Add support for can_loop and cond_break macros on big endian systems.,"big endian,can_loop,cond_break",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
98d7ca374ba4b39e7535613d40e159f09ca14da2,98d7ca374ba4b39e7535613d40e159f09ca14da2,Alexei Starovoitov,ast@kernel.org,1718242693,Daniel Borkmann,daniel@iogearbox.net,1718394759,cc45a92aa7645787141a5f250bc085c9f815fbc3,124e8c2b1b5d08a10d3a44ed082eaaf98a78c91f,"bpf: Track delta between ""linked"" registers.

Compilers can generate the code
  r1 = r2
  r1 += 0x1
  if r2 < 1000 goto ...
  use knowledge of r2 range in subsequent r1 operations

So remember constant delta between r2 and r1 and update r1 after 'if' condition.

Unfortunately LLVM still uses this pattern for loops with 'can_loop' construct:
for (i = 0; i < 1000 && can_loop; i++)

The ""undo"" pass was introduced in LLVM
https://reviews.llvm.org/D121937
to prevent this optimization"," but it cannot cover all cases.
Instead of fighting middle end optimizer in BPF backend teach the verifier
about this pattern.

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/bpf/20240613013815.953-3-alexei.starovoitov@gmail.com
",[''],The commit teaches the eBPF verifier to track the delta between linked registers for improved optimization handling.,"delta, verifier, registers",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
124e8c2b1b5d08a10d3a44ed082eaaf98a78c91f,124e8c2b1b5d08a10d3a44ed082eaaf98a78c91f,Alexei Starovoitov,ast@kernel.org,1718242692,Daniel Borkmann,daniel@iogearbox.net,1718394759,294b18099b8d97eb02a0fb9dd45c59700fee1496,cdbde084d163835ef41cabb59be2292bb0421c51,"bpf: Relax tuple len requirement for sk helpers.

__bpf_skc_lookup() safely handles incorrect values of tuple len","
hence we can allow zero to be passed as tuple len.
This patch alone doesn't make an observable verifier difference.
It's a trivial improvement that might simplify bpf programs.

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/bpf/20240613013815.953-2-alexei.starovoitov@gmail.com
",[''],The commit relaxes tuple length requirements in bpf_skc_lookup for sk helpers to simplify BPF programs.,"bpf, tuple len, sk helpers",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,['socket like programs']
7bdcedd5c8fb88e7176b93812b139eca5fe0aa46,7bdcedd5c8fb88e7176b93812b139eca5fe0aa46,Tony Ambardar,tony.ambardar@gmail.com,1717478596,Daniel Borkmann,daniel@iogearbox.net,1718385277,a6028bf51cb9f40bb981dc9e59b5c6ea3fcd0d9a,0a5d3258d7c97295a89d22e54733b54aacb62562,"bpf: Harden __bpf_kfunc tag against linker kfunc removal

BPF kfuncs are often not directly referenced and may be inadvertently
removed by optimization steps during kernel builds"," thus the __bpf_kfunc
tag mitigates against this removal by including the __used macro. However","['\nthis macro alone does not prevent removal during linking', ' and may still\nyield build warnings (e.g. on mips64el):\n\n  [...]\n    LD      vmlinux\n    BTFIDS  vmlinux\n  WARN: resolve_btfids: unresolved symbol bpf_verify_pkcs7_signature\n  WARN: resolve_btfids: unresolved symbol bpf_lookup_user_key\n  WARN: resolve_btfids: unresolved symbol bpf_lookup_system_key\n  WARN: resolve_btfids: unresolved symbol bpf_key_put\n  WARN: resolve_btfids: unresolved symbol bpf_iter_task_next\n  WARN: resolve_btfids: unresolved symbol bpf_iter_css_task_new\n  WARN: resolve_btfids: unresolved symbol bpf_get_file_xattr\n  WARN: resolve_btfids: unresolved symbol bpf_ct_insert_entry\n  WARN: resolve_btfids: unresolved symbol bpf_cgroup_release\n  WARN: resolve_btfids: unresolved symbol bpf_cgroup_from_id\n  WARN: resolve_btfids: unresolved symbol bpf_cgroup_acquire\n  WARN: resolve_btfids: unresolved symbol bpf_arena_free_pages\n    NM      System.map\n    SORTTAB vmlinux\n    OBJCOPY vmlinux.32\n  [...]\n\nUpdate the __bpf_kfunc tag to better guard against linker optimization by\nincluding the new __retain compiler macro', "" which fixes the warnings above.\n\nVerify the __retain macro with readelf by checking object flags for 'R':\n\n  $ readelf -Wa kernel/trace/bpf_trace.o\n  Section Headers:\n    [Nr]  Name              Type     Address  Off  Size ES Flg Lk Inf Al\n  [...]\n    [178] .text.bpf_key_put PROGBITS 00000000 6420 0050 00 AXR  0   0  8\n  [...]\n  Key to Flags:\n  [...]\n    R (retain)"", ' D (mbind)', ' p (processor specific)\n\nFixes: 57e7c169cd6a (""bpf: Add __bpf_kfunc tag for marking kernel functions as kfuncs"")\nReported-by: kernel test robot <lkp@intel.com>\nSigned-off-by: Tony Ambardar <tony.ambardar@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Jiri Olsa <jolsa@kernel.org>\nReviewed-by: Jiri Olsa <jolsa@kernel.org>\nCc: Yonghong Song <yonghong.song@linux.dev>\nCloses: https://lore.kernel.org/r/202401211357.OCX9yllM-lkp@intel.com/\nLink: https://lore.kernel.org/bpf/ZlmGoT9KiYLZd91S@krava/T/\nLink: https://lore.kernel.org/bpf/e9c64e9b5c073dabd457ff45128aabcab7630098.1717477560.git.Tony.Ambardar@gmail.com\n', '']",The commit hardens the __bpf_kfunc tag to prevent linker from removing BPF kfuncs during kernel build optimization.,"bpf, kfunc, linker",It's a security fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0a5d3258d7c97295a89d22e54733b54aacb62562,0a5d3258d7c97295a89d22e54733b54aacb62562,Tony Ambardar,tony.ambardar@gmail.com,1717478595,Daniel Borkmann,daniel@iogearbox.net,1718384912,2744d65b1abe2e175a49763c8108941dd93fc0f0,2bbe3e5a2f4ef69d13be54f1cf895b4658287080,"compiler_types.h: Define __retain for __attribute__((__retain__))

Some code includes the __used macro to prevent functions and data from
being optimized out. This macro implements __attribute__((__used__))","
which operates at the compiler and IR-level","[' and so still allows a linker\nto remove objects intended to be kept.\n\nCompilers supporting __attribute__((__retain__)) can address this gap by\nsetting the flag SHF_GNU_RETAIN on the section of a function/variable', '\nindicating to the linker the object should be retained. This attribute is\navailable since gcc 11', ' clang 13', ' and binutils 2.36.\n\nProvide a __retain macro implementing __attribute__((__retain__))', "" whose\nfirst user will be the '__bpf_kfunc' tag.\n\n[ Additional remark from discussion:\n\n  Why is CONFIG_LTO_CLANG added here? The __used macro permits garbage\n  collection at section level"", ' so CLANG_LTO_CLANG without\n  CONFIG_LD_DEAD_CODE_DATA_ELIMINATION should not change final section\n  dynamics?\n\n  The conditional guard was included to ensure consistent behaviour\n  between __retain and other features forcing split sections. In\n  particular', ' the same guard is used in vmlinux.lds.h to merge split\n  sections where needed. For example', "" using __retain in LLVM builds\n  without CONFIG_LTO was failing CI tests on kernel-patches/bpf because\n  the kernel didn't boot properly. And in further testing"", ' the kernel\n  had no issues loading BPF kfunc modules with such split sections', ' so\n  the module (partial) linking scripts were left alone. ]\n\nSigned-off-by: Tony Ambardar <tony.ambardar@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nCc: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/bpf/ZlmGoT9KiYLZd91S@krava/T/\nLink: https://lore.kernel.org/bpf/b31bca5a5e6765a0f32cc8c19b1d9cdbfaa822b5.1717477560.git.Tony.Ambardar@gmail.com\n', '']",The commit defines a new __retain macro using __attribute__ to enhance compiler-level function and data retention.,"macro, attribute, retain",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
2bbe3e5a2f4ef69d13be54f1cf895b4658287080,2bbe3e5a2f4ef69d13be54f1cf895b4658287080,Florian Westphal,fw@strlen.de,1718360253,Daniel Borkmann,daniel@iogearbox.net,1718378421,2ab765d06c6c3bf045064400f5a3636e81ae429a,b99a95bc56c52a428befbce12d9451fd7a0f3bc2,"bpf: Avoid splat in pskb_pull_reason

syzkaller builds (CONFIG_DEBUG_NET=y) frequently trigger a debug
hint in pskb_may_pull.

We'd like to retain this debug check because it might hint at integer
overflows and other issues (kernel code should pull headers"," not huge
value).

In bpf case","[' this splat isn\'t interesting at all: such (nonsensical)\nbpf programs are typically generated by a fuzzer anyway.\n\nDo what Eric suggested and suppress such warning.\n\nFor CONFIG_DEBUG_NET=n we don\'t need the extra check because\npskb_may_pull will do the right thing: return an error without the\nWARN() backtrace.\n\nFixes: 219eee9c0d16 (""net: skbuff: add overflow debug check to pull/push helpers"")\nReported-by: syzbot+0c4150bff9fff3bf023c@syzkaller.appspotmail.com\nSuggested-by: Eric Dumazet <edumazet@google.com>\nSigned-off-by: Florian Westphal <fw@strlen.de>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Eric Dumazet <edumazet@google.com>\nAcked-by: Daniel Borkmann <daniel@iogearbox.net>\nCloses: https://syzkaller.appspot.com/bug?extid=0c4150bff9fff3bf023c\nLink: https://lore.kernel.org/netdev/9f254c96-54f2-4457-b7ab-1d9f6187939c@gmail.com/\nLink: https://lore.kernel.org/bpf/20240614101801.9496-1-fw@strlen.de\n', '']",The commit addresses a debug issue in pskb_may_pull to prevent potential integer overflows when pull headers in BPF.,"debug, pskb_may_pull, integer overflows",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
33c0fb85b571b0f1bbdbf466e770eebeb29e6f41,33c0fb85b571b0f1bbdbf466e770eebeb29e6f41,Benjamin Tissoires,bentiss@kernel.org,1717837288,Benjamin Tissoires,bentiss@kernel.org,1718356821,4d2d1fff9618dca4a64f23d3b8e93858207c89da,f1a5fb6c7cf637e991cedc799e1470e01e148669,"HID: bpf: make part of struct hid_device writable

It is useful to change the name"," the phys and/or the uniq of a
struct hid_device during .rdesc_fixup().

For example","[' hid-uclogic.ko changes the uniq to store the firmware version\nto differentiate between 2 devices sharing the same PID. In the same\nway', ' changing the device name is useful when the device export 3 nodes', '\nall with the same name.\n\nLink: https://lore.kernel.org/r/20240608-hid_bpf_struct_ops-v3-16-6ac6ade58329@kernel.org\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']",The commit makes part of the struct hid_device writable in the BPF subsystem.,"HID, struct, writable",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['HID driver like programs']
f1a5fb6c7cf637e991cedc799e1470e01e148669,f1a5fb6c7cf637e991cedc799e1470e01e148669,Benjamin Tissoires,bentiss@kernel.org,1717837287,Benjamin Tissoires,bentiss@kernel.org,1718356821,58469a8d1b6e90b4af524c3b50a0ea0ebc758299,bd0747543b3d973df6af0f43965f58965375d524,"HID: bpf: rework hid_bpf_ops_btf_struct_access

The idea is to provide a list of stucts and their editable fields.

Currently no functional changes are introduced here"," we will add some
more writeable fields in the next patch.

Acked-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/r/20240608-hid_bpf_struct_ops-v3-15-6ac6ade58329@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Rework hid_bpf_ops_btf_struct_access to list structs and editable fields without functional changes.,"HID,BPF,structs",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['HID driver like programs']
bd0747543b3d973df6af0f43965f58965375d524,bd0747543b3d973df6af0f43965f58965375d524,Benjamin Tissoires,bentiss@kernel.org,1717837286,Benjamin Tissoires,bentiss@kernel.org,1718356821,dfa704245a5d770dc2f89881ffc3b65c289a71ed,c94ae2189acac38b01be60e3b878605fb328782c,"bpf: allow bpf helpers to be used into HID-BPF struct_ops

Without this helpers like bpf_printk() or bpf_map_update() are not
available"," making anything but change of bytes impossible to do.

Link: https://lore.kernel.org/r/20240608-hid_bpf_struct_ops-v3-14-6ac6ade58329@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Enable bpf helpers within HID-BPF struct_ops to access functions like bpf_printk or bpf_map_update.,"bpf helpers,HID-BPF,struct_ops",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['HID driver like programs']
c94ae2189acac38b01be60e3b878605fb328782c,c94ae2189acac38b01be60e3b878605fb328782c,Benjamin Tissoires,bentiss@kernel.org,1717837285,Benjamin Tissoires,bentiss@kernel.org,1718356820,db2b5d3594fa3f8af7f76d41b71795402d32e129,26ba1e0a982b9efe8b121d7e41dae4fdf118b048,"HID: bpf: error on warnings when compiling bpf objects

There is no real reasons to paper over warnings for such small programs.

Link: https://lore.kernel.org/r/20240608-hid_bpf_struct_ops-v3-13-6ac6ade58329@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",,This commit ensures BPF object compilation errors on warnings for HID programs.,"HID,BPF,compilation",It's a build system or CI/CD change.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['HID driver like programs']
26ba1e0a982b9efe8b121d7e41dae4fdf118b048,26ba1e0a982b9efe8b121d7e41dae4fdf118b048,Benjamin Tissoires,bentiss@kernel.org,1717837284,Benjamin Tissoires,bentiss@kernel.org,1718356820,f22a5e8303c5126f7ef310bb2f1e034a3552c204,5f42e19de53faf9e6d4455638f75b7c3a3f8d58f,"HID: bpf: Artist24: remove unused variable

warning: unused variable ‘tilt’ [-Wunused-variable]

Signed-off-by: Peter Hutterer <peter.hutterer@who-t.net>
Link: https://lore.kernel.org/r/20240608-hid_bpf_struct_ops-v3-12-6ac6ade58329@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",,Remove unused variable 'tilt' from HID bpf code.,"remove, unused, variable",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['HID driver like programs']
5f42e19de53faf9e6d4455638f75b7c3a3f8d58f,5f42e19de53faf9e6d4455638f75b7c3a3f8d58f,Benjamin Tissoires,bentiss@kernel.org,1717837283,Benjamin Tissoires,bentiss@kernel.org,1718356820,5bd6b5b9745dc40b6a8736e9885e057794363a33,c5958697a5fa29d3ba9332205a88725afe9ed912,"Documentation: HID: add a small blurb on udev-hid-bpf

This is the current decision we took: we don't provide automatic loading
of HID-BPF by the kernel directly"," but rely on an external tool for it.

This tool is currently udev-hid-bpf","["" so let's make people aware of it.\n\nLink: https://lore.kernel.org/r/20240608-hid_bpf_struct_ops-v3-11-6ac6ade58329@kernel.org\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n"", '']",This commit adds documentation about using udev-hid-bpf for loading HID-BPF programs.,"Documentation,HID-BPF,udev-hid-bpf",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['HID driver like programs']
c5958697a5fa29d3ba9332205a88725afe9ed912,c5958697a5fa29d3ba9332205a88725afe9ed912,Benjamin Tissoires,bentiss@kernel.org,1717837282,Benjamin Tissoires,bentiss@kernel.org,1718356820,a9f3c532361f32d91cbde4b88095db2eb7242a2d,05b3b8f19441b6bf039cec1990de3c75bb9dbbd9,"Documentation: HID: amend HID-BPF for struct_ops

Now that we are using struct_ops"," the docs need to be changed.

Link: https://lore.kernel.org/r/20240608-hid_bpf_struct_ops-v3-10-6ac6ade58329@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],The commit updates HID-BPF documentation to reflect changes involving struct_ops.,"Documentation, HID, struct_ops",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,['HID driver like programs']
05b3b8f19441b6bf039cec1990de3c75bb9dbbd9,05b3b8f19441b6bf039cec1990de3c75bb9dbbd9,Benjamin Tissoires,bentiss@kernel.org,1717837281,Benjamin Tissoires,bentiss@kernel.org,1718356820,997add8797644223073e24dc40a90fe9596161bb,4a86220e046da009bef0948e9f51d1d26d68f93c,"selftests/hid: add subprog call test

I got a weird verifier error with a subprog once"," so let's have a test
for it.

Link: https://lore.kernel.org/r/20240608-hid_bpf_struct_ops-v3-9-6ac6ade58329@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Add a subprogram call test to HID selftests to debug a verifier error.,"HID,selftests,subprog",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['HID driver like programs']
4a86220e046da009bef0948e9f51d1d26d68f93c,4a86220e046da009bef0948e9f51d1d26d68f93c,Benjamin Tissoires,bentiss@kernel.org,1717837280,Benjamin Tissoires,bentiss@kernel.org,1718356820,41e0cf9fdf3c33a3ae99190bc4d3f30702b76c3d,50fe0fc6e206c9b85a0a6cc183ee5513d70179d1,"HID: bpf: remove tracing HID-BPF capability

We can now rely on struct_ops as we cleared the users in-tree.

Link: https://lore.kernel.org/r/20240608-hid_bpf_struct_ops-v3-8-6ac6ade58329@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",,Remove HID-BPF tracing capability using struct_ops after clearing in-tree users.,"HID,BPF,struct_ops",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['HID driver like programs']
50fe0fc6e206c9b85a0a6cc183ee5513d70179d1,50fe0fc6e206c9b85a0a6cc183ee5513d70179d1,Benjamin Tissoires,bentiss@kernel.org,1717837279,Benjamin Tissoires,bentiss@kernel.org,1718356820,9b2def9a362e5a9236497c277f15f9b2d026d921,df67602fb8d5a02e40f37efcf4b5cb958c8ca880,"HID: bpf: convert in-tree fixes into struct_ops

Very mechanical:
- Change HID_BPF_DEVICE_EVENT and HID_BPF_RDESC_FIXUP #defines
- add a matching SEC("".struct_ops.link"")
- in ArtistPro16Gen2 make the 2 functions static and have a new one
  calling them

Link: https://lore.kernel.org/r/20240608-hid_bpf_struct_ops-v3-7-6ac6ade58329@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",,Convert in-tree HID fixes into struct_ops for improved organization and functionality.,"HID, struct_ops, conversion",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['HID driver like programs']
df67602fb8d5a02e40f37efcf4b5cb958c8ca880,df67602fb8d5a02e40f37efcf4b5cb958c8ca880,Benjamin Tissoires,bentiss@kernel.org,1717837278,Benjamin Tissoires,bentiss@kernel.org,1718356820,acc2df23f82dbc013ef9c5559b78e742a28c80d0,e342d6f6f7d82b48c4540b947d8032a3b7b3e6f8,"HID: bpf: add defines for HID-BPF SEC in in-tree bpf fixes

We are going to switch over struct_ops"," so instead of having to manually
replace all fields one by one","["" let's have a common place to change it.\n\nLink: https://lore.kernel.org/r/20240608-hid_bpf_struct_ops-v3-6-6ac6ade58329@kernel.org\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n"", '']",Add defines for HID BPF SEC with in-tree bpf fixes and switch over struct_ops.,"HID, BPF, fixes",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['HID driver like programs']
e342d6f6f7d82b48c4540b947d8032a3b7b3e6f8,e342d6f6f7d82b48c4540b947d8032a3b7b3e6f8,Benjamin Tissoires,bentiss@kernel.org,1717837277,Benjamin Tissoires,bentiss@kernel.org,1718356820,908cb6c954eef7a2dea1012b642e3f88c0ded633,d7696738d66b4f1379fe77eef61cd1047d7f0773,"HID: samples: convert the 2 HID-BPF samples into struct_ops

This is mostly mechanical: attach_prog is dropped"," and
the SEC are converted into struct_ops.

Link: https://lore.kernel.org/r/20240608-hid_bpf_struct_ops-v3-5-6ac6ade58329@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Convert HID-BPF samples into struct_ops to simplify implementations.,"HID,struct_ops,samples",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['HID driver like programs']
d7696738d66b4f1379fe77eef61cd1047d7f0773,d7696738d66b4f1379fe77eef61cd1047d7f0773,Benjamin Tissoires,bentiss@kernel.org,1717837276,Benjamin Tissoires,bentiss@kernel.org,1718356819,afde2de984697a0681c360ef89f4643f86c3e9b8,ebc0d8093e8c97de459615438edefad1a4ac352c,"selftests/hid: convert the hid_bpf selftests with struct_ops

We drop the need for the attach() bpf syscall"," but we need to set up
the hid_id field before calling __load().

The .bpf.c part is mechanical: we create one struct_ops per HID-BPF
program","[' as all the tests are for one program at a time.\n\nLink: https://lore.kernel.org/r/20240608-hid_bpf_struct_ops-v3-4-6ac6ade58329@kernel.org\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']","The commit converts HID-BPF selftests to use struct_ops, removing the need for the attach() BPF syscall and setting up the hid_id field before loading.","hid_bpf,selftests,struct_ops",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['HID driver like programs']
ebc0d8093e8c97de459615438edefad1a4ac352c,ebc0d8093e8c97de459615438edefad1a4ac352c,Benjamin Tissoires,bentiss@kernel.org,1717837275,Benjamin Tissoires,bentiss@kernel.org,1718356816,0777c8ebab5266327d80405b15f034ebc06d4d90,99b40bf8053fa261d368ef78848961c04aa93c74,"HID: bpf: implement HID-BPF through bpf_struct_ops

We do this implementation in several steps to not have the CI failing:
- first (this patch)"," we add struct_ops while keeping the existing infra
  available
- then we change the selftests","[' the examples and the existing in-tree\n  HID-BPF programs\n- then we remove the existing trace points making old HID-BPF obsolete\n\nThere are a few advantages of struct_ops over tracing:\n- compatibility with sleepable programs (for hid_hw_raw_request() in\n  a later patch)\n- a lot simpler in the kernel: it\'s a simple rcu protected list\n- we can add more parameters to the function called without much trouble\n- the ""attach"" is now generic through BPF-core: the caller just needs to\n  set hid_id and flags before calling __load().\n- all the BPF tough part is not handled in BPF-core through generic\n  processing\n- hid_bpf_ctx is now only writable where it needs be\n\nAcked-by: Alexei Starovoitov <ast@kernel.org>\nLink: https://lore.kernel.org/r/20240608-hid_bpf_struct_ops-v3-3-6ac6ade58329@kernel.org\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']",Implement HID-BPF support using bpf_struct_ops while maintaining existing infrastructure.,"HIDBPF, bpf_struct_ops, implementation",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['HID driver like programs']
99b40bf8053fa261d368ef78848961c04aa93c74,99b40bf8053fa261d368ef78848961c04aa93c74,Benjamin Tissoires,bentiss@kernel.org,1717837274,Benjamin Tissoires,bentiss@kernel.org,1718356402,5e6b5554dc545c8432c6e8aab223a6cfdc16c966,146a06a0d225cae240065233fd168fb0b95a10ff,"HID: bpf: add hid_get/put_device() helpers

no code change"," but this way we reduce code duplication and we
can export it later.

Link: https://lore.kernel.org/r/20240608-hid_bpf_struct_ops-v3-2-6ac6ade58329@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Add hid_get and hid_put_device helpers to reduce code duplication in HID.,"hid_get, hid_put, helpers",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['HID driver like programs']
146a06a0d225cae240065233fd168fb0b95a10ff,146a06a0d225cae240065233fd168fb0b95a10ff,Benjamin Tissoires,bentiss@kernel.org,1717837273,Benjamin Tissoires,bentiss@kernel.org,1718356402,a4c5f435332cd23107fbee2a5090bc6f6e532992,061d1af7b0305227182bd9da60c7706c079348b7,"HID: rename struct hid_bpf_ops into hid_ops

Those operations are the ones from HID", not HID-BPF,"["" and I'd like to\nreuse hid_bpf_ops as the user facing struct_ops API.\n\nLink: https://lore.kernel.org/r/20240608-hid_bpf_struct_ops-v3-1-6ac6ade58329@kernel.org\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n"", '']",Renamed struct `hid_bpf_ops` to `hid_ops` for improved clarity.,"HID, rename, ops",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['HID driver like programs']
cdbde084d163835ef41cabb59be2292bb0421c51,cdbde084d163835ef41cabb59be2292bb0421c51,Alexei Starovoitov,ast@kernel.org,1718321584,Alexei Starovoitov,ast@kernel.org,1718321585,57df14787c55b7ddfbf0b609138da6a0459cc3e2,373a4e13ab4bc947f429fd92409d686fbec57132 2d45ab1eda469c802728d0a74e1601de5e71c098,"Merge branch 'bpf-make-trusted-args-nullable'

Vadim Fedorenko says:

====================
bpf: make trusted args nullable

Current verifier checks for the arg to be nullable after checking for
certain pointer types. It prevents programs to pass NULL to kfunc args
even if they are marked as nullable. This patchset adjusts verifier and
changes bpf crypto kfuncs to allow null for IV parameter which is
optional for some ciphers. Benchmark shows ~4% improvements when there
is no need to initialise 0-sized dynptr.

v3:
- add special selftest for nullable parameters
v2:
- adjust kdoc accordingly
====================

Link: https://lore.kernel.org/r/20240613211817.1551967-1-vadfed@meta.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Improve the eBPF verifier to allow nullable kfunc arguments for better performance.,"nullable, kfunc, verifier",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2d45ab1eda469c802728d0a74e1601de5e71c098,2d45ab1eda469c802728d0a74e1601de5e71c098,Vadim Fedorenko,vadfed@meta.com,1718313497,Alexei Starovoitov,ast@kernel.org,1718321584,57df14787c55b7ddfbf0b609138da6a0459cc3e2,9b560751f75f7b2484fa22c781be68f4f9fec2b0,"selftests: bpf: add testmod kfunc for nullable params

Add special test to be sure that only __nullable BTF params can be
replaced by NULL. This patch adds fake kfuncs in bpf_testmod to
properly test different params.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Vadim Fedorenko <vadfed@meta.com>
Link: https://lore.kernel.org/r/20240613211817.1551967-6-vadfed@meta.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit adds a bpf_testmod test for nullable BTF parameter handling in kfuncs.,"testmod,nullable,kfunc",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
9b560751f75f7b2484fa22c781be68f4f9fec2b0,9b560751f75f7b2484fa22c781be68f4f9fec2b0,Vadim Fedorenko,vadfed@meta.com,1718313496,Alexei Starovoitov,ast@kernel.org,1718321584,cd895f7a80d7ae3c4ec349ed96f6594382c9a585,9363dc8ddc4e222c4259013ae5428070712910b9,"selftests: bpf: crypto: adjust bench to use nullable IV

The bench shows some improvements"," around 4% faster on decrypt.

Before:

Benchmark 'crypto-decrypt' started.
Iter   0 (325.719us): hits    5.105M/s (  5.105M/prod)","[' drops 0.000M/s', ' total operations    5.105M/s\nIter   1 (-17.295us): hits    5.224M/s (  5.224M/prod)', ' drops 0.000M/s', ' total operations    5.224M/s\nIter   2 (  5.504us): hits    4.630M/s (  4.630M/prod)', ' drops 0.000M/s', ' total operations    4.630M/s\nIter   3 (  9.239us): hits    5.148M/s (  5.148M/prod)', ' drops 0.000M/s', ' total operations    5.148M/s\nIter   4 ( 37.885us): hits    5.198M/s (  5.198M/prod)', ' drops 0.000M/s', ' total operations    5.198M/s\nIter   5 (-53.282us): hits    5.167M/s (  5.167M/prod)', ' drops 0.000M/s', ' total operations    5.167M/s\nIter   6 (-17.809us): hits    5.186M/s (  5.186M/prod)', ' drops 0.000M/s', ' total operations    5.186M/s\nSummary: hits    5.092 ± 0.228M/s (  5.092M/prod)', ' drops    0.000 ±0.000M/s', "" total operations    5.092 ± 0.228M/s\n\nAfter:\n\nBenchmark 'crypto-decrypt' started.\nIter   0 (268.912us): hits    5.312M/s (  5.312M/prod)"", ' drops 0.000M/s', ' total operations    5.312M/s\nIter   1 (124.869us): hits    5.354M/s (  5.354M/prod)', ' drops 0.000M/s', ' total operations    5.354M/s\nIter   2 (-36.801us): hits    5.334M/s (  5.334M/prod)', ' drops 0.000M/s', ' total operations    5.334M/s\nIter   3 (254.628us): hits    5.334M/s (  5.334M/prod)', ' drops 0.000M/s', ' total operations    5.334M/s\nIter   4 (-77.691us): hits    5.275M/s (  5.275M/prod)', ' drops 0.000M/s', ' total operations    5.275M/s\nIter   5 (-164.510us): hits    5.313M/s (  5.313M/prod)', ' drops 0.000M/s', ' total operations    5.313M/s\nIter   6 (-81.376us): hits    5.346M/s (  5.346M/prod)', ' drops 0.000M/s', ' total operations    5.346M/s\nSummary: hits    5.326 ± 0.029M/s (  5.326M/prod)', ' drops    0.000 ±0.000M/s', ' total operations    5.326 ± 0.029M/s\n\nReviewed-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Vadim Fedorenko <vadfed@meta.com>\nLink: https://lore.kernel.org/r/20240613211817.1551967-5-vadfed@meta.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']","The commit adjusts the selftests for bpf crypto to use a nullable IV, resulting in improved decryption performance.","selftests,bpf,crypto",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9363dc8ddc4e222c4259013ae5428070712910b9,9363dc8ddc4e222c4259013ae5428070712910b9,Vadim Fedorenko,vadfed@meta.com,1718313495,Alexei Starovoitov,ast@kernel.org,1718321584,782fcc1137f80989d2d87cc83c33dd15ad6827c9,65d6d61d25968d1f13a478a6f303ed8d6b978a77,"selftests: bpf: crypto: use NULL instead of 0-sized dynptr

Adjust selftests to use nullable option for state and IV arg.

Reviewed-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Vadim Fedorenko <vadfed@meta.com>
Link: https://lore.kernel.org/r/20240613211817.1551967-4-vadfed@meta.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Adjusts selftests to use nullable option for state and IV argument in BPF.,"selftests,bpf,crypto",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
65d6d61d25968d1f13a478a6f303ed8d6b978a77,65d6d61d25968d1f13a478a6f303ed8d6b978a77,Vadim Fedorenko,vadfed@meta.com,1718313494,Alexei Starovoitov,ast@kernel.org,1718321584,da75dcfa04bc84a5b49b0f5088448ea6bd12ebb9,a90797993afcb0eaf6bf47a062ff47eb3810a6d5,"bpf: crypto: make state and IV dynptr nullable

Some ciphers do not require state and IV buffer"," but with current
implementation 0-sized dynptr is always needed. With adjustment to
verifier we can provide NULL instead of 0-sized dynptr. Make crypto
kfuncs ready for this.

Reviewed-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Vadim Fedorenko <vadfed@meta.com>
Link: https://lore.kernel.org/r/20240613211817.1551967-3-vadfed@meta.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],"This commit allows the state and IV dynptr in bpf crypto functions to be nullable, supporting ciphers that don't require them.","crypto,state,dynptr",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a90797993afcb0eaf6bf47a062ff47eb3810a6d5,a90797993afcb0eaf6bf47a062ff47eb3810a6d5,Vadim Fedorenko,vadfed@meta.com,1718313493,Alexei Starovoitov,ast@kernel.org,1718321584,bae52ca95911eef3ebeb75bfa1c4d261737a3c2d,373a4e13ab4bc947f429fd92409d686fbec57132,"bpf: verifier: make kfuncs args nullalble

Some arguments to kfuncs might be NULL in some cases. But currently it's
not possible to pass NULL to any BTF structures because the check for
the suffix is located after all type checks. Move it to earlier place
to allow nullable args.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Vadim Fedorenko <vadfed@meta.com>
Link: https://lore.kernel.org/r/20240613211817.1551967-2-vadfed@meta.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Allow nullable arguments for kfuncs in the BPF verifier by adjusting type check order.,"verifier, kfuncs, nullable",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b99a95bc56c52a428befbce12d9451fd7a0f3bc2,b99a95bc56c52a428befbce12d9451fd7a0f3bc2,Maciej Żenczykowski,maze@google.com,1718299906,Alexei Starovoitov,ast@kernel.org,1718303085,df900cf0e4647c0bf91f3ed7d2c5478e311232c5,ceb65eb60026e03e1028a99f0ec94f22065e722a,"bpf: fix UML x86_64 compile failure

pcpu_hot (defined in arch/x86) is not available on user mode linux (ARCH=um)

Cc: Andrii Nakryiko <andrii@kernel.org>
Cc: John Fastabend <john.fastabend@gmail.com>
Cc: Alexei Starovoitov <ast@kernel.org>
Fixes: 1ae6921009e5 (""bpf: inline bpf_get_smp_processor_id() helper"")
Signed-off-by: Maciej Żenczykowski <maze@google.com>
Link: https://lore.kernel.org/r/20240613173146.2524647-1-maze@google.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Fixes UML x86_64 compilation failure by addressing problem with pcpu_hot not being available.,"UML,x86_64,compile",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6a8260147745fe493d733d4e5f9b327da3720905,6a8260147745fe493d733d4e5f9b327da3720905,Daniel Xu,dxu@dxuuu.xyz,1718295566,Alexei Starovoitov,ast@kernel.org,1718302723,89ef7a194e42de9d31893e5c15d44fa42462654b,78746f93e903d022c692b9bb3a3e2570167b2dc2,"bpf: selftests: Do not use generated kfunc prototypes for arena progs

When selftests are built with a new enough clang"," the arena selftests
opt-in to use LLVM address_space attribute annotations for arena
pointers.

These annotations are not emitted by kfunc prototype generation. This
causes compilation errors when clang sees conflicting prototypes.

Fix by opting arena selftests out of using generated kfunc prototypes.

Fixes: 770abbb5a25a (""bpftool: Support dumping kfunc prototypes from BTF"")
Reported-by: kernel test robot <lkp@intel.com>
Closes: https://lore.kernel.org/r/202406131810.c1B8hTm8-lkp@intel.com/
Signed-off-by: Daniel Xu <dxu@dxuuu.xyz>
Link: https://lore.kernel.org/r/fc59a617439ceea9ad8dfbb4786843c2169496ae.1718295425.git.dxu@dxuuu.xyz
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Fix selftests by opting arena selftests out of generated kfunc prototypes due to conflicting prototypes with LLVM address_space attribute annotations.,"selftests, kfunc prototypes, LLVM",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
78746f93e903d022c692b9bb3a3e2570167b2dc2,78746f93e903d022c692b9bb3a3e2570167b2dc2,Daniel Xu,dxu@dxuuu.xyz,1718295565,Alexei Starovoitov,ast@kernel.org,1718302723,93eebc7dfdda1d2b14177f637ac3e6e89a7e15d1,041c1dc988fdffd5eb0c13f1ce5d1b3b0125f208,"bpf: Fix bpf_dynptr documentation comments

The function argument names were changed but the doc comment was not.
Fix htmldocs build warning by updating doc comments.

Fixes: cce4c40b9606 (""bpf: treewide: Align kfunc signatures to prog point-of-view"")
Signed-off-by: Daniel Xu <dxu@dxuuu.xyz>
Link: https://lore.kernel.org/r/d0b0eb05f91e12e5795966153b11998d3fc1d433.1718295425.git.dxu@dxuuu.xyz
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Fix documentation comment mismatches for bpf_dynptr to resolve htmldocs build warnings.,"documentation, comments, htmldocs",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
ceb65eb60026e03e1028a99f0ec94f22065e722a,ceb65eb60026e03e1028a99f0ec94f22065e722a,Daniel Borkmann,daniel@iogearbox.net,1718279590,Alexei Starovoitov,ast@kernel.org,1718302561,ada58631382c2fa24a0b95f053b5513620b46f19,e73cd1cfc2177654e562b04f514be5f0f0b96da2,"selftests/bpf: Add test coverage for reg_set_min_max handling

Add a test case for the jmp32/k fix to ensure selftests have coverage.

Before fix:

  # ./vmtest.sh -- ./test_progs -t verifier_or_jmp32_k
  [...]
  ./test_progs -t verifier_or_jmp32_k
  tester_init:PASS:tester_log_buf 0 nsec
  process_subtest:PASS:obj_open_mem 0 nsec
  process_subtest:PASS:specs_alloc 0 nsec
  run_subtest:PASS:obj_open_mem 0 nsec
  run_subtest:FAIL:unexpected_load_success unexpected success: 0
  #492/1   verifier_or_jmp32_k/or_jmp32_k: bit ops + branch on unknown value:FAIL
  #492     verifier_or_jmp32_k:FAIL
  Summary: 0/0 PASSED", 0 SKIPPED,"[' 1 FAILED\n\nAfter fix:\n\n  # ./vmtest.sh -- ./test_progs -t verifier_or_jmp32_k\n  [...]\n  ./test_progs -t verifier_or_jmp32_k\n  #492/1   verifier_or_jmp32_k/or_jmp32_k: bit ops + branch on unknown value:OK\n  #492     verifier_or_jmp32_k:OK\n  Summary: 1/1 PASSED', ' 0 SKIPPED', ' 0 FAILED\n\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nLink: https://lore.kernel.org/r/20240613115310.25383-3-daniel@iogearbox.net\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add a test case for verifying reg_set_min_max handling in eBPF selftests.,"test, reg_set_min_max, selftests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tracepoints like programs']
e73cd1cfc2177654e562b04f514be5f0f0b96da2,e73cd1cfc2177654e562b04f514be5f0f0b96da2,Daniel Borkmann,daniel@iogearbox.net,1718279589,Alexei Starovoitov,ast@kernel.org,1718302561,80e9183bca908b2452d45c87141e7b13c33502af,92424801261d1564a0bb759da3cf3ccd69fdf5a2,"bpf: Reduce stack consumption in check_stack_write_fixed_off

The fake_reg moved into env->fake_reg given it consumes a lot of stack
space (120 bytes). Migrate the fake_reg in check_stack_write_fixed_off()
as well now that we have it.

Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/r/20240613115310.25383-2-daniel@iogearbox.net
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Reduced stack space by moving fake_reg to env->fake_reg in check_stack_write_fixed_off.,"stack, fake_reg, consumption",It's a performance optimization.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
92424801261d1564a0bb759da3cf3ccd69fdf5a2,92424801261d1564a0bb759da3cf3ccd69fdf5a2,Daniel Borkmann,daniel@iogearbox.net,1718279588,Alexei Starovoitov,ast@kernel.org,1718302561,654062646ac86c1f6322806b02e95326852c5e3d,26ba7c3f139f843bf46ed0779e30d84641767959,"bpf: Fix reg_set_min_max corruption of fake_reg

Juan reported that after doing some changes to buzzer [0] and implementing
a new fuzzing strategy guided by coverage"," they noticed the following in
one of the probes:

  [...]
  13: (79) r6 = *(u64 *)(r0 +0)         ; R0=map_value(ks=4","['vs=8) R6_w=scalar()\n  14: (b7) r0 = 0                       ; R0_w=0\n  15: (b4) w0 = -1                      ; R0_w=0xffffffff\n  16: (74) w0 >>= 1                     ; R0_w=0x7fffffff\n  17: (5c) w6 &= w0                     ; R0_w=0x7fffffff R6_w=scalar(smin=smin32=0', 'smax=umax=umax32=0x7fffffff', 'var_off=(0x0; 0x7fffffff))\n  18: (44) w6 |= 2                      ; R6_w=scalar(smin=umin=smin32=umin32=2', 'smax=umax=umax32=0x7fffffff', 'var_off=(0x2; 0x7ffffffd))\n  19: (56) if w6 != 0x7ffffffd goto pc+1\n  REG INVARIANTS VIOLATION (true_reg2): range bounds violation u64=[0x7fffffff', ' 0x7ffffffd] s64=[0x7fffffff', ' 0x7ffffffd] u32=[0x7fffffff', ' 0x7ffffffd] s32=[0x7fffffff', ' 0x7ffffffd] var_off=(0x7fffffff', ' 0x0)\n  REG INVARIANTS VIOLATION (false_reg1): range bounds violation u64=[0x7fffffff', ' 0x7ffffffd] s64=[0x7fffffff', ' 0x7ffffffd] u32=[0x7fffffff', ' 0x7ffffffd] s32=[0x7fffffff', ' 0x7ffffffd] var_off=(0x7fffffff', ' 0x0)\n  REG INVARIANTS VIOLATION (false_reg2): const tnum out of sync with range bounds u64=[0x0', ' 0xffffffffffffffff] s64=[0x8000000000000000', ' 0x7fffffffffffffff] u32=[0x0', ' 0xffffffff] s32=[0x80000000', ' 0x7fffffff] var_off=(0x7fffffff', ' 0x0)\n  19: R6_w=0x7fffffff\n  20: (95) exit\n\n  from 19 to 21: R0=0x7fffffff R6=scalar(smin=umin=smin32=umin32=2', 'smax=umax=smax32=umax32=0x7ffffffe', 'var_off=(0x2; 0x7ffffffd)) R7=map_ptr(ks=4', 'vs=8) R9=ctx() R10=fp0 fp-24=map_ptr(ks=4', 'vs=8) fp-40=mmmmmmmm\n  21: R0=0x7fffffff R6=scalar(smin=umin=smin32=umin32=2', 'smax=umax=smax32=umax32=0x7ffffffe', 'var_off=(0x2; 0x7ffffffd)) R7=map_ptr(ks=4', 'vs=8) R9=ctx() R10=fp0 fp-24=map_ptr(ks=4', 'vs=8) fp-40=mmmmmmmm\n  21: (14) w6 -= 2147483632             ; R6_w=scalar(smin=umin=umin32=2', 'smax=umax=0xffffffff', 'smin32=0x80000012', 'smax32=14', 'var_off=(0x2; 0xfffffffd))\n  22: (76) if w6 s>= 0xe goto pc+1      ; R6_w=scalar(smin=umin=umin32=2', 'smax=umax=0xffffffff', 'smin32=0x80000012', 'smax32=13', 'var_off=(0x2; 0xfffffffd))\n  23: (95) exit\n\n  from 22 to 24: R0=0x7fffffff R6_w=14 R7=map_ptr(ks=4', 'vs=8) R9=ctx() R10=fp0 fp-24=map_ptr(ks=4', 'vs=8) fp-40=mmmmmmmm\n  24: R0=0x7fffffff R6_w=14 R7=map_ptr(ks=4', 'vs=8) R9=ctx() R10=fp0 fp-24=map_ptr(ks=4', 'vs=8) fp-40=mmmmmmmm\n  24: (14) w6 -= 14                     ; R6_w=0\n  [...]\n\nWhat can be seen here is a register invariant violation on line 19. After\nthe binary-or in line 18', ' the verifier knows that bit 2 is set but knows\nnothing about the rest of the content which was loaded from a map value', '\nmeaning', ' range is [2', '0x7fffffff] with var_off=(0x2; 0x7ffffffd). When in\nline 19 the verifier analyzes the branch', ' it splits the register states\nin reg_set_min_max() into the registers of the true branch (true_reg1', '\ntrue_reg2) and the registers of the false branch (false_reg1', ' false_reg2).\n\nSince the test is w6 != 0x7ffffffd', ' the src_reg is a known constant.\nInternally', ' the verifier creates a ""fake"" register initialized as scalar\nto the value of 0x7ffffffd', ' and then passes it onto reg_set_min_max(). Now', '\nfor line 19', ' it is mathematically impossible to take the false branch of\nthis program', ' yet the verifier analyzes it. It is impossible because the\nsecond bit of r6 will be set due to the prior or operation and the\nconstant in the condition has that bit unset (hex(fd) == binary(1111 1101).\n\nWhen the verifier first analyzes the false / fall-through branch', ' it will\ncompute an intersection between the var_off of r6 and of the constant. This\nis because the verifier creates a ""fake"" register initialized to the value\nof the constant. The intersection result later refines both registers in\nregs_refine_cond_op():\n\n  [...]\n  t = tnum_intersect(tnum_subreg(reg1->var_off)', ' tnum_subreg(reg2->var_off));\n  reg1->var_off = tnum_with_subreg(reg1->var_off', ' t);\n  reg2->var_off = tnum_with_subreg(reg2->var_off', ' t);\n  [...]\n\nSince the verifier is analyzing the false branch of the conditional jump', '\nreg1 is equal to false_reg1 and reg2 is equal to false_reg2', ' i.e. the reg2\nis the ""fake"" register that was meant to hold a constant value. The resulting\nvar_off of the intersection says that both registers now hold a known value\nof var_off=(0x7fffffff', ' 0x0) or in other words: this operation manages to\nmake the verifier think that the ""constant"" value that was passed in the\njump operation now holds a different value.\n\nNormally this would not be an issue since it should not influence the true\nbranch', ' however', ' false_reg2 and true_reg2 are pointers to the same ""fake""\nregister. Meaning', ' the false branch can influence the results of the true\nbranch. In line 24', ' the verifier assumes R6_w=0', ' but the actual runtime\nvalue in this case is 1. The fix is simply not passing in the same ""fake""\nregister location as inputs to reg_set_min_max()', ' but instead making a\ncopy. Moving the fake_reg into the env also reduces stack consumption by\n120 bytes. With this', ' the verifier successfully rejects invalid accesses\nfrom the test program.\n\n  [0] https://github.com/google/buzzer\n\nFixes: 67420501e868 (""bpf: generalize reg_set_min_max() to handle non-const register comparisons"")\nReported-by: Juan José López Jaimez <jjlopezjaimez@google.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: John Fastabend <john.fastabend@gmail.com>\nLink: https://lore.kernel.org/r/20240613115310.25383-1-daniel@iogearbox.net\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit fixes a corruption issue in reg_set_min_max for fake registers in eBPF.,"reg_set_min_max, corruption, fake_reg",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
041c1dc988fdffd5eb0c13f1ce5d1b3b0125f208,041c1dc988fdffd5eb0c13f1ce5d1b3b0125f208,Vadim Fedorenko,vadfed@meta.com,1717685931,Daniel Borkmann,daniel@iogearbox.net,1718281793,81b6698d112bb09cd4ee9a04c79a397d02110abd,a3cfe84cca28f205761a0450016593b0d728165e,"selftests/bpf: Validate CHECKSUM_COMPLETE option

Adjust skb program test to run with checksum validation.

Signed-off-by: Vadim Fedorenko <vadfed@meta.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240606145851.229116-2-vadfed@meta.com
",,Add checksum validation to skb program selftest in bpf.,"checksum, skb, selftest",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
a3cfe84cca28f205761a0450016593b0d728165e,a3cfe84cca28f205761a0450016593b0d728165e,Vadim Fedorenko,vadfed@meta.com,1717685930,Daniel Borkmann,daniel@iogearbox.net,1718281787,15b374e2476950553d60dc612cf7709bc1fc40d1,4ff5747158f323939e2ce8881ca61f3c646948c4,"bpf: Add CHECKSUM_COMPLETE to bpf test progs

Add special flag to validate that TC BPF program properly updates
checksum information in skb.

Signed-off-by: Vadim Fedorenko <vadfed@meta.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Reviewed-by: Jakub Kicinski <kuba@kernel.org>
Acked-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240606145851.229116-1-vadfed@meta.com
",,Add CHECKSUM_COMPLETE flag to test TC BPF program's checksum updates in skb.,"CHECKSUM_COMPLETE, TC, skb",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tc/netfilter like programs']
d2675fe95fc7e880aecad2d08626131527e084a6,d2675fe95fc7e880aecad2d08626131527e084a6,Jakub Kicinski,kuba@kernel.org,1718228042,Jakub Kicinski,kuba@kernel.org,1718228043,75f6dda28ad47e21ce91e564a90e198ffad5b409,91579c93a9b207725559e3199870419afd50220f d1dab4f71d372e00e2d34a9c32bf261623e3a95c,"Merge branch 'net-flow-dissector-allow-explicit-passing-of-netns'

Florian Westphal says:

====================
net: flow dissector: allow explicit passing of netns

Change since last version:
 fix kdoc comment warning reported by kbuild robot", no other changes,"['\n thus retaining RvB tags from Eric and Willem.\n v1: https://lore.kernel.org/netdev/20240607083205.3000-1-fw@strlen.de/\n\nYears ago flow dissector gained ability to delegate flow dissection\nto a bpf program', ' scoped per netns.\n\nThe netns is derived from skb->dev', ' and if that is not available', ' from\nskb->sk.  If neither is set', ' we hit a (benign) WARN_ON_ONCE().\n\nThis WARN_ON_ONCE can be triggered from netfilter.\nKnown skb origins are nf_send_reset and ipv4 stack generated IGMP\nmessages.\n\nLets allow callers to pass the current netns explicitly and make\nnf_tables use those instead.\n\nThis targets net-next instead of net because the WARN is benign and this\nis not a regression.\n====================\n\nLink: https://lore.kernel.org/r/20240608221057.16070-1-fw@strlen.de\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",The commit merges changes to allow explicit passing of netns in net flow dissector.,"flow,dissector,netns",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
b975d3ee5962237c1e2f5d5aeeaaf0dc2173486c,b975d3ee5962237c1e2f5d5aeeaaf0dc2173486c,Florian Westphal,fw@strlen.de,1717884639,Jakub Kicinski,kuba@kernel.org,1718228018,2f71b19764682e5e8cded567a6c3f193033401d3,91579c93a9b207725559e3199870419afd50220f,"net: add and use skb_get_hash_net

Years ago flow dissector gained ability to delegate flow dissection
to a bpf program"," scoped per netns.

Unfortunately","[' skb_get_hash() only gets an sk_buff argument instead\nof both net+skb.  This means the flow dissector needs to obtain the\nnetns pointer from somewhere else.\n\nThe netns is derived from skb->dev', ' and if that is not available', ' from\nskb->sk.  If neither is set', ' we hit a (benign) WARN_ON_ONCE().\n\nTrying both dev and sk covers most cases', ' but not all', ' as recently\nreported by Christoph Paasch.\n\nIn case of nf-generated tcp reset', "" both sk and dev are NULL:\n\nWARNING: .. net/core/flow_dissector.c:1104\n skb_flow_dissect_flow_keys include/linux/skbuff.h:1536 [inline]\n skb_get_hash include/linux/skbuff.h:1578 [inline]\n nft_trace_init+0x7d/0x120 net/netfilter/nf_tables_trace.c:320\n nft_do_chain+0xb26/0xb90 net/netfilter/nf_tables_core.c:268\n nft_do_chain_ipv4+0x7a/0xa0 net/netfilter/nft_chain_filter.c:23\n nf_hook_slow+0x57/0x160 net/netfilter/core.c:626\n __ip_local_out+0x21d/0x260 net/ipv4/ip_output.c:118\n ip_local_out+0x26/0x1e0 net/ipv4/ip_output.c:127\n nf_send_reset+0x58c/0x700 net/ipv4/netfilter/nf_reject_ipv4.c:308\n nft_reject_ipv4_eval+0x53/0x90 net/ipv4/netfilter/nft_reject_ipv4.c:30\n [..]\n\nsyzkaller did something like this:\ntable inet filter {\n  chain input {\n    type filter hook input priority filter; policy accept;\n    meta nftrace set 1\n    tcp dport 42 reject with tcp reset\n   }\n   chain output {\n    type filter hook output priority filter; policy accept;\n    # empty chain is enough\n   }\n}\n\n... then sends a tcp packet to port 42.\n\nInitial attempt to simply set skb->dev from nf_reject_ipv4 doesn't cover\nall cases: skbs generated via ipv4 igmp_send_report trigger similar splat.\n\nMoreover"", ' Pablo Neira found that nft_hash.c uses __skb_get_hash_symmetric()\nwhich would trigger same warn splat for such skbs.\n\nLets allow callers to pass the current netns explicitly.\nThe nf_trace infrastructure is adjusted to use the new helper.\n\n__skb_get_hash_symmetric is handled in the next patch.\n\nReported-by: Christoph Paasch <cpaasch@apple.com>\nCloses: https://github.com/multipath-tcp/mptcp_net-next/issues/494\nReviewed-by: Willem de Bruijn <willemb@google.com>\nSigned-off-by: Florian Westphal <fw@strlen.de>\nReviewed-by: Eric Dumazet <edumazet@google.com>\nLink: https://lore.kernel.org/r/20240608221057.16070-2-fw@strlen.de\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",The commit introduces skb_get_hash_net to leverage flow dissection by bpf programs in the network stack.,"flow dissection,bpf program,network",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['tc/netfilter like programs', 'socket like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4ff5747158f323939e2ce8881ca61f3c646948c4,4ff5747158f323939e2ce8881ca61f3c646948c4,Alexei Starovoitov,ast@kernel.org,1718215292,Alexei Starovoitov,ast@kernel.org,1718215292,93fefc8047f6a553b4e4ce76b3a5e5dab71b444d,98b303c9bf05dae932efbd71e18d81f6c64f20d8 770abbb5a25a5b767f1c60ba366aea503728e957,"Merge branch 'bpf-support-dumping-kfunc-prototypes-from-btf'

Daniel Xu says:

====================
bpf: Support dumping kfunc prototypes from BTF

This patchset enables both detecting as well as dumping compilable
prototypes for kfuncs.

The first commit instructs pahole to DECL_TAG kfuncs when available.
This requires v1.27 which was released on 6/11/24. With it"," users will
be able to look at BTF inside vmlinux (or modules) and check if the
kfunc they want is available.

The final commit teaches bpftool how to dump kfunc prototypes. This
is done for developer convenience.

The rest of the commits are fixups to enable selftests to use the
newly dumped kfunc prototypes. With these","[' selftests will regularly\nexercise the newly added codepaths.\n\nTested with and without the required pahole changes:\n\n  * https://github.com/kernel-patches/bpf/pull/7186\n  * https://github.com/kernel-patches/bpf/pull/7187\n\n=== Changelog ===\nFrom v4:\n* Change bpf_session_cookie() return type\n* Only fixup used fentry test kfunc prototypes\n* Extract out projection detection into shared btf_is_projection_of()\n* Fix kernel test robot build warnings about doc comments\n\nFrom v3:\n* Teach selftests to use dumped prototypes\n\nFrom v2:\n* Update Makefile.btf with pahole flag\n* More error checking\n* Output formatting changes\n* Drop already-merged commit\n\nFrom v1:\n* Add __weak annotation\n* Use btf_dump for kfunc prototypes\n* Update kernel bpf_rdonly_cast() signature\n====================\n\nLink: https://lore.kernel.org/r/cover.1718207789.git.dxu@dxuuu.xyz\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit adds support for dumping kfunc prototypes from BTF for developer convenience.,"kfunc, BTF, bpftool",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
770abbb5a25a5b767f1c60ba366aea503728e957,770abbb5a25a5b767f1c60ba366aea503728e957,Daniel Xu,dxu@dxuuu.xyz,1718207916,Alexei Starovoitov,ast@kernel.org,1718215292,93fefc8047f6a553b4e4ce76b3a5e5dab71b444d,c567cba34585514f82600a10587c8813c50e3a7c,"bpftool: Support dumping kfunc prototypes from BTF

This patch enables dumping kfunc prototypes from bpftool. This is useful
b/c with this patch"," end users will no longer have to manually define
kfunc prototypes. For the kernel tree","[' this also means we can optionally\ndrop kfunc prototypes from:\n\n        tools/testing/selftests/bpf/bpf_kfuncs.h\n        tools/testing/selftests/bpf/bpf_experimental.h\n\nExample usage:\n\n        $ make PAHOLE=/home/dxu/dev/pahole/build/pahole -j30 vmlinux\n\n        $ ./tools/bpf/bpftool/bpftool btf dump file ./vmlinux format c | rg ""__ksym;"" | head -3\n        extern void cgroup_rstat_updated(struct cgroup *cgrp', ' int cpu) __weak __ksym;\n        extern void cgroup_rstat_flush(struct cgroup *cgrp) __weak __ksym;\n        extern struct bpf_key *bpf_lookup_user_key(u32 serial', ' u64 flags) __weak __ksym;\n\nSigned-off-by: Daniel Xu <dxu@dxuuu.xyz>\nLink: https://lore.kernel.org/r/bf6c08f9263c4bd9d10a717de95199d766a13f61.1718207789.git.dxu@dxuuu.xyz\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']","This patch enables bpftool to automatically dump kfunc prototypes from BTF, which aids users by eliminating the need for manual definitions.","bpftool, kfunc, BTF",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The bpftool utility,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c567cba34585514f82600a10587c8813c50e3a7c,c567cba34585514f82600a10587c8813c50e3a7c,Daniel Xu,dxu@dxuuu.xyz,1718207915,Alexei Starovoitov,ast@kernel.org,1718215291,0d43674a39aa772526021a94de0a2cd8374e0fdc,f709124dd72fe7a3f6ba7764b2ed145c55c33e47,"bpf: selftests: xfrm: Opt out of using generated kfunc prototypes

The xfrm_info selftest locally defines an aliased type such that folks
with CONFIG_XFRM_INTERFACE=m/n configs can still build the selftests.
See commit aa67961f3243 (""selftests/bpf: Allow building bpf tests with CONFIG_XFRM_INTERFACE=[m|n]"").

Thus"," it is simpler if this selftest opts out of using enerated kfunc
prototypes. The preprocessor macro this commit uses will be introduced
in the final commit.

Signed-off-by: Daniel Xu <dxu@dxuuu.xyz>
Link: https://lore.kernel.org/r/afe0bb1c50487f52542cdd5230c4aef9e36ce250.1718207789.git.dxu@dxuuu.xyz
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Opt out of using generated kfunc prototypes for xfrm selftest to support CONFIG_XFRM_INTERFACE configurations.,"selftests, kfunc, xfrm",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f709124dd72fe7a3f6ba7764b2ed145c55c33e47,f709124dd72fe7a3f6ba7764b2ed145c55c33e47,Daniel Xu,dxu@dxuuu.xyz,1718207914,Alexei Starovoitov,ast@kernel.org,1718215291,beef5a1c581dd1eaedc5b2c27c6869cea236627e,cce4c40b960673f9e020835def310f1e89d3a940,"bpf: selftests: nf: Opt out of using generated kfunc prototypes

The bpf-nf selftests play various games with aliased types such that
folks with CONFIG_NF_CONNTRACK=m/n configs can still build the
selftests. See commits:

1058b6a78db2 (""selftests/bpf: Do not fail build if CONFIG_NF_CONNTRACK=m/n"")
92afc5329a5b (""selftests/bpf: Fix build errors if CONFIG_NF_CONNTRACK=m"")

Thus"," it is simpler if these selftests opt out of using generated kfunc
prototypes. The preprocessor macro this commit uses will be introduced
in the final commit.

Signed-off-by: Daniel Xu <dxu@dxuuu.xyz>
Link: https://lore.kernel.org/r/044a5b10cb3abd0d71cb1c818ee0bfc4a2239332.1718207789.git.dxu@dxuuu.xyz
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The commit allows bpf-nf selftests to opt out of using generated kfunc prototypes for compatibility with different CONFIG_NF_CONNTRACK settings.,"bpf-nf,selftests,kfunc",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
cce4c40b960673f9e020835def310f1e89d3a940,cce4c40b960673f9e020835def310f1e89d3a940,Daniel Xu,dxu@dxuuu.xyz,1718207913,Alexei Starovoitov,ast@kernel.org,1718215291,a468b9c66bcea3e5c796b3f1f7d80cb9fa86ca1b,ec209ad86324de84ef66990f0e9df0851e45e054,"bpf: treewide: Align kfunc signatures to prog point-of-view

Previously"," kfunc declarations in bpf_kfuncs.h (and others) used ""user
facing"" types for kfuncs prototypes while the actual kfunc definitions
used ""kernel facing"" types. More specifically: bpf_dynptr vs
bpf_dynptr_kern","[' __sk_buff vs sk_buff', "" and xdp_md vs xdp_buff.\n\nIt wasn't an issue before"", ' as the verifier allows aliased types.\nHowever', ' since we are now generating kfunc prototypes in vmlinux.h (in\naddition to keeping bpf_kfuncs.h around)', ' this conflict creates\ncompilation errors.\n\nFix this conflict by using ""user facing"" types in kfunc definitions.\nThis results in more casts', ' but otherwise has no additional runtime\ncost.\n\nNote', ' similar to 5b268d1ebcdc (""bpf: Have bpf_rdonly_cast() take a const\npointer"")', ' we also make kfuncs take const arguments where appropriate in\norder to make the kfunc more permissive.\n\nSigned-off-by: Daniel Xu <dxu@dxuuu.xyz>\nLink: https://lore.kernel.org/r/b58346a63a0e66bc9b7504da751b526b0b189a67.1718207789.git.dxu@dxuuu.xyz\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Align kfunc signatures to match the program's point-of-view in eBPF.,"kfunc signatures, alignment, eBPF",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ec209ad86324de84ef66990f0e9df0851e45e054,ec209ad86324de84ef66990f0e9df0851e45e054,Daniel Xu,dxu@dxuuu.xyz,1718207912,Alexei Starovoitov,ast@kernel.org,1718215291,cd5d9b2cf0419b0527efb65f6f88137b98802e08,0ce089cbdc6a393bf9ad04964427852800503a58,"bpf: verifier: Relax caller requirements for kfunc projection type args

Currently"," if a kfunc accepts a projection type as an argument (eg
struct __sk_buff *)","[' the caller must exactly provide exactly the same\ntype with provable provenance.\n\nHowever in practice', ' kfuncs that accept projection types _must_ cast to\nthe underlying type before use b/c projection type layouts are\ncompletely made up. Thus', ' it is ok to relax the verifier rules around\nimplicit conversions.\n\nWe will use this functionality in the next commit when we align kfuncs\nto user-facing types.\n\nSigned-off-by: Daniel Xu <dxu@dxuuu.xyz>\nLink: https://lore.kernel.org/r/e2c025cb09ccfd4af1ec9e18284dc3cecff7514d.1718207789.git.dxu@dxuuu.xyz\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit modifies the eBPF verifier to relax requirements for kfunc projection type arguments.,"verifier, kfunc, projection",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0ce089cbdc6a393bf9ad04964427852800503a58,0ce089cbdc6a393bf9ad04964427852800503a58,Daniel Xu,dxu@dxuuu.xyz,1718207911,Alexei Starovoitov,ast@kernel.org,1718215291,b3348e120fa3f826e7d8945b5b63048018205004,2b8dd87332cd2782b5b3f0c423bd6693e487ed30,"bpf: selftests: Namespace struct_opt callbacks in bpf_dctcp

With generated kfunc prototypes"," the existing callback names will
conflict. Fix by namespacing with a bpf_ prefix.

Signed-off-by: Daniel Xu <dxu@dxuuu.xyz>
Link: https://lore.kernel.org/r/efe7aadad8a054e5aeeba94b1d2e4502eee09d7a.1718207789.git.dxu@dxuuu.xyz
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Namespace struct_opt callbacks in bpf_dctcp with bpf_ prefix to avoid conflicts.,"namespace, callbacks, conflict",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2b8dd87332cd2782b5b3f0c423bd6693e487ed30,2b8dd87332cd2782b5b3f0c423bd6693e487ed30,Daniel Xu,dxu@dxuuu.xyz,1718207910,Alexei Starovoitov,ast@kernel.org,1718215291,0a2fba86be896a371f7e8f39098b7eed0f695b60,ac42f636dc11b2e8d6dea9dd5bb10a39c7bec342,"bpf: Make bpf_session_cookie() kfunc return long *

We will soon be generating kfunc prototypes from BTF. As part of that","
we need to align the manual signatures in bpf_kfuncs.h with the actual
kfunc definitions. There is currently a conflicting signature for
bpf_session_cookie() w.r.t. return type.

The original intent was to return long * and not __u64 *. You can see
evidence of that intent in a3a5113393cc (""selftests/bpf: Add kprobe
session cookie test"").

Fix conflict by changing kfunc definition.

Fixes: 5c919acef851 (""bpf: Add support for kprobe session cookie"")
Signed-off-by: Daniel Xu <dxu@dxuuu.xyz>
Link: https://lore.kernel.org/r/7043e1c251ab33151d6e3830f8ea1902ed2604ac.1718207789.git.dxu@dxuuu.xyz
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Fixes signature conflict by changing bpf_session_cookie() kfunc return type to long *.,"kfunc,long *,signature",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['kprobe/uprobe/ftrace like programs']
ac42f636dc11b2e8d6dea9dd5bb10a39c7bec342,ac42f636dc11b2e8d6dea9dd5bb10a39c7bec342,Daniel Xu,dxu@dxuuu.xyz,1718207909,Alexei Starovoitov,ast@kernel.org,1718215291,94ecb2c00b4d6e4efed2f684420bc0109cdee0b3,89f0b1abac497c47d0851b780abecc756c1e8734,"bpf: selftests: Fix bpf_map_sum_elem_count() kfunc prototype

The prototype in progs/map_percpu_stats.c is not in line with how the
actual kfuncs are defined in kernel/bpf/map_iter.c. This causes
compilation errors when kfunc prototypes are generated from BTF.

Fix by aligning with actual kfunc definitions.

Signed-off-by: Daniel Xu <dxu@dxuuu.xyz>
Link: https://lore.kernel.org/r/0497e11a71472dcb71ada7c90ad691523ae87c3b.1718207789.git.dxu@dxuuu.xyz
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Fix the kfunc prototype for bpf_map_sum_elem_count in eBPF selftests to align with kernel definitions.,"kfunc,prototype,selftests",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
89f0b1abac497c47d0851b780abecc756c1e8734,89f0b1abac497c47d0851b780abecc756c1e8734,Daniel Xu,dxu@dxuuu.xyz,1718207908,Alexei Starovoitov,ast@kernel.org,1718215291,19cb226b6eca78783a58d47c3e60c93b1ad5f926,dff96e4f5078c6c61fc6c36dddf27b124c4318fc,"bpf: selftests: Fix bpf_cpumask_first_zero() kfunc prototype

The prototype in progs/nested_trust_common.h is not in line with how the
actual kfuncs are defined in kernel/bpf/cpumask.c. This causes compilation
errors when kfunc prototypes are generated from BTF.

Fix by aligning with actual kfunc definitions.

Signed-off-by: Daniel Xu <dxu@dxuuu.xyz>
Link: https://lore.kernel.org/r/437936a4e554b02e04566dd6e3f0a5d08370cc8c.1718207789.git.dxu@dxuuu.xyz
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Fixes prototype mismatch for bpf_cpumask_first_zero() in selftests to align with kernel kfunc definitions.,"selftests, prototype, alignment",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
dff96e4f5078c6c61fc6c36dddf27b124c4318fc,dff96e4f5078c6c61fc6c36dddf27b124c4318fc,Daniel Xu,dxu@dxuuu.xyz,1718207907,Alexei Starovoitov,ast@kernel.org,1718215290,1b673dcf56db74184c624870d3c91052bb1fe995,718135f5bd24ec10ff38aa0294a7da0a7b99fa89,"bpf: selftests: Fix fentry test kfunc prototypes

Some prototypes in progs/get_func_ip_test.c were not in line with how the
actual kfuncs are defined in net/bpf/test_run.c. This causes compilation
errors when kfunc prototypes are generated from BTF.

Fix by aligning with actual kfunc definitions.

Also remove two unused prototypes.

Signed-off-by: Daniel Xu <dxu@dxuuu.xyz>
Link: https://lore.kernel.org/r/1e68870e7626b7b9c6420e65076b307fc404a2f0.1718207789.git.dxu@dxuuu.xyz
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Fixed fentry test kfunc prototypes in selftests for correct compilation with BTF.,"fentry,kfunc,BTF",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
718135f5bd24ec10ff38aa0294a7da0a7b99fa89,718135f5bd24ec10ff38aa0294a7da0a7b99fa89,Daniel Xu,dxu@dxuuu.xyz,1718207906,Alexei Starovoitov,ast@kernel.org,1718215290,fac931e21209e0e0bc7bd2021300bf6a32d6377f,ebb79e96f1ea454fbcc8fe27dfe44e751bd74b4b,"bpf: selftests: Fix bpf_iter_task_vma_new() prototype

bpf_iter_task_vma_new() is defined as taking a u64 as its 3rd argument.
u64 is a unsigned long long. bpf_experimental.h was defining the
prototype as unsigned long.

Fix by using __u64.

Signed-off-by: Daniel Xu <dxu@dxuuu.xyz>
Link: https://lore.kernel.org/r/fab4509bfee914f539166a91c3ff41e949f3df30.1718207789.git.dxu@dxuuu.xyz
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Fixes prototype mismatch in bpf_iter_task_vma_new() by correcting the third argument type to __u64.,"prototype,fix,__u64",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ebb79e96f1ea454fbcc8fe27dfe44e751bd74b4b,ebb79e96f1ea454fbcc8fe27dfe44e751bd74b4b,Daniel Xu,dxu@dxuuu.xyz,1718207905,Alexei Starovoitov,ast@kernel.org,1718215290,16c92ae5524f281941806d851448e5a9b01a9146,98b303c9bf05dae932efbd71e18d81f6c64f20d8,"kbuild: bpf: Tell pahole to DECL_TAG kfuncs

With [0]"," pahole can now discover kfuncs and inject DECL_TAG
into BTF. With this commit","[' we will start shipping said DECL_TAGs\nto downstream consumers if pahole supports it.\n\nThis is useful for feature probing kfuncs as well as generating\ncompilable prototypes. This is particularly important as kfuncs\ndo not have stable ABI.\n\n[0]: https://git.kernel.org/pub/scm/devel/pahole/pahole.git/commit/?id=72e88f29c6f7e14201756e65bd66157427a61aaf\n\nSigned-off-by: Daniel Xu <dxu@dxuuu.xyz>\nLink: https://lore.kernel.org/r/324aac5c627bddb80d9968c30df6382846994cc8.1718207789.git.dxu@dxuuu.xyz\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Enable pahole to discover and inject DECL_TAG kfuncs into BTF.,"pahole, kfuncs, BTF",It's a build system or CI/CD change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
bf0baa5bbdc9b99ea081d360f245e5f96e835612,bf0baa5bbdc9b99ea081d360f245e5f96e835612,Puranjay Mohan,puranjay@kernel.org,1714756727,Catalin Marinas,catalin.marinas@arm.com,1718203459,4acac0c94439b1e1feb92caca8521f1d012aabe6,7647e2b109f4d508fcb35bb8089a27c4fdd81f61,"arm64: implement raw_smp_processor_id() using thread_info

Historically"," arm64 implemented raw_smp_processor_id() as a read of
current_thread_info()->cpu. This changed when arm64 moved thread_info into
task struct","[' as at the time CONFIG_THREAD_INFO_IN_TASK made core code use\nthread_struct::cpu for the cpu number', ' and due to header dependencies\nprevented using this in raw_smp_processor_id(). As a workaround', ' we moved to\nusing a percpu variable in commit:\n\n  57c82954e77fa12c (""arm64: make cpu number a percpu variable"")\n\nSince then', ' thread_info::cpu was reintroduced', ' and core code was made to use\nthis in commits:\n\n  001430c1910df65a (""arm64: add CPU field to struct thread_info"")\n  bcf9033e5449bdca (""sched: move CPU field back into thread_info if THREAD_INFO_IN_TASK=y"")\n\nConsequently it is possible to use current_thread_info()->cpu again.\n\nThis decreases the number of emitted instructions like in the following\nexample:\n\nDump of assembler code for function bpf_get_smp_processor_id:\n   0xffff8000802cd608 <+0>:     nop\n   0xffff8000802cd60c <+4>:     nop\n   0xffff8000802cd610 <+8>:     adrp    x0', ' 0xffff800082138000\n   0xffff8000802cd614 <+12>:    mrs     x1', ' tpidr_el1\n   0xffff8000802cd618 <+16>:    add     x0', ' x0', ' #0x8\n   0xffff8000802cd61c <+20>:    ldrsw   x0', ' [x0', ' x1]\n   0xffff8000802cd620 <+24>:    ret\n\nAfter this patch:\n\nDump of assembler code for function bpf_get_smp_processor_id:\n   0xffff8000802c9130 <+0>:     nop\n   0xffff8000802c9134 <+4>:     nop\n   0xffff8000802c9138 <+8>:     mrs     x0', ' sp_el0\n   0xffff8000802c913c <+12>:    ldr     w0', ' [x0', ' #24]\n   0xffff8000802c9140 <+16>:    ret\n\nA microbenchmark[1] was built to measure the performance improvement\nprovided by this change. It calls the following function given number of\ntimes and finds the runtime overhead:\n\nstatic noinline int get_cpu_id(void)\n{\n\treturn smp_processor_id();\n}\n\nRun the benchmark like:\n modprobe smp_processor_id nr_function_calls=1000000000\n\n      +--------------------------+------------------------+\n      |        | Number of Calls |    Time taken          |\n      +--------+-----------------+------------------------+\n      | Before |   1000000000    |   1602888401ns         |\n      +--------+-----------------+------------------------+\n      | After  |   1000000000    |   1206212658ns         |\n      +--------+-----------------+------------------------+\n      |  Difference (decrease)   |   396675743ns (24.74%) |\n      +---------------------------------------------------+\n\nRemove the percpu variable cpu_number as it is used only in\nset_smp_ipi_range() as a dummy variable to be passed to ipi_handler().\nUse irq_stat in place of cpu_number here like arm32.\n\n[1] https://github.com/puranjaymohan/linux/commit/77d3fdd\n\nSigned-off-by: Puranjay Mohan <puranjay@kernel.org>\nAcked-by: Mark Rutland <mark.rutland@arm.com>\nReviewed-by: Stephen Boyd <swboyd@chromium.org>\nLink: https://lore.kernel.org/r/20240503171847.68267-2-puranjay@kernel.org\nSigned-off-by: Catalin Marinas <catalin.marinas@arm.com>\n', '']",The commit implements raw_smp_processor_id using thread_info for the arm64 architecture.,"arm64, raw_smp_processor_id, thread_info",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
7180f8d91fcbf252de572d9ffacc945effed0060,7180f8d91fcbf252de572d9ffacc945effed0060,Mateusz Guzik,mjguzik@gmail.com,1718127502,Christian Brauner,brauner@kernel.org,1718194199,9d9f7d2891edf6d6058f71207c0a778f196d3250,1613e604df0cd359cf2a7fbd9be7a0bcfacfabd0,"vfs: add rcu-based find_inode variants for iget ops

This avoids one inode hash lock acquire in the common case on inode
creation"," in effect significantly reducing contention.

On the stock kernel said lock is typically taken twice:
1. once to check if the inode happens to already be present
2. once to add it to the hash

The back-to-back lock/unlock pattern is known to degrade performance
significantly","[' which is further exacerbated if the hash is heavily\npopulated (long chains to walk', ' extending hold time). Arguably hash\nsizing and hashing algo need to be revisited', "" but that's beyond the\nscope of this patch.\n\nWith the acquire from step 1 eliminated with RCU lookup throughput\nincreases significantly at the scale of 20 cores (benchmark results at\nthe bottom).\n\nSo happens the hash already supports RCU-based operation"", "" but lookups on\ninode insertions didn't take advantage of it.\n\nThis of course has its limits as the global lock is still a bottleneck.\nThere was a patchset posted which introduced fine-grained locking[1] but\nit appears staled. Apart from that doubt was expressed whether a\nhandrolled hash implementation is appropriate to begin with"", ' suggesting\nreplacement with rhashtables. Nobody committed to carrying [1] across\nthe finish line or implementing anything better', "" thus the bandaid below.\n\niget_locked consumers (notably ext4) get away without any changes\nbecause inode comparison method is built-in.\n\niget5_locked consumers pass a custom callback. Since removal of locking\nadds more problems (inode can be changing) it's not safe to assume all\nfilesystems happen to cope.  Thus iget5_locked_rcu gets added"", ' requiring\nmanual conversion of interested filesystems.\n\nIn order to reduce code duplication find_inode and find_inode_fast grow\nan argument indicating whether inode hash lock is held', ' which is passed\ndown in case sleeping is necessary. They always rcu_read_lock', "" which is\nredundant but harmless. Doing it conditionally reduces readability for\nno real gain that I can see. RCU-alike restrictions were already put on\ncallbacks due to the hash spinlock being held.\n\nBenchmarking:\nThere is a real cache-busting workload scanning millions of files in\nparallel (it's a backup appliance)"", ' where the initial lookup is\nguaranteed to fail resulting in the two lock acquires on stock kernel\n(and one with the patch at hand).\n\nImplemented below is a synthetic benchmark providing the same behavior.\n[I shall note the workload is not running on Linux', "" instead it was\ncausing trouble elsewhere. Benchmark below was used while addressing\nsaid problems and was found to adequately represent the real workload.]\n\nTotal real time fluctuates by 1-2s.\n\nWith 20 threads each walking a dedicated 1000 dirs * 1000 files\ndirectory tree to stat(2) on a 32 core + 24GB RAM vm:\n\next4 (needed mkfs.ext4 -N 24000000):\nbefore: 3.77s user 890.90s system 1939% cpu 46.118 total\nafter:  3.24s user 397.73s system 1858% cpu 21.581 total (-53%)\n\nThat's 20 million files to visit"", ' while the machine can only cache about\n15 million at a time (obtained from ext4_inode_cache object count in\n/proc/slabinfo). Since each terminal inode is only visited once per run\nthis amounts to 0% hit ratio for the dentry cache and the hash table\n(there are however hits for the intermediate directories).\n\nOn repeated runs the kernel caches the last ~15 mln', ' meaning there is ~5\nmln of uncached inodes which are going to be visited first', ' evicting the\npreviously cached state as it happens.\n\nLack of hits can be trivially verified with bpftrace', "" like so:\nbpftrace -e 'kretprobe:find_inode_fast { @[kstack()"", ' retval != 0] = count(); }\'\\\n-c ""/bin/sh walktrees /testfs 20""\n\nBest ran more than once.\n\nExpected results after ""warmup"":\n[snip]\n@[\n    __ext4_iget+275\n    ext4_lookup+224\n    __lookup_slow+130\n    walk_component+219\n    link_path_walk.part.0.constprop.0+614\n    path_lookupat+62\n    filename_lookup+204\n    vfs_statx+128\n    vfs_fstatat+131\n    __do_sys_newfstatat+38\n    do_syscall_64+87\n    entry_SYSCALL_64_after_hwframe+118\n', ' 1]: 20000\n@[\n    __ext4_iget+275\n    ext4_lookup+224\n    __lookup_slow+130\n    walk_component+219\n    path_lookupat+106\n    filename_lookup+204\n    vfs_statx+128\n    vfs_fstatat+131\n    __do_sys_newfstatat+38\n    do_syscall_64+87\n    entry_SYSCALL_64_after_hwframe+118\n', ' 1]: 20000000\n\nThat is 20 million calls for the initial lookup and 20 million after\nallocating a new inode', ' all of them failing to return a value != 0\n(i.e.', ' they are returning NULL -- no match found).\n\nOf course aborting the benchmark in the middle and starting it again (or\nmessing with the state in other ways) is going to alter these results.\n\nBenchmark can be found here: https://people.freebsd.org/~mjg/fstree.tgz\n\n[1] https://lore.kernel.org/all/20231206060629.2827226-1-david@fromorbit.com/\n\nSigned-off-by: Mateusz Guzik <mjguzik@gmail.com>\nLink: https://lore.kernel.org/r/20240611173824.535995-2-mjguzik@gmail.com\nReviewed-by: Jan Kara <jack@suse.cz>\nSigned-off-by: Christian Brauner <brauner@kernel.org>\n', '']",Added RCU-based find_inode variants to iget operations for reduced inode hash lock contention.,"RCU, inode, performance",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
30addd1dc6cc4558ec7024448f04bc77d508fe7d,30addd1dc6cc4558ec7024448f04bc77d508fe7d,Jiri Olsa,jolsa@kernel.org,1718149469,Masami Hiramatsu (Google),mhiramat@kernel.org,1718149469,2808111288cb160cf0663149b4289caac82fdb6b,9e7f74e64ae58688a33a6445e4f9a4e291d0824f,"selftests/bpf: Add uretprobe shadow stack test

Adding uretprobe shadow stack test that runs all existing
uretprobe tests with shadow stack enabled if it's available.

Link: https://lore.kernel.org/all/20240611112158.40795-9-jolsa@kernel.org/

Acked-by: Andrii Nakryiko <andrii@kernel.org>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
",,Add selftests for uretprobe to test shadow stack functionality.,"uretprobe,shadow stack,selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
9e7f74e64ae58688a33a6445e4f9a4e291d0824f,9e7f74e64ae58688a33a6445e4f9a4e291d0824f,Jiri Olsa,jolsa@kernel.org,1718149468,Masami Hiramatsu (Google),mhiramat@kernel.org,1718149468,2f3da3b7727acdc41be9632f2513ac27af1ed877,f42a58ffb8bb54e66bf9668a6be91477828c0c1b,"selftests/bpf: Add uretprobe syscall call from user space test

Adding test to verify that when called from outside of the
trampoline provided by kernel"," the uretprobe syscall will cause
calling process to receive SIGILL signal and the attached bpf
program is not executed.

Link: https://lore.kernel.org/all/20240611112158.40795-8-jolsa@kernel.org/

Acked-by: Andrii Nakryiko <andrii@kernel.org>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
",[''],This commit adds a test to verify uretprobe syscall behavior from user space in selftests.,"selftests,bpf,uretprobe",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
f42a58ffb8bb54e66bf9668a6be91477828c0c1b,f42a58ffb8bb54e66bf9668a6be91477828c0c1b,Jiri Olsa,jolsa@kernel.org,1718149468,Masami Hiramatsu (Google),mhiramat@kernel.org,1718149468,90dd76bf311f610cb059848a666241a427dd7e96,3e8e25761a40194887336650673587191564e12c,"selftests/bpf: Add uretprobe syscall test for regs changes

Adding test that creates uprobe consumer on uretprobe which changes some
of the registers. Making sure the changed registers are propagated to the
user space when the ureptobe syscall trampoline is used on x86_64.

To be able to do this"," adding support to bpf_testmod to create uprobe via
new attribute file:
  /sys/kernel/bpf_testmod_uprobe

This file is expecting file offset and creates related uprobe on current
process exe file and removes existing uprobe if offset is 0. The can be
only single uprobe at any time.

The uprobe has specific consumer that changes registers used in ureprobe
syscall trampoline and which are later checked in the test.

Link: https://lore.kernel.org/all/20240611112158.40795-7-jolsa@kernel.org/

Acked-by: Andrii Nakryiko <andrii@kernel.org>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
",[''],The commit adds a selftest for uretprobe syscall to verify register changes on x86_64.,"selftests,bpf,uretpobe",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
3e8e25761a40194887336650673587191564e12c,3e8e25761a40194887336650673587191564e12c,Jiri Olsa,jolsa@kernel.org,1718149468,Masami Hiramatsu (Google),mhiramat@kernel.org,1718149468,8a42fbd670ce42667c5c04f9b18320fd7d1928e4,29edd8b003db897d81d82d950785327f164650d3,"selftests/bpf: Add uretprobe syscall test for regs integrity

Add uretprobe syscall test that compares register values before
and after the uretprobe is hit. It also compares the register
values seen from attached bpf program.

Link: https://lore.kernel.org/all/20240611112158.40795-6-jolsa@kernel.org/

Acked-by: Andrii Nakryiko <andrii@kernel.org>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
",,Add uretprobe syscall test to verify register integrity with BPF program comparison.,"uretprobe,syscall,registers",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
29edd8b003db897d81d82d950785327f164650d3,29edd8b003db897d81d82d950785327f164650d3,Jiri Olsa,jolsa@kernel.org,1718149468,Masami Hiramatsu (Google),mhiramat@kernel.org,1718149468,f2ad3c83d7fec324012da11df7c7bd90ff41c910,ff474a78cef5cb5f32be52fe25b78441327a2e7c,"selftests/x86: Add return uprobe shadow stack test

Adding return uprobe test for shadow stack and making sure it's
working properly. Borrowed some of the code from bpf selftests.

Link: https://lore.kernel.org/all/20240611112158.40795-5-jolsa@kernel.org/

Acked-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
",,Add a return uprobe test for shadow stack verification in selftests/x86.,"uproprobe, shadow stack, selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
ff474a78cef5cb5f32be52fe25b78441327a2e7c,ff474a78cef5cb5f32be52fe25b78441327a2e7c,Jiri Olsa,jolsa@kernel.org,1718149468,Masami Hiramatsu (Google),mhiramat@kernel.org,1718149468,c2320aabb257bd62e8d33f8c4e0ae1e516407743,190fec72df4a5d4d98b1e783c333f471e5e5f344,"uprobe: Add uretprobe syscall to speed up return probe

Adding uretprobe syscall instead of trap to speed up return probe.

At the moment the uretprobe setup/path is:

  - install entry uprobe

  - when the uprobe is hit"," it overwrites probed function's return address
    on stack with address of the trampoline that contains breakpoint
    instruction

  - the breakpoint trap code handles the uretprobe consumers execution and
    jumps back to original return address

This patch replaces the above trampoline's breakpoint instruction with new
ureprobe syscall call. This syscall does exactly the same job as the trap
with some more extra work:

  - syscall trampoline must save original value for rax/r11/rcx registers
    on stack - rax is set to syscall number and r11/rcx are changed and
    used by syscall instruction

  - the syscall code reads the original values of those registers and
    restore those values in task's pt_regs area

  - only caller from trampoline exposed in '[uprobes]' is allowed","['\n    the process will receive SIGILL signal otherwise\n\nEven with some extra work', "" using the uretprobes syscall shows speed\nimprovement (compared to using standard breakpoint):\n\n  On Intel (11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz)\n\n  current:\n    uretprobe-nop  :    1.498 ± 0.000M/s\n    uretprobe-push :    1.448 ± 0.001M/s\n    uretprobe-ret  :    0.816 ± 0.001M/s\n\n  with the fix:\n    uretprobe-nop  :    1.969 ± 0.002M/s  < 31% speed up\n    uretprobe-push :    1.910 ± 0.000M/s  < 31% speed up\n    uretprobe-ret  :    0.934 ± 0.000M/s  < 14% speed up\n\n  On Amd (AMD Ryzen 7 5700U)\n\n  current:\n    uretprobe-nop  :    0.778 ± 0.001M/s\n    uretprobe-push :    0.744 ± 0.001M/s\n    uretprobe-ret  :    0.540 ± 0.001M/s\n\n  with the fix:\n    uretprobe-nop  :    0.860 ± 0.001M/s  < 10% speed up\n    uretprobe-push :    0.818 ± 0.001M/s  < 10% speed up\n    uretprobe-ret  :    0.578 ± 0.000M/s  <  7% speed up\n\nThe performance test spawns a thread that runs loop which triggers\nuprobe with attached bpf program that increments the counter that\ngets printed in results above.\n\nThe uprobe (and uretprobe) kind is determined by which instruction\nis being patched with breakpoint instruction. That's also important\nfor uretprobes"", ' because uprobe is installed for each uretprobe.\n\nThe performance test is part of bpf selftests:\n  tools/testing/selftests/bpf/run_bench_uprobes.sh\n\nNote at the moment uretprobe syscall is supported only for native\n64-bit process', ' compat process still uses standard breakpoint.\n\nNote that when shadow stack is enabled the uretprobe syscall returns\nvia iret', ' which is slower than return via sysret', "" but won't cause the\nshadow stack violation.\n\nLink: https://lore.kernel.org/all/20240611112158.40795-4-jolsa@kernel.org/\n\nSuggested-by: Andrii Nakryiko <andrii@kernel.org>\nReviewed-by: Oleg Nesterov <oleg@redhat.com>\nReviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Oleg Nesterov <oleg@redhat.com>\nSigned-off-by: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\n"", '']",The commit introduces a new uretprobe syscall to enhance the efficiency of return probes.,"uretprobe, syscall, probe",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['kprobe/uprobe/ftrace like programs']
98b303c9bf05dae932efbd71e18d81f6c64f20d8,98b303c9bf05dae932efbd71e18d81f6c64f20d8,Kenta Tada,tadakentaso@gmail.com,1717759024,Alexei Starovoitov,ast@kernel.org,1718131149,e5214d06ca6fc657db34bbc70c0675aa6660dbab,bb678f01804ccaa861b012b2b9426d69673d8a84,"bpftool: Query only cgroup-related attach types

When CONFIG_NETKIT=y","
bpftool-cgroup shows error even if the cgroup's path is correct:

$ bpftool cgroup tree /sys/fs/cgroup
CgroupPath
ID       AttachType      AttachFlags     Name
Error: can't query bpf programs attached to /sys/fs/cgroup: No such device or address

>From strace and kernel tracing","[' I found netkit returned ENXIO and this command failed.\nI think this AttachType(BPF_NETKIT_PRIMARY) is not relevant to cgroup.\n\nbpftool-cgroup should query just only cgroup-related attach types.\n\nv2->v3:\n  - removed an unnecessary check\n\nv1->v2:\n  - used an array of cgroup attach types\n\nSigned-off-by: Kenta Tada <tadakentaso@gmail.com>\nReviewed-by: Quentin Monnet <qmo@kernel.org>\nLink: https://lore.kernel.org/r/20240607111704.6716-1-tadakentaso@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit fixes an error in bpftool when querying cgroup-related attach types with CONFIG_NETKIT=y.,"bpftool,cgroup,query",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,['cgroup like programs']
b1156532bc29ac9a8d1cf71510cabc8f68181540,b1156532bc29ac9a8d1cf71510cabc8f68181540,Jakub Kicinski,kuba@kernel.org,1718067734,Jakub Kicinski,kuba@kernel.org,1718067734,d7209c26ece681ecab283559d493944ded42d37b,93d4e8bb3f137e8037a65ea96f175f81c25c50e5 f85af9d955ac9601174e1c64f4b3308c1cae4a7e,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next

Daniel Borkmann says:

====================
pull-request: bpf-next 2024-06-06

We've added 54 non-merge commits during the last 10 day(s) which contain
a total of 50 files changed", 1887 insertions(+),"[' 527 deletions(-).\n\nThe main changes are:\n\n1) Add a user space notification mechanism via epoll when a struct_ops\n   object is getting detached/unregistered', ' from Kui-Feng Lee.\n\n2) Big batch of BPF selftest refactoring for sockmap and BPF congctl\n   tests', ' from Geliang Tang.\n\n3) Add BTF field (type and string fields', ' right now) iterator support\n   to libbpf instead of using existing callback-based approaches', '\n   from Andrii Nakryiko.\n\n4) Extend BPF selftests for the latter with a new btf_field_iter\n   selftest', ' from Alan Maguire.\n\n5) Add new kfuncs for a generic', ' open-coded bits iterator', ""\n   from Yafang Shao.\n\n6) Fix BPF selftests' kallsyms_find() helper under kernels configured\n   with CONFIG_LTO_CLANG_THIN"", ' from Yonghong Song.\n\n7) Remove a bunch of unused structs in BPF selftests', '\n   from David Alan Gilbert.\n\n8) Convert test_sockmap section names into names understood by libbpf\n   so it can deduce program type and attach type', ' from Jakub Sitnicki.\n\n9) Extend libbpf with the ability to configure log verbosity\n   via LIBBPF_LOG_LEVEL environment variable', ' from Mykyta Yatsenko.\n\n10) Fix BPF selftests with regards to bpf_cookie and find_vma flakiness\n    in nested VMs', ' from Song Liu.\n\n11) Extend riscv32/64 JITs to introduce shift/add helpers to generate Zba\n    optimization', ' from Xiao Wang.\n\n12) Enable BPF programs to declare arrays and struct fields with kptr', '\n    bpf_rb_root', ' and bpf_list_head', "" from Kui-Feng Lee.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next: (54 commits)\n  selftests/bpf: Drop useless arguments of do_test in bpf_tcp_ca\n  selftests/bpf: Use start_test in test_dctcp in bpf_tcp_ca\n  selftests/bpf: Use start_test in test_dctcp_fallback in bpf_tcp_ca\n  selftests/bpf: Add start_test helper in bpf_tcp_ca\n  selftests/bpf: Use connect_to_fd_opts in do_test in bpf_tcp_ca\n  libbpf: Auto-attach struct_ops BPF maps in BPF skeleton\n  selftests/bpf: Add btf_field_iter selftests\n  selftests/bpf: Fix send_signal test with nested CONFIG_PARAVIRT\n  libbpf: Remove callback-based type/string BTF field visitor helpers\n  bpftool: Use BTF field iterator in btfgen\n  libbpf: Make use of BTF field iterator in BTF handling code\n  libbpf: Make use of BTF field iterator in BPF linker code\n  libbpf: Add BTF field iterator\n  selftests/bpf: Ignore .llvm.<hash> suffix in kallsyms_find()\n  selftests/bpf: Fix bpf_cookie and find_vma in nested VM\n  selftests/bpf: Test global bpf_list_head arrays.\n  selftests/bpf: Test global bpf_rb_root arrays and fields in nested struct types.\n  selftests/bpf: Test kptr arrays and kptrs in nested struct fields.\n  bpf: limit the number of levels of a nested struct type.\n  bpf: look into the types of the fields of a struct type recursively.\n  ...\n====================\n\nLink: https://lore.kernel.org/r/20240606223146.23020-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n"", '']",Merge pull request for bpf-next containing 54 non-merge commits affecting 50 files.,"merge, bpf-next, commits",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2ba6d15786f6c11b6e497eebe68b8baec52f7984,2ba6d15786f6c11b6e497eebe68b8baec52f7984,David S. Miller,davem@davemloft.net,1718023686,David S. Miller,davem@davemloft.net,1718023686,ed103d96d1b627bcc4e09ab6d3e0db29dcaf9ba8,395059c52e0104a5e01832f866caa8b15284dd9a eef8e906aea270f4b8912a0b51403b80aec54d30,"Merge branch 'fix-changing-dsa-conduit'

Marek Behún says:

====================
Fix changing DSA conduit

This series fixes an issue in the DSA code related to host interface UC
address installed into port FDB and port conduit address database when
live-changing port conduit.

The first patch refactores/deduplicates the installation/uninstallation
of the interface's MAC address and the second patch fixes the issue.

Cover letter for v1 and v2:
  https://patchwork.kernel.org/project/netdevbpf/cover/20240429163627.16031-1-kabel@kernel.org/
  https://patchwork.kernel.org/project/netdevbpf/cover/20240502122922.28139-1-kabel@kernel.org/
====================

Signed-off-by: David S. Miller <davem@davemloft.net>
",,Fixes an issue in the DSA code related to host interface UC address and port FDB database during conduit changes.,"DSA, conduit, MAC",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
b8481381d4e2549f06812eb6069198144696340c,b8481381d4e2549f06812eb6069198144696340c,Linus Torvalds,torvalds@linux-foundation.org,1717949091,Linus Torvalds,torvalds@linux-foundation.org,1717949091,f89a2db5e640f6f601b40ca6a4d5e9028e00bcb1,637c2dfcd9f5e194ab2e879704460840edcde537 ca9680821dfec73c9100860bda4fab1f1309722e,"Merge tag 'perf-tools-fixes-for-v6.10-2-2024-06-09' of git://git.kernel.org/pub/scm/linux/kernel/git/perf/perf-tools

Pull perf tools fixes from Arnaldo Carvalho de Melo:

 - Update copies of kernel headers"," which resulted in support for the
   new 'mseal' syscall","[' SUBVOL statx return mask bit', ' RISC-V and PPC\n   prctls', "" fcntl's DUPFD_QUERY"", ' POSTED_MSI_NOTIFICATION IRQ vector', ""\n   'map_shadow_stack' syscall for x86-32.\n\n - Revert perf.data record memory allocation optimization that ended up\n   causing a regression"", ' work is being done to re-introduce it in the\n   next merge window.\n\n - Fix handling of minimal vmlinux.h file used with BPF\'s CO-RE when\n   interrupting the build.\n\n* tag \'perf-tools-fixes-for-v6.10-2-2024-06-09\' of git://git.kernel.org/pub/scm/linux/kernel/git/perf/perf-tools:\n  perf bpf: Fix handling of minimal vmlinux.h file when interrupting the build\n  Revert ""perf record: Reduce memory for recording PERF_RECORD_LOST_SAMPLES event""\n  tools headers arm64: Sync arm64\'s cputype.h with the kernel sources\n  tools headers uapi: Sync linux/stat.h with the kernel sources to pick STATX_SUBVOL\n  tools headers UAPI: Update i915_drm.h with the kernel sources\n  tools headers UAPI: Sync kvm headers with the kernel sources\n  tools arch x86: Sync the msr-index.h copy with the kernel sources\n  tools headers: Update the syscall tables and unistd.h', "" mostly to support the new 'mseal' syscall\n  perf trace beauty: Update the arch/x86/include/asm/irq_vectors.h copy with the kernel sources to pick POSTED_MSI_NOTIFICATION\n  perf beauty: Update copy of linux/socket.h with the kernel sources\n  tools headers UAPI: Sync fcntl.h with the kernel sources to pick F_DUPFD_QUERY\n  tools headers UAPI: Sync linux/prctl.h with the kernel sources\n  tools include UAPI: Sync linux/stat.h with the kernel sources\n"", '']",Merge of perf tools fixes and update copies of kernel headers.,"Merge,perf-tools,headers",It's a build system or CI/CD change.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
f85af9d955ac9601174e1c64f4b3308c1cae4a7e,f85af9d955ac9601174e1c64f4b3308c1cae4a7e,Geliang Tang,tanggeliang@kylinos.cn,1717054872,Daniel Borkmann,daniel@iogearbox.net,1717707846,fbd6222b981d77cca537fcc3447165c2cf68ae19,cd984b2ed62423eb3daceacb21d651115a612af6,"selftests/bpf: Drop useless arguments of do_test in bpf_tcp_ca

bpf_map_lookup_elem() has been removed from do_test()"," it makes the
sk_stg_map argument of do_test() useless. In addition","[' two exactly the\nsame opts are passed in all the places where do_test() is invoked', ' so\ncli_opts argument can be dropped too.\n\nThis patch drops these two useless arguments of do_test() in bpf_tcp_ca.c.\n\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/7056eab111d78a05bce29d2821228dc93f240de4.1717054461.git.tanggeliang@kylinos.cn\n', '']",Remove unused arguments from do_test in bpf_tcp_ca selftests.,"do_test,bpf_tcp_ca,selftests",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
cd984b2ed62423eb3daceacb21d651115a612af6,cd984b2ed62423eb3daceacb21d651115a612af6,Geliang Tang,tanggeliang@kylinos.cn,1717054871,Daniel Borkmann,daniel@iogearbox.net,1717707845,fb8752b38572b05a18f08ea1e4bef42d9b6ea174,224eeb5598c30ee835dc9fea4c7ad85a8fb7eda4,"selftests/bpf: Use start_test in test_dctcp in bpf_tcp_ca

The ""if (sk_stg_map)"" block in do_test() is only used by test_dctcp()","
it makes sense to move it from do_test() into test_dctcp(). Then
do_test() can be used by other tests except test_dctcp().

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/9938916627b9810c877e5c03a621bc0ba5acf5c5.1717054461.git.tanggeliang@kylinos.cn
",[''],"Refactor test_dctcp to use start_test, allowing do_test to be reused for other tests.","selftests,bpf,test_dctcp",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
224eeb5598c30ee835dc9fea4c7ad85a8fb7eda4,224eeb5598c30ee835dc9fea4c7ad85a8fb7eda4,Geliang Tang,tanggeliang@kylinos.cn,1717054870,Daniel Borkmann,daniel@iogearbox.net,1717707845,19e1f3cd1cec9de326f3728328f7680ee6f484e6,fee97d0c9a14b5dd5cce0ec1df3a54a6b963f40c,"selftests/bpf: Use start_test in test_dctcp_fallback in bpf_tcp_ca

The newly added helper start_test() can be used in test_dctcp_fallback()
too"," to replace start_server_str() and connect_to_fd_opts(). In that
way","[' two network_helper_opts srv_opts and cli_opts are used instead of\nthe previously shared opts.\n\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/792ca3bb013fa06e618176da02d75e4f79a76733.1717054461.git.tanggeliang@kylinos.cn\n', '']",The commit refactors test_dctcp_fallback to use the new start_test helper function in bpf_tcp_ca selftests.,"start_test, test_dctcp_fallback, refactoring",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fee97d0c9a14b5dd5cce0ec1df3a54a6b963f40c,fee97d0c9a14b5dd5cce0ec1df3a54a6b963f40c,Geliang Tang,tanggeliang@kylinos.cn,1717054869,Daniel Borkmann,daniel@iogearbox.net,1717707845,ac2f0c968d22454b02391c98e46b8f73020c64a0,9abdfd8a212332c64f6d0a27fc2ad69e9e0335d1,"selftests/bpf: Add start_test helper in bpf_tcp_ca

For moving the ""if (sk_stg_map)"" block out of do_test()"," extract the
code before this block as a new function start_test(). It creates
server-side and client-side sockets and returns them to the caller.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/48f2921ff9be958f5d3d28fe6bb7269a61cafa9f.1717054461.git.tanggeliang@kylinos.cn
",[''],Implemented a new start_test helper function in bpf_tcp_ca selftests to refactor socket creation.,"start_test, bpf_tcp_ca, refactor",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['socket like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9abdfd8a212332c64f6d0a27fc2ad69e9e0335d1,9abdfd8a212332c64f6d0a27fc2ad69e9e0335d1,Geliang Tang,tanggeliang@kylinos.cn,1717054868,Daniel Borkmann,daniel@iogearbox.net,1717707845,5196cf3014b60e094cd31bf19c615754b874cbf3,08ac454e258e38813afb906650f19acce3afd982,"selftests/bpf: Use connect_to_fd_opts in do_test in bpf_tcp_ca

This patch uses connect_to_fd_opts() instead of using connect_fd_to_fd()
and settcpca() in do_test() in prog_tests/bpf_tcp_ca.c to accept a struct
network_helper_opts argument.

Then define a dctcp dedicated post_socket_cb callback stg_post_socket_cb()","
invoking both settcpca() and bpf_map_update_elem() in it","[' and set it in\ntest_dctcp(). For passing map_fd into stg_post_socket_cb() callback', ' a new\nmember map_fd is added in struct cb_opts.\n\nAdd another ""const struct network_helper_opts *cli_opts"" to do_test() to\nseparate it from the server ""opts"".\n\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/876ec90430865bc468e3b7f6fb2648420b075548.1717054461.git.tanggeliang@kylinos.cn\n', '']",Refactor bpf_tcp_ca do_test function to use connect_to_fd_opts and introduce a dctcp post_socket callback.,"bpf_tcp_ca, connect_to_fd_opts, dctcp",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['tc/netfilter like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0ac55d095d375e84fcdac5e51011613734e57854,0ac55d095d375e84fcdac5e51011613734e57854,Paul E. McKenney,paulmck@kernel.org,1715229836,Paul E. McKenney,paulmck@kernel.org,1717699482,bf5c056e143ea5215345184579007d36ce4cd71d,b9f147cdc2c0bf54ca2c25ed185806f1fc6da65f,"tools/rcu: Add rcu-updaters.sh script

This commit adds a tools/rcu/rcu-updaters.sh script that uses bpftrace
to print a histogram of the RCU update-side primitives invoked during
the specified time interval"," or until manually terminated if no interval
is specified.

Sample output on an idle laptop:

@counts[poll_state_synchronize_rcu]: 6
@counts[synchronize_srcu]: 13
@counts[call_rcu_tasks_trace]: 25
@counts[synchronize_rcu]: 54
@counts[kvfree_call_rcu]: 428
@counts[call_rcu]: 2134

Note that when run on a kernel missing one or more of the symbols","[' this\nscript will issue a diagnostic for each that is not found', ' but continue\nnormally for the rest of the functions.\n\nSigned-off-by: Paul E. McKenney <paulmck@kernel.org>\n', '']",Added a script using bpftrace to print a histogram of RCU update-side primitives.,"bpftrace, RCU, script",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['other']
08ac454e258e38813afb906650f19acce3afd982,08ac454e258e38813afb906650f19acce3afd982,Mykyta Yatsenko,yatsenko@meta.com,1717609895,Andrii Nakryiko,andrii@kernel.org,1717693565,d98f6e8a40758535eb8141f2575096b939ae8628,b24862bac7b5db326716ad07bbff7b6ee3b09a59,"libbpf: Auto-attach struct_ops BPF maps in BPF skeleton

Similarly to `bpf_program`"," support `bpf_map` automatic attachment in
`bpf_object__attach_skeleton`. Currently only struct_ops maps could be
attached.

On bpftool side","[' code-generate links in skeleton struct for struct_ops maps.\nSimilarly to `bpf_program_skeleton`', ' set links in `bpf_map_skeleton`.\n\nOn libbpf side', ' extend `bpf_map` with new `autoattach` field to support\nenabling or disabling autoattach functionality', ' introducing\ngetter/setter for this field.\n\n`bpf_object__(attach|detach)_skeleton` is extended with\nattaching/detaching struct_ops maps logic.\n\nSigned-off-by: Mykyta Yatsenko <yatsenko@meta.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240605175135.117127-1-yatsenko@meta.com\n', '']",This commit enables automatic attachment of struct_ops BPF maps in BPF skeletons using libbpf.,"libbpf,struct_ops,auto-attach",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d30d0e49da71de8df10bf3ff1b3de880653af562,d30d0e49da71de8df10bf3ff1b3de880653af562,Linus Torvalds,torvalds@linux-foundation.org,1717692927,Linus Torvalds,torvalds@linux-foundation.org,1717692927,65c58dfad109ecfa19de9a50cbc0937c7698ecaf,2faf6332c506fc3bd23815f8fe8f6d0c35271c17 27bc86540899ee793ab2f4c846e745aa0de443f1,"Merge tag 'net-6.10-rc3' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Jakub Kicinski:
 ""Including fixes from BPF and big collection of fixes for WiFi core and
  drivers.

  Current release - regressions:

   - vxlan: fix regression when dropping packets due to invalid src
     addresses

   - bpf: fix a potential use-after-free in bpf_link_free()

   - xdp: revert support for redirect to any xsk socket bound to the
     same UMEM as it can result in a corruption

   - virtio_net:
      - add missing lock protection when reading return code from
        control_buf
      - fix false-positive lockdep splat in DIM
      - Revert ""wifi: wilc1000: convert list management to RCU""

   - wifi: ath11k: fix error path in ath11k_pcic_ext_irq_config

  Previous releases - regressions:

   - rtnetlink: make the ""split"" NLM_DONE handling generic"," restore the
     old behavior for two cases where we started coalescing those
     messages with normal messages","[' breaking sloppily-coded userspace\n\n   - wifi:\n      - cfg80211: validate HE operation element parsing\n      - cfg80211: fix 6 GHz scan request building\n      - mt76: mt7615: add missing chanctx ops\n      - ath11k: move power type check to ASSOC stage', ' fix connecting to\n        6 GHz AP\n      - ath11k: fix WCN6750 firmware crash caused by 17 num_vdevs\n      - rtlwifi: ignore IEEE80211_CONF_CHANGE_RETRY_LIMITS\n      - iwlwifi: mvm: fix a crash on 7265\n\n  Previous releases - always broken:\n\n   - ncsi: prevent multi-threaded channel probing', ' a spec violation\n\n   - vmxnet3: disable rx data ring on dma allocation failure\n\n   - ethtool: init tsinfo stats if requested', ' prevent unintentionally\n     reporting all-zero stats on devices which don\'t implement any\n\n   - dst_cache: fix possible races in less common IPv6 features\n\n   - tcp: auth: don\'t consider TCP_CLOSE to be in TCP_AO_ESTABLISHED\n\n   - ax25: fix two refcounting bugs\n\n   - eth: ionic: fix kernel panic in XDP_TX action\n\n  Misc:\n\n   - tcp: count CLOSE-WAIT sockets for TCP_MIB_CURRESTAB""\n\n* tag \'net-6.10-rc3\' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (107 commits)\n  selftests: net: lib: set \'i\' as local\n  selftests: net: lib: avoid error removing empty netns name\n  selftests: net: lib: support errexit with busywait\n  net: ethtool: fix the error condition in ethtool_get_phy_stats_ethtool()\n  ipv6: fix possible race in __fib6_drop_pcpu_from()\n  af_unix: Annotate data-race of sk->sk_shutdown in sk_diag_fill().\n  af_unix: Use skb_queue_len_lockless() in sk_diag_show_rqlen().\n  af_unix: Use skb_queue_empty_lockless() in unix_release_sock().\n  af_unix: Use unix_recvq_full_lockless() in unix_stream_connect().\n  af_unix: Annotate data-race of net->unx.sysctl_max_dgram_qlen.\n  af_unix: Annotate data-races around sk->sk_sndbuf.\n  af_unix: Annotate data-races around sk->sk_state in UNIX_DIAG.\n  af_unix: Annotate data-race of sk->sk_state in unix_stream_read_skb().\n  af_unix: Annotate data-races around sk->sk_state in sendmsg() and recvmsg().\n  af_unix: Annotate data-race of sk->sk_state in unix_accept().\n  af_unix: Annotate data-race of sk->sk_state in unix_stream_connect().\n  af_unix: Annotate data-races around sk->sk_state in unix_write_space() and poll().\n  af_unix: Annotate data-race of sk->sk_state in unix_inq_len().\n  af_unix: Annodate data-races around sk->sk_state for writers.\n  af_unix: Set sk->sk_state under unix_state_lock() for truly disconencted peer.\n  ...\n', '']","The commit merges networking and BPF-related fixes, addressing regressions and issues in vxlan, bpf, xdp, virtio_net, and wifi.","networking, BPF, wifi",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['xdp like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b24862bac7b5db326716ad07bbff7b6ee3b09a59,b24862bac7b5db326716ad07bbff7b6ee3b09a59,Alan Maguire,alan.maguire@oracle.com,1717601594,Daniel Borkmann,daniel@iogearbox.net,1717682190,52464cc46bb2b00e73a11a8299b0bd3609dc2f0d,7015843afcaf68c132784c89528dfddc0005e483,"selftests/bpf: Add btf_field_iter selftests

The added selftests verify that for every BTF kind we iterate correctly
over consituent strings and ids.

Signed-off-by: Alan Maguire <alan.maguire@oracle.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240605153314.3727466-1-alan.maguire@oracle.com
",,Added new selftests for verifying BTF field iterators' correct iteration over strings and IDs.,"selftests,BTF,iteration",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7015843afcaf68c132784c89528dfddc0005e483,7015843afcaf68c132784c89528dfddc0005e483,Yonghong Song,yonghong.song@linux.dev,1717618323,Daniel Borkmann,daniel@iogearbox.net,1717681753,d312367dcb688438abb02b0701d63238d5b0e3b8,072088704433f75dacf9e33179dd7a81f0a238d4,"selftests/bpf: Fix send_signal test with nested CONFIG_PARAVIRT

Alexei reported that send_signal test may fail with nested CONFIG_PARAVIRT
configs. In this particular case", the base VM is AMD with 166 cpus,"[' and I\nrun selftests with regular qemu on top of that and indeed send_signal test\nfailed. I also tried with an Intel box with 80 cpus and there is no issue.\n\nThe main qemu command line includes:\n\n  -enable-kvm -smp 16 -cpu host\n\nThe failure log looks like:\n\n  $ ./test_progs -t send_signal\n  [   48.501588] watchdog: BUG: soft lockup - CPU#9 stuck for 26s! [test_progs:2225]\n  [   48.503622] Modules linked in: bpf_testmod(O)\n  [   48.503622] CPU: 9 PID: 2225 Comm: test_progs Tainted: G           O       6.9.0-08561-g2c1713a8f1c9-dirty #69\n  [   48.507629] Hardware name: QEMU Standard PC (i440FX + PIIX', ' 1996)', ' BIOS rel-1.15.0-0-g2dd4b9b3f840-prebuilt.qemu.org 04/01/2014\n  [   48.511635] RIP: 0010:handle_softirqs+0x71/0x290\n  [   48.511635] Code: [...] 10 0a 00 00 00 31 c0 65 66 89 05 d5 f4 fa 7e fb bb ff ff ff ff <49> c7 c2 cb\n  [   48.518527] RSP: 0018:ffffc90000310fa0 EFLAGS: 00000246\n  [   48.519579] RAX: 0000000000000000 RBX: 00000000ffffffff RCX: 00000000000006e0\n  [   48.522526] RDX: 0000000000000006 RSI: ffff88810791ae80 RDI: 0000000000000000\n  [   48.523587] RBP: ffffc90000fabc88 R08: 00000005a0af4f7f R09: 0000000000000000\n  [   48.525525] R10: 0000000561d2f29c R11: 0000000000006534 R12: 0000000000000280\n  [   48.528525] R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000\n  [   48.528525] FS:  00007f2f2885cd00(0000) GS:ffff888237c40000(0000) knlGS:0000000000000000\n  [   48.531600] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n  [   48.535520] CR2: 00007f2f287059f0 CR3: 0000000106a28002 CR4: 00000000003706f0\n  [   48.537538] Call Trace:\n  [   48.537538]  <IRQ>\n  [   48.537538]  ? watchdog_timer_fn+0x1cd/0x250\n  [   48.539590]  ? lockup_detector_update_enable+0x50/0x50\n  [   48.539590]  ? __hrtimer_run_queues+0xff/0x280\n  [   48.542520]  ? hrtimer_interrupt+0x103/0x230\n  [   48.544524]  ? __sysvec_apic_timer_interrupt+0x4f/0x140\n  [   48.545522]  ? sysvec_apic_timer_interrupt+0x3a/0x90\n  [   48.547612]  ? asm_sysvec_apic_timer_interrupt+0x1a/0x20\n  [   48.547612]  ? handle_softirqs+0x71/0x290\n  [   48.547612]  irq_exit_rcu+0x63/0x80\n  [   48.551585]  sysvec_apic_timer_interrupt+0x75/0x90\n  [   48.552521]  </IRQ>\n  [   48.553529]  <TASK>\n  [   48.553529]  asm_sysvec_apic_timer_interrupt+0x1a/0x20\n  [   48.555609] RIP: 0010:finish_task_switch.isra.0+0x90/0x260\n  [   48.556526] Code: [...] 9f 58 0a 00 00 48 85 db 0f 85 89 01 00 00 4c 89 ff e8 53 d9 bd 00 fb 66 90 <4d> 85 ed 74\n  [   48.562524] RSP: 0018:ffffc90000fabd38 EFLAGS: 00000282\n  [   48.563589] RAX: 0000000000000000 RBX: 0000000000000000 RCX: ffffffff83385620\n  [   48.563589] RDX: ffff888237c73ae4 RSI: 0000000000000000 RDI: ffff888237c6fd00\n  [   48.568521] RBP: ffffc90000fabd68 R08: 0000000000000000 R09: 0000000000000000\n  [   48.569528] R10: 0000000000000001 R11: 0000000000000000 R12: ffff8881009d0000\n  [   48.573525] R13: ffff8881024e5400 R14: ffff88810791ae80 R15: ffff888237c6fd00\n  [   48.575614]  ? finish_task_switch.isra.0+0x8d/0x260\n  [   48.576523]  __schedule+0x364/0xac0\n  [   48.577535]  schedule+0x2e/0x110\n  [   48.578555]  pipe_read+0x301/0x400\n  [   48.579589]  ? destroy_sched_domains_rcu+0x30/0x30\n  [   48.579589]  vfs_read+0x2b3/0x2f0\n  [   48.579589]  ksys_read+0x8b/0xc0\n  [   48.583590]  do_syscall_64+0x3d/0xc0\n  [   48.583590]  entry_SYSCALL_64_after_hwframe+0x4b/0x53\n  [   48.586525] RIP: 0033:0x7f2f28703fa1\n  [   48.587592] Code: [...] 00 00 00 0f 1f 44 00 00 f3 0f 1e fa 80 3d c5 23 14 00 00 74 13 31 c0 0f 05 <48> 3d 00 f0\n  [   48.593534] RSP: 002b:00007ffd90f8cf88 EFLAGS: 00000246 ORIG_RAX: 0000000000000000\n  [   48.595589] RAX: ffffffffffffffda RBX: 00007ffd90f8d5e8 RCX: 00007f2f28703fa1\n  [   48.595589] RDX: 0000000000000001 RSI: 00007ffd90f8cfb0 RDI: 0000000000000006\n  [   48.599592] RBP: 00007ffd90f8d2f0 R08: 0000000000000064 R09: 0000000000000000\n  [   48.602527] R10: 0000000000000000 R11: 0000000000000246 R12: 0000000000000000\n  [   48.603589] R13: 00007ffd90f8d608 R14: 00007f2f288d8000 R15: 0000000000f6bdb0\n  [   48.605527]  </TASK>\n\nIn the test', ' two processes are communicating through pipe. Further debugging\nwith strace found that the above splat is triggered as read() syscall could\nnot receive the data even if the corresponding write() syscall in another\nprocess successfully wrote data into the pipe.\n\nThe failed subtest is ""send_signal_perf"". The corresponding perf event has\nsample_period 1 and config PERF_COUNT_SW_CPU_CLOCK. sample_period 1 means every\noverflow event will trigger a call to the BPF program. So I suspect this may\noverwhelm the system. So I increased the sample_period to 100', '000 and the test\npassed. The sample_period 10', '000 still has the test failed.\n\nIn other parts of selftest', ' e.g.', ' [1]', ' sample_freq is used instead. So I\ndecided to use sample_freq = 1', '000 since the test can pass as well.\n\n  [1] https://lore.kernel.org/bpf/20240604070700.3032142-1-song@kernel.org/\n\nReported-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240605201203.2603846-1-yonghong.song@linux.dev\n', '']",Fixes a send_signal test issue when using nested CONFIG_PARAVIRT configurations.,"send_signal test, CONFIG_PARAVIRT, selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['other']
5899c885131a7b2926ed26f6a5df1fc3c878418d,5899c885131a7b2926ed26f6a5df1fc3c878418d,Jakub Kicinski,kuba@kernel.org,1717640885,Jakub Kicinski,kuba@kernel.org,1717640886,4cb6faca8dd7c6e27e47ec75bf9e106493624f80,886bf9172da06a85de3c68a651477d7d625fd6cc 7d67d11fbe194f71298263f48e33ae2afa38197e,"Merge branch 'intel-wired-lan-driver-updates-2024-05-29-ice-igc'

Jacob Keller says:

====================
Intel Wired LAN Driver Updates 2024-05-29 (ice"," igc)

This series includes fixes for the ice driver as well as a fix for the igc
driver.

Jacob fixes two issues in the ice driver with reading the NVM for providing
firmware data via devlink info. First","[' fix an off-by-one error when reading\nthe Preserved Fields Area', ' resolving an infinite loop triggered on some\nNVMs which lack certain data in the NVM. Second', ' fix the reading of the NVM\nShadow RAM on newer E830 and E825-C devices which have a variable sized CSS\nheader rather than assuming this header is always the same fixed size as in\nthe E810 devices.\n\nLarysa fixes three issues with the ice driver XDP logic that could occur if\nthe number of queues is changed after enabling an XDP program. First', ' the\naf_xdp_zc_qps bitmap is removed and replaced by simpler logic to track\nwhether queues are in zero-copy mode. Second', ' the reset and .ndo_bpf flows\nare distinguished to avoid potential races with a PF reset occuring\nsimultaneously to .ndo_bpf callback from userspace. Third', ' the logic for\nmapping XDP queues to vectors is fixed so that XDP state is restored for\nXDP queues after a reconfiguration.\n\nSasha fixes reporting of Energy Efficient Ethernet support via ethtool in\nthe igc driver.\n\nv1: https://lore.kernel.org/r/20240530-net-2024-05-30-intel-net-fixes-v1-0-8b11c8c9bff8@intel.com\n====================\n\nLink: https://lore.kernel.org/r/20240603-net-2024-05-30-intel-net-fixes-v2-0-e3563aa89b0c@intel.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']","The commit merges updates for the Intel wired LAN driver, with specific fixes to the ice and igc drivers.","Intel, LAN, driver",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
f3df4044254c98128890b512bf19cc05588f1fe5,f3df4044254c98128890b512bf19cc05588f1fe5,Larysa Zaremba,larysa.zaremba@intel.com,1717450954,Jakub Kicinski,kuba@kernel.org,1717640876,09c7452f1b084e7918c0cdce028c8866ba58eb90,744d197162c2070a6045a71e2666ed93a57cc65d,"ice: map XDP queues to vectors in ice_vsi_map_rings_to_vectors()

ice_pf_dcb_recfg() re-maps queues to vectors with
ice_vsi_map_rings_to_vectors()"," which does not restore the previous
state for XDP queues. This leads to no AF_XDP traffic after rebuild.

Map XDP queues to vectors in ice_vsi_map_rings_to_vectors().
Also","[' move the code around', ' so XDP queues are mapped independently only\nthrough .ndo_bpf().\n\nFixes: 6624e780a577 (""ice: split ice_vsi_setup into smaller functions"")\nReviewed-by: Przemek Kitszel <przemyslaw.kitszel@intel.com>\nSigned-off-by: Larysa Zaremba <larysa.zaremba@intel.com>\nReviewed-by: Simon Horman <horms@kernel.org>\nTested-by: Chandan Kumar Rout <chandanx.rout@intel.com>\nSigned-off-by: Jacob Keller <jacob.e.keller@intel.com>\nLink: https://lore.kernel.org/r/20240603-net-2024-05-30-intel-net-fixes-v2-5-e3563aa89b0c@intel.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Fixes mapping of XDP queues to vectors to restore AF_XDP traffic after rebuild.,"XDP,queues,vectors",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['xdp like programs']
744d197162c2070a6045a71e2666ed93a57cc65d,744d197162c2070a6045a71e2666ed93a57cc65d,Larysa Zaremba,larysa.zaremba@intel.com,1717450953,Jakub Kicinski,kuba@kernel.org,1717640876,bf5fb21ba711a6cb451fe69519c997880ad449b6,adbf5a42341f6ea038d3626cd4437d9f0ad0b2dd,"ice: add flag to distinguish reset from .ndo_bpf in XDP rings config

Commit 6624e780a577 (""ice: split ice_vsi_setup into smaller functions"")
has placed ice_vsi_free_q_vectors() after ice_destroy_xdp_rings() in
the rebuild process. The behaviour of the XDP rings config functions is
context-dependent"," so the change of order has led to
ice_destroy_xdp_rings() doing additional work and removing XDP prog","[' when\nit was supposed to be preserved.\n\nAlso', ' dependency on the PF state reset flags creates an additional', '\nfortunately less common problem:\n\n* PFR is requested e.g. by tx_timeout handler\n* .ndo_bpf() is asked to delete the program', ' calls ice_destroy_xdp_rings()', '\n  but reset flag is set', ' so rings are destroyed without deleting the\n  program\n* ice_vsi_rebuild tries to delete non-existent XDP rings', ' because the\n  program is still on the VSI\n* system crashes\n\nWith a similar race', ' when requested to attach a program', '\nice_prepare_xdp_rings() can actually skip setting the program in the VSI\nand nevertheless report success.\n\nInstead of reverting to the old order of function calls', ' add an enum\nargument to both ice_prepare_xdp_rings() and ice_destroy_xdp_rings() in\norder to distinguish between calls from rebuild and .ndo_bpf().\n\nFixes: efc2214b6047 (""ice: Add support for XDP"")\nReviewed-by: Igor Bagnucki <igor.bagnucki@intel.com>\nSigned-off-by: Larysa Zaremba <larysa.zaremba@intel.com>\nReviewed-by: Simon Horman <horms@kernel.org>\nTested-by: Chandan Kumar Rout <chandanx.rout@intel.com>\nSigned-off-by: Jacob Keller <jacob.e.keller@intel.com>\nLink: https://lore.kernel.org/r/20240603-net-2024-05-30-intel-net-fixes-v2-4-e3563aa89b0c@intel.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Add a flag to distinguish reset from .ndo_bpf in XDP rings configuration in the ice driver.,"flag, reset, XDP",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,['xdp like programs']
0105eaabb27f31d9b8d340aca6fb6a3420cab30f,0105eaabb27f31d9b8d340aca6fb6a3420cab30f,Cong Wang,cong.wang@bytedance.com,1716912518,Andrew Morton,akpm@linux-foundation.org,1717640365,c6b52ebebd80146ee3395737d292cdcc4d3330bb,7cc5a5d65011983952a9c62f170f5b79e24b1239,"vmalloc: check CONFIG_EXECMEM in is_vmalloc_or_module_addr()

After commit 2c9e5d4a0082 (""bpf: remove CONFIG_BPF_JIT dependency on
CONFIG_MODULES of"") CONFIG_BPF_JIT does not depend on CONFIG_MODULES any
more and bpf jit also uses the [MODULES_VADDR"," MODULES_END] memory region.
But is_vmalloc_or_module_addr() still checks CONFIG_MODULES","[' which then\nreturns false for a bpf jit memory region when CONFIG_MODULES is not\ndefined.  It leads to the following kernel BUG:\n\n[    1.567023] ------------[ cut here ]------------\n[    1.567883] kernel BUG at mm/vmalloc.c:745!\n[    1.568477] Oops: invalid opcode: 0000 [#1] PREEMPT SMP KASAN NOPTI\n[    1.569367] CPU: 0 PID: 1 Comm: swapper/0 Not tainted 6.9.0+ #448\n[    1.570247] Hardware name: QEMU Standard PC (Q35 + ICH9', ' 2009)', ' BIOS 1.15.0-1 04/01/2014\n[    1.570786] RIP: 0010:vmalloc_to_page+0x48/0x1ec\n[    1.570786] Code: 0f 00 00 e8 eb 1a 05 00 b8 37 00 00 00 48 ba fe ff ff ff ff 1f 00 00 4c 03 25 76 49 c6 02 48 c1 e0 28 48 01 e8 48 39 d0 76 02 <0f> 0b 4c 89 e7 e8 bf 1a 05 00 49 8b 04 24 48 a9 9f ff ff ff 0f 84\n[    1.570786] RSP: 0018:ffff888007787960 EFLAGS: 00010212\n[    1.570786] RAX: 000036ffa0000000 RBX: 0000000000000640 RCX: ffffffff8147e93c\n[    1.570786] RDX: 00001ffffffffffe RSI: dffffc0000000000 RDI: ffffffff840e32c8\n[    1.570786] RBP: ffffffffa0000000 R08: 0000000000000000 R09: 0000000000000000\n[    1.570786] R10: ffff888007787a88 R11: ffffffff8475d8e7 R12: ffffffff83e80ff8\n[    1.570786] R13: 0000000000000640 R14: 0000000000000640 R15: 0000000000000640\n[    1.570786] FS:  0000000000000000(0000) GS:ffff88806cc00000(0000) knlGS:0000000000000000\n[    1.570786] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[    1.570786] CR2: ffff888006a01000 CR3: 0000000003e80000 CR4: 0000000000350ef0\n[    1.570786] Call Trace:\n[    1.570786]  <TASK>\n[    1.570786]  ? __die_body+0x1b/0x58\n[    1.570786]  ? die+0x31/0x4b\n[    1.570786]  ? do_trap+0x9d/0x138\n[    1.570786]  ? vmalloc_to_page+0x48/0x1ec\n[    1.570786]  ? do_error_trap+0xcd/0x102\n[    1.570786]  ? vmalloc_to_page+0x48/0x1ec\n[    1.570786]  ? vmalloc_to_page+0x48/0x1ec\n[    1.570786]  ? handle_invalid_op+0x2f/0x38\n[    1.570786]  ? vmalloc_to_page+0x48/0x1ec\n[    1.570786]  ? exc_invalid_op+0x2b/0x41\n[    1.570786]  ? asm_exc_invalid_op+0x16/0x20\n[    1.570786]  ? vmalloc_to_page+0x26/0x1ec\n[    1.570786]  ? vmalloc_to_page+0x48/0x1ec\n[    1.570786]  __text_poke+0xb6/0x458\n[    1.570786]  ? __pfx_text_poke_memcpy+0x10/0x10\n[    1.570786]  ? __pfx___mutex_lock+0x10/0x10\n[    1.570786]  ? __pfx___text_poke+0x10/0x10\n[    1.570786]  ? __pfx_get_random_u32+0x10/0x10\n[    1.570786]  ? srso_return_thunk+0x5/0x5f\n[    1.570786]  text_poke_copy_locked+0x70/0x84\n[    1.570786]  text_poke_copy+0x32/0x4f\n[    1.570786]  bpf_arch_text_copy+0xf/0x27\n[    1.570786]  bpf_jit_binary_pack_finalize+0x26/0x5a\n[    1.570786]  bpf_int_jit_compile+0x576/0x8ad\n[    1.570786]  ? __pfx_bpf_int_jit_compile+0x10/0x10\n[    1.570786]  ? srso_return_thunk+0x5/0x5f\n[    1.570786]  ? __kmalloc_node_track_caller+0x2b5/0x2e0\n[    1.570786]  bpf_prog_select_runtime+0x7c/0x199\n[    1.570786]  bpf_prepare_filter+0x1e9/0x25b\n[    1.570786]  ? __pfx_bpf_prepare_filter+0x10/0x10\n[    1.570786]  ? srso_return_thunk+0x5/0x5f\n[    1.570786]  ? _find_next_bit+0x29/0x7e\n[    1.570786]  bpf_prog_create+0xb8/0xe0\n[    1.570786]  ptp_classifier_init+0x75/0xa1\n[    1.570786]  ? __pfx_ptp_classifier_init+0x10/0x10\n[    1.570786]  ? srso_return_thunk+0x5/0x5f\n[    1.570786]  ? register_pernet_subsys+0x36/0x42\n[    1.570786]  ? srso_return_thunk+0x5/0x5f\n[    1.570786]  sock_init+0x99/0xa3\n[    1.570786]  ? __pfx_sock_init+0x10/0x10\n[    1.570786]  do_one_initcall+0x104/0x2c4\n[    1.570786]  ? __pfx_do_one_initcall+0x10/0x10\n[    1.570786]  ? parameq+0x25/0x2d\n[    1.570786]  ? rcu_is_watching+0x1c/0x3c\n[    1.570786]  ? trace_kmalloc+0x81/0xb2\n[    1.570786]  ? srso_return_thunk+0x5/0x5f\n[    1.570786]  ? __kmalloc+0x29c/0x2c7\n[    1.570786]  ? srso_return_thunk+0x5/0x5f\n[    1.570786]  do_initcalls+0xf9/0x123\n[    1.570786]  kernel_init_freeable+0x24f/0x289\n[    1.570786]  ? __pfx_kernel_init+0x10/0x10\n[    1.570786]  kernel_init+0x19/0x13a\n[    1.570786]  ret_from_fork+0x24/0x41\n[    1.570786]  ? __pfx_kernel_init+0x10/0x10\n[    1.570786]  ret_from_fork_asm+0x1a/0x30\n[    1.570786]  </TASK>\n[    1.570819] ---[ end trace 0000000000000000 ]---\n[    1.571463] RIP: 0010:vmalloc_to_page+0x48/0x1ec\n[    1.572111] Code: 0f 00 00 e8 eb 1a 05 00 b8 37 00 00 00 48 ba fe ff ff ff ff 1f 00 00 4c 03 25 76 49 c6 02 48 c1 e0 28 48 01 e8 48 39 d0 76 02 <0f> 0b 4c 89 e7 e8 bf 1a 05 00 49 8b 04 24 48 a9 9f ff ff ff 0f 84\n[    1.574632] RSP: 0018:ffff888007787960 EFLAGS: 00010212\n[    1.575129] RAX: 000036ffa0000000 RBX: 0000000000000640 RCX: ffffffff8147e93c\n[    1.576097] RDX: 00001ffffffffffe RSI: dffffc0000000000 RDI: ffffffff840e32c8\n[    1.577084] RBP: ffffffffa0000000 R08: 0000000000000000 R09: 0000000000000000\n[    1.578077] R10: ffff888007787a88 R11: ffffffff8475d8e7 R12: ffffffff83e80ff8\n[    1.578810] R13: 0000000000000640 R14: 0000000000000640 R15: 0000000000000640\n[    1.579823] FS:  0000000000000000(0000) GS:ffff88806cc00000(0000) knlGS:0000000000000000\n[    1.580992] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[    1.581869] CR2: ffff888006a01000 CR3: 0000000003e80000 CR4: 0000000000350ef0\n[    1.582800] Kernel panic - not syncing: Fatal exception\n[    1.583765] ---[ end Kernel panic - not syncing: Fatal exception ]---\n\nFix this by checking CONFIG_EXECMEM instead.\n\nLink: https://lkml.kernel.org/r/20240528160838.102223-1-xiyou.wangcong@gmail.com\nFixes: 2c9e5d4a0082 (""bpf: remove CONFIG_BPF_JIT dependency on CONFIG_MODULES of"")\nSigned-off-by: Cong Wang <cong.wang@bytedance.com>\nAcked-by: Mike Rapoport (IBM) <rppt@kernel.org>\nCc: Luis Chamberlain <mcgrof@kernel.org>\nCc: Daniel Borkmann <daniel@iogearbox.net>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\n', '']",Check CONFIG_EXECMEM in is_vmalloc_or_module_addr after changes to BPF JIT dependencies.,"CONFIG_EXECMEM,BPF JIT,is_vmalloc_or_module_addr",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
886bf9172da06a85de3c68a651477d7d625fd6cc,886bf9172da06a85de3c68a651477d7d625fd6cc,Jakub Kicinski,kuba@kernel.org,1717639387,Jakub Kicinski,kuba@kernel.org,1717639388,99a6d9cfae97c0192997ef37d347896bb3d447d6,323a359f9b077f382f4483023d096a4d316fd135 03e38d315f3c5258270ad50f2ae784b6372e87c3,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Daniel Borkmann says:

====================
pull-request: bpf 2024-06-05

We've added 8 non-merge commits during the last 6 day(s) which contain
a total of 9 files changed", 34 insertions(+),"[' 35 deletions(-).\n\nThe main changes are:\n\n1) Fix a potential use-after-free in bpf_link_free when the link uses\n   dealloc_deferred to free the link object but later still tests for\n   presence of link->ops->dealloc', ' from Cong Wang.\n\n2) Fix BPF test infra to set the run context for rawtp test_run callback\n   where syzbot reported a crash', ' from Jiri Olsa.\n\n3) Fix bpf_session_cookie BTF_ID in the special_kfunc_set list to exclude\n   it for the case of !CONFIG_FPROBE', ' also from Jiri Olsa.\n\n4) Fix a Coverity static analysis report to not close() a link_fd of -1\n   in the multi-uprobe feature detector', ' from Andrii Nakryiko.\n\n5) Revert support for redirect to any xsk socket bound to the same umem\n   as it can result in corrupted ring state which can lead to a crash when\n   flushing rings. A different approach will be pursued for bpf-next to\n   address it safely', ' from Magnus Karlsson.\n\n6) Fix inet_csk_accept prototype in test_sk_storage_tracing.c which caused\n   BPF CI failure after the last tree fast forwarding', ' from Andrii Nakryiko.\n\n7) Fix a coccicheck warning in BPF devmap that iterator variable cannot\n   be NULL', ' from Thorsten Blum.\n\n* tag \'for-netdev\' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  Revert ""xsk: Document ability to redirect to any socket bound to the same umem""\n  Revert ""xsk: Support redirect to any socket bound to the same umem""\n  bpf: Set run context for rawtp test_run callback\n  bpf: Fix a potential use-after-free in bpf_link_free()\n  bpf', "" devmap: Remove unnecessary if check in for loop\n  libbpf: don't close(-1) in multi-uprobe feature detector\n  bpf: Fix bpf_session_cookie BTF_ID in special_kfunc_set list\n  selftests/bpf: fix inet_csk_accept prototype in test_sk_storage_tracing.c\n====================\n\nLink: https://lore.kernel.org/r/20240605091525.22628-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n"", '']",Merged branch with 8 non-merge eBPF related commits to the netdev subsystem.,"eBPF, non-merge, netdev",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
072088704433f75dacf9e33179dd7a81f0a238d4,072088704433f75dacf9e33179dd7a81f0a238d4,Andrii Nakryiko,andrii@kernel.org,1717546589,Daniel Borkmann,daniel@iogearbox.net,1717599285,c065cbeac46ce990353dc6a9f25ff8da7177a17b,e1a8630291fde2a0edac2955e3df48587dac9906,"libbpf: Remove callback-based type/string BTF field visitor helpers

Now that all libbpf/bpftool code switched to btf_field_iter"," remove
btf_type_visit_type_ids() and btf_type_visit_str_offs() callback-based
helpers as not needed anymore.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Tested-by: Alan Maguire <alan.maguire@oracle.com>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Link: https://lore.kernel.org/bpf/20240605001629.4061937-6-andrii@kernel.org
",[''],The commit removes callback-based type/string BTF field visitor helpers from libbpf as they are now unnecessary.,"libbpf,BTF,helpers",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e1a8630291fde2a0edac2955e3df48587dac9906,e1a8630291fde2a0edac2955e3df48587dac9906,Andrii Nakryiko,andrii@kernel.org,1717546588,Daniel Borkmann,daniel@iogearbox.net,1717599281,ebacd0fe8e6d496e80d78e9a14af3d39bdc52525,c2641123696b572a3b059e1b45777317ba9f9086,"bpftool: Use BTF field iterator in btfgen

Switch bpftool's code which is using libbpf-internal
btf_type_visit_type_ids() helper to new btf_field_iter functionality.

This makes bpftool code simpler"," but also unblocks removing libbpf's
btf_type_visit_type_ids() helper completely.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Tested-by: Alan Maguire <alan.maguire@oracle.com>
Reviewed-by: Quentin Monnet <qmo@kernel.org>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Link: https://lore.kernel.org/bpf/20240605001629.4061937-5-andrii@kernel.org
",[''],Replaced bpftool's libbpf-internal functionality with a new btf field iterator for simplification.,"bpftool,BTF iterator,simplification",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The bpftool utility,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c2641123696b572a3b059e1b45777317ba9f9086,c2641123696b572a3b059e1b45777317ba9f9086,Andrii Nakryiko,andrii@kernel.org,1717546587,Daniel Borkmann,daniel@iogearbox.net,1717599277,cb5c3b3155a1e4553d66c1860cca69bd548c4807,2bce2c1cb2f0acbf619737a10575f99df0c43984,"libbpf: Make use of BTF field iterator in BTF handling code

Use new BTF field iterator logic to replace all the callback-based
visitor calls. There is still a .BTF.ext callback-based visitor APIs
that should be converted"," which will happens as a follow up.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Tested-by: Alan Maguire <alan.maguire@oracle.com>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Link: https://lore.kernel.org/bpf/20240605001629.4061937-4-andrii@kernel.org
",[''],The commit replaces callback-based visitor calls with a BTF field iterator in the libbpf code.,"BTF,libbpf,iterator",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2bce2c1cb2f0acbf619737a10575f99df0c43984,2bce2c1cb2f0acbf619737a10575f99df0c43984,Andrii Nakryiko,andrii@kernel.org,1717546586,Daniel Borkmann,daniel@iogearbox.net,1717599272,000ced203a6a1054130b9a5848f29915b9ea67ad,68153bb2fffbe59804370e514482f95c4b2053ff,"libbpf: Make use of BTF field iterator in BPF linker code

Switch all BPF linker code dealing with iterating BTF type ID and string
offset fields to new btf_field_iter facilities.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Tested-by: Alan Maguire <alan.maguire@oracle.com>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Link: https://lore.kernel.org/bpf/20240605001629.4061937-3-andrii@kernel.org
",,Utilize BTF field iterator in BPF linker code for type ID and string offset fields.,BTF iterator linker,It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
68153bb2fffbe59804370e514482f95c4b2053ff,68153bb2fffbe59804370e514482f95c4b2053ff,Andrii Nakryiko,andrii@kernel.org,1717546585,Daniel Borkmann,daniel@iogearbox.net,1717599266,130e88dd4f4f856a770497b71bb4a05fa565ed98,898ac74c5b5f8b551a377d6a60ca4e30023ac9d2,"libbpf: Add BTF field iterator

Implement iterator-based type ID and string offset BTF field iterator.
This is used extensively in BTF-handling code and BPF linker code for
various sanity checks", rewriting IDs/offsets,"[' etc. Currently this is\nimplemented as visitor pattern calling custom callbacks', ' which makes the\nlogic (especially in simple cases) unnecessarily obscure and harder to\nfollow.\n\nHaving equivalent functionality using iterator pattern makes for simpler\nto understand and maintain code. As we add more code for BTF processing\nlogic in libbpf', "" it's best to switch to iterator pattern before adding\nmore callback-based code.\n\nThe idea for iterator-based implementation is to record offsets of\nnecessary fields within fixed btf_type parts (which should be iterated\njust once)"", ' and', ' for kinds that have multiple members (based on vlen\nfield)', ' record where in each member necessary fields are located.\n\nGeneric iteration code then just keeps track of last offset that was\nreturned and handles N members correctly. Return type is just u32\npointer', ' where NULL is returned when all relevant fields were already\niterated.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Alan Maguire <alan.maguire@oracle.com>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/bpf/20240605001629.4061937-2-andrii@kernel.org\n', '']",Introduce BTF field iterator for improved type ID and offset management in libbpf.,"BTF,iterator,libbpf",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ca9680821dfec73c9100860bda4fab1f1309722e,ca9680821dfec73c9100860bda4fab1f1309722e,Namhyung Kim,namhyung@kernel.org,1716311260,Arnaldo Carvalho de Melo,acme@redhat.com,1717597980,181f96f89f2f88b2550b6379242e70e64e08f646,5b3cde198878b2f3269d5e7efbc0d514899b1fd8,"perf bpf: Fix handling of minimal vmlinux.h file when interrupting the build

Ingo reported that he was seeing these when hitting Control+C during a
perf tools build:

  Makefile.perf:1149: *** Missing bpftool input for generating vmlinux.h. Stop.

The failure happens when you don't have vmlinux.h or vmlinux with BTF.

ifeq ($(VMLINUX_H)",")
  ifeq ($(VMLINUX_BTF)","["")\n    $(error Missing bpftool input for generating vmlinux.h)\n  endif\nendif\n\nVMLINUX_BTF can be empty if you didn't build a kernel or it doesn't have\na BTF section and the current kernel also has no BTF.  This is totally\nok.\n\nBut VMLINUX_H should be set to the minimal version in the source tree\n(unless you overwrite it manually) when you don't pass GEN_VMLINUX_H=1\n(which requires VMLINUX_BTF should not be empty).  The problem is that\nit's defined in Makefile.config which is not included for `make clean`.\n\nReported-by: Ingo Molnar <mingo@kernel.org>\nSigned-off-by: Namhyung Kim <namhyung@kernel.org>\nTested-by: Ingo Molnar <mingo@kernel.org>\nCc: Adrian Hunter <adrian.hunter@intel.com>\nCc: Ian Rogers <irogers@google.com>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: Kan Liang <kan.liang@linux.intel.com>\nLink: http://lore.kernel.org/lkml/CAM9d7ch5HTr+k+_GpbMrX0HUo5BZ11byh1xq0Two7B7RQACuNw@mail.gmail.com\nLink: http://lore.kernel.org/lkml/ZjssGrj+abyC6mYP@gmail.com\nSigned-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>\n"", '']",The commit fixes handling of minimal vmlinux.h file when interrupting the perf tools build process.,"perf bpf,vmlinux.h,build error",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The bpftool utility,"[""It's not related to any of the above.""]"
491aee894a08bc9b8bb52e7363b9d4bc6403f363,491aee894a08bc9b8bb52e7363b9d4bc6403f363,Taehee Yoo,ap420073@gmail.com,1717390675,David S. Miller,davem@davemloft.net,1717580967,6a7b9033236d98a1b934d9e88fa62caf21264944,0a8d3f2e3e8d8aea8af017e14227b91d5989b696,"ionic: fix kernel panic in XDP_TX action

In the XDP_TX path"," ionic driver sends a packet to the TX path with rx
page and corresponding dma address.
After tx is done","["" ionic_tx_clean() frees that page.\nBut RX ring buffer isn't reset to NULL.\nSo"", ' it uses a freed page', ' which causes kernel panic.\n\nBUG: unable to handle page fault for address: ffff8881576c110c\nPGD 773801067 P4D 773801067 PUD 87f086067 PMD 87efca067 PTE 800ffffea893e060\nOops: Oops: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC KASAN NOPTI\nCPU: 1 PID: 25 Comm: ksoftirqd/1 Not tainted 6.9.0+ #11\nHardware name: ASUS System Product Name/PRIME Z690-P D4', ' BIOS 0603 11/01/2021\nRIP: 0010:bpf_prog_f0b8caeac1068a55_balancer_ingress+0x3b/0x44f\nCode: 00 53 41 55 41 56 41 57 b8 01 00 00 00 48 8b 5f 08 4c 8b 77 00 4c 89 f7 48 83 c7 0e 48 39 d8\nRSP: 0018:ffff888104e6fa28 EFLAGS: 00010283\nRAX: 0000000000000002 RBX: ffff8881576c1140 RCX: 0000000000000002\nRDX: ffffffffc0051f64 RSI: ffffc90002d33048 RDI: ffff8881576c110e\nRBP: ffff888104e6fa88 R08: 0000000000000000 R09: ffffed1027a04a23\nR10: 0000000000000000 R11: 0000000000000000 R12: ffff8881b03a21a8\nR13: ffff8881589f800f R14: ffff8881576c1100 R15: 00000001576c1100\nFS: 0000000000000000(0000) GS:ffff88881ae00000(0000) knlGS:0000000000000000\nCS: 0010 DS: 0000 ES: 0000 CR0: 0000000080050033\nCR2: ffff8881576c110c CR3: 0000000767a90000 CR4: 00000000007506f0\nPKRU: 55555554\nCall Trace:\n<TASK>\n? __die+0x20/0x70\n? page_fault_oops+0x254/0x790\n? __pfx_page_fault_oops+0x10/0x10\n? __pfx_is_prefetch.constprop.0+0x10/0x10\n? search_bpf_extables+0x165/0x260\n? fixup_exception+0x4a/0x970\n? exc_page_fault+0xcb/0xe0\n? asm_exc_page_fault+0x22/0x30\n? 0xffffffffc0051f64\n? bpf_prog_f0b8caeac1068a55_balancer_ingress+0x3b/0x44f\n? do_raw_spin_unlock+0x54/0x220\nionic_rx_service+0x11ab/0x3010 [ionic 9180c3001ab627d82bbc5f3ebe8a0decaf6bb864]\n? ionic_tx_clean+0x29b/0xc60 [ionic 9180c3001ab627d82bbc5f3ebe8a0decaf6bb864]\n? __pfx_ionic_tx_clean+0x10/0x10 [ionic 9180c3001ab627d82bbc5f3ebe8a0decaf6bb864]\n? __pfx_ionic_rx_service+0x10/0x10 [ionic 9180c3001ab627d82bbc5f3ebe8a0decaf6bb864]\n? ionic_tx_cq_service+0x25d/0xa00 [ionic 9180c3001ab627d82bbc5f3ebe8a0decaf6bb864]\n? __pfx_ionic_rx_service+0x10/0x10 [ionic 9180c3001ab627d82bbc5f3ebe8a0decaf6bb864]\nionic_cq_service+0x69/0x150 [ionic 9180c3001ab627d82bbc5f3ebe8a0decaf6bb864]\nionic_txrx_napi+0x11a/0x540 [ionic 9180c3001ab627d82bbc5f3ebe8a0decaf6bb864]\n__napi_poll.constprop.0+0xa0/0x440\nnet_rx_action+0x7e7/0xc30\n? __pfx_net_rx_action+0x10/0x10\n\nFixes: 8eeed8373e1c (""ionic: Add XDP_TX support"")\nSigned-off-by: Taehee Yoo <ap420073@gmail.com>\nReviewed-by: Shannon Nelson <shannon.nelson@amd.com>\nReviewed-by: Brett Creeley <brett.creeley@amd.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>\n', '']",Fix kernel panic issue in the XDP_TX action of the ionic driver.,"kernel panic,XDP_TX ionic",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['xdp like programs']
03e38d315f3c5258270ad50f2ae784b6372e87c3,03e38d315f3c5258270ad50f2ae784b6372e87c3,Magnus Karlsson,magnus.karlsson@intel.com,1717504166,Daniel Borkmann,daniel@iogearbox.net,1717573385,1483bf8d691058a81cfbc547b4516272edd8dc97,7fcf26b315bbb728036da0862de6b335da83dff2,"Revert ""xsk: Document ability to redirect to any socket bound to the same umem""

This reverts commit 968595a93669b6b4f6d1fcf80cf2d97956b6868f.

Reported-by: Yuval El-Hanany <YuvalE@radware.com>
Signed-off-by: Magnus Karlsson <magnus.karlsson@intel.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/xdp-newbies/8100DBDC-0B7C-49DB-9995-6027F6E63147@radware.com
Link: https://lore.kernel.org/bpf/20240604122927.29080-3-magnus.karlsson@gmail.com
",,This commit reverts a previous documentation update regarding xsk socket redirection.,"revert,xsk,umem",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['socket like programs']
7fcf26b315bbb728036da0862de6b335da83dff2,7fcf26b315bbb728036da0862de6b335da83dff2,Magnus Karlsson,magnus.karlsson@intel.com,1717504165,Daniel Borkmann,daniel@iogearbox.net,1717573350,7d19b4d26135482b39c0febf4f7ef56fe0eec936,d0d1df8ba18abc57f28fb3bc053b2bf319367f2c,"Revert ""xsk: Support redirect to any socket bound to the same umem""

This reverts commit 2863d665ea41282379f108e4da6c8a2366ba66db.

This patch introduced a potential kernel crash when multiple napi instances
redirect to the same AF_XDP socket. By removing the queue_index check"," it is
possible for multiple napi instances to access the Rx ring at the same time","['\nwhich will result in a corrupted ring state which can lead to a crash when\nflushing the rings in __xsk_flush(). This can happen when the linked list of\nsockets to flush gets corrupted by concurrent accesses. A quick and small fix\nis not possible', ' so let us revert this for now.\n\nReported-by: Yuval El-Hanany <YuvalE@radware.com>\nSigned-off-by: Magnus Karlsson <magnus.karlsson@intel.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/xdp-newbies/8100DBDC-0B7C-49DB-9995-6027F6E63147@radware.com\nLink: https://lore.kernel.org/bpf/20240604122927.29080-2-magnus.karlsson@gmail.com\n', '']",Revert commit 2863d665ea4 due to potential kernel crash with xsk redirect to same AF_XDP socket.,"Revert, xsk, AF_XDP",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['socket like programs', 'other']"
d0d1df8ba18abc57f28fb3bc053b2bf319367f2c,d0d1df8ba18abc57f28fb3bc053b2bf319367f2c,Jiri Olsa,jolsa@kernel.org,1717513224,Daniel Borkmann,daniel@iogearbox.net,1717573293,8292b3906975a234bf0fcb5c6aa5e5629d656703,2884dc7d08d98a89d8d65121524bb7533183a63a,"bpf: Set run context for rawtp test_run callback

syzbot reported crash when rawtp program executed through the
test_run interface calls bpf_get_attach_cookie helper or any
other helper that touches task->bpf_ctx pointer.

Setting the run context (task->bpf_ctx pointer) for test_run
callback.

Fixes: 7adfc6c9b315 (""bpf: Add bpf_get_attach_cookie() BPF helper to access bpf_cookie value"")
Reported-by: syzbot+3ab78ff125b7979e45f9@syzkaller.appspotmail.com
Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Closes: https://syzkaller.appspot.com/bug?extid=3ab78ff125b7979e45f9
Link: https://lore.kernel.org/bpf/20240604150024.359247-1-jolsa@kernel.org
",,Fixes crash by setting run context for raw tracepoint test_run callbacks in BPF.,"run context, rawtp, crash",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
898ac74c5b5f8b551a377d6a60ca4e30023ac9d2,898ac74c5b5f8b551a377d6a60ca4e30023ac9d2,Yonghong Song,yonghong.song@linux.dev,1717524034,Andrii Nakryiko,andrii@kernel.org,1717530584,76f7ebe742e88529d202b954570abf3b98828462,61ce0ea7591fef2eb6e89ce40ffcc24fda4dbbc5,"selftests/bpf: Ignore .llvm.<hash> suffix in kallsyms_find()

I hit the following failure when running selftests with
internal backported upstream kernel:
  test_ksyms:PASS:kallsyms_fopen 0 nsec
  test_ksyms:FAIL:ksym_find symbol 'bpf_link_fops' not found
  #123     ksyms:FAIL

In /proc/kallsyms"," we have
  $ cat /proc/kallsyms | grep bpf_link_fops
  ffffffff829f0cb0 d bpf_link_fops.llvm.12608678492448798416
The CONFIG_LTO_CLANG_THIN is enabled in the kernel which is responsible
for bpf_link_fops.llvm.12608678492448798416 symbol name.

In prog_tests/ksyms.c we have
  kallsyms_find(""bpf_link_fops""","[' &link_fops_addr)\nand kallsyms_find() compares ""bpf_link_fops"" with symbols\nin /proc/kallsyms in order to find the entry. With\nbpf_link_fops.llvm.<hash> in /proc/kallsyms', ' the kallsyms_find()\nfailed.\n\nTo fix the issue', ' in kallsyms_find()', ' if a symbol has suffix\n.llvm.<hash>', ' that suffix will be ignored for comparison.\nThis fixed the test failure.\n\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240604180034.1356016-1-yonghong.song@linux.dev\n', '']",Fix kallsyms_find() to ignore .llvm.<hash> suffix for proper symbol resolution in selftests.,"selftests,kallsyms,llvm",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
61ce0ea7591fef2eb6e89ce40ffcc24fda4dbbc5,61ce0ea7591fef2eb6e89ce40ffcc24fda4dbbc5,Song Liu,song@kernel.org,1717484820,Andrii Nakryiko,andrii@kernel.org,1717525074,09649074f6ebde1305acef37c57614fa3b0e9d0d,49df0019f36798d414e6b913bec30a3a0cd47c70,"selftests/bpf: Fix bpf_cookie and find_vma in nested VM

bpf_cookie and find_vma are flaky in nested VMs"," which is used by some CI
systems. It turns out these failures are caused by unreliable perf event
in nested VM. Fix these by:

  1. Use PERF_COUNT_SW_CPU_CLOCK in find_vma;
  2. Increase sample_freq in bpf_cookie.

Signed-off-by: Song Liu <song@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240604070700.3032142-1-song@kernel.org
",[''],Fix unreliable perf event issues in bpf_cookie and find_vma selftests within nested VMs.,"bpf_cookie,nested VM,perf event",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tracepoints like programs']
8d4e21bd4cca8013d2c6f55d42df85838d4ebce6,8d4e21bd4cca8013d2c6f55d42df85838d4ebce6,Steven Rostedt (Google),rostedt@goodmis.org,1717441651,Steven Rostedt (Google),rostedt@goodmis.org,1717511920,968096b521d877f1f7c982a878ba1471953cfa40,35b944a997e25962122c3dea68b020e7fbb06cbd,"selftests/ftrace: Add fgraph-multi.tc test

Add a test that creates 3 instances and enables function_graph tracer in
each as well as the top instance"," where each will enable a filter (but one
that traces all functions) and check that they are filtering properly.

Link: https://lore.kernel.org/linux-trace-kernel/20240603190825.252845939@goodmis.org

Cc: Masami Hiramatsu <mhiramat@kernel.org>
Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Cc: Florent Revest <revest@chromium.org>
Cc: Martin KaFai Lau <martin.lau@linux.dev>
Cc: bpf <bpf@vger.kernel.org>
Cc: Sven Schnelle <svens@linux.ibm.com>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Alan Maguire <alan.maguire@oracle.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Guo Ren <guoren@kernel.org>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
",[''],Add selftest for function_graph tracing with multiple instances and filtering.,"selftests,ftrace,function_graph",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['kprobe/uprobe/ftrace like programs']
35b944a997e25962122c3dea68b020e7fbb06cbd,35b944a997e25962122c3dea68b020e7fbb06cbd,Steven Rostedt (Google),rostedt@goodmis.org,1717441650,Steven Rostedt (Google),rostedt@goodmis.org,1717511908,d34e10d0ee5a6fdef94a187a211e0819a4c27f13,fe835e3ca40e172aa8ad12f4ed2898c181fafab0,"selftests/ftrace: Add function_graph tracer to func-filter-pid test

The function tracer is tested to see if pid filtering works. Add a test to
test function_graph tracer as well"," but only if the function_graph tracer
is enabled for the top level or instance.

Link: https://lore.kernel.org/linux-trace-kernel/20240603190825.083048115@goodmis.org

Cc: Masami Hiramatsu <mhiramat@kernel.org>
Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Cc: Florent Revest <revest@chromium.org>
Cc: Martin KaFai Lau <martin.lau@linux.dev>
Cc: bpf <bpf@vger.kernel.org>
Cc: Sven Schnelle <svens@linux.ibm.com>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Alan Maguire <alan.maguire@oracle.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Guo Ren <guoren@kernel.org>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
",[''],The commit adds a test for the function_graph tracer to check if pid filtering works in selftests for ftrace.,"function_graph,tracer,pid-filtering",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tracepoints like programs']
fe835e3ca40e172aa8ad12f4ed2898c181fafab0,fe835e3ca40e172aa8ad12f4ed2898c181fafab0,Steven Rostedt (Google),rostedt@goodmis.org,1717441649,Steven Rostedt (Google),rostedt@goodmis.org,1717511903,bd6d3f769d470731a3067a5b9f5840761ef6727b,cc60ee813b50334b32343861057dc9e981e9c7f0,"function_graph: Use static_call and branch to optimize return function

In most cases function graph is used by a single user. Instead of calling
a loop to call function graph callbacks in this case"," call the function
return callback directly.

Use the static_key that is set when the function graph tracer has less
than 2 callbacks registered. It will do the direct call in that case","[' and\nwill do the loop over all callers when there are 2 or more callbacks\nregistered.\n\nLink: https://lore.kernel.org/linux-trace-kernel/20240603190824.921460797@goodmis.org\n\nCc: Masami Hiramatsu <mhiramat@kernel.org>\nCc: Mark Rutland <mark.rutland@arm.com>\nCc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>\nCc: Andrew Morton <akpm@linux-foundation.org>\nCc: Alexei Starovoitov <alexei.starovoitov@gmail.com>\nCc: Florent Revest <revest@chromium.org>\nCc: Martin KaFai Lau <martin.lau@linux.dev>\nCc: bpf <bpf@vger.kernel.org>\nCc: Sven Schnelle <svens@linux.ibm.com>\nCc: Alexei Starovoitov <ast@kernel.org>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: Arnaldo Carvalho de Melo <acme@kernel.org>\nCc: Daniel Borkmann <daniel@iogearbox.net>\nCc: Alan Maguire <alan.maguire@oracle.com>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Thomas Gleixner <tglx@linutronix.de>\nCc: Guo Ren <guoren@kernel.org>\nReviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\nSigned-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>\n', '']",Optimize function graph tracer by using static calls for single callback scenarios.,"function_graph, static_call, optimize",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
cc60ee813b50334b32343861057dc9e981e9c7f0,cc60ee813b50334b32343861057dc9e981e9c7f0,Steven Rostedt (Google),rostedt@goodmis.org,1717441648,Steven Rostedt (Google),rostedt@goodmis.org,1717511895,32fd28b25122cc9da91ff5a07a0ed54b4001294c,a5b6d4da0218a0539c36ad6794c624c2c6ca7b32,"function_graph: Use static_call and branch to optimize entry function

In most cases function graph is used by a single user. Instead of calling
a loop to call function graph callbacks in this case"," call the function
entry callback directly.

Add a static_key that will be used to set the function graph logic to
either do the loop (when more than one callback is registered) or to call
the callback directly if there is only one registered callback.

Link: https://lore.kernel.org/linux-trace-kernel/20240603190824.766858241@goodmis.org

Cc: Masami Hiramatsu <mhiramat@kernel.org>
Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Cc: Florent Revest <revest@chromium.org>
Cc: Martin KaFai Lau <martin.lau@linux.dev>
Cc: bpf <bpf@vger.kernel.org>
Cc: Sven Schnelle <svens@linux.ibm.com>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Alan Maguire <alan.maguire@oracle.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Guo Ren <guoren@kernel.org>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
",[''],Optimize function graph entry function by using static_call and branch to reduce overhead when only one callback is registered.,"function_graph, static_call, optimization",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a5b6d4da0218a0539c36ad6794c624c2c6ca7b32,a5b6d4da0218a0539c36ad6794c624c2c6ca7b32,Steven Rostedt (Google),rostedt@goodmis.org,1717441647,Steven Rostedt (Google),rostedt@goodmis.org,1717511890,895eca6404b350d6b0ebca968469bc59bdd1d3b3,420e1354bcb6f006f183a1b6fe5dd21f60a457ef,"function_graph: Use bitmask to loop on fgraph entry

Instead of looping through all the elements of fgraph_array[] to see if
there's an gops attached to one and then calling its gops->func(). Create
a fgraph_array_bitmask that sets bits when an index in the array is
reserved (via the simple lru algorithm). Then only the bits set in this
bitmask needs to be looked at where only elements in the array that have
ops registered need to be looked at.

Note"," we do not care about races. If a bit is set before the gops is
assigned","[' it only wastes time looking at the element and ignoring it (as\nit did before this bitmask is added).\n\nLink: https://lore.kernel.org/linux-trace-kernel/20240603190824.604448781@goodmis.org\n\nCc: Mark Rutland <mark.rutland@arm.com>\nCc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>\nCc: Andrew Morton <akpm@linux-foundation.org>\nCc: Alexei Starovoitov <alexei.starovoitov@gmail.com>\nCc: Florent Revest <revest@chromium.org>\nCc: Martin KaFai Lau <martin.lau@linux.dev>\nCc: bpf <bpf@vger.kernel.org>\nCc: Sven Schnelle <svens@linux.ibm.com>\nCc: Alexei Starovoitov <ast@kernel.org>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: Arnaldo Carvalho de Melo <acme@kernel.org>\nCc: Daniel Borkmann <daniel@iogearbox.net>\nCc: Alan Maguire <alan.maguire@oracle.com>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Thomas Gleixner <tglx@linutronix.de>\nCc: Guo Ren <guoren@kernel.org>\nReviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\nSigned-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>\n', '']",The commit optimizes function graph processing using a bitmask for improved performance in handling function operations.,"bitmask, fgraph, optimization",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,['tracepoints like programs']
420e1354bcb6f006f183a1b6fe5dd21f60a457ef,420e1354bcb6f006f183a1b6fe5dd21f60a457ef,Steven Rostedt (Google),rostedt@goodmis.org,1717441646,Steven Rostedt (Google),rostedt@goodmis.org,1717511883,3844c1a6a79d464f0eb90ac9543b95977c71c208,dd120af2d5f8f3d2d742a64cefc4a529d382ab06,"function_graph: Use for_each_set_bit() in __ftrace_return_to_handler()

Instead of iterating through the entire fgraph_array[] and seeing if one
of the bitmap bits are set to know to call the array's retfunc() function","
use for_each_set_bit() on the bitmap itself. This will only iterate for
the number of set bits.

Link: https://lore.kernel.org/linux-trace-kernel/20240603190824.447448026@goodmis.org

Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Cc: Florent Revest <revest@chromium.org>
Cc: Martin KaFai Lau <martin.lau@linux.dev>
Cc: bpf <bpf@vger.kernel.org>
Cc: Sven Schnelle <svens@linux.ibm.com>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Alan Maguire <alan.maguire@oracle.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Guo Ren <guoren@kernel.org>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
",[''],Optimized function_graph handling by using for_each_set_bit to iterate only over set bits in __ftrace_return_to_handler().,"function_graph,for_each_set_bit,ftrace",It's a performance optimization.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
dd120af2d5f8f3d2d742a64cefc4a529d382ab06,dd120af2d5f8f3d2d742a64cefc4a529d382ab06,Masami Hiramatsu (Google),mhiramat@kernel.org,1717441645,Steven Rostedt (Google),rostedt@goodmis.org,1717511879,b7cef75f1573193f1faaf0e8c3f0d36665e7bb41,47c3c70aa36971c90e32e91f9254110195d67a02,"ftrace: Add multiple fgraph storage selftest

Add a selftest for multiple function graph tracer with storage on a same
function. In this case"," the shadow stack entry will be shared among those
fgraph with different data storage. So this will ensure the fgraph will
not mixed those storage data.

Link: https://lore.kernel.org/linux-trace-kernel/171509111465.162236.3795819216426570800.stgit@devnote2
Link: https://lore.kernel.org/linux-trace-kernel/20240603190824.284049716@goodmis.org

Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Cc: Florent Revest <revest@chromium.org>
Cc: Martin KaFai Lau <martin.lau@linux.dev>
Cc: bpf <bpf@vger.kernel.org>
Cc: Sven Schnelle <svens@linux.ibm.com>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Alan Maguire <alan.maguire@oracle.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Guo Ren <guoren@kernel.org>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Suggested-by: Steven Rostedt (Google) <rostedt@goodmis.org>
Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
",[''],This commit adds a selftest for multiple function graph tracer with shared storage to ensure data is not mixed.,"ftrace,selftest,fgraph",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
47c3c70aa36971c90e32e91f9254110195d67a02,47c3c70aa36971c90e32e91f9254110195d67a02,Steven Rostedt (VMware),rostedt@goodmis.org,1717441644,Steven Rostedt (Google),rostedt@goodmis.org,1717511872,dca34b7ee357a02da6371fec6546d7413e9e9ae8,91c46b0aa917546432b5b219494859cda0edc39e,"function_graph: Add selftest for passing local variables

Add boot up selftest that passes variables from a function entry to a
function exit"," and make sure that they do get passed around.

Co-developed with Masami Hiramatsu:
Link: https://lore.kernel.org/linux-trace-kernel/171509110271.162236.11047551496319744627.stgit@devnote2
Link: https://lore.kernel.org/linux-trace-kernel/20240603190824.122952310@goodmis.org

Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Cc: Florent Revest <revest@chromium.org>
Cc: Martin KaFai Lau <martin.lau@linux.dev>
Cc: bpf <bpf@vger.kernel.org>
Cc: Sven Schnelle <svens@linux.ibm.com>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Alan Maguire <alan.maguire@oracle.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Guo Ren <guoren@kernel.org>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
Signed-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
",[''],Added a boot up selftest for validating passing of local variables in function_graph tracing.,"selftest,function_graph,local variables",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
91c46b0aa917546432b5b219494859cda0edc39e,91c46b0aa917546432b5b219494859cda0edc39e,Steven Rostedt (VMware),rostedt@goodmis.org,1717441643,Steven Rostedt (Google),rostedt@goodmis.org,1717511868,d9b679ed4fb95a43862073742b8bdaafd696a72a,b84214890a9bc56f0fe4ec4fc72f2307ed05096d,"function_graph: Implement fgraph_reserve_data() and fgraph_retrieve_data()

Added functions that can be called by a fgraph_ops entryfunc and retfunc to
store state between the entry of the function being traced to the exit of
the same function. The fgraph_ops entryfunc() may call
fgraph_reserve_data() to store up to 32 words onto the task's shadow
ret_stack and this then can be retrieved by fgraph_retrieve_data() called
by the corresponding retfunc().

Co-developed with Masami Hiramatsu:
Link: https://lore.kernel.org/linux-trace-kernel/171509109089.162236.11372474169781184034.stgit@devnote2
Link: https://lore.kernel.org/linux-trace-kernel/20240603190823.959703050@goodmis.org

Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Cc: Florent Revest <revest@chromium.org>
Cc: Martin KaFai Lau <martin.lau@linux.dev>
Cc: bpf <bpf@vger.kernel.org>
Cc: Sven Schnelle <svens@linux.ibm.com>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Alan Maguire <alan.maguire@oracle.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Guo Ren <guoren@kernel.org>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
Signed-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
",,Implement functions for storing and retrieving data across function entry and exit in function graph tracing.,"fgraph, tracing, state",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b84214890a9bc56f0fe4ec4fc72f2307ed05096d,b84214890a9bc56f0fe4ec4fc72f2307ed05096d,Steven Rostedt (VMware),rostedt@goodmis.org,1717441642,Steven Rostedt (Google),rostedt@goodmis.org,1717511864,c5d46adaaa39a406fc1c87aee7c0015aacb494ff,068da098eb504469dc195137ae35eeacfe0c8de9,"function_graph: Move graph notrace bit to shadow stack global var

The use of the task->trace_recursion for the logic used for the function
graph no-trace was a bit of an abuse of that variable. Now that there
exists global vars that are per stack for registered graph traces"," use
that instead.

Link: https://lore.kernel.org/linux-trace-kernel/171509107907.162236.6564679266777519065.stgit@devnote2
Link: https://lore.kernel.org/linux-trace-kernel/20240603190823.796709456@goodmis.org

Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Cc: Florent Revest <revest@chromium.org>
Cc: Martin KaFai Lau <martin.lau@linux.dev>
Cc: bpf <bpf@vger.kernel.org>
Cc: Sven Schnelle <svens@linux.ibm.com>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Alan Maguire <alan.maguire@oracle.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Guo Ren <guoren@kernel.org>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
Signed-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
",[''],Move graph notrace logic to use shadow stack global variable instead of task trace_recursion.,"function_graph, notrace, shadow_stack",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
068da098eb504469dc195137ae35eeacfe0c8de9,068da098eb504469dc195137ae35eeacfe0c8de9,Steven Rostedt (VMware),rostedt@goodmis.org,1717441641,Steven Rostedt (Google),rostedt@goodmis.org,1717511860,0f837504ceab56bd526a25d0fa631f1e4c67824a,12117f3307b63f287756d7ec8cc4f11b94e1206a,"function_graph: Move graph depth stored data to shadow stack global var

The use of the task->trace_recursion for the logic used for the function
graph depth was a bit of an abuse of that variable. Now that there
exists global vars that are per stack for registered graph traces"," use that
instead.

Link: https://lore.kernel.org/linux-trace-kernel/171509106728.162236.2398372644430125344.stgit@devnote2
Link: https://lore.kernel.org/linux-trace-kernel/20240603190823.634870264@goodmis.org

Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Cc: Florent Revest <revest@chromium.org>
Cc: Martin KaFai Lau <martin.lau@linux.dev>
Cc: bpf <bpf@vger.kernel.org>
Cc: Sven Schnelle <svens@linux.ibm.com>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Alan Maguire <alan.maguire@oracle.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Guo Ren <guoren@kernel.org>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
Signed-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
",[''],Moved function graph depth data to global shadow stack variable for cleaner implementation.,"function_graph, shadow stack, global variable",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['tracepoints like programs']
12117f3307b63f287756d7ec8cc4f11b94e1206a,12117f3307b63f287756d7ec8cc4f11b94e1206a,Steven Rostedt (VMware),rostedt@goodmis.org,1717441640,Steven Rostedt (Google),rostedt@goodmis.org,1717511855,7cf941e3b34404039e5aa2050cd7ca4bb0237607,4497412a1f7b5d9e0849f125652f2cc58cdba562,"function_graph: Move set_graph_function tests to shadow stack global var

The use of the task->trace_recursion for the logic used for the
set_graph_function was a bit of an abuse of that variable. Now that there
exists global vars that are per stack for registered graph traces"," use that
instead.

Link: https://lore.kernel.org/linux-trace-kernel/171509105520.162236.10339831553995971290.stgit@devnote2
Link: https://lore.kernel.org/linux-trace-kernel/20240603190823.472955399@goodmis.org

Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Cc: Florent Revest <revest@chromium.org>
Cc: Martin KaFai Lau <martin.lau@linux.dev>
Cc: bpf <bpf@vger.kernel.org>
Cc: Sven Schnelle <svens@linux.ibm.com>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Alan Maguire <alan.maguire@oracle.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Guo Ren <guoren@kernel.org>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
Signed-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
",[''],Refactor function graph logic by moving set_graph_function tests to use shadow stack global variables.,"function_graph, shadow stack, refactor",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
4497412a1f7b5d9e0849f125652f2cc58cdba562,4497412a1f7b5d9e0849f125652f2cc58cdba562,Steven Rostedt (VMware),rostedt@goodmis.org,1717441639,Steven Rostedt (Google),rostedt@goodmis.org,1717511849,25a9a34da53bba0dd2539c3199f0c8d3597e6a68,6d4786592ac88aa31f45fde6bfaad3162e3a92a4,"function_graph: Add ""task variables"" per task for fgraph_ops

Add a ""task variables"" array on the tasks shadow ret_stack that is the
size of longs for each possible registered fgraph_ops. That's a total
of 16"," taking up 8 * 16 = 128 bytes (out of a page size 4k).

This will allow for fgraph_ops to do specific features on a per task basis
having a way to maintain state for each task.

Co-developed with Masami Hiramatsu:
Link: https://lore.kernel.org/linux-trace-kernel/171509104383.162236.12239656156685718550.stgit@devnote2
Link: https://lore.kernel.org/linux-trace-kernel/20240603190823.308806126@goodmis.org

Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Cc: Florent Revest <revest@chromium.org>
Cc: Martin KaFai Lau <martin.lau@linux.dev>
Cc: bpf <bpf@vger.kernel.org>
Cc: Sven Schnelle <svens@linux.ibm.com>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Alan Maguire <alan.maguire@oracle.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Guo Ren <guoren@kernel.org>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
Signed-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
",[''],Add task-specific variables to shadow ret_stack for maintaining state with fgraph_ops in function graph tracing.,"task variables,fgraph_ops,shadow ret_stack",It's a new feature.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
6d4786592ac88aa31f45fde6bfaad3162e3a92a4,6d4786592ac88aa31f45fde6bfaad3162e3a92a4,Masami Hiramatsu (Google),mhiramat@kernel.org,1717441638,Steven Rostedt (Google),rostedt@goodmis.org,1717511841,9b5f608a9e54b56f81ac6c94dbcd7dfd5297b146,df3ec5da6a1e7f6e142680d7c5266d3af187170b,"function_graph: Use a simple LRU for fgraph_array index number

Since the fgraph_array index is used for the bitmap on the shadow
stack"," it may leave some entries after a function_graph instance is
removed. Thus if another instance reuses the fgraph_array index soon
after releasing it","[' the fgraph may confuse to call the newer callback\nfor the entries which are pushed by the older instance.\nTo avoid reusing the fgraph_array index soon after releasing', ' introduce\na simple LRU table for managing the index number. This will reduce the\npossibility of this confusion.\n\nLink: https://lore.kernel.org/linux-trace-kernel/171509103267.162236.6885097397289135378.stgit@devnote2\nLink: https://lore.kernel.org/linux-trace-kernel/20240603190823.147421545@goodmis.org\n\nCc: Mark Rutland <mark.rutland@arm.com>\nCc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>\nCc: Andrew Morton <akpm@linux-foundation.org>\nCc: Alexei Starovoitov <alexei.starovoitov@gmail.com>\nCc: Florent Revest <revest@chromium.org>\nCc: Martin KaFai Lau <martin.lau@linux.dev>\nCc: bpf <bpf@vger.kernel.org>\nCc: Sven Schnelle <svens@linux.ibm.com>\nCc: Alexei Starovoitov <ast@kernel.org>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: Arnaldo Carvalho de Melo <acme@kernel.org>\nCc: Daniel Borkmann <daniel@iogearbox.net>\nCc: Alan Maguire <alan.maguire@oracle.com>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Thomas Gleixner <tglx@linutronix.de>\nCc: Guo Ren <guoren@kernel.org>\nSigned-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\nSigned-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>\n', '']",Implement a simple LRU for fgraph_array index number in function_graph to manage bitmap in shadow stack.,"LRU,fgraph_array,shadow stack",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
df3ec5da6a1e7f6e142680d7c5266d3af187170b,df3ec5da6a1e7f6e142680d7c5266d3af187170b,Steven Rostedt (Google),rostedt@goodmis.org,1717441637,Steven Rostedt (Google),rostedt@goodmis.org,1717511831,4ba7160fda7f476c0a6fb6201aa5ebbeb1af26fe,c132be2c4fcc1150ad0791c2a85dd4c9ad0bd0c8,"function_graph: Add pid tracing back to function graph tracer

Now that the function_graph has a main callback that handles the function
graph subops tracing"," it no longer honors the pid filtering of ftrace. Add
back this logic in the function_graph code to update the gops callback for
the entry function to test if it should trace the current task or not.

Link: https://lore.kernel.org/linux-trace-kernel/20240603190822.991720703@goodmis.org

Cc: Masami Hiramatsu <mhiramat@kernel.org>
Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Cc: Florent Revest <revest@chromium.org>
Cc: Martin KaFai Lau <martin.lau@linux.dev>
Cc: bpf <bpf@vger.kernel.org>
Cc: Sven Schnelle <svens@linux.ibm.com>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Alan Maguire <alan.maguire@oracle.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Guo Ren <guoren@kernel.org>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
",[''],Reintroduce PID filtering in the function graph tracer within the function_graph subsystem.,"function_graph,tracer,PID",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['kprobe/uprobe/ftrace like programs']
c132be2c4fcc1150ad0791c2a85dd4c9ad0bd0c8,c132be2c4fcc1150ad0791c2a85dd4c9ad0bd0c8,Steven Rostedt (VMware),rostedt@goodmis.org,1717441636,Steven Rostedt (Google),rostedt@goodmis.org,1717511812,a891ba9ff769864233e41cb81ad1311b668b1488,d9bbfbd14f58d2955cc7a3efa8ae6d4e09ee5995,"function_graph: Have the instances use their own ftrace_ops for filtering

Allow for instances to have their own ftrace_ops part of the fgraph_ops
that makes the funtion_graph tracer filter on the set_ftrace_filter file
of the instance and not the top instance.

This uses the new ftrace_startup_subops()"," by using graph_ops as the
""manager ops"" that defines the callback function and adds the functions
defined by the filters of the ops for each trace instance. The callback
defined by the manager ops will call the registered fgraph ops that were
added to the fgraph_array.

Co-developed with Masami Hiramatsu:
Link: https://lore.kernel.org/linux-trace-kernel/171509102088.162236.15758883237657317789.stgit@devnote2
Link: https://lore.kernel.org/linux-trace-kernel/20240603190822.832946261@goodmis.org

Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Cc: Florent Revest <revest@chromium.org>
Cc: Martin KaFai Lau <martin.lau@linux.dev>
Cc: bpf <bpf@vger.kernel.org>
Cc: Sven Schnelle <svens@linux.ibm.com>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Alan Maguire <alan.maguire@oracle.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Guo Ren <guoren@kernel.org>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
Signed-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
",[''],The commit allows function graph tracer instances to use their own ftrace_ops for filtering instead of the top instance.,"function_graph, ftrace_ops, filtering",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
d9bbfbd14f58d2955cc7a3efa8ae6d4e09ee5995,d9bbfbd14f58d2955cc7a3efa8ae6d4e09ee5995,Steven Rostedt (Google),rostedt@goodmis.org,1717441635,Steven Rostedt (Google),rostedt@goodmis.org,1717511804,4aa5cf216f061348a647b8621c5c533792c95405,5fccc7552ccbc521bad61653ee739b1196b1bc53,"ftrace: Allow subops filtering to be modified

The subops filters use a ""manager"" ops to enable and disable its filters.
The manager ops can handle more than one subops"," and its filter is what
controls what functions get set. Add a ftrace_hash_move_and_update_subops()
function that will update the manager ops when the subops filters change.

Link: https://lore.kernel.org/linux-trace-kernel/20240603190822.673932251@goodmis.org

Cc: Masami Hiramatsu <mhiramat@kernel.org>
Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Cc: Florent Revest <revest@chromium.org>
Cc: Martin KaFai Lau <martin.lau@linux.dev>
Cc: bpf <bpf@vger.kernel.org>
Cc: Sven Schnelle <svens@linux.ibm.com>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Alan Maguire <alan.maguire@oracle.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Guo Ren <guoren@kernel.org>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
",[''],Enhances ftrace by allowing suboperation filters to be modified through manager operations.,"ftrace, subops, filters",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['tracepoints like programs']
5fccc7552ccbc521bad61653ee739b1196b1bc53,5fccc7552ccbc521bad61653ee739b1196b1bc53,Steven Rostedt (Google),rostedt@goodmis.org,1717441634,Steven Rostedt (Google),rostedt@goodmis.org,1717511798,8fdeb1ddf59ef91e55db01704b43caabfdf02f6a,ab6b84630382914ffcbab59f4913c9a60971d034,"ftrace: Add subops logic to allow one ops to manage many

There are cases where a single system will use a single function callback
to handle multiple users. For example"," to allow function_graph tracer to
have multiple users where each can trace their own set of functions","[' it is\nuseful to only have one ftrace_ops registered to ftrace that will call a\nfunction by the function_graph tracer to handle the multiplexing with the\ndifferent registered  function_graph tracers.\n\nAdd a ""subop_list"" to the ftrace_ops that will hold a list of other\nftrace_ops that the top ftrace_ops will manage.\n\nThe function ftrace_startup_subops() that takes the manager ftrace_ops and\na subop ftrace_ops it will manage. If there are no subops with the\nftrace_ops yet', ' it will copy the ftrace_ops subop filters to the manager\nftrace_ops and register that with ftrace_startup()', ' and adds the subop to\nits subop_list. If the manager ops already has something registered', ' it\nwill then merge the new subop filters with what it has and enable the new\nfunctions that covers all the subops it has.\n\nTo remove a subop', ' ftrace_shutdown_subops() is called which will use the\nsubop_list of the manager ops to rebuild all the functions it needs to\ntrace', ' and update the ftrace records to only call the functions it now has\nregistered. If there are no more functions registered', ' it will then call\nftrace_shutdown() to disable itself completely.\n\nNote', ' it is up to the manager ops callback to always make sure that the\nsubops callbacks are called if its filter matches', ' as there are times in\nthe update where the callback could be calling more functions than those\nthat are currently registered.\n\nThis could be updated to handle other systems other than function_graph', '\nfor example', ' fprobes could use this (but will need an interface to call\nftrace_startup_subops()).\n\nLink: https://lore.kernel.org/linux-trace-kernel/20240603190822.508431129@goodmis.org\n\nCc: Masami Hiramatsu <mhiramat@kernel.org>\nCc: Mark Rutland <mark.rutland@arm.com>\nCc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>\nCc: Andrew Morton <akpm@linux-foundation.org>\nCc: Alexei Starovoitov <alexei.starovoitov@gmail.com>\nCc: Florent Revest <revest@chromium.org>\nCc: Martin KaFai Lau <martin.lau@linux.dev>\nCc: bpf <bpf@vger.kernel.org>\nCc: Sven Schnelle <svens@linux.ibm.com>\nCc: Alexei Starovoitov <ast@kernel.org>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: Arnaldo Carvalho de Melo <acme@kernel.org>\nCc: Daniel Borkmann <daniel@iogearbox.net>\nCc: Alan Maguire <alan.maguire@oracle.com>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Thomas Gleixner <tglx@linutronix.de>\nCc: Guo Ren <guoren@kernel.org>\nReviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\nSigned-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>\n', '']",Enhances ftrace with subops logic to support multiple users managing their own function callbacks.,"ftrace,subops,callbacks",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ab6b84630382914ffcbab59f4913c9a60971d034,ab6b84630382914ffcbab59f4913c9a60971d034,Steven Rostedt (VMware),rostedt@goodmis.org,1717441633,Steven Rostedt (Google),rostedt@goodmis.org,1717511793,dba41090f4d6aaf603e34bffa821d32d69dfb7d4,26dda5631d1bb2f254f4c94aa87ee6c92a89cfdb,"ftrace: Allow ftrace startup flags to exist without dynamic ftrace

Some of the flags for ftrace_startup() may be exposed even when
CONFIG_DYNAMIC_FTRACE is not configured in. This is fine as the difference
between dynamic ftrace and static ftrace is done within the internals of
ftrace itself. No need to have use cases fail to compile because dynamic
ftrace is disabled.

This change is needed to move some of the logic of what is passed to
ftrace_startup() out of the parameters of ftrace_startup().

Link: https://lore.kernel.org/linux-trace-kernel/171509100890.162236.4362350342549122222.stgit@devnote2
Link: https://lore.kernel.org/linux-trace-kernel/20240603190822.350654104@goodmis.org

Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Cc: Florent Revest <revest@chromium.org>
Cc: Martin KaFai Lau <martin.lau@linux.dev>
Cc: bpf <bpf@vger.kernel.org>
Cc: Sven Schnelle <svens@linux.ibm.com>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Alan Maguire <alan.maguire@oracle.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Guo Ren <guoren@kernel.org>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
Signed-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
",,Enable ftrace startup flags to function without dynamic ftrace configuration.,"ftrace, dynamic, flags",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"[""It's not related to any of the above.""]"
26dda5631d1bb2f254f4c94aa87ee6c92a89cfdb,26dda5631d1bb2f254f4c94aa87ee6c92a89cfdb,Steven Rostedt (VMware),rostedt@goodmis.org,1717441632,Steven Rostedt (Google),rostedt@goodmis.org,1717511788,745c4c9c44cd6c2b5f563f96e818eb0d0f42be5d,37238abe3cb47b8daaa8706c9949f67b2a705cf1,"ftrace: Allow function_graph tracer to be enabled in instances

Now that function graph tracing can handle more than one user"," allow it to
be enabled in the ftrace instances. Note","[' the filtering of the functions is\nstill joined by the top level set_ftrace_filter and friends', ' as well as the\ngraph and nograph files.\n\nCo-developed with Masami Hiramatsu:\nLink: https://lore.kernel.org/linux-trace-kernel/171509099743.162236.1699959255446248163.stgit@devnote2\nLink: https://lore.kernel.org/linux-trace-kernel/20240603190822.190630762@goodmis.org\n\nCc: Mark Rutland <mark.rutland@arm.com>\nCc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>\nCc: Andrew Morton <akpm@linux-foundation.org>\nCc: Alexei Starovoitov <alexei.starovoitov@gmail.com>\nCc: Florent Revest <revest@chromium.org>\nCc: Martin KaFai Lau <martin.lau@linux.dev>\nCc: bpf <bpf@vger.kernel.org>\nCc: Sven Schnelle <svens@linux.ibm.com>\nCc: Alexei Starovoitov <ast@kernel.org>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: Arnaldo Carvalho de Melo <acme@kernel.org>\nCc: Daniel Borkmann <daniel@iogearbox.net>\nCc: Alan Maguire <alan.maguire@oracle.com>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Thomas Gleixner <tglx@linutronix.de>\nCc: Guo Ren <guoren@kernel.org>\nReviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\nSigned-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>\nSigned-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\nSigned-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>\n', '']",The commit enables function graph tracing for multiple ftrace instances.,"function graph, ftrace, instances",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['tracepoints like programs']
37238abe3cb47b8daaa8706c9949f67b2a705cf1,37238abe3cb47b8daaa8706c9949f67b2a705cf1,Steven Rostedt (VMware),rostedt@goodmis.org,1717441631,Steven Rostedt (Google),rostedt@goodmis.org,1717511782,f8d8a1985cd0ba19fdd2ec2f593bee65e9ca5545,2fbb549983763b2cc32a1ab840fe59cc1822e06d,"ftrace/function_graph: Pass fgraph_ops to function graph callbacks

Pass the fgraph_ops structure to the function graph callbacks. This will
allow callbacks to add a descriptor to a fgraph_ops private field that wil
be added in the future and use it for the callbacks. This will be useful
when more than one callback can be registered to the function graph tracer.

Co-developed with Masami Hiramatsu:
Link: https://lore.kernel.org/linux-trace-kernel/171509098588.162236.4787930115997357578.stgit@devnote2
Link: https://lore.kernel.org/linux-trace-kernel/20240603190822.035147698@goodmis.org

Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Cc: Florent Revest <revest@chromium.org>
Cc: Martin KaFai Lau <martin.lau@linux.dev>
Cc: bpf <bpf@vger.kernel.org>
Cc: Sven Schnelle <svens@linux.ibm.com>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Alan Maguire <alan.maguire@oracle.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Guo Ren <guoren@kernel.org>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
Signed-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
",,The commit enables passing fgraph_ops to function graph callbacks for enhanced functionality.,"fgraph_ops,function graph,callbacks",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
2fbb549983763b2cc32a1ab840fe59cc1822e06d,2fbb549983763b2cc32a1ab840fe59cc1822e06d,Steven Rostedt (VMware),rostedt@goodmis.org,1717441630,Steven Rostedt (Google),rostedt@goodmis.org,1717511771,38d415e454f3a6ce7969c987d6b263a315d6fc5b,375bb57292f49fa0956cc2739c81749b88e69510,"function_graph: Remove logic around ftrace_graph_entry and return

The function pointers ftrace_graph_entry and ftrace_graph_return are no
longer called via the function_graph tracer. Instead"," an array structure is
now used that will allow for multiple users of the function_graph
infrastructure. The variables are still used by the architecture code for
non dynamic ftrace configs","[' where a test is made against them to see if\nthey point to the default stub function or not. This is how the static\nfunction tracing knows to call into the function graph tracer\ninfrastructure or not.\n\nTwo new stub functions are made. entry_run() and return_run(). The\nftrace_graph_entry and ftrace_graph_return are set to them respectively\nwhen the function graph tracer is enabled', ' and this will trigger the\narchitecture specific function graph code to be executed.\n\nThis also requires checking the global_ops hash for all calls into the\nfunction_graph tracer.\n\nCo-developed with Masami Hiramatsu:\nLink: https://lore.kernel.org/linux-trace-kernel/171509097408.162236.17387844142114638932.stgit@devnote2\nLink: https://lore.kernel.org/linux-trace-kernel/20240603190821.872127216@goodmis.org\n\nCc: Mark Rutland <mark.rutland@arm.com>\nCc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>\nCc: Andrew Morton <akpm@linux-foundation.org>\nCc: Alexei Starovoitov <alexei.starovoitov@gmail.com>\nCc: Florent Revest <revest@chromium.org>\nCc: Martin KaFai Lau <martin.lau@linux.dev>\nCc: bpf <bpf@vger.kernel.org>\nCc: Sven Schnelle <svens@linux.ibm.com>\nCc: Alexei Starovoitov <ast@kernel.org>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: Arnaldo Carvalho de Melo <acme@kernel.org>\nCc: Daniel Borkmann <daniel@iogearbox.net>\nCc: Alan Maguire <alan.maguire@oracle.com>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Thomas Gleixner <tglx@linutronix.de>\nCc: Guo Ren <guoren@kernel.org>\nReviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\nSigned-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>\nSigned-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\nSigned-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>\n', '']",The commit removes legacy logic for ftrace_graph_entry and ftrace_graph_return in function_graph tracer to support multiple users.,"function_graph,tracer,ftrace",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
375bb57292f49fa0956cc2739c81749b88e69510,375bb57292f49fa0956cc2739c81749b88e69510,Masami Hiramatsu (Google),mhiramat@kernel.org,1717441629,Steven Rostedt (Google),rostedt@goodmis.org,1717511765,11b2ae3d5fd6f9678094207523f36c0cbfea46eb,7aa1eaef9f4282c9acd39588b1fdc9dda7e73f34,"function_graph: Handle tail calls for stack unwinding

For the tail-call"," there would be 2 or more ftrace_ret_stacks on the
ret_stack","[' which records ""return_to_handler"" as the return address except\nfor the last one.  But on the real stack', ' there should be 1 entry because\ntail-call reuses the return address on the stack and jump to the next\nfunction.\n\nIn ftrace_graph_ret_addr() that is used for stack unwinding', ' skip tail\ncalls as a real stack unwinder would do.\n\nLink: https://lore.kernel.org/linux-trace-kernel/171509096221.162236.8806372072523195752.stgit@devnote2\nLink: https://lore.kernel.org/linux-trace-kernel/20240603190821.717065217@goodmis.org\n\nCc: Mark Rutland <mark.rutland@arm.com>\nCc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>\nCc: Andrew Morton <akpm@linux-foundation.org>\nCc: Alexei Starovoitov <alexei.starovoitov@gmail.com>\nCc: Florent Revest <revest@chromium.org>\nCc: Martin KaFai Lau <martin.lau@linux.dev>\nCc: bpf <bpf@vger.kernel.org>\nCc: Sven Schnelle <svens@linux.ibm.com>\nCc: Alexei Starovoitov <ast@kernel.org>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: Arnaldo Carvalho de Melo <acme@kernel.org>\nCc: Daniel Borkmann <daniel@iogearbox.net>\nCc: Alan Maguire <alan.maguire@oracle.com>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Thomas Gleixner <tglx@linutronix.de>\nCc: Guo Ren <guoren@kernel.org>\nSigned-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\nSigned-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>\n', '']",Improve stack unwinding by handling tail calls in function_graph tracer.,"function_graph,tail calls,stack unwinding",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['tracepoints like programs']
7aa1eaef9f4282c9acd39588b1fdc9dda7e73f34,7aa1eaef9f4282c9acd39588b1fdc9dda7e73f34,Steven Rostedt (VMware),rostedt@goodmis.org,1717441628,Steven Rostedt (Google),rostedt@goodmis.org,1717511758,1a9f7a9b753533c0dfb9463823437ffe87a835ef,518d6804a865772735588c5b2203d6c0c0bf98a9,"function_graph: Allow multiple users to attach to function graph

Allow for multiple users to attach to function graph tracer at the same
time. Only 16 simultaneous users can attach to the tracer. This is because
there's an array that stores the pointers to the attached fgraph_ops. When
a function being traced is entered"," each of the ftrace_ops entryfunc is
called and if it returns non zero","[' its index into the array will be added\nto the shadow stack.\n\nOn exit of the function being traced', ' the shadow stack will contain the\nindexes of the ftrace_ops on the array that want their retfunc to be\ncalled.\n\nBecause a function may sleep for a long time (if a task sleeps itself)', '\nthe return of the function may be literally days later. If the ftrace_ops\nis removed', ' its place on the array is replaced with a ftrace_ops that\ncontains the stub functions and that will be called when the function\nfinally returns.\n\nIf another ftrace_ops is added that happens to get the same index into the\narray', "" its return function may be called. But that's actually the way\nthings current work with the old function graph tracer. If one tracer is\nremoved and another is added"", ' the new one will get the return calls of the\nfunction traced by the previous one', ' thus this is not a regression. This\ncan be fixed by adding a counter to each time the array item is updated and\nsave that on the shadow stack as well', "" such that it won't be called if the\nindex saved does not match the index on the array.\n\nNote"", ' being able to filter functions when both are called is not completely\nhandled yet', "" but that shouldn't be too hard to manage.\n\nCo-developed with Masami Hiramatsu:\nLink: https://lore.kernel.org/linux-trace-kernel/171509096221.162236.8806372072523195752.stgit@devnote2\nLink: https://lore.kernel.org/linux-trace-kernel/20240603190821.555493396@goodmis.org\n\nCc: Mark Rutland <mark.rutland@arm.com>\nCc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>\nCc: Andrew Morton <akpm@linux-foundation.org>\nCc: Alexei Starovoitov <alexei.starovoitov@gmail.com>\nCc: Florent Revest <revest@chromium.org>\nCc: Martin KaFai Lau <martin.lau@linux.dev>\nCc: bpf <bpf@vger.kernel.org>\nCc: Sven Schnelle <svens@linux.ibm.com>\nCc: Alexei Starovoitov <ast@kernel.org>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: Arnaldo Carvalho de Melo <acme@kernel.org>\nCc: Daniel Borkmann <daniel@iogearbox.net>\nCc: Alan Maguire <alan.maguire@oracle.com>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Thomas Gleixner <tglx@linutronix.de>\nCc: Guo Ren <guoren@kernel.org>\nReviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\nSigned-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>\nSigned-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\nSigned-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>\n"", '']","This commit enables multiple users to attach to the function graph tracer concurrently, with a maximum limit of 16 users.","function_graph,tracer,multiple_users",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['tracepoints like programs']
518d6804a865772735588c5b2203d6c0c0bf98a9,518d6804a865772735588c5b2203d6c0c0bf98a9,Steven Rostedt (VMware),rostedt@goodmis.org,1717441627,Steven Rostedt (Google),rostedt@goodmis.org,1717511753,3fba56bf0d3f9f004670f4dcfe4445f0c82bb0dd,59e5f04e4184181227889663618e01dce676e671,"function_graph: Add an array structure that will allow multiple callbacks

Add an array structure that will eventually allow the function graph tracer
to have up to 16 simultaneous callbacks attached. It's an array of 16
fgraph_ops pointers"," that is assigned when one is registered. On entry of a
function the entry of the first item in the array is called","[' and if it\nreturns zero', ' then the callback returns non zero if it wants the return\ncallback to be called on exit of the function.\n\nThe array will simplify the process of having more than one callback\nattached to the same function', ' as its index into the array can be stored on\nthe shadow stack. We need to only save the index', ' because this will allow\nthe fgraph_ops to be freed before the function returns (which may happen if\nthe function call schedule for a long time).\n\nCo-developed with Masami Hiramatsu:\nLink: https://lore.kernel.org/linux-trace-kernel/171509095075.162236.8272148192748284581.stgit@devnote2\nLink: https://lore.kernel.org/linux-trace-kernel/20240603190821.392113213@goodmis.org\n\nCc: Mark Rutland <mark.rutland@arm.com>\nCc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>\nCc: Andrew Morton <akpm@linux-foundation.org>\nCc: Alexei Starovoitov <alexei.starovoitov@gmail.com>\nCc: Florent Revest <revest@chromium.org>\nCc: Martin KaFai Lau <martin.lau@linux.dev>\nCc: bpf <bpf@vger.kernel.org>\nCc: Sven Schnelle <svens@linux.ibm.com>\nCc: Alexei Starovoitov <ast@kernel.org>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: Arnaldo Carvalho de Melo <acme@kernel.org>\nCc: Daniel Borkmann <daniel@iogearbox.net>\nCc: Alan Maguire <alan.maguire@oracle.com>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Thomas Gleixner <tglx@linutronix.de>\nCc: Guo Ren <guoren@kernel.org>\nReviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\nSigned-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>\nSigned-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\nSigned-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>\n', '']",Add array structure for multiple callbacks in function graph tracer.,"array,crafter,function",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['tracepoints like programs']
59e5f04e4184181227889663618e01dce676e671,59e5f04e4184181227889663618e01dce676e671,Steven Rostedt (VMware),rostedt@goodmis.org,1717441626,Steven Rostedt (Google),rostedt@goodmis.org,1717511740,481e60e325affeb762ef9f8214b35aa0771f1d55,42675b723b4842bca7bfb0f209aa9a493a10324a,"fgraph: Use BUILD_BUG_ON() to make sure we have structures divisible by long

Instead of using ""ALIGN()"""," use BUILD_BUG_ON() as the structures should
always be divisible by sizeof(long).

Co-developed with Masami Hiramatsu:
Link: https://lore.kernel.org/linux-trace-kernel/171509093949.162236.14518699447151894536.stgit@devnote2
Link: http://lkml.kernel.org/r/20190524111144.GI2589@hirez.programming.kicks-ass.net
Link: https://lore.kernel.org/linux-trace-kernel/20240603190821.232168933@goodmis.org

Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Cc: Florent Revest <revest@chromium.org>
Cc: Martin KaFai Lau <martin.lau@linux.dev>
Cc: bpf <bpf@vger.kernel.org>
Cc: Sven Schnelle <svens@linux.ibm.com>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Alan Maguire <alan.maguire@oracle.com>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Guo Ren <guoren@kernel.org>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Suggested-by: Peter Zijlstra <peterz@infradead.org>
Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
Signed-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
",[''],The commit replaces ALIGN() with BUILD_BUG_ON() to ensure structures are divisible by long.,"BUILD_BUG_ON, structures, divisible",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['tracepoints like programs']
42675b723b4842bca7bfb0f209aa9a493a10324a,42675b723b4842bca7bfb0f209aa9a493a10324a,Steven Rostedt (VMware),rostedt@goodmis.org,1717441625,Steven Rostedt (Google),rostedt@goodmis.org,1717511709,30ceb20e46c23b7431ab64714c1579a259eb888b,c3f38fa61af77b49866b006939479069cd451173,"function_graph: Convert ret_stack to a series of longs

In order to make it possible to have multiple callbacks registered with the
function_graph tracer"," the retstack needs to be converted from an array of
ftrace_ret_stack structures to an array of longs. This will allow to store
the list of callbacks on the stack for the return side of the functions.

Link: https://lore.kernel.org/linux-trace-kernel/171509092742.162236.4427737821399314856.stgit@devnote2
Link: https://lore.kernel.org/linux-trace-kernel/20240603190821.073111754@goodmis.org

Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Cc: Florent Revest <revest@chromium.org>
Cc: Martin KaFai Lau <martin.lau@linux.dev>
Cc: bpf <bpf@vger.kernel.org>
Cc: Sven Schnelle <svens@linux.ibm.com>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Alan Maguire <alan.maguire@oracle.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Guo Ren <guoren@kernel.org>
Reviewed-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
Signed-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
",[''],Convert ret_stack from ftrace_ret_stack structures to longs for multi-callback support in function_graph tracer.,"function_graph,ret_stack,longs",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['tracepoints like programs']
49df0019f36798d414e6b913bec30a3a0cd47c70,49df0019f36798d414e6b913bec30a3a0cd47c70,Alexei Starovoitov,ast@kernel.org,1717473163,Alexei Starovoitov,ast@kernel.org,1717473163,355da146e35dbe12ef5a0e4f7a5fbfd35ecf9cba,49784c7979321c49a8055f5c588d24c34a8c55fc 43d50ffb1f7e32865cdd343224659614d8b558b9,"Merge branch 'enable-bpf-programs-to-declare-arrays-of-kptr-bpf_rb_root-and-bpf_list_head'

Kui-Feng Lee says:

====================
Enable BPF programs to declare arrays of kptr", bpf_rb_root,"[' and bpf_list_head.\n\nSome types', ' such as type kptr', ' bpf_rb_root', ' and bpf_list_head', ' are\ntreated in a special way. Previously', ' these types could not be the\ntype of a field in a struct type that is used as the type of a global\nvariable. They could not be the type of a field in a struct type that\nis used as the type of a field in the value type of a map either. They\ncould not even be the type of array elements. This means that they can\nonly be the type of global variables or of direct fields in the value\ntype of a map.\n\nThe patch set aims to enable the use of these specific types in arrays\nand struct fields', ' providing flexibility. It examines the types of\nglobal variables or the value types of maps', ' such as arrays and struct\ntypes', ' recursively to identify these special types and generate field\ninformation for them.\n\nFor example', '\n\n  ...\n  struct task_struct __kptr *ptr[3];\n  ...\n\nit will create 3 instances of ""struct btf_field"" in the ""btf_record"" of\nthe data section.\n\n [...', '\n  btf_field(offset=0x100', ' type=BPF_KPTR_REF)', '\n  btf_field(offset=0x108', ' type=BPF_KPTR_REF)', '\n  btf_field(offset=0x110', ' type=BPF_KPTR_REF)', '\n  ...\n ]\n\nIt creates a record of each of three elements. These three records are\nalmost identical except their offsets.\n\nAnother example is\n\n  ...\n  struct A {\n    ...\n    struct task_struct __kptr *task;\n    struct bpf_rb_root root;\n    ...\n  }\n\n  struct A foo[2];\n\nit will create 4 records.\n\n [...', '\n  btf_field(offset=0x7100', ' type=BPF_KPTR_REF)', '\n  btf_field(offset=0x7108', ' type=BPF_RB_ROOT:)', '\n  btf_field(offset=0x7200', ' type=BPF_KPTR_REF)', '\n  btf_field(offset=0x7208', ' type=BPF_RB_ROOT:)', '\n  ...\n ]\n\nAssuming that the size of an element/struct A is 0x100 and ""foo""\nstarts at 0x7000', ' it includes two kptr records at 0x7100 and 0x7200', '\nand two rbtree root records at 0x7108 and 0x7208.\n\nAll these field information will be flatten', ' for struct types', ' and\nrepeated', ' for arrays.\n---\nChanges from v6:\n\n - Return BPF_KPTR_REF from btf_get_field_type() only if var_type is a\n   struct type.\n\n   - Pass btf and type to btf_get_field_type().\n\nChanges from v5:\n\n - Ensure field->offset values of kptrs are advanced correctly from\n   one nested struct/or array to another.\n\nChanges from v4:\n\n - Return -E2BIG for i == MAX_RESOLVE_DEPTH.\n\nChanges from v3:\n\n - Refactor the common code of btf_find_struct_field() and\n   btf_find_datasec_var().\n\n - Limit the number of levels looking into a struct types.\n\nChanges from v2:\n\n - Support fields in nested struct type.\n\n - Remove nelems and duplicate field information with offset\n   adjustments for arrays.\n\nChanges from v1:\n\n - Move the check of element alignment out of btf_field_cmp() to\n   btf_record_find().\n\n - Change the order of the previous patch 4 ""bpf:\n   check_map_kptr_access() compute the offset from the reg state"" as\n   the patch 7 now.\n\n - Reject BPF_RB_NODE and BPF_LIST_NODE with nelems > 1.\n\n - Rephrase the commit log of the patch ""bpf: check_map_access() with\n   the knowledge of arrays"" to clarify the alignment on elements.\n\nv6: https://lore.kernel.org/all/20240520204018.884515-1-thinker.li@gmail.com/\nv5: https://lore.kernel.org/all/20240510011312.1488046-1-thinker.li@gmail.com/\nv4: https://lore.kernel.org/all/20240508063218.2806447-1-thinker.li@gmail.com/\nv3: https://lore.kernel.org/all/20240501204729.484085-1-thinker.li@gmail.com/\nv2: https://lore.kernel.org/all/20240412210814.603377-1-thinker.li@gmail.com/\nv1: https://lore.kernel.org/bpf/20240410004150.2917641-1-thinker.li@gmail.com/\n\nKui-Feng Lee (9):\n  bpf: Remove unnecessary checks on the offset of btf_field.\n  bpf: Remove unnecessary call to btf_field_type_size().\n  bpf: refactor btf_find_struct_field() and btf_find_datasec_var().\n  bpf: create repeated fields for arrays.\n  bpf: look into the types of the fields of a struct type recursively.\n  bpf: limit the number of levels of a nested struct type.\n  selftests/bpf: Test kptr arrays and kptrs in nested struct fields.\n  selftests/bpf: Test global bpf_rb_root arrays and fields in nested\n    struct types.\n  selftests/bpf: Test global bpf_list_head arrays.\n\n kernel/bpf/btf.c                              | 310 ++++++++++++------\n kernel/bpf/verifier.c                         |   4 +-\n .../selftests/bpf/prog_tests/cpumask.c        |   5 +\n .../selftests/bpf/prog_tests/linked_list.c    |  12 +\n .../testing/selftests/bpf/prog_tests/rbtree.c |  47 +++\n .../selftests/bpf/progs/cpumask_success.c     | 171 ++++++++++\n .../testing/selftests/bpf/progs/linked_list.c |  42 +++\n tools/testing/selftests/bpf/progs/rbtree.c    |  77 +++++\n 8 files changed', ' 558 insertions(+)', ' 110 deletions(-)\n====================\n\nLink: https://lore.kernel.org/r/20240523174202.461236-1-thinker.li@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Enable BPF programs to declare arrays of kptrs using bpf_rb_root and bpf_list_head.,"BPF, arrays, kptrs",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
43d50ffb1f7e32865cdd343224659614d8b558b9,43d50ffb1f7e32865cdd343224659614d8b558b9,Kui-Feng Lee,thinker.li@gmail.com,1716486122,Alexei Starovoitov,ast@kernel.org,1717473163,355da146e35dbe12ef5a0e4f7a5fbfd35ecf9cba,d55c765a9b2d54b53ef86a62d6209e2e5eb62585,"selftests/bpf: Test global bpf_list_head arrays.

Make sure global arrays of bpf_list_heads and fields of bpf_list_heads in
nested struct types work correctly.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240523174202.461236-10-thinker.li@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Added tests for global bpf_list_head arrays and nested structures in selftests/bpf.,"bpf_list_head, selftests, arrays",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d55c765a9b2d54b53ef86a62d6209e2e5eb62585,d55c765a9b2d54b53ef86a62d6209e2e5eb62585,Kui-Feng Lee,thinker.li@gmail.com,1716486121,Alexei Starovoitov,ast@kernel.org,1717473162,a5659c1ca934ebb6458f8641f323635b983bbf19,c4c6c3b785a0b1426add15d078da61f899abeaac,"selftests/bpf: Test global bpf_rb_root arrays and fields in nested struct types.

Make sure global arrays of bpf_rb_root and fields of bpf_rb_root in nested
struct types work correctly.

Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240523174202.461236-9-thinker.li@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add selftests for global bpf_rb_root arrays and nested struct types.,"selftests,bpf_rb_root,nested_struct",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c4c6c3b785a0b1426add15d078da61f899abeaac,c4c6c3b785a0b1426add15d078da61f899abeaac,Kui-Feng Lee,thinker.li@gmail.com,1716486120,Alexei Starovoitov,ast@kernel.org,1717473162,bdf978cfc78a73d41542df82a794c3b069184d61,f19caf57d80f4432acea61d858d45ce194444389,"selftests/bpf: Test kptr arrays and kptrs in nested struct fields.

Make sure that BPF programs can declare global kptr arrays and kptr fields
in struct types that is the type of a global variable or the type of a
nested descendant field in a global variable.

An array with only one element is special case"," that it treats the element
like a non-array kptr field. Nested arrays are also tested to ensure they
are handled properly.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240523174202.461236-8-thinker.li@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Test kptr arrays and nested struct fields in BPF programs.,"kptr,struct,selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f19caf57d80f4432acea61d858d45ce194444389,f19caf57d80f4432acea61d858d45ce194444389,Kui-Feng Lee,thinker.li@gmail.com,1716486119,Alexei Starovoitov,ast@kernel.org,1717473162,3c3ae664d5c0edac1fedef8d4989d440830107fe,64e8ee814819f21beeeda00d4119221443d77992,"bpf: limit the number of levels of a nested struct type.

Limit the number of levels looking into struct types to avoid running out
of stack space.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240523174202.461236-7-thinker.li@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Limit the inspection depth of nested struct types in BPF to prevent stack overflow.,"nested struct, stack space, limit",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
64e8ee814819f21beeeda00d4119221443d77992,64e8ee814819f21beeeda00d4119221443d77992,Kui-Feng Lee,thinker.li@gmail.com,1716486118,Alexei Starovoitov,ast@kernel.org,1717473162,589335220e243aedf7c9d235ba9cb1a52218ea5a,994796c0256c4001633488fd24c3d54691949f8d,"bpf: look into the types of the fields of a struct type recursively.

The verifier has field information for specific special types"," such as
kptr","[' rbtree root', ' and list head. These types are handled\ndifferently. However', ' we did not previously examine the types of fields of\na struct type variable. Field information records were not generated for\nthe kptrs', ' rbtree roots', ' and linked_list heads that are not located at the\noutermost struct type of a variable.\n\nFor example', '\n\n  struct A {\n    struct task_struct __kptr * task;\n  };\n\n  struct B {\n    struct A mem_a;\n  }\n\n  struct B var_b;\n\nIt did not examine ""struct A"" so as not to generate field information for\nthe kptr in ""struct A"" for ""var_b"".\n\nThis patch enables BPF programs to define fields of these special types in\na struct type other than the direct type of a variable or in a struct type\nthat is the type of a field in the value type of a map.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Kui-Feng Lee <thinker.li@gmail.com>\nLink: https://lore.kernel.org/r/20240523174202.461236-6-thinker.li@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit enhances the eBPF verifier to recursively check struct field types.,"verifier, struct, recursive",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
994796c0256c4001633488fd24c3d54691949f8d,994796c0256c4001633488fd24c3d54691949f8d,Kui-Feng Lee,thinker.li@gmail.com,1716486117,Alexei Starovoitov,ast@kernel.org,1717473162,2e419b5ab98ddee8e08aa29fb0fd8d183e02e1d9,a7db0d4f872a869feb7c0201c0fa736c309192d5,"bpf: create repeated fields for arrays.

The verifier uses field information for certain special types"," such as
kptr","[' rbtree root', ' and list head. These types are treated\ndifferently. However', ' we did not previously support these types in\narrays. This update examines arrays and duplicates field information the\nsame number of times as the length of the array if the element type is one\nof the special types.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Kui-Feng Lee <thinker.li@gmail.com>\nLink: https://lore.kernel.org/r/20240523174202.461236-5-thinker.li@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit introduces repeated fields for arrays to enhance the eBPF verifier's handling of special types.,"repeated, arrays, verifier",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a7db0d4f872a869feb7c0201c0fa736c309192d5,a7db0d4f872a869feb7c0201c0fa736c309192d5,Kui-Feng Lee,thinker.li@gmail.com,1716486116,Alexei Starovoitov,ast@kernel.org,1717473162,18aba24503b94e7955511c90d82608a91854b90e,482f7133791e894b94a57ab3251e03d4c98ea42b,"bpf: refactor btf_find_struct_field() and btf_find_datasec_var().

Move common code of the two functions to btf_find_field_one().

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240523174202.461236-4-thinker.li@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Refactored btf_find_struct_field and btf_find_datasec_var into btf_find_field_one for code simplification.,"refactor,btf,functions",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
482f7133791e894b94a57ab3251e03d4c98ea42b,482f7133791e894b94a57ab3251e03d4c98ea42b,Kui-Feng Lee,thinker.li@gmail.com,1716486115,Alexei Starovoitov,ast@kernel.org,1717473162,dd090e2e84e49f85eeca59f47fb231427a559e8c,c95a3be45ad22ee8925d6d1ab531d5ba98216311,"bpf: Remove unnecessary call to btf_field_type_size().

field->size has been initialized by bpf_parse_fields() with the value
returned by btf_field_type_size(). Use it instead of calling
btf_field_type_size() again.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240523174202.461236-3-thinker.li@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit removes an unnecessary call to the btf_field_type_size function in the bpf code.,"bpf, btf, field",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c95a3be45ad22ee8925d6d1ab531d5ba98216311,c95a3be45ad22ee8925d6d1ab531d5ba98216311,Kui-Feng Lee,thinker.li@gmail.com,1716486114,Alexei Starovoitov,ast@kernel.org,1717473162,83dde6f4495c03d8ca07b3a73cbaf98a4c517dbd,49784c7979321c49a8055f5c588d24c34a8c55fc,"bpf: Remove unnecessary checks on the offset of btf_field.

reg_find_field_offset() always return a btf_field with a matching offset
value. Checking the offset of the returned btf_field is unnecessary.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240523174202.461236-2-thinker.li@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit removes unnecessary checks on the offset of btf_field returned by reg_find_field_offset.,"offset,btf_field,checks",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
49784c7979321c49a8055f5c588d24c34a8c55fc,49784c7979321c49a8055f5c588d24c34a8c55fc,Geliang Tang,tanggeliang@kylinos.cn,1716447004,Daniel Borkmann,daniel@iogearbox.net,1717435975,795745b38bd3ba2226863dd1862353047fbade66,de1b5ea789dc28066cc8dc634b6825bd6148f38b,"selftests/bpf: Drop duplicate bpf_map_lookup_elem in test_sockmap

bpf_map_lookup_elem is invoked in bpf_prog3() already"," no need to invoke
it again. This patch drops it.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Tested-by: Jakub Sitnicki <jakub@cloudflare.com>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/bpf/ea8458462b876ee445173e3effb535fd126137ed.1716446893.git.tanggeliang@kylinos.cn
",[''],Remove duplicate invocation of bpf_map_lookup_elem in test_sockmap function in selftests.,"selftests,sockmap,duplicate",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['socket like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
de1b5ea789dc28066cc8dc634b6825bd6148f38b,de1b5ea789dc28066cc8dc634b6825bd6148f38b,Geliang Tang,tanggeliang@kylinos.cn,1716447003,Daniel Borkmann,daniel@iogearbox.net,1717435975,8f9bb70b0f3def3a5da1c521521e09af9322bf64,dcb681b659f2a0a546752730c9daa92dc6120d52,"selftests/bpf: Check length of recv in test_sockmap

The value of recv in msg_loop may be negative", like EWOULDBLOCK,"[' so it\'s\nnecessary to check if it is positive before accumulating it to bytes_recvd.\n\nFixes: 16962b2404ac (""bpf: sockmap', ' add selftests"")\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Jakub Sitnicki <jakub@cloudflare.com>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nLink: https://lore.kernel.org/bpf/5172563f7c7b2a2e953cef02e89fc34664a7b190.1716446893.git.tanggeliang@kylinos.cn\n', '']",Add a check for negative recv length in test_sockmap selftests.,"recv,length,selftests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
dcb681b659f2a0a546752730c9daa92dc6120d52,dcb681b659f2a0a546752730c9daa92dc6120d52,Geliang Tang,tanggeliang@kylinos.cn,1716447002,Daniel Borkmann,daniel@iogearbox.net,1717435974,00419d332db0b7d43a14c96f995e97d2b5bffaae,467a0c79b5514d7301ae679770380679a8e32668,"selftests/bpf: Fix size of map_fd in test_sockmap

The array size of map_fd[] is 9"," not 8. This patch changes it as a more
general form: ARRAY_SIZE(map_fd).

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Tested-by: Jakub Sitnicki <jakub@cloudflare.com>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/bpf/0972529ee01ebf8a8fd2b310bdec90831c94be77.1716446893.git.tanggeliang@kylinos.cn
",[''],Fixed the array size definition of map_fd in selftests/bpf for test_sockmap to use ARRAY_SIZE macro.,"array, map_fd, test_sockmap",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
467a0c79b5514d7301ae679770380679a8e32668,467a0c79b5514d7301ae679770380679a8e32668,Geliang Tang,tanggeliang@kylinos.cn,1716447001,Daniel Borkmann,daniel@iogearbox.net,1717435974,224e364f59fa778004b52221f7184f725633d3f2,24bb90a42633ea47256d4f13289dd3181236e028,"selftests/bpf: Drop prog_fd array in test_sockmap

The program fds can be got by using bpf_program__fd(progs[])"," then
prog_fd becomes useless. This patch drops it.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Tested-by: Jakub Sitnicki <jakub@cloudflare.com>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/bpf/9a6335e4d8dbab23c0d8906074457ceddd61e74b.1716446893.git.tanggeliang@kylinos.cn
",[''],The commit removes the unused prog_fd array from the test_sockmap in selftests.,"prog_fd, test_sockmap, bpf_program__fd",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
24bb90a42633ea47256d4f13289dd3181236e028,24bb90a42633ea47256d4f13289dd3181236e028,Geliang Tang,tanggeliang@kylinos.cn,1716447000,Daniel Borkmann,daniel@iogearbox.net,1717435974,263232ab2aa7cc0047a7d6a4b14d764facfb1918,3f32a115f61d31049e3e91d469bca849f712a979,"selftests/bpf: Replace tx_prog_fd with tx_prog in test_sockmap

bpf_program__attach_sockmap() needs to take a parameter of type bpf_program
instead of an fd"," so tx_prog_fd becomes useless. This patch uses a pointer
tx_prog to point to an item in progs[] array.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Tested-by: Jakub Sitnicki <jakub@cloudflare.com>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/bpf/23b37f932c547dd1ebfe154bbc0b0e957be21ee6.1716446893.git.tanggeliang@kylinos.cn
",[''],Refactored test_sockmap to use bpf_program pointer instead of file descriptor for attaching programs.,"bpf_program, sockmap, refactor",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['socket like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3f32a115f61d31049e3e91d469bca849f712a979,3f32a115f61d31049e3e91d469bca849f712a979,Geliang Tang,tanggeliang@kylinos.cn,1716446999,Daniel Borkmann,daniel@iogearbox.net,1717435974,608a414439e62d5092e74fc0eb487559b864a43f,a9f0ea175948c21640ae1cc145e679db7fc45fa6,"selftests/bpf: Use bpf_link attachments in test_sockmap

Switch attachments to bpf_link using bpf_program__attach_sockmap() instead
of bpf_prog_attach().

This patch adds a new array progs[] to replace prog_fd[] array"," set in
populate_progs() for each program in bpf object.

And another new array links[] to save the attached bpf_link. It is
initalized as NULL in populate_progs","[' set as the return valuses of\nbpf_program__attach_sockmap()', ' and detached by bpf_link__detach().\n\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Jakub Sitnicki <jakub@cloudflare.com>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nLink: https://lore.kernel.org/bpf/32cf8376a810e2e9c719f8e4cfb97132ed2d1f9c.1716446893.git.tanggeliang@kylinos.cn\n', '']",Use bpf_link attachments in test_sockmap by switching to bpf_program__attach_sockmap.,"bpf_link, attachments, test_sockmap",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a9f0ea175948c21640ae1cc145e679db7fc45fa6,a9f0ea175948c21640ae1cc145e679db7fc45fa6,Geliang Tang,tanggeliang@kylinos.cn,1716446998,Daniel Borkmann,daniel@iogearbox.net,1717435974,1a23bade9f9769cc349b28e3e7005f8cb455acad,d95ba15b97847f4ae520db83bd98b61d50fb3068,"selftests/bpf: Drop duplicate definition of i in test_sockmap

There's already a definition of i in run_options() at the beginning"," no
need to define a new one in ""if (tx_prog_fd > 0)"" block.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Tested-by: Jakub Sitnicki <jakub@cloudflare.com>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/bpf/8d690682330a59361562bca75d6903253d16f312.1716446893.git.tanggeliang@kylinos.cn
",[''],The commit removes a duplicate variable definition in the test_sockmap function of selftests for BPF.,"duplicate, definition, test_sockmap",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d95ba15b97847f4ae520db83bd98b61d50fb3068,d95ba15b97847f4ae520db83bd98b61d50fb3068,Geliang Tang,tanggeliang@kylinos.cn,1716446997,Daniel Borkmann,daniel@iogearbox.net,1717435974,096c6f9f562630a29ba3bfaffad1c61c7772e346,ec1249d3278183d419276b9a7fe73591cd3dd505,"selftests/bpf: Fix tx_prog_fd values in test_sockmap

The values of tx_prog_fd in run_options() should not be 0"," so set it as -1
in else branch","[' and test it using ""if (tx_prog_fd > 0)"" condition', ' not\n""if (tx_prog_fd)"" or ""if (tx_prog_fd >= 0)"".\n\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Jakub Sitnicki <jakub@cloudflare.com>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nLink: https://lore.kernel.org/bpf/08b20ffc544324d40939efeae93800772a91a58e.1716446893.git.tanggeliang@kylinos.cn\n', '']",Fix incorrect tx_prog_fd values in selftests/bpf test_sockmap.,"selftests,bpf,tx_prog_fd",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
2884dc7d08d98a89d8d65121524bb7533183a63a,2884dc7d08d98a89d8d65121524bb7533183a63a,Cong Wang,cong.wang@bytedance.com,1717352823,Daniel Borkmann,daniel@iogearbox.net,1717431379,2ba0a318481cbdc9dd240af512fc8563635c3354,2317dc2c22cc353b699c7d1db47b2fe91f54055c,"bpf: Fix a potential use-after-free in bpf_link_free()

After commit 1a80dbcb2dba"," bpf_link can be freed by
link->ops->dealloc_deferred","[' but the code still tests and uses\nlink->ops->dealloc afterward', ' which leads to a use-after-free as\nreported by syzbot. Actually', ' one of them should be sufficient', ' so\njust call one of them instead of both. Also add a WARN_ON() in case\nof any problematic implementation.\n\nFixes: 1a80dbcb2dba (""bpf: support deferring bpf_link dealloc to after RCU grace period"")\nReported-by: syzbot+1989ee16d94720836244@syzkaller.appspotmail.com\nSigned-off-by: Cong Wang <cong.wang@bytedance.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/bpf/20240602182703.207276-1-xiyou.wangcong@gmail.com\n', '']",Fixes a potential use-after-free issue in bpf_link_free function.,"use-after-free,bpf_link_free,fix",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2317dc2c22cc353b699c7d1db47b2fe91f54055c,2317dc2c22cc353b699c7d1db47b2fe91f54055c,Thorsten Blum,thorsten.blum@toblux.com,1716977941,Daniel Borkmann,daniel@iogearbox.net,1717427363,3928bdbf9088d489be803b1b6c60d6a7b743922f,7d0b3953f6d832daec10a0d76e2d4db405768a8b,bpf," devmap: Remove unnecessary if check in for loop

The iterator variable dst cannot be NULL and the if check can be removed.
Remove it and fix the following Coccinelle/coccicheck warning reported
by itnull.cocci:

	ERROR: iterator variable bound on line 762 cannot be NULL

Signed-off-by: Thorsten Blum <thorsten.blum@toblux.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Reviewed-by: Toke Høiland-Jørgensen <toke@redhat.com>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Link: https://lore.kernel.org/bpf/20240529101900.103913-2-thorsten.blum@toblux.com
",[''],Remove unnecessary NULL check in bpf devmap iterator variable to fix coccicheck warning.,"devmap, NULL check, coccicheck",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ec1249d3278183d419276b9a7fe73591cd3dd505,ec1249d3278183d419276b9a7fe73591cd3dd505,Jeff Johnson,quic_jjohnson@quicinc.com,1717172923,Daniel Borkmann,daniel@iogearbox.net,1717427021,80a2bd2f8dc7f4667be87782734754c3e27acfe5,ce5249b91e34d81255c00950d415ebd4c3cae8d4,"test_bpf: Add missing MODULE_DESCRIPTION()

make allmodconfig && make W=1 C=1 reports:
WARNING: modpost: missing MODULE_DESCRIPTION() in lib/test_bpf.o

Add the missing invocation of the MODULE_DESCRIPTION() macro.

Signed-off-by: Jeff Johnson <quic_jjohnson@quicinc.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240531-md-lib-test_bpf-v1-1-868e4bd2f9ed@quicinc.com
",,Add missing MODULE_DESCRIPTION() macro to resolve modpost warning in test_bpf module.,"MODULE_DESCRIPTION, test_bpf, warning",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
ce5249b91e34d81255c00950d415ebd4c3cae8d4,ce5249b91e34d81255c00950d415ebd4c3cae8d4,Swan Beaujard,beaujardswan@gmail.com,1717369092,Daniel Borkmann,daniel@iogearbox.net,1717426707,129d4c406f58bd7127d9ded0156229c1a31a265c,a450d36b05fa225b071ce9fbf522544caea06594,"bpftool: Fix typo in MAX_NUM_METRICS macro name

Correct typo in bpftool profiler and change all instances of 'MATRICS' to
'METRICS' in the profiler.bpf.c file.

Signed-off-by: Swan Beaujard <beaujardswan@gmail.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Quentin Monnet <qmo@kernel.org>
Link: https://lore.kernel.org/bpf/20240602225812.81171-1-beaujardswan@gmail.com
",,This commit fixes a typo in the MAX_NUM_METRICS macro name in bpftool.,"typo, bpftool, metrics",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a450d36b05fa225b071ce9fbf522544caea06594,a450d36b05fa225b071ce9fbf522544caea06594,Dr. David Alan Gilbert,linux@treblig.org,1717371672,Daniel Borkmann,daniel@iogearbox.net,1717426386,e5ff27edc4525303d09158ebca457f12b6eb08c0,3f67639d8e582c89c79549c619b22a00dd330e4e,"selftests/bpf: Remove unused struct 'libcap'

'libcap' is unused since commit b1c2768a82b9 (""bpf: selftests: Remove libcap
usage from test_verifier""). Remove it.

Signed-off-by: Dr. David Alan Gilbert <linux@treblig.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240602234112.225107-4-linux@treblig.org
",,This commit removes the unused struct 'libcap' from selftests/bpf in Linux eBPF.,"selftests,bpf,libcap",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
3f67639d8e582c89c79549c619b22a00dd330e4e,3f67639d8e582c89c79549c619b22a00dd330e4e,Dr. David Alan Gilbert,linux@treblig.org,1717371671,Daniel Borkmann,daniel@iogearbox.net,1717426377,f0e56881e1fda5238562d282fcc4f1f04a8a29d2,dfa7c9ffa607235119e029b70ced72f29059f8f3,"selftests/bpf: Remove unused 'key_t' structs

'key_t' is unused in a couple of files since the original commit 60dd49ea6539
(""selftests/bpf: Add test for bpf array map iterators""). Remove it.

Signed-off-by: Dr. David Alan Gilbert <linux@treblig.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240602234112.225107-3-linux@treblig.org
",,Remove unused 'key_t' structs in selftests/bpf related files.,"remove, key_t, selftests",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
dfa7c9ffa607235119e029b70ced72f29059f8f3,dfa7c9ffa607235119e029b70ced72f29059f8f3,Dr. David Alan Gilbert,linux@treblig.org,1717371670,Daniel Borkmann,daniel@iogearbox.net,1717426362,991ac90a028c0d8746c86ecdb5bdce7c46f50965,96a27ee76f0e95b56f94b6902da7a5ebef372612,"selftests/bpf: Remove unused struct 'scale_test_def'

'scale_test_def' is unused since commit 3762a39ce85f (""selftests/bpf: Split out
bpf_verif_scale selftests into multiple tests""). Remove it.

Signed-off-by: Dr. David Alan Gilbert <linux@treblig.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240602234112.225107-2-linux@treblig.org
",,The commit removes an unused struct 'scale_test_def' from selftests/bpf.,"unused, struct, selftests",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
96a27ee76f0e95b56f94b6902da7a5ebef372612,96a27ee76f0e95b56f94b6902da7a5ebef372612,Xiao Wang,xiao.w.wang@intel.com,1716537343,Daniel Borkmann,daniel@iogearbox.net,1717425923,24657fa8ed9ffa3b3c22cfd1503a43d34b51bd27,531876c80004ecff7bfdbd8ba6c6b48835ef5e22,riscv," bpf: Introduce shift add helper with Zba optimization

Zba extension is very useful for generating addresses that index into array
of basic data types. This patch introduces sh2add and sh3add helpers for
RV32 and RV64 respectively","[' to accelerate addressing for array of unsigned\nlong data.\n\nSigned-off-by: Xiao Wang <xiao.w.wang@intel.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Björn Töpel <bjorn@kernel.org>\nLink: https://lore.kernel.org/bpf/20240524075543.4050464-3-xiao.w.wang@intel.com\n', '']",Introduce sh2add and sh3add helpers for RISC-V with Zba optimization for address generation.,"RISC-V, helpers, optimization",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
83814698cf48ce3aadc5d88a3f577f04482ff92a,83814698cf48ce3aadc5d88a3f577f04482ff92a,Linus Torvalds,torvalds@linux-foundation.org,1717288475,Linus Torvalds,torvalds@linux-foundation.org,1717288475,b35bbbdffe75f446f042aab69e752202789fcd44,54bec8ed5732339438271d07376890454fa58046 be2fc65d66e0406cc9d39d40becaecdf4ee765f3,"Merge tag 'powerpc-6.10-2' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux

Pull powerpc fixes from Michael Ellerman:

 - Enforce full ordering for ATOMIC operations with BPF_FETCH

 - Fix uaccess build errors seen with GCC 13/14

 - Fix build errors on ppc32 due to ARCH_HAS_KERNEL_FPU_SUPPORT

 - Drop error message from lparcfg guest name lookup

Thanks to Christophe Leroy", Guenter Roeck,"[' Nathan Lynch', ' Naveen N Rao', '\nPuranjay Mohan', "" and Samuel Holland.\n\n* tag 'powerpc-6.10-2' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux:\n  powerpc: Limit ARCH_HAS_KERNEL_FPU_SUPPORT to PPC64\n  powerpc/uaccess: Use YZ asm constraint for ld\n  powerpc/uaccess: Fix build errors seen with GCC 13/14\n  powerpc/pseries/lparcfg: drop error message from guest name lookup\n  powerpc/bpf: enforce full ordering for ATOMIC operations with BPF_FETCH\n"", '']",Merges powerpc-related fixes including ATOMIC operations ordering and build error corrections.,"powerpc, atomic, build",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
531876c80004ecff7bfdbd8ba6c6b48835ef5e22,531876c80004ecff7bfdbd8ba6c6b48835ef5e22,Andrii Nakryiko,andrii@kernel.org,1717021959,Alexei Starovoitov,ast@kernel.org,1717212955,2155c4d8b9eae681b2ac8081c12d43ce80c7c6e5,3f8fde319524411b96badee3c96f35831300388a,"libbpf: keep FD_CLOEXEC flag when dup()'ing FD

Make sure to preserve and/or enforce FD_CLOEXEC flag on duped FDs.
Use dup3() with O_CLOEXEC flag for that.

Without this fix libbpf effectively clears FD_CLOEXEC flag on each of BPF
map/prog FD"," which is definitely not the right or expected behavior.

Reported-by: Lennart Poettering <lennart@poettering.net>
Fixes: bc308d011ab8 (""libbpf: call dup2() syscall directly"")
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Link: https://lore.kernel.org/r/20240529223239.504241-1-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Fixes FD_CLOEXEC flag handling in libbpf by using dup3().,"FD_CLOEXEC, libbpf, dup3",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7d0b3953f6d832daec10a0d76e2d4db405768a8b,7d0b3953f6d832daec10a0d76e2d4db405768a8b,Andrii Nakryiko,andrii@kernel.org,1717024332,Alexei Starovoitov,ast@kernel.org,1717192611,00bb24b6c4a1d0d8ee02f8072535e7fb3a7dd22e,aeb8fe0283d4d3b0f27a87c5f5c938e7324f7d8f,"libbpf: don't close(-1) in multi-uprobe feature detector

Guard close(link_fd) with extra link_fd >= 0 check to prevent close(-1).

Detected by Coverity static analysis.

Fixes: 04d939a2ab22 (""libbpf: detect broken PID filtering logic for multi-uprobe"")
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Link: https://lore.kernel.org/r/20240529231212.768828-1-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Guard added to ensure link_fd >= 0 before calling close to prevent errors in libbpf.,"libbpf, close, fix",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,['kprobe/uprobe/ftrace like programs']
aeb8fe0283d4d3b0f27a87c5f5c938e7324f7d8f,aeb8fe0283d4d3b0f27a87c5f5c938e7324f7d8f,Jiri Olsa,jolsa@kernel.org,1717184700,Alexei Starovoitov,ast@kernel.org,1717192488,201b1e04eaab996d844cc22683aecb263ef35d75,62da3acd28955e7299babebdfcb14243b789e773,"bpf: Fix bpf_session_cookie BTF_ID in special_kfunc_set list

The bpf_session_cookie is unavailable for !CONFIG_FPROBE as reported
by Sebastian [1].

To fix that we remove CONFIG_FPROBE ifdef for session kfuncs"," which
is fine","[' because there\'s filter for session programs.\n\nThen based on bpf_trace.o dependency:\n  obj-$(CONFIG_BPF_EVENTS) += bpf_trace.o\n\nwe add bpf_session_cookie BTF_ID in special_kfunc_set list dependency\non CONFIG_BPF_EVENTS.\n\n[1] https://lore.kernel.org/bpf/20240531071557.MvfIqkn7@linutronix.de/T/#m71c6d5ec71db2967288cb79acedc15cc5dbfeec5\nReported-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>\nTested-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>\nSuggested-by: Alexei Starovoitov <ast@kernel.org>\nFixes: 5c919acef8514 (""bpf: Add support for kprobe session cookie"")\nSigned-off-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/r/20240531194500.2967187-1-jolsa@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes bpf_session_cookie BTF_ID availability issue by removing CONFIG_FPROBE dependency for session kfuncs.,"bpf_session_cookie, BTF_ID, CONFIG_FPROBE",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
62da3acd28955e7299babebdfcb14243b789e773,62da3acd28955e7299babebdfcb14243b789e773,Andrii Nakryiko,andrii@kernel.org,1716935538,Alexei Starovoitov,ast@kernel.org,1717192465,4b164bb3732c7c48fb5b9770fc7be6783d306546,d8ec19857b095b39d114ae299713bd8ea6c1e66a,"selftests/bpf: fix inet_csk_accept prototype in test_sk_storage_tracing.c

Recent kernel change ([0]) changed inet_csk_accept() prototype. Adapt
progs/test_sk_storage_tracing.c to take that into account.

  [0] 92ef0fd55ac8 (""net: change proto and proto_ops accept type"")

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240528223218.3445297-1-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Fix inet_csk_accept prototype in test_sk_storage_tracing.c due to recent kernel change.,"selftests,bpf,inet_csk_accept",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tracepoints like programs']
bba1f6758a9ec90c1adac5dcf78f8a15f1bad65b,bba1f6758a9ec90c1adac5dcf78f8a15f1bad65b,Al Viro,viro@zeniv.linux.org.uk,1717127906,Al Viro,viro@zeniv.linux.org.uk,1717127906,47f2857d30e241862f7c8acb5c41b83382c5c93d,b4cf5fc01ce83e5c0bcf3dbb9f929428646b9098,"lirc: rc_dev_get_from_fd(): fix file leak

missing fdput() on a failure exit

Fixes: 6a9d552483d50 ""media: rc: bpf attach/detach requires write permission"" # v6.9
Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
",,Fixes a file descriptor leak in lirc's rc_dev_get_from_fd() function by ensuring fdput() is called on failure.,"file leak, lirc, fdput",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
3f8fde319524411b96badee3c96f35831300388a,3f8fde319524411b96badee3c96f35831300388a,Martin KaFai Lau,martin.lau@kernel.org,1717090493,Martin KaFai Lau,martin.lau@kernel.org,1717108454,c30297f679e7bddf7ce822b59147a4b587158c41,46253c4ae96162a840ad65c1394de63796d7798a d14c1fac0c9722c4ec79589921c9e798601ca9d5,"Merge branch 'Notify user space when a struct_ops object is detached/unregistered'

Kui-Feng Lee says:

====================
The subsystems managing struct_ops objects may need to detach a
struct_ops object due to errors or other reasons. It would be useful
to notify user space programs so that error recovery or logging can be
carried out.

This patch set enables the detach feature for struct_ops links and
send an event to epoll when a link is detached.  Subsystems could call
link->ops->detach() to detach a link and notify user space programs
through epoll.

The signatures of callback functions in ""struct bpf_struct_ops"" have
been changed as well to pass an extra link argument to
subsystems. Subsystems could detach the links received from reg() and
update() callbacks if there is. This also provides a way that
subsystems can distinguish registrations for an object that has been
registered multiple times for several links.

However"," bpf struct_ops maps without BPF_F_LINK have no any link.
Subsystems will receive NULL link pointer for this case.
---
Changes from v6:

 - Fix the missing header at patch 5.

 - Move RCU_INIT_POINTER() back to its original position.

Changes from v5:

 - Change the commit title of the patch for bpftool.

Changes from v4:

 - Change error code for bpf_struct_ops_map_link_update()

 - Always return 0 for bpf_struct_ops_map_link_detach()

 - Hold update_mutex in bpf_struct_ops_link_create()

 - Add a separated instance of file_operations for links supporting
    poll.

 - Fix bpftool for bpf_link_fops_poll.

Changes from v3:

 - Add a comment to explain why holding update_mutex is not necessary
    in bpf_struct_ops_link_create()

 - Use rcu_access_pointer() in bpf_struct_ops_map_link_poll().

Changes from v2:

 - Rephrased commit logs and comments.

 - Addressed some mistakes from patch splitting.

 - Replace mutex with spinlock in bpf_testmod.c to address lockdep
    Splat and simplify the implementation.

 - Fix an argument passing to rcu_dereference_protected().

Changes from v1:

 - Pass a link to reg","[' unreg', ' and update callbacks.\n\n - Provide a function to detach a link from underlying subsystems.\n\n - Add a kfunc to mimic detachments from subsystems', ' and provide a\n    flexible way to control when to do detachments.\n\n - Add two tests to detach a link from the subsystem after the refcount\n    of the link drops to zero.\n\nv6: https://lore.kernel.org/bpf/20240524223036.318800-1-thinker.li@gmail.com/\nv5: https://lore.kernel.org/all/20240523230848.2022072-1-thinker.li@gmail.com/\nv4: https://lore.kernel.org/all/20240521225121.770930-1-thinker.li@gmail.com/\nv3: https://lore.kernel.org/all/20240510002942.1253354-1-thinker.li@gmail.com/\nv2: https://lore.kernel.org/all/20240507055600.2382627-1-thinker.li@gmail.com/\nv1: https://lore.kernel.org/all/20240429213609.487820-1-thinker.li@gmail.com/\n====================\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Implement notification for user space when struct_ops objects are detached or unregistered using epoll.,"struct_ops, detach, epoll",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d14c1fac0c9722c4ec79589921c9e798601ca9d5,d14c1fac0c9722c4ec79589921c9e798601ca9d5,Kui-Feng Lee,thinker.li@gmail.com,1717052386,Martin KaFai Lau,martin.lau@kernel.org,1717108454,c30297f679e7bddf7ce822b59147a4b587158c41,1a4b858b6a045828de1b536cfab7819c50864ed6,"bpftool: Change pid_iter.bpf.c to comply with the change of bpf_link_fops.

To support epoll", a new instance of file_operations,"[' bpf_link_fops_poll', '\nhas been added for links that support epoll. The pid_iter.bpf.c checks\nf_ops for links and other BPF objects. The check should fail for struct_ops\nlinks without this patch.\n\nAcked-by: Quentin Monnet <qmo@kernel.org>\nSigned-off-by: Kui-Feng Lee <thinker.li@gmail.com>\nLink: https://lore.kernel.org/r/20240530065946.979330-9-thinker.li@gmail.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Update bpftool's pid_iter.bpf.c to align with changes in bpf_link_fops for epoll support.,"bpftool,bpf_link,epoll",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The bpftool utility,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1a4b858b6a045828de1b536cfab7819c50864ed6,1a4b858b6a045828de1b536cfab7819c50864ed6,Kui-Feng Lee,thinker.li@gmail.com,1717052383,Martin KaFai Lau,martin.lau@kernel.org,1717108454,f53330aaf10aa8fd2acce185f5fc2745fe236e3c,67c3e8353f45c27800eecc46e00e8272f063f7d1,"selftests/bpf: test struct_ops with epoll

Verify whether a user space program is informed through epoll with EPOLLHUP
when a struct_ops object is detached.

The BPF code in selftests/bpf/progs/struct_ops_module.c has become
complex. Therefore"," struct_ops_detach.c has been added to segregate the BPF
code for detachment tests from the BPF code for other tests based on the
recommendation of Andrii Nakryiko.

Suggested-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240530065946.979330-6-thinker.li@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Tests have been added to verify epoll notifications for struct_ops detachment in selftests.,"epoll, struct_ops, detachment",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
67c3e8353f45c27800eecc46e00e8272f063f7d1,67c3e8353f45c27800eecc46e00e8272f063f7d1,Kui-Feng Lee,thinker.li@gmail.com,1717052382,Martin KaFai Lau,martin.lau@kernel.org,1717108453,93bf01e455328e537e1d9e441164be4264219ed2,1adddc97aa44c8783f9f0276ea70854d56f9f6df,"bpf: export bpf_link_inc_not_zero.

bpf_link_inc_not_zero() will be used by kernel modules.  We will use it in
bpf_testmod.c later.

Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240530065946.979330-5-thinker.li@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,The commit exports the function bpf_link_inc_not_zero for use by kernel modules.,"export,bpf_link,kernel",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1adddc97aa44c8783f9f0276ea70854d56f9f6df,1adddc97aa44c8783f9f0276ea70854d56f9f6df,Kui-Feng Lee,thinker.li@gmail.com,1717052381,Martin KaFai Lau,martin.lau@kernel.org,1717108453,9bf857f946cbe8a3c1cdb08f759f981bb11d8f09,6fb2544ea1493f52e50b753604791c01bd2cf897,"bpf: support epoll from bpf struct_ops links.

Add epoll support to bpf struct_ops links to trigger EPOLLHUP event upon
detachment.

This patch implements the ""poll"" of the ""struct file_operations"" for BPF
links and introduces a new ""poll"" operator in the ""struct bpf_link_ops"". By
implementing ""poll"" of ""struct bpf_link_ops"" for the links of struct_ops","
the file descriptor of a struct_ops link can be added to an epoll file
descriptor to receive EPOLLHUP events.

Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240530065946.979330-4-thinker.li@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],This commit adds epoll support to bpf struct_ops links to handle EPOLLHUP events.,"epoll, struct_ops, EPOLLHUP",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6fb2544ea1493f52e50b753604791c01bd2cf897,6fb2544ea1493f52e50b753604791c01bd2cf897,Kui-Feng Lee,thinker.li@gmail.com,1717052380,Martin KaFai Lau,martin.lau@kernel.org,1717108453,0876de2cb261e1fcf94fdb11672018e99e065b22,73287fe228721b05690e671adbcccc6cf5435be6,"bpf: enable detaching links of struct_ops objects.

Implement the detach callback in bpf_link_ops for struct_ops so that user
programs can detach a struct_ops link. The subsystems that struct_ops
objects are registered to can also use this callback to detach the links
being passed to them.

Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240530065946.979330-3-thinker.li@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Implemented the detach callback in bpf_link_ops to enable detaching links of struct_ops objects.,"detach, struct_ops, bpf_link_ops",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
73287fe228721b05690e671adbcccc6cf5435be6,73287fe228721b05690e671adbcccc6cf5435be6,Kui-Feng Lee,thinker.li@gmail.com,1717052379,Martin KaFai Lau,martin.lau@kernel.org,1717108453,79813d3b5556ae05d70eb6794fc8024294db4ca3,46253c4ae96162a840ad65c1394de63796d7798a,"bpf: pass bpf_struct_ops_link to callbacks in bpf_struct_ops.

Pass an additional pointer of bpf_struct_ops_link to callback function reg","
unreg","[' and update provided by subsystems defined in bpf_struct_ops. A\nbpf_struct_ops_map can be registered for multiple links. Passing a pointer\nof bpf_struct_ops_link helps subsystems to distinguish them.\n\nThis pointer will be used in the later patches to let the subsystem\ninitiate a detachment on a link that was registered to it previously.\n\nSigned-off-by: Kui-Feng Lee <thinker.li@gmail.com>\nLink: https://lore.kernel.org/r/20240530065946.979330-2-thinker.li@gmail.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",The commit passes an additional pointer of bpf_struct_ops_link to callback functions in bpf_struct_ops.,"bpf_struct_ops, callbacks, pointer",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
46253c4ae96162a840ad65c1394de63796d7798a,46253c4ae96162a840ad65c1394de63796d7798a,Jakub Sitnicki,jakub@cloudflare.com,1716365376,Andrii Nakryiko,andrii@kernel.org,1717105337,98bfab486b5aafec09ad9f13464fabcec8de480b,f088cabffcb646b559055464bb5fa79206752f07,"selftests/bpf: use section names understood by libbpf in test_sockmap

libbpf can deduce program type and attach type from the ELF section name.
We don't need to pass it out-of-band if we switch to libbpf convention [1].

[1] https://docs.kernel.org/bpf/libbpf/program_types.html

Signed-off-by: Jakub Sitnicki <jakub@cloudflare.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240522080936.2475833-1-jakub@cloudflare.com
",,Update selftests to use libbpf-convention section names for program type deduction in test_sockmap.,"selftests, libbpf, section names",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
af752016340021d433a962063067e819dba889b1,af752016340021d433a962063067e819dba889b1,Ian Rogers,irogers@google.com,1716583947,Namhyung Kim,namhyung@kernel.org,1717088757,4cfbd4d243d26cffcf9955d15c72f3ad2d278805,d92aa899fe0a66350303a1986d6dc7ec4b3a1ea7,"perf top: Allow filters on events

Allow filters to be added to perf top events. One use is to workaround
issues with:
```
$ perf top --uid=""$(id -u)""
```
which tries to scan /proc find processes belonging to the uid and can
fail in such a pid terminates between the scan and the
perf_event_open reporting:
```
Error:
The sys_perf_event_open() syscall returned with 3 (No such process) for event (cycles:P).
/bin/dmesg | grep -i perf may provide additional information.
```
A similar filter:
```
$ perf top -e cycles:P --filter ""uid == $(id -u)""
```
doesn't fail this way.

Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: John Fastabend <john.fastabend@gmail.com>
Cc: Changbin Du <changbin.du@huawei.com>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Andrii Nakryiko <andrii@kernel.org>
Cc: bpf@vger.kernel.org
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
Link: https://lore.kernel.org/r/20240524205227.244375-4-irogers@google.com
",,The commit adds filters to Perf top events to address issues caused by terminated processes.,"filters, events, perf",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
d92aa899fe0a66350303a1986d6dc7ec4b3a1ea7,d92aa899fe0a66350303a1986d6dc7ec4b3a1ea7,Ian Rogers,irogers@google.com,1716583946,Namhyung Kim,namhyung@kernel.org,1717088757,a57346e02167583943c079105dfa62e3c33d7fb9,63b9cbd7941aa9ec5cb61567042176c4ce04b020,"perf bpf filter: Add uid and gid terms

Allow the BPF filter to use the uid and gid terms determined by the
bpf_get_current_uid_gid BPF helper. For example"," the following will
record the cpu-clock event system wide discarding samples that don't
belong to the current user.

$ perf record -e cpu-clock --filter ""uid == $(id -u)"" -a sleep 0.1

Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: John Fastabend <john.fastabend@gmail.com>
Cc: Changbin Du <changbin.du@huawei.com>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Andrii Nakryiko <andrii@kernel.org>
Cc: bpf@vger.kernel.org
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
Link: https://lore.kernel.org/r/20240524205227.244375-3-irogers@google.com
",[''],This commit adds uid and gid filtering capability to the perf BPF filter using bpf_get_current_uid_gid.,"uid,gid,filter",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
63b9cbd7941aa9ec5cb61567042176c4ce04b020,63b9cbd7941aa9ec5cb61567042176c4ce04b020,Ian Rogers,irogers@google.com,1716583945,Namhyung Kim,namhyung@kernel.org,1717088757,5c1e7e12fde31b93d663a77f7af56ac11b99cf6e,d163d60258c755845cbc9cfe0e45fca71e649488,"perf bpf filter: Give terms their own enum

Give the term types their own enum so that additional terms can be
added that don't correspond to a PERF_SAMPLE_xx flag. The term values
are numerically ascending rather than bit field positions"," this means
they need translating to a PERF_SAMPLE_xx bit field in certain places
using a shift.

Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: John Fastabend <john.fastabend@gmail.com>
Cc: Changbin Du <changbin.du@huawei.com>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Andrii Nakryiko <andrii@kernel.org>
Cc: bpf@vger.kernel.org
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
Link: https://lore.kernel.org/r/20240524205227.244375-2-irogers@google.com
",[''],Refactor perf BPF filter to assign unique enums to term types for expansion beyond PERF_SAMPLE_xx flags.,"perf,BPF,enum",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['profile like programs']
d8ec19857b095b39d114ae299713bd8ea6c1e66a,d8ec19857b095b39d114ae299713bd8ea6c1e66a,Linus Torvalds,torvalds@linux-foundation.org,1717083184,Linus Torvalds,torvalds@linux-foundation.org,1717083184,57a75bbcf7ef6e671208c61e35ae570ba51b3359,4a4be1ad3a6efea16c56615f31117590fd881358 13c7c941e72908b8cce5a84b45a7b5e485ca12ed,"Merge tag 'net-6.10-rc2' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Paolo Abeni:
 ""Including fixes from bpf and netfilter.

  Current release - regressions:

   - gro: initialize network_offset in network layer

   - tcp: reduce accepted window in NEW_SYN_RECV state

  Current release - new code bugs:

   - eth: mlx5e: do not use ptp structure for tx ts stats when not
     initialized

   - eth: ice: check for unregistering correct number of devlink params

  Previous releases - regressions:

   - bpf: Allow delete from sockmap/sockhash only if update is allowed

   - sched: taprio: extend minimum interval restriction to entire cycle
     too

   - netfilter: ipset: add list flush to cancel_gc

   - ipv4: fix address dump when IPv4 is disabled on an interface

   - sock_map: avoid race between sock_map_close and sk_psock_put

   - eth: mlx5: use mlx5_ipsec_rx_status_destroy to correctly delete
     status rules

  Previous releases - always broken:

   - core: fix __dst_negative_advice() race

   - bpf:
       - fix multi-uprobe PID filtering logic
       - fix pkt_type override upon netkit pass verdict

   - netfilter: tproxy: bail out if IP has been disabled on the device

   - af_unix: annotate data-race around unix_sk(sk)->addr

   - eth: mlx5e: fix UDP GSO for encapsulated packets

   - eth: idpf: don't enable NAPI and interrupts prior to allocating Rx
     buffers

   - eth: i40e: fully suspend and resume IO operations in EEH case

   - eth: octeontx2-pf: free send queue buffers incase of leaf to inner

   - eth: ipvlan: dont Use skb->sk in ipvlan_process_v{4","6}_outbound""

* tag 'net-6.10-rc2' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (69 commits)
  netdev: add qstat for csum complete
  ipvlan: Dont Use skb->sk in ipvlan_process_v{4","['6}_outbound\n  net: ena: Fix redundant device NUMA node override\n  ice: check for unregistering correct number of devlink params\n  ice: fix 200G PHY types to link speed mapping\n  i40e: Fully suspend and resume IO operations in EEH case\n  i40e: factoring out i40e_suspend/i40e_resume\n  e1000e: move force SMBUS near the end of enable_ulp function\n  net: dsa: microchip: fix RGMII error in KSZ DSA driver\n  ipv4: correctly iterate over the target netns in inet_dump_ifaddr()\n  net: fix __dst_negative_advice() race\n  nfc/nci: Add the inconsistency check between the input data length and count\n  MAINTAINERS: dwmac: starfive: update Maintainer\n  net/sched: taprio: extend minimum interval restriction to entire cycle too\n  net/sched: taprio: make q->picos_per_byte available to fill_sched_entry()\n  netfilter: nft_fib: allow from forward/input without iif selector\n  netfilter: tproxy: bail out if IP has been disabled on the device\n  netfilter: nft_payload: skbuff vlan metadata mangle support\n  net: ti: icssg-prueth: Fix start counter for ft1 filter\n  sock_map: avoid race between sock_map_close and sk_psock_put\n  ...\n', '']",This commit merges networking fixes addressing regressions and bugs for the current and previous Linux kernel releases.,"networking, bugs, bpf",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
f088cabffcb646b559055464bb5fa79206752f07,f088cabffcb646b559055464bb5fa79206752f07,Andrii Nakryiko,andrii@kernel.org,1717023708,Andrii Nakryiko,andrii@kernel.org,1717023708,a7fa5ceb4f4fb94fd757e1c64161aea51fda867f,fbe3e8473f391adbf67eb0f317305fe62c66096c 6ba7acdb93b4ecb554d5838fca3f5f0fcf9fff14,"Merge branch 'bpf-add-a-generic-bits-iterator'

Yafang Shao says:

====================
bpf: Add a generic bits iterator

Three new kfuncs", namely bpf_iter_bits_{new,"['next', 'destroy}', ' have been\nadded for the new bpf_iter_bits functionality. These kfuncs enable the\niteration of the bits from a given address and a given number of bits.\n\n- bpf_iter_bits_new\n  Initialize a new bits iterator for a given memory area. Due to the\n  limitation of bpf memalloc', ' the max number of bits to be iterated\n  over is (4096 * 8).\n- bpf_iter_bits_next\n  Get the next bit in a bpf_iter_bits\n- bpf_iter_bits_destroy\n  Destroy a bpf_iter_bits\n\nThe bits iterator can be used in any context and on any address.\n\nChanges:\n- v7->v8:\n  Refine the interface to avoid dealing with endianness (Andrii)\n- v6->v7:\n  Fix endianness error for non-long-aligned data (Andrii)\n- v5->v6:\n  Add positive tests (Andrii)\n- v4->v5:\n  Simplify test cases (Andrii)\n- v3->v4:\n  - Fix endianness error on s390x (Andrii)\n  - zero-initialize kit->bits_copy and zero out nr_bits (Andrii)\n- v2->v3:\n  Optimization for u64/u32 mask (Andrii)\n- v1->v2:\n  Simplify the CPU number verification code to avoid the failure on s390x\n  (Eduard)\n- bpf: Add bpf_iter_cpumask\n  https://lwn.net/Articles/961104/\n- bpf: Add new bpf helper bpf_for_each_cpu\n  https://lwn.net/Articles/939939/\n====================\n\nLink: https://lore.kernel.org/r/20240517023034.48138-1-laoar.shao@gmail.com\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n', '']",Add a generic bits iterator with new kfuncs to the BPF subsystem.,"generic, bits, iterator",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6ba7acdb93b4ecb554d5838fca3f5f0fcf9fff14,6ba7acdb93b4ecb554d5838fca3f5f0fcf9fff14,Yafang Shao,laoar.shao@gmail.com,1715913034,Andrii Nakryiko,andrii@kernel.org,1717023708,a7fa5ceb4f4fb94fd757e1c64161aea51fda867f,4665415975b0827e9646cab91c61d02a6b364d59,"selftests/bpf: Add selftest for bits iter

Add test cases for the bits iter:

- Positive cases
  - Bit mask representing a single word (8-byte unit)
  - Bit mask representing data spanning more than one word
  - The index of the set bit

- Nagative cases
  - bpf_iter_bits_destroy() is required after calling
    bpf_iter_bits_new()
  - bpf_iter_bits_destroy() can only destroy an initialized iter
  - bpf_iter_bits_next() must use an initialized iter
  - Bit mask representing zero words
  - Bit mask representing fewer words than expected
  - Case for ENOMEM
  - Case for NULL pointer

Signed-off-by: Yafang Shao <laoar.shao@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240517023034.48138-3-laoar.shao@gmail.com
",,Add selftests for bits iterator handling various positive and negative cases in the BPF environment.,"selftests,bits iterator,test cases",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4665415975b0827e9646cab91c61d02a6b364d59,4665415975b0827e9646cab91c61d02a6b364d59,Yafang Shao,laoar.shao@gmail.com,1715913033,Andrii Nakryiko,andrii@kernel.org,1717023707,9b717740936f9082b47ef0e0209816dc8de26658,fbe3e8473f391adbf67eb0f317305fe62c66096c,"bpf: Add bits iterator

Add three new kfuncs for the bits iterator:
- bpf_iter_bits_new
  Initialize a new bits iterator for a given memory area. Due to the
  limitation of bpf memalloc"," the max number of words (8-byte units) that
  can be iterated over is limited to (4096 / 8).
- bpf_iter_bits_next
  Get the next bit in a bpf_iter_bits
- bpf_iter_bits_destroy
  Destroy a bpf_iter_bits

The bits iterator facilitates the iteration of the bits of a memory area","['\nsuch as cpumask. It can be used in any context and on any address.\n\nSigned-off-by: Yafang Shao <laoar.shao@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240517023034.48138-2-laoar.shao@gmail.com\n', '']",The commit introduces three new kernel functions for bits iteration within a memory area using a bits iterator.,"bits, iterator, kfuncs",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['other']
b1e7cee96127468c2483cf10c2899c9b5cf79bf8,b1e7cee96127468c2483cf10c2899c9b5cf79bf8,Puranjay Mohan,puranjay@kernel.org,1715594568,Michael Ellerman,mpe@ellerman.id.au,1716984762,62e34ecc27389af48f377230d56a90a52b6686f7,1613e604df0cd359cf2a7fbd9be7a0bcfacfabd0,"powerpc/bpf: enforce full ordering for ATOMIC operations with BPF_FETCH

The Linux Kernel Memory Model [1][2] requires RMW operations that have a
return value to be fully ordered.

BPF atomic operations with BPF_FETCH (including BPF_XCHG and
BPF_CMPXCHG) return a value back so they need to be JITed to fully
ordered operations. POWERPC currently emits relaxed operations for
these.

We can show this by running the following litmus-test:

  PPC SB+atomic_add+fetch

  {
      0:r0=x;  (* dst reg assuming offset is 0 *)
      0:r1=2;  (* src reg *)
      0:r2=1;
      0:r4=y;  (* P0 writes to this"," P1 reads this *)
      0:r5=z;  (* P1 writes to this","[' P0 reads this *)\n      0:r6=0;\n\n      1:r2=1;\n      1:r4=y;\n      1:r5=z;\n  }\n\n  P0                      | P1            ;\n  stw         r2', ' 0(r4)   | stw  r2', '0(r5) ;\n                          |               ;\n  loop:lwarx  r3', ' r6', ' r0  |               ;\n  mr          r8', ' r3      |               ;\n  add         r3', ' r3', ' r1  | sync          ;\n  stwcx.      r3', ' r6', ' r0  |               ;\n  bne         loop        |               ;\n  mr          r1', ' r8      |               ;\n                          |               ;\n  lwa         r7', ' 0(r5)   | lwa  r7', '0(r4) ;\n\n  ~exists(0:r7=0 /\\ 1:r7=0)\n\n  Witnesses\n  Positive: 9 Negative: 3\n  Condition ~exists (0:r7=0 /\\ 1:r7=0)\n  Observation SB+atomic_add+fetch Sometimes 3 9\n\nThis test shows that the older store in P0 is reordered with a newer\nload to a different address. Although there is a RMW operation with\nfetch between them. Adding a sync before and after RMW fixes the issue:\n\n  Witnesses\n  Positive: 9 Negative: 0\n  Condition ~exists (0:r7=0 /\\ 1:r7=0)\n  Observation SB+atomic_add+fetch Never 0 9\n\n[1] https://www.kernel.org/doc/Documentation/memory-barriers.txt\n[2] https://www.kernel.org/doc/Documentation/atomic_t.txt\n\nFixes: aea7ef8a82c0 (""powerpc/bpf/32: add support for BPF_ATOMIC bitwise operations"")\nFixes: 2d9206b22743 (""powerpc/bpf/32: Add instructions for atomic_[cmp]xchg"")\nFixes: dbe6e2456fb0 (""powerpc/bpf/64: add support for atomic fetch operations"")\nFixes: 1e82dfaa7819 (""powerpc/bpf/64: Add instructions for atomic_[cmp]xchg"")\nCc: stable@vger.kernel.org # v6.0+\nSigned-off-by: Puranjay Mohan <puranjay@kernel.org>\nReviewed-by: Christophe Leroy <christophe.leroy@csgroup.eu>\nReviewed-by: Naveen N Rao <naveen@kernel.org>\nAcked-by: Paul E. McKenney <paulmck@kernel.org>\nSigned-off-by: Michael Ellerman <mpe@ellerman.id.au>\nLink: https://msgid.link/20240513100248.110535-1-puranjay@kernel.org\n\n', '']",Enforce full memory ordering for POWERPC BPF atomic operations using BPF_FETCH.,"POWERPC, BPF_FETCH, ordering",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fbe3e8473f391adbf67eb0f317305fe62c66096c,fbe3e8473f391adbf67eb0f317305fe62c66096c,Martin KaFai Lau,martin.lau@kernel.org,1716943984,Martin KaFai Lau,martin.lau@kernel.org,1716959775,3abbb5d1f2e692d464295709e60f15d9562b1770,eb4e7726279a344c82e3c23be396bcfd0a4d5669 ed61271af5230cef9b9329bb1eacc1b1a9800d07,Merge branch 'use network helpers," part 5'

Geliang Tang says:

====================
This patchset uses post_socket_cb callbacks of struct network_helper_opts
to refactor do_test() in bpf_tcp_ca.c.

v5:
 - address Martin's comments in v4 (thanks)
 - add patch 4","[' use start_server_str in test_dctcp_fallback too\n - ASSERT_* is already used in settcpca', "" use this helper in cc_cb (patch 3).\n\nv4:\n - address Martin's comments in v3 (thanks).\n - drop 2 patches"", ' keep ""type"" as the individual arg to start_server_addr', '\n   connect_to_addr and start_server_str.\n\nv3:\n - Add 4 new patches', ' 1-3 are cleanups. 4 adds a new helper.\n - address Martin\'s comments in v2.\n\nv2:\n - rebased on commit ""selftests/bpf: Add test for the use of new args in\n cong_control""\n====================\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Refactor do_test() in bpf_tcp_ca.c using network helpers post_socket_cb callbacks.,"network, refactor, callbacks",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['socket like programs']
ed61271af5230cef9b9329bb1eacc1b1a9800d07,ed61271af5230cef9b9329bb1eacc1b1a9800d07,Geliang Tang,tanggeliang@kylinos.cn,1716638899,Martin KaFai Lau,martin.lau@kernel.org,1716943984,3abbb5d1f2e692d464295709e60f15d9562b1770,79b330c57debe6b15f441e999bb62042afd5b08e,"selftests/bpf: Use start_server_str in do_test in bpf_tcp_ca

This patch uses new helper start_server_str() in do_test() in bpf_tcp_ca.c
to accept a struct network_helper_opts argument instead of using
start_server() and settcpca(). Then change the type of the first paramenter
of do_test() into a struct network_helper_opts one.

Define its own cb_opts and opts for each test"," set its own cc name into
cb_opts.cc","[' and cc_cb() into post_socket_cb callback', ' then pass it to\ndo_test().\n\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nLink: https://lore.kernel.org/r/6e1b6555e3284e77c8aa60668c61a66c5f99aa37.1716638248.git.tanggeliang@kylinos.cn\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Refactor bpf_tcp_ca test to use start_server_str with network_helper_opts for better test configuration.,"start_server_str, network_helper_opts, do_test",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
79b330c57debe6b15f441e999bb62042afd5b08e,79b330c57debe6b15f441e999bb62042afd5b08e,Geliang Tang,tanggeliang@kylinos.cn,1716638898,Martin KaFai Lau,martin.lau@kernel.org,1716943984,a62fd2628f63874ddee6d852152b7fc3191d9d3f,e078255abd53ac44c9133fd98d51645dbd196123,"selftests/bpf: Use post_socket_cb in start_server_str

This patch uses start_server_str() helper in test_dctcp_fallback() in
bpf_tcp_ca.c"," instead of using start_server() and settcpca(). For
support opts in start_server_str() helper","[' opts->cb_opts needs to be\npassed to post_socket_cb() in __start_server().\n\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nLink: https://lore.kernel.org/r/414c749321fa150435f7fe8e12c80fec8b447c78.1716638248.git.tanggeliang@kylinos.cn\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Use start_server_str helper in bpf_tcp_ca.c tests for DCTCP fallback.,"start_server_str,test_dctcp_fallback,bpf_tcp_ca",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
e078255abd53ac44c9133fd98d51645dbd196123,e078255abd53ac44c9133fd98d51645dbd196123,Geliang Tang,tanggeliang@kylinos.cn,1716638897,Martin KaFai Lau,martin.lau@kernel.org,1716943984,1046081598c5ee4209a49cd82b4a5aadb55b565f,6f802cb8988e8e41f2fdb74ac949d3a0ef9a9594,"selftests/bpf: Use post_socket_cb in connect_to_fd_opts

Since the post_socket_cb() callback is added in struct network_helper_opts","
it's make sense to use it not only in __start_server()","[' but also in\nconnect_to_fd_opts(). Then it can be used to set TCP_CONGESTION sockopt.\n\nAdd a ""void *"" type member cb_opts into struct network_helper_opts', ' and add\na new struct named cb_opts in prog_tests/bpf_tcp_ca.c', ' then cc can be moved\ninto struct cb_opts from network_helper_opts. Define a new callback cc_cb()\nto set TCP_CONGESTION sockopt', ' and set it to post_socket_cb pointer of opts.\nDefine a new cb_opts cubic', ' set it to cb_opts of opts. Pass this opts to\nconnect_to_fd_opts() in test_dctcp_fallback().\n\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nLink: https://lore.kernel.org/r/b512bb8d8f6854c9ea5c409b69d1bf37c6f272c6.1716638248.git.tanggeliang@kylinos.cn\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",The commit modifies BPF selftests to use the post_socket_cb callback in connect_to_fd_opts for consistency.,"selftests,bpf,callback",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
6f802cb8988e8e41f2fdb74ac949d3a0ef9a9594,6f802cb8988e8e41f2fdb74ac949d3a0ef9a9594,Geliang Tang,tanggeliang@kylinos.cn,1716638896,Martin KaFai Lau,martin.lau@kernel.org,1716943983,003ebcbbecfd31789e2caa15e182e3fc81a28b6c,ed31adf6874db172e3212ac1ebaf701ed6190650,"selftests/bpf: Add start_server_str helper

It's a tech debt that start_server() does not take the ""opts"" argument.
It's pretty handy to have start_server() as a helper that takes string
address.

So this patch creates a new helper start_server_str(). Then start_server()
can be a wrapper of it.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/606e6cfd7e1aff8bc51ede49862eed0802e52170.1716638248.git.tanggeliang@kylinos.cn
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Add start_server_str helper to enhance start_server() functionality in BPF selftests.,"start_server_str, helper, selftests",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ed31adf6874db172e3212ac1ebaf701ed6190650,ed31adf6874db172e3212ac1ebaf701ed6190650,Geliang Tang,tanggeliang@kylinos.cn,1716638895,Martin KaFai Lau,martin.lau@kernel.org,1716943983,0217dd38368584252da86ab516bdf3cc99c0f601,eb4e7726279a344c82e3c23be396bcfd0a4d5669,"selftests/bpf: Drop struct post_socket_opts

It's not possible to have one generic/common ""struct post_socket_opts""
for all tests. It's better to have the individual test define its own
callback opts struct.

So this patch drops struct post_socket_opts"," and changes the second
parameter of post_socket_cb as ""void *"" type.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/f8bda41c7cb9cb6979b2779f89fb3a684234304f.1716638248.git.tanggeliang@kylinos.cn
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],The commit removes the generic struct post_socket_opts in selftests for more test-specific callback structures.,"selftests,struct,callback",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
eb4e7726279a344c82e3c23be396bcfd0a4d5669,eb4e7726279a344c82e3c23be396bcfd0a4d5669,Mykyta Yatsenko,yatsenko@meta.com,1716556720,Andrii Nakryiko,andrii@kernel.org,1716938706,4aca2e5c18389f01ec9919e13ea4f728792b474b,4b3529edbb8ff069d762c6947e055e10c1748170,"libbpf: Configure log verbosity with env variable

Configure logging verbosity by setting LIBBPF_LOG_LEVEL environment
variable"," which is applied only to default logger. Once user set their
custom logging callback","[' it is up to them to handle filtering.\n\nSigned-off-by: Mykyta Yatsenko <yatsenko@meta.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240524131840.114289-1-yatsenko@meta.com\n', '']",This commit adds the ability to configure logging verbosity in libbpf using an environment variable.,"log verbosity, libbpf, environment",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"[""It's not related to any of the above.""]"
4b3529edbb8ff069d762c6947e055e10c1748170,4b3529edbb8ff069d762c6947e055e10c1748170,Jakub Kicinski,kuba@kernel.org,1716906448,Jakub Kicinski,kuba@kernel.org,1716906449,afa5c995e3f28f3473b91c2622e2d8ba4b3ba9d3,c30ff5f3aec3f77e13cfd7373390639bfdcffba7 d9cbd8343b010016fcaabc361c37720dcafddcbe,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next

Daniel Borkmann says:

====================
pull-request: bpf-next 2024-05-28

We've added 23 non-merge commits during the last 11 day(s) which contain
a total of 45 files changed", 696 insertions(+),"["" 277 deletions(-).\n\nThe main changes are:\n\n1) Rename skb's mono_delivery_time to tstamp_type for extensibility\n   and add SKB_CLOCK_TAI type support to bpf_skb_set_tstamp()"", '\n   from Abhishek Chauhan.\n\n2) Add netfilter CT zone ID and direction to bpf_ct_opts so that arbitrary\n   CT zones can be used from XDP/tc BPF netfilter CT helper functions', '\n   from Brad Cowie.\n\n3) Several tweaks to the instruction-set.rst IETF doc to address\n   the Last Call review comments', ' from Dave Thaler.\n\n4) Small batch of riscv64 BPF JIT optimizations in order to emit more\n   compressed instructions to the JITed image for better icache efficiency', '\n   from Xiao Wang.\n\n5) Sort bpftool C dump output from BTF', ' aiming to simplify vmlinux.h\n   diffing and forcing more natural type definitions ordering', '\n   from Mykyta Yatsenko.\n\n6) Use DEV_STATS_INC() macro in BPF redirect helpers to silence\n   a syzbot/KCSAN race report for the tx_errors counter', '\n   from Jiang Yunshui.\n\n7) Un-constify bpf_func_info in bpftool to fix compilation with LLVM 17+\n   which started treating const structs as constants and thus breaking\n   full BTF program name resolution', ' from Ivan Babrou.\n\n8) Fix up BPF program numbers in test_sockmap selftest in order to reduce\n   some of the test-internal array sizes', ' from Geliang Tang.\n\n9) Small cleanup in Makefile.btf script to use test-ge check for v1.25-only\n   pahole', "" from Alan Maguire.\n\n10) Fix bpftool's make dependencies for vmlinux.h in order to avoid needless\n    rebuilds in some corner cases"", "" from Artem Savkov.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next: (23 commits)\n  bpf"", ' net: Use DEV_STAT_INC()\n  bpf', ' docs: Fix instruction.rst indentation\n  bpf', ' docs: Clarify call local offset\n  bpf', ' docs: Add table captions\n  bpf', ' docs: clarify sign extension of 64-bit use of 32-bit imm\n  bpf', ' docs: Use RFC 2119 language for ISA requirements\n  bpf', ' docs: Move sentence about returning R0 to abi.rst\n  bpf: constify member bpf_sysctl_kern:: Table\n  riscv', ' bpf: Try RVC for reg move within BPF_CMPXCHG JIT\n  riscv', ' bpf: Use STACK_ALIGN macro for size rounding up\n  riscv', ' bpf: Optimize zextw insn with Zba extension\n  selftests/bpf: Handle forwarding of UDP CLOCK_TAI packets\n  net: Add additional bit to support clockid_t timestamp type\n  net: Rename mono_delivery_time to tstamp_type for scalabilty\n  selftests/bpf: Update tests for new ct zone opts for nf_conntrack kfuncs\n  net: netfilter: Make ct zone opts configurable for bpf ct helpers\n  selftests/bpf: Fix prog numbers in test_sockmap\n  bpf: Remove unused variable ""prev_state""\n  bpftool: Un-const bpf_func_info to fix it for llvm 17 and newer\n  bpf: Fix order of args in call to bpf_map_kvcalloc\n  ...\n====================\n\nLink: https://lore.kernel.org/r/20240528105924.30905-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Merge tag 'for-netdev' from the bpf-next branch into the current branch.,"merge, bpf-next, netdev",It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
4b4647add7d3c8530493f7247d11e257ee425bf0,4b4647add7d3c8530493f7247d11e257ee425bf0,Thadeu Lima de Souza Cascardo,cascardo@igalia.com,1716562022,Paolo Abeni,pabeni@redhat.com,1716890719,2a05a37b69b36db56f84e880728667297200104e,c519cf9b7434183bb56ed1e200ac577a5fd34d9b,"sock_map: avoid race between sock_map_close and sk_psock_put

sk_psock_get will return NULL if the refcount of psock has gone to 0"," which
will happen when the last call of sk_psock_put is done. However","['\nsk_psock_drop may not have finished yet', ' so the close callback will still\npoint to sock_map_close despite psock being NULL.\n\nThis can be reproduced with a thread deleting an element from the sock map', '\nwhile the second one creates a socket', ' adds it to the map and closes it.\n\nThat will trigger the WARN_ON_ONCE:\n\n------------[ cut here ]------------\nWARNING: CPU: 1 PID: 7220 at net/core/sock_map.c:1701 sock_map_close+0x2a2/0x2d0 net/core/sock_map.c:1701\nModules linked in:\nCPU: 1 PID: 7220 Comm: syz-executor380 Not tainted 6.9.0-syzkaller-07726-g3c999d1ae3c7 #0\nHardware name: Google Google Compute Engine/Google Compute Engine', ' BIOS Google 04/02/2024\nRIP: 0010:sock_map_close+0x2a2/0x2d0 net/core/sock_map.c:1701\nCode: df e8 92 29 88 f8 48 8b 1b 48 89 d8 48 c1 e8 03 42 80 3c 20 00 74 08 48 89 df e8 79 29 88 f8 4c 8b 23 eb 89 e8 4f 15 23 f8 90 <0f> 0b 90 48 83 c4 08 5b 41 5c 41 5d 41 5e 41 5f 5d e9 13 26 3d 02\nRSP: 0018:ffffc9000441fda8 EFLAGS: 00010293\nRAX: ffffffff89731ae1 RBX: ffffffff94b87540 RCX: ffff888029470000\nRDX: 0000000000000000 RSI: ffffffff8bcab5c0 RDI: ffffffff8c1faba0\nRBP: 0000000000000000 R08: ffffffff92f9b61f R09: 1ffffffff25f36c3\nR10: dffffc0000000000 R11: fffffbfff25f36c4 R12: ffffffff89731840\nR13: ffff88804b587000 R14: ffff88804b587000 R15: ffffffff89731870\nFS:  000055555e080380(0000) GS:ffff8880b9500000(0000) knlGS:0000000000000000\nCS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\nCR2: 0000000000000000 CR3: 00000000207d4000 CR4: 0000000000350ef0\nCall Trace:\n <TASK>\n unix_release+0x87/0xc0 net/unix/af_unix.c:1048\n __sock_release net/socket.c:659 [inline]\n sock_close+0xbe/0x240 net/socket.c:1421\n __fput+0x42b/0x8a0 fs/file_table.c:422\n __do_sys_close fs/open.c:1556 [inline]\n __se_sys_close fs/open.c:1541 [inline]\n __x64_sys_close+0x7f/0x110 fs/open.c:1541\n do_syscall_x64 arch/x86/entry/common.c:52 [inline]\n do_syscall_64+0xf5/0x240 arch/x86/entry/common.c:83\n entry_SYSCALL_64_after_hwframe+0x77/0x7f\nRIP: 0033:0x7fb37d618070\nCode: 00 00 48 c7 c2 b8 ff ff ff f7 d8 64 89 02 b8 ff ff ff ff eb d4 e8 10 2c 00 00 80 3d 31 f0 07 00 00 74 17 b8 03 00 00 00 0f 05 <48> 3d 00 f0 ff ff 77 48 c3 0f 1f 80 00 00 00 00 48 83 ec 18 89 7c\nRSP: 002b:00007ffcd4a525d8 EFLAGS: 00000202 ORIG_RAX: 0000000000000003\nRAX: ffffffffffffffda RBX: 0000000000000005 RCX: 00007fb37d618070\nRDX: 0000000000000010 RSI: 00000000200001c0 RDI: 0000000000000004\nRBP: 0000000000000000 R08: 0000000100000000 R09: 0000000100000000\nR10: 0000000000000000 R11: 0000000000000202 R12: 0000000000000000\nR13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000\n </TASK>\n\nUse sk_psock', ' which will only check that the pointer is not been set to\nNULL yet', ' which should only happen after the callbacks are restored. If', '\nthen', ' a reference can still be gotten', ' we may call sk_psock_stop and cancel\npsock->work.\n\nAs suggested by Paolo Abeni', ' reorder the condition so the control flow is\nless convoluted.\n\nAfter that change', ' the reproducer does not trigger the WARN_ON_ONCE\nanymore.\n\nSuggested-by: Paolo Abeni <pabeni@redhat.com>\nReported-by: syzbot+07a2e4a1a57118ef7355@syzkaller.appspotmail.com\nCloses: https://syzkaller.appspot.com/bug?extid=07a2e4a1a57118ef7355\nFixes: aadb2bb83ff7 (""sock_map: Fix a potential use-after-free in sock_map_close()"")\nFixes: 5b4a79ba65a1 (""bpf', "" sockmap: Don't let sock_map_{close"", 'destroy', 'unhash} call itself"")\nCc: stable@vger.kernel.org\nSigned-off-by: Thadeu Lima de Souza Cascardo <cascardo@igalia.com>\nAcked-by: Jakub Sitnicki <jakub@cloudflare.com>\nLink: https://lore.kernel.org/r/20240524144702.1178377-1-cascardo@igalia.com\nSigned-off-by: Paolo Abeni <pabeni@redhat.com>\n', '']",Fix potential race condition between sock_map_close and sk_psock_put functions.,"race, sock_map, refcount",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,['socket like programs']
d9cbd8343b010016fcaabc361c37720dcafddcbe,d9cbd8343b010016fcaabc361c37720dcafddcbe,yunshui,jiangyunshui@kylinos.cn,1716435320,Daniel Borkmann,daniel@iogearbox.net,1716890651,bca0593a4757df7d7d20410e46e08b3855d39faa,e245ef8a0b06fa5a18ca3bdcf82430166419283e,bpf," net: Use DEV_STAT_INC()

syzbot/KCSAN reported that races happen when multiple CPUs updating
dev->stats.tx_error concurrently. Adopt SMP safe DEV_STATS_INC() to
update the dev->stats fields.

Reported-by: syzbot <syzkaller@googlegroups.com>
Signed-off-by: yunshui <jiangyunshui@kylinos.cn>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240523033520.4029314-1-jiangyunshui@kylinos.cn
",[''],Fix race condition in network stats update using SMP safe DEV_STATS_INC().,"race condition, SMP safe, DEV_STATS_INC",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
2786ae339ef504f480753b54219b65471aaf98e8,2786ae339ef504f480753b54219b65471aaf98e8,Jakub Kicinski,kuba@kernel.org,1716852390,Jakub Kicinski,kuba@kernel.org,1716852390,97e30a59f15ef156645b0c8f7a389e848c0ede7c,52a2f0608366a629d43dacd3191039c95fef74ba a63bf556160fb19591183383da6757f52119981d,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Daniel Borkmann says:

====================
pull-request: bpf 2024-05-27

We've added 15 non-merge commits during the last 7 day(s) which contain
a total of 18 files changed", 583 insertions(+),"[' 55 deletions(-).\n\nThe main changes are:\n\n1) Fix broken BPF multi-uprobe PID filtering logic which filtered by thread\n   while the promise was to filter by process', ' from Andrii Nakryiko.\n\n2) Fix the recent influx of syzkaller reports to sockmap which triggered\n   a locking rule violation by performing a map_delete', ' from Jakub Sitnicki.\n\n3) Fixes to netkit driver in particular on skb->pkt_type override upon pass\n   verdict', ' from Daniel Borkmann.\n\n4) Fix an integer overflow in resolve_btfids which can wrongly trigger build\n   failures', ' from Friedrich Vock.\n\n5) Follow-up fixes for ARC JIT reported by static analyzers', '\n   from Shahab Vahedi.\n\n* tag \'for-netdev\' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  selftests/bpf: Cover verifier checks for mutating sockmap/sockhash\n  Revert ""bpf', ' sockmap: Prevent lock inversion deadlock in map delete elem""\n  bpf: Allow delete from sockmap/sockhash only if update is allowed\n  selftests/bpf: Add netkit test for pkt_type\n  selftests/bpf: Add netkit tests for mac address\n  netkit: Fix pkt_type override upon netkit pass verdict\n  netkit: Fix setting mac address in l2 mode\n  ARC', ' bpf: Fix issues reported by the static analyzers\n  selftests/bpf: extend multi-uprobe tests with USDTs\n  selftests/bpf: extend multi-uprobe tests with child thread case\n  libbpf: detect broken PID filtering logic for multi-uprobe\n  bpf: remove unnecessary rcu_read_{lock', 'unlock}() in multi-uprobe attach logic\n  bpf: fix multi-uprobe PID filtering logic\n  bpf: Fix potential integer overflow in resolve_btfids\n  MAINTAINERS: Add myself as reviewer of ARM64 BPF JIT\n====================\n\nLink: https://lore.kernel.org/r/20240527203551.29712-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Merged changes from the 'for-netdev' branch containing updates to the Linux kernel's BPF subsystem.,"merge, bpf, netdev",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a63bf556160fb19591183383da6757f52119981d,a63bf556160fb19591183383da6757f52119981d,Jakub Sitnicki,jakub@cloudflare.com,1716808809,Daniel Borkmann,daniel@iogearbox.net,1716831266,e6102ba20bfdef0c8312cf878c6e129995581b1c,3b9ce0491a43e9af7f108b2f1bced7cd35931660,"selftests/bpf: Cover verifier checks for mutating sockmap/sockhash

Verifier enforces that only certain program types can mutate sock{map","hash}
maps","["" that is update it or delete from it. Add test coverage for these\nchecks so we don't regress.\n\nSigned-off-by: Jakub Sitnicki <jakub@cloudflare.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nLink: https://lore.kernel.org/bpf/20240527-sockmap-verify-deletes-v1-3-944b372f2101@cloudflare.com\n"", '']",Add self-tests for verifying sockmap and sockhash mutation rules in the eBPF verifier.,"selftests, verifier, sockmap",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).', ""It's not related to any of the above.""]"
3b9ce0491a43e9af7f108b2f1bced7cd35931660,3b9ce0491a43e9af7f108b2f1bced7cd35931660,Jakub Sitnicki,jakub@cloudflare.com,1716808808,Daniel Borkmann,daniel@iogearbox.net,1716831265,3ba3ed3599c9ad372609e9e7ffb6bf1cba40e24d,98e948fb60d41447fd8d2d0c3b8637fc6b6dc26d,"Revert ""bpf"," sockmap: Prevent lock inversion deadlock in map delete elem""

This reverts commit ff91059932401894e6c86341915615c5eb0eca48.

This check is no longer needed. BPF programs attached to tracepoints are
now rejected by the verifier when they attempt to delete from a
sockmap/sockhash maps.

Signed-off-by: Jakub Sitnicki <jakub@cloudflare.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/bpf/20240527-sockmap-verify-deletes-v1-2-944b372f2101@cloudflare.com
",[''],Revert commit to remove unnecessary check for tracepoints in sockmap/sockhash operations.,"revert, sockmap, tracepoints",It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF maps,['tracepoints like programs']
98e948fb60d41447fd8d2d0c3b8637fc6b6dc26d,98e948fb60d41447fd8d2d0c3b8637fc6b6dc26d,Jakub Sitnicki,jakub@cloudflare.com,1716808807,Daniel Borkmann,daniel@iogearbox.net,1716831220,a96449f76eff9a59365db5570758d363176cea30,95348e463eabc803341c67d562f9e0a5f0a48fe6,"bpf: Allow delete from sockmap/sockhash only if update is allowed

We have seen an influx of syzkaller reports where a BPF program attached to
a tracepoint triggers a locking rule violation by performing a map_delete
on a sockmap/sockhash.

We don't intend to support this artificial use scenario. Extend the
existing verifier allowed-program-type check for updating sockmap/sockhash
to also cover deleting from a map.

From now on only BPF programs which were previously allowed to update
sockmap/sockhash can delete from these map types.

Fixes: ff9105993240 (""bpf"," sockmap: Prevent lock inversion deadlock in map delete elem"")
Reported-by: Tetsuo Handa <penguin-kernel@i-love.sakura.ne.jp>
Reported-by: syzbot+ec941d6e24f633a59172@syzkaller.appspotmail.com
Signed-off-by: Jakub Sitnicki <jakub@cloudflare.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Tested-by: syzbot+ec941d6e24f633a59172@syzkaller.appspotmail.com
Acked-by: John Fastabend <john.fastabend@gmail.com>
Closes: https://syzkaller.appspot.com/bug?extid=ec941d6e24f633a59172
Link: https://lore.kernel.org/bpf/20240527-sockmap-verify-deletes-v1-1-944b372f2101@cloudflare.com
",[''],Enhance verifier to restrict sockmap/sockhash delete operations to permitted BPF program types to avoid locking rule violations.,"sockmap,sockhash,locking",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,['tracepoints like programs']
e245ef8a0b06fa5a18ca3bdcf82430166419283e,e245ef8a0b06fa5a18ca3bdcf82430166419283e,Dave Thaler,dthaler1968@googlemail.com,1716704295,Alexei Starovoitov,ast@kernel.org,1716742722,62b3687ad60374687b0ed1def56fb1599e26dd8f,f980f13e4eb299abba6692365315196e1ba6fd2c,bpf," docs: Fix instruction.rst indentation

The table captions patch corrected indented most tables to work with
the table directive for adding a caption but missed two of them.

Signed-off-by: Dave Thaler <dthaler1968@gmail.com>
Reviewed-by: Christoph Hellwig <hch@lst.de>
Link: https://lore.kernel.org/r/20240526061815.22497-1-dthaler1968@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Fix indentation issues in instruction.rst table captions for proper rendering.,"indentation, documentation, table",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
2313022ec5942e3ddd2e4e57002ed71926887f87,2313022ec5942e3ddd2e4e57002ed71926887f87,Linus Torvalds,torvalds@linux-foundation.org,1716668268,Linus Torvalds,torvalds@linux-foundation.org,1716668268,bd0319acba4685e224f17bc302daa502d650f7a3,56fb6f92854f29dcb6c3dc3ba92eeda1b615e88c 919e3ece7f5aaf7b5f3c54538d5303b6eeeb053b,"Merge tag 'uml-for-linus-6.10-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/uml/linux

Pull UML updates from Richard Weinberger:

 - Fixes for -Wmissing-prototypes warnings and further cleanup

 - Remove callback returning void from rtc and virtio drivers

 - Fix bash location

* tag 'uml-for-linus-6.10-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/uml/linux: (26 commits)
  um: virtio_uml: Convert to platform remove callback returning void
  um: rtc: Convert to platform remove callback returning void
  um: Remove unused do_get_thread_area function
  um: Fix -Wmissing-prototypes warnings for __vdso_*
  um: Add an internal header shared among the user code
  um: Fix the declaration of kasan_map_memory
  um: Fix the -Wmissing-prototypes warning for get_thread_reg
  um: Fix the -Wmissing-prototypes warning for __switch_mm
  um: Fix -Wmissing-prototypes warnings for (rt_)sigreturn
  um: Stop tracking host PID in cpu_tasks
  um: process: remove unused 'n' variable
  um: vector: remove unused len variable/calculation
  um: vector: fix bpfflash parameter evaluation
  um: slirp: remove set but unused variable 'pid'
  um: signal: move pid variable where needed
  um: Makefile: use bash from the environment
  um: Add winch to winch_handlers before registering winch IRQ
  um: Fix -Wmissing-prototypes warnings for __warp_* and foo
  um: Fix -Wmissing-prototypes warnings for text_poke*
  um: Move declarations to proper headers
  ...
",,Merged UML updates focusing on cleanup and fixing -Wmissing-prototypes warnings from the Linux kernel.,"UML, cleanup, warnings",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
95348e463eabc803341c67d562f9e0a5f0a48fe6,95348e463eabc803341c67d562f9e0a5f0a48fe6,Daniel Borkmann,daniel@iogearbox.net,1716568579,Alexei Starovoitov,ast@kernel.org,1716659591,e8062791b197694f238e725e2bcb2cadfb5910f7,998ffeb2738e26f134dc8e63b5dcaece22573957,"selftests/bpf: Add netkit test for pkt_type

Add a test case to assert that the skb->pkt_type which was set from the BPF
program is retained from the netkit xmit side to the peer's device at tcx
ingress location.

  # ./vmtest.sh -- ./test_progs -t netkit
  [...]
  ./test_progs -t netkit
  [    1.140780] bpf_testmod: loading out-of-tree module taints kernel.
  [    1.141127] bpf_testmod: module verification failed: signature and/or required key missing - tainting kernel
  [    1.284601] tsc: Refined TSC clocksource calibration: 3408.006 MHz
  [    1.286672] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x311fd9b189d"," max_idle_ns: 440795225691 ns
  [    1.290384] clocksource: Switched to clocksource tsc
  #345     tc_netkit_basic:OK
  #346     tc_netkit_device:OK
  #347     tc_netkit_multi_links:OK
  #348     tc_netkit_multi_opts:OK
  #349     tc_netkit_neigh_links:OK
  #350     tc_netkit_pkt_type:OK
  Summary: 6/0 PASSED","[' 0 SKIPPED', ' 0 FAILED\n\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/r/20240524163619.26001-4-daniel@iogearbox.net\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit adds a test for verifying pkt_type in BPF netkit selftests.,"selftests,netkit,pkt_type",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
998ffeb2738e26f134dc8e63b5dcaece22573957,998ffeb2738e26f134dc8e63b5dcaece22573957,Daniel Borkmann,daniel@iogearbox.net,1716568578,Alexei Starovoitov,ast@kernel.org,1716659337,32d71431910f2beba683c40b443997986f08ba81,3998d184267dfcff858aaa84d3de17429253629d,"selftests/bpf: Add netkit tests for mac address

This adds simple tests around setting MAC addresses in the different
netkit modes.

Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/r/20240524163619.26001-3-daniel@iogearbox.net
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit adds selftests for netkit involving MAC address settings.,"selftests, netkit, MAC",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['other']
3998d184267dfcff858aaa84d3de17429253629d,3998d184267dfcff858aaa84d3de17429253629d,Daniel Borkmann,daniel@iogearbox.net,1716568577,Alexei Starovoitov,ast@kernel.org,1716659337,9862377f9644922177186ccfce9296e527fd3e03,d6fe532b7499e4575f9647879b7a34625817fe7f,"netkit: Fix pkt_type override upon netkit pass verdict

When running Cilium connectivity test suite with netkit in L2 mode"," we
found that compared to tcx a few tests were failing which pushed traffic
into an L7 proxy sitting in host namespace. The problem in particular is
around the invocation of eth_type_trans() in netkit.

In case of tcx","[' this is run before the tcx ingress is triggered inside\nhost namespace and thus if the BPF program uses the bpf_skb_change_type()\nhelper the newly set type is retained. However', ' in case of netkit', ' the\nlate eth_type_trans() invocation overrides the earlier decision from the\nBPF program which eventually leads to the test failure.\n\nInstead of eth_type_trans()', ' split out the relevant parts', ' meaning', ' reset\nof mac header and call to eth_skb_pkt_type() before the BPF program is run\nin order to have the same behavior as with tcx', ' and refactor a small helper\ncalled eth_skb_pull_mac() which is run in case it\'s passed up the stack\nwhere the mac header must be pulled. With this all connectivity tests pass.\n\nFixes: 35dfaad7188c (""netkit', ' bpf: Add bpf programmable net device"")\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Nikolay Aleksandrov <razor@blackwall.org>\nLink: https://lore.kernel.org/r/20240524163619.26001-2-daniel@iogearbox.net\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes pkt_type override issue in netkit affecting connectivity tests with traffic directed to L7 proxy.,"netkit, pkt_type, Cilium",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
d6fe532b7499e4575f9647879b7a34625817fe7f,d6fe532b7499e4575f9647879b7a34625817fe7f,Daniel Borkmann,daniel@iogearbox.net,1716568576,Alexei Starovoitov,ast@kernel.org,1716659337,303db3b2d23ec12cf01998f603ec97948b4f414b,dd6a403795f0c7b5c566f86f2ee6b687278d3c1c,"netkit: Fix setting mac address in l2 mode

When running Cilium connectivity test suite with netkit in L2 mode"," we
found that it is expected to be able to specify a custom MAC address for
the devices","[' in particular', ' cilium-cni obtains the specified MAC address\nby querying the endpoint and sets the MAC address of the interface inside\nthe Pod. Thus', ' fix the missing support in netkit for L2 mode.\n\nFixes: 35dfaad7188c (""netkit', ' bpf: Add bpf programmable net device"")\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Nikolay Aleksandrov <razor@blackwall.org>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nLink: https://lore.kernel.org/r/20240524163619.26001-1-daniel@iogearbox.net\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit fixes the issue of setting MAC addresses in Netkit when in L2 mode for Cilium connectivity tests.,"Netkit, MAC address, L2 mode",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['other']
dd6a403795f0c7b5c566f86f2ee6b687278d3c1c,dd6a403795f0c7b5c566f86f2ee6b687278d3c1c,Shahab Vahedi,shahab@synopsys.com,1716609388,Alexei Starovoitov,ast@kernel.org,1716659241,365a2e0e7266d9be0554f260d4bd58bf688a8f07,590016ad83de770153a09151336d95544d6bd7ad,ARC," bpf: Fix issues reported by the static analyzers

Also updated couple of comments along the way.

One of the issues reported was indeed a bug in the code:

  memset(ctx","[' 0', ' sizeof(ctx))      // original line\n  memset(ctx', ' 0', ' sizeof(*ctx))     // fixed line\n\nThat was a nice catch.\n\nReported-by: kernel test robot <lkp@intel.com>\nCloses: https://lore.kernel.org/oe-kbuild-all/202405222314.UG5F2NHn-lkp@intel.com/\nCloses: https://lore.kernel.org/oe-kbuild-all/202405232036.Xqoc3b0J-lkp@intel.com/\nSigned-off-by: Shahab Vahedi <shahab@synopsys.com>\nLink: https://lore.kernel.org/r/20240525035628.1026-1-list+bpf@vahedi.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']","This commit fixes issues reported by static analyzers, including a bug in the code, and updates some comments.","bug, static analyzers, comments",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
590016ad83de770153a09151336d95544d6bd7ad,590016ad83de770153a09151336d95544d6bd7ad,Alexei Starovoitov,ast@kernel.org,1716659163,Alexei Starovoitov,ast@kernel.org,1716659163,2f016edc5b9d6493df7368f06884af7bac6e574d,44382b3ed6b2787710c8ade06c0e97f5970a47c8 198034a87dfeb64d5a8359a5089022c6b923646e,"Merge branch 'fix-bpf-multi-uprobe-pid-filtering-logic'

Andrii Nakryiko says:

====================
Fix BPF multi-uprobe PID filtering logic

It turns out that current implementation of multi-uprobe PID filtering logic
is broken. It filters by thread"," while the promise is filtering by process.
Patch #1 fixes the logic trivially. The rest is testing and mitigations that
are necessary for libbpf to not break users of USDT programs.

v1->v2:
  - fix selftest in last patch (CI);
  - use semicolon in patch #3 (Jiri).
====================

Link: https://lore.kernel.org/r/20240521163401.3005045-1-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Fixes BPF multi-uprobe PID filtering logic from filtering by thread to filtering by process.,"BPF, uprobe, filtering",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,['kprobe/uprobe/ftrace like programs']
198034a87dfeb64d5a8359a5089022c6b923646e,198034a87dfeb64d5a8359a5089022c6b923646e,Andrii Nakryiko,andrii@kernel.org,1716309241,Alexei Starovoitov,ast@kernel.org,1716659162,2f016edc5b9d6493df7368f06884af7bac6e574d,70342420a1cf1173bdec456e5fa574a804e422db,"selftests/bpf: extend multi-uprobe tests with USDTs

Validate libbpf's USDT-over-multi-uprobe logic by adding USDTs to
existing multi-uprobe tests. This checks correct libbpf fallback to
singular uprobes (when run on older kernels with buggy PID filtering).
We reuse already established child process and child thread testing
infrastructure"," so additions are minimal. These test fail on either
older kernels or older version of libbpf that doesn't detect PID
filtering problems.

Acked-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240521163401.3005045-6-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Enhanced multi-uprobe tests with USDTs to validate libbpf's logic and improve testing on older kernels.,"multi-uprobe, USDTs, libbpf",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tracepoints like programs']
70342420a1cf1173bdec456e5fa574a804e422db,70342420a1cf1173bdec456e5fa574a804e422db,Andrii Nakryiko,andrii@kernel.org,1716309240,Alexei Starovoitov,ast@kernel.org,1716659162,4636693b5cc3ec019e1c1e69b420f136b41b0ee1,04d939a2ab229a3821f04fc81f7c027842f501f1,"selftests/bpf: extend multi-uprobe tests with child thread case

Extend existing multi-uprobe tests to test that PID filtering works
correctly. We already have child *process* tests"," but we need also child
*thread* tests. This patch adds spawn_thread() helper to start child
thread","[' wait for it to be ready', ' and then instruct it to trigger desired\nuprobes.\n\nAdditionally', ' we extend BPF-side code to track thread ID', ' not just\nprocess ID. Also we detect whether extraneous triggerings with\nunexpected process IDs happened', ' and validate that none of that happened\nin practice.\n\nThese changes prove that fixed PID filtering logic for multi-uprobe\nworks as expected. These tests fail on old kernels.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/r/20240521163401.3005045-5-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Extend multi-uprobe tests to include PID filtering for child threads.,"multi-uprobe,PIDs,threads",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
04d939a2ab229a3821f04fc81f7c027842f501f1,04d939a2ab229a3821f04fc81f7c027842f501f1,Andrii Nakryiko,andrii@kernel.org,1716309239,Alexei Starovoitov,ast@kernel.org,1716659162,9d3f1d6d2832d365a5f87a1ff8b7dc9f2328b487,4a8f635a60540888dab3804992e86410360339c8,"libbpf: detect broken PID filtering logic for multi-uprobe

Libbpf is automatically (and transparently to user) detecting
multi-uprobe support in the kernel", and,"[' if supported', ' uses\nmulti-uprobes to improve USDT attachment speed.\n\nUSDTs can be attached system-wide or for the specific process by PID. In\nthe latter case', ' we rely on correct kernel logic of not triggering USDT\nfor unrelated processes.\n\nAs such', ' on older kernels that do support multi-uprobes', ' but still have\nbroken PID filtering logic', ' we need to fall back to singular uprobes.\n\nUnfortunately', ' whether user is using PID filtering or not is known at\nthe attachment time', ' which happens after relevant BPF programs were\nloaded into the kernel. Also unfortunately', ' we need to make a call\nwhether to use multi-uprobes or singular uprobe for SEC(""usdt"") programs\nduring BPF object load time', ' at which point we have no information about\npossible PID filtering.\n\nThe distinction between single and multi-uprobes is small', ' but important\nfor the kernel. Multi-uprobes get BPF_TRACE_UPROBE_MULTI attach type', '\nand kernel internally substitiute different implementation of some of\nBPF helpers (e.g.', ' bpf_get_attach_cookie()) depending on whether uprobe\nis multi or singular. So', "" multi-uprobes and singular uprobes cannot be\nintermixed.\n\nAll the above implies that we have to make an early and conservative\ncall about the use of multi-uprobes. And so this patch modifies libbpf's\nexisting feature detector for multi-uprobe support to also check correct\nPID filtering. If PID filtering is not yet fixed"", "" we fall back to\nsingular uprobes for USDTs.\n\nThis extension to feature detection is simple thanks to kernel's -EINVAL\naddition for pid < 0.\n\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240521163401.3005045-4-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Libbpf now detects broken PID filtering logic for multi-uprobe support in the kernel.,"libbpf,multi-uprobe,PID-filtering",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,['kprobe/uprobe/ftrace like programs']
4a8f635a60540888dab3804992e86410360339c8,4a8f635a60540888dab3804992e86410360339c8,Andrii Nakryiko,andrii@kernel.org,1716309238,Alexei Starovoitov,ast@kernel.org,1716659162,d5616c72bde13807d4ff75fab5acfa3c5371143b,46ba0e49b64232adac35a2bc892f1710c5b0fb7f,bpf: remove unnecessary rcu_read_{lock,"unlock}() in multi-uprobe attach logic

get_pid_task() internally already calls rcu_read_lock() and
rcu_read_unlock()","[' so there is no point to do this one extra time.\n\nThis is a drive-by improvement and has no correctness implications.\n\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240521163401.3005045-3-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Removed redundant RCU read locks in the multi-uprobe attach logic for bpf.,"bpf, RCU, uprobe",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
46ba0e49b64232adac35a2bc892f1710c5b0fb7f,46ba0e49b64232adac35a2bc892f1710c5b0fb7f,Andrii Nakryiko,andrii@kernel.org,1716309237,Alexei Starovoitov,ast@kernel.org,1716659162,6fd4199126856396394680fd9553ac4c14fd81c9,44382b3ed6b2787710c8ade06c0e97f5970a47c8,"bpf: fix multi-uprobe PID filtering logic

Current implementation of PID filtering logic for multi-uprobes in
uprobe_prog_run() is filtering down to exact *thread*"," while the intent
for PID filtering it to filter by *process* instead. The check in
uprobe_prog_run() also differs from the analogous one in
uprobe_multi_link_filter() for some reason. The latter is correct","['\nchecking task->mm', ' not the task itself.\n\nFix the check in uprobe_prog_run() to perform the same task->mm check.\n\nWhile doing this', ' we also update get_pid_task() use to use PIDTYPE_TGID\ntype of lookup', "" given the intent is to get a representative task of an\nentire process. This doesn't change behavior"", ' but seems more logical. It\nwould hold task group leader task now', ' not any random thread task.\n\nLast but not least', ' given multi-uprobe support is half-broken due to\nthis PID filtering logic (depending on whether PID filtering is\nimportant or not)', "" we need to make it easy for user space consumers\n(including libbpf) to easily detect whether PID filtering logic was\nalready fixed.\n\nWe do it here by adding an early check on passed pid parameter. If it's\nnegative (and so has no chance of being a valid PID)"", ' we return -EINVAL.\nPrevious behavior would eventually return -ESRCH (""No process found"")', ""\ngiven there can't be any process with negative PID. This subtle change\nwon't make any practical change in behavior"", ' but will allow applications\nto detect PID filtering fixes easily. Libbpf fixes take advantage of\nthis in the next patch.\n\nCc: stable@vger.kernel.org\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nFixes: b733eeade420 (""bpf: Add pid filter support for uprobe_multi link"")\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240521163401.3005045-2-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix process PID filtering logic for multi-uprobes in the uprobe_prog_run function.,"PID filtering, multi-uprobes, logic",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['kprobe/uprobe/ftrace like programs']
f980f13e4eb299abba6692365315196e1ba6fd2c,f980f13e4eb299abba6692365315196e1ba6fd2c,Dave Thaler,dthaler1968@googlemail.com,1716651212,Alexei Starovoitov,ast@kernel.org,1716658917,cf2ec6c3b4a9fd8bcf0788af163eaa9be5367004,6a6d8b6f00ade597e0030669fae3fdf57cfba33b,bpf," docs: Clarify call local offset

In the Jump instructions section it explains that the offset is
""relative to the instruction following the jump instruction"".
But the program-local section confusingly said ""referenced by
offset from the call instruction","[' similar to JA"".\n\nThis patch updates that sentence with consistent wording', "" saying\nit's relative to the instruction following the call instruction.\n\nSigned-off-by: Dave Thaler <dthaler1968@gmail.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240525153332.21355-1-dthaler1968@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Clarifies documentation on offset referencing in program-local section for BPF jump and call instructions.,"documentation, offset, jump",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
6a6d8b6f00ade597e0030669fae3fdf57cfba33b,6a6d8b6f00ade597e0030669fae3fdf57cfba33b,Dave Thaler,dthaler1968@googlemail.com,1716569178,Alexei Starovoitov,ast@kernel.org,1716658771,1d321b4d31afdaa22b00a9647b5d4e65963eadd1,4e1215d9a1903fc9e976aa8903674d050c7af5ff,bpf," docs: Add table captions

As suggested by Ines Robles in his IETF GENART review at
https://datatracker.ietf.org/doc/review-ietf-bpf-isa-02-genart-lc-robles-2024-05-16/

Signed-off-by: Dave Thaler <dthaler1968@gmail.com>
Link: https://lore.kernel.org/r/20240524164618.18894-1-dthaler1968@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The commit adds table captions to documentation as per an IETF GENART review suggestion.,"table captions, documentation, review",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
4e1215d9a1903fc9e976aa8903674d050c7af5ff,4e1215d9a1903fc9e976aa8903674d050c7af5ff,Dave Thaler,dthaler1968@googlemail.com,1716241975,Alexei Starovoitov,ast@kernel.org,1716658743,c087489b3a7f5ffb2b73a42022a4a4ad796c70ba,a985fdca5e7e665d58dc40c92a67c8b67b6291db,bpf," docs: clarify sign extension of 64-bit use of 32-bit imm

imm is defined as a 32-bit signed integer.

{MOV","[' K', ' ALU64} says it does ""dst = src"" (where src is \'imm\') and it\ndoes do dst = (s64)imm', ' which in that sense does sign extend imm. The MOVSX\ninstruction is explained as sign extending', ' so added the example of\n{MOV', ' K', ' ALU64} to make this more clear.\n\n{JLE', ' K', ' JMP} says it does ""PC += offset if dst <= src"" (where src is \'imm\'', '\nand the comparison is unsigned). This was apparently ambiguous to some\nreaders as to whether the comparison was ""dst <= (u64)(u32)imm"" or\n""dst <= (u64)(s64)imm"" so added an example to make this more clear.\n\nv1 -> v2: Address comments from Yonghong\n\nSigned-off-by: Dave Thaler <dthaler1968@googlemail.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nAcked-by: David Vernet <void@manifault.com>\nLink: https://lore.kernel.org/r/20240520215255.10595-1-dthaler1968@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Clarify documentation regarding sign extension of 64-bit use of 32-bit immediate values.,"sign extension, 64-bit, documentation",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a985fdca5e7e665d58dc40c92a67c8b67b6291db,a985fdca5e7e665d58dc40c92a67c8b67b6291db,Dave Thaler,dthaler1968@googlemail.com,1715965135,Alexei Starovoitov,ast@kernel.org,1716658715,36dce8a271663ecc713da392e09d22f6f6633dad,4652072e7b9d643edc9ebb04e3e2c021461b7af0,bpf," docs: Use RFC 2119 language for ISA requirements

Per IETF convention and discussion at LSF/MM/BPF","[' use MUST etc.\nkeywords as requested by IETF Area Director review.  Also as\nrequested', ' indicate that documenting BTF is out of scope of this\ndocument and will be covered by a separate IETF specification.\n\nAdded paragraph about the terminology that is required IETF boilerplate\nand must be worded exactly as such.\n\nSigned-off-by: Dave Thaler <dthaler1968@googlemail.com>\nAcked-by: David Vernet <void@manifault.com>\nLink: https://lore.kernel.org/r/20240517165855.4688-1-dthaler1968@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Update documentation to use RFC 2119 language for ISA requirements.,"documentation, RFC 2119, ISA",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
4652072e7b9d643edc9ebb04e3e2c021461b7af0,4652072e7b9d643edc9ebb04e3e2c021461b7af0,Dave Thaler,dthaler1968@googlemail.com,1715960085,Alexei Starovoitov,ast@kernel.org,1716658669,19ee76f42e4dd42c51b0fed02ab269c0d4053c60,2c1713a8f1c94033a6e00aae4693ab03e8a3b9f1,bpf," docs: Move sentence about returning R0 to abi.rst

As discussed at LSF/MM/BPF","[' the sentence about using R0 for returning\nvalues from calls is part of the calling convention and belongs in\nabi.rst.  Any further additions or clarifications to this text are left\nfor future patches on abi.rst.  The current patch is simply to unblock\nprogression of instruction-set.rst to a standard.\n\nIn contrast', ' the restriction of register numbers to the range 0-10\nis untouched', ' left in the instruction-set.rst definition of the\nsrc_reg and dst_reg fields.\n\nSigned-off-by: Dave Thaler <dthaler1968@googlemail.com>\nLink: https://lore.kernel.org/r/20240517153445.3914-1-dthaler1968@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Moved documentation sentence about returning R0 to abi.rst in bpf.,"documentation, returning, R0",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
b1480ed230acf4f7f069a7f5e3ddda62bbf4ba97,b1480ed230acf4f7f069a7f5e3ddda62bbf4ba97,Will Deacon,will@kernel.org,1716327493,Andrew Morton,akpm@linux-foundation.org,1716576906,d22c6852ba72b8f10f1de5015f98a78eb8fa3315,fb9293b6b0156fbf6ab97a1625d99a29c36d9f0c,"arm64: patching: fix handling of execmem addresses

Klara Modin reported warnings for a kernel configured with BPF_JIT but
without MODULES:

[   44.131296] Trying to vfree() bad address (000000004a17c299)
[   44.138024] WARNING: CPU: 1 PID: 193 at mm/vmalloc.c:3189 remove_vm_area (mm/vmalloc.c:3189 (discriminator 1))
[   44.146675] CPU: 1 PID: 193 Comm: kworker/1:2 Tainted: G      D W          6.9.0-01786-g2c9e5d4a0082 #25
[   44.158229] Hardware name: Raspberry Pi 3 Model B (DT)
[   44.164433] Workqueue: events bpf_prog_free_deferred
[   44.170492] pstate: 60000005 (nZCv daif -PAN -UAO -TCO -DIT -SSBS BTYPE=--)
[   44.178601] pc : remove_vm_area (mm/vmalloc.c:3189 (discriminator 1))
[   44.183705] lr : remove_vm_area (mm/vmalloc.c:3189 (discriminator 1))
[   44.188772] sp : ffff800082a13c70
[   44.193112] x29: ffff800082a13c70 x28: 0000000000000000 x27: 0000000000000000
[   44.201384] x26: 0000000000000000 x25: ffff00003a44efa0 x24: 00000000d4202000
[   44.209658] x23: ffff800081223dd0 x22: ffff00003a198a40 x21: ffff8000814dd880
[   44.217924] x20: 00000000d4202000 x19: ffff8000814dd880 x18: 0000000000000006
[   44.226206] x17: 0000000000000000 x16: 0000000000000020 x15: 0000000000000002
[   44.234460] x14: ffff8000811a6370 x13: 0000000020000000 x12: 0000000000000000
[   44.242710] x11: ffff8000811a6370 x10: 0000000000000144 x9 : ffff8000811fe370
[   44.250959] x8 : 0000000000017fe8 x7 : 00000000fffff000 x6 : ffff8000811fe370
[   44.259206] x5 : 0000000000000000 x4 : 0000000000000000 x3 : 0000000000000000
[   44.267457] x2 : 0000000000000000 x1 : 0000000000000000 x0 : ffff000002203240
[   44.275703] Call trace:
[   44.279158] remove_vm_area (mm/vmalloc.c:3189 (discriminator 1))
[   44.283858] vfree (mm/vmalloc.c:3322)
[   44.287835] execmem_free (mm/execmem.c:70)
[   44.292347] bpf_jit_free_exec+0x10/0x1c
[   44.297283] bpf_prog_pack_free (kernel/bpf/core.c:1006)
[   44.302457] bpf_jit_binary_pack_free (kernel/bpf/core.c:1195)
[   44.307951] bpf_jit_free (include/linux/filter.h:1083 arch/arm64/net/bpf_jit_comp.c:2474)
[   44.312342] bpf_prog_free_deferred (kernel/bpf/core.c:2785)
[   44.317785] process_one_work (kernel/workqueue.c:3273)
[   44.322684] worker_thread (kernel/workqueue.c:3342 (discriminator 2) kernel/workqueue.c:3429 (discriminator 2))
[   44.327292] kthread (kernel/kthread.c:388)
[   44.331342] ret_from_fork (arch/arm64/kernel/entry.S:861)

The problem is because bpf_arch_text_copy() silently fails to write to the
read-only area as a result of patch_map() faulting and the resulting
-EFAULT being chucked away.

Update patch_map() to use CONFIG_EXECMEM instead of
CONFIG_STRICT_MODULE_RWX to check for vmalloc addresses.

Link: https://lkml.kernel.org/r/20240521213813.703309-1-rppt@kernel.org
Fixes: 2c9e5d4a0082 (""bpf: remove CONFIG_BPF_JIT dependency on CONFIG_MODULES of"")
Signed-off-by: Will Deacon <will@kernel.org>
Signed-off-by: Mike Rapoport (IBM) <rppt@kernel.org>
Reported-by: Klara Modin <klarasmodin@gmail.com>
Closes: https://lore.kernel.org/all/7983fbbf-0127-457c-9394-8d6e4299c685@gmail.com
Tested-by: Klara Modin <klarasmodin@gmail.com>
Cc: Björn Töpel <bjorn@kernel.org>
Cc: Luis Chamberlain <mcgrof@kernel.org>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
",,Fix handling of execmem addresses in arm64 patching to address a BPF_JIT warning when configured without modules.,"arm64, execmem, BPF_JIT",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2c1713a8f1c94033a6e00aae4693ab03e8a3b9f1,2c1713a8f1c94033a6e00aae4693ab03e8a3b9f1,Thomas Weißschuh,linux@weissschuh.net,1716044327,Daniel Borkmann,daniel@iogearbox.net,1716565472,a532036e561cc47497039c481b72c69d848a9968,99fa63d9ca60c4c1cc843fde205e4bc6e86b218f,"bpf: constify member bpf_sysctl_kern:: Table

The sysctl core is preparing to only expose instances of struct ctl_table
as ""const"". This will also affect the ctl_table argument of sysctl handlers","
for which bpf_sysctl_kern::table is also used.

As the function prototype of all sysctl handlers throughout the tree
needs to stay consistent that change will be done in one commit.

To reduce the size of that final commit","[' switch this utility type which\nis not bound by ""typedef proc_handler"" to ""const struct ctl_table"".\n\nNo functional change.\n\nSigned-off-by: Thomas Weißschuh <linux@weissschuh.net>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Joel Granados <j.granados@samsung.com>\nLink: https://lore.kernel.org/bpf/20240518-sysctl-const-handler-bpf-v1-1-f0d7186743c1@weissschuh.net\n', '']",The commit modifies bpf_sysctl_kern to constify the table parameter in preparation for changes to sysctl handler consistency.,"bpf_sysctl_kern,constify,sysctl",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The syscall interface,"[""It's not related to any of the above.""]"
99fa63d9ca60c4c1cc843fde205e4bc6e86b218f,99fa63d9ca60c4c1cc843fde205e4bc6e86b218f,Xiao Wang,xiao.w.wang@intel.com,1716095107,Daniel Borkmann,daniel@iogearbox.net,1716565233,b9b2b76672511530c0a304e2b020ea804b333542,e944fc8152744a41dc62e720995538e48b053bb9,riscv," bpf: Try RVC for reg move within BPF_CMPXCHG JIT

We could try to emit compressed insn for reg move operation during CMPXCHG
JIT","[' the instruction compression has no impact on the jump offsets of\nfollowing forward and backward jump instructions.\n\nSigned-off-by: Xiao Wang <xiao.w.wang@intel.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Björn Töpel <bjorn@kernel.org>\nLink: https://lore.kernel.org/bpf/20240519050507.2217791-1-xiao.w.wang@intel.com\n', '']",The commit attempts to emit compressed instructions for register move operations during CMPXCHG JIT for RISC-V architecture.,"RISC-V,compressed,insn",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e944fc8152744a41dc62e720995538e48b053bb9,e944fc8152744a41dc62e720995538e48b053bb9,Xiao Wang,xiao.w.wang@intel.com,1716434315,Daniel Borkmann,daniel@iogearbox.net,1716563816,f3e3ab4a55d73ebb1665384c0713b70ef29c07b8,c12603e76ef666ce5c51a9d6faf155c9e3de7601,riscv," bpf: Use STACK_ALIGN macro for size rounding up

Use the macro STACK_ALIGN that is defined in asm/processor.h for stack size
rounding up","[' just like bpf_jit_comp32.c does.\n\nSigned-off-by: Xiao Wang <xiao.w.wang@intel.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Pu Lehui <pulehui@huawei.com>\nLink: https://lore.kernel.org/bpf/20240523031835.3977713-1-xiao.w.wang@intel.com\n', '']",The commit utilizes the STACK_ALIGN macro for stack size rounding up in the RISC-V architecture.,"STACK_ALIGN, stack, RISC-V",It's a performance optimization.,"Simple, can be used without much configuration. For example, a simple helper function.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
44382b3ed6b2787710c8ade06c0e97f5970a47c8,44382b3ed6b2787710c8ade06c0e97f5970a47c8,Friedrich Vock,friedrich.vock@gmx.de,1715670571,Daniel Borkmann,daniel@iogearbox.net,1716563532,ffd66a523cd4888ffba95883d30df99f22a9fb7d,8d00547ea8754afdc4a550af2fb7af2e3ba93cf8,"bpf: Fix potential integer overflow in resolve_btfids

err is a 32-bit integer", but elf_update returns an off_t,"[' which is 64-bit\nat least on 64-bit platforms. If symbols_patch is called on a binary between\n2-4GB in size', ' the result will be negative when cast to a 32-bit integer', '\nwhich the code assumes means an error occurred. This can wrongly trigger\nbuild failures when building very large kernel images.\n\nFixes: fbbb68de80a4 (""bpf: Add resolve_btfids tool to resolve BTF IDs in ELF object"")\nSigned-off-by: Friedrich Vock <friedrich.vock@gmx.de>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240514070931.199694-1-friedrich.vock@gmx.de\n', '']",Fix potential integer overflow in resolve_btfids function.,"integer,overflow,resolve_btfids",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c12603e76ef666ce5c51a9d6faf155c9e3de7601,c12603e76ef666ce5c51a9d6faf155c9e3de7601,Xiao Wang,xiao.w.wang@intel.com,1715850270,Daniel Borkmann,daniel@iogearbox.net,1716562392,82fb7b57e3cd4b398760b135b4a6c7e916e26037,ecec1887e24f11a3fcc391aa0f33fe0802be0804,riscv," bpf: Optimize zextw insn with Zba extension

The Zba extension provides add.uw insn which can be used to implement
zext.w with rs2 set as ZERO.

Signed-off-by: Xiao Wang <xiao.w.wang@intel.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Tested-by: Pu Lehui <pulehui@huawei.com>
Reviewed-by: Andrew Jones <ajones@ventanamicro.com>
Reviewed-by: Pu Lehui <pulehui@huawei.com>
Link: https://lore.kernel.org/bpf/20240516090430.493122-1-xiao.w.wang@intel.com
",[''],Optimize zextw instruction with Zba extension for RISC-V architecture.,"Zba extension,zextw,RISC-V",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ecec1887e24f11a3fcc391aa0f33fe0802be0804,ecec1887e24f11a3fcc391aa0f33fe0802be0804,Martin KaFai Lau,martin.lau@kernel.org,1716498837,Martin KaFai Lau,martin.lau@kernel.org,1716498890,d730869ec1e4a9fbdf865f952e8fc26c28503f71,a87f34e742d279d54d529e4bc4763fdaab32a466 c34e3ab2a76e6a55a64e0d56acc5607062c2bad9,"Merge branch 'Replace mono_delivery_time with tstamp_type'

Abhishek Chauhan says:

====================
Patch 1 :- This patch takes care of only renaming the mono delivery
timestamp to tstamp_type with no change in functionality of
existing available code in kernel also
Starts assigning tstamp_type with either mono or real and
introduces a new enum in the skbuff.h"," again no change in functionality
of the existing available code in kernel ","[' just making the code scalable.\n\nPatch 2 :- Additional bit was added to support tai timestamp type to\navoid tstamp drops in the forwarding path when testing TC-ETF.\nPatch is also updating bpf filter.c\nSome updates to bpf header files with introduction to BPF_SKB_CLOCK_TAI\nand documentation updates stating deprecation of BPF_SKB_TSTAMP_UNSPEC\nand BPF_SKB_TSTAMP_DELIVERY_MONO\n\nPatch 3:- Handles forwarding of UDP packets with TAI clock id tstamp_type\ntype with supported changes for tc_redirect/tc_redirect_dtime\nto handle forwarding of UDP packets with TAI tstamp_type\n====================\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Renames mono delivery timestamp to tstamp_type without changing functionality in the kernel.,"rename,tstamp_type,enum",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
c34e3ab2a76e6a55a64e0d56acc5607062c2bad9,c34e3ab2a76e6a55a64e0d56acc5607062c2bad9,Abhishek Chauhan,quic_abchauha@quicinc.com,1715289514,Martin KaFai Lau,martin.lau@kernel.org,1716498883,d730869ec1e4a9fbdf865f952e8fc26c28503f71,1693c5db6ab8262e6f5263f9d211855959aa5acd,"selftests/bpf: Handle forwarding of UDP CLOCK_TAI packets

With changes in the design to forward CLOCK_TAI in the skbuff
framework","  existing selftest framework needs modification
to handle forwarding of UDP packets with CLOCK_TAI as clockid.

Signed-off-by: Abhishek Chauhan <quic_abchauha@quicinc.com>
Reviewed-by: Martin KaFai Lau <martin.lau@kernel.org>
Link: https://lore.kernel.org/r/20240509211834.3235191-4-quic_abchauha@quicinc.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Modified selftests/bpf to handle forwarding of UDP packets with CLOCK_TAI in the skbuff framework.,"selftests, UDP, CLOCK_TAI",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
a87f34e742d279d54d529e4bc4763fdaab32a466,a87f34e742d279d54d529e4bc4763fdaab32a466,Brad Cowie,brad@faucet.nz,1716354432,Martin KaFai Lau,martin.lau@kernel.org,1716415256,cb8876a56ce1b7a557e21a223cd6efb486799086,ece4b296904167336d0aaab26bd7122018835202,"selftests/bpf: Update tests for new ct zone opts for nf_conntrack kfuncs

Add test for allocating and looking up ct entry in a
non-default ct zone with kfuncs bpf_{xdp","skb}_ct_alloc
and bpf_{xdp","[""skb}_ct_lookup.\n\nAdd negative tests for looking up ct entry in a different\nct zone to where it was allocated and with a different\ndirection.\n\nUpdate reserved test for old struct definition to test for\nct_zone_id being set when opts size isn't NF_BPF_CT_OPTS_SZ (16).\n\nSigned-off-by: Brad Cowie <brad@faucet.nz>\nLink: https://lore.kernel.org/r/20240522050712.732558-2-brad@faucet.nz\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n"", '']",This commit updates self-tests for new connection tracking zone options in nf_conntrack kfuncs.,"self-tests, nf_conntrack, kfuncs",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['xdp like programs', 'tc/netfilter like programs']"
ece4b296904167336d0aaab26bd7122018835202,ece4b296904167336d0aaab26bd7122018835202,Brad Cowie,brad@faucet.nz,1716354431,Martin KaFai Lau,martin.lau@kernel.org,1716415256,1e76d69c55a244163bfdef543ad42410618ffb22,6c8d7598dfed759bf1d9d0322b4c2b42eb7252d8,"net: netfilter: Make ct zone opts configurable for bpf ct helpers

Add ct zone id and direction to bpf_ct_opts so that arbitrary ct zones
can be used for xdp/tc bpf ct helper functions bpf_{xdp","skb}_ct_alloc
and bpf_{xdp","['skb}_ct_lookup.\n\nSigned-off-by: Brad Cowie <brad@faucet.nz>\nLink: https://lore.kernel.org/r/20240522050712.732558-1-brad@faucet.nz\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Make connection tracking zone options configurable for BPF connection tracking helpers in xdp/tc programs.,"ct zone, bpf ct, netfilter",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['xdp like programs', 'tc/netfilter like programs']"
6c8d7598dfed759bf1d9d0322b4c2b42eb7252d8,6c8d7598dfed759bf1d9d0322b4c2b42eb7252d8,Geliang Tang,tanggeliang@kylinos.cn,1715926906,Andrii Nakryiko,andrii@kernel.org,1716314841,5026a8607e161c488dc372ab9f279f7c1894edbb,1b0215a3633a4c54ed7ec3af93e7a782dda8d965,"selftests/bpf: Fix prog numbers in test_sockmap

bpf_prog5 and bpf_prog7 are removed from progs/test_sockmap_kern.h in
commit d79a32129b21 (""bpf: Selftests"," remove prints from sockmap tests"")","['\nnow there are only 9 progs in it', ' not 11:\n\n\tSEC(""sk_skb1"")\n\tint bpf_prog1(struct __sk_buff *skb)\n\tSEC(""sk_skb2"")\n\tint bpf_prog2(struct __sk_buff *skb)\n\tSEC(""sk_skb3"")\n\tint bpf_prog3(struct __sk_buff *skb)\n\tSEC(""sockops"")\n\tint bpf_sockmap(struct bpf_sock_ops *skops)\n\tSEC(""sk_msg1"")\n\tint bpf_prog4(struct sk_msg_md *msg)\n\tSEC(""sk_msg2"")\n\tint bpf_prog6(struct sk_msg_md *msg)\n\tSEC(""sk_msg3"")\n\tint bpf_prog8(struct sk_msg_md *msg)\n\tSEC(""sk_msg4"")\n\tint bpf_prog9(struct sk_msg_md *msg)\n\tSEC(""sk_msg5"")\n\tint bpf_prog10(struct sk_msg_md *msg)\n\nThis patch updates the array sizes of prog_fd[]', ' prog_attach_type[] and\nprog_type[] from 11 to 9 accordingly.\n\nFixes: d79a32129b21 (""bpf: Selftests', ' remove prints from sockmap tests"")\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/9c10d9f974f07fcb354a43a8eca67acb2fafc587.1715926605.git.tanggeliang@kylinos.cn\n', '']",Fixes program numbering in selftests related to sockmap handling in BPF.,"selftests, sockmap, fix",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
1b0215a3633a4c54ed7ec3af93e7a782dda8d965,1b0215a3633a4c54ed7ec3af93e7a782dda8d965,Ying Zhang,yingzhang098@163.com,1716308222,Andrii Nakryiko,andrii@kernel.org,1716313699,301d934b4eb09ab3c45b71e446dab2b2f7ecaa42,f4aba3471cfb9ccf69b476463f19b4c50fef6b14,"bpf: Remove unused variable ""prev_state""

The variable ""prev_state"" is not used for any actual operations

v2: Fix commit message and description.

Signed-off-by: Ying Zhang <yingzhang098@163.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/bpf/20240521161702.4339-1-yingzhang098@163.com
",,"Remove the unused variable ""prev_state"" from the BPF codebase.","remove, unused, variable",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f4aba3471cfb9ccf69b476463f19b4c50fef6b14,f4aba3471cfb9ccf69b476463f19b4c50fef6b14,Ivan Babrou,ivan@cloudflare.com,1716245509,Andrii Nakryiko,andrii@kernel.org,1716312988,d450f78e9d0d25957ef384db728470f20837a26c,6f130e4d4a5f7174f98300376f3994817ad7e21c,"bpftool: Un-const bpf_func_info to fix it for llvm 17 and newer

LLVM 17 started treating const structs as constants:

* https://github.com/llvm/llvm-project/commit/0b2d5b967d98

Combined with pointer laundering via ptr_to_u64", which takes a const ptr,"['\nbut in reality treats the underlying memory as mutable', ' this makes clang\nalways pass zero to btf__type_by_id', ' which breaks full name resolution.\n\nDisassembly before (LLVM 16) and after (LLVM 17):\n\n    -    8b 75 cc                 mov    -0x34(%rbp)', '%esi\n    -    e8 47 8d 02 00           call   3f5b0 <btf__type_by_id>\n    +    31 f6                    xor    %esi', ""%esi\n    +    e8 a9 8c 02 00           call   3f510 <btf__type_by_id>\n\nIt's a bigger project to fix this properly (and a question whether LLVM\nitself should detect this)"", "" but for right now let's just fix bpftool.\n\nFor more information"", ' see this thread in bpf mailing list:\n\n* https://lore.kernel.org/bpf/CABWYdi0ymezpYsQsPv7qzpx2fWuTkoD1-wG1eT-9x-TSREFrQg@mail.gmail.com/T/\n\nFixes: b662000aff84 (""bpftool: Adding support for BTF program names"")\nSigned-off-by: Ivan Babrou <ivan@cloudflare.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Nick Desaulniers <ndesaulniers@google.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/bpf/20240520225149.5517-1-ivan@cloudflare.com\n', '']",This commit modifies bpftool to handle non-const bpf_func_info to ensure compatibility with LLVM version 17 and newer.,"bpftool, LLVM 17, bpf_func_info",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6f130e4d4a5f7174f98300376f3994817ad7e21c,6f130e4d4a5f7174f98300376f3994817ad7e21c,Mohammad Shehar Yaar Tausif,sheharyaar48@gmail.com,1715844251,Alexei Starovoitov,ast@kernel.org,1716054376,3d557fc55d69779ddc771515c05f96a2c719ecb3,34021caef79f76e70ac31247d321ecd0683c4939,"bpf: Fix order of args in call to bpf_map_kvcalloc

The original function call passed size of smap->bucket before the number of
buckets which raises the error 'calloc-transposed-args' on compilation.

Signed-off-by: Mohammad Shehar Yaar Tausif <sheharyaar48@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240516072411.42016-1-sheharyaar48@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Fix order of arguments in bpf_map_kvcalloc to resolve calloc-transposed-args compilation error.,"args, bpf_map_kvcalloc, calloc",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
34021caef79f76e70ac31247d321ecd0683c4939,34021caef79f76e70ac31247d321ecd0683c4939,Alan Maguire,alan.maguire@oracle.com,1715704036,Alexei Starovoitov,ast@kernel.org,1716054376,b0fa2ab7294afb00d3ed9d81c4442cbd8767c372,e7b64f9d3f5b10186038201e0b91f734cbd7fc3d,kbuild," bpf: Use test-ge check for v1.25-only pahole

There is no need to set the pahole v1.25-only flags in an
""ifeq"" version clause; we are already in a <= v1.25 branch
of ""ifeq""","[' so that combined with a ""test-ge"" v1.25 ensures the\nflags will be applied for v1.25 only.\n\nSuggested-by: Masahiro Yamada <masahiroy@kernel.org>\nSigned-off-by: Alan Maguire <alan.maguire@oracle.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240514162716.2448265-1-alan.maguire@oracle.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Simplified kbuild configurations by removing redundant pahole version check for v1.25.,"kbuild,pahole,version",It's a build system or CI/CD change.,"Simple, can be used without much configuration. For example, a simple helper function.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
e7b64f9d3f5b10186038201e0b91f734cbd7fc3d,e7b64f9d3f5b10186038201e0b91f734cbd7fc3d,Artem Savkov,asavkov@redhat.com,1715599618,Alexei Starovoitov,ast@kernel.org,1716054376,623e749b91a4c1148678d935ec1fc53a59b4fee8,94133cf24bb33889aac267a7f0e3e6a08b8a8e5a,"bpftool: Fix make dependencies for vmlinux.h

With pre-generated vmlinux.h there is no dependency on neither vmlinux
nor bootstrap bpftool. Define dependencies separately for both modes.
This avoids needless rebuilds in some corner cases.

Suggested-by: Jan Stancek <jstancek@redhat.com>
Signed-off-by: Artem Savkov <asavkov@redhat.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Quentin Monnet <qmo@kernel.org>
Link: https://lore.kernel.org/bpf/20240513112658.43691-1-asavkov@redhat.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Fix make dependencies for vmlinux.h in bpftool to avoid unnecessary rebuilds.,"bpftool,vmlinux,dependencies",It's a build system or CI/CD change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The bpftool utility,"[""It's not related to any of the above.""]"
94133cf24bb33889aac267a7f0e3e6a08b8a8e5a,94133cf24bb33889aac267a7f0e3e6a08b8a8e5a,Mykyta Yatsenko,yatsenko@meta.com,1715692341,Alexei Starovoitov,ast@kernel.org,1716054376,e216440a607c5efdce134e920c36aa633e941fc8,4b377b4868ef17b040065bd468668c707d2477a5,"bpftool: Introduce btf c dump sorting

Sort bpftool c dump output; aiming to simplify vmlinux.h diffing and
forcing more natural type definitions ordering.

Definitions are sorted first by their BTF kind ranks"," then by their base
type name and by their own name.

Type ranks

Assign ranks to btf kinds (defined in function btf_type_rank) to set
next order:
1. Anonymous enums/enums64
2. Named enums/enums64
3. Trivial types typedefs (ints","[' then floats)\n4. Structs/Unions\n5. Function prototypes\n6. Forward declarations\n\nType rank is set to maximum for unnamed reference types', ' structs and\nunions to avoid emitting those types early. They will be emitted as\npart of the type chain starting with named type.\n\nLexicographical ordering\n\nEach type is assigned a sort_name and own_name.\nsort_name is the resolved name of the final base type for reference\ntypes (typedef', ' pointer', ' array etc). Sorting by sort_name allows to\ngroup typedefs of the same base type. sort_name for non-reference type\nis the same as own_name. own_name is a direct name of particular type', '\nis used as final sorting step.\n\nSigned-off-by: Mykyta Yatsenko <yatsenko@meta.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nTested-by: Andrii Nakryiko <andrii@kernel.org>\nReviewed-by: Quentin Monnet <qmo@kernel.org>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240514131221.20585-1-yatsenko@meta.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Sorts bpftool's BTF c dump output to improve diffing and type ordering.,"bpftool, BTF, sorting",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The bpftool utility,"[""It's not related to any of the above.""]"
f08a1e912d3e60bf3028ea1c5199a609d12cd37c,f08a1e912d3e60bf3028ea1c5199a609d12cd37c,Linus Torvalds,torvalds@linux-foundation.org,1715997434,Linus Torvalds,torvalds@linux-foundation.org,1715997434,000756585151956ab074e1cb1ca1689bd9f82e0c,26aa834ff2eef00a863a64b1a94a5a88a94eb963 fe56d6e4a99a40f50e64d5a8043f1fa838b1f7a1,"Merge tag 'net-6.10-rc0' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Jakub Kicinski:
 ""Current release - regressions:

   - virtio_net: fix missed error path rtnl_unlock after control queue
     locking rework

  Current release - new code bugs:

   - bpf: fix KASAN slab-out-of-bounds in percpu_array_map_gen_lookup","
     caused by missing nested map handling

   - drv: dsa: correct initialization order for KSZ88x3 ports

  Previous releases - regressions:

   - af_packet: do not call packet_read_pending() from
     tpacket_destruct_skb() fix performance regression

   - ipv6: fix route deleting failure when metric equals 0","[' don\'t assume\n     0 means not set / default in this case\n\n  Previous releases - always broken:\n\n   - bridge: couple of syzbot-driven fixes""\n\n* tag \'net-6.10-rc0\' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (30 commits)\n  selftests: net: local_termination: annotate the expected failures\n  net: dsa: microchip: Correct initialization order for KSZ88x3 ports\n  MAINTAINERS: net: Update reviewers for TI\'s Ethernet drivers\n  dt-bindings: net: ti: Update maintainers list\n  l2tp: fix ICMP error handling for UDP-encap sockets\n  net: txgbe: fix to control VLAN strip\n  net: wangxun: match VLAN CTAG and STAG features\n  net: wangxun: fix to change Rx features\n  af_packet: do not call packet_read_pending() from tpacket_destruct_skb()\n  virtio_net: Fix missed rtnl_unlock\n  netrom: fix possible dead-lock in nr_rt_ioctl()\n  idpf: don\'t skip over ethtool tcp-data-split setting\n  dt-bindings: net: qcom: ethernet: Allow dma-coherent\n  bonding: fix oops during rmmod\n  net/ipv6: Fix route deleting failure when metric equals 0\n  selftests/net: reduce xfrm_policy test time\n  selftests/bpf: Adjust btf_dump test to reflect recent change in file_operations\n  selftests/bpf: Adjust test_access_variable_array after a kernel function name change\n  selftests/net/lib: no need to record ns name if it already exist\n  net: qrtr: ns: Fix module refcnt\n  ...\n', '']",Merge with networking fixes including bug resolutions for bpf and virtio_net.,"networking, fixes, bpf",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['other']
91b6163be404e36baea39fc978e4739fd0448ebd,91b6163be404e36baea39fc978e4739fd0448ebd,Linus Torvalds,torvalds@linux-foundation.org,1715992284,Linus Torvalds,torvalds@linux-foundation.org,1715992284,584aa4e467f037bdab91c350ab83fbe4fd4e55fd,06f054b1fee83415fe35204845708988fc16ef22 a35dd3a786f57903151b18275b1eed105084cf72,"Merge tag 'sysctl-6.10-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/sysctl/sysctl

Pull sysctl updates from Joel Granados:

 - Remove sentinel elements from ctl_table structs in kernel/*

   Removing sentinels in ctl_table arrays reduces the build time size
   and runtime memory consumed by ~64 bytes per array. Removals for
   net/", io_uring/,"[' mm/', ' ipc/ and security/ are set to go into mainline\n   through their respective subsystems making the next release the most\n   likely place where the final series that removes the check for\n   proc_name == NULL will land.\n\n   This adds to removals already in arch/', ' drivers/ and fs/.\n\n - Adjust ctl_table definitions and references to allow constification\n     - Remove unused ctl_table function arguments\n     - Move non-const elements from ctl_table to ctl_table_header\n     - Make ctl_table pointers const in ctl_table_root structure\n\n   Making the static ctl_table structs const will increase safety by\n   keeping the pointers to proc_handler functions in .rodata. Though no\n   ctl_tables where made const in this PR', "" the ground work for making\n   that possible has started with these changes sent by Thomas\n   Weißschuh.\n\n* tag 'sysctl-6.10-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/sysctl/sysctl:\n  sysctl: drop now unnecessary out-of-bounds check\n  sysctl: move sysctl type to ctl_table_header\n  sysctl: drop sysctl_is_perm_empty_ctl_table\n  sysctl: treewide: constify argument ctl_table_root::permissions(table)\n  sysctl: treewide: drop unused argument ctl_table_root::set_ownership(table)\n  bpf: Remove the now superfluous sentinel elements from ctl_table array\n  delayacct: Remove the now superfluous sentinel elements from ctl_table array\n  kprobes: Remove the now superfluous sentinel elements from ctl_table array\n  printk: Remove the now superfluous sentinel elements from ctl_table array\n  scheduler: Remove the now superfluous sentinel elements from ctl_table array\n  seccomp: Remove the now superfluous sentinel elements from ctl_table array\n  timekeeping: Remove the now superfluous sentinel elements from ctl_table array\n  ftrace: Remove the now superfluous sentinel elements from ctl_table array\n  umh: Remove the now superfluous sentinel elements from ctl_table array\n  kernel misc: Remove the now superfluous sentinel elements from ctl_table array\n"", '']",Merge sysctl updates to remove sentinel elements from ctl_table structs for reduced memory and build time size.,"sysctl, ctl_table, memory reduction",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
52d94c180a9f6e586c8234b7feb7c8b9282f53c9,52d94c180a9f6e586c8234b7feb7c8b9282f53c9,Jakub Kicinski,kuba@kernel.org,1715906884,Jakub Kicinski,kuba@kernel.org,1715906884,702fd1fbb18eb6e2b24ec22a8fe9a7ff2e2286c1,83e93942796db58652288f0391ac00072401816f 51e2b8d33199df9675d2a36ec6aad0c27e91c6fe,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Daniel Borkmann says:

====================
pull-request: bpf 2024-05-17

We've added 7 non-merge commits during the last 2 day(s) which contain
a total of 8 files changed", 20 insertions(+),"[' 9 deletions(-).\n\nThe main changes are:\n\n1) Fix KASAN slab-out-of-bounds in percpu_array_map_gen_lookup and add\n   BPF selftests to cover this case', "" from Andrii Nakryiko.\n   (Report https://lore.kernel.org/bpf/20240514231155.1004295-1-kuba@kernel.org/)\n\n2) Fix two BPF selftests to adjust for kernel changes after fast-forwarding\n   Linus' tree to make BPF CI all green again"", ' from Martin KaFai Lau.\n\n3) Fix libbpf feature detectors when using token_fd by adjusting the\n   attribute size for memset to cover the former', "" also from Andrii Nakryiko.\n\n4) Fix the description of 'src' in ALU instructions for the BPF ISA\n   standardization doc"", "" from Puranjay Mohan.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  selftests/bpf: Adjust btf_dump test to reflect recent change in file_operations\n  selftests/bpf: Adjust test_access_variable_array after a kernel function name change\n  selftests/bpf: add more variations of map-in-map situations\n  bpf: save extended inner map info for percpu array maps as well\n  MAINTAINERS: Update ARM64 BPF JIT maintainer\n  bpf"", "" docs: Fix the description of 'src' in ALU instructions\n  libbpf: fix feature detectors when using token_fd\n====================\n\nLink: https://lore.kernel.org/r/20240517001600.23703-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n"", '']",Merged updates from bpf repository containing 8 file changes.,"merge, bpf, updates",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
51e2b8d33199df9675d2a36ec6aad0c27e91c6fe,51e2b8d33199df9675d2a36ec6aad0c27e91c6fe,Martin KaFai Lau,martin.lau@kernel.org,1715877790,Daniel Borkmann,daniel@iogearbox.net,1715903411,21f89df0ecb1e63e64fe003247868ef0c80ccbee,5405807edd4168c2dc2f307f3c6b70e9579bf7be,"selftests/bpf: Adjust btf_dump test to reflect recent change in file_operations

The btf_dump test fails:

test_btf_dump_struct_data:FAIL:file_operations unexpected file_operations: actual '(struct file_operations){
	.owner = (struct module *)0xffffffffffffffff","
	.fop_flags = (fop_flags_t)4294967295","[""\n\t.llseek = (loff_t (*)(struct f' != expected '(struct file_operations){\n\t.owner = (struct module *)0xffffffffffffffff"", '\n\t.llseek = (loff_t (*)(struct file *', ' loff_t', ' int))0xffffffffffffffff', '\'\n\nThe ""fop_flags"" is a recent addition to the struct file_operations in\ncommit 210a03c9d51a (""fs: claw back a few FMODE_* bits"")\n\nThis patch changes the test_btf_dump_struct_data() to reflect\nthis change.\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Alan Maguire <alan.maguire@oracle.com>\nLink: https://lore.kernel.org/bpf/20240516164310.2481460-1-martin.lau@linux.dev\n', '']",Adjust btf_dump selftest to align with changes in file_operations structure.,"btf_dump,test,file_operations",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5405807edd4168c2dc2f307f3c6b70e9579bf7be,5405807edd4168c2dc2f307f3c6b70e9579bf7be,Martin KaFai Lau,martin.lau@kernel.org,1715878900,Daniel Borkmann,daniel@iogearbox.net,1715903296,13ec2950fd596482a337268eeede5f01ad0b05ec,2322113ac9d0c5653017adbab504fb307b0e92e2,"selftests/bpf: Adjust test_access_variable_array after a kernel function name change

After commit 4c3e509ea9f2 (""sched/balancing: Rename load_balance() => sched_balance_rq()"")","
the load_balance kernel function is renamed to sched_balance_rq.

This patch adjusts the fentry program in test_access_variable_array.c
to reflect this kernel function name change.

Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240516170140.2689430-1-martin.lau@linux.dev
",[''],Adjusts the bpf selftest for a changed kernel function name after a recent rename.,"selftests,bpf,sched_balance_rq",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tracepoints like programs']
a49468240e89628236b738b5ab9416eae8f90c15,a49468240e89628236b738b5ab9416eae8f90c15,Linus Torvalds,torvalds@linux-foundation.org,1715807108,Linus Torvalds,torvalds@linux-foundation.org,1715807108,aed63fd4ccb7bff9df171e469429e0c7eec5cc46,8c06da67d0bd3139a97f301b4aa9c482b9d4f29e 2c9e5d4a008293407836d29d35dfd4353615bd2f,"Merge tag 'modules-6.10-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/mcgrof/linux

Pull modules updates from Luis Chamberlain:
 ""Finally something fun. Mike Rapoport does some cleanup to allow us to
  take out module_alloc() out of modules into a new paint shedded
  execmem_alloc() and execmem_free() so to make emphasis these helpers
  are actually used outside of modules.

  It starts with a non-functional changes API rename / placeholders to
  then allow architectures to define their requirements into a new shiny
  struct execmem_info with ranges"," and requirements for those ranges.

  Archs now can intitialize this execmem_info as the last part of
  mm_core_init() if they have to diverge from the norm. Each range is a
  known type clearly articulated and spelled out in enum execmem_type.

  Although a lot of this is major cleanup and prep work for future
  enhancements an immediate clear gain is we get to enable KPROBES
  without MODULES now. That is ultimately what motiviated to pick this
  work up again","[' now with smaller goal as concrete stepping stone""\n\n* tag \'modules-6.10-rc1\' of git://git.kernel.org/pub/scm/linux/kernel/git/mcgrof/linux:\n  bpf: remove CONFIG_BPF_JIT dependency on CONFIG_MODULES of\n  kprobes: remove dependency on CONFIG_MODULES\n  powerpc: use CONFIG_EXECMEM instead of CONFIG_MODULES where appropriate\n  x86/ftrace: enable dynamic ftrace without CONFIG_MODULES\n  arch: make execmem setup available regardless of CONFIG_MODULES\n  powerpc: extend execmem_params for kprobes allocations\n  arm64: extend execmem_info for generated code allocations\n  riscv: extend execmem_params for generated code allocations\n  mm/execmem', ' arch: convert remaining overrides of module_alloc to execmem\n  mm/execmem', ' arch: convert simple overrides of module_alloc to execmem\n  mm: introduce execmem_alloc() and execmem_free()\n  module: make module_memory_{alloc', 'free} more self-contained\n  sparc: simplify module_alloc()\n  nios2: define virtual address space for modules\n  mips: module: rename MODULE_START to MODULES_VADDR\n  arm64: module: remove unneeded call to kasan_alloc_module_shadow()\n  kallsyms: replace deprecated strncpy with strscpy\n  module: allow UNUSED_KSYMS_WHITELIST to be relative against objtree.\n', '']",The commit integrates module updates for execmem helper functions and architecture execution memory info struct for future enhancements and kprobe enabling.,"execmem, cleanup, kprobes",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,['kprobe/uprobe/ftrace like programs']
2322113ac9d0c5653017adbab504fb307b0e92e2,2322113ac9d0c5653017adbab504fb307b0e92e2,Andrii Nakryiko,andrii@kernel.org,1715754280,Alexei Starovoitov,ast@kernel.org,1715790894,cdbd7b6721cdba8d2eed7c1a4d589537cd4862bb,9ee98229083186837199912a7debb666146b8c17,"selftests/bpf: add more variations of map-in-map situations

Add test cases validating usage of PERCPU_ARRAY and PERCPU_HASH maps as
inner maps.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>
Link: https://lore.kernel.org/r/20240515062440.846086-2-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add test cases for using PERCPU_ARRAY and PERCPU_HASH maps as inner maps in selftests.,"test cases, inner maps, PERCPU",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9ee98229083186837199912a7debb666146b8c17,9ee98229083186837199912a7debb666146b8c17,Andrii Nakryiko,andrii@kernel.org,1715754279,Alexei Starovoitov,ast@kernel.org,1715790894,ec01949d678ef183fc8ac9707ee5eaaeb7e62e04,325423cafc12031a69692363ddcabc63113bb3d6,"bpf: save extended inner map info for percpu array maps as well

ARRAY_OF_MAPS and HASH_OF_MAPS map types have special logic to save
a few extra fields required for correct operations of ARRAY maps"," when
they are used as inner maps. PERCPU_ARRAY maps have similar
requirements as they now support generating inline element lookup
logic. So make sure that both classes of maps are handled correctly.

Reported-by: Jakub Kicinski <kuba@kernel.org>
Fixes: db69718b8efa (""bpf: inline bpf_map_lookup_elem() for PERCPU_ARRAY maps"")
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>
Link: https://lore.kernel.org/r/20240515062440.846086-1-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The commit extends inner map handling to include PERCPU_ARRAY maps for enhanced element lookup logic.,"inner map, PERCPU_ARRAY, element lookup",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).', 'other']"
7a8030057f6791d35dd20987f9ff15855c01c1bb,7a8030057f6791d35dd20987f9ff15855c01c1bb,Puranjay Mohan,puranjay@kernel.org,1715691783,Alexei Starovoitov,ast@kernel.org,1715790894,d569ed0747d2deac7a968b415e902b747b7b5f31,1de27bba6d50a909647f304eadc0f7c59a842a50,bpf," docs: Fix the description of 'src' in ALU instructions

An ALU instruction's source operand can be the value in the source
register or the 32-bit immediate value encoded in the instruction. This
is controlled by the 's' bit of the 'opcode'.

The current description explicitly uses the phrase 'value of the source
register' when defining the meaning of 'src'.

Change the description to use 'source operand' in place of 'value of the
source register'.

Signed-off-by: Puranjay Mohan <puranjay@kernel.org>
Acked-by: Dave Thaler <dthaler1968@gmail.com>
Link: https://lore.kernel.org/r/20240514130303.113607-1-puranjay@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Update documentation to clarify the description of the source operand in ALU instructions.,"ALU,instruction,operand",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
1de27bba6d50a909647f304eadc0f7c59a842a50,1de27bba6d50a909647f304eadc0f7c59a842a50,Andrii Nakryiko,andrii@kernel.org,1715623683,Alexei Starovoitov,ast@kernel.org,1715790893,ebf60051d8cd8151960eadebf7d77a493a53d0d9,621cde16e49b3ecf7d59a8106a20aaebfb4a59a9,"libbpf: fix feature detectors when using token_fd

Adjust `union bpf_attr` size passed to kernel in two feature-detecting
functions to take into account prog_token_fd field.

Libbpf is avoiding memset()'ing entire `union bpf_attr` by only using
minimal set of bpf_attr's fields. Two places have been missed when
wiring BPF token support in libbpf's feature detection logic.

Fix them trivially.

Fixes: f3dcee938f48 (""libbpf: Wire up token_fd into feature probing logic"")
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240513180804.403775-1-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Fix feature detection logic in libbpf by adjusting bpf_attr size for token_fd support.,"libbpf,feature detection,token_fd",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8bd67ebb50c0145fd2ca8681ab65eb7e8cde1afc,8bd67ebb50c0145fd2ca8681ab65eb7e8cde1afc,Nikolay Aleksandrov,razor@blackwall.org,1715596459,David S. Miller,davem@davemloft.net,1715769662,befe059e9e33254f9ed8cc9560ea46aa20bdd4a4,aea27a92a41dae14843f92c79e9e42d8f570105c,"net: bridge: xmit: make sure we have at least eth header len bytes

syzbot triggered an uninit value[1] error in bridge device's xmit path
by sending a short (less than ETH_HLEN bytes) skb. To fix it check if
we can actually pull that amount instead of assuming.

Tested with dropwatch:
 drop at: br_dev_xmit+0xb93/0x12d0 [bridge] (0xffffffffc06739b3)
 origin: software
 timestamp: Mon May 13 11:31:53 2024 778214037 nsec
 protocol: 0x88a8
 length: 2
 original length: 2
 drop reason: PKT_TOO_SMALL

[1]
BUG: KMSAN: uninit-value in br_dev_xmit+0x61d/0x1cb0 net/bridge/br_device.c:65
 br_dev_xmit+0x61d/0x1cb0 net/bridge/br_device.c:65
 __netdev_start_xmit include/linux/netdevice.h:4903 [inline]
 netdev_start_xmit include/linux/netdevice.h:4917 [inline]
 xmit_one net/core/dev.c:3531 [inline]
 dev_hard_start_xmit+0x247/0xa20 net/core/dev.c:3547
 __dev_queue_xmit+0x34db/0x5350 net/core/dev.c:4341
 dev_queue_xmit include/linux/netdevice.h:3091 [inline]
 __bpf_tx_skb net/core/filter.c:2136 [inline]
 __bpf_redirect_common net/core/filter.c:2180 [inline]
 __bpf_redirect+0x14a6/0x1620 net/core/filter.c:2187
 ____bpf_clone_redirect net/core/filter.c:2460 [inline]
 bpf_clone_redirect+0x328/0x470 net/core/filter.c:2432
 ___bpf_prog_run+0x13fe/0xe0f0 kernel/bpf/core.c:1997
 __bpf_prog_run512+0xb5/0xe0 kernel/bpf/core.c:2238
 bpf_dispatcher_nop_func include/linux/bpf.h:1234 [inline]
 __bpf_prog_run include/linux/filter.h:657 [inline]
 bpf_prog_run include/linux/filter.h:664 [inline]
 bpf_test_run+0x499/0xc30 net/bpf/test_run.c:425
 bpf_prog_test_run_skb+0x14ea/0x1f20 net/bpf/test_run.c:1058
 bpf_prog_test_run+0x6b7/0xad0 kernel/bpf/syscall.c:4269
 __sys_bpf+0x6aa/0xd90 kernel/bpf/syscall.c:5678
 __do_sys_bpf kernel/bpf/syscall.c:5767 [inline]
 __se_sys_bpf kernel/bpf/syscall.c:5765 [inline]
 __x64_sys_bpf+0xa0/0xe0 kernel/bpf/syscall.c:5765
 x64_sys_call+0x96b/0x3b50 arch/x86/include/generated/asm/syscalls_64.h:322
 do_syscall_x64 arch/x86/entry/common.c:52 [inline]
 do_syscall_64+0xcf/0x1e0 arch/x86/entry/common.c:83
 entry_SYSCALL_64_after_hwframe+0x77/0x7f

Fixes: 1da177e4c3f4 (""Linux-2.6.12-rc2"")
Reported-by: syzbot+a63a1f6a062033cf0f40@syzkaller.appspotmail.com
Closes: https://syzkaller.appspot.com/bug?extid=a63a1f6a062033cf0f40
Signed-off-by: Nikolay Aleksandrov <razor@blackwall.org>
Signed-off-by: David S. Miller <davem@davemloft.net>
",,Fix uninitialized value error in bridge xmit path by ensuring minimum Ethernet header length.,"bridge,xmit,error",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['tc/netfilter like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1b294a1f35616977caddaddf3e9d28e576a1adbc,1b294a1f35616977caddaddf3e9d28e576a1adbc,Linus Torvalds,torvalds@linux-foundation.org,1715740944,Linus Torvalds,torvalds@linux-foundation.org,1715740944,723a406740083006b8f8724b5c5e532d4efa431d,b850dc206a57ae272c639e31ac202ec0c2f46960 654de42f3fc6edc29d743c1dbcd1424f7793f63d,"Merge tag 'net-next-6.10' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net-next

Pull networking updates from Jakub Kicinski:
 ""Core & protocols:

   - Complete rework of garbage collection of AF_UNIX sockets.

     AF_UNIX is prone to forming reference count cycles due to fd
     passing functionality. New method based on Tarjan's Strongly
     Connected Components algorithm should be both faster and remove a
     lot of workarounds we accumulated over the years.

   - Add TCP fraglist GRO support"," allowing chaining multiple TCP
     packets and forwarding them together. Useful for small switches /
     routers which lack basic checksum offload in some scenarios (e.g.
     PPPoE).

   - Support using SMP threads for handling packet backlog i.e. packet
     processing from software interfaces and old drivers which don't use
     NAPI. This helps move the processing out of the softirq jumble.

   - Continue work of converting from rtnl lock to RCU protection.

     Don't require rtnl lock when reading: IPv6 routing FIB","[' IPv6\n     address labels', ' netdev threaded NAPI sysfs files', "" bonding driver's\n     sysfs files"", ' MPLS devconf', ' IPv4 FIB rules', ' netns IDs', ' tcp metrics', '\n     TC Qdiscs', ' neighbor entries', ' ARP entries via ioctl(SIOCGARP)', ' a lot\n     of the link information available via rtnetlink.\n\n   - Small optimizations from Eric to UDP wake up handling', ' memory\n     accounting', ' RPS/RFS implementation', ' TCP packet sizing etc.\n\n   - Allow direct page recycling in the bulk API used by XDP', ' for +2%\n     PPS.\n\n   - Support peek with an offset on TCP sockets.\n\n   - Add MPTCP APIs for querying last time packets were received/sent/acked\n     and whether MPTCP ""upgrade"" succeeded on a TCP socket.\n\n   - Add intra-node communication shortcut to improve SMC performance.\n\n   - Add IPv6 (and IPv{4', '6}-over-IPv{4', '6}) support to the GTP protocol\n     driver.\n\n   - Add HSR-SAN (RedBOX) mode of operation to the HSR protocol driver.\n\n   - Add reset reasons for tracing what caused a TCP reset to be sent.\n\n   - Introduce direction attribute for xfrm (IPSec) states. State can be\n     used either for input or output packet processing.\n\n  Things we sprinkled into general kernel code:\n\n   - Add bitmap_{read', 'write}()', ' bitmap_size()', ' expose BYTES_TO_BITS().\n\n     This required touch-ups and renaming of a few existing users.\n\n   - Add Endian-dependent __counted_by_{le', 'be} annotations.\n\n   - Make building selftests ""quieter"" by printing summaries like\n     ""CC object.o"" rather than full commands with all the arguments.\n\n  Netfilter:\n\n   - Use GFP_KERNEL to clone elements', ' to deal better with OOM\n     situations and avoid failures in the .commit step.\n\n  BPF:\n\n   - Add eBPF JIT for ARCv2 CPUs.\n\n   - Support attaching kprobe BPF programs through kprobe_multi link in\n     a session mode', ' meaning', ' a BPF program is attached to both function\n     entry and return', ' the entry program can decide if the return\n     program gets executed and the entry program can share u64 cookie\n     value with return program. ""Session mode"" is a common use-case for\n     tetragon and bpftrace.\n\n   - Add the ability to specify and retrieve BPF cookie for raw\n     tracepoint programs in order to ease migration from classic to raw\n     tracepoints.\n\n   - Add an internal-only BPF per-CPU instruction for resolving per-CPU\n     memory addresses and implement support in x86', "" ARM64 and RISC-V\n     JITs. This allows inlining functions which need to access per-CPU\n     state.\n\n   - Optimize x86 BPF JIT's emit_mov_imm64"", "" and add support for various\n     atomics in bpf_arena which can be JITed as a single x86\n     instruction. Support BPF arena on ARM64.\n\n   - Add a new bpf_wq API for deferring events and refactor\n     process-context bpf_timer code to keep common code where possible.\n\n   - Harden the BPF verifier's and/or/xor value tracking.\n\n   - Introduce crypto kfuncs to let BPF programs call kernel crypto\n     APIs.\n\n   - Support bpf_tail_call_static() helper for BPF programs with GCC 13.\n\n   - Add bpf_preempt_{disable"", 'enable}() kfuncs in order to allow a BPF\n     program to have code sections where preemption is disabled.\n\n  Driver API:\n\n   - Skip software TC processing completely if all installed rules are\n     marked as HW-only', ' instead of checking the HW-only flag rule by\n     rule.\n\n   - Add support for configuring PoE (Power over Ethernet)', ' similar to\n     the already existing support for PoDL (Power over Data Line)\n     config.\n\n   - Initial bits of a queue control API', ' for now allowing a single\n     queue to be reset without disturbing packet flow to other queues.\n\n   - Common (ethtool) statistics for hardware timestamping.\n\n  Tests and tooling:\n\n   - Remove the need to create a config file to run the net forwarding\n     tests so that a naive ""make run_tests"" can exercise them.\n\n   - Define a method of writing tests which require an external endpoint\n     to communicate with (to send/receive data towards the test\n     machine). Add a few such tests.\n\n   - Create a shared code library for writing Python tests. Expose the\n     YAML Netlink library from tools/ to the tests for easy Netlink\n     access.\n\n   - Move netfilter tests under net/', ' extend them', ' separate performance\n     tests from correctness tests', ' and iron out issues found by running\n     them ""on every commit"".\n\n   - Refactor BPF selftests to use common network helpers.\n\n   - Further work filling in YAML definitions of Netlink messages for:\n     nftables', ' team driver', ' bonding interfaces', ' vlan interfaces', ' VF\n     info', ' TC u32 mark', ' TC police action.\n\n   - Teach Python YAML Netlink to decode attribute policies.\n\n   - Extend the definition of the ""indexed array"" construct in the specs\n     to cover arrays of scalars rather than just nests.\n\n   - Add hyperlinks between definitions in generated Netlink docs.\n\n  Drivers:\n\n   - Make sure unsupported flower control flags are rejected by drivers', '\n     and make more drivers report errors directly to the application\n     rather than dmesg (large number of driver changes from Asbjørn\n     Sloth Tønnesen).\n\n   - Ethernet high-speed NICs:\n      - Broadcom (bnxt):\n         - support multiple RSS contexts and steering traffic to them\n         - support XDP metadata\n         - make page pool allocations more NUMA aware\n      - Intel (100G', ' ice', ' idpf):\n         - extract datapath code common among Intel drivers into a library\n         - use fewer resources in switchdev by sharing queues with the PF\n         - add PFCP filter support\n         - add Ethernet filter support\n         - use a spinlock instead of HW lock in PTP clock ops\n         - support 5 layer Tx scheduler topology\n      - nVidia/Mellanox:\n         - 800G link modes and 100G SerDes speeds\n         - per-queue IRQ coalescing configuration\n      - Marvell Octeon:\n         - support offloading TC packet mark action\n\n   - Ethernet NICs consumer', ' embedded and virtual:\n      - stop lying about skb->truesize in USB Ethernet drivers', "" it\n        messes up TCP memory calculations\n      - Google cloud vNIC:\n         - support changing ring size via ethtool\n         - support ring reset using the queue control API\n      - VirtIO net:\n         - expose flow hash from RSS to XDP\n         - per-queue statistics\n         - add selftests\n      - Synopsys (stmmac):\n         - support controllers which require an RX clock signal from the\n           MII bus to perform their hardware initialization\n      - TI:\n         - icssg_prueth: support ICSSG-based Ethernet on AM65x SR1.0 devices\n         - icssg_prueth: add SW TX / RX Coalescing based on hrtimers\n         - cpsw: minimal XDP support\n      - Renesas (ravb):\n         - support describing the MDIO bus\n      - Realtek (r8169):\n         - add support for RTL8168M\n      - Microchip Sparx5:\n         - matchall and flower actions mirred and redirect\n\n   - Ethernet switches:\n      - nVidia/Mellanox:\n         - improve events processing performance\n      - Marvell:\n         - add support for MV88E6250 family internal PHYs\n      - Microchip:\n         - add DCB and DSCP mapping support for KSZ switches\n         - vsc73xx: convert to PHYLINK\n      - Realtek:\n         - rtl8226b/rtl8221b: add C45 instances and SerDes switching\n\n   - Many driver changes related to PHYLIB and PHYLINK deprecated API\n     cleanup\n\n   - Ethernet PHYs:\n      - Add a new driver for Airoha EN8811H 2.5 Gigabit PHY.\n      - micrel: lan8814: add support for PPS out and external timestamp trigger\n\n   - WiFi:\n      - Disable Wireless Extensions (WEXT) in all Wi-Fi 7 devices\n        drivers. Modern devices can only be configured using nl80211.\n      - mac80211/cfg80211\n         - handle color change per link for WiFi 7 Multi-Link Operation\n      - Intel (iwlwifi):\n         - don't support puncturing in 5 GHz\n         - support monitor mode on passive channels\n         - BZ-W device support\n         - P2P with HE/EHT support\n         - re-add support for firmware API 90\n         - provide channel survey information for Automatic Channel Selection\n      - MediaTek (mt76):\n         - mt7921 LED control\n         - mt7925 EHT radiotap support\n         - mt7920e PCI support\n      - Qualcomm (ath11k):\n         - P2P support for QCA6390"", ' WCN6855 and QCA2066\n         - support hibernation\n         - ieee80211-freq-limit Device Tree property support\n      - Qualcomm (ath12k):\n         - refactoring in preparation of multi-link support\n         - suspend and hibernation support\n         - ACPI support\n         - debugfs support', ' including dfs_simulate_radar support\n      - RealTek:\n         - rtw88: RTL8723CS SDIO device support\n         - rtw89: RTL8922AE Wi-Fi 7 PCI device support\n         - rtw89: complete features of new WiFi 7 chip 8922AE including\n           BT-coexistence and Wake-on-WLAN\n         - rtw89: use BIOS ACPI settings to set TX power and channels\n         - rtl8xxxu: enable Management Frame Protection (MFP) support\n\n   - Bluetooth:\n      - support for Intel BlazarI and Filmore Peak2 (BE201)\n      - support for MediaTek MT7921S SDIO\n      - initial support for Intel PCIe BT driver\n      - remove HCI_AMP support""\n\n* tag \'net-next-6.10\' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net-next: (1827 commits)\n  selftests: netfilter: fix packetdrill conntrack testcase\n  net: gro: fix napi_gro_cb zeroed alignment\n  Bluetooth: btintel_pcie: Refactor and code cleanup\n  Bluetooth: btintel_pcie: Fix warning reported by sparse\n  Bluetooth: hci_core: Fix not handling hdev->le_num_of_adv_sets=1\n  Bluetooth: btintel: Fix compiler warning for multi_v7_defconfig config\n  Bluetooth: btintel_pcie: Fix compiler warnings\n  Bluetooth: btintel_pcie: Add *setup* function to download firmware\n  Bluetooth: btintel_pcie: Add support for PCIe transport\n  Bluetooth: btintel: Export few static functions\n  Bluetooth: HCI: Remove HCI_AMP support\n  Bluetooth: L2CAP: Fix div-by-zero in l2cap_le_flowctl_init()\n  Bluetooth: qca: Fix error code in qca_read_fw_build_info()\n  Bluetooth: hci_conn: Use __counted_by() and avoid -Wfamnae warning\n  Bluetooth: btintel: Add support for Filmore Peak2 (BE201)\n  Bluetooth: btintel: Add support for BlazarI\n  LE Create Connection command timeout increased to 20 secs\n  dt-bindings: net: bluetooth: Add MediaTek MT7921S SDIO Bluetooth\n  Bluetooth: compute LE flow credits based on recvbuf space\n  Bluetooth: hci_sync: Use cmd->num_cis instead of magic number\n  ...\n', '']","Merge networking updates including AF_UNIX rework, TCP fraglist GRO support, and SMP threads usage for packet backlog.","networking, AF_UNIX, TCP",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
614da38e2f7afe9e01c6e359dfa09285f26fa381,614da38e2f7afe9e01c6e359dfa09285f26fa381,Linus Torvalds,torvalds@linux-foundation.org,1715724766,Linus Torvalds,torvalds@linux-foundation.org,1715724766,bd5b66bade4842bb1a8b2c55771c1d23398a1213,ce952d8f0e9b58dc6a2bde7e47ca7fa7925583cc c9c92fc4c2ef4e2f11af0ba19cb18d9b5e3e6f08,"Merge tag 'hid-for-linus-2024051401' of git://git.kernel.org/pub/scm/linux/kernel/git/hid/hid

Pull HID updates from Jiri Kosina:

 - Firmware loading from host support in intel-ish driver"," needed to
   support Lunar Lake and later (Zhang Lixu)

 - updates to HID-BPF infrastructure","["" with some of the specific fixes\n   (e.g. rdesc fixups) abstracted into separate BPF programs for\n   consumption from libevdev/udev-hid-bpf (Benjamin Tissoires)\n\n - support for Deck IMU in hid-steam (Max Maisel)\n\n - fixes for better support of 3rd party playstation DS4 controllers\n   (Max Staudt)\n\n - support for missing mappings and codes from HUT 1.5 in hid-debug\n   (Thomas Kuehne)\n\n - initial support for ROG Ally and ROG X13 devices (Luke D. Jones)\n\n - full support for WinWing Orion2 (Ivan Gorinov)\n\n* tag 'hid-for-linus-2024051401' of git://git.kernel.org/pub/scm/linux/kernel/git/hid/hid: (74 commits)\n  selftests/hid: skip tests with HID-BPF if udev-hid-bpf is not installed\n  selftests/hid: add tests for the Raptor Mach 2 joystick\n  selftests/hid: move the gamepads definitions in the test file\n  selftests/hid: import base_gamepad.py from hid-tools\n  selftests/hid: add Huion Kamvas Pro 19 tests\n  selftests/hid: tablets: also check for XP-Pen offset correction\n  selftests/hid: tablets: add a couple of XP-PEN tablets\n  selftests/hid: tablets: reduce the number of pen state\n  selftests/hid: add support for HID-BPF pre-loading before starting a test\n  selftests/hid: import base_device.py from hid-tools\n  HID: bpf: add in-tree HID-BPF fix for the Raptor Mach 2\n  HID: bpf: add in-tree HID-BPF fix for the Huion Kamvas Pro 19\n  HID: bpf: add in-tree HID-BPF fix for the XBox Elite 2 over Bluetooth\n  HID: bpf: add in-tree HID-BPF fix for the Wacom ArtPen\n  HID: bpf: add in-tree HID-BPF fix for the IOGear Kaliber Gaming MMOmentum mouse\n  HID: bpf: add in-tree HID-BPF fix for the HP Elite Presenter Mouse\n  HID: bpf: add in-tree HID-BPF fix for the XPPen Artist 16\n  HID: bpf: add first in-tree HID-BPF fix for the XPPen Artist 24\n  HID: do not assume HAT Switch logical max < 8\n  HID: amd_sfh: Use amd_get_c2p_val() to read C2P register\n  ...\n"", '']",Merge HID updates including intel-ish driver firmware loading support and HID-BPF infrastructure improvements.,"HID,BPF,firmware",It's a new feature.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,['HID driver like programs']
21c38a3bd4ee3fb7337d013a638302fb5e5f9dc2,21c38a3bd4ee3fb7337d013a638302fb5e5f9dc2,Jesper Dangaard Brouer,hawk@kernel.org,1714572251,Tejun Heo,tj@kernel.org,1715715797,ea18a93308d8c449aca46bcd10cc9f657a5e0542,c1457d9aad5ee2feafcf85aa9a58ab50500159d2,"cgroup/rstat: add cgroup_rstat_cpu_lock helpers and tracepoints

This closely resembles helpers added for the global cgroup_rstat_lock in
commit fc29e04ae1ad (""cgroup/rstat: add cgroup_rstat_lock helpers and
tracepoints""). This is for the per CPU lock cgroup_rstat_cpu_lock.

Based on production workloads"," we observe the fast-path ""update"" function
cgroup_rstat_updated() is invoked around 3 million times per sec","[' while the\n""flush"" function cgroup_rstat_flush_locked()', ' walking each possible CPU', '\ncan see periodic spikes of 700 invocations/sec.\n\nFor this reason', ' the tracepoints are split into normal and fastpath\nversions for this per-CPU lock. Making it feasible for production to\ncontinuously monitor the non-fastpath tracepoint to detect lock contention\nissues. The reason for monitoring is that lock disables IRQs which can\ndisturb e.g. softirq processing on the local CPUs involved. When the\nglobal cgroup_rstat_lock stops disabling IRQs (e.g converted to a mutex)', '\nthis per CPU lock becomes the next bottleneck that can introduce latency\nvariations.\n\nA practical bpftrace script for monitoring contention latency:\n\n bpftrace -e \'\n   tracepoint:cgroup:cgroup_rstat_cpu_lock_contended {\n     @start[tid]=nsecs; @cnt[probe]=count()}\n   tracepoint:cgroup:cgroup_rstat_cpu_locked {\n     if (args->contended) {\n       @wait_ns=hist(nsecs-@start[tid]); delete(@start[tid]);}\n     @cnt[probe]=count()}\n   interval:s:1 {time(""%H:%M:%S ""); print(@wait_ns); print(@cnt); clear(@cnt);}\'\n\nSigned-off-by: Jesper Dangaard Brouer <hawk@kernel.org>\nSigned-off-by: Tejun Heo <tj@kernel.org>\n', '']",Add cgroup_rstat_cpu_lock helpers and tracepoints for improved cgroup statistics locking efficiency.,"cgroup,helpers,tracepoints",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e29fd84c5b49085cf27e1d5f27237d2fb19edefe,e29fd84c5b49085cf27e1d5f27237d2fb19edefe,Jiri Kosina,jkosina@suse.com,1715687089,Jiri Kosina,jkosina@suse.com,1715687089,b603f41d1b410d9c24ab34ab42e44edca819c43f,bc5fbae23a880ebe42d4843294667e932379fb71 89ea968a9d759f71ac7b8d50949a8e5e5bcb1111,"Merge branch 'for-6.10/hid-bpf' into for-linus

- updates to HID-BPF infrastructure"," with some of the specific
  fixes (e.g. rdesc fixups) abstracted into separate BPF programs
  for consumption by libevdev/udev-hid-bpf (Benjamin Tissoires)
",[''],Merges updates to the HID-BPF infrastructure including rdesc fixups abstracted into separate BPF programs.,"HID-BPF,infrastructure,fixups",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['HID driver like programs', ""It's not related to any of the above.""]"
2c9e5d4a008293407836d29d35dfd4353615bd2f,2c9e5d4a008293407836d29d35dfd4353615bd2f,Mike Rapoport (IBM),rppt@kernel.org,1714925188,Luis Chamberlain,mcgrof@kernel.org,1715672189,57adbf37570d251815cc352cd9b234b790e2562a,7582b7be16d0ba90e3dbd9575a730cabd9eb852a,"bpf: remove CONFIG_BPF_JIT dependency on CONFIG_MODULES of

BPF just-in-time compiler depended on CONFIG_MODULES because it used
module_alloc() to allocate memory for the generated code.

Since code allocations are now implemented with execmem"," drop dependency of
CONFIG_BPF_JIT on CONFIG_MODULES and make it select CONFIG_EXECMEM.

Suggested-by: Björn Töpel <bjorn@kernel.org>
Signed-off-by: Mike Rapoport (IBM) <rppt@kernel.org>
Signed-off-by: Luis Chamberlain <mcgrof@kernel.org>
",[''],"Remove CONFIG_BPF_JIT dependency on CONFIG_MODULES, now using CONFIG_EXECMEM for memory allocation.","BPF JIT, CONFIG_MODULES, CONFIG_EXECMEM",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e2effa2235d9c7d0e9410637a2602bc69ee4f800,e2effa2235d9c7d0e9410637a2602bc69ee4f800,Mike Rapoport (IBM),rppt@kernel.org,1714925182,Luis Chamberlain,mcgrof@kernel.org,1715671903,59de3d23c841abf039cc08793a36fc1e8d245b6a,4d7b321a9ce0782a953874ec69acc2b12b9cb2cd,"arm64: extend execmem_info for generated code allocations

The memory allocations for kprobes and BPF on arm64 can be placed
anywhere in vmalloc address space and currently this is implemented with
overrides of alloc_insn_page() and bpf_jit_alloc_exec() in arm64.

Define EXECMEM_KPROBES and EXECMEM_BPF ranges in arm64::execmem_info and
drop overrides of alloc_insn_page() and bpf_jit_alloc_exec().

Signed-off-by: Mike Rapoport (IBM) <rppt@kernel.org>
Acked-by: Will Deacon <will@kernel.org>
Signed-off-by: Luis Chamberlain <mcgrof@kernel.org>
",,Enhance arm64 execmem_info for improved management of kprobes and BPF memory allocations.,"arm64, execmem_info, memory",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,['kprobe/uprobe/ftrace like programs']
4d7b321a9ce0782a953874ec69acc2b12b9cb2cd,4d7b321a9ce0782a953874ec69acc2b12b9cb2cd,Mike Rapoport (IBM),rppt@kernel.org,1714925181,Luis Chamberlain,mcgrof@kernel.org,1715671903,e8abfa527afe7d24a55eb9d6c3bee1d4e46fd511,223b5e57d0d50b0c07b933350dbcde92018d3080,"riscv: extend execmem_params for generated code allocations

The memory allocations for kprobes and BPF on RISC-V are not placed in
the modules area and these custom allocations are implemented with
overrides of alloc_insn_page() and  bpf_jit_alloc_exec().

Define MODULES_VADDR and MODULES_END as VMALLOC_START and VMALLOC_END for
32 bit and slightly reorder execmem_params initialization to support both
32 and 64 bit variants"," define EXECMEM_KPROBES and EXECMEM_BPF ranges in
riscv::execmem_params and drop overrides of alloc_insn_page() and
bpf_jit_alloc_exec().

Signed-off-by: Mike Rapoport (IBM) <rppt@kernel.org>
Reviewed-by: Alexandre Ghiti <alexghiti@rivosinc.com>
Signed-off-by: Luis Chamberlain <mcgrof@kernel.org>
",[''],Extend execmem_params for custom memory allocations for kprobes and BPF on RISC-V.,"execmem_params,RISC-V,BPF",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
17ca7fc22f4bbc795e4d136449521b2fecb88e06,17ca7fc22f4bbc795e4d136449521b2fecb88e06,Linus Torvalds,torvalds@linux-foundation.org,1715645627,Linus Torvalds,torvalds@linux-foundation.org,1715645627,a1bee109d288772d04c4832109593e0e736fc6e3,48fc82c40bc29a80361b1eab0e4a9494628a7144 854dd99b5ddc9d90e31e5f112462a5994dd31810,"Merge tag 'perf-core-2024-05-13' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip

Pull perf events updates from Ingo Molnar:

 - Combine perf and BPF for fast evalution of HW breakpoint
   conditions

 - Add LBR capture support outside of hardware events

 - Trigger IO signals for watermark_wakeup

 - Add RAPL support for Intel Arrow Lake and Lunar Lake

 - Optimize frequency-throttling

 - Miscellaneous cleanups & fixes

* tag 'perf-core-2024-05-13' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (21 commits)
  perf/bpf: Mark perf_event_set_bpf_handler() and perf_event_free_bpf_handler() as inline too
  selftests/perf_events: Test FASYNC with watermark wakeups
  perf/ring_buffer: Trigger IO signals for watermark_wakeup
  perf: Move perf_event_fasync() to perf_event.h
  perf/bpf: Change the !CONFIG_BPF_SYSCALL stubs to static inlines
  selftest/bpf: Test a perf BPF program that suppresses side effects
  perf/bpf: Allow a BPF program to suppress all sample side effects
  perf/bpf: Remove unneeded uses_default_overflow_handler()
  perf/bpf: Call BPF handler directly"," not through overflow machinery
  perf/bpf: Remove #ifdef CONFIG_BPF_SYSCALL from struct perf_event members
  perf/bpf: Create bpf_overflow_handler() stub for !CONFIG_BPF_SYSCALL
  perf/bpf: Reorder bpf_overflow_handler() ahead of __perf_event_overflow()
  perf/x86/rapl: Add support for Intel Lunar Lake
  perf/x86/rapl: Add support for Intel Arrow Lake
  perf/core: Reduce PMU access to adjust sample freq
  perf/core: Optimize perf_adjust_freq_unthr_context()
  perf/x86/amd: Don't reject non-sampling events with configured LBR
  perf/x86/amd: Support capturing LBR from software events
  perf/x86/amd: Avoid taking branches before disabling LBR
  perf/x86/amd: Ensure amd_pmu_core_disable_all() is always inlined
  ...
",[''],This commit merges perf updates including BPF integration for hardware breakpoint conditions and miscellaneous cleanups and optimizations.,"perf, BPF, optimizations",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6e62702feb6d474e969b52f0379de93e9729e457,6e62702feb6d474e969b52f0379de93e9729e457,Jakub Kicinski,kuba@kernel.org,1715643622,Jakub Kicinski,kuba@kernel.org,1715643670,aa109c16cb31139adffc01d01e40e28275ce7507,afd29f36aaf733985df1ba162424581b8b8853b4 ba39486d2c43ba7c103c438540aa56c8bde3b6c7,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next

Daniel Borkmann says:

====================
pull-request: bpf-next 2024-05-13

We've added 119 non-merge commits during the last 14 day(s) which contain
a total of 134 files changed", 9462 insertions(+),"[' 4742 deletions(-).\n\nThe main changes are:\n\n1) Add BPF JIT support for 32-bit ARCv2 processors', ' from Shahab Vahedi.\n\n2) Add BPF range computation improvements to the verifier in particular\n   around XOR and OR operators', ' refactoring of checks for range computation\n   and relaxing MUL range computation so that src_reg can also be an unknown\n   scalar', ' from Cupertino Miranda.\n\n3) Add support to attach kprobe BPF programs through kprobe_multi link in\n   a session mode', ' meaning', ' a BPF program is attached to both function entry\n   and return', ' the entry program can decide if the return program gets\n   executed and the entry program can share u64 cookie value with return\n   program. Session mode is a common use-case for tetragon and bpftrace', ""\n   from Jiri Olsa.\n\n4) Fix a potential overflow in libbpf's ring__consume_n() and improve libbpf\n   as well as BPF selftest's struct_ops handling"", ' from Andrii Nakryiko.\n\n5) Improvements to BPF selftests in context of BPF gcc backend', '\n   from Jose E. Marchesi & David Faust.\n\n6) Migrate remaining BPF selftest tests from test_sock_addr.c to prog_test-\n   -style in order to retire the old test', ' run it in BPF CI and additionally\n   expand test coverage', ' from Jordan Rife.\n\n7) Big batch for BPF selftest refactoring in order to remove duplicate code\n   around common network helpers', ' from Geliang Tang.\n\n8) Another batch of improvements to BPF selftests to retire obsolete\n   bpf_tcp_helpers.h as everything is available vmlinux.h', '\n   from Martin KaFai Lau.\n\n9) Fix BPF map tear-down to not walk the map twice on free when both timer\n   and wq is used', ' from Benjamin Tissoires.\n\n10) Fix BPF verifier assumptions about socket->sk that it can be non-NULL', '\n    from Alexei Starovoitov.\n\n11) Change BTF build scripts to using --btf_features for pahole v1.26+', '\n    from Alan Maguire.\n\n12) Small improvements to BPF reusing struct_size() and krealloc_array()', '\n    from Andy Shevchenko.\n\n13) Fix s390 JIT to emit a barrier for BPF_FETCH instructions', '\n    from Ilya Leoshkevich.\n\n14) Extend TCP ->cong_control() callback in order to feed in ack and\n    flag parameters and allow write-access to tp->snd_cwnd_stamp\n    from BPF program', ' from Miao Xu.\n\n15) Add support for internal-only per-CPU instructions to inline\n    bpf_get_smp_processor_id() helper call for arm64 and riscv64 BPF JITs', '\n    from Puranjay Mohan.\n\n16) Follow-up to remove the redundant ethtool.h from tooling infrastructure', '\n    from Tushar Vyavahare.\n\n17) Extend libbpf to support ""module:<function>"" syntax for tracing\n    programs', "" from Viktor Malik.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next: (119 commits)\n  bpf: make list_for_each_entry portable\n  bpf: ignore expected GCC warning in test_global_func10.c\n  bpf: disable strict aliasing in test_global_func9.c\n  selftests/bpf: Free strdup memory in xdp_hw_metadata\n  selftests/bpf: Fix a few tests for GCC related warnings.\n  bpf: avoid gcc overflow warning in test_xdp_vlan.c\n  tools: remove redundant ethtool.h from tooling infra\n  selftests/bpf: Expand ATTACH_REJECT tests\n  selftests/bpf: Expand getsockname and getpeername tests\n  sefltests/bpf: Expand sockaddr hook deny tests\n  selftests/bpf: Expand sockaddr program return value tests\n  selftests/bpf: Retire test_sock_addr.(c|sh)\n  selftests/bpf: Remove redundant sendmsg test cases\n  selftests/bpf: Migrate ATTACH_REJECT test cases\n  selftests/bpf: Migrate expected_attach_type tests\n  selftests/bpf: Migrate wildcard destination rewrite test\n  selftests/bpf: Migrate sendmsg6 v4 mapped address tests\n  selftests/bpf: Migrate sendmsg deny test cases\n  selftests/bpf: Migrate WILDCARD_IP test\n  selftests/bpf: Handle SYSCALL_EPERM and SYSCALL_ENOTSUPP test cases\n  ...\n====================\n\nLink: https://lore.kernel.org/r/20240513134114.17575-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n"", '']",This commit merges multiple changes from the bpf-next branch into the main branch.,"merge, bpf-next, commit",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c9f9df3f6347b33ae770747c40bae38836e3658c,c9f9df3f6347b33ae770747c40bae38836e3658c,Jakub Kicinski,kuba@kernel.org,1715631048,Jakub Kicinski,kuba@kernel.org,1715631048,3a4e7a54dcdeffc70d8482794207174982bfdb4d,1164057b3c0093240e45517d711da2d1fd86789a 3e9bc0472b910d4115e16e9c2d684c7757cb6c60,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Daniel Borkmann says:

====================
pull-request: bpf 2024-05-13

We've added 3 non-merge commits during the last 2 day(s) which contain
a total of 2 files changed", 62 insertions(+),"["" 8 deletions(-).\n\nThe main changes are:\n\n1) Fix a case where syzkaller found that it's unexpectedly possible\n   to attach a cgroup_skb program to the sockopt hooks. The fix adds\n   missing attach_type enforcement for the link_create case along\n   with selftests"", "" from Stanislav Fomichev.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  selftests/bpf: Add sockopt case to verify prog_type\n  selftests/bpf: Extend sockopt tests to use BPF_LINK_CREATE\n  bpf: Add BPF_PROG_TYPE_CGROUP_SKB attach type enforcement in BPF_LINK_CREATE\n====================\n\nLink: https://lore.kernel.org/r/20240513041845.31040-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n"", '']",This commit merges changes from the bpf repository affecting 2 files with 62 insertions.,"bpf,merge,changes",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c0b9620bc3f0a0f914996cc6631522d41870a9e0,c0b9620bc3f0a0f914996cc6631522d41870a9e0,Linus Torvalds,torvalds@linux-foundation.org,1715618946,Linus Torvalds,torvalds@linux-foundation.org,1715618946,8fdf2fed856bebe2c3e60302df3fb64cafa87339,736676f5c3abd1fc01c41813a95246e892937f6d 64619b283bb35b12a96129e82b40304f7e5551b7,"Merge tag 'rcu.next.v6.10' of https://github.com/urezki/linux

Pull RCU updates from Uladzislau Rezki:

 - Fix a lockdep complain for lazy-preemptible kernel"," remove redundant
   BH disable for TINY_RCU","[' remove redundant READ_ONCE() in tree.c', ' fix\n   false positives KCSAN splat and fix buffer overflow in the\n   print_cpu_stall_info().\n\n - Misc updates related to bpf', ' tracing and update the MAINTAINERS file.\n\n - An improvement of a normal synchronize_rcu() call in terms of\n   latency. It maintains a separate track for sync. users only. This\n   approach bypasses per-cpu nocb-lists thus sync-users do not depend on\n   nocb-list length and how fast regular callbacks are processed.\n\n - RCU tasks: switch tasks RCU grace periods to sleep at TASK_IDLE\n   priority', ' fix some comments', ' add some diagnostic warning to the\n   exit_tasks_rcu_start() and fix a buffer overflow in the\n   show_rcu_tasks_trace_gp_kthread().\n\n - RCU torture: Increase memory to guest OS', ' fix a Tasks Rude RCU\n   testing', ' some updates for TREE09', ' dump mode information to debug GP\n   kthread state', ' remove redundant READ_ONCE()', ' fix some comments about\n   RCU_TORTURE_PIPE_LEN and pipe_count', ' remove some redundant pointer\n   initialization', ' fix a hung splat task by when the rcutorture tests\n   start to exit', ' fix invalid context warning', "" add '--do-kvfree'\n   parameter to torture test and use slow register unregister callbacks\n   only for rcutype test.\n\n* tag 'rcu.next.v6.10' of https://github.com/urezki/linux: (48 commits)\n  rcutorture: Use rcu_gp_slow_register/unregister() only for rcutype test\n  torture: Scale --do-kvfree test time\n  rcutorture: Fix invalid context warning when enable srcu barrier testing\n  rcutorture: Make stall-tasks directly exit when rcutorture tests end\n  rcutorture: Removing redundant function pointer initialization\n  rcutorture: Make rcutorture support print rcu-tasks gp state\n  rcutorture: Use the gp_kthread_dbg operation specified by cur_ops\n  rcutorture: Re-use value stored to ->rtort_pipe_count instead of re-reading\n  rcutorture: Fix rcu_torture_one_read() pipe_count overflow comment\n  rcutorture: Remove extraneous rcu_torture_pipe_update_one() READ_ONCE()\n  rcu: Allocate WQ with WQ_MEM_RECLAIM bit set\n  rcu: Support direct wake-up of synchronize_rcu() users\n  rcu: Add a trace event for synchronize_rcu_normal()\n  rcu: Reduce synchronize_rcu() latency\n  rcu: Fix buffer overflow in print_cpu_stall_info()\n  rcu: Mollify sparse with RCU guard\n  rcu-tasks: Fix show_rcu_tasks_trace_gp_kthread buffer overflow\n  rcu-tasks: Fix the comments for tasks_rcu_exit_srcu_stall_timer\n  rcu-tasks: Replace exit_tasks_rcu_start() initialization with WARN_ON_ONCE()\n  rcu: Remove redundant CONFIG_PROVE_RCU #if condition\n  ...\n"", '']",Merge RCU updates to fix a lockdep complaint in lazy-preemptible kernel.,"RCU, lockdep, preemptible",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
ba39486d2c43ba7c103c438540aa56c8bde3b6c7,ba39486d2c43ba7c103c438540aa56c8bde3b6c7,Jose E. Marchesi,jose.marchesi@oracle.com,1715462563,Alexei Starovoitov,ast@kernel.org,1715560904,d948584d73987d413508c2ad82f3f7832494446b,6a2f786e6905007e82bac212296deca29815916d,"bpf: make list_for_each_entry portable

[Changes from V1:
- The __compat_break has been abandoned in favor of
  a more readable can_loop macro that can be used anywhere"," including
  loop conditions.]

The macro list_for_each_entry is defined in bpf_arena_list.h as
follows:

  #define list_for_each_entry(pos","[' head', ' member)\t\t\t\t\\\n\tfor (void * ___tmp = (pos = list_entry_safe((head)->first', '\t\t\\\n\t\t\t\t\t\t    typeof(*(pos))', ' member)', '\t\\\n\t\t\t      (void *)0);\t\t\t\t\t\\\n\t     pos && ({ ___tmp = (void *)pos->member.next; 1; });\t\t\\\n\t     cond_break', '\t\t\t\t\t\t\t\\\n\t     pos = list_entry_safe((void __arena *)___tmp', ' typeof(*(pos))', ' member))\n\nThe macro cond_break', ' in turn', "" expands to a statement expression that\ncontains a `break' statement.  Compound statement expressions"", "" and the\nsubsequent ability of placing statements in the header of a `for'\nloop"", ' are GNU extensions.\n\nUnfortunately', ' clang implements this GNU extension differently than\nGCC:\n\n- In GCC the `break\' statement is bound to the containing ""breakable""\n  context in which the defining `for\' appears.  If there is no such\n  context', "" GCC emits a warning: break statement without enclosing `for'\n  o `switch' statement.\n\n- In clang the `break' statement is bound to the defining `for'.  If\n  the defining `for' is itself inside some breakable construct"", ' then\n  clang emits a -Wgcc-compat warning.\n\nThis patch adds a new macro can_loop to bpf_experimental', ' that\nimplements the same logic than cond_break but evaluates to a boolean\nexpression.  The patch also changes all the current instances of usage\nof cond_break withing the header of loop accordingly.\n\nTested in bpf-next master.\nNo regressions.\n\nSigned-off-by: Jose E. Marchesi <jose.marchesi@oracle.com>\nCc: david.faust@oracle.com\nCc: cupertino.miranda@oracle.com\nCc: Alexei Starovoitov <alexei.starovoitov@gmail.com>\nLink: https://lore.kernel.org/r/20240511212243.23477-1-jose.marchesi@oracle.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Improves portability of list_for_each_entry macro in bpf_arena_list.h by using can_loop macro.,"list_for_each_entry, portability, can_loop",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6a2f786e6905007e82bac212296deca29815916d,6a2f786e6905007e82bac212296deca29815916d,Jose E. Marchesi,jose.marchesi@oracle.com,1715462629,Alexei Starovoitov,ast@kernel.org,1715560284,b1caa94011a1eecff887b0d6bce42ea79b72c92a,73868988c90d2701587ab2a48b5858ab935afb17,"bpf: ignore expected GCC warning in test_global_func10.c

The BPF selftest global_func10 in progs/test_global_func10.c contains:

  struct Small {
  	long x;
  };

  struct Big {
  	long x;
  	long y;
  };

  [...]

  __noinline int foo(const struct Big *big)
  {
	if (!big)
		return 0;

	return bpf_get_prandom_u32() < big->y;
  }

  [...]

  SEC(""cgroup_skb/ingress"")
  __failure __msg(""invalid indirect access to stack"")
  int global_func10(struct __sk_buff *skb)
  {
	const struct Small small = {.x = skb->len };

	return foo((struct Big *)&small) ? 1 : 0;
  }

GCC emits a ""maybe uninitialized"" warning for the code above"," because
it knows `foo' accesses `big->y'.

Since the purpose of this selftest is to check that the verifier will
fail on this sort of invalid memory access","[' this patch just silences\nthe compiler warning.\n\nTested in bpf-next master.\nNo regressions.\n\nSigned-off-by: Jose E. Marchesi <jose.marchesi@oracle.com>\nCc: david.faust@oracle.com\nCc: cupertino.miranda@oracle.com\nCc: Yonghong Song <yonghong.song@linux.dev>\nCc: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20240511212349.23549-1-jose.marchesi@oracle.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit modifies a BPF selftest to ignore a specific GCC warning indicating uninitialized data access.,"BPF selftest, GCC warning, verifier",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['cgroup like programs']
73868988c90d2701587ab2a48b5858ab935afb17,73868988c90d2701587ab2a48b5858ab935afb17,Jose E. Marchesi,jose.marchesi@oracle.com,1715462533,Alexei Starovoitov,ast@kernel.org,1715560215,651bdcfb5aa1713c2a6acc32ff271dab95d8bc85,a3c1c95538e22283ef6fa529e3ffa0e6d47ee190,"bpf: disable strict aliasing in test_global_func9.c

The BPF selftest test_global_func9.c performs type punning and breaks
srict-aliasing rules.

In particular"," given:

  int global_func9(struct __sk_buff *skb)
  {
	int result = 0;

	[...]
	{
		const struct C c = {.x = skb->len","["" .y = skb->family };\n\n\t\tresult |= foo((const struct S *)&c);\n\t}\n  }\n\nWhen building with strict-aliasing enabled (the default) the\ninitialization of `c' gets optimized away in its entirely:\n\n\t[... no initialization of `c' ...]\n\tr1 = r10\n\tr1 += -40\n\tcall\tfoo\n\tw0 |= w6\n\nSince GCC knows that `foo' accesses s->x"", ' we get a ""maybe\nuninitialized"" warning.\n\nOn the other hand', "" when strict-aliasing is disabled GCC only optimizes\naway the store to `.y':\n\n\tr1 = *(u32 *) (r6+0)\n\t*(u32 *) (r10+-40) = r1  ; This is .x = skb->len in `c'\n\tr1 = r10\n\tr1 += -40\n\tcall\tfoo\n\tw0 |= w6\n\nIn this case the warning is not emitted"", ' because s-> is initialized.\n\nThis patch disables strict aliasing in this test when building with\nGCC.  clang seems to not optimize this particular code even when\nstrict aliasing is enabled.\n\nTested in bpf-next master.\n\nSigned-off-by: Jose E. Marchesi <jose.marchesi@oracle.com>\nCc: david.faust@oracle.com\nCc: cupertino.miranda@oracle.com\nCc: Yonghong Song <yonghong.song@linux.dev>\nCc: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20240511212213.23418-1-jose.marchesi@oracle.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Disable strict aliasing in test_global_func9.c due to type punning violations.,"disable, strict aliasing, selftest",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['xdp like programs', 'other']"
a3c1c95538e22283ef6fa529e3ffa0e6d47ee190,a3c1c95538e22283ef6fa529e3ffa0e6d47ee190,Geliang Tang,tanggeliang@kylinos.cn,1715417424,Alexei Starovoitov,ast@kernel.org,1715560122,eeb34020f3711932589566cb22bd238be943b34c,5ddafcc377f98778acc08f660dee6400aece6a62,"selftests/bpf: Free strdup memory in xdp_hw_metadata

The strdup() function returns a pointer to a new string which is a
duplicate of the string ""ifname"". Memory for the new string is obtained
with malloc()"," and need to be freed with free().

This patch adds this missing ""free(saved_hwtstamp_ifname)"" in cleanup()
to avoid a potential memory leak in xdp_hw_metadata.c.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/af9bcccb96655e82de5ce2b4510b88c9c8ed5ed0.1715417367.git.tanggeliang@kylinos.cn
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Fixes a potential memory leak by adding a missing free operation in xdp_hw_metadata.c.,"memory leak, free, strdup",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['xdp like programs']
5ddafcc377f98778acc08f660dee6400aece6a62,5ddafcc377f98778acc08f660dee6400aece6a62,Cupertino Miranda,cupertino.miranda@oracle.com,1715366330,Alexei Starovoitov,ast@kernel.org,1715559914,266a8d4e1c5a341804774203d4f761833ee66daf,792a04bed41caec79c787d105b0d442351b3bcc8,"selftests/bpf: Fix a few tests for GCC related warnings.

This patch corrects a few warnings to allow selftests to compile for
GCC.

-- progs/cpumask_failure.c --

progs/bpf_misc.h:136:22: error: ‘cpumask’ is used uninitialized
[-Werror=uninitialized]
  136 | #define __sink(expr) asm volatile("""" : ""+g""(expr))
      |                      ^~~
progs/cpumask_failure.c:68:9: note: in expansion of macro ‘__sink’
   68 |         __sink(cpumask);

The macro __sink(cpumask) with the '+' contraint modifier forces the
the compiler to expect a read and write from cpumask. GCC detects
that cpumask is never initialized and reports an error.
This patch removes the spurious non required definitions of cpumask.

-- progs/dynptr_fail.c --

progs/dynptr_fail.c:1444:9: error: ‘ptr1’ may be used uninitialized
[-Werror=maybe-uninitialized]
 1444 |         bpf_dynptr_clone(&ptr1"," &ptr2);

Many of the tests in the file are related to the detection of
uninitialized pointers by the verifier. GCC is able to detect possible
uninitialized values","[' and reports this as an error.\nThe patch initializes all of the previous uninitialized structs.\n\n-- progs/test_tunnel_kern.c --\n\nprogs/test_tunnel_kern.c:590:9: error: array subscript 1 is outside\narray bounds of ‘struct geneve_opt[1]’ [-Werror=array-bounds=]\n  590 |         *(int *) &gopt.opt_data = bpf_htonl(0xdeadbeef);\n      |         ^~~~~~~~~~~~~~~~~~~~~~~\nprogs/test_tunnel_kern.c:575:27: note: at offset 4 into object ‘gopt’ of\nsize 4\n  575 |         struct geneve_opt gopt;\n\nThis tests accesses beyond the defined data for the struct geneve_opt\nwhich contains as last field ""u8 opt_data[0]"" which clearly does not get\nreserved space (in stack) in the function header. This pattern is\nrepeated in ip6geneve_set_tunnel and geneve_set_tunnel functions.\nGCC is able to see this and emits a warning.\nThe patch introduces a local struct that allocates enough space to\nsafely allow the write to opt_data field.\n\n-- progs/jeq_infer_not_null_fail.c --\n\nprogs/jeq_infer_not_null_fail.c:21:40: error: array subscript ‘struct\nbpf_map[0]’ is partly outside array bounds of ‘struct <anonymous>[1]’\n[-Werror=array-bounds=]\n   21 |         struct bpf_map *inner_map = map->inner_map_meta;\n      |                                        ^~\nprogs/jeq_infer_not_null_fail.c:14:3: note: object ‘m_hash’ of size 32\n   14 | } m_hash SEC("".maps"");\n\nThis example defines m_hash in the context of the compilation unit and\ncasts it to struct bpf_map which is much smaller than the size of struct\nbpf_map. It errors out in GCC when it attempts to access an element that\nwould be defined in struct bpf_map outsize of the defined limits for\nm_hash.\nThis patch disables the warning through a GCC pragma.\n\nThis changes were tested in bpf-next master selftests without any\nregressions.\n\nSigned-off-by: Cupertino Miranda <cupertino.miranda@oracle.com>\nCc: jose.marchesi@oracle.com\nCc: david.faust@oracle.com\nCc: Yonghong Song <yonghong.song@linux.dev>\nCc: Eduard Zingerman <eddyz87@gmail.com>\nCc: Andrii Nakryiko <andrii.nakryiko@gmail.com>\nLink: https://lore.kernel.org/r/20240510183850.286661-2-cupertino.miranda@oracle.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes GCC warnings in eBPF selftests for successful compilation.,"GCC,warnings,selftests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
792a04bed41caec79c787d105b0d442351b3bcc8,792a04bed41caec79c787d105b0d442351b3bcc8,David Faust,david.faust@oracle.com,1715196912,Alexei Starovoitov,ast@kernel.org,1715559572,137c791ff42c5609a74e395ba1564373b2d0e8b2,bbe91a9f6889934e661fa924144c7023f0a1c4cf,"bpf: avoid gcc overflow warning in test_xdp_vlan.c

This patch fixes an integer overflow warning raised by GCC in
xdp_prognum1 of progs/test_xdp_vlan.c:

  GCC-BPF  [test_maps] test_xdp_vlan.bpf.o
progs/test_xdp_vlan.c: In function 'xdp_prognum1':
progs/test_xdp_vlan.c:163:25: error: integer overflow in expression
 '(short int)(((__builtin_constant_p((int)vlan_hdr->h_vlan_TCI)) != 0
   ? (int)(short unsigned int)((short int)((int)vlan_hdr->h_vlan_TCI
   << 8 >> 8) << 8 | (short int)((int)vlan_hdr->h_vlan_TCI << 0 >> 8
   << 0)) & 61440 : (int)__builtin_bswap16(vlan_hdr->h_vlan_TCI)
   & 61440) << 8 >> 8) << 8' of type 'short int' results in '0' [-Werror=overflow]
  163 |                         bpf_htons((bpf_ntohs(vlan_hdr->h_vlan_TCI) & 0xf000)
      |                         ^~~~~~~~~

The problem lies with the expansion of the bpf_htons macro and the
expression passed into it.  The bpf_htons macro (and similarly the
bpf_ntohs macro) expand to a ternary operation using either
__builtin_bswap16 or ___bpf_swab16 to swap the bytes"," depending on
whether the expression is constant.

For an expression","["" with 'value' as a u16"", "" like:\n\n  bpf_htons (value & 0xf000)\n\nThe entire (value & 0xf000) is 'x' in the expansion of ___bpf_swab16\nand we get as one part of the expanded swab16:\n\n  ((__u16)(value & 0xf000) << 8 >> 8 << 8\n\nThis will always evaluate to 0"", ' which is intentional since this\nsubexpression deals with the byte guaranteed to be 0 by the mask.\n\nHowever', ' GCC warns because the precise reason this always evaluates to 0\nis an overflow.  Specifically', ' the plain 0xf000 in the expression is a\nsigned 32-bit integer', "" which causes 'value' to also be promoted to a\nsigned 32-bit integer"", "" and the combination of the 8-bit left shift and\ndown-cast back to __u16 results in a signed overflow (really a 'warning:\noverflow in conversion from int to __u16' which is propegated up through\nthe rest of the expression leading to the ultimate overflow warning\nabove)"", ' which is a valid warning despite being the intended result of\nthis code.\n\nClang does not warn on this case', ' likely because it performs constant\nfolding later in the compilation process relative to GCC.  It seems that\nby the time clang does constant folding for this expression', ' the side of\nthe ternary with this overflow has already been discarded.\n\nFortunately', ' this warning is easily silenced by simply making the 0xf000\nmask explicitly unsigned.  This has no impact on the result.\n\nSigned-off-by: David Faust <david.faust@oracle.com>\nCc: jose.marchesi@oracle.com\nCc: cupertino.miranda@oracle.com\nCc: Eduard Zingerman <eddyz87@gmail.com>\nCc: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240508193512.152759-1-david.faust@oracle.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixed GCC overflow warning in xdp_prognum1 function of test_xdp_vlan.c program.,GCC overflow warning,It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['xdp like programs']
e9dd2290f1fb9a46c1c0e322cb0e53cf914903fb,e9dd2290f1fb9a46c1c0e322cb0e53cf914903fb,Alexei Starovoitov,ast@kernel.org,1715559043,Alexei Starovoitov,ast@kernel.org,1715559053,1fc450c4a6ec6974c72b36ba0415d5086968ef6f,20a759df3bba35bf5c3ddec0c02ad69b603b584c a3d3eb957ddc733d04c0da67024b1c30d8826cc2,"Merge branch 'retire-progs-test_sock_addr'

Jordan Rife says:

====================
Retire progs/test_sock_addr.c

This patch series migrates remaining tests from bpf/test_sock_addr.c to
prog_tests/sock_addr.c and progs/verifier_sock_addr.c in order to fully
retire the old-style test program and expands test coverage to test
previously untested scenarios related to sockaddr hooks.

This is a continuation of the work started recently during the expansion
of prog_tests/sock_addr.c.

Link: https://lore.kernel.org/bpf/20240429214529.2644801-1-jrife@google.com/T/#u

=======
Patches
=======
* Patch 1 moves tests that check valid return values for recvmsg hooks
  into progs/verifier_sock_addr.c"," a new addition to the verifier test
  suite.
* Patches 2-5 lay the groundwork for test migration","[' enabling\n  prog_tests/sock_addr.c to handle more test dimensions.\n* Patches 6-11 move existing tests to prog_tests/sock_addr.c.\n* Patch 12 removes some redundant test cases.\n* Patches 14-17 expand on existing test coverage.\n====================\n\nLink: https://lore.kernel.org/r/20240510190246.3247730-1-jrife@google.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit migrates tests from bpf/test_sock_addr.c to prog_tests for better test coverage of sockaddr hooks.,"test migration, sockaddr hooks, verifier",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).', 'socket like programs', 'other']"
a3d3eb957ddc733d04c0da67024b1c30d8826cc2,a3d3eb957ddc733d04c0da67024b1c30d8826cc2,Jordan Rife,jrife@google.com,1715367754,Alexei Starovoitov,ast@kernel.org,1715559042,1fc450c4a6ec6974c72b36ba0415d5086968ef6f,bc467e953e4fbafd94d04c355f875bf1adf438e2,"selftests/bpf: Expand ATTACH_REJECT tests

This expands coverage for ATTACH_REJECT tests to include connect_unix","
sendmsg_unix","[' recvmsg*', ' getsockname*', ' and getpeername*.\n\nSigned-off-by: Jordan Rife <jrife@google.com>\nLink: https://lore.kernel.org/r/20240510190246.3247730-18-jrife@google.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Expanded the ATTACH_REJECT test coverage to include connect_unix.,"ATTACH_REJECT,test coverage,connect_unix",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
bc467e953e4fbafd94d04c355f875bf1adf438e2,bc467e953e4fbafd94d04c355f875bf1adf438e2,Jordan Rife,jrife@google.com,1715367753,Alexei Starovoitov,ast@kernel.org,1715559042,1c303bfb6d17fe713f8c0d371084c2e2fcf574b6,dfb7539b47b501ccc0d23bae718500ada2157aee,"selftests/bpf: Expand getsockname and getpeername tests

This expands coverage for getsockname and getpeername hooks to include
getsockname4", getsockname6,"[' getpeername4', ' and getpeername6.\n\nSigned-off-by: Jordan Rife <jrife@google.com>\nLink: https://lore.kernel.org/r/20240510190246.3247730-17-jrife@google.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit expands test coverage for BPF getsockname and getpeername hooks.,"getsockname, getpeername, hooks",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
dfb7539b47b501ccc0d23bae718500ada2157aee,dfb7539b47b501ccc0d23bae718500ada2157aee,Jordan Rife,jrife@google.com,1715367752,Alexei Starovoitov,ast@kernel.org,1715559042,af8bfb396616fb4fff15762645efa514dfd30f89,1e0a8367c89f82816735973d0e65a3c8e1b43179,"sefltests/bpf: Expand sockaddr hook deny tests

This patch expands test coverage for EPERM tests to include connect and
bind calls and rounds out the coverage for sendmsg by adding tests for
sendmsg_unix.

Signed-off-by: Jordan Rife <jrife@google.com>
Link: https://lore.kernel.org/r/20240510190246.3247730-16-jrife@google.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,"This commit adds expanded selftests for EPERM scenarios involving connect, bind, and sendmsg_unix calls.","selftests, EPERM, sockaddr",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"[""It's not related to any of the above.""]"
1e0a8367c89f82816735973d0e65a3c8e1b43179,1e0a8367c89f82816735973d0e65a3c8e1b43179,Jordan Rife,jrife@google.com,1715367751,Alexei Starovoitov,ast@kernel.org,1715559042,c2b50ce15599374463efe748b96ed2cd6e440614,61ecfdfce2647281e7d14119bfa529922ce2d8b2,"selftests/bpf: Expand sockaddr program return value tests

This patch expands verifier coverage for program return values to cover
bind", connect,"[' sendmsg', ' getsockname', ' and getpeername hooks. It also\nrounds out the recvmsg coverage by adding test cases for recvmsg_unix\nhooks.\n\nSigned-off-by: Jordan Rife <jrife@google.com>\nLink: https://lore.kernel.org/r/20240510190246.3247730-15-jrife@google.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit expands verifier tests for sockaddr program return values to include bind operations.,"verifier,sockaddr,tests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
61ecfdfce2647281e7d14119bfa529922ce2d8b2,61ecfdfce2647281e7d14119bfa529922ce2d8b2,Jordan Rife,jrife@google.com,1715367750,Alexei Starovoitov,ast@kernel.org,1715559042,997aa2cf1c46ece51417afec7e46b21785dbff2d,9c3f17862faef89696d26655a6d10f90137df42e,"selftests/bpf: Retire test_sock_addr.(c|sh)

Fully remove test_sock_addr.c and test_sock_addr.sh"," as test coverage
has been fully moved to prog_tests/sock_addr.c.

Signed-off-by: Jordan Rife <jrife@google.com>
Link: https://lore.kernel.org/r/20240510190246.3247730-14-jrife@google.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The commit removes obsolete test files due to test coverage relocation.,"remove,test,coverage",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
9c3f17862faef89696d26655a6d10f90137df42e,9c3f17862faef89696d26655a6d10f90137df42e,Jordan Rife,jrife@google.com,1715367749,Alexei Starovoitov,ast@kernel.org,1715559042,75ad865e531f7337eff9b23d6bf134295e079a94,cded71f595c0c4396acc9657911c5aa2a289a8dc,"selftests/bpf: Remove redundant sendmsg test cases

Remove these test cases completely"," as the same behavior is already
covered by other sendmsg* test cases in prog_tests/sock_addr.c. This
just rewrites the destination address similar to sendmsg_v4_prog and
sendmsg_v6_prog.

Signed-off-by: Jordan Rife <jrife@google.com>
Link: https://lore.kernel.org/r/20240510190246.3247730-13-jrife@google.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Remove redundant sendmsg test cases in selftests/bpf.,"remove, sendmsg, test cases",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
cded71f595c0c4396acc9657911c5aa2a289a8dc,cded71f595c0c4396acc9657911c5aa2a289a8dc,Jordan Rife,jrife@google.com,1715367748,Alexei Starovoitov,ast@kernel.org,1715559042,0a19936a1008dd0e3c96b7e1aa76b8de24fffe00,b0f3af0bffefc54650d9fb10810fc2f974365dfd,"selftests/bpf: Migrate ATTACH_REJECT test cases

Migrate test case from bpf/test_sock_addr.c ensuring that program
attachment fails when using an inappropriate attach type.

Signed-off-by: Jordan Rife <jrife@google.com>
Link: https://lore.kernel.org/r/20240510190246.3247730-12-jrife@google.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Migrates ATTACH_REJECT test cases to ensure proper program attachment failure handling in selftests/bpf.,"migrate, ATTACH_REJECT, selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['tc/netfilter like programs', ""It's not related to any of the above.""]"
b0f3af0bffefc54650d9fb10810fc2f974365dfd,b0f3af0bffefc54650d9fb10810fc2f974365dfd,Jordan Rife,jrife@google.com,1715367747,Alexei Starovoitov,ast@kernel.org,1715559042,d5e5c90bda48c70de53351c7e89eb8f805acdb4a,8eaf8056a44b28a7b198aa699e35854bbec2c452,"selftests/bpf: Migrate expected_attach_type tests

Migrates tests from progs/test_sock_addr.c ensuring that programs fail
to load when the expected attach type does not match.

Signed-off-by: Jordan Rife <jrife@google.com>
Link: https://lore.kernel.org/r/20240510190246.3247730-11-jrife@google.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,This commit migrates bpf selftests to ensure program loading fails with incorrect attach types.,"migrate, selftests, expected_attach_type",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
8eaf8056a44b28a7b198aa699e35854bbec2c452,8eaf8056a44b28a7b198aa699e35854bbec2c452,Jordan Rife,jrife@google.com,1715367746,Alexei Starovoitov,ast@kernel.org,1715559041,bfaf6231145318930d61fed08e34f4e6fabfb1e2,54462e8452f139e313e315959e005408cd31a4e6,"selftests/bpf: Migrate wildcard destination rewrite test

Migrate test case from bpf/test_sock_addr.c ensuring that sendmsg
respects when sendmsg6 hooks rewrite the destination IP with the IPv6
wildcard IP"," [::].

Signed-off-by: Jordan Rife <jrife@google.com>
Link: https://lore.kernel.org/r/20240510190246.3247730-10-jrife@google.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The commit migrates a test case to ensure sendmsg hooks handle IPv6 wildcard IPs correctly.,"migrate,test case,sendmsg",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
54462e8452f139e313e315959e005408cd31a4e6,54462e8452f139e313e315959e005408cd31a4e6,Jordan Rife,jrife@google.com,1715367745,Alexei Starovoitov,ast@kernel.org,1715559041,734c9bbfac75e3c226610c0fc0fb57fab175a173,f46a10483b27cc5a62b45e7e727445de6430e785,"selftests/bpf: Migrate sendmsg6 v4 mapped address tests

Migrate test case from bpf/test_sock_addr.c ensuring that sendmsg
returns -ENOTSUPP when sending to an IPv4-mapped IPv6 address to
prog_tests/sock_addr.c.

Signed-off-by: Jordan Rife <jrife@google.com>
Link: https://lore.kernel.org/r/20240510190246.3247730-9-jrife@google.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Migrate IPv4-mapped IPv6 address test cases from bpf/test_sock_addr.c to prog_tests/sock_addr.c.,"migrate, test case, sock_addr",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f46a10483b27cc5a62b45e7e727445de6430e785,f46a10483b27cc5a62b45e7e727445de6430e785,Jordan Rife,jrife@google.com,1715367744,Alexei Starovoitov,ast@kernel.org,1715559041,1bdf6bd6397d830524dc4dc6eb215300688a5040,d1b24fcf1c16290ce8cac467be2f7d6773de9da4,"selftests/bpf: Migrate sendmsg deny test cases

This set of tests checks that sendmsg calls are rejected (return -EPERM)
when the sendmsg* hook returns 0. Replace those in bpf/test_sock_addr.c
with corresponding tests in prog_tests/sock_addr.c.

Signed-off-by: Jordan Rife <jrife@google.com>
Link: https://lore.kernel.org/r/20240510190246.3247730-8-jrife@google.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Migrate sendmsg deny test cases from bpf/test_sock_addr.c to prog_tests/sock_addr.c.,"migrate,test cases,sendmsg",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
d1b24fcf1c16290ce8cac467be2f7d6773de9da4,d1b24fcf1c16290ce8cac467be2f7d6773de9da4,Jordan Rife,jrife@google.com,1715367743,Alexei Starovoitov,ast@kernel.org,1715559041,7bbbbab98e166d7c223e7dc38e2fe3cace4885ca,a2618c0d854235deaac2325cf8200a55274afa2b,"selftests/bpf: Migrate WILDCARD_IP test

Move wildcard IP sendmsg test case out of bpf/test_sock_addr.c into
prog_tests/sock_addr.c.

Signed-off-by: Jordan Rife <jrife@google.com>
Link: https://lore.kernel.org/r/20240510190246.3247730-7-jrife@google.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Migrated WILDCARD_IP test case to a new location in the source tree.,"Migrate,test,WILDCARD_IP",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
a2618c0d854235deaac2325cf8200a55274afa2b,a2618c0d854235deaac2325cf8200a55274afa2b,Jordan Rife,jrife@google.com,1715367742,Alexei Starovoitov,ast@kernel.org,1715559041,acd965f32b49da9fcaa8dfaf856b360d37113a9b,5a047b2226c0511d4528d1467dc90f08fffafc38,"selftests/bpf: Handle SYSCALL_EPERM and SYSCALL_ENOTSUPP test cases

In preparation to move test cases from bpf/test_sock_addr.c that expect
system calls to return ENOTSUPP or EPERM"," this patch propagates errno
from relevant system calls up to test_sock_addr() where the result can
be checked.

Signed-off-by: Jordan Rife <jrife@google.com>
Link: https://lore.kernel.org/r/20240510190246.3247730-6-jrife@google.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The commit updates selftests for bpf to handle SYSCALL_EPERM and SYSCALL_ENOTSUPP cases in test_sock_addr.c.,"selftests, SYSCALL_EPERM, SYSCALL_ENOTSUPP",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['socket like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5a047b2226c0511d4528d1467dc90f08fffafc38,5a047b2226c0511d4528d1467dc90f08fffafc38,Jordan Rife,jrife@google.com,1715367741,Alexei Starovoitov,ast@kernel.org,1715559041,97c820a06655716e8ae686bec0c0ddc5b7310d72,5eff48f33fb733de9b88a5381e0428f3e873c670,"selftests/bpf: Handle ATTACH_REJECT test cases

In preparation to move test cases from bpf/test_sock_addr.c that expect
ATTACH_REJECT"," this patch adds BPF_SKEL_FUNCS_RAW to generate load and
destroy functions that use bpf_prog_attach() to control the attach_type.

The normal load functions use bpf_program__attach_cgroup which does not
have the same degree of control over the attach type","[' as\nbpf_program_attach_fd() calls bpf_link_create() with the attach type\nextracted from prog using bpf_program__expected_attach_type(). It is\ncurrently not possible to modify the attach type before\nbpf_program__attach_cgroup() is called', ' since\nbpf_program__set_expected_attach_type() has no effect after the program\nis loaded.\n\nSigned-off-by: Jordan Rife <jrife@google.com>\nLink: https://lore.kernel.org/r/20240510190246.3247730-5-jrife@google.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit enhances selftests/bpf by handling ATTACH_REJECT test cases and improving attach type control in BPF skeleton functions.,"selftests,bpf,ATTACH_REJECT",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['cgroup like programs']
5eff48f33fb733de9b88a5381e0428f3e873c670,5eff48f33fb733de9b88a5381e0428f3e873c670,Jordan Rife,jrife@google.com,1715367740,Alexei Starovoitov,ast@kernel.org,1715559041,d83fbefb3068454dfc046b54263ea10fefc3bcc6,86b65c6db0190fb6c119e83da4de0eccf74fb1ff,"selftests/bpf: Handle LOAD_REJECT test cases

In preparation to move test cases from bpf/test_sock_addr.c that expect
LOAD_REJECT"," this patch adds expected_attach_type and extends load_fn to
accept an expected attach type and a flag indicating whether or not
rejection is expected.

Signed-off-by: Jordan Rife <jrife@google.com>
Link: https://lore.kernel.org/r/20240510190246.3247730-4-jrife@google.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Handle LOAD_REJECT test cases in selftests/bpf by adding expected_attach_type and extending load_fn function.,"LOAD_REJECT,test cases,expected_attach_type",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).', ""It's not related to any of the above.""]"
86b65c6db0190fb6c119e83da4de0eccf74fb1ff,86b65c6db0190fb6c119e83da4de0eccf74fb1ff,Jordan Rife,jrife@google.com,1715367739,Alexei Starovoitov,ast@kernel.org,1715559040,260233ae794c406a0ac93a68de34ba2da6c15ba1,73964e9085bbea517a675d5d8ceeb1e609a34748,"selftests/bpf: Use program name for skel load/destroy functions

In preparation to migrate tests from bpf/test_sock_addr.c to
sock_addr.c"," update BPF_SKEL_FUNCS so that it generates functions
based on prog_name instead of skel_name. This allows us to differentiate
between programs in the same skeleton.

Signed-off-by: Jordan Rife <jrife@google.com>
Link: https://lore.kernel.org/r/20240510190246.3247730-3-jrife@google.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],"The commit updates BPF_SKEL_FUNCS to use program names for load/destroy functions in bpf self-tests, aiding migration of test_sock_addr to sock_addr.","BPF_SKEL_FUNCS, self-tests, program names",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
73964e9085bbea517a675d5d8ceeb1e609a34748,73964e9085bbea517a675d5d8ceeb1e609a34748,Jordan Rife,jrife@google.com,1715367738,Alexei Starovoitov,ast@kernel.org,1715559040,4e1246b3751bee60f2020a3ca71dec5c7c2e12d8,20a759df3bba35bf5c3ddec0c02ad69b603b584c,"selftests/bpf: Migrate recvmsg* return code tests to verifier_sock_addr.c

This set of tests check that the BPF verifier rejects programs with
invalid return codes (recvmsg4 and recvmsg6 hooks can only return 1).
This patch replaces the tests in test_sock_addr.c with
verifier_sock_addr.c", a new verifier prog_tests for sockaddr hooks,"[' in a\nstep towards fully retiring test_sock_addr.c.\n\nSigned-off-by: Jordan Rife <jrife@google.com>\nLink: https://lore.kernel.org/r/20240510190246.3247730-2-jrife@google.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Migrate and verify BPF tests for recvmsg return codes to verifier_sock_addr.c.,"BPF verifier, recvmsg, tests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
ea558c86248b4955e5c5f3c0c921df450880605e,ea558c86248b4955e5c5f3c0c921df450880605e,Namhyung Kim,namhyung@kernel.org,1714433827,Arnaldo Carvalho de Melo,acme@redhat.com,1715558992,156c03a9f1da0c3b7ff5952fca1ebf0eb5d04ca2,d9c5f5f94c2d356fdf3503f7fcaf254512bc032d,"tools lib subcmd: Show parent options in help

I've just realized that help message in a subcommand didn't show one
in the parent command.  Since the option parser understands the parent","
display code should do the same.  For example","[' `perf ftrace latency -h`\nshould show options in the `perf ftrace` command too.\n\nBefore:\n\n  $ perf ftrace latency -h\n\n   Usage: perf ftrace [<options>] [<command>]\n      or: perf ftrace [<options>] -- [<command>] [<options>]\n      or: perf ftrace {trace|latency} [<options>] [<command>]\n      or: perf ftrace {trace|latency} [<options>] -- [<command>] [<options>]\n\n      -b', ' --use-bpf         Use BPF to measure function latency\n      -n', ' --use-nsec        Use nano-second histogram\n      -T', ' --trace-funcs <func>\n                            Show latency of given function\n\nAfter:\n\n  $ perf ftrace latency -h\n\n   Usage: perf ftrace [<options>] [<command>]\n      or: perf ftrace [<options>] -- [<command>] [<options>]\n      or: perf ftrace {trace|latency} [<options>] [<command>]\n      or: perf ftrace {trace|latency} [<options>] -- [<command>] [<options>]\n\n      -a', ' --all-cpus        System-wide collection from all CPUs\n      -b', ' --use-bpf         Use BPF to measure function latency\n      -C', ' --cpu <cpu>       List of cpus to monitor\n      -n', ' --use-nsec        Use nano-second histogram\n      -p', ' --pid <pid>       Trace on existing process id\n      -T', ' --trace-funcs <func>\n                            Show latency of given function\n      -v', ' --verbose         Be more verbose\n          --tid <tid>       Trace on existing thread id (exclusive to --pid)\n\nReviewed-by: Ian Rogers <irogers@google.com>\nSigned-off-by: Namhyung Kim <namhyung@kernel.org>\nCc: Adrian Hunter <adrian.hunter@intel.com>\nCc: Ingo Molnar <mingo@kernel.org>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: Kan Liang <kan.liang@linux.intel.com>\nCc: Peter Zijlstra <peterz@infradead.org>\nLink: https://lore.kernel.org/r/20240429233707.1511175-1-namhyung@kernel.org\nSigned-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>\n', '']",Updated help message to show parent options in subcommands for tools library.,"help, subcommand, parser",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"[""It's not related to any of the above.""]"
20a759df3bba35bf5c3ddec0c02ad69b603b584c,20a759df3bba35bf5c3ddec0c02ad69b603b584c,Puranjay Mohan,puranjay@kernel.org,1714940193,Alexei Starovoitov,ast@kernel.org,1715558406,7006fd829bd640badfba46ab78baa7c03ff5f4d8,80c5a07ae673a740ef7ef0fe1ab588075a25ce8d,riscv," bpf: make some atomic operations fully ordered

The BPF atomic operations with the BPF_FETCH modifier along with
BPF_XCHG and BPF_CMPXCHG are fully ordered but the RISC-V JIT implements
all atomic operations except BPF_CMPXCHG with relaxed ordering.

Section 8.1 of the ""The RISC-V Instruction Set Manual Volume I:
Unprivileged ISA"" [1]","[' titled', ' ""Specifying Ordering of Atomic\nInstructions"" says:\n\n| To provide more efficient support for release consistency [5]', ' each\n| atomic instruction has two bits', ' aq and rl', ' used to specify additional\n| memory ordering constraints as viewed by other RISC-V harts.\n\nand\n\n| If only the aq bit is set', ' the atomic memory operation is treated as\n| an acquire access.\n| If only the rl bit is set', ' the atomic memory operation is treated as a\n| release access.\n|\n| If both the aq and rl bits are set', ' the atomic memory operation is\n| sequentially consistent.\n\nFix this by setting both aq and rl bits as 1 for operations with\nBPF_FETCH and BPF_XCHG.\n\n[1] https://riscv.org/wp-content/uploads/2017/05/riscv-spec-v2.2.pdf\n\nFixes: dd642ccb45ec (""riscv', ' bpf: Implement more atomic operations for RV64"")\nSigned-off-by: Puranjay Mohan <puranjay@kernel.org>\nReviewed-by: Pu Lehui <pulehui@huawei.com>\nLink: https://lore.kernel.org/r/20240505201633.123115-1-puranjay@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",RISC-V JIT updates atomic operations to be fully ordered in BPF contexts.,"RISC-V, atomic, JIT",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
80c5a07ae673a740ef7ef0fe1ab588075a25ce8d,80c5a07ae673a740ef7ef0fe1ab588075a25ce8d,Xiao Wang,xiao.w.wang@intel.com,1715080578,Alexei Starovoitov,ast@kernel.org,1715558203,3ee3909d6464aedf22dd0fa25d3407eec9ed0dfb,68378982f0b21de02ac3c6a11e2420badefcb4bc,riscv," bpf: Fix typo in comment

We can use either ""instruction"" or ""insn"" in the comment.

Signed-off-by: Xiao Wang <xiao.w.wang@intel.com>
Reviewed-by: Pu Lehui <pulehui@huawei.com>
Link: https://lore.kernel.org/r/20240507111618.437121-1-xiao.w.wang@intel.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Fix a typo in a comment for the RISC-V architecture support in eBPF.,"typo,fixed,comment",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
68378982f0b21de02ac3c6a11e2420badefcb4bc,68378982f0b21de02ac3c6a11e2420badefcb4bc,Ilya Leoshkevich,iii@linux.ibm.com,1715040169,Alexei Starovoitov,ast@kernel.org,1715558157,21098308f0f3465e5e38a20e7bd06c2735b7dad5,55302bc1ca64160fec4dfa25e52142691ecb5dcd,"s390/bpf: Emit a barrier for BPF_FETCH instructions

BPF_ATOMIC_OP() macro documentation states that ""BPF_ADD | BPF_FETCH""
should be the same as atomic_fetch_add()"," which is currently not the
case on s390x: the serialization instruction ""bcr 14","['0"" is missing.\nThis applies to ""and""', ' ""or"" and ""xor"" variants too.\n\ns390x is allowed to reorder stores with subsequent fetches from\ndifferent addresses', ' so code relying on BPF_FETCH acting as a barrier', '\nfor example:\n\n  stw [%r0]', ' 1\n  afadd [%r1]', ' %r2\n  ldxw %r3', ' [%r4]\n\nmay be broken. Fix it by emitting ""bcr 14', '0"".\n\nNote that a separate serialization instruction is not needed for\nBPF_XCHG and BPF_CMPXCHG', ' because COMPARE AND SWAP performs\nserialization itself.\n\nFixes: ba3b86b9cef0 (""s390/bpf: Implement new atomic ops"")\nReported-by: Puranjay Mohan <puranjay12@gmail.com>\nCloses: https://lore.kernel.org/bpf/mb61p34qvq3wf.fsf@kernel.org/\nSigned-off-by: Ilya Leoshkevich <iii@linux.ibm.com>\nReviewed-by: Puranjay Mohan <puranjay@kernel.org>\nLink: https://lore.kernel.org/r/20240507000557.12048-1-iii@linux.ibm.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']","The commit addresses a serialization issue on s390x with BPF_FETCH instructions, ensuring proper atomic operations.","s390,bpf,atomic",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
55302bc1ca64160fec4dfa25e52142691ecb5dcd,55302bc1ca64160fec4dfa25e52142691ecb5dcd,Alexei Starovoitov,ast@kernel.org,1715558074,Alexei Starovoitov,ast@kernel.org,1715558075,fd23f2dc376d2db2d93c1831ad0abae58eb0868e,f122668ddcce450c2585f0be4bf4478d6fd6176b 75fe4c0b3e181f5e3b990128013ac192fdfd4012,"Merge branch 'bpf-inline-helpers-in-arm64-and-riscv-jits'

Puranjay Mohan says:

====================
bpf: Inline helpers in arm64 and riscv JITs

Changes in v5 -> v6:
arm64 v5: https://lore.kernel.org/all/20240430234739.79185-1-puranjay@kernel.org/
riscv v2: https://lore.kernel.org/all/20240430175834.33152-1-puranjay@kernel.org/
- Combine riscv and arm64 changes in single series
- Some coding style fixes

Changes in v4 -> v5:
v4: https://lore.kernel.org/all/20240429131647.50165-1-puranjay@kernel.org/
- Implement the inlining of the bpf_get_smp_processor_id() in the JIT.

NOTE: This needs to be based on:
https://lore.kernel.org/all/20240430175834.33152-1-puranjay@kernel.org/
to be built.

Manual run of bpf-ci with this series rebased on above:
https://github.com/kernel-patches/bpf/pull/6929

Changes in v3 -> v4:
v3: https://lore.kernel.org/all/20240426121349.97651-1-puranjay@kernel.org/
- Fix coding style issue related to C89 standards.

Changes in v2 -> v3:
v2: https://lore.kernel.org/all/20240424173550.16359-1-puranjay@kernel.org/
- Fixed the xlated dump of percpu mov to ""r0 = &(void __percpu *)(r0)""
- Made ARM64 and x86-64 use the same code for inlining. The only difference
  that remains is the per-cpu address of the cpu_number.

Changes in v1 -> v2:
v1: https://lore.kernel.org/all/20240405091707.66675-1-puranjay12@gmail.com/
- Add a patch to inline bpf_get_smp_processor_id()
- Fix an issue in MRS instruction encoding as pointed out by Will
- Remove CONFIG_SMP check because arm64 kernel always compiles with CONFIG_SMP

This series adds the support of internal only per-CPU instructions and inlines
the bpf_get_smp_processor_id() helper call for ARM64 and RISC-V BPF JITs.

Here is an example of calls to bpf_get_smp_processor_id() and
percpu_array_map_lookup_elem() before and after this series on ARM64.

                                         BPF
                                        =====
              BEFORE                                       AFTER
             --------                                     -------

int cpu = bpf_get_smp_processor_id();           int cpu = bpf_get_smp_processor_id();
(85) call bpf_get_smp_processor_id#229032       (85) call bpf_get_smp_processor_id#8

p = bpf_map_lookup_elem(map", &zero);            p = bpf_map_lookup_elem(map,"[' &zero);\n(18) r1 = map[id:78]                            (18) r1 = map[id:153]\n(18) r2 = map[id:82][0]+65536                   (18) r2 = map[id:157][0]+65536\n(85) call percpu_array_map_lookup_elem#313512   (07) r1 += 496\n                                                (61) r0 = *(u32 *)(r2 +0)\n                                                (35) if r0 >= 0x1 goto pc+5\n                                                (67) r0 <<= 3\n                                                (0f) r0 += r1\n                                                (79) r0 = *(u64 *)(r0 +0)\n                                                (bf) r0 = &(void __percpu *)(r0)\n                                                (05) goto pc+1\n                                                (b7) r0 = 0\n\n                                      ARM64 JIT\n                                     ===========\n\n              BEFORE                                       AFTER\n             --------                                     -------\n\nint cpu = bpf_get_smp_processor_id();           int cpu = bpf_get_smp_processor_id();\nmov     x10', ' #0xfffffffffffff4d0                mrs     x10', ' sp_el0\nmovk    x10', ' #0x802b', ' lsl #16                   ldr     w7', ' [x10', ' #24]\nmovk    x10', ' #0x8000', ' lsl #32\nblr     x10\nadd     x7', ' x0', ' #0x0\n\np = bpf_map_lookup_elem(map', ' &zero);            p = bpf_map_lookup_elem(map', ' &zero);\nmov     x0', ' #0xffff0003ffffffff                 mov     x0', ' #0xffff0003ffffffff\nmovk    x0', ' #0xce5c', ' lsl #16                    movk    x0', ' #0xe0f3', ' lsl #16\nmovk    x0', ' #0xca00                             movk    x0', ' #0x7c00\nmov     x1', ' #0xffff8000ffffffff                 mov     x1', ' #0xffff8000ffffffff\nmovk    x1', ' #0x8bdb', ' lsl #16                    movk    x1', ' #0xb0c7', ' lsl #16\nmovk    x1', ' #0x6000                             movk    x1', ' #0xe000\nmov     x10', ' #0xffffffffffff3ed0                add     x0', ' x0', ' #0x1f0\nmovk    x10', ' #0x802d', ' lsl #16                   ldr     w7', ' [x1]\nmovk    x10', ' #0x8000', ' lsl #32                   cmp     x7', ' #0x1\nblr     x10                                     b.cs    0x0000000000000090\nadd     x7', ' x0', ' #0x0                            lsl     x7', ' x7', ' #3\n                                                add     x7', ' x7', ' x0\n                                                ldr     x7', ' [x7]\n                                                mrs     x10', ' tpidr_el1\n                                                add     x7', ' x7', ' x10\n                                                b       0x0000000000000094\n                                                mov     x7', ' #0x0\n\n              Performance improvement found using benchmark[1]\n\n./benchs/run_bench_trigger.sh glob-arr-inc arr-inc hash-inc\n\n  +---------------+-------------------+-------------------+--------------+\n  |      Name     |      Before       |        After      |   % change   |\n  |---------------+-------------------+-------------------+--------------|\n  | glob-arr-inc  | 23.380 ± 1.675M/s | 25.893 ± 0.026M/s |   + 10.74%   |\n  | arr-inc       | 23.928 ± 0.034M/s | 25.213 ± 0.063M/s |   + 5.37%    |\n  | hash-inc      | 12.352 ± 0.005M/s | 12.609 ± 0.013M/s |   + 2.08%    |\n  +---------------+-------------------+-------------------+--------------+\n\n[1] https://github.com/anakryiko/linux/commit/8dec900975ef\n\n             RISCV64 JIT output for `call bpf_get_smp_processor_id`\n            =======================================================\n\n                  Before                           After\n                 --------                         -------\n\n           auipc   t1', '0x848c                  ld    a5', '32(tp)\n           jalr    604(t1)\n           mv      a5', 'a0\n\n  Benchmark using [1] on Qemu.\n\n  ./benchs/run_bench_trigger.sh glob-arr-inc arr-inc hash-inc\n\n  +---------------+------------------+------------------+--------------+\n  |      Name     |     Before       |       After      |   % change   |\n  |---------------+------------------+------------------+--------------|\n  | glob-arr-inc  | 1.077 ± 0.006M/s | 1.336 ± 0.010M/s |   + 24.04%   |\n  | arr-inc       | 1.078 ± 0.002M/s | 1.332 ± 0.015M/s |   + 23.56%   |\n  | hash-inc      | 0.494 ± 0.004M/s | 0.653 ± 0.001M/s |   + 32.18%   |\n  +---------------+------------------+------------------+--------------+\n====================\n\nLink: https://lore.kernel.org/r/20240502151854.9810-1-puranjay@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit merges inline helper support for ARM64 and RISC-V JITs in the BPF subsystem.,"inline helpers, ARM64, RISC-V",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
75fe4c0b3e181f5e3b990128013ac192fdfd4012,75fe4c0b3e181f5e3b990128013ac192fdfd4012,Puranjay Mohan,puranjay@kernel.org,1714663134,Alexei Starovoitov,ast@kernel.org,1715558074,fd23f2dc376d2db2d93c1831ad0abae58eb0868e,7a4c32222b0e14349a6311e72bf6ebd3e1d1064b,bpf," arm64: inline bpf_get_smp_processor_id() helper

Inline calls to bpf_get_smp_processor_id() helper in the JIT by emitting
a read from struct thread_info. The SP_EL0 system register holds the
pointer to the task_struct and thread_info is the first member of this
struct. We can read the cpu number from the thread_info.

Here is how the ARM64 JITed assembly changes after this commit:

                                      ARM64 JIT
                                     ===========

              BEFORE                                    AFTER
             --------                                  -------

int cpu = bpf_get_smp_processor_id();        int cpu = bpf_get_smp_processor_id();

mov     x10","[' #0xfffffffffffff4d0             mrs     x10', ' sp_el0\nmovk    x10', ' #0x802b', ' lsl #16                ldr     w7', ' [x10', ' #24]\nmovk    x10', ' #0x8000', ' lsl #32\nblr     x10\nadd     x7', ' x0', ' #0x0\n\n               Performance improvement using benchmark[1]\n\n./benchs/run_bench_trigger.sh glob-arr-inc arr-inc hash-inc\n\n+---------------+-------------------+-------------------+--------------+\n|      Name     |      Before       |        After      |   % change   |\n|---------------+-------------------+-------------------+--------------|\n| glob-arr-inc  | 23.380 ± 1.675M/s | 25.893 ± 0.026M/s |   + 10.74%   |\n| arr-inc       | 23.928 ± 0.034M/s | 25.213 ± 0.063M/s |   + 5.37%    |\n| hash-inc      | 12.352 ± 0.005M/s | 12.609 ± 0.013M/s |   + 2.08%    |\n+---------------+-------------------+-------------------+--------------+\n\n[1] https://github.com/anakryiko/linux/commit/8dec900975ef\n\nSigned-off-by: Puranjay Mohan <puranjay@kernel.org>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240502151854.9810-5-puranjay@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Inline calls to bpf_get_smp_processor_id in ARM64 JIT using thread_info.,"inline,JIT,ARM64",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7a4c32222b0e14349a6311e72bf6ebd3e1d1064b,7a4c32222b0e14349a6311e72bf6ebd3e1d1064b,Puranjay Mohan,puranjay12@gmail.com,1714663133,Alexei Starovoitov,ast@kernel.org,1715558074,9ddaf85ad93083fce7617d27bdae282c52eb2e16,2ddec2c80b4402c293c7e6e0881cecaaf77e8cec,arm64," bpf: add internal-only MOV instruction to resolve per-CPU addrs

Support an instruction for resolving absolute addresses of per-CPU
data from their per-CPU offsets. This instruction is internal-only and
users are not allowed to use them directly. They will only be used for
internal inlining optimizations for now between BPF verifier and BPF
JITs.

Since commit 7158627686f0 (""arm64: percpu: implement optimised pcpu
access using tpidr_el1"")","[' the per-cpu offset for the CPU is stored in\nthe tpidr_el1/2 register of that CPU.\n\nTo support this BPF instruction in the ARM64 JIT', ' the following ARM64\ninstructions are emitted:\n\nmov dst', ' src\t\t// Move src to dst', ' if src != dst\nmrs tmp', ' tpidr_el1/2\t// Move per-cpu offset of the current cpu in tmp.\nadd dst', ' dst', ' tmp\t// Add the per cpu offset to the dst.\n\nTo measure the performance improvement provided by this change', ' the\nbenchmark in [1] was used:\n\nBefore:\nglob-arr-inc   :   23.597 ± 0.012M/s\narr-inc        :   23.173 ± 0.019M/s\nhash-inc       :   12.186 ± 0.028M/s\n\nAfter:\nglob-arr-inc   :   23.819 ± 0.034M/s\narr-inc        :   23.285 ± 0.017M/s\nhash-inc       :   12.419 ± 0.011M/s\n\n[1] https://github.com/anakryiko/linux/commit/8dec900975ef\n\nSigned-off-by: Puranjay Mohan <puranjay12@gmail.com>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240502151854.9810-4-puranjay@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add internal-only MOV instruction for resolving absolute addresses of per-CPU data for inlining optimizations in BPF verifier and JITs on arm64.,"MOV instruction, per-CPU, optimization",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2ddec2c80b4402c293c7e6e0881cecaaf77e8cec,2ddec2c80b4402c293c7e6e0881cecaaf77e8cec,Puranjay Mohan,puranjay@kernel.org,1714663132,Alexei Starovoitov,ast@kernel.org,1715558074,89aee6a00fc8312f43c2fae605a8e0a4c9062721,19c56d4e5be102cd118162b9f72d9c6d353e76fc,riscv," bpf: inline bpf_get_smp_processor_id()

Inline the calls to bpf_get_smp_processor_id() in the riscv bpf jit.

RISCV saves the pointer to the CPU's task_struct in the TP (thread
pointer) register. This makes it trivial to get the CPU's processor id.
As thread_info is the first member of task_struct","[' we can read the\nprocessor id from TP + offsetof(struct thread_info', ' cpu).\n\n          RISCV64 JIT output for `call bpf_get_smp_processor_id`\n\t  ======================================================\n\n                Before                           After\n               --------                         -------\n\n         auipc   t1', '0x848c                  ld    a5', '32(tp)\n         jalr    604(t1)\n         mv      a5', 'a0\n\nBenchmark using [1] on Qemu.\n\n./benchs/run_bench_trigger.sh glob-arr-inc arr-inc hash-inc\n\n+---------------+------------------+------------------+--------------+\n|      Name     |     Before       |       After      |   % change   |\n|---------------+------------------+------------------+--------------|\n| glob-arr-inc  | 1.077 ± 0.006M/s | 1.336 ± 0.010M/s |   + 24.04%   |\n| arr-inc       | 1.078 ± 0.002M/s | 1.332 ± 0.015M/s |   + 23.56%   |\n| hash-inc      | 0.494 ± 0.004M/s | 0.653 ± 0.001M/s |   + 32.18%   |\n+---------------+------------------+------------------+--------------+\n\nNOTE: This benchmark includes changes from this patch and the previous\n      patch that implemented the per-cpu insn.\n\n[1] https://github.com/anakryiko/linux/commit/8dec900975ef\n\nSigned-off-by: Puranjay Mohan <puranjay@kernel.org>\nAcked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Björn Töpel <bjorn@kernel.org>\nLink: https://lore.kernel.org/r/20240502151854.9810-3-puranjay@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Inline bpf_get_smp_processor_id() calls in the RISC-V BPF JIT for efficient CPU processor ID retrieval.,"inline,RISC-V,JIT",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
19c56d4e5be102cd118162b9f72d9c6d353e76fc,19c56d4e5be102cd118162b9f72d9c6d353e76fc,Puranjay Mohan,puranjay@kernel.org,1714663131,Alexei Starovoitov,ast@kernel.org,1715558074,0b3078b5e18ca50af611fc29c79cb0222405853e,f122668ddcce450c2585f0be4bf4478d6fd6176b,riscv," bpf: add internal-only MOV instruction to resolve per-CPU addrs

Support an instruction for resolving absolute addresses of per-CPU
data from their per-CPU offsets. This instruction is internal-only and
users are not allowed to use them directly. They will only be used for
internal inlining optimizations for now between BPF verifier and BPF
JITs.

RISC-V uses generic per-cpu implementation where the offsets for CPUs
are kept in an array called __per_cpu_offset[cpu_number]. RISCV stores
the address of the task_struct in TP register. The first element in
task_struct is struct thread_info","[' and we can get the cpu number by\nreading from the TP register + offsetof(struct thread_info', ' cpu).\n\nOnce we have the cpu number in a register we read the offset for that\ncpu from address: &__per_cpu_offset + cpu_number << 3. Then we add this\noffset to the destination register.\n\nTo measure the improvement from this change', ' the benchmark in [1] was\nused on Qemu:\n\nBefore:\nglob-arr-inc   :    1.127 ± 0.013M/s\narr-inc        :    1.121 ± 0.004M/s\nhash-inc       :    0.681 ± 0.052M/s\n\nAfter:\nglob-arr-inc   :    1.138 ± 0.011M/s\narr-inc        :    1.366 ± 0.006M/s\nhash-inc       :    0.676 ± 0.001M/s\n\n[1] https://github.com/anakryiko/linux/commit/8dec900975ef\n\nSigned-off-by: Puranjay Mohan <puranjay@kernel.org>\nAcked-by: Björn Töpel <bjorn@kernel.org>\nLink: https://lore.kernel.org/r/20240502151854.9810-2-puranjay@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add an internal-only MOV instruction for resolving per-CPU addresses in RISC-V architecture.,"MOV instruction,RISC-V,per-CPU",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f122668ddcce450c2585f0be4bf4478d6fd6176b,f122668ddcce450c2585f0be4bf4478d6fd6176b,Shahab Vahedi,shahab@synopsys.com,1714488964,Alexei Starovoitov,ast@kernel.org,1715557896,728a4617241183e817241430b59315e81c41afc5,fcd1ed89a0439c45e1336bd9649485c44b7597c7,"ARC: Add eBPF JIT support

This will add eBPF JIT support to the 32-bit ARCv2 processors. The
implementation is qualified by running the BPF tests on a Synopsys HSDK
board with ""ARC HS38 v2.1c at 500 MHz"" as the 4-core CPU.

The test_bpf.ko reports 2-10 fold improvements in execution time of its
tests. For instance:

test_bpf: #33 tcpdump port 22 jited:0 704 1766 2104 PASS
test_bpf: #33 tcpdump port 22 jited:1 120  224  260 PASS

test_bpf: #141 ALU_DIV_X: 4294967295 / 4294967295 = 1 jited:0 238 PASS
test_bpf: #141 ALU_DIV_X: 4294967295 / 4294967295 = 1 jited:1  23 PASS

test_bpf: #776 JMP32_JGE_K: all ... magnitudes jited:0 2034681 PASS
test_bpf: #776 JMP32_JGE_K: all ... magnitudes jited:1 1020022 PASS

Deployment and structure
------------------------
The related codes are added to ""arch/arc/net"":

- bpf_jit.h       -- The interface that a back-end translator must provide
- bpf_jit_core.c  -- Knows how to handle the input eBPF byte stream
- bpf_jit_arcv2.c -- The back-end code that knows the translation logic

The bpf_int_jit_compile() at the end of bpf_jit_core.c is the entrance
to the whole process. Normally", the translation is done in one pass,"['\nnamely the ""normal pass"". In case some relocations are not known during\nthis pass', ' some data (arc_jit_data) is allocated for the next pass to\ncome. This possible next (and last) pass is called the ""extra pass"".\n\n1. Normal pass       # The necessary pass\n     1a. Dry run       # Get the whole JIT length', ' epilogue offset', ' etc.\n     1b. Emit phase    # Allocate memory and start emitting instructions\n2. Extra pass        # Only needed if there are relocations to be fixed\n     2a. Patch relocations\n\nSupport status\n--------------\nThe JIT compiler supports BPF instructions up to ""cpu=v4"". However', ' it\ndoes not yet provide support for:\n\n- Tail calls\n- Atomic operations\n- 64-bit division/remainder\n- BPF_PROBE_MEM* (exception table)\n\nThe result of ""test_bpf"" test suite on an HSDK board is:\n\nhsdk-lnx# insmod test_bpf.ko test_suite=test_bpf\n\n  test_bpf: Summary: 863 PASSED', ' 186 FAILED', "" [851/851 JIT'ed]\n\nAll the failing test cases are due to the ones that were not JIT'ed.\nCategorically"", ' they can be represented as:\n\n  .-----------.------------.-------------.\n  | test type |   opcodes  | # of cases  |\n  |-----------+------------+-------------|\n  | atomic    | 0xC3', ' 0xDB |         149 |\n  | div64     | 0x37', ' 0x3F |          22 |\n  | mod64     | 0x97', "" 0x9F |          15 |\n  `-----------^------------+-------------|\n                           | (total) 186 |\n                           `-------------'\n\nSetup: build config\n-------------------\nThe following configs must be set to have a working JIT test:\n\n  CONFIG_BPF_JIT=y\n  CONFIG_BPF_JIT_ALWAYS_ON=y\n  CONFIG_TEST_BPF=m\n\nThe following options are not necessary for the tests module"", '\nbut are good to have:\n\n  CONFIG_DEBUG_INFO=y             # prerequisite for below\n  CONFIG_DEBUG_INFO_BTF=y         # so bpftool can generate vmlinux.h\n\n  CONFIG_FTRACE=y                 #\n  CONFIG_BPF_SYSCALL=y            # all these options lead to\n  CONFIG_KPROBE_EVENTS=y          # having CONFIG_BPF_EVENTS=y\n  CONFIG_PERF_EVENTS=y            #\n\nSome BPF programs provide data through /sys/kernel/debug:\n  CONFIG_DEBUG_FS=y\narc# mount -t debugfs debugfs /sys/kernel/debug\n\nSetup: elfutils\n---------------\nThe libdw.{so', 'a} library that is used by pahole for processing\nthe final binary must come from elfutils 0.189 or newer. The\nsupport for ARCv2 [1] has been added since that version.\n\n[1]\nhttps://sourceware.org/git/?p=elfutils.git;a=commit;h=de3d46b3e7\n\nSetup: pahole\n-------------\nThe line below in linux/scripts/Makefile.btf must be commented out:\n\npahole-flags-$(call test-ge', ' $(pahole-ver)', ' 121) += --btf_gen_floats\n\nOr else', ' the build will fail:\n\n$ make V=1\n  ...\n  BTF     .btf.vmlinux.bin.o\npahole -J --btf_gen_floats                    \\\n       -j --lang_exclude=rust                 \\\n       --skip_encoding_btf_inconsistent_proto \\\n       --btf_gen_optimized .tmp_vmlinux.btf\nComplex', ' interval and imaginary float types are not supported\nEncountered error while encoding BTF.\n  ...\n  BTFIDS  vmlinux\n./tools/bpf/resolve_btfids/resolve_btfids vmlinux\nlibbpf: failed to find \'.BTF\' ELF section in vmlinux\nFAILED: load BTF from vmlinux: No data available\n\nThis is due to the fact that the ARC toolchains generate\n""complex float"" DIE entries in libgcc and at the moment', "" pahole\ncan't handle such entries.\n\nRunning the tests\n-----------------\nhost$ scp /bld/linux/lib/test_bpf.ko arc:\narc # sysctl net.core.bpf_jit_enable=1\narc # insmod test_bpf.ko test_suite=test_bpf\n      ...\n      test_bpf: #1048 Staggered jumps: JMP32_JSLE_X jited:1 697811 PASS\n      test_bpf: Summary: 863 PASSED"", ' 186 FAILED', "" [851/851 JIT'ed]\n\nAcknowledgments\n---------------\n- Claudiu Zissulescu for his unwavering support\n- Yuriy Kolerov for testing and troubleshooting\n- Vladimir Isaev for the pahole workaround\n- Sergey Matyukevich for paving the road by adding the interpreter support\n\nSigned-off-by: Shahab Vahedi <shahab@synopsys.com>\nLink: https://lore.kernel.org/r/20240430145604.38592-1-list+bpf@vahedi.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Adds eBPF JIT support to 32-bit ARCv2 processors for improved performance.,"eBPF JIT support, ARCv2, performance",It's a new feature.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fcd1ed89a0439c45e1336bd9649485c44b7597c7,fcd1ed89a0439c45e1336bd9649485c44b7597c7,Alan Maguire,alan.maguire@oracle.com,1715090114,Andrii Nakryiko,andrii@kernel.org,1715291075,c094a419732049a99a3f9a9fab88485e735781f0,0d03a4d24bfa4f806ddc2cfa8ebd0eac81139b23,kbuild,"bpf: Switch to using --btf_features for pahole v1.26 and later

The btf_features list can be used for pahole v1.26 and later -
it is useful because if a feature is not yet implemented it will
not exit with a failure message.  This will allow us to add feature
requests to the pahole options without having to check pahole versions
in future; if the version of pahole supports the feature it will be
added.

Signed-off-by: Alan Maguire <alan.maguire@oracle.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Tested-by: Eduard Zingerman <eddyz87@gmail.com>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240507135514.490467-1-alan.maguire@oracle.com
",[''],Enable btf_features for pahole v1.26+ to avoid compatibility issues with future feature requests.,"btf_features,pahole,compatibility",It's a build system or CI/CD change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7abbf38cd8edb92bc72fe3405f8a0bf19f7761c2,7abbf38cd8edb92bc72fe3405f8a0bf19f7761c2,Geliang Tang,tanggeliang@kylinos.cn,1714908913,Martin KaFai Lau,martin.lau@kernel.org,1715287238,00f58e7fa719f53892628b80a95ddd6be441ba67,65a3f0df44dd3db0f77e6ccff0a126969abc0da4,"selftests/bpf: Drop get_port in test_tcp_check_syncookie

The arguments ""addr"" and ""len"" of run_test() have dropped. This makes
function get_port() useless. Drop it from test_tcp_check_syncookie_user.c.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/a9b5c8064ab4cbf0f68886fe0e4706428b8d0d47.1714907662.git.tanggeliang@kylinos.cn
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Removed the unused get_port function from test_tcp_check_syncookie due to dropped arguments.,"Dropped, test, function",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
65a3f0df44dd3db0f77e6ccff0a126969abc0da4,65a3f0df44dd3db0f77e6ccff0a126969abc0da4,Geliang Tang,tanggeliang@kylinos.cn,1714908912,Martin KaFai Lau,martin.lau@kernel.org,1715287238,a233cb5a677e66f6c4e198e7b37e4439588f95de,5059c73eca67e686dea42af079c41857cb00a5a6,"selftests/bpf: Use connect_to_fd in test_tcp_check_syncookie

This patch uses public helper connect_to_fd() exported in network_helpers.h
instead of the local defined function connect_to_server() in
test_tcp_check_syncookie_user.c. This can avoid duplicate code.

Then the arguments ""addr"" and ""len"" of run_test() become useless"," drop them
too.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/e0ae6b790ac0abc7193aadfb2660c8c9eb0fe1f0.1714907662.git.tanggeliang@kylinos.cn
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],The commit replaces a locally defined function with a public helper to reduce code duplication in a BPF selftest.,"selftests,bpf,connect_to_fd",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tracepoints like programs']
5059c73eca67e686dea42af079c41857cb00a5a6,5059c73eca67e686dea42af079c41857cb00a5a6,Geliang Tang,tanggeliang@kylinos.cn,1714908911,Martin KaFai Lau,martin.lau@kernel.org,1715287238,21994083ea25f7265a4ec87328feda66d5a049d3,49e1fa8dbd81340f610057be3f3909f24c232807,"selftests/bpf: Use connect_to_fd in sockopt_inherit

This patch uses public helper connect_to_fd() exported in network_helpers.h
instead of the local defined function connect_to_server() in
prog_tests/sockopt_inherit.c. This can avoid duplicate code.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/71db79127cc160b0643fd9a12c70ae019ae076a1.1714907662.git.tanggeliang@kylinos.cn
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,"Refactored sockopt_inherit test to use connect_to_fd from network_helpers.h, replacing local connect_to_server to eliminate code duplication.","refactoring, selftests, duplication",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
49e1fa8dbd81340f610057be3f3909f24c232807,49e1fa8dbd81340f610057be3f3909f24c232807,Geliang Tang,tanggeliang@kylinos.cn,1714908910,Martin KaFai Lau,martin.lau@kernel.org,1715287238,fc50583586dff003832a56fa604d97e424694266,5166b3e3e30a8eb93f7182283ed4db719bdfde1a,"selftests/bpf: Use start_server_addr in test_tcp_check_syncookie

Include network_helpers.h in test_tcp_check_syncookie_user.c"," use
public helper start_server_addr() in it instead of the local defined
function start_server(). This can avoid duplicate code.

Add two helpers v6only_true() and v6only_false() to set IPV6_V6ONLY
sockopt to true or false","[' set them to post_socket_cb pointer of struct\nnetwork_helper_opts', ' and pass it to start_server_setsockopt().\n\nIn order to use functions defined in network_helpers.c', ' Makefile needs\nto be updated too.\n\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nLink: https://lore.kernel.org/r/e0c5324f5da84f453f47543536e70f126eaa8678.1714907662.git.tanggeliang@kylinos.cn\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",The commit refactors test_tcp_check_syncookie to use start_server_addr and adds helpers to manage IPV6_V6ONLY sockopt.,"refactor, helpers, IPV6_V6ONLY",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"[""It's not related to any of the above.""]"
5166b3e3e30a8eb93f7182283ed4db719bdfde1a,5166b3e3e30a8eb93f7182283ed4db719bdfde1a,Geliang Tang,tanggeliang@kylinos.cn,1714908909,Martin KaFai Lau,martin.lau@kernel.org,1715287238,1411c5e983766b8bc25f2b8184adb1ce73d47f08,20434d2d896f85b38fa1fe91b8739afcd9cde3b3,"selftests/bpf: Use start_server_addr in sockopt_inherit

Include network_helpers.h in prog_tests/sockopt_inherit.c"," use public
helper start_server_addr() instead of the local defined function
start_server(). This can avoid duplicate code.

Add a helper custom_cb() to set SOL_CUSTOM sockopt looply","[' set it to\npost_socket_cb pointer of struct network_helper_opts', ' and pass it to\nstart_server_addr().\n\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nLink: https://lore.kernel.org/r/687af66f743a0bf15cdba372c5f71fe64863219e.1714907662.git.tanggeliang@kylinos.cn\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Refactor sockopt_inherit.c to use network_helpers and add custom_cb for SOL_CUSTOM sockopt loop.,network_helpers sockopt custom_cb,It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
20434d2d896f85b38fa1fe91b8739afcd9cde3b3,20434d2d896f85b38fa1fe91b8739afcd9cde3b3,Geliang Tang,tanggeliang@kylinos.cn,1714908908,Martin KaFai Lau,martin.lau@kernel.org,1715287229,3b55f7de36502ae460b7b7418222b99c9c5c9dd1,cbe35adf691a3227b11131a922245c4d6409d2d6,"selftests/bpf: Add post_socket_cb for network_helper_opts

__start_server() sets SO_REUSPORT through setsockopt() when the parameter
'reuseport' is set. This patch makes it more flexible by adding a function
pointer post_socket_cb into struct network_helper_opts. The
'const struct post_socket_opts *cb_opts' args in the post_socket_cb is
for the future extension.

The 'reuseport' parameter can be dropped.
Now the original start_reuseport_server() can be implemented by setting a
newly defined reuseport_cb() function pointer to post_socket_cb filed of
struct network_helper_opts.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/470cb82f209f055fc7fb39c66c6b090b5b7ed2b2.1714907662.git.tanggeliang@kylinos.cn
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Introduced post_socket_cb function pointer to enhance flexibility in network_helper_opts for setting SO_REUSEPORT.,"post_socket_cb,function pointer,network_helper_opts",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
cbe35adf691a3227b11131a922245c4d6409d2d6,cbe35adf691a3227b11131a922245c4d6409d2d6,Alexei Starovoitov,ast@kernel.org,1715278392,Alexei Starovoitov,ast@kernel.org,1715278393,a1edbcb9da11f2300df7fd76ea17fb65c6bf9c03,009367099eb61a4fc2af44d4eb06b6b4de7de6db 6a650816b098a15c4690a22e3889858264d01aa8,"Merge branch 'selftests-bpf-retire-bpf_tcp_helpers-h'

Martin KaFai Lau says:

====================
selftests/bpf: Retire bpf_tcp_helpers.h

From: Martin KaFai Lau <martin.lau@kernel.org>

The earlier commit 8e6d9ae2e09f (""selftests/bpf: Use bpf_tracing.h instead of bpf_tcp_helpers.h"")
removed the bpf_tcp_helpers.h usages from the non networking tests.

This patch set is a continuation of this effort to retire
the bpf_tcp_helpers.h from the networking tests (mostly tcp-cc related).

The main usage of the bpf_tcp_helpers.h is the partial kernel
socket definitions (e.g. sock"," tcp_sock). New fields are kept adding
back to those partial socket definitions while everything is available
in the vmlinux.h. The recent bpf_cc_cubic.c test tried to extend
bpf_tcp_helpers.c but eventually used the vmlinux.h instead. To avoid
this unnecessary detour for new tests and have one consistent way
of using the kernel sockets","[' this patch set retires the bpf_tcp_helpers.h\nusages and consolidates the tests to use vmlinux.h instead.\n====================\n\nLink: https://lore.kernel.org/r/20240509175026.3423614-1-martin.lau@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit retires the bpf_tcp_helpers.h from networking tests for consistent kernel socket usage via vmlinux.h.,"retire, bpf_tcp_helpers, vmlinux",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tc/netfilter like programs']
6a650816b098a15c4690a22e3889858264d01aa8,6a650816b098a15c4690a22e3889858264d01aa8,Martin KaFai Lau,martin.lau@kernel.org,1715277026,Alexei Starovoitov,ast@kernel.org,1715278392,a1edbcb9da11f2300df7fd76ea17fb65c6bf9c03,c075c9c4af289bb5956b0164283a85cf9c293c8e,"selftests/bpf: Retire bpf_tcp_helpers.h

The previous patches have consolidated the tests to use
bpf_tracing_net.h (i.e. vmlinux.h) instead of bpf_tcp_helpers.h.

This patch can finally retire the bpf_tcp_helpers.h from
the repository.

Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
Link: https://lore.kernel.org/r/20240509175026.3423614-11-martin.lau@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit retires bpf_tcp_helpers.h in favor of using bpf_tracing_net.h for selftests.,"retire,bpf_tcp_helpers.h,bpf_tracing_net.h",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tracepoints like programs']
c075c9c4af289bb5956b0164283a85cf9c293c8e,c075c9c4af289bb5956b0164283a85cf9c293c8e,Martin KaFai Lau,martin.lau@kernel.org,1715277025,Alexei Starovoitov,ast@kernel.org,1715278392,fc524d6ac07d95e055de20e54877ae6e2a3c4f96,6eee55aa769c241182da73a391980f51edba27dc,"selftests/bpf: Remove the bpf_tcp_helpers.h usages from other non tcp-cc tests

The patch removes the remaining bpf_tcp_helpers.h usages in the
non tcp-cc networking tests. It either replaces it with bpf_tracing_net.h
or just removed it because the test is not actually using any
kernel sockets. For the later"," the missing macro (mainly SOL_TCP) is
defined locally.

An exception is the test_sock_fields which is testing
the ""struct bpf_sock"" type instead of the kernel sock type.
Whenever ""vmlinux.h"" is used instead","[' it hits a verifier\nerror on doing arithmetic on the sock_common pointer:\n\n; return !a6[0] && !a6[1] && !a6[2] && a6[3] == bpf_htonl(1); @ test_sock_fields.c:54\n21: (61) r2 = *(u32 *)(r1 +28)        ; R1_w=sock_common() R2_w=scalar(smin=0', 'smax=umax=0xffffffff', 'var_off=(0x0; 0xffffffff))\n22: (56) if w2 != 0x0 goto pc-6       ; R2_w=0\n23: (b7) r3 = 28                      ; R3_w=28\n24: (bf) r2 = r1                      ; R1_w=sock_common() R2_w=sock_common()\n25: (0f) r2 += r3\nR2 pointer arithmetic on sock_common prohibited\n\nHence', ' instead of including bpf_tracing_net.h', ' the test_sock_fields test\ndefines a tcp_sock with one lsndtime field in it.\n\nAnother highlight is', ' in sockopt_qos_to_cc.c', ' the tcp_cc_eq()\nis replaced by bpf_strncmp(). tcp_cc_eq() was a workaround\nin bpf_tcp_helpers.h before bpf_strncmp had been added.\n\nThe SOL_IPV6 addition to bpf_tracing_net.h is needed by the\ntest_tcpbpf_kern test.\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nLink: https://lore.kernel.org/r/20240509175026.3423614-10-martin.lau@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit removes inappropriate bpf_tcp_helpers.h references from non tcp-cc networking tests and updates test_sock_fields to use vmlinux.h.,"bpf_tcp_helpers,non tcp-cc,vmlinux",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6eee55aa769c241182da73a391980f51edba27dc,6eee55aa769c241182da73a391980f51edba27dc,Martin KaFai Lau,martin.lau@kernel.org,1715277024,Alexei Starovoitov,ast@kernel.org,1715278392,80f567d24605f88f9035b337bb6f713b5bfbb1c9,6ad4e6e94697e960630594907666bc09e78a3b8a,"selftests/bpf: Remove bpf_tcp_helpers.h usages from other misc bpf tcp-cc tests

This patch removed the final few bpf_tcp_helpers.h usages
in some misc bpf tcp-cc tests and replace it with
bpf_tracing_net.h (i.e. vmlinux.h)

Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
Link: https://lore.kernel.org/r/20240509175026.3423614-9-martin.lau@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit removes usages of bpf_tcp_helpers.h in BPF tcp-cc tests and replaces it with bpf_tracing_net.h.,"bpf_tcp_helpers.h,tcp-cc,bpf_tracing_net.h",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tracepoints like programs']
6ad4e6e94697e960630594907666bc09e78a3b8a,6ad4e6e94697e960630594907666bc09e78a3b8a,Martin KaFai Lau,martin.lau@kernel.org,1715277023,Alexei Starovoitov,ast@kernel.org,1715278392,fd907e0e3e4a3bcef07fe49307fbe1885ec57535,a824c9a8a4d9a654d62674a8425c0f1abc9c3d33,"selftests/bpf: Use bpf_tracing_net.h in bpf_dctcp

This patch uses bpf_tracing_net.h (i.e. vmlinux.h) in bpf_dctcp.
This will allow to retire the bpf_tcp_helpers.h and consolidate
tcp-cc tests to vmlinux.h.

It will have a dup on min/max macros with the bpf_cubic. It could
be further refactored in the future.

Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
Link: https://lore.kernel.org/r/20240509175026.3423614-8-martin.lau@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,"The commit updates bpf_dctcp to use bpf_tracing_net.h, allowing tcp-cc tests consolidation into vmlinux.h.","bpf_dctcp,bpf_tracing_net,consolidation",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tracepoints like programs']
a824c9a8a4d9a654d62674a8425c0f1abc9c3d33,a824c9a8a4d9a654d62674a8425c0f1abc9c3d33,Martin KaFai Lau,martin.lau@kernel.org,1715277022,Alexei Starovoitov,ast@kernel.org,1715278392,849109c0f9b65ebe1eaa9b52ba5c644ee82a6787,b1d87ae9b0d3d91767d85183e40c96f4229a6c21,"selftests/bpf: Use bpf_tracing_net.h in bpf_cubic

This patch uses bpf_tracing_net.h (i.e. vmlinux.h) in bpf_cubic.
This will allow to retire the bpf_tcp_helpers.h and consolidate
tcp-cc tests to vmlinux.h.

Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
Link: https://lore.kernel.org/r/20240509175026.3423614-7-martin.lau@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit updates selftests to use bpf_tracing_net.h in bpf_cubic and retires bpf_tcp_helpers.h.,"bpf_tracing_net,vmlinux,tests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['tc/netfilter like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b1d87ae9b0d3d91767d85183e40c96f4229a6c21,b1d87ae9b0d3d91767d85183e40c96f4229a6c21,Martin KaFai Lau,martin.lau@kernel.org,1715277021,Alexei Starovoitov,ast@kernel.org,1715278392,4bc3ec298d3b0752201e926d57e4e430fab50e09,7d3851a31832bf8dc776a78494b788518734ad0f,"selftests/bpf: Rename tcp-cc private struct in bpf_cubic and bpf_dctcp

The ""struct bictcp"" and ""struct dctcp"" are private to the bpf prog
and they are stored in the private buffer in inet_csk(sk)->icsk_ca_priv.
Hence"," there is no bpf CO-RE required.

The same struct name exists in the vmlinux.h. To reuse vmlinux.h","['\nthey need to be renamed such that the bpf prog logic will be\nimmuned from the kernel tcp-cc changes.\n\nThis patch adds a ""bpf_"" prefix to them.\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nLink: https://lore.kernel.org/r/20240509175026.3423614-6-martin.lau@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Rename private structs in bpf_cubic and bpf_dctcp to avoid name conflict with vmlinux.h.,"private structs, bpf_cubic, bpf_dctcp",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tc/netfilter like programs']
7d3851a31832bf8dc776a78494b788518734ad0f,7d3851a31832bf8dc776a78494b788518734ad0f,Martin KaFai Lau,martin.lau@kernel.org,1715277020,Alexei Starovoitov,ast@kernel.org,1715278391,b76899f62b243ae92c557b88d1e193b7de5dbd27,cc5b18ce1714160be3e0e3b9440a6306dc87e5c4,"selftests/bpf: Sanitize the SEC and inline usages in the bpf-tcp-cc tests

It is needed to remove the BPF_STRUCT_OPS usages from the tcp-cc tests
because it is defined in bpf_tcp_helpers.h which is going to be retired.
While at it"," this patch consolidates all tcp-cc struct_ops programs to
use the SEC(""struct_ops"") + BPF_PROG().

It also removes the unnecessary __always_inline usages from the
tcp-cc tests.

Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
Link: https://lore.kernel.org/r/20240509175026.3423614-5-martin.lau@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Refactor bpf-tcp-cc tests by removing BPF_STRUCT_OPS and unnecessary __always_inline usages for alignment with upcoming changes.,"bpf-tcp-cc,BPF_STRUCT_OPS,sanitize",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tc/netfilter like programs']
cc5b18ce1714160be3e0e3b9440a6306dc87e5c4,cc5b18ce1714160be3e0e3b9440a6306dc87e5c4,Martin KaFai Lau,martin.lau@kernel.org,1715277019,Alexei Starovoitov,ast@kernel.org,1715278391,8e2a74eea0b9dbcc527298c05cb7d124dae9dafa,cbaec46df6c08a2fab6be03d093d3d6ce74adc9a,"selftests/bpf: Reuse the tcp_sk() from the bpf_tracing_net.h

This patch removes the individual tcp_sk implementations from the
tcp-cc tests. The tcp_sk() implementation from the bpf_tracing_net.h
is reused instead.

Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
Link: https://lore.kernel.org/r/20240509175026.3423614-4-martin.lau@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Refactor selftests by reusing the tcp_sk() from bpf_tracing_net.h in tcp-cc tests.,"selftests,tcp_sk,bpf_tracing_net",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tracepoints like programs']
cbaec46df6c08a2fab6be03d093d3d6ce74adc9a,cbaec46df6c08a2fab6be03d093d3d6ce74adc9a,Martin KaFai Lau,martin.lau@kernel.org,1715277018,Alexei Starovoitov,ast@kernel.org,1715278391,c99c5157cb79050ec7f9326c8283d03edd32acd2,c0338e609e6e8aff8a7052c90cff83a6bc792ebc,"selftests/bpf: Add a few tcp helper functions and macros to bpf_tracing_net.h

This patch adds a few tcp related helper functions to bpf_tracing_net.h.
They will be useful for both tcp-cc and network tracing related
bpf progs. They have already been in the bpf_tcp_helpers.h. This change
is needed to retire the bpf_tcp_helpers.h and consolidate all tests
to vmlinux.h (i.e. bpf_tracing_net.h).

Some of the helpers (tcp_sk and inet_csk) are also defined in
bpf_cc_cubic.c and they are removed. While at it"," remove
the vmlinux.h from bpf_cc_cubic.c. bpf_tracing_net.h (which has
vmlinux.h after this patch) is enough and will be consistent
with the other tcp-cc tests in the later patches.

The other TCP_* macro additions will be needed for the bpf_dctcp
changes in the later patch.

Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
Link: https://lore.kernel.org/r/20240509175026.3423614-3-martin.lau@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The commit adds TCP helper functions to bpf_tracing_net.h for tcp-cc and network tracing eBPF programs.,"tcp helper functions,tracing,consolidation",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['tracepoints like programs', 'kprobe/uprobe/ftrace like programs', 'tc/netfilter like programs']"
c0338e609e6e8aff8a7052c90cff83a6bc792ebc,c0338e609e6e8aff8a7052c90cff83a6bc792ebc,Martin KaFai Lau,martin.lau@kernel.org,1715277017,Alexei Starovoitov,ast@kernel.org,1715278391,cc617e77d1df9e0cced592a750948baec8462ad2,009367099eb61a4fc2af44d4eb06b6b4de7de6db,"selftests/bpf: Remove bpf_tracing_net.h usages from two networking tests

This patch removes the bpf_tracing_net.h usage from the networking tests","
fib_lookup and test_lwt_redirect. Instead of using the (copied) macro
TC_ACT_SHOT and ETH_HLEN from bpf_tracing_net.h","[' they can directly\nuse the ones defined in the network header files under linux/.\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nLink: https://lore.kernel.org/r/20240509175026.3423614-2-martin.lau@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit removes the usage of bpf_tracing_net.h in two networking tests.,"bpf_tracing_net, networking, tests",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tc/netfilter like programs']
009367099eb61a4fc2af44d4eb06b6b4de7de6db,009367099eb61a4fc2af44d4eb06b6b4de7de6db,Jose E. Marchesi,jose.marchesi@oracle.com,1715163193,Andrii Nakryiko,andrii@kernel.org,1715205655,fe2af65273e1e7981a195649bf2770c2cac00298,911edc69c832161b62a8ad10a6972290157a7bd3,"bpf: Avoid uninitialized value in BPF_CORE_READ_BITFIELD

[Changes from V1:
 - Use a default branch in the switch statement to initialize `val'.]

GCC warns that `val' may be used uninitialized in the
BPF_CRE_READ_BITFIELD macro"," defined in bpf_core_read.h as:

	[...]
	unsigned long long val;						      \
	[...]								      \
	switch (__CORE_RELO(s","[' field', "" BYTE_SIZE)) {\t\t\t      \\\n\tcase 1: val = *(const unsigned char *)p; break;\t\t\t      \\\n\tcase 2: val = *(const unsigned short *)p; break;\t\t      \\\n\tcase 4: val = *(const unsigned int *)p; break;\t\t\t      \\\n\tcase 8: val = *(const unsigned long long *)p; break;\t\t      \\\n        }       \t\t\t\t\t\t\t      \\\n\t[...]\n\tval;\t\t\t\t\t\t\t\t      \\\n\t}\t\t\t\t\t\t\t\t      \\\n\nThis patch adds a default entry in the switch statement that sets\n`val' to zero in order to avoid the warning"", ' and random values to be\nused in case __builtin_preserve_field_info returns unexpected values\nfor BPF_FIELD_BYTE_SIZE.\n\nTested in bpf-next master.\nNo regressions.\n\nSigned-off-by: Jose E. Marchesi <jose.marchesi@oracle.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240508101313.16662-1-jose.marchesi@oracle.com\n', '']",Fixed potential uninitialized value warning in BPF_CORE_READ_BITFIELD macro.,"uninitialized,value,macro",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
911edc69c832161b62a8ad10a6972290157a7bd3,911edc69c832161b62a8ad10a6972290157a7bd3,Jose E. Marchesi,jose.marchesi@oracle.com,1715166212,Alexei Starovoitov,ast@kernel.org,1715187419,6cb2526411487c32f0356fe940e1d96e1ab69187,1209a523f6914404e8941d9e04caa42be7cab8d5,"bpf: guard BPF_NO_PRESERVE_ACCESS_INDEX in skb_pkt_end.c

This little patch is a follow-up to:
https://lore.kernel.org/bpf/20240507095011.15867-1-jose.marchesi@oracle.com/T/#u

The temporary workaround of passing -DBPF_NO_PRESERVE_ACCESS_INDEX
when building with GCC triggers a redefinition preprocessor error when
building progs/skb_pkt_end.c.  This patch adds a guard to avoid
redefinition.

Signed-off-by: Jose E. Marchesi <jose.marchesi@oracle.com>
Cc: david.faust@oracle.com
Cc: cupertino.miranda@oracle.com
Cc: Eduard Zingerman <eddyz87@gmail.com>
Cc: Yonghong Song <yonghong.song@linux.dev>
Cc: Andrii Nakryiko <andrii.nakryiko@gmail.com>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20240508110332.17332-1-jose.marchesi@oracle.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,This patch adds a guard to prevent preprocessor errors when building with BPF_NO_PRESERVE_ACCESS_INDEX.,"guard, preprocessor, GCC",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1209a523f6914404e8941d9e04caa42be7cab8d5,1209a523f6914404e8941d9e04caa42be7cab8d5,Jose E. Marchesi,jose.marchesi@oracle.com,1715164551,Alexei Starovoitov,ast@kernel.org,1715187390,c69b8da8a03710c98bf85ec6f9da01f214373ba0,cd3fc3b9782130a5bc1dc3dfccffbc1657637a93,"bpf: avoid UB in usages of the __imm_insn macro

[Changes from V2:
 - no-strict-aliasing is only applied when building with GCC.
 - cpumask_failure.c is excluded"," as it doesn't use __imm_insn.]

The __imm_insn macro is defined in bpf_misc.h as:

  #define __imm_insn(name","[' expr) [name]""i""(*(long *)&(expr))\n\nThis may lead to type-punning and strict aliasing rules violations in\nit\'s typical usage where the address of a struct bpf_insn is passed as\nexpr', ' like in:\n\n  __imm_insn(st_mem', '\n             BPF_ST_MEM(BPF_W', ' BPF_REG_1', ' offsetof(struct __sk_buff', ' mark)', ' 42))\n\nWhere:\n\n  #define BPF_ST_MEM(SIZE', ' DST', ' OFF', ' IMM)\t\t\t\t\\\n\t((struct bpf_insn) {\t\t\t\t\t\\\n\t\t.code  = BPF_ST | BPF_SIZE(SIZE) | BPF_MEM', '\t\\\n\t\t.dst_reg = DST', '\t\t\t\t\t\\\n\t\t.src_reg = 0', '\t\t\t\t\t\\\n\t\t.off   = OFF', '\t\t\t\t\t\\\n\t\t.imm   = IMM })\n\nIn all the actual instances of this in the BPF selftests the value is\nfed to a volatile asm statement as soon as it gets read from memory', '\nand thus it is unlikely anti-aliasing rules breakage may lead to\nmisguided optimizations.\n\nHowever', ' GCC detects the potential problem (indirectly) by issuing a\nwarning stating that a temporary <Uxxxxxx> is used uninitialized', '\nwhere the temporary corresponds to the memory read by *(long *).\n\nThis patch adds -fno-strict-aliasing to the compilation flags of the\nparticular selftests that do type punning via __imm_insn', ' only for\nGCC.\n\nTested in master bpf-next.\nNo regressions.\n\nSigned-off-by: Jose E. Marchesi <jose.marchesi@oracle.com>\nCc: david.faust@oracle.com\nCc: cupertino.miranda@oracle.com\nCc: Yonghong Song <yonghong.song@linux.dev>\nCc: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240508103551.14955-1-jose.marchesi@oracle.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit addresses undefined behavior in the usage of the __imm_insn macro for BPF programs.,"undefined behavior, macro, GCC",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['kprobe/uprobe/ftrace like programs']
cd3fc3b9782130a5bc1dc3dfccffbc1657637a93,cd3fc3b9782130a5bc1dc3dfccffbc1657637a93,Jose E. Marchesi,jose.marchesi@oracle.com,1715107676,Alexei Starovoitov,ast@kernel.org,1715187327,cf872dd7603e1ac693cd05426198ccaa6fc13ffd,e612b5c1d3ee325aff991b4078b4999bf6bac096,"bpf: avoid uninitialized warnings in verifier_global_subprogs.c

[Changes from V1:
- The warning to disable is -Wmaybe-uninitialized"," not -Wuninitialized.
- This warning is only supported in GCC.]

The BPF selftest verifier_global_subprogs.c contains code that
purposedly performs out of bounds access to memory","[' to check whether\nthe kernel verifier is able to catch them.  For example:\n\n  __noinline int global_unsupp(const int *mem)\n  {\n\tif (!mem)\n\t\treturn 0;\n\treturn mem[100]; /* BOOM */\n  }\n\nWith -O1 and higher and no inlining', ' GCC notices this fact and emits a\n""maybe uninitialized"" warning.  This is by design.  Note that the\nemission of these warnings is highly dependent on the precise\noptimizations that are performed.\n\nThis patch adds a compiler pragma to verifier_global_subprogs.c to\nignore these warnings.\n\nTested in bpf-next master.\nNo regressions.\n\nSigned-off-by: Jose E. Marchesi <jose.marchesi@oracle.com>\nCc: david.faust@oracle.com\nCc: cupertino.miranda@oracle.com\nCc: Yonghong Song <yonghong.song@linux.dev>\nCc: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240507184756.1772-1-jose.marchesi@oracle.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit addresses uninitialized warnings in the BPF verifier by disabling specific GCC warnings in verifier_global_subprogs.c.,"uninitialized,warnings,BPF",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e612b5c1d3ee325aff991b4078b4999bf6bac096,e612b5c1d3ee325aff991b4078b4999bf6bac096,Puranjay Mohan,puranjay@kernel.org,1714147876,Alexei Starovoitov,ast@kernel.org,1715179145,15ff3a2c8447fd6d735287ca9537d65d92656b9a,7e2c7a3f732b77623cea01b89b8cc6724c90a439,bpf," arm64: Add support for lse atomics in bpf_arena

When LSE atomics are available","[' BPF atomic instructions are implemented\nas single ARM64 atomic instructions', ' therefore it is easy to enable\nthese in bpf_arena using the currently available exception handling\nsetup.\n\nLL_SC atomics use loops and therefore would need more work to enable in\nbpf_arena.\n\nEnable LSE atomics based instructions in bpf_arena and use the\nbpf_jit_supports_insn() callback to reject atomics in bpf_arena if LSE\natomics are not available.\n\nAll atomics and arena_atomics selftests are passing:\n\n  [root@ip-172-31-2-216 bpf]# ./test_progs -a atomics', 'arena_atomics\n  #3/1     arena_atomics/add:OK\n  #3/2     arena_atomics/sub:OK\n  #3/3     arena_atomics/and:OK\n  #3/4     arena_atomics/or:OK\n  #3/5     arena_atomics/xor:OK\n  #3/6     arena_atomics/cmpxchg:OK\n  #3/7     arena_atomics/xchg:OK\n  #3       arena_atomics:OK\n  #10/1    atomics/add:OK\n  #10/2    atomics/sub:OK\n  #10/3    atomics/and:OK\n  #10/4    atomics/or:OK\n  #10/5    atomics/xor:OK\n  #10/6    atomics/cmpxchg:OK\n  #10/7    atomics/xchg:OK\n  #10      atomics:OK\n  Summary: 2/14 PASSED', ' 0 SKIPPED', ' 0 FAILED\n\nSigned-off-by: Puranjay Mohan <puranjay@kernel.org>\nLink: https://lore.kernel.org/r/20240426161116.441-1-puranjay@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add support for LSE atomics in bpf_arena on arm64 architecture.,"LSE atomics, bpf_arena, arm64",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7e2c7a3f732b77623cea01b89b8cc6724c90a439,7e2c7a3f732b77623cea01b89b8cc6724c90a439,Martin KaFai Lau,martin.lau@kernel.org,1715124120,Martin KaFai Lau,martin.lau@kernel.org,1715124313,587a047f502580fa81c3b74a17204016c926097a,93d1c2da15017a443cad812468450b72f43e3bd8 7b9959b8cdbc40b31b4c66bb900ec8d5e5b305bd,"Merge branch 'libbpf: further struct_ops fixes and improvements'

Andrii Nakryiko says:

====================
Fix yet another case of mishandling SEC(""struct_ops"") programs that were
nulled out programmatically through BPF skeleton by the user.

While at it", add some improvements around detecting and reporting errors,"['\nspecifically a common case of declaring SEC(""struct_ops"") program', ' but\nforgetting to actually make use of it by setting it as a callback\nimplementation in SEC("".struct_ops"") variable (i.e.', ' map) declaration.\n\nA bunch of new selftests are added as well.\n====================\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']","This commit addresses mishandling of SEC(""struct_ops"") programs and adds improvements for detecting and reporting errors in libbpf.","struct_ops, errors, improvements",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['LSM like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7b9959b8cdbc40b31b4c66bb900ec8d5e5b305bd,7b9959b8cdbc40b31b4c66bb900ec8d5e5b305bd,Andrii Nakryiko,andrii@kernel.org,1715040815,Martin KaFai Lau,martin.lau@kernel.org,1715124119,587a047f502580fa81c3b74a17204016c926097a,41df0733ea414a49094258adab4d600db0420731,"selftests/bpf: shorten subtest names for struct_ops_module test

Drive-by clean up"," we shouldn't use meaningless ""test_"" prefix for
subtest names.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240507001335.1445325-8-andrii@kernel.org
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],The commit shortens subtest names for struct_ops_module in selftests to avoid meaningless prefixes.,"shorten,selftests,cleanup",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
41df0733ea414a49094258adab4d600db0420731,41df0733ea414a49094258adab4d600db0420731,Andrii Nakryiko,andrii@kernel.org,1715040814,Martin KaFai Lau,martin.lau@kernel.org,1715124119,aeec94caec6a45199bcc6668e4b00da233894564,c78420bafe7cf9ce14fa7ceb40ce62e1372e661d,"selftests/bpf: validate struct_ops early failure detection logic

Add a simple test that validates that libbpf will reject isolated
struct_ops program early with helpful warning message.

Also validate that explicit use of such BPF program through BPF skeleton
after BPF object is open won't trigger any warnings.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240507001335.1445325-7-andrii@kernel.org
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Add a test for early failure detection in struct_ops programs using BPF skeleton.,"selftests,bpf,struct_ops",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c78420bafe7cf9ce14fa7ceb40ce62e1372e661d,c78420bafe7cf9ce14fa7ceb40ce62e1372e661d,Andrii Nakryiko,andrii@kernel.org,1715040813,Martin KaFai Lau,martin.lau@kernel.org,1715124119,5dee2aad44a0fc9a6254ff09125cf5aa4c8a1b39,548c2ede0dc81cb8c86f3a72c1c63fe1c179cbfe,"libbpf: improve early detection of doomed-to-fail BPF program loading

Extend libbpf's pre-load checks for BPF programs"," detecting more typical
conditions that are destinated to cause BPF program failure. This is an
opportunity to provide more helpful and actionable error message to
users","[' instead of potentially very confusing BPF verifier log and/or\nerror.\n\nIn this case', ' we detect struct_ops BPF program that was not referenced\nanywhere', ' but still attempted to be loaded (according to libbpf logic).\nSuggest that the program might need to be used in some struct_ops\nvariable. User will get a message of the following kind:\n\n  libbpf: prog \'test_1_forgotten\': SEC(""struct_ops"") program isn\'t referenced anywhere', ' did you forget to use it?\n\nSuggested-by: Tejun Heo <tj@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240507001335.1445325-6-andrii@kernel.org\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",This commit enhances libbpf to provide better early detection and error messages for programs that are likely to fail during loading.,"libbpf, detection, error",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
548c2ede0dc81cb8c86f3a72c1c63fe1c179cbfe,548c2ede0dc81cb8c86f3a72c1c63fe1c179cbfe,Andrii Nakryiko,andrii@kernel.org,1715040812,Martin KaFai Lau,martin.lau@kernel.org,1715124119,7b7d7cdb28f3dd005ebaeb22fc423a70a25edfb0,9d66d60e968d85742569d025a2fb509cb57333bb,"libbpf: fix libbpf_strerror_r() handling unknown errors

strerror_r()"," used from libbpf-specific libbpf_strerror_r() wrapper is
documented to return error in two different ways","["" depending on glibc\nversion. Take that into account when handling strerror_r()'s own errors"", '\nwhich happens when we pass some non-standard (internal) kernel error to\nit. Before this patch we\'d have ""ERROR: strerror_r(524)=22""', ' which is\nquite confusing. Now for the same situation we\'ll see a bit less\nvisually scary ""unknown error (-524)"".\n\nAt least we won\'t confuse user with irrelevant EINVAL (22).\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240507001335.1445325-5-andrii@kernel.org\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Fix incorrect handling of unknown errors in libbpf's strerror_r wrapper function.,"libbpf, strerror_r, errors",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9d66d60e968d85742569d025a2fb509cb57333bb,9d66d60e968d85742569d025a2fb509cb57333bb,Andrii Nakryiko,andrii@kernel.org,1715040811,Martin KaFai Lau,martin.lau@kernel.org,1715124119,0056133a1840fba0679ecead0f07574264f7a33f,e18e2e70dbd1ee3099049557060067b6ec703efa,"selftests/bpf: add another struct_ops callback use case test

Add a test which tests the case that was just fixed. Kernel has full
type information about callback"," but user explicitly nulls out the
reference to declaratively set BPF program reference.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240507001335.1445325-4-andrii@kernel.org
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Add a selftest for struct_ops callback handling in eBPF.,"selftests, struct_ops, callback",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e18e2e70dbd1ee3099049557060067b6ec703efa,e18e2e70dbd1ee3099049557060067b6ec703efa,Andrii Nakryiko,andrii@kernel.org,1715040810,Martin KaFai Lau,martin.lau@kernel.org,1715124119,c3b020b972eac6993a7c63617a50bd141c5e13a0,8374b56b1df5566d19d645e49da2bf31b660bcfd,"libbpf: handle yet another corner case of nulling out struct_ops program

There is yet another corner case where user can set STRUCT_OPS program
reference in STRUCT_OPS map to NULL"," but libbpf will fail to disable
autoload for such BPF program. This time it's the case of ""new"" kernel
which has type information about callback field","[' but user explicitly\nnulled-out program reference from user-space after opening BPF object.\n\nFix', ' hopefully', ' the last remaining unhandled case.\n\nFixes: 0737df6de946 (""libbpf: better fix for handling nulled-out struct_ops program"")\nFixes: f973fccd43d3 (""libbpf: handle nulled-out program in struct_ops correctly"")\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240507001335.1445325-3-andrii@kernel.org\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",The commit addresses a corner case in libbpf for handling null STRUCT_OPS program references in STRUCT_OPS maps on newer kernels.,"libbpf, STRUCT_OPS, null",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8374b56b1df5566d19d645e49da2bf31b660bcfd,8374b56b1df5566d19d645e49da2bf31b660bcfd,Andrii Nakryiko,andrii@kernel.org,1715040809,Martin KaFai Lau,martin.lau@kernel.org,1715124119,a2ee3b0a2aa6b786ab10b3836c1f7bcaf09f6739,93d1c2da15017a443cad812468450b72f43e3bd8,"libbpf: remove unnecessary struct_ops prog validity check

libbpf ensures that BPF program references set in map->st_ops->progs[i]
during open phase are always valid STRUCT_OPS programs. This is done in
bpf_object__collect_st_ops_relos(). So there is no need to double-check
that in bpf_map__init_kern_struct_ops().

Simplify the code by removing unnecessary check. Also"," we avoid using
local prog variable to keep code similar to the upcoming fix","[' which adds\nsimilar logic in another part of bpf_map__init_kern_struct_ops().\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240507001335.1445325-2-andrii@kernel.org\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']","The commit removes an unnecessary struct_ops prog validity check in libbpf, simplifying the code.","libbpf, struct_ops, simplify",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
93d1c2da15017a443cad812468450b72f43e3bd8,93d1c2da15017a443cad812468450b72f43e3bd8,Andrii Nakryiko,andrii@kernel.org,1715118060,Andrii Nakryiko,andrii@kernel.org,1715118061,e18c2e0d23aac8b9637d55b8ddf01a1ca28d950e,675b4e24bc50f4600b6bf3527fdbaa1f73498334 b2e086cb28aa358f7b5564888304908aff735827,"Merge branch 'fix-number-of-arguments-in-test'

Cupertino Miranda says:

====================
Fix number of arguments in test

Hi everyone","

This is a new version based on comments.

Regards","['\nCupertino\n\nChanges from v1:\n - Comment with gcc-bpf replaced by bpf_gcc.\n - Used pragma GCC optimize to disable GCC optimization in test.\n\nCc: Alexei Starovoitov <alexei.starovoitov@gmail.com>\nCc: Andrii Nakryiko <andrii.nakryiko@gmail.com>\nCc: Eduard Zingerman <eddyz87@gmail.com>\nCc: Yonghong Song <yonghong.song@linux.dev>\nCc: David Faust <david.faust@oracle.com>\nCc: Jose Marchesi <jose.marchesi@oracle.com>\nCc: Elena Zannoni <elena.zannoni@oracle.com>\n====================\n\nLink: https://lore.kernel.org/r/20240507122220.207820-1-cupertino.miranda@oracle.com\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n', '']",The commit fixes the number of arguments in a test case.,"fix, test, arguments",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
b2e086cb28aa358f7b5564888304908aff735827,b2e086cb28aa358f7b5564888304908aff735827,Cupertino Miranda,cupertino.miranda@oracle.com,1715084540,Andrii Nakryiko,andrii@kernel.org,1715118060,e18c2e0d23aac8b9637d55b8ddf01a1ca28d950e,207cf6e649ee551ab3bdb1cfe1b2848e6a4337a5,"selftests/bpf: Change functions definitions to support GCC

The test_xdp_noinline.c contains 2 functions that use more then 5
arguments. This patch collapses the 2 last arguments in an array.
Also in GCC and ipa_sra optimization increases the number of arguments
used in function encap_v4. This pass disables the optimization for that
particular file.

Signed-off-by: Cupertino Miranda <cupertino.miranda@oracle.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/bpf/20240507122220.207820-3-cupertino.miranda@oracle.com
",,Modify self-tests to ensure compatibility with GCC by adjusting function arguments.,"self-tests,GCC,arguments",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['xdp like programs']
207cf6e649ee551ab3bdb1cfe1b2848e6a4337a5,207cf6e649ee551ab3bdb1cfe1b2848e6a4337a5,Cupertino Miranda,cupertino.miranda@oracle.com,1715084539,Andrii Nakryiko,andrii@kernel.org,1715118060,f3082e2ad5d8f4b1fea3389e2d366c448ed43846,675b4e24bc50f4600b6bf3527fdbaa1f73498334,"selftests/bpf: Add CFLAGS per source file and runner

This patch adds support to specify CFLAGS per source file and per test
runner.

Signed-off-by: Cupertino Miranda <cupertino.miranda@oracle.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/bpf/20240507122220.207820-2-cupertino.miranda@oracle.com
",,This commit adds support for specifying CFLAGS per source file and test runner in selftests for BPF.,"CFLAGS,selftests,BPF",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
675b4e24bc50f4600b6bf3527fdbaa1f73498334,675b4e24bc50f4600b6bf3527fdbaa1f73498334,Jose E. Marchesi,jose.marchesi@oracle.com,1715075411,Andrii Nakryiko,andrii@kernel.org,1715118000,2cd0591f6a6783e93dcbc6be1ac408a6e4f8d57f,eda80aacd00c016d7c03a2bfe231fafdce0e16b0,"bpf: Temporarily define BPF_NO_PRESEVE_ACCESS_INDEX for GCC

The vmlinux.h file generated by bpftool makes use of compiler pragmas
in order to install the CO-RE preserve_access_index in all the struct
types derived from the BTF info:

  #ifndef __VMLINUX_H__
  #define __VMLINUX_H__

  #ifndef BPF_NO_PRESERVE_ACCESS_INDEX
  #pragma clang attribute push (__attribute__((preserve_access_index))"," apply_t = record
  #endif

  [... type definitions generated from kernel BTF ... ]

  #ifndef BPF_NO_PRESERVE_ACCESS_INDEX
  #pragma clang attribute pop
  #endif

The `clang attribute push/pop' pragmas are specific to clang/llvm and
are not supported by GCC.

At the moment the BTF dumping services in libbpf do not support
dicriminating between types dumped because they are directly referred
and types dumped because they are dependencies.  A suitable API is
being worked now. See [1] and [2].

In the interim","[' this patch changes the selftests/bpf Makefile so it\npasses -DBPF_NO_PRESERVE_ACCESS_INDEX to GCC when it builds the\nselftests.  This workaround is temporary', ' and may have an impact on\nthe results of the GCC-built tests.\n\n[1] https://lore.kernel.org/bpf/20240503111836.25275-1-jose.marchesi@oracle.com/T/#u\n[2] https://lore.kernel.org/bpf/20240504205510.24785-1-jose.marchesi@oracle.com/T/#u\n\nTested in bpf-next master.\nNo regressions.\n\nSigned-off-by: Jose E. Marchesi <jose.marchesi@oracle.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240507095011.15867-1-jose.marchesi@oracle.com\n', '']",Temporarily define BPF_NO_PRESEVE_ACCESS_INDEX to ensure compatibility with GCC in vmlinux.h file generated by bpftool.,"BPF,GCC,libbpf",It's a build system or CI/CD change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
eda80aacd00c016d7c03a2bfe231fafdce0e16b0,eda80aacd00c016d7c03a2bfe231fafdce0e16b0,Andrii Nakryiko,andrii@kernel.org,1715117480,Andrii Nakryiko,andrii@kernel.org,1715117481,62e0a5e4524fc533da84a074294bff604acd5577,75b0fbf15d8466be618a997cae774eef445c0c7d b0fbdf759da05a35b67fd27b8859738b79af25d6,"Merge branch 'bpf-avoid-attribute-ignored-warnings-in-gcc'

Jose E. Marchesi says:

====================
bpf: avoid `attribute ignored' warnings in GCC

These two patches avoid warnings (turned into errors) when building
the BPF selftests with GCC.

[Changes from V1:
- As requested by reviewer"," an additional patch has been added in
  order to remove __hidden from the `private' macro in
  cpumask_common.h.
- Typo bening -> benign fixed in the commit message of the second
  patch.]
====================

Link: https://lore.kernel.org/r/20240507074227.4523-1-jose.marchesi@oracle.com
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
",[''],Avoid warnings in BPF selftests due to ignored attribute errors in GCC.,"warnings,BPF,GCC",It's a build system or CI/CD change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b0fbdf759da05a35b67fd27b8859738b79af25d6,b0fbdf759da05a35b67fd27b8859738b79af25d6,Jose E. Marchesi,jose.marchesi@oracle.com,1715067747,Andrii Nakryiko,andrii@kernel.org,1715117480,62e0a5e4524fc533da84a074294bff604acd5577,2ce987e1650216638b2b5f44948c6efea67038ae,"bpf: Disable some `attribute ignored' warnings in GCC

This patch modifies selftests/bpf/Makefile to pass -Wno-attributes to
GCC.  This is because of the following attributes which are ignored:

- btf_decl_tag
- btf_type_tag

  There are many of these.  At the moment none of these are
  recognized/handled by gcc-bpf.

  We are aware that btf_decl_tag is necessary for some of the
  selftest harness to communicate test failure/success.  Support for
  it is in progress in GCC upstream:

  https://gcc.gnu.org/pipermail/gcc-patches/2024-May/650482.html

  However", the GCC master branch is not yet open,"[' so the series\n  above (currently under review upstream) wont be able to make it\n  there until 14.1 gets released', ' probably mid next week.\n\n  As for btf_type_tag', ' more extensive work will be needed in GCC\n  upstream to support it in both BTF and DWARF.  We have a WIP big\n  patch for that', ' but that is not needed to compile/build the\n  selftests.\n\n- used\n\n  There are SEC macros defined in the selftests as:\n\n  #define SEC(N) __attribute__((section(N)', ""used))\n\n  The SEC macro is used for both functions and global variables.\n  According to the GCC documentation `used' attribute is really only\n  meaningful for functions"", ' and it warns when the attribute is used\n  for other global objects', ' like for example ctl_array in\n  test_xdp_noinline.c.\n\n  Ignoring this is benign.\n\n- align_value\n\n  In progs/test_cls_redirect.c:127 there is:\n\n  typedef uint8_t *net_ptr __attribute__((align_value(8)));\n\n  GCC warns that it is ignoring this attribute', ' because it is not\n  implemented by GCC.\n\n  I think ignoring this attribute in GCC is benign', "" because according\n  to the clang documentation [1] its purpose seems to be merely\n  declarative and doesn't seem to translate into extra checks at\n  run-time"", ' only to perhaps better optimized code (""runtime behavior\n  is undefined if the pointed memory object is not aligned to the\n  specified alignment"").\n\n  [1] https://clang.llvm.org/docs/AttributeReference.html#align-value\n\nTested in bpf-next master.\n\nSigned-off-by: Jose E. Marchesi <jose.marchesi@oracle.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/bpf/20240507074227.4523-3-jose.marchesi@oracle.com\n', '']",The commit updates the Makefile to disable certain GCC attribute warnings for btf_decl_tag and btf_type_tag.,"GCC, warnings, Makefile",It's a build system or CI/CD change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2ce987e1650216638b2b5f44948c6efea67038ae,2ce987e1650216638b2b5f44948c6efea67038ae,Jose E. Marchesi,jose.marchesi@oracle.com,1715067746,Andrii Nakryiko,andrii@kernel.org,1715117480,bbbf2a0a74ed23ada895ab0b7fdafc3b2a02ec3d,75b0fbf15d8466be618a997cae774eef445c0c7d,"bpf: Avoid __hidden__ attribute in static object

An object defined as `static' defaults to hidden visibility.  If
additionally the visibility(__weak__) compiler attribute is applied to
the declaration of the object"," GCC warns that the attribute gets
ignored.

This patch removes the only instance of this problem among the BPF
selftests.

Tested in bpf-next master.

Signed-off-by: Jose E. Marchesi <jose.marchesi@oracle.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/bpf/20240507074227.4523-2-jose.marchesi@oracle.com
",[''],The commit removes the __hidden__ attribute for static objects in BPF selftests to resolve a compiler warning.,"__hidden__ attribute, static objects, BPF selftests",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
75b0fbf15d8466be618a997cae774eef445c0c7d,75b0fbf15d8466be618a997cae774eef445c0c7d,Haiyue Wang,haiyue.wang@intel.com,1715063619,Alexei Starovoitov,ast@kernel.org,1715116397,ce13ac4a304803e14b9bdd2ebbb9aa4198a12839,329a6720a3ebbc041983b267981ab2cac102de93,"bpf: Remove redundant page mask of vmf->address

As the comment described in ""struct vm_fault"":
	"".address""      : 'Faulting virtual address - masked'
	"".real_address"" : 'Faulting virtual address - unmasked'

The link [1] said: ""Whatever the routes"," all architectures end up to the
invocation of handle_mm_fault() which","[' in turn', ' (likely) ends up calling\n__handle_mm_fault() to carry out the actual work of allocating the page\ntables.""\n\n  __handle_mm_fault() does address assignment:\n\t.address = address & PAGE_MASK', '\n\t.real_address = address', '\n\nThis is debug dump by running `./test_progs -a ""*arena*""`:\n\n[   69.767494] arena fault: vmf->address = 10000001d000', ' vmf->real_address = 10000001d008\n[   69.767496] arena fault: vmf->address = 10000001c000', ' vmf->real_address = 10000001c008\n[   69.767499] arena fault: vmf->address = 10000001b000', ' vmf->real_address = 10000001b008\n[   69.767501] arena fault: vmf->address = 10000001a000', ' vmf->real_address = 10000001a008\n[   69.767504] arena fault: vmf->address = 100000019000', ' vmf->real_address = 100000019008\n[   69.769388] arena fault: vmf->address = 10000001e000', "" vmf->real_address = 10000001e1e8\n\nSo we can use the value of 'vmf->address' to do BPF arena kernel address\nspace cast directly.\n\n[1] https://docs.kernel.org/mm/page_tables.html\n\nSigned-off-by: Haiyue Wang <haiyue.wang@intel.com>\nLink: https://lore.kernel.org/r/20240507063358.8048-1-haiyue.wang@intel.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",The commit removes a redundant page mask of vmf->address in the bpf code.,"redundant,page,mask",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The syscall interface,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
89ea968a9d759f71ac7b8d50949a8e5e5bcb1111,89ea968a9d759f71ac7b8d50949a8e5e5bcb1111,Benjamin Tissoires,bentiss@kernel.org,1715006172,Benjamin Tissoires,bentiss@kernel.org,1715089198,4323a95fbcc36568a41235c3b4b28da5670230d7,b22cbfb42c19a378cca5fae3a98395225af05384,"selftests/hid: skip tests with HID-BPF if udev-hid-bpf is not installed

udev-hid-bpf is still not installed everywhere"," and we should probably
not assume it is installed automatically.

Link: https://lore.kernel.org/r/20240506143612.148031-1-bentiss@kernel.org
Reviewed-by: Peter Hutterer <peter.hutterer@who-t.net>
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Skip HID-BPF self-tests if udev-hid-bpf is not installed.,"self-tests,HID-BPF,udev",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['HID driver like programs']
b22cbfb42c19a378cca5fae3a98395225af05384,b22cbfb42c19a378cca5fae3a98395225af05384,Benjamin Tissoires,bentiss@kernel.org,1712769578,Benjamin Tissoires,bentiss@kernel.org,1715089195,71d8ff440783b6ff25e0afb893f9058af55fb9e9,aa7e560454a90d4fe9924500f1ae2a3779806b85,"selftests/hid: add tests for the Raptor Mach 2 joystick

The only interesting bit is the HAT switch"," and we use a BPF program
to fix it. So ensure this works correctly.

Link: https://lore.kernel.org/r/20240410-bpf_sources-v1-18-a8bf16033ef8@kernel.org
Reviewed-by: Peter Hutterer <peter.hutterer@who-t.net>
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Add selftests for Raptor Mach 2 joystick using BPF program to ensure correct functionality of the HAT switch.,"selftests, joystick, BPF",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['HID driver like programs']
aa7e560454a90d4fe9924500f1ae2a3779806b85,aa7e560454a90d4fe9924500f1ae2a3779806b85,Benjamin Tissoires,bentiss@kernel.org,1712769577,Benjamin Tissoires,bentiss@kernel.org,1715089191,17b7e8bd4bfc0b94302842fba888d6ea07aac6b4,c6b03c736a523902bb53bb9897f5c75292b3424b,"selftests/hid: move the gamepads definitions in the test file

More in line with the other test_* files.

No code change

Link: https://lore.kernel.org/r/20240410-bpf_sources-v1-17-a8bf16033ef8@kernel.org
Reviewed-by: Peter Hutterer <peter.hutterer@who-t.net>
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",,Moved gamepad definitions within selftests/hid to the test file for consistency.,"gamepads,hid,selftests",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['HID driver like programs']
c6b03c736a523902bb53bb9897f5c75292b3424b,c6b03c736a523902bb53bb9897f5c75292b3424b,Benjamin Tissoires,bentiss@kernel.org,1712769576,Benjamin Tissoires,bentiss@kernel.org,1715089187,3501bf56377d7fcf08997b751877e2b5c32d9bce,51de9ee0a6c7f0d06fa7b80ff2ef9f3f661c3eb6,"selftests/hid: import base_gamepad.py from hid-tools

We need to slightly change base_device.py for supporting HID-BPF","
so instead of monkey patching","["" let's just embed it in the kernel tree.\n\nLink: https://lore.kernel.org/r/20240410-bpf_sources-v1-16-a8bf16033ef8@kernel.org\nReviewed-by: Peter Hutterer <peter.hutterer@who-t.net>\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n"", '']",This commit imports base_gamepad.py from hid-tools and modifies base_device.py to support HID-BPF.,"base_gamepad.py,hid-tools,HID-BPF",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['HID driver like programs']
51de9ee0a6c7f0d06fa7b80ff2ef9f3f661c3eb6,51de9ee0a6c7f0d06fa7b80ff2ef9f3f661c3eb6,Benjamin Tissoires,bentiss@kernel.org,1712769575,Benjamin Tissoires,bentiss@kernel.org,1715089183,0586f76bfa1d755dce02a60ffe49a4e39801f3cc,1b2c3caf7839adff892d8397995803d93e347974,"selftests/hid: add Huion Kamvas Pro 19 tests

This tablets gets a lot of things wrong:
- the secondary button is reported through Secondary Tip Switch
- the third button is reported through Invert

We need to add some out of proximity intermediate state when moving
back and forth with the eraser mode as it can only be triggered by
physically returning the pen"," meaning that the tolerated transitions
can never happen.

Link: https://lore.kernel.org/r/20240410-bpf_sources-v1-15-a8bf16033ef8@kernel.org
Reviewed-by: Peter Hutterer <peter.hutterer@who-t.net>
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Add tests for Huion Kamvas Pro 19 in HID selftests to address incorrect button reporting.,"HID selftests, Huion Kamvas, button",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['HID driver like programs']
1b2c3caf7839adff892d8397995803d93e347974,1b2c3caf7839adff892d8397995803d93e347974,Benjamin Tissoires,bentiss@kernel.org,1712769574,Benjamin Tissoires,bentiss@kernel.org,1715089179,0315b020072bf9ac1fd316e1da436e05093cfed7,03899011df4b2bb0f9b3ac57b1044b161a336f31,"selftests/hid: tablets: also check for XP-Pen offset correction

The values are taken from the HID-BPF file.
Basically we are recomputing the array provided there.

Link: https://lore.kernel.org/r/20240410-bpf_sources-v1-14-a8bf16033ef8@kernel.org
Reviewed-by: Peter Hutterer <peter.hutterer@who-t.net>
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",,Added offset correction for XP-Pen in HID selftests for tablets.,"offset correction, XP-Pen, selftests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['HID driver like programs']
03899011df4b2bb0f9b3ac57b1044b161a336f31,03899011df4b2bb0f9b3ac57b1044b161a336f31,Benjamin Tissoires,bentiss@kernel.org,1712769573,Benjamin Tissoires,bentiss@kernel.org,1715089174,9152c64498c1d1a4b6e10121f0280c82dc5c1ef0,e14d88d9b8dae40c6f612c6fc74b7d03d12f3c94,"selftests/hid: tablets: add a couple of XP-PEN tablets

Those tablets don't need special initialization"," but are reporting
the events with the wrong usages:
- tip switch is used when the eraser should be used
- eraser is used instead of the secondary barrel switch

Add tests for those so we don't regress in the future.

Currently we set x/y tilt to 0 to not trigger the bpf program
compensate_coordinates_by_tilt()

Link: https://lore.kernel.org/r/20240410-bpf_sources-v1-13-a8bf16033ef8@kernel.org
Reviewed-by: Peter Hutterer <peter.hutterer@who-t.net>
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Add test cases for XP-PEN tablets in selftests/hid to address event reporting issues.,"XP-PEN, selftests, tablets",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['HID driver like programs']
e14d88d9b8dae40c6f612c6fc74b7d03d12f3c94,e14d88d9b8dae40c6f612c6fc74b7d03d12f3c94,Benjamin Tissoires,bentiss@kernel.org,1712769572,Benjamin Tissoires,bentiss@kernel.org,1715089170,4b1aee3772a51e4c922b1deb3f7176f48472c199,e906463087cec0a179ddcafe08aeef5899af6b00,"selftests/hid: tablets: reduce the number of pen state

All the *_WITH*BUTTON states were almost identical except for the
button itself.

I need to add a new device with a third button"," and adding a bunch of
states is going to be quite cumbersome.

So convert the `button` parameter of PenState as a boolean","[' and store\nwhich button is the target as an argument to all functions that need it.\n\nLink: https://lore.kernel.org/r/20240410-bpf_sources-v1-12-a8bf16033ef8@kernel.org\nReviewed-by: Peter Hutterer <peter.hutterer@who-t.net>\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']",Refactor the pen button state handling in HID selftests by converting button parameter to a boolean for simplicity.,"HID,selftests,refactor",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['HID driver like programs']
e906463087cec0a179ddcafe08aeef5899af6b00,e906463087cec0a179ddcafe08aeef5899af6b00,Benjamin Tissoires,bentiss@kernel.org,1712769571,Benjamin Tissoires,bentiss@kernel.org,1715089166,09ee01e25e496756aaf1d42c4e3c3849355aefa9,a7def2e51c667578140d9aa3282533463ed3df91,"selftests/hid: add support for HID-BPF pre-loading before starting a test

few required changes:
- we need to count how many times a udev 'bind' event happens
- we need to tell `udev-hid-bpf` to not automatically attach the
  provided HID-BPF objects
- we need to manually attach the ones from the kernel tree"," and wait
  for the second udev 'bind' event to happen

Link: https://lore.kernel.org/r/20240410-bpf_sources-v1-11-a8bf16033ef8@kernel.org
Reviewed-by: Peter Hutterer <peter.hutterer@who-t.net>
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Add support for pre-loading HID-BPF in selftests before tests start.,"HID-BPF, selftests, udev",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['HID driver like programs']
a7def2e51c667578140d9aa3282533463ed3df91,a7def2e51c667578140d9aa3282533463ed3df91,Benjamin Tissoires,bentiss@kernel.org,1712769570,Benjamin Tissoires,bentiss@kernel.org,1715089163,d74968d1d3f3163c496e93b7cca9141f2d822dc0,0cd1465cac52d7d5b4584a29f97bddc5e8bb421f,"selftests/hid: import base_device.py from hid-tools

We need to slightly change base_device.py for supporting HID-BPF","
so instead of monkey patching","["" let's just embed it in the kernel tree.\n\nLink: https://lore.kernel.org/r/20240410-bpf_sources-v1-10-a8bf16033ef8@kernel.org\nReviewed-by: Peter Hutterer <peter.hutterer@who-t.net>\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n"", '']",Import base_device.py from hid-tools and modify it to support HID-BPF.,"base_device.py,HID-BPF,selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['HID driver like programs']
0cd1465cac52d7d5b4584a29f97bddc5e8bb421f,0cd1465cac52d7d5b4584a29f97bddc5e8bb421f,Benjamin Tissoires,bentiss@kernel.org,1712769569,Benjamin Tissoires,bentiss@kernel.org,1715089159,1f586e10087f177e3566a5cbe4e1fe4ce31a2f34,9f1bf4c225329d27e85fc1c5b5af9e6ebf4a8ff3,"HID: bpf: add in-tree HID-BPF fix for the Raptor Mach 2

This device is already fixed by ""HID: do not assume HAT Switch
logical max < 8""", but for people without the fix already,"[' having the\nHID-BPF locally can fix the device while they wait for their\ndistribution to update.\n\nLink: https://lore.kernel.org/r/20240410-bpf_sources-v1-9-a8bf16033ef8@kernel.org\nReviewed-by: Peter Hutterer <peter.hutterer@who-t.net>\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']",Add HID-BPF fix for Raptor Mach 2 to address compatibility with previous HID fix.,"HID,BPF,Raptor",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['HID driver like programs']
9f1bf4c225329d27e85fc1c5b5af9e6ebf4a8ff3,9f1bf4c225329d27e85fc1c5b5af9e6ebf4a8ff3,Benjamin Tissoires,bentiss@kernel.org,1712769568,Benjamin Tissoires,bentiss@kernel.org,1715089156,8766e103998a9d4c235eb8386cd42f63196ff0b9,1c046d09c6ba4ff5fb959b2d195cacadb2ae6977,"HID: bpf: add in-tree HID-BPF fix for the Huion Kamvas Pro 19

This tablets gets a lot of things wrong:
- the secondary button is reported through Secondary Tip Switch
- the third button is reported through Invert

Fortunately", before entering eraser mode,"[' (so Invert = 1)', '\nthe tablet always sends an out-of-proximity event.\nSo we can detect that single event and:\n- if there was none but the invert bit was toggled: this is the\n  third button\n- if there was this out-of-proximity event', ' we are entering\n  eraser mode', ' and we will until the next out-of-proximity.\n\nLink: https://lore.kernel.org/r/20240410-bpf_sources-v1-8-a8bf16033ef8@kernel.org\nReviewed-by: Peter Hutterer <peter.hutterer@who-t.net>\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']",Fixes HID-BPF issues with incorrect button mapping for Huion Kamvas Pro 19 tablet.,"HID-BPF, Huion Kamvas, fix",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['HID driver like programs']
1c046d09c6ba4ff5fb959b2d195cacadb2ae6977,1c046d09c6ba4ff5fb959b2d195cacadb2ae6977,Benjamin Tissoires,bentiss@kernel.org,1712769567,Benjamin Tissoires,bentiss@kernel.org,1715089152,5943b580af384322d3373b1203d38a6fadc302df,d9e78973921d215a6453b609a6326dab9dbc5a60,"HID: bpf: add in-tree HID-BPF fix for the XBox Elite 2 over Bluetooth

When using the XBox Wireless Controller Elite 2 over Bluetooth","
the device exports the paddle on the back of the device as a single
bitfield value of usage ""Assign Selection"".

The kernel doesn't process those usages properly and report KEY_UNKNOWN
for it.

SDL doesn't know how to interprete that KEY_UNKNOWN and thus ignores the
paddles.

Given that over USB the kernel uses BTN_TRIGGER_HAPPY[5-8]","[' we\ncan tweak the report descriptor to make the kernel interprete it properly:\n- we need an application collection of gamepad (so we have to close the\n  current Consumer Control one)\n- we need to change the usage to be buttons from 0x15 to 0x18\n\nLink: https://lore.kernel.org/r/20240410-bpf_sources-v1-7-a8bf16033ef8@kernel.org\nReviewed-by: Peter Hutterer <peter.hutterer@who-t.net>\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']",Fixes HID-BPF handling of Xbox Elite 2 paddle usage over Bluetooth in Linux.,"HID,Bluetooth,Xbox",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['HID driver like programs']
d9e78973921d215a6453b609a6326dab9dbc5a60,d9e78973921d215a6453b609a6326dab9dbc5a60,Benjamin Tissoires,bentiss@kernel.org,1712769566,Benjamin Tissoires,bentiss@kernel.org,1715089147,26c150f33a55dccc1b6d3632d902dbddf89a6d9f,0bc8f89f40403cfbc3c6e676b0bee240a9349d3f,"HID: bpf: add in-tree HID-BPF fix for the Wacom ArtPen

This pen is compatible with multiple Wacom tablets"," but we only add support
for the Intuos Pro 2 M","[' as this is the one our user reported the bug\nagainst.\n\nWe can not generically add all compatible Wacom tablets as we are\nwriting the offsets by hand.\n\nThe point of this HID-BPF program is to work around a firmware limitation\nwhere the pressure is repeated every other report.\nGiven that we know this will happen', ' we can change the first new pressure\ninformation with the mean compared to the previous one. This way we\nsmooth the incoming pressure without losing information.\n\nCc: Ping Cheng <pinglinux@gmail.com>\nCc: Jason Gerecke <killertofu@gmail.com>\nCc: Aaron Armstrong Skomra <skomra@gmail.com>\nCc: Joshua Dickens <Joshua@joshua-dickens.com>\nLink: https://lore.kernel.org/r/20240410-bpf_sources-v1-6-a8bf16033ef8@kernel.org\nReviewed-by: Peter Hutterer <peter.hutterer@who-t.net>\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']",Add HID-BPF support for the Wacom ArtPen compatible with Intuos Pro 2 M tablets.,"HID, BPF, Wacom",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['HID driver like programs']
0bc8f89f40403cfbc3c6e676b0bee240a9349d3f,0bc8f89f40403cfbc3c6e676b0bee240a9349d3f,Benjamin Tissoires,bentiss@kernel.org,1712769565,Benjamin Tissoires,bentiss@kernel.org,1715089144,0538c95b2948c9464061233f7035aaade4d2574e,4e6d2a297dd5be26ad409b7a05b20bd033d1c95e,"HID: bpf: add in-tree HID-BPF fix for the IOGear Kaliber Gaming MMOmentum mouse

Allows to export more than 5 buttons on this 12 buttons mouse.

Link: https://lore.kernel.org/r/20240410-bpf_sources-v1-5-a8bf16033ef8@kernel.org
Reviewed-by: Peter Hutterer <peter.hutterer@who-t.net>
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",,Add support in HID-BPF for more than 5 buttons on the IOGear Kaliber Gaming MMOmentum mouse.,"HID-BPF, IOGear, buttons",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['HID driver like programs']
4e6d2a297dd5be26ad409b7a05b20bd033d1c95e,4e6d2a297dd5be26ad409b7a05b20bd033d1c95e,Benjamin Tissoires,bentiss@kernel.org,1712769564,Benjamin Tissoires,bentiss@kernel.org,1715089140,ed9b98394858399f5d755642227deee2c0adccab,e0599675a32cb994a076a4b40d3e42d8353a5bb7,"HID: bpf: add in-tree HID-BPF fix for the HP Elite Presenter Mouse

Duplicate of commit 0db117359e47 (""HID: add quirk for 03f0:464a HP Elite
Presenter Mouse"")"," but in a slightly better way.

This time we actually change the application collection","[' making clearer\nfor userspace what the second mouse is.\n\nNote that having both hid-quirks fix and this HID-BPF fix is not a\nproblem at all.\n\nLink: https://lore.kernel.org/r/20240410-bpf_sources-v1-4-a8bf16033ef8@kernel.org\nReviewed-by: Peter Hutterer <peter.hutterer@who-t.net>\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']",Add in-tree HID-BPF fix for HP Elite Presenter Mouse with improved application collection changes.,"HID-BPF, HP, fix",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['HID driver like programs']
e0599675a32cb994a076a4b40d3e42d8353a5bb7,e0599675a32cb994a076a4b40d3e42d8353a5bb7,Benjamin Tissoires,bentiss@kernel.org,1712769563,Benjamin Tissoires,bentiss@kernel.org,1715089137,1dbdc5ce864409c8a8861476151bbec8383db6d3,04b3e5ab055553e074ea54ef316982b55cdde96b,"HID: bpf: add in-tree HID-BPF fix for the XPPen Artist 16

Same problem than the Artist 24: the second button on the pen is treated
like an eraser.
But the problem is even worse this time. There is an actual eraser at
the tail of the pen.

The compensation of the coordinates was done by Martin

Signed-off-by: Martin Sivak <mars@montik.net>
Link: https://lore.kernel.org/r/20240410-bpf_sources-v1-3-a8bf16033ef8@kernel.org
Reviewed-by: Peter Hutterer <peter.hutterer@who-t.net>
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",,Fixes the HID-BPF handling for the XPPen Artist 16 to correctly recognize the pen eraser function.,"HID-BPF,XPPen Artist,eraser",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['HID driver like programs']
04b3e5ab055553e074ea54ef316982b55cdde96b,04b3e5ab055553e074ea54ef316982b55cdde96b,Benjamin Tissoires,bentiss@kernel.org,1712769562,Benjamin Tissoires,bentiss@kernel.org,1715089133,48c4349295d9509c46a65491fd522189746c4d18,65ad580a14e875c2d8c027cf1a2ca03b849ff843,"HID: bpf: add first in-tree HID-BPF fix for the XPPen Artist 24

This commit adds a fix for XPPen Artist 24 where the second button on
the pen is used as an eraser.

It's a ""feature"" from Microsoft"," but it turns out that it's actually
painful for artists. So we ship here a HID-BPF program that turns this
second button into an actual button.

Note that the HID-BPF program is not directly loaded by the kernel itself
but by udev-hid-bpf[0]. But having the sources here allows us to also
integrate tests into tools/testing/selftests/hid to ensure the HID-BPF
program are actually tested.

[0] https://gitlab.freedesktop.org/libevdev/udev-hid-bpf

Link: https://lore.kernel.org/r/20240410-bpf_sources-v1-2-a8bf16033ef8@kernel.org
Reviewed-by: Peter Hutterer <peter.hutterer@who-t.net>
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Add HID-BPF fix for XPPen Artist 24 to turn second pen button into a functional button instead of an eraser.,"HID,BPF,XPPen",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['HID driver like programs']
65ad580a14e875c2d8c027cf1a2ca03b849ff843,65ad580a14e875c2d8c027cf1a2ca03b849ff843,Benjamin Tissoires,bentiss@kernel.org,1712769561,Benjamin Tissoires,bentiss@kernel.org,1715089116,426b9017f1eec4f1b019e521777a08b93393e622,b912cf042072e12e93faa874265b30cc0aa521b9,"HID: do not assume HAT Switch logical max < 8

Turns out that the code can handle a greater range"," but the data stored
can not. This is problematic on the Raptor Mach 2 joystick which
logical max is 239. The kernel interprets it as `-15` and thus ignores
the Hat Switch handling.

Link: https://gitlab.freedesktop.org/libevdev/udev-hid-bpf/-/issues/17
Link: https://lore.kernel.org/r/20240410-bpf_sources-v1-1-a8bf16033ef8@kernel.org
Reviewed-by: Peter Hutterer <peter.hutterer@who-t.net>
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],This commit fixes the handling of HAT Switch logical maximums greater than 8 in the Raptor Mach 2 joystick.,"HID, HAT Switch, joystick",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['HID driver like programs']
8ecf3c1dab1c675721d3d0255556abe2306fa340,8ecf3c1dab1c675721d3d0255556abe2306fa340,Christophe Leroy,christophe.leroy@csgroup.eu,1709652983,Michael Ellerman,mpe@ellerman.id.au,1715084222,df05258dde6471d1198bcdf18f24a30306e70c9e,be140f1732b523947425aaafbe2e37b41b622d96,"powerpc/bpf/32: Fix failing test_bpf tests

Recent additions in BPF like cpu v4 instructions"," test_bpf module
exhibits the following failures:

  test_bpf: #82 ALU_MOVSX | BPF_B jited:1 ret 2 != 1 (0x2 != 0x1)FAIL (1 times)
  test_bpf: #83 ALU_MOVSX | BPF_H jited:1 ret 2 != 1 (0x2 != 0x1)FAIL (1 times)
  test_bpf: #84 ALU64_MOVSX | BPF_B jited:1 ret 2 != 1 (0x2 != 0x1)FAIL (1 times)
  test_bpf: #85 ALU64_MOVSX | BPF_H jited:1 ret 2 != 1 (0x2 != 0x1)FAIL (1 times)
  test_bpf: #86 ALU64_MOVSX | BPF_W jited:1 ret 2 != 1 (0x2 != 0x1)FAIL (1 times)

  test_bpf: #165 ALU_SDIV_X: -6 / 2 = -3 jited:1 ret 2147483645 != -3 (0x7ffffffd != 0xfffffffd)FAIL (1 times)
  test_bpf: #166 ALU_SDIV_K: -6 / 2 = -3 jited:1 ret 2147483645 != -3 (0x7ffffffd != 0xfffffffd)FAIL (1 times)

  test_bpf: #169 ALU_SMOD_X: -7 % 2 = -1 jited:1 ret 1 != -1 (0x1 != 0xffffffff)FAIL (1 times)
  test_bpf: #170 ALU_SMOD_K: -7 % 2 = -1 jited:1 ret 1 != -1 (0x1 != 0xffffffff)FAIL (1 times)

  test_bpf: #172 ALU64_SMOD_K: -7 % 2 = -1 jited:1 ret 1 != -1 (0x1 != 0xffffffff)FAIL (1 times)

  test_bpf: #313 BSWAP 16: 0x0123456789abcdef -> 0xefcd
  eBPF filter opcode 00d7 (@2) unsupported
  jited:0 301 PASS
  test_bpf: #314 BSWAP 32: 0x0123456789abcdef -> 0xefcdab89
  eBPF filter opcode 00d7 (@2) unsupported
  jited:0 555 PASS
  test_bpf: #315 BSWAP 64: 0x0123456789abcdef -> 0x67452301
  eBPF filter opcode 00d7 (@2) unsupported
  jited:0 268 PASS
  test_bpf: #316 BSWAP 64: 0x0123456789abcdef >> 32 -> 0xefcdab89
  eBPF filter opcode 00d7 (@2) unsupported
  jited:0 269 PASS
  test_bpf: #317 BSWAP 16: 0xfedcba9876543210 -> 0x1032
  eBPF filter opcode 00d7 (@2) unsupported
  jited:0 460 PASS
  test_bpf: #318 BSWAP 32: 0xfedcba9876543210 -> 0x10325476
  eBPF filter opcode 00d7 (@2) unsupported
  jited:0 320 PASS
  test_bpf: #319 BSWAP 64: 0xfedcba9876543210 -> 0x98badcfe
  eBPF filter opcode 00d7 (@2) unsupported
  jited:0 222 PASS
  test_bpf: #320 BSWAP 64: 0xfedcba9876543210 >> 32 -> 0x10325476
  eBPF filter opcode 00d7 (@2) unsupported
  jited:0 273 PASS

  test_bpf: #344 BPF_LDX_MEMSX | BPF_B
  eBPF filter opcode 0091 (@5) unsupported
  jited:0 432 PASS
  test_bpf: #345 BPF_LDX_MEMSX | BPF_H
  eBPF filter opcode 0089 (@5) unsupported
  jited:0 381 PASS
  test_bpf: #346 BPF_LDX_MEMSX | BPF_W
  eBPF filter opcode 0081 (@5) unsupported
  jited:0 505 PASS

  test_bpf: #490 JMP32_JA: Unconditional jump: if (true) return 1
  eBPF filter opcode 0006 (@1) unsupported
  jited:0 261 PASS

  test_bpf: Summary: 1040 PASSED","[' 10 FAILED', ' [924/1038 JIT\'ed]\n\nFix them by adding missing processing.\n\nFixes: daabb2b098e0 (""bpf/tests: add tests for cpuv4 instructions"")\nSigned-off-by: Christophe Leroy <christophe.leroy@csgroup.eu>\nSigned-off-by: Michael Ellerman <mpe@ellerman.id.au>\nLink: https://msgid.link/91de862dda99d170697eb79ffb478678af7e0b27.1709652689.git.christophe.leroy@csgroup.eu\n', '']",Fixes failing test_bpf cases on powerpc architecture related to BPF instructions and kernel tests.,"test_bpf,bpf,instructions",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
329a6720a3ebbc041983b267981ab2cac102de93,329a6720a3ebbc041983b267981ab2cac102de93,Alexei Starovoitov,ast@kernel.org,1715040552,Alexei Starovoitov,ast@kernel.org,1715040560,d5c433c0d9cf68d1e208cc06512d49f00d9e3a33,41b307ad756e1b7b618bf9d9c1cce3595705ede4 92956786b4e26ea22e5b3c1c86cc71f5c9b3b9d8,"Merge branch 'bpf-verifier-range-computation-improvements'

Cupertino Miranda says:

====================
bpf/verifier: range computation improvements

Hi everyone","

This is what I hope to be the last version. :)

Regards","['\nCupertino\n\nChanges from v1:\n - Reordered patches in the series.\n - Fix refactor to be acurate with original code.\n - Fixed other mentioned small problems.\n\nChanges from v2:\n - Added a patch to replace mark_reg_unknowon for __mark_reg_unknown in\n   the context of range computation.\n - Reverted implementation of refactor to v1 which used a simpler\n   boolean return value in check function.\n - Further relaxed MUL to allow it to still compute a range when neither\n   of its registers is a known value.\n - Simplified tests based on Eduards example.\n - Added messages in selftest commits.\n\nChanges from v3:\n - Improved commit message of patch nr 1.\n - Coding style fixes.\n - Improve XOR and OR tests.\n - Made function calls to pass struct bpf_reg_state pointer instead.\n - Improved final code as a last patch.\n\nChanges from v4:\n - Merged patch nr 7 in 2.\n\n====================\n\nLink: https://lore.kernel.org/r/20240506141849.185293-1-cupertino.miranda@oracle.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Improve bpf verifier with enhanced range computation methodology.,"verifier, range, computation",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
92956786b4e26ea22e5b3c1c86cc71f5c9b3b9d8,92956786b4e26ea22e5b3c1c86cc71f5c9b3b9d8,Cupertino Miranda,cupertino.miranda@oracle.com,1715005129,Alexei Starovoitov,ast@kernel.org,1715040552,d5c433c0d9cf68d1e208cc06512d49f00d9e3a33,41d047a871062f1a4d1871a1908d380c14e75428,"selftests/bpf: MUL range computation tests.

Added a test for bound computation in MUL when non constant
values are used and both registers have bounded ranges.

Signed-off-by: Cupertino Miranda <cupertino.miranda@oracle.com>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Acked-by: Andrii Nakryiko <andrii.nakryiko@gmail.com>
Cc: Yonghong Song <yonghong.song@linux.dev>
Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Cc: David Faust <david.faust@oracle.com>
Cc: Jose Marchesi <jose.marchesi@oracle.com>
Cc: Elena Zannoni <elena.zannoni@oracle.com>
Link: https://lore.kernel.org/r/20240506141849.185293-7-cupertino.miranda@oracle.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add test case for MUL range computation with non-constant values and bounded registers.,"test,MUL,range",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['tracepoints like programs', 'kprobe/uprobe/ftrace like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
41d047a871062f1a4d1871a1908d380c14e75428,41d047a871062f1a4d1871a1908d380c14e75428,Cupertino Miranda,cupertino.miranda@oracle.com,1715005128,Alexei Starovoitov,ast@kernel.org,1715040552,3461ffd9f5283a4ff853a704fb887b0d798ff767,5ec9a7d13f49b9c1c5ba854244d1f2ba414cf139,"bpf/verifier: relax MUL range computation check

MUL instruction required that src_reg would be a known value (i.e.
src_reg would be a const value). The condition in this case can be
relaxed"," since the range computation algorithm used in current code
already supports a proper range computation for any valid range value on
its operands.

Signed-off-by: Cupertino Miranda <cupertino.miranda@oracle.com>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Acked-by: Andrii Nakryiko <andrii.nakryiko@gmail.com>
Cc: Yonghong Song <yonghong.song@linux.dev>
Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Cc: David Faust <david.faust@oracle.com>
Cc: Jose Marchesi <jose.marchesi@oracle.com>
Cc: Elena Zannoni <elena.zannoni@oracle.com>
Link: https://lore.kernel.org/r/20240506141849.185293-6-cupertino.miranda@oracle.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The commit relaxes the MUL range computation check in the eBPF verifier.,"MUL,relax,verifier",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5ec9a7d13f49b9c1c5ba854244d1f2ba414cf139,5ec9a7d13f49b9c1c5ba854244d1f2ba414cf139,Cupertino Miranda,cupertino.miranda@oracle.com,1715005127,Alexei Starovoitov,ast@kernel.org,1715040551,448928be55a8dfcc6c0855d697b78c850fdad69b,138cc42c05d11fd5ee82ee1606d2c9823373a926,"selftests/bpf: XOR and OR range computation tests.

Added a test for bound computation in XOR and OR when non constant
values are used and both registers have bounded ranges.

Signed-off-by: Cupertino Miranda <cupertino.miranda@oracle.com>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Cc: Yonghong Song <yonghong.song@linux.dev>
Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Cc: David Faust <david.faust@oracle.com>
Cc: Jose Marchesi <jose.marchesi@oracle.com>
Cc: Elena Zannoni <elena.zannoni@oracle.com>
Cc: Andrii Nakryiko <andrii.nakryiko@gmail.com>
Link: https://lore.kernel.org/r/20240506141849.185293-5-cupertino.miranda@oracle.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Added XOR and OR range computation tests for non-constant values in eBPF selftests.,"XOR, OR, selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
138cc42c05d11fd5ee82ee1606d2c9823373a926,138cc42c05d11fd5ee82ee1606d2c9823373a926,Cupertino Miranda,cupertino.miranda@oracle.com,1715005126,Alexei Starovoitov,ast@kernel.org,1715040551,383933f497a27b1046f720057b979d727e0d0516,0922c78f592c60e5a8fe6ab968479def124d4ff3,"bpf/verifier: improve XOR and OR range computation

Range for XOR and OR operators would not be attempted unless src_reg
would resolve to a single value"," i.e. a known constant value.
This condition is unnecessary","[' and the following XOR/OR operator\nhandling could compute a possible better range.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\n\nSigned-off-by: Cupertino Miranda <cupertino.miranda@oracle.com\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nCc: Yonghong Song <yonghong.song@linux.dev>\nCc: Alexei Starovoitov <alexei.starovoitov@gmail.com>\nCc: David Faust <david.faust@oracle.com>\nCc: Jose Marchesi <jose.marchesi@oracle.com>\nCc: Elena Zannoni <elena.zannoni@oracle.com>\nCc: Andrii Nakryiko <andrii.nakryiko@gmail.com>\nLink: https://lore.kernel.org/r/20240506141849.185293-4-cupertino.miranda@oracle.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Improves range computation logic for XOR and OR operations in BPF verifier.,"verifier,XOR,OR",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0922c78f592c60e5a8fe6ab968479def124d4ff3,0922c78f592c60e5a8fe6ab968479def124d4ff3,Cupertino Miranda,cupertino.miranda@oracle.com,1715005125,Alexei Starovoitov,ast@kernel.org,1715040551,c1b1bdf43c77e34bc31a2252067487e259a94e86,d786957ebd3fb4cfd9147dbcccd1e8f3871b45ce,"bpf/verifier: refactor checks for range computation

Split range computation checks in its own function"," isolating pessimitic
range set for dst_reg and failing return to a single point.

Signed-off-by: Cupertino Miranda <cupertino.miranda@oracle.com>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Cc: Yonghong Song <yonghong.song@linux.dev>
Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Cc: David Faust <david.faust@oracle.com>
Cc: Jose Marchesi <jose.marchesi@oracle.com>
Cc: Elena Zannoni <elena.zannoni@oracle.com>
Cc: Andrii Nakryiko <andrii.nakryiko@gmail.com>

bpf/verifier: improve code after range computation recent changes.
Link: https://lore.kernel.org/r/20240506141849.185293-3-cupertino.miranda@oracle.com

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Refactor range computation checks into a separate function in the eBPF verifier.,"refactor, range computation, verifier",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d786957ebd3fb4cfd9147dbcccd1e8f3871b45ce,d786957ebd3fb4cfd9147dbcccd1e8f3871b45ce,Cupertino Miranda,cupertino.miranda@oracle.com,1715005124,Alexei Starovoitov,ast@kernel.org,1715040551,8248921c59a99bdf7bfac780f92ea5c1246da626,41b307ad756e1b7b618bf9d9c1cce3595705ede4,"bpf/verifier: replace calls to mark_reg_unknown.

In order to further simplify the code in adjust_scalar_min_max_vals all
the calls to mark_reg_unknown are replaced by __mark_reg_unknown.

static void mark_reg_unknown(struct bpf_verifier_env *env","
  			     struct bpf_reg_state *regs","[' u32 regno)\n{\n\tif (WARN_ON(regno >= MAX_BPF_REG)) {\n\t\t... mark all regs not init ...\n\t\treturn;\n    }\n\t__mark_reg_unknown(env', "" regs + regno);\n}\n\nThe 'regno >= MAX_BPF_REG' does not apply to\nadjust_scalar_min_max_vals()"", ' because it is only called from the\nfollowing stack:\n  - check_alu_op\n    - adjust_reg_min_max_vals\n      - adjust_scalar_min_max_vals\n\nThe check_alu_op() does check_reg_arg() which verifies that both src and\ndst register numbers are within bounds.\n\nSigned-off-by: Cupertino Miranda <cupertino.miranda@oracle.com>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nCc: Yonghong Song <yonghong.song@linux.dev>\nCc: Alexei Starovoitov <alexei.starovoitov@gmail.com>\nCc: David Faust <david.faust@oracle.com>\nCc: Jose Marchesi <jose.marchesi@oracle.com>\nCc: Elena Zannoni <elena.zannoni@oracle.com>\nCc: Andrii Nakryiko <andrii.nakryiko@gmail.com>\nLink: https://lore.kernel.org/r/20240506141849.185293-2-cupertino.miranda@oracle.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit replaces calls to mark_reg_unknown with __mark_reg_unknown in the eBPF verifier for code simplification.,"mark_reg_unknown, bpf, verifier",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
41b307ad756e1b7b618bf9d9c1cce3595705ede4,41b307ad756e1b7b618bf9d9c1cce3595705ede4,John Hubbard,jhubbard@nvidia.com,1714950054,Andrii Nakryiko,andrii@kernel.org,1715031576,a41194186c6f374dc9093246364c1b0ed031553d,e549b39a0ab8880d7ae6c6495b00fc1cb8f36174,bpftool," selftests/hid/bpf: Fix 29 clang warnings

When building either tools/bpf/bpftool","[' or tools/testing/selftests/hid', '\n(the same Makefile is used for these)', ' clang generates many instances of\nthe following:\n\n    ""clang: warning: -lLLVM-17: \'linker\' input unused""\n\nQuentin points out that the LLVM version is only required in $(LIBS)', '\nnot in $(CFLAGS)', ' so the fix is to remove it from CFLAGS.\n\nSuggested-by: Quentin Monnet <qmo@kernel.org>\nSigned-off-by: John Hubbard <jhubbard@nvidia.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Quentin Monnet <qmo@kernel.org>\nLink: https://lore.kernel.org/bpf/20240505230054.13813-1-jhubbard@nvidia.com\n', '']",Fixes 29 clang warnings in selftests/hid/bpf for bpftool.,"clang,warnings,bpftool",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,['HID driver like programs']
e549b39a0ab8880d7ae6c6495b00fc1cb8f36174,e549b39a0ab8880d7ae6c6495b00fc1cb8f36174,Michal Schmidt,mschmidt@redhat.com,1715007022,Andrii Nakryiko,andrii@kernel.org,1715028142,e2b4ed7f9f9cc6b2904155c29ccf6b4b63077b96,8e6d9ae2e09f1f6ba65614a5e5c5a2a2e335dcba,"selftests/bpf: Fix pointer arithmetic in test_xdp_do_redirect

Cast operation has a higher precedence than addition. The code here
wants to zero the 2nd half of the 64-bit metadata"," but due to a pointer
arithmetic mistake","[' it writes the zero at offset 16 instead.\n\nJust adding parentheses around ""data + 4"" would fix this', ' but I think\nthis will be slightly better readable with array syntax.\n\nI was unable to test this with tools/testing/selftests/bpf/vmtest.sh', '\nbecause my glibc is newer than glibc in the provided VM image.\nSo I just checked the difference in the compiled code.\nobjdump -S tools/testing/selftests/bpf/xdp_do_redirect.test.o:\n  -\t*((__u32 *)data) = 0x42; /* metadata test value */\n  +\t((__u32 *)data)[0] = 0x42; /* metadata test value */\n        be7:\t48 8d 85 30 fc ff ff \tlea    -0x3d0(%rbp)', '%rax\n        bee:\tc7 00 42 00 00 00    \tmovl   $0x42', '(%rax)\n  -\t*((__u32 *)data + 4) = 0;\n  +\t((__u32 *)data)[1] = 0;\n        bf4:\t48 8d 85 30 fc ff ff \tlea    -0x3d0(%rbp)', '%rax\n  -     bfb:\t48 83 c0 10          \tadd    $0x10', '%rax\n  +     bfb:\t48 83 c0 04          \tadd    $0x4', '%rax\n        bff:\tc7 00 00 00 00 00    \tmovl   $0x0', '(%rax)\n\nFixes: 5640b6d89434 (""selftests/bpf: fix ""metadata marker"" getting overwritten by the netstack"")\nSigned-off-by: Michal Schmidt <mschmidt@redhat.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nReviewed-by: Toke Høiland-Jørgensen <toke@redhat.com>\nLink: https://lore.kernel.org/bpf/20240506145023.214248-1-mschmidt@redhat.com\n', '']",Fixes pointer arithmetic mistake in test_xdp_do_redirect for selftests in BPF.,"pointer, arithmetic, selftests",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['xdp like programs']
8e6d9ae2e09f1f6ba65614a5e5c5a2a2e335dcba,8e6d9ae2e09f1f6ba65614a5e5c5a2a2e335dcba,Martin KaFai Lau,martin.lau@kernel.org,1714783845,Andrii Nakryiko,andrii@kernel.org,1715028024,811617fea13f0eb366fc71068a5e0ca0b1a56e6b,a9e7715ce8b3a62a2133e47e87107632a26ad1e2,"selftests/bpf: Use bpf_tracing.h instead of bpf_tcp_helpers.h

The bpf programs that this patch changes require the BPF_PROG macro.
The BPF_PROG macro is defined in the libbpf's bpf_tracing.h.
Some tests include bpf_tcp_helpers.h which includes bpf_tracing.h.
They don't need other things from bpf_tcp_helpers.h other than
bpf_tracing.h. This patch simplifies it by directly including
the bpf_tracing.h.

The motivation of this unnecessary code churn is to retire
the bpf_tcp_helpers.h by directly using vmlinux.h. Right now","
the main usage of the bpf_tcp_helpers.h is the partial kernel
socket definitions (e.g. socket","[' sock', ' tcp_sock). While the test\ncases continue to grow', ' fields are kept adding to those partial\nsocket definitions (e.g. the recent bpf_cc_cubic.c test which\ntried to extend bpf_tcp_helpers.c but eventually used the\nvmlinux.h instead).\n\nThe idea is to retire bpf_tcp_helpers.c and consistently use\nvmlinux.h for the tests that require the kernel sockets. This\npatch tackles the obvious tests that can directly use bpf_tracing.h\ninstead of bpf_tcp_helpers.h.\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240504005045.848376-1-martin.lau@linux.dev\n', '']",The commit simplifies code by directly including bpf_tracing.h instead of bpf_tcp_helpers.h in selftests/bpf.,"bpf_tracing.h,selftests,bpf_tcp_helpers.h",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tracepoints like programs']
61688a82e047a4166436bf2665716cc070572ffa,61688a82e047a4166436bf2665716cc070572ffa,Hari Bathini,hbathini@linux.ibm.com,1714671125,Michael Ellerman,mpe@ellerman.id.au,1714997118,09628b901852a720ed6b8c9b8d6654109123a57f,2ecfe59cd7de1f202e9af2516a61fbbf93d0bd4d,"powerpc/bpf: enable kfunc call

Currently"," bpf jit code on powerpc assumes all the bpf functions and
helpers to be part of core kernel text. This is false for kfunc case","['\nas function addresses may not be part of core kernel text area. So', '\nadd support for addresses that are not within core kernel text area\ntoo', ' to enable kfunc support. Emit instructions based on whether the\nfunction address is within core kernel text address or not', ' to retain\noptimized instruction sequence where possible.\n\nIn case of PCREL', ' as a bpf function that is not within core kernel\ntext area is likely to go out of range with relative addressing on\nkernel base', ' use PC relative addressing. If that goes out of range', '\nload the full address with PPC_LI64().\n\nWith addresses that are not within core kernel text area supported', '\noverride bpf_jit_supports_kfunc_call() to enable kfunc support. Also', '\noverride bpf_jit_supports_far_kfunc_call() to enable 64-bit pointers', '\nas an address offset can be more than 32-bit long on PPC64.\n\nSigned-off-by: Hari Bathini <hbathini@linux.ibm.com>\nSigned-off-by: Michael Ellerman <mpe@ellerman.id.au>\nLink: https://msgid.link/20240502173205.142794-2-hbathini@linux.ibm.com\n\n', '']",Enable kfunc calls in powerpc BPF JIT by addressing assumptions about BPF function locations.,"powerpc, kfunc, JIT",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2ecfe59cd7de1f202e9af2516a61fbbf93d0bd4d,2ecfe59cd7de1f202e9af2516a61fbbf93d0bd4d,Hari Bathini,hbathini@linux.ibm.com,1714671124,Michael Ellerman,mpe@ellerman.id.au,1714997118,26b5ae261b36c0c074b43aa26749c306f2958f58,fae573060c8da4d84a2551c6753d272abfda8ddc,"powerpc/64/bpf: fix tail calls for PCREL addressing

With PCREL addressing", there is no kernel TOC. So,"["" it is not setup in\nprologue when PCREL addressing is used. But the number of instructions\nto skip on a tail call was not adjusted accordingly. That resulted in\nnot so obvious failures while using tailcalls. 'tailcalls' selftest\ncrashed the system with the below call trace:\n\n  bpf_test_run+0xe8/0x3cc (unreliable)\n  bpf_prog_test_run_skb+0x348/0x778\n  __sys_bpf+0xb04/0x2b00\n  sys_bpf+0x28/0x38\n  system_call_exception+0x168/0x340\n  system_call_vectored_common+0x15c/0x2ec\n\nAlso"", ' as bpf programs are always module addresses and a bpf helper in\ngeneral is a core kernel text address', ' using PC relative addressing\noften fails with ""out of range of pcrel address"" error. Switch to\nusing kernel base for relative addressing to handle this better.\n\nFixes: 7e3a68be42e1 (""powerpc/64: vmlinux support building with PCREL addresing"")\nCc: stable@vger.kernel.org # v6.4+\nSigned-off-by: Hari Bathini <hbathini@linux.ibm.com>\nSigned-off-by: Michael Ellerman <mpe@ellerman.id.au>\nLink: https://msgid.link/20240502173205.142794-1-hbathini@linux.ibm.com\n\n', '']",Fixes tail call handling for PCREL addressing mode on powerpc/64 architecture.,"tail calls, PCREL, powerpc",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a9e7715ce8b3a62a2133e47e87107632a26ad1e2,a9e7715ce8b3a62a2133e47e87107632a26ad1e2,Jose E. Marchesi,jose.marchesi@oracle.com,1714669765,Andrii Nakryiko,andrii@kernel.org,1714715938,880720a0e92a73f85ef14201eafb8dc6d166d19f,cf9bea94f6b2934d409511c05337010b137316a3,"libbpf: Avoid casts from pointers to enums in bpf_tracing.h

[Differences from V1:
  - Do not introduce a global typedef"," as this is a public header.
  - Keep the void* casts in BPF_KPROBE_READ_RET_IP and
    BPF_KRETPROBE_READ_RET_IP","[' as these are necessary\n    for converting to a const void* argument of\n    bpf_probe_read_kernel.]\n\nThe BPF_PROG', ' BPF_KPROBE and BPF_KSYSCALL macros defined in\ntools/lib/bpf/bpf_tracing.h use a clever hack in order to provide a\nconvenient way to define entry points for BPF programs as if they were\nnormal C functions that get typed actual arguments', ' instead of as\nelements in a single ""context"" array argument.\n\nFor example', ' PPF_PROGS allows writing:\n\n  SEC(""struct_ops/cwnd_event"")\n  void BPF_PROG(cwnd_event', ' struct sock *sk', ' enum tcp_ca_event event)\n  {\n        bbr_cwnd_event(sk', ' event);\n        dctcp_cwnd_event(sk', ' event);\n        cubictcp_cwnd_event(sk', ' event);\n  }\n\nThat expands into a pair of functions:\n\n  void ____cwnd_event (unsigned long long *ctx', ' struct sock *sk', ' enum tcp_ca_event event)\n  {\n        bbr_cwnd_event(sk', ' event);\n        dctcp_cwnd_event(sk', ' event);\n        cubictcp_cwnd_event(sk', ' event);\n  }\n\n  void cwnd_event (unsigned long long *ctx)\n  {\n        _Pragma(""GCC diagnostic push"")\n        _Pragma(""GCC diagnostic ignored \\""-Wint-conversion\\"""")\n        return ____cwnd_event(ctx', ' (void*)ctx[0]', ' (void*)ctx[1]);\n        _Pragma(""GCC diagnostic pop"")\n  }\n\nNote how the 64-bit unsigned integers in the incoming CTX get casted\nto a void pointer', ' and then implicitly converted to whatever type of\nthe actual argument in the wrapped function.  In this case:\n\n  Arg1: unsigned long long -> void * -> struct sock *\n  Arg2: unsigned long long -> void * -> enum tcp_ca_event\n\nThe behavior of GCC and clang when facing such conversions differ:\n\n  pointer -> pointer\n\n    Allowed by the C standard.\n    GCC: no warning nor error.\n    clang: no warning nor error.\n\n  pointer -> integer type\n\n    [C standard says the result of this conversion is implementation\n     defined', ' and it may lead to unaligned pointer etc.]\n\n    GCC: error: integer from pointer without a cast [-Wint-conversion]\n    clang: error: incompatible pointer to integer conversion [-Wint-conversion]\n\n  pointer -> enumerated type\n\n    GCC: error: incompatible types in assigment (*)\n    clang: error: incompatible pointer to integer conversion [-Wint-conversion]\n\nThese macros work because converting pointers to pointers is allowed', '\nand converting pointers to integers also works provided a suitable\ninteger type even if it is implementation defined', ' much like casting a\npointer to uintptr_t is guaranteed to work by the C standard.  The\nconversion errors emitted by both compilers by default are silenced by\nthe pragmas.\n\nHowever', ' the GCC error marked with (*) above when assigning a pointer\nto an enumerated value is not associated with the -Wint-conversion\nwarning', ' and it is not possible to turn it off.\n\nThis is preventing building the BPF kernel selftests with GCC.\n\nThis patch fixes this by avoiding intermediate casts to void*', ""\nreplaced with casts to `unsigned long long'"", ' which is an integer type\ncapable of safely store a BPF pointer', ' much like the standard\nuintptr_t.\n\nTesting performed in bpf-next master:\n  - vmtest.sh -- ./test_verifier\n  - vmtest.sh -- ./test_progs\n  - make M=samples/bpf\nNo regressions.\n\nSigned-off-by: Jose E. Marchesi <jose.marchesi@oracle.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240502170925.3194-1-jose.marchesi@oracle.com\n', '']",This commit avoids pointer-to-enum casts in the libbpf bpf_tracing.h code.,"libbpf, enums, casts",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,['kprobe/uprobe/ftrace like programs']
cf9bea94f6b2934d409511c05337010b137316a3,cf9bea94f6b2934d409511c05337010b137316a3,Jose E. Marchesi,jose.marchesi@oracle.com,1714303559,Andrii Nakryiko,andrii@kernel.org,1714715242,936bd3b2ecf89b3dbd8e8f848dfcec9042c61cd3,087d757fb4736ecbd3e42eebf9b39d5225d4a2ee,"libbpf: Fix bpf_ksym_exists() in GCC

The macro bpf_ksym_exists is defined in bpf_helpers.h as:

  #define bpf_ksym_exists(sym) ({								\
  	_Static_assert(!__builtin_constant_p(!!sym)"," #sym "" should be marked as __weak"");	\
  	!!sym;											\
  })

The purpose of the macro is to determine whether a given symbol has
been defined","[' given the address of the object associated with the\nsymbol.  It also has a compile-time check to make sure the object\nwhose address is passed to the macro has been declared as weak', "" which\nmakes the check on `sym' meaningful.\n\nAs it happens"", "" the check for weak doesn't work in GCC in all cases"", '\nbecause __builtin_constant_p not always folds at parse time when\noptimizing.  This is because optimizations that happen later in the\ncompilation process', ' like inlining', ' may make a previously non-constant\nexpression a constant.  This results in errors like the following when\nbuilding the selftests with GCC:\n\n  bpf_helpers.h:190:24: error: expression in static assertion is not constant\n  190 |         _Static_assert(!__builtin_constant_p(!!sym)', ' #sym "" should be marked as __weak"");       \\\n      |                        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nFortunately recent versions of GCC support a __builtin_has_attribute\nthat can be used to directly check for the __weak__ attribute.  This\npatch changes bpf_helpers.h to use that builtin when building with a\nrecent enough GCC', ' and to omit the check if GCC is too old to support\nthe builtin.\n\nThe macro used for GCC becomes:\n\n  #define bpf_ksym_exists(sym) ({\t\t\t\t\t\t\t\t\t\\\n\t_Static_assert(__builtin_has_attribute (*sym', ' __weak__)', ' #sym "" should be marked as __weak"");\t\\\n\t!!sym;\t\t\t\t\t\t\t\t\t\t\t\t\\\n  })\n\nNote that since bpf_ksym_exists is designed to get the address of the\nobject associated with symbol SYM', ' we pass *sym to\n__builtin_has_attribute instead of sym.  When an expression is passed\nto __builtin_has_attribute then it is the type of the passed\nexpression that is checked for the specified attribute.  The\nexpression itself is not evaluated.  This accommodates well with the\nexisting usages of the macro:\n\n- For function objects:\n\n  struct task_struct *bpf_task_acquire(struct task_struct *p) __ksym __weak;\n  [...]\n  bpf_ksym_exists(bpf_task_acquire)\n\n- For variable objects:\n\n  extern const struct rq runqueues __ksym __weak; /* typed */\n  [...]\n  bpf_ksym_exists(&runqueues)\n\nNote also that BPF support was added in GCC 10 and support for\n__builtin_has_attribute in GCC 9.\n\nLocally tested in bpf-next master branch.\nNo regressions.\n\nSigned-of-by: Jose E. Marchesi <jose.marchesi@oracle.com>\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/bpf/20240428112559.10518-1-jose.marchesi@oracle.com\n', '']",Fix issue with bpf_ksym_exists macro in GCC within the libbpf library.,"libbpf,GCC,macro",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
087d757fb4736ecbd3e42eebf9b39d5225d4a2ee,087d757fb4736ecbd3e42eebf9b39d5225d4a2ee,Andrii Nakryiko,andrii@kernel.org,1714508392,Martin KaFai Lau,martin.lau@kernel.org,1714693263,f3cbe0b31c148fc7e2957e0bb2874ab8c4d10a6c,00f0e08f23fc007f4a5a71cd7e37fcdb15af0c1b,"libbpf: fix ring_buffer__consume_n() return result logic

Add INT_MAX check to ring_buffer__consume_n(). We do the similar check
to handle int return result of all these ring buffer APIs in other APIs
and ring_buffer__consume_n() is missing one. This patch fixes this
omission.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>
Link: https://lore.kernel.org/r/20240430201952.888293-2-andrii@kernel.org
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Fix logic in libbpf's ring_buffer__consume_n() to properly handle INT_MAX case.,"libbpf,int,ring_buffer",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
00f0e08f23fc007f4a5a71cd7e37fcdb15af0c1b,00f0e08f23fc007f4a5a71cd7e37fcdb15af0c1b,Andrii Nakryiko,andrii@kernel.org,1714508391,Martin KaFai Lau,martin.lau@kernel.org,1714693262,9bf2f7de3fb366f9cda9f3566132e53885be313c,29f38ca3e5ca5cacc33291f22c4848c6907b9d2b,"libbpf: fix potential overflow in ring__consume_n()

ringbuf_process_ring() return int64_t"," while ring__consume_n() assigns
it to int. It's highly unlikely","[' but possible for ringbuf_process_ring()\nto return value larger than INT_MAX', ' so use int64_t. ring__consume_n()\ndoes check INT_MAX before returning int result to the user.\n\nFixes: 4d22ea94ea33 (""libbpf: Add ring__consume_n / ring_buffer__consume_n"")\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nLink: https://lore.kernel.org/r/20240430201952.888293-1-andrii@kernel.org\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Fix potential overflow in ring__consume_n function in libbpf by adjusting data type assignment.,"potential overflow, ring__consume_n, libbpf",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
29f38ca3e5ca5cacc33291f22c4848c6907b9d2b,29f38ca3e5ca5cacc33291f22c4848c6907b9d2b,Martin KaFai Lau,martin.lau@kernel.org,1714689590,Martin KaFai Lau,martin.lau@kernel.org,1714692730,8e45830a9f0b33c1d5b0f27b746b91ae350d88d6,f8c423d1ca4f4f4224bb6ca486478b7f51a91701 96c3490d6423b7f24d356e24a61c24de69f3de77,"Merge branch 'Add new args into tcp_congestion_ops' cong_control'

Miao Xu says:

====================
This patchset attempts to add two new arguments into the hookpoint
cong_control in tcp_congestion_ops. The new arguments are inherited
from the caller tcp_cong_control and can be used by any bpf cc prog
that implements its own logic inside this hookpoint.

Please review. Thanks a lot!

Changelog
=====
v2->v3:
  - Fixed the broken selftest caused by the new arguments.
  - Renamed the selftest file name and bpf prog name.

v1->v2:
  - Split the patchset into 3 separate patches.
  - Added highlights in the selftest prog.
  - Removed the dependency on bpf_tcp_helpers.h.
====================

Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Merge to add new arguments to tcp_congestion_ops hook and fix related selftests.,"tcp, congestion-control, hookpoint",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tc/netfilter like programs']
96c3490d6423b7f24d356e24a61c24de69f3de77,96c3490d6423b7f24d356e24a61c24de69f3de77,Miao Xu,miaxu@meta.com,1714623798,Martin KaFai Lau,martin.lau@kernel.org,1714692724,8e45830a9f0b33c1d5b0f27b746b91ae350d88d6,0325cbd21e3c26eff88bc7da303ffb46b4f5d294,"selftests/bpf: Add test for the use of new args in cong_control

This patch adds a selftest to show the usage of the new arguments in
cong_control. For simplicity's sake"," the testing example reuses cubic's
kernel functions.

Signed-off-by: Miao Xu <miaxu@meta.com>
Link: https://lore.kernel.org/r/20240502042318.801932-4-miaxu@meta.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Add a selftest for demonstrating new arguments usage in cong_control.,"selftest,new arguments,cong control",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['other']
0325cbd21e3c26eff88bc7da303ffb46b4f5d294,0325cbd21e3c26eff88bc7da303ffb46b4f5d294,Miao Xu,miaxu@meta.com,1714623797,Martin KaFai Lau,martin.lau@kernel.org,1714692416,0be09be46ced079b7b53b2b5fa528212c23daea7,57bfc7605ca5b102ba336779ae9adbc5bbba1d96,"bpf: tcp: Allow to write tp->snd_cwnd_stamp in bpf_tcp_ca

This patch allows the write of tp->snd_cwnd_stamp in a bpf tcp
ca program. An use case of writing this field is to keep track
of the time whenever tp->snd_cwnd is raised or reduced inside
the `cong_control` callback.

Reviewed-by: Eric Dumazet <edumazet@google.com>
Signed-off-by: Miao Xu <miaxu@meta.com>
Link: https://lore.kernel.org/r/20240502042318.801932-3-miaxu@meta.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Allows writing tp->snd_cwnd_stamp in BPF TCP congestion control programs.,"bpf,tcp,snd_cwnd_stamp",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['cgroup like programs']
f8c423d1ca4f4f4224bb6ca486478b7f51a91701,f8c423d1ca4f4f4224bb6ca486478b7f51a91701,Martin KaFai Lau,martin.lau@kernel.org,1714676963,Martin KaFai Lau,martin.lau@kernel.org,1714688817,68733e5147e407466dbcdd8d6248ce797315cb8a,08e90da6872a9f9f63ca2911bbce6883b6fc1a19 e0c8a7e7526ff1526d4dcc7d71aad4e7fe2ec767,"Merge branch 'selftests/bpf: Add sockaddr tests for kernel networking'

Jordan Rife says:

====================
This patch series adds test coverage for BPF sockaddr hooks and their
interactions with kernel socket functions (i.e. kernel_bind()","
kernel_connect()","[' kernel_sendmsg()', ' sock_sendmsg()', '\nkernel_getpeername()', ' and kernel_getsockname()) while also rounding out\nIPv4 and IPv6 sockaddr hook coverage in prog_tests/sock_addr.c.\n\nAs with v1 of this patch series', ' we add regression coverage for the\nissues addressed by these patches', '\n\n- commit 0bdf399342c5(""net: Avoid address overwrite in kernel_connect"")\n- commit 86a7e0b69bd5(""net: prevent rewrite of msg_name in sock_sendmsg()"")\n- commit c889a99a21bf(""net: prevent address rewrite in kernel_bind()"")\n- commit 01b2885d9415(""net: Save and restore msg_namelen in sock_sendmsg"")\n\nbut broaden the focus a bit.\n\nIn order to extend prog_tests/sock_addr.c to test these kernel\nfunctions', ' we add a set of new kfuncs that wrap individual socket\noperations to bpf_testmod and invoke them through set of corresponding\nSYSCALL programs (progs/sock_addr_kern.c). Each test case can be\nconfigured to use a different set of ""sock_ops"" depending on whether it\nis testing kernel calls (kernel_bind()', ' kernel_connect()', ' etc.) or\nsystem calls (bind()', ' connect()', ' etc.).\n\n=======\nPatches\n=======\n* Patch 1 fixes the sock_addr bind test program to work for big endian\n  architectures such as s390x.\n* Patch 2 introduces the new kfuncs to bpf_testmod.\n* Patch 3 introduces the BPF program which allows us to invoke these\n  kfuncs invividually from the test program.\n* Patch 4 lays the groundwork for IPv4 and IPv6 sockaddr hook coverage\n  by migrating much of the environment setup logic from\n  bpf/test_sock_addr.sh into prog_tests/sock_addr.c and moves test cases\n  to cover bind4/6', ' connect4/6', ' sendmsg4/6 and recvmsg4/6 hooks.\n* Patch 5 makes the set of socket operations for each test case\n  configurable', ' laying the groundwork for Patch 6.\n* Patch 6 introduces two sets of sock_ops that invoke the kernel\n  equivalents of connect()', ' bind()', ' etc. and uses these to add coverage\n  for the kernel socket functions.\n\n=======\nChanges\n=======\nv2->v3\n------\n* Renamed bind helpers. Dropped ""_ntoh"" suffix.\n* Added guards to kfuncs to make sure addrlen and msglen do not exceed\n  the buffer capacity.\n* Added KF_SLEEPABLE flag to kfuncs.\n* Added a mutex (sock_lock) to kfuncs to serialize access to sock.\n* Added NULL check for sock to each kfunc.\n* Use the ""sock_addr"" networking namespace for all network interface\n  setup and testing.\n* Use ""nodad"" when calling ""ip -6 addr add"" during interface setup to\n  avoid delays and remove ping loop.\n* Removed test cases from test_sock_addr.c to make it clear what remains\n  to be migrated.\n* Removed unused parameter (expect_change) from sock_addr_op().\n\nLink: https://lore.kernel.org/bpf/20240412165230.2009746-1-jrife@google.com/T/#u\n\nv1->v2\n------\n* Dropped test_progs/sock_addr_kern.c and the sock_addr_kern test module\n  in favor of simply expanding bpf_testmod and test_progs/sock_addr.c.\n* Migrated environment setup logic from bpf/test_sock_addr.sh into\n  prog_tests/sock_addr.c rather than invoking the script from the test\n  program.\n* Added kfuncs to bpf_testmod as well as the sock_addr_kern BPF program\n  to enable us to invoke kernel socket functions from\n  test_progs/sock_addr.c.\n* Added test coverage for kernel socket functions to\n  test_progs/sock_addr.c.\n\nLink: https://lore.kernel.org/bpf/20240329191907.1808635-1-jrife@google.com/T/#u\n====================\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",This commit adds test coverage for BPF sockaddr hooks testing kernel socket functions like kernel_bind and kernel_connect.,"test coverage,sockaddr hooks,kernel functions",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
e0c8a7e7526ff1526d4dcc7d71aad4e7fe2ec767,e0c8a7e7526ff1526d4dcc7d71aad4e7fe2ec767,Jordan Rife,jrife@google.com,1714427123,Martin KaFai Lau,martin.lau@kernel.org,1714688611,68733e5147e407466dbcdd8d6248ce797315cb8a,524e05ac4e14bb50b4f442e1fe88540abc9b72fd,"selftests/bpf: Add kernel socket operation tests

This patch creates two sets of sock_ops that call out to the SYSCALL
hooks in the sock_addr_kern BPF program and uses them to construct
test cases for the range of supported operations (kernel_connect()","
kernel_bind()","[' kernel_sendms()', ' sock_sendmsg()', ' kernel_getsockname()', '\nkenel_getpeername()). This ensures that these interact with BPF sockaddr\nhooks as intended.\n\nBeyond this it also ensures that these operations do not modify their\naddress parameter', ' providing regression coverage for the issues\naddressed by this set of patches:\n\n- commit 0bdf399342c5(""net: Avoid address overwrite in kernel_connect"")\n- commit 86a7e0b69bd5(""net: prevent rewrite of msg_name in sock_sendmsg()"")\n- commit c889a99a21bf(""net: prevent address rewrite in kernel_bind()"")\n- commit 01b2885d9415(""net: Save and restore msg_namelen in sock_sendmsg"")\n\nSigned-off-by: Jordan Rife <jrife@google.com>\nLink: https://lore.kernel.org/r/20240429214529.2644801-7-jrife@google.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Added kernel socket operation tests in selftests for BPF programs involving syscall hooks.,socket tests syscall,It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
524e05ac4e14bb50b4f442e1fe88540abc9b72fd,524e05ac4e14bb50b4f442e1fe88540abc9b72fd,Jordan Rife,jrife@google.com,1714427122,Martin KaFai Lau,martin.lau@kernel.org,1714688611,765072b222024b6ccc7e4569d273de808bfa1195,8a9d22b8aeb2182cfe83991f11a88b3351084d3e,"selftests/bpf: Make sock configurable for each test case

In order to reuse the same test code for both socket system calls (e.g.
connect()", bind(),"[' etc.) and kernel socket functions (e.g.\nkernel_connect()', ' kernel_bind()', ' etc.)', ' this patch introduces the ""ops""\nfield to sock_addr_test. This field allows each test cases to configure\nthe set of functions used in the test case to create', ' manipulate', ' and\ntear down a socket.\n\nSigned-off-by: Jordan Rife <jrife@google.com>\nLink: https://lore.kernel.org/r/20240429214529.2644801-6-jrife@google.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",The commit makes socket configurations customizable in each eBPF selftest case.,"selftests,bpf,socket",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
8a9d22b8aeb2182cfe83991f11a88b3351084d3e,8a9d22b8aeb2182cfe83991f11a88b3351084d3e,Jordan Rife,jrife@google.com,1714427121,Martin KaFai Lau,martin.lau@kernel.org,1714688605,3537da922bc2becfa3c0230e14ef6078a1fa0f1f,15b6671efa508ff9c1fb995452913f8de85db73b,"selftests/bpf: Move IPv4 and IPv6 sockaddr test cases

This patch lays the groundwork for testing IPv4 and IPv6 sockaddr hooks
and their interaction with both socket syscalls and kernel functions
(e.g. kernel_connect", kernel_bind,"[' etc.). It moves some of the test\ncases from the old-style bpf/test_sock_addr.c self test into the\nsock_addr prog_test in a step towards fully retiring\nbpf/test_sock_addr.c. We will expand the test dimensions in the\nsock_addr prog_test in a later patch series in order to migrate the\nremaining test cases.\n\nSigned-off-by: Jordan Rife <jrife@google.com>\nLink: https://lore.kernel.org/r/20240429214529.2644801-5-jrife@google.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",The commit reorganizes IPv4 and IPv6 sockaddr test cases to facilitate testing hooks with socket syscalls and kernel functions.,"IPv4, IPv6, sockaddr",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
15b6671efa508ff9c1fb995452913f8de85db73b,15b6671efa508ff9c1fb995452913f8de85db73b,Jordan Rife,jrife@google.com,1714427120,Martin KaFai Lau,martin.lau@kernel.org,1714676962,490dac80cc2bad6118a4d518b95f0f5a51ab1809,bbb1cfdd02249dc8cf878e86a523b28814ed36c0,"selftests/bpf: Implement BPF programs for kernel socket operations

This patch lays out a set of SYSCALL programs that can be used to invoke
the socket operation kfuncs in bpf_testmod"," allowing a test program to
manipulate kernel socket operations from userspace.

Signed-off-by: Jordan Rife <jrife@google.com>
Link: https://lore.kernel.org/r/20240429214529.2644801-4-jrife@google.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],This commit implements BPF programs for testing kernel socket operations in selftests.,"BPF, socket, selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
bbb1cfdd02249dc8cf878e86a523b28814ed36c0,bbb1cfdd02249dc8cf878e86a523b28814ed36c0,Jordan Rife,jrife@google.com,1714427119,Martin KaFai Lau,martin.lau@kernel.org,1714676962,83c8c1aef023f1ed9d469c6365826914e1b97bf6,8e667a065daa6f4c01eadc20f3815f7bf13255bc,"selftests/bpf: Implement socket kfuncs for bpf_testmod

This patch adds a set of kfuncs to bpf_testmod that can be used to
manipulate a socket from kernel space.

Signed-off-by: Jordan Rife <jrife@google.com>
Link: https://lore.kernel.org/r/20240429214529.2644801-3-jrife@google.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Add kfuncs to bpf_testmod for manipulating sockets from kernel space.,"kfuncs,socket,bpf_testmod",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['socket like programs']
8e667a065daa6f4c01eadc20f3815f7bf13255bc,8e667a065daa6f4c01eadc20f3815f7bf13255bc,Jordan Rife,jrife@google.com,1714427118,Martin KaFai Lau,martin.lau@kernel.org,1714676962,c318b7d5d6a1964bf818346968d62112856a9c5b,08e90da6872a9f9f63ca2911bbce6883b6fc1a19,"selftests/bpf: Fix bind program for big endian systems

Without this fix"," the bind4 and bind6 programs will reject bind attempts
on big endian systems. This patch ensures that CI tests pass for the
s390x architecture.

Signed-off-by: Jordan Rife <jrife@google.com>
Link: https://lore.kernel.org/r/20240429214529.2644801-2-jrife@google.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],This commit fixes the bind program to work on big endian systems for selftests in s390x architecture.,"bind program, big endian, selftests",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e958da0ddbe831197a0023251880a4a09d5ba268,e958da0ddbe831197a0023251880a4a09d5ba268,Jakub Kicinski,kuba@kernel.org,1714676713,Jakub Kicinski,kuba@kernel.org,1714676785,eacded26f9563064a44fd1afe730493898adadb9,dcc61472534e48a200262fd297ab21f8dd94d6cc 545c494465d24b10a4370545ba213c0916f70b95,"Merge git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Cross-merge networking fixes after downstream PR.

Conflicts:

include/linux/filter.h
kernel/bpf/core.c
  66e13b615a0c (""bpf: verifier: prevent userspace memory access"")
  d503a04f8bc0 (""bpf: Add support for certain atomics in bpf_arena to x86 JIT"")
https://lore.kernel.org/all/20240429114939.210328b0@canb.auug.org.au/

No adjacent changes.

Signed-off-by: Jakub Kicinski <kuba@kernel.org>
",,Cross-merge of network-related fixes into main branch with handling of conflicts.,"cross-merge, networking, conflicts",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
08e90da6872a9f9f63ca2911bbce6883b6fc1a19,08e90da6872a9f9f63ca2911bbce6883b6fc1a19,Jose E. Marchesi,jose.marchesi@oracle.com,1714658911,Andrii Nakryiko,andrii@kernel.org,1714666921,24997d9e9fbde4e33637d21f8a9942c8e36677c6,7c13ef16e87ac2e44d16c0468b1191bceb06f95c,"bpf: Missing trailing slash in tools/testing/selftests/bpf/Makefile

tools/lib/bpf/Makefile assumes that the patch in OUTPUT is a directory
and that it includes a trailing slash.  This seems to be a common
expectation for OUTPUT among all the Makefiles.

In the rule for runqslower in tools/testing/selftests/bpf/Makefile the
variable BPFTOOL_OUTPUT is set to a directory name that lacks a
trailing slash.  This results in a malformed BPF_HELPER_DEFS being
defined in lib/bpf/Makefile.

This problem becomes evident when a file like
tools/lib/bpf/bpf_tracing.h gets updated.

This patch fixes the problem by adding the missing slash in the value
for BPFTOOL_OUTPUT in the $(OUTPUT)/runqslower rule.

Regtested by running selftests in bpf-next master and building
samples/bpf programs.

Signed-off-by: Jose E. Marchesi <jose.marchesi@oracle.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240502140831.23915-1-jose.marchesi@oracle.com
",,Added missing trailing slash in BPFTOOL_OUTPUT to fix malformed BPF_HELPER_DEFS in Makefile.,"Makefile, trailing slash, BPFTOOL_OUTPUT",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
7c13ef16e87ac2e44d16c0468b1191bceb06f95c,7c13ef16e87ac2e44d16c0468b1191bceb06f95c,Jiri Olsa,jolsa@kernel.org,1714636541,Andrii Nakryiko,andrii@kernel.org,1714665384,ccee84d8045d808a904dcc4b45b5d831e81f6c8b,5a3941f84b8f91bb1e111499d803b32188d33e5d,"libbpf: Fix error message in attach_kprobe_multi

We just failed to retrieve pattern"," so we need to print spec instead.

Fixes: ddc6b04989eb (""libbpf: Add bpf_program__attach_kprobe_multi_opts function"")
Reported-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240502075541.1425761-2-jolsa@kernel.org
",[''],This commit fixes an error message in the libbpf function for attaching kprobe multiple options.,"libbpf,error message,kprobe",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,['kprobe/uprobe/ftrace like programs']
5a3941f84b8f91bb1e111499d803b32188d33e5d,5a3941f84b8f91bb1e111499d803b32188d33e5d,Jiri Olsa,jolsa@kernel.org,1714636540,Andrii Nakryiko,andrii@kernel.org,1714665383,b17b5aeba04269535dff4f7436c3503cf96c67fc,ac2f438c2a85acd07e0ac7dc2f69d45bda1bb498,"libbpf: Fix error message in attach_kprobe_session

We just failed to retrieve pattern"," so we need to print spec instead.

Fixes: 2ca178f02b2f (""libbpf: Add support for kprobe session attach"")
Reported-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240502075541.1425761-1-jolsa@kernel.org
",[''],The commit fixes the error message in libbpf during kprobe session attachment.,"libbpf,error message,kprobe",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
545c494465d24b10a4370545ba213c0916f70b95,545c494465d24b10a4370545ba213c0916f70b95,Linus Torvalds,torvalds@linux-foundation.org,1714665107,Linus Torvalds,torvalds@linux-foundation.org,1714665107,b672512df4f470eeaeee888703ff4db9cec6e456,0106679839f7c69632b3b9833c3268c316c0a9fc 78cfe547607a83de60cd25304fa2422777634712,"Merge tag 'net-6.9-rc7' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Paolo Abeni:
 ""Including fixes from bpf.

  Relatively calm week"," likely due to public holiday in most places. No
  known outstanding regressions.

  Current release - regressions:

   - rxrpc: fix wrong alignmask in __page_frag_alloc_align()

   - eth: e1000e: change usleep_range to udelay in PHY mdic access

  Previous releases - regressions:

   - gro: fix udp bad offset in socket lookup

   - bpf: fix incorrect runtime stat for arm64

   - tipc: fix UAF in error path

   - netfs: fix a potential infinite loop in extract_user_to_sg()

   - eth: ice: ensure the copied buf is NUL terminated

   - eth: qeth: fix kernel panic after setting hsuid

  Previous releases - always broken:

   - bpf:
       - verifier: prevent userspace memory access
       - xdp: use flags field to disambiguate broadcast redirect

   - bridge: fix multicast-to-unicast with fraglist GSO

   - mptcp: ensure snd_nxt is properly initialized on connect

   - nsh: fix outer header access in nsh_gso_segment().

   - eth: bcmgenet: fix racing registers access

   - eth: vxlan: fix stats counters.

  Misc:

   - a bunch of MAINTAINERS file updates""

* tag 'net-6.9-rc7' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (45 commits)
  MAINTAINERS: mark MYRICOM MYRI-10G as Orphan
  MAINTAINERS: remove Ariel Elior
  net: gro: add flush check in udp_gro_receive_segment
  net: gro: fix udp bad offset in socket lookup by adding {inner_}network_offset to napi_gro_cb
  ipv4: Fix uninit-value access in __ip_make_skb()
  s390/qeth: Fix kernel panic after setting hsuid
  vxlan: Pull inner IP header in vxlan_rcv().
  tipc: fix a possible memleak in tipc_buf_append
  tipc: fix UAF in error path
  rxrpc: Clients must accept conn from any address
  net: core: reject skb_copy(_expand) for fraglist GSO skbs
  net: bridge: fix multicast-to-unicast with fraglist GSO
  mptcp: ensure snd_nxt is properly initialized on connect
  e1000e: change usleep_range to udelay in PHY mdic access
  net: dsa: mv88e6xxx: Fix number of databases for 88E6141 / 88E6341
  cxgb4: Properly lock TX queue for the selftest.
  rxrpc: Fix using alignmask being zero for __page_frag_alloc_align()
  vxlan: Add missing VNI filter counter update in arp_reduce().
  vxlan: Fix racy device stats updates.
  net: qede: use return from qede_parse_actions()
  ...
",[''],"This commit merges networking fixes, including BPF-related issues and various other network component corrections.","networking,fixed,BPF",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ac2f438c2a85acd07e0ac7dc2f69d45bda1bb498,ac2f438c2a85acd07e0ac7dc2f69d45bda1bb498,Vadim Fedorenko,vadfed@meta.com,1714582890,Martin KaFai Lau,martin.lau@kernel.org,1714595546,3dc85b54ee0f51405712da26609aa35e413f3017,0737df6de94661ae55fd3343ce9abec32c687e62,"bpf: crypto: fix build when CONFIG_CRYPTO=m

Crypto subsytem can be build as a module. In this case we still have to
build BPF crypto framework otherwise the build will fail.

Fixes: 3e1c6f35409f (""bpf: make common crypto API for TC/XDP programs"")
Reported-by: kernel test robot <lkp@intel.com>
Closes: https://lore.kernel.org/oe-kbuild-all/202405011634.4JK40epY-lkp@intel.com/
Signed-off-by: Vadim Fedorenko <vadfed@meta.com>
Link: https://lore.kernel.org/r/20240501170130.1682309-1-vadfed@meta.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Fix build issue in BPF crypto framework when crypto subsystem is built as a module.,"build, crypto, fix",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['tc/netfilter like programs', 'xdp like programs']"
0737df6de94661ae55fd3343ce9abec32c687e62,0737df6de94661ae55fd3343ce9abec32c687e62,Andrii Nakryiko,andrii@kernel.org,1714537026,Martin KaFai Lau,martin.lau@kernel.org,1714583844,1928d9d9c26c2532e5c56c0d765c1570617c6442,d913aaa990b6024ce815b66e6ce64d88ba2cd0eb,"libbpf: better fix for handling nulled-out struct_ops program

Previous attempt to fix the handling of nulled-out (from skeleton)
struct_ops program is working well only if struct_ops program is defined
as non-autoloaded by default (i.e."," has SEC(""?struct_ops"") annotation","['\nwith question mark).\n\nUnfortunately', ' that fix is incomplete due to how\nbpf_object_adjust_struct_ops_autoload() is marking referenced or\nnon-referenced struct_ops program as autoloaded (or not). Because\nbpf_object_adjust_struct_ops_autoload() is run after\nbpf_map__init_kern_struct_ops() step', ' which sets program slot to NULL', '\nsuch programs won\'t be considered ""referenced""', "" and so its autoload\nproperty won't be changed.\n\nThis all sounds convoluted and it is"", ' but the desire is to have as\nnatural behavior (as far as struct_ops usage is concerned) as possible.\n\nThis fix is redoing the original fix but makes it work for\nautoloaded-by-default struct_ops programs as well. We achieve this by\nforcing prog->autoload to false if prog was declaratively set for some\nstruct_ops map', ' but then nulled-out from skeleton (programmatically).\nThis achieves desired effect of not autoloading it. If such program is\nstill referenced somewhere else (different struct_ops map or different\ncallback field)', ' it will get its autoload property adjusted by\nbpf_object_adjust_struct_ops_autoload() later.\n\nWe also fix selftest', ' which accidentally used SEC(""?struct_ops"")\nannotation. It was meant to use autoload-by-default program from the\nvery beginning.\n\nFixes: f973fccd43d3 (""libbpf: handle nulled-out program in struct_ops correctly"")\nCc: Kui-Feng Lee <thinker.li@gmail.com>\nCc: Eduard Zingerman <eddyz87@gmail.com>\nCc: Martin KaFai Lau <martin.lau@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240501041706.3712608-1-andrii@kernel.org\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Fixes handling of nulled-out struct_ops programs in libbpf for non-autoloaded by default cases.,"libbpf, struct_ops, autoloaded",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d913aaa990b6024ce815b66e6ce64d88ba2cd0eb,d913aaa990b6024ce815b66e6ce64d88ba2cd0eb,Andrii Nakryiko,andrii@kernel.org,1714582428,Andrii Nakryiko,andrii@kernel.org,1714582428,a8820f8570a0b6634fc1f0e84099a18c8fac9137,9a1a2cb5a0e3531d68a2616663ddce49df85dfff 960635887c967338fd567def3e7905a294f5002b,"Merge branch 'libbpf-support-module-function-syntax-for-tracing-programs'

Viktor Malik says:

====================
libbpf: support ""module:function"" syntax for tracing programs

In some situations"," it is useful to explicitly specify a kernel module
to search for a tracing program target (e.g. when a function of the same
name exists in multiple modules or in vmlinux).

This change enables that by allowing the ""module:function"" syntax for
the find_kernel_btf_id function. Thanks to this","["" the syntax can be used\nboth from a SEC macro (i.e. `SEC(fentry/module:function)`) and via the\nbpf_program__set_attach_target API call.\n---\n\nChanges in v2:\n- stylistic changes (suggested by Andrii)\n- added Andrii's ack to the second patch\n====================\n\nLink: https://lore.kernel.org/r/cover.1714469650.git.vmalik@redhat.com\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n"", '']","This commit adds support for ""module:function"" syntax in libbpf for tracing programs.","libbpf, module:function, tracing",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,['tracepoints like programs']
960635887c967338fd567def3e7905a294f5002b,960635887c967338fd567def3e7905a294f5002b,Viktor Malik,vmalik@redhat.com,1714469887,Andrii Nakryiko,andrii@kernel.org,1714582428,a8820f8570a0b6634fc1f0e84099a18c8fac9137,8f8a024272f3e335854515b41638bdf89c6d3146,"selftests/bpf: add tests for the ""module: Function"" syntax

The previous patch added support for the ""module:function"" syntax for
tracing programs. This adds tests for explicitly specifying the module
name via the SEC macro and via the bpf_program__set_attach_target call.

Signed-off-by: Viktor Malik <vmalik@redhat.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/8a076168ed847f7c8a6c25715737b1fea84e38be.1714469650.git.vmalik@redhat.com
",,Add selftests for module:function syntax in tracing programs using SEC macro and bpf_program__set_attach_target.,"selftests,module,function",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tracepoints like programs']
8f8a024272f3e335854515b41638bdf89c6d3146,8f8a024272f3e335854515b41638bdf89c6d3146,Viktor Malik,vmalik@redhat.com,1714469886,Andrii Nakryiko,andrii@kernel.org,1714582427,ebd3594f73d8bd495851b1dc43559d04162656c7,9a1a2cb5a0e3531d68a2616663ddce49df85dfff,"libbpf: support ""module: Function"" syntax for tracing programs

In some situations"," it is useful to explicitly specify a kernel module
to search for a tracing program target (e.g. when a function of the same
name exists in multiple modules or in vmlinux).

This patch enables that by allowing the ""module:function"" syntax for the
find_kernel_btf_id function. Thanks to this","[' the syntax can be used both\nfrom a SEC macro (i.e. `SEC(fentry/module:function)`) and via the\nbpf_program__set_attach_target API call.\n\nSigned-off-by: Viktor Malik <vmalik@redhat.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/9085a8cb9a552de98e554deb22ff7e977d025440.1714469650.git.vmalik@redhat.com\n', '']",The commit adds support for specifying a module for tracing programs using 'module:function' syntax in libbpf.,"libbpf, tracing programs, module function",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['tracepoints like programs', 'kprobe/uprobe/ftrace like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e03c05ac9813410d15c9c39ccf02c84efe563533,e03c05ac9813410d15c9c39ccf02c84efe563533,Andrii Nakryiko,andrii@kernel.org,1713467349,Masami Hiramatsu (Google),mhiramat@kernel.org,1714573128,87dc83a0f32ca2fd563cebeec0a164f8b7ae6ba1,b0e28a4b5becea84ae6fca5cbd8a6b80a134e223,"rethook: honor CONFIG_FTRACE_VALIDATE_RCU_IS_WATCHING in rethook_try_get()

Take into account CONFIG_FTRACE_VALIDATE_RCU_IS_WATCHING when validating
that RCU is watching when trying to setup rethooko on a function entry.

One notable exception when we force rcu_is_watching() check is
CONFIG_KPROBE_EVENTS_ON_NOTRACE=y case"," in which case kretprobes will use
old-style int3-based workflow instead of relying on ftrace","[' making RCU\nwatching check important to validate.\n\nThis further (in addition to improvements in the previous patch)\nimproves BPF multi-kretprobe (which rely on rethook) runtime throughput\nby 2.3%', ' according to BPF benchmarks ([0]).\n\n  [0] https://lore.kernel.org/bpf/CAEf4BzauQ2WKMjZdc9s0rBWa01BYbgwHN6aNDXQSHYia47pQ-w@mail.gmail.com/\n\nLink: https://lore.kernel.org/all/20240418190909.704286-2-andrii@kernel.org/\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Paul E. McKenney <paulmck@kernel.org>\nAcked-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\nSigned-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\n', '']",The commit updates rethook to honor CONFIG_FTRACE_VALIDATE_RCU_IS_WATCHING during function entry validation.,"rethook, ftrace, RCU",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['tracepoints like programs', 'kprobe/uprobe/ftrace like programs']"
b0e28a4b5becea84ae6fca5cbd8a6b80a134e223,b0e28a4b5becea84ae6fca5cbd8a6b80a134e223,Andrii Nakryiko,andrii@kernel.org,1713467348,Masami Hiramatsu (Google),mhiramat@kernel.org,1714573128,436194932eee40c5eced2d6019b6d28287ffaf7a,0dc715295d4143d1659879f7f50ad4e9a6f6a99c,"ftrace: make extra rcu_is_watching() validation check optional

Introduce CONFIG_FTRACE_VALIDATE_RCU_IS_WATCHING config option to
control whether ftrace low-level code performs additional
rcu_is_watching()-based validation logic in an attempt to catch noinstr
violations.

This check is expected to never be true and is mostly useful for
low-level validation of ftrace subsystem invariants. For most users it
should probably be kept disabled to eliminate unnecessary runtime
overhead.

This improves BPF multi-kretprobe (relying on ftrace and rethook
infrastructure) runtime throughput by 2%"," according to BPF benchmarks ([0]).

  [0] https://lore.kernel.org/bpf/CAEf4BzauQ2WKMjZdc9s0rBWa01BYbgwHN6aNDXQSHYia47pQ-w@mail.gmail.com/

Link: https://lore.kernel.org/all/20240418190909.704286-1-andrii@kernel.org/

Cc: Steven Rostedt <rostedt@goodmis.org>
Cc: Masami Hiramatsu <mhiramat@kernel.org>
Cc: Paul E. McKenney <paulmck@kernel.org>
Acked-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>
",[''],Introduce optional CONFIG_FTRACE_VALIDATE_RCU_IS_WATCHING for ftrace rcu_is_watching validation to improve BPF multi-kretprobe performance by 2%.,"ftrace, rcu_is_watching, BPF",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
0dc715295d4143d1659879f7f50ad4e9a6f6a99c,0dc715295d4143d1659879f7f50ad4e9a6f6a99c,Jonathan Haslam,jonathan.haslam@gmail.com,1713781385,Masami Hiramatsu (Google),mhiramat@kernel.org,1714573127,8017d84b919d58f1515473f836593275d07e88a4,5120d167e21c674afd0630c65e7f6a00fa0667f1,"uprobes: reduce contention on uprobes_tree access

Active uprobes are stored in an RB tree and accesses to this tree are
dominated by read operations. Currently these accesses are serialized by
a spinlock but this leads to enormous contention when large numbers of
threads are executing active probes.

This patch converts the spinlock used to serialize access to the
uprobes_tree RB tree into a reader-writer spinlock. This lock type
aligns naturally with the overwhelmingly read-only nature of the tree
usage here. Although the addition of reader-writer spinlocks are
discouraged [0]"," this fix is proposed as an interim solution while an
RCU based approach is implemented (that work is in a nascent form). This
fix also has the benefit of being trivial","[' self contained and therefore\nsimple to backport.\n\nWe have used a uprobe benchmark from the BPF selftests [1] to estimate\nthe improvements. Each block of results below show 1 line per execution\nof the benchmark (""the ""Summary"" line) and each line is a run with one\nmore thread added - a thread is a ""producer"". The lines are edited to\nremove extraneous output.\n\nThe tests were executed with this driver script:\n\nfor num_threads in {1..20}\ndo\n  sudo ./bench -a -p $num_threads trig-uprobe-nop | grep Summary\ndone\n\nSPINLOCK (BEFORE)\n==================\nSummary: hits    1.396 ± 0.007M/s (  1.396M/prod)\nSummary: hits    1.656 ± 0.016M/s (  0.828M/prod)\nSummary: hits    2.246 ± 0.008M/s (  0.749M/prod)\nSummary: hits    2.114 ± 0.010M/s (  0.529M/prod)\nSummary: hits    2.013 ± 0.009M/s (  0.403M/prod)\nSummary: hits    1.753 ± 0.008M/s (  0.292M/prod)\nSummary: hits    1.847 ± 0.001M/s (  0.264M/prod)\nSummary: hits    1.889 ± 0.001M/s (  0.236M/prod)\nSummary: hits    1.833 ± 0.006M/s (  0.204M/prod)\nSummary: hits    1.900 ± 0.003M/s (  0.190M/prod)\nSummary: hits    1.918 ± 0.006M/s (  0.174M/prod)\nSummary: hits    1.925 ± 0.002M/s (  0.160M/prod)\nSummary: hits    1.837 ± 0.001M/s (  0.141M/prod)\nSummary: hits    1.898 ± 0.001M/s (  0.136M/prod)\nSummary: hits    1.799 ± 0.016M/s (  0.120M/prod)\nSummary: hits    1.850 ± 0.005M/s (  0.109M/prod)\nSummary: hits    1.816 ± 0.002M/s (  0.101M/prod)\nSummary: hits    1.787 ± 0.001M/s (  0.094M/prod)\nSummary: hits    1.764 ± 0.002M/s (  0.088M/prod)\n\nRW SPINLOCK (AFTER)\n===================\nSummary: hits    1.444 ± 0.020M/s (  1.444M/prod)\nSummary: hits    2.279 ± 0.011M/s (  1.139M/prod)\nSummary: hits    3.422 ± 0.014M/s (  1.141M/prod)\nSummary: hits    3.565 ± 0.017M/s (  0.891M/prod)\nSummary: hits    2.671 ± 0.013M/s (  0.534M/prod)\nSummary: hits    2.409 ± 0.005M/s (  0.401M/prod)\nSummary: hits    2.485 ± 0.008M/s (  0.355M/prod)\nSummary: hits    2.496 ± 0.003M/s (  0.312M/prod)\nSummary: hits    2.585 ± 0.002M/s (  0.287M/prod)\nSummary: hits    2.908 ± 0.011M/s (  0.291M/prod)\nSummary: hits    2.346 ± 0.016M/s (  0.213M/prod)\nSummary: hits    2.804 ± 0.004M/s (  0.234M/prod)\nSummary: hits    2.556 ± 0.001M/s (  0.197M/prod)\nSummary: hits    2.754 ± 0.004M/s (  0.197M/prod)\nSummary: hits    2.482 ± 0.002M/s (  0.165M/prod)\nSummary: hits    2.412 ± 0.005M/s (  0.151M/prod)\nSummary: hits    2.710 ± 0.003M/s (  0.159M/prod)\nSummary: hits    2.826 ± 0.005M/s (  0.157M/prod)\nSummary: hits    2.718 ± 0.001M/s (  0.143M/prod)\nSummary: hits    2.844 ± 0.006M/s (  0.142M/prod)\n\nThe numbers in parenthesis give averaged throughput per thread which is\nof greatest interest here as a measure of scalability. Improvements are\nin the order of 22 - 68% with this particular benchmark (mean = 43%).\n\nV2:\n - Updated commit message to include benchmark results.\n\n[0] https://docs.kernel.org/locking/spinlocks.html\n[1] https://github.com/torvalds/linux/blob/master/tools/testing/selftests/bpf/benchs/bench_trigger.c\n\nLink: https://lore.kernel.org/all/20240422102306.6026-1-jonathan.haslam@gmail.com/\n\nSigned-off-by: Jonathan Haslam <jonathan.haslam@gmail.com>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\n', '']",Convert spinlock on uprobes_tree to reader-writer spinlock to reduce contention for read-heavy operations.,"uprobes, contention, spinlock",It's a performance optimization.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
5120d167e21c674afd0630c65e7f6a00fa0667f1,5120d167e21c674afd0630c65e7f6a00fa0667f1,Kui-Feng Lee,thinker.li@gmail.com,1712598700,Masami Hiramatsu (Google),mhiramat@kernel.org,1714573127,982f06455fc8b5c7c659e351b4039aa16151e03e,73142cab3af1b99157837297f437b306d7a70bff,"rethook: Remove warning messages printed for finding return address of a frame.

The function rethook_find_ret_addr() prints a warning message and returns 0
when the target task is running and is not the ""current"" task in order to
prevent the incorrect return address"," although it still may return an
incorrect address.

However","[' the warning message turns into noise when BPF profiling programs\ncall bpf_get_task_stack() on running tasks in a firm with a large number of\nhosts.\n\nThe callers should be aware and willing to take the risk of receiving an\nincorrect return address from a task that is currently running other than\nthe ""current"" one. A warning is not needed here as the callers are intent\non it.\n\nLink: https://lore.kernel.org/all/20240408175140.60223-1-thinker.li@gmail.com/\n\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nSigned-off-by: Kui-Feng Lee <thinker.li@gmail.com>\nSigned-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\n', '']",The commit removes warning messages in rethook for finding the return address of a frame when the target task is not the current task.,"rethook, warning, return address",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['other']
cdf355cc60e388d992bdd205b8ee70dc4d533461,cdf355cc60e388d992bdd205b8ee70dc4d533461,Andrii Nakryiko,andrii@kernel.org,1710785848,Masami Hiramatsu (Google),mhiramat@kernel.org,1714573126,5532a4cd8753e22e94eb290b27f5fe4c7ec15c5b,1b8f85defbc82e2eb8f27c5f6060ea507ad4d5a3,"uprobes: add speculative lockless system-wide uprobe filter check

It's very common with BPF-based uprobe/uretprobe use cases to have
a system-wide (not PID specific) probes used. In this case uprobe's
trace_uprobe_filter->nr_systemwide counter is bumped at registration
time"," and actual filtering is short circuited at the time when
uprobe/uretprobe is triggered.

This is a great optimization","["" and the only issue with it is that to even\nget to checking this counter uprobe subsystem is taking\nread-side trace_uprobe_filter->rwlock. This is actually noticeable in\nprofiles and is just another point of contention when uprobe is\ntriggered on multiple CPUs simultaneously.\n\nThis patch moves this nr_systemwide check outside of filter list's\nrwlock scope"", ' as rwlock is meant to protect list modification', ' while\nnr_systemwide-based check is speculative and racy already', ' despite the\nlock (as discussed in [0]). trace_uprobe_filter_remove() and\ntrace_uprobe_filter_add() already check for filter->nr_systewide\nexplicitly outside of __uprobe_perf_filter', "" so no modifications are\nrequired there.\n\nConfirming with BPF selftests's based benchmarks.\n\nBEFORE (based on changes in previous patch)\n===========================================\nuprobe-nop     :    2.732 ± 0.022M/s\nuprobe-push    :    2.621 ± 0.016M/s\nuprobe-ret     :    1.105 ± 0.007M/s\nuretprobe-nop  :    1.396 ± 0.007M/s\nuretprobe-push :    1.347 ± 0.008M/s\nuretprobe-ret  :    0.800 ± 0.006M/s\n\nAFTER\n=====\nuprobe-nop     :    2.878 ± 0.017M/s (+5.5%"", ' total +8.3%)\nuprobe-push    :    2.753 ± 0.013M/s (+5.3%', ' total +10.2%)\nuprobe-ret     :    1.142 ± 0.010M/s (+3.8%', ' total +3.8%)\nuretprobe-nop  :    1.444 ± 0.008M/s (+3.5%', ' total +6.5%)\nuretprobe-push :    1.410 ± 0.010M/s (+4.8%', ' total +7.1%)\nuretprobe-ret  :    0.816 ± 0.002M/s (+2.0%', ' total +3.9%)\n\nIn the above', ' first percentage value is based on top of previous patch\n(lazy uprobe buffer optimization)', ' while the ""total"" percentage is\nbased on kernel without any of the changes in this patch set.\n\nAs can be seen', ' we get about 4% - 10% speed up', ' in total', ' with both lazy\nuprobe buffer and speculative filter check optimizations.\n\n  [0] https://lore.kernel.org/bpf/20240313131926.GA19986@redhat.com/\n\nReviewed-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/all/20240318181728.2795838-4-andrii@kernel.org/\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\nSigned-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\n', '']",Introduces speculative lockless system-wide filtering for BPF-based uprobes for performance optimization.,"uprobes, system-wide, optimization",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
1b8f85defbc82e2eb8f27c5f6060ea507ad4d5a3,1b8f85defbc82e2eb8f27c5f6060ea507ad4d5a3,Andrii Nakryiko,andrii@kernel.org,1710785847,Masami Hiramatsu (Google),mhiramat@kernel.org,1714573126,07ba60c9a2b07086f551ef79064a42a40e0e32cf,3eaea21b4d27cff0017c20549aeb53034c58fc23,"uprobes: prepare uprobe args buffer lazily

uprobe_cpu_buffer and corresponding logic to store uprobe args into it
are used for uprobes/uretprobes that are created through tracefs or
perf events.

BPF is yet another user of uprobe/uretprobe infrastructure"," but doesn't
need uprobe_cpu_buffer and associated data. For BPF-only use cases this
buffer handling and preparation is a pure overhead. At the same time","['\nBPF-only uprobe/uretprobe usage is very common in practice. Also', ' for\na lot of cases applications are very senstivie to performance overheads', '\nas they might be tracing a very high frequency functions like\nmalloc()/free()', ' so every bit of performance improvement matters.\n\nAll that is to say that this uprobe_cpu_buffer preparation is an\nunnecessary overhead that each BPF user of uprobes/uretprobe has to pay.\nThis patch is changing this by making uprobe_cpu_buffer preparation\noptional. It will happen only if either tracefs-based or perf event-based\nuprobe/uretprobe consumer is registered for given uprobe/uretprobe. For\nBPF-only use cases this step will be skipped.\n\nWe used uprobe/uretprobe benchmark which is part of BPF selftests (see [0])\nto estimate the improvements. We have 3 uprobe and 3 uretprobe\nscenarios', ' which vary an instruction that is replaced by uprobe: nop\n(fastest uprobe case)', ' `push rbp` (typical case)', ' and non-simulated\n`ret` instruction (slowest case). Benchmark thread is constantly calling\nuser space function in a tight loop. User space function has attached\nBPF uprobe or uretprobe program doing nothing but atomic counter\nincrements to count number of triggering calls. Benchmark emits\nthroughput in millions of executions per second.\n\nBEFORE these changes\n====================\nuprobe-nop     :    2.657 ± 0.024M/s\nuprobe-push    :    2.499 ± 0.018M/s\nuprobe-ret     :    1.100 ± 0.006M/s\nuretprobe-nop  :    1.356 ± 0.004M/s\nuretprobe-push :    1.317 ± 0.019M/s\nuretprobe-ret  :    0.785 ± 0.007M/s\n\nAFTER these changes\n===================\nuprobe-nop     :    2.732 ± 0.022M/s (+2.8%)\nuprobe-push    :    2.621 ± 0.016M/s (+4.9%)\nuprobe-ret     :    1.105 ± 0.007M/s (+0.5%)\nuretprobe-nop  :    1.396 ± 0.007M/s (+2.9%)\nuretprobe-push :    1.347 ± 0.008M/s (+2.3%)\nuretprobe-ret  :    0.800 ± 0.006M/s (+1.9)\n\nSo the improvements on this particular machine seems to be between 2% and 5%.\n\n  [0] https://github.com/torvalds/linux/blob/master/tools/testing/selftests/bpf/benchs/bench_trigger.c\n\nReviewed-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/all/20240318181728.2795838-3-andrii@kernel.org/\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\nSigned-off-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\n', '']",Lazily prepare uprobe args buffer to optimize BPF use cases.,"uprobe,args,BPF",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
02b670c1f88e78f42a6c5aee155c7b26960ca054,02b670c1f88e78f42a6c5aee155c7b26960ca054,Linus Torvalds,torvalds@linux-foundation.org,1714377651,Ingo Molnar,mingo@kernel.org,1714549303,063bf87a22571419fb0eb304bb947b283e61cdd7,720a22fd6c1cdadf691281909950c0cbc5cdf17e,"x86/mm: Remove broken vsyscall emulation code from the page fault code

The syzbot-reported stack trace from hell in this discussion thread
actually has three nested page faults:

  https://lore.kernel.org/r/000000000000d5f4fc0616e816d4@google.com

... and I think that's actually the important thing here:

 - the first page fault is from user space"," and triggers the vsyscall
   emulation.

 - the second page fault is from __do_sys_gettimeofday()","[' and that should\n   just have caused the exception that then sets the return value to\n   -EFAULT\n\n - the third nested page fault is due to _raw_spin_unlock_irqrestore() ->\n   preempt_schedule() -> trace_sched_switch()', ' which then causes a BPF\n   trace program to run', ' which does that bpf_probe_read_compat()', "" which\n   causes that page fault under pagefault_disable().\n\nIt's quite the nasty backtrace"", "" and there's a lot going on.\n\nThe problem is literally the vsyscall emulation"", "" which sets\n\n        current->thread.sig_on_uaccess_err = 1;\n\nand that causes the fixup_exception() code to send the signal *despite* the\nexception being caught.\n\nAnd I think that is in fact completely bogus.  It's completely bogus\nexactly because it sends that signal even when it *shouldn't* be sent -\nlike for the BPF user mode trace gathering.\n\nIn other words"", ' I think the whole ""sig_on_uaccess_err"" thing is entirely\nbroken', ' because it makes any nested page-faults do all the wrong things.\n\nNow', ' arguably', "" I don't think anybody should enable vsyscall emulation any\nmore"", ' but this test case clearly does.\n\nI think we should just make the ""send SIGSEGV"" be something that the\nvsyscall emulation does on its own', ' not this broken per-thread state for\nsomething that isn\'t actually per thread.\n\nThe x86 page fault code actually tried to deal with the ""incorrect nesting""\nby having that:\n\n                if (in_interrupt())\n                        return;\n\nwhich ignores the sig_on_uaccess_err case when it happens in interrupts', '\nbut as shown by this example', ' these nested page faults do not need to be\nabout interrupts at all.\n\nIOW', ' I think the only right thing is to remove that horrendously broken\ncode.\n\nThe attached patch looks like the ObviouslyCorrect(tm) thing to do.\n\nNOTE! This broken code goes back to this commit in 2011:\n\n  4fc3490114bb (""x86-64: Set siginfo and context on vsyscall emulation faults"")\n\n... and back then the reason was to get all the siginfo details right.\nHonestly', "" I do not for a moment believe that it's worth getting the siginfo\ndetails right here"", ' but part of the commit says:\n\n    This fixes issues with UML when vsyscall=emulate.\n\n... and so my patch to remove this garbage will probably break UML in this\nsituation.\n\nI do not believe that anybody should be running with vsyscall=emulate in\n2024 in the first place', "" much less if you are doing things like UML. But\nlet's see if somebody screams.\n\nReported-and-tested-by: syzbot+83e7f982ca045ab4405c@syzkaller.appspotmail.com\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>\nSigned-off-by: Ingo Molnar <mingo@kernel.org>\nTested-by: Jiri Olsa <jolsa@kernel.org>\nAcked-by: Andy Lutomirski <luto@kernel.org>\nLink: https://lore.kernel.org/r/CAHk-=wh9D6f7HUkDgZHKmDCHUQmp+Co89GP+b8+z+G56BKeyNg@mail.gmail.com\n"", '']",The commit removes broken vsyscall emulation code from x86 page fault handling.,"vsyscall, emulation, x86",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
8405e6980f21e2b75f232e970edd76bc50cf1491,8405e6980f21e2b75f232e970edd76bc50cf1491,Geliang Tang,tanggeliang@kylinos.cn,1714015423,Martin KaFai Lau,martin.lau@kernel.org,1714518090,ac0583a8b1aab0fd602c83895039ac11a0675f7c,044032ee6c4e786746058aaf5527be13e831cc5c,"selftests/bpf: Drop start_server_proto helper

Protocol can be set by __start_server() helper directly now"," this makes
the heler start_server_proto() useless.

This patch drops it","[' and implenments start_server() using make_sockaddr()\nand __start_server().\n\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nLink: https://lore.kernel.org/r/55d8a04e0bb8240a5fda2da3e9bdffe6fc8547b2.1714014697.git.tanggeliang@kylinos.cn\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",This commit removes the now redundant start_server_proto helper in bpf selftests.,"remove,redundant,selftests",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
044032ee6c4e786746058aaf5527be13e831cc5c,044032ee6c4e786746058aaf5527be13e831cc5c,Geliang Tang,tanggeliang@kylinos.cn,1714015422,Martin KaFai Lau,martin.lau@kernel.org,1714518090,feea09398229788574db961ffc1fb5c8718e5e00,95b88500b97ca8bafc0b9c8e79e9716c2ddc40c6,"selftests/bpf: Make start_mptcp_server static

start_mptcp_server() shouldn't be a public helper"," it only be used in
MPTCP tests. This patch moves it into prog_tests/mptcp.c","[' and implenments\nit using make_sockaddr() and start_server_addr() instead of using\nstart_server_proto().\n\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nLink: https://lore.kernel.org/r/50ec7049e280c60a2924937940851f8fee2b73b8.1714014697.git.tanggeliang@kylinos.cn\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",The commit makes start_mptcp_server a static function specific to MPTCP tests.,"static,function,MPTCP",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
95b88500b97ca8bafc0b9c8e79e9716c2ddc40c6,95b88500b97ca8bafc0b9c8e79e9716c2ddc40c6,Geliang Tang,tanggeliang@kylinos.cn,1714015421,Martin KaFai Lau,martin.lau@kernel.org,1714518090,31466fbbc5903bee849809166e39f20b671ae732,06ebfd11678ad63cfd7021580e13d1582ee6c782,"selftests/bpf: Add opts argument for __start_server

This patch adds network_helper_opts parameter for __start_server()
instead of ""int protocol"" and ""int timeout_ms"". This not only reduces
the number of parameters"," but also makes it more flexible.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/127d2f0929980b41f757dcfebe1b667e6bfb43f1.1714014697.git.tanggeliang@kylinos.cn
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],This commit adds a flexible opts argument for the __start_server function in selftests/bpf.,"opts, __start_server, selftests",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
3e9bc0472b910d4115e16e9c2d684c7757cb6c60,3e9bc0472b910d4115e16e9c2d684c7757cb6c60,Martin KaFai Lau,martin.lau@kernel.org,1714499018,Martin KaFai Lau,martin.lau@kernel.org,1714499144,b874cd1679811cd8b572d84a8de80369f14528bb,b867247555c4181bf84eb10b72b176862c29112d 095ddb501b39b7842e5da555915ad89e370b9888,"Merge branch 'bpf: Add BPF_PROG_TYPE_CGROUP_SKB attach type enforcement in BPF_LINK_CREATE'

Stanislav Fomichev says:

====================
Syzkaller found a case where it's possible to attach cgroup_skb program
to the sockopt hooks. Apparently it's currently possible to do that","
but only when using BPF_LINK_CREATE API. The first patch in the series
has more info on why that happens.
====================

Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Adds enforcement for BPF_PROG_TYPE_CGROUP_SKB attach type in BPF_LINK_CREATE API.,"BPF_LINK_CREATE, attach type, cgroup_skb",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The syscall interface,['cgroup like programs']
095ddb501b39b7842e5da555915ad89e370b9888,095ddb501b39b7842e5da555915ad89e370b9888,Stanislav Fomichev,sdf@google.com,1714173380,Martin KaFai Lau,martin.lau@kernel.org,1714499017,b874cd1679811cd8b572d84a8de80369f14528bb,d70b2660e75b85bdaa9d75f9c4224c2f6f89cf23,"selftests/bpf: Add sockopt case to verify prog_type

Make sure only sockopt programs can be attached to the setsockopt
and getsockopt hooks.

Signed-off-by: Stanislav Fomichev <sdf@google.com>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20240426231621.2716876-4-sdf@google.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Added sockopt test case to ensure only sockopt programs attach to setsockopt/getsockopt hooks.,"sockopt,test case,prog_type",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
d70b2660e75b85bdaa9d75f9c4224c2f6f89cf23,d70b2660e75b85bdaa9d75f9c4224c2f6f89cf23,Stanislav Fomichev,sdf@google.com,1714173379,Martin KaFai Lau,martin.lau@kernel.org,1714499017,cb3eed3fda2e2255c69b4cd992882e7e7b48141f,543576ec15b17c0c93301ac8297333c7b6e84ac7,"selftests/bpf: Extend sockopt tests to use BPF_LINK_CREATE

Run all existing test cases with the attachment created via
BPF_LINK_CREATE. Next commit will add extra test cases to verify
link_create attach_type enforcement.

Signed-off-by: Stanislav Fomichev <sdf@google.com>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20240426231621.2716876-3-sdf@google.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Extend existing BPF sockopt tests to utilize BPF_LINK_CREATE for attachment.,"selftests,bpf,BPF_LINK_CREATE",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
543576ec15b17c0c93301ac8297333c7b6e84ac7,543576ec15b17c0c93301ac8297333c7b6e84ac7,Stanislav Fomichev,sdf@google.com,1714173378,Martin KaFai Lau,martin.lau@kernel.org,1714499017,9ee27656356c0a9d30f53a807ef9f42a931f5c00,b867247555c4181bf84eb10b72b176862c29112d,"bpf: Add BPF_PROG_TYPE_CGROUP_SKB attach type enforcement in BPF_LINK_CREATE

bpf_prog_attach uses attach_type_to_prog_type to enforce proper
attach type for BPF_PROG_TYPE_CGROUP_SKB. link_create uses
bpf_prog_get and relies on bpf_prog_attach_check_attach_type
to properly verify prog_type <> attach_type association.

Add missing attach_type enforcement for the link_create case.
Otherwise"," it's currently possible to attach cgroup_skb prog
types to other cgroup hooks.

Fixes: af6eea57437a (""bpf: Implement bpf_link-based cgroup BPF program attachment"")
Link: https://lore.kernel.org/bpf/0000000000004792a90615a1dde0@google.com/
Reported-by: syzbot+838346b979830606c854@syzkaller.appspotmail.com
Signed-off-by: Stanislav Fomichev <sdf@google.com>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20240426231621.2716876-2-sdf@google.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],This commit enforces attach type verification for cgroup_skb programs in BPF_LINK_CREATE.,"attach type, cgroup_skb, link_create",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['cgroup like programs']
06ebfd11678ad63cfd7021580e13d1582ee6c782,06ebfd11678ad63cfd7021580e13d1582ee6c782,Andrii Nakryiko,andrii@kernel.org,1714495554,Andrii Nakryiko,andrii@kernel.org,1714497807,b575361002db6d53f2840aa2562b19dac72f64fc,05cbc217aafbc631a6c2fab4accf95850cb48358 a3a5113393ccfad2eb23ca091aa6e55b5bd67eb4,"Merge branch 'bpf-introduce-kprobe_multi-session-attach'

Jiri Olsa says:

====================
bpf: Introduce kprobe_multi session attach

hi","
adding support to attach kprobe program through kprobe_multi link
in a session mode","[' which means:\n  - program is attached to both function entry and return\n  - entry program can decided if the return program gets executed\n  - entry program can share u64 cookie value with return program\n\nThe initial RFC for this was posted in [0] and later discussed more\nand which ended up with the session idea [1]\n\nHaving entry together with return probe for given function is common\nuse case for tetragon', ' bpftrace and most likely for others.\n\nAt the moment if we want both entry and return probe to execute bpf\nprogram we need to create two (entry and return probe) links. The link\nfor return probe creates extra entry probe to setup the return probe.\nThe extra entry probe execution could be omitted if we had a way to\nuse just single link for both entry and exit probe.\n\nIn addition the possibility to control the return program execution\nand sharing data within entry and return probe allows for other use\ncases.\n\nv2 changes:\n  - renamed BPF_TRACE_KPROBE_MULTI_SESSION to BPF_TRACE_KPROBE_SESSION\n    [Andrii]\n  - use arrays for results in selftest [Andrii]\n  - various small selftests and libbpf changes [Andrii]\n  - moved the verifier cookie setup earlier in check_kfunc_call [Andrii]\n  - added acks\n\nAlso available at:\n  https://git.kernel.org/pub/scm/linux/kernel/git/jolsa/perf.git\n  bpf/session_data\n\nthanks', '\njirka\n\n[0] https://lore.kernel.org/bpf/20240207153550.856536-1-jolsa@kernel.org/\n[1] https://lore.kernel.org/bpf/20240228090242.4040210-1-jolsa@kernel.org/\n---\n====================\n\nLink: https://lore.kernel.org/r/20240430112830.1184228-1-jolsa@kernel.org\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n', '']",Introduce support for attaching kprobe programs using kprobe_multi in session mode.,"kprobe, session, attach",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
a3a5113393ccfad2eb23ca091aa6e55b5bd67eb4,a3a5113393ccfad2eb23ca091aa6e55b5bd67eb4,Jiri Olsa,jolsa@kernel.org,1714476510,Andrii Nakryiko,andrii@kernel.org,1714497805,b575361002db6d53f2840aa2562b19dac72f64fc,0983b1697aefbf69f465f907b934b89bbce467ea,"selftests/bpf: Add kprobe session cookie test

Adding kprobe session test that verifies the cookie value
get properly propagated from entry to return program.

Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240430112830.1184228-8-jolsa@kernel.org
",,Add a kprobe selftest to verify cookie propagation from entry to return program.,"kprobe,selftest,cookie",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
0983b1697aefbf69f465f907b934b89bbce467ea,0983b1697aefbf69f465f907b934b89bbce467ea,Jiri Olsa,jolsa@kernel.org,1714476509,Andrii Nakryiko,andrii@kernel.org,1714497781,283de1dbd8467acb6090369c5cc5dc71fb3c6371,7b94965429f2fa32a83e1275c6bf6ed0add08603,"selftests/bpf: Add kprobe session test

Adding kprobe session test and testing that the entry program
return value controls execution of the return probe program.

Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240430112830.1184228-7-jolsa@kernel.org
",,Add test case for kprobe session to verify entry program's control over return probe execution.,"kprobe,test,session",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
7b94965429f2fa32a83e1275c6bf6ed0add08603,7b94965429f2fa32a83e1275c6bf6ed0add08603,Jiri Olsa,jolsa@kernel.org,1714476508,Andrii Nakryiko,andrii@kernel.org,1714495553,92edffe018c8abf1adce83fe45250bb7ce80d067,2ca178f02b2f4e523e970894def16282e4adbc39,"libbpf: Add kprobe session attach type name to attach_type_name

Adding kprobe session attach type name to attach_type_name","
so libbpf_bpf_attach_type_str returns proper string name for
BPF_TRACE_KPROBE_SESSION attach type.

Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240430112830.1184228-6-jolsa@kernel.org
",[''],Add kprobe session attach type name to attach_type_name in libbpf.,"libbpf,kprobe,attach type",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,['kprobe/uprobe/ftrace like programs']
2ca178f02b2f4e523e970894def16282e4adbc39,2ca178f02b2f4e523e970894def16282e4adbc39,Jiri Olsa,jolsa@kernel.org,1714476507,Andrii Nakryiko,andrii@kernel.org,1714495553,d4e662ddc8bf58b47007e8da3e2ee2c2853e337a,5c919acef85147886eb2abf86fb147f94680a8b0,"libbpf: Add support for kprobe session attach

Adding support to attach program in kprobe session mode
with bpf_program__attach_kprobe_multi_opts function.

Adding session bool to bpf_kprobe_multi_opts struct that allows
to load and attach the bpf program via kprobe session.
the attachment to create kprobe multi session.

Also adding new program loader section that allows:
 SEC(""kprobe.session/bpf_fentry_test*"")

and loads/attaches kprobe program as kprobe session.

Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240430112830.1184228-5-jolsa@kernel.org
",,Add support for kprobe session mode attachment to bpf programs with new loader section and options.,"kprobe, session, attach",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,['kprobe/uprobe/ftrace like programs']
5c919acef85147886eb2abf86fb147f94680a8b0,5c919acef85147886eb2abf86fb147f94680a8b0,Jiri Olsa,jolsa@kernel.org,1714476506,Andrii Nakryiko,andrii@kernel.org,1714495553,045b9f1176ff8ddecdf9fe1b31f2b7e19aa4aa16,adf46d88ae4b2557f7e2e02547a25fb866935711,"bpf: Add support for kprobe session cookie

Adding support for cookie within the session of kprobe multi
entry and return program.

The session cookie is u64 value and can be retrieved be new
kfunc bpf_session_cookie"," which returns pointer to the cookie
value. The bpf program can use the pointer to store (on entry)
and load (on return) the value.

The cookie value is implemented via fprobe feature that allows
to share values between entry and return ftrace fprobe callbacks.

Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240430112830.1184228-4-jolsa@kernel.org
",[''],This commit adds support for a session cookie in kprobe programs using fprobe to share values between entry and return callbacks.,"kprobe, session cookie, fprobe",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
adf46d88ae4b2557f7e2e02547a25fb866935711,adf46d88ae4b2557f7e2e02547a25fb866935711,Jiri Olsa,jolsa@kernel.org,1714476505,Andrii Nakryiko,andrii@kernel.org,1714495553,aa4dd40c1ba688087885a2d0374c790aad2b23ac,535a3692ba7245792e6f23654507865d4293c850,"bpf: Add support for kprobe session context

Adding struct bpf_session_run_ctx object to hold session related
data"," which is atm is_return bool and data pointer coming in
following changes.

Placing bpf_session_run_ctx layer in between bpf_run_ctx and
bpf_kprobe_multi_run_ctx so the session data can be retrieved
regardless of if it's kprobe_multi or uprobe_multi link","[' which\nsupport is coming in future. This way both kprobe_multi and\nuprobe_multi can use same kfuncs to access the session data.\n\nAdding bpf_session_is_return kfunc that returns true if the\nbpf program is executed from the exit probe of the kprobe multi\nlink attached in wrapper mode. It returns false otherwise.\n\nAdding new kprobe hook for kprobe program type.\n\nSigned-off-by: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240430112830.1184228-3-jolsa@kernel.org\n', '']",The commit adds kprobe session context support by introducing struct bpf_session_run_ctx for session data management.,"kprobe, session, context",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['kprobe/uprobe/ftrace like programs']
535a3692ba7245792e6f23654507865d4293c850,535a3692ba7245792e6f23654507865d4293c850,Jiri Olsa,jolsa@kernel.org,1714476504,Andrii Nakryiko,andrii@kernel.org,1714495553,7352550565832f6ebad9e0e333c9857821e624dc,05cbc217aafbc631a6c2fab4accf95850cb48358,"bpf: Add support for kprobe session attach

Adding support to attach bpf program for entry and return probe
of the same function. This is common use case which at the moment
requires to create two kprobe multi links.

Adding new BPF_TRACE_KPROBE_SESSION attach type that instructs
kernel to attach single link program to both entry and exit probe.

It's possible to control execution of the bpf program on return
probe simply by returning zero or non zero from the entry bpf
program execution to execute or not the bpf program on return
probe respectively.

Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240430112830.1184228-2-jolsa@kernel.org
",,Add support for attaching BPF programs to both entry and return kprobe sessions with a single link.,"kprobe,BPF,attach",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
32a4ca1361d7a51e5003d4af4dfbf570f1b5fd00,32a4ca1361d7a51e5003d4af4dfbf570f1b5fd00,Jakub Kicinski,kuba@kernel.org,1714401863,Jakub Kicinski,kuba@kernel.org,1714490132,ae88dade4a4cc727704e96456e9c090eee7329c2,ff4b2bfa63bd07cca35f6e704dc5035650595950,"selftests: net: py: extract tool logic

The main use of the ip() wrapper over cmd() is that it can parse JSON.
cmd(""ip -j link show"") will return stdout as a string"," and test has
to call json.loads(). With ip(""link show""","[' json=True) the return value\nwill be already parsed.\n\nMore tools (ethtool', ' bpftool etc.) support the --json switch.\nTo avoid having to wrap all of them individually create a tool()\nhelper.\n\nSwitch from -j to --json (for ethtool).\nWhile at it consume the netns attribute at the ip() level.\n\nReviewed-by: Willem de Bruijn <willemb@google.com>\nLink: https://lore.kernel.org/r/20240429144426.743476-4-kuba@kernel.org\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Refactor selftests to improve JSON parsing by extracting tool logic into the ip() wrapper.,"selftests, JSON, wrapper",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
05cbc217aafbc631a6c2fab4accf95850cb48358,05cbc217aafbc631a6c2fab4accf95850cb48358,Benjamin Tissoires,bentiss@kernel.org,1714473806,Daniel Borkmann,daniel@iogearbox.net,1714487338,7a6b3c7b3b4ba041afba675efe19bebefaa878ce,a891711d0166133ec5120615fcf365d9745d82b2,"selftests/bpf: Drop an unused local variable

Some copy/paste leftover"," this is never used.

Fixes: e3d9eac99afd (""selftests/bpf: wq: add bpf_wq_init() checks"")
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>
Link: https://lore.kernel.org/bpf/20240430-bpf-next-v3-3-27afe7f3b17c@kernel.org
",[''],The commit removes an unused local variable in selftests/bpf.,"unused variable, selftests, cleanup",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
a891711d0166133ec5120615fcf365d9745d82b2,a891711d0166133ec5120615fcf365d9745d82b2,Benjamin Tissoires,bentiss@kernel.org,1714473805,Daniel Borkmann,daniel@iogearbox.net,1714487326,7011e016746a27dcc06228506e6d2d6ab806ff9b,b98a5c68ccaa94e93b9e898091fe2cf21c1500e6,"bpf: Do not walk twice the hash map on free

If someone stores both a timer and a workqueue in a hash map", on free,"[' we\nwould walk it twice.\n\nAdd a check in htab_free_malloced_timers_or_wq and free the timers and\nworkqueues if they are present.\n\nFixes: 246331e3f1ea (""bpf: allow struct bpf_wq to be embedded in arraymaps and hashmaps"")\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nLink: https://lore.kernel.org/bpf/20240430-bpf-next-v3-2-27afe7f3b17c@kernel.org\n', '']",Optimize hash map free operation to prevent double walking in bpf subsystem.,"hash map, bpf, optimize",It's a performance optimization.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b98a5c68ccaa94e93b9e898091fe2cf21c1500e6,b98a5c68ccaa94e93b9e898091fe2cf21c1500e6,Benjamin Tissoires,bentiss@kernel.org,1714473804,Daniel Borkmann,daniel@iogearbox.net,1714487313,1d966ca8b4a480aaa183bc5d1eb2759645af885a,1bba3b3d373dbafae891e7cb06b8c82c8d62aba1,"bpf: Do not walk twice the map on free

If someone stores both a timer and a workqueue in a map"," on free
we would walk it twice.

Add a check in array_map_free_timers_wq and free the timers and
workqueues if they are present.

Fixes: 246331e3f1ea (""bpf: allow struct bpf_wq to be embedded in arraymaps and hashmaps"")
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>
Link: https://lore.kernel.org/bpf/20240430-bpf-next-v3-1-27afe7f3b17c@kernel.org
",[''],Prevent twice traversal of map containing timers and workqueues during free operation in eBPF.,"map,free,twice",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['other']
1bba3b3d373dbafae891e7cb06b8c82c8d62aba1,1bba3b3d373dbafae891e7cb06b8c82c8d62aba1,Andrii Nakryiko,andrii@kernel.org,1714273794,Martin KaFai Lau,martin.lau@kernel.org,1714434513,a0dbfaaf0e1970a93b7b2536632329019a219d49,f973fccd43d34b096077d5d21d051ef75b22a7ea,"selftests/bpf: validate nulled-out struct_ops program is handled properly

Add a selftests validating that it's possible to have some struct_ops
callback set declaratively"," then disable it (by setting to NULL)
programmatically. Libbpf should detect that such program should
not be loaded. Otherwise","[' it will unnecessarily fail the loading\nwhen the host kernel does not have the type information.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240428030954.3918764-2-andrii@kernel.org\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Added selftests to ensure struct_ops program handles nulled-out callbacks properly in libbpf.,"selftests, struct_ops, libbpf",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f973fccd43d34b096077d5d21d051ef75b22a7ea,f973fccd43d34b096077d5d21d051ef75b22a7ea,Andrii Nakryiko,andrii@kernel.org,1714273793,Martin KaFai Lau,martin.lau@kernel.org,1714434366,9cd7d6ace7c93aedc960a429e91ed40d45e8bcf4,cfd3bfe9507b4aa39f7e86772e60b50b799e490e,"libbpf: handle nulled-out program in struct_ops correctly

If struct_ops has one of program callbacks set declaratively and host
kernel is old and doesn't support this callback"," libbpf will allow to
load such struct_ops as long as that callback was explicitly nulled-out
(presumably through skeleton). This is all working correctly","["" except we\nwon't reset corresponding program slot to NULL before bailing out"", ' which\nwill lead to libbpf not detecting that BPF program has to be not\nauto-loaded. Fix this by unconditionally resetting corresponding program\nslot to NULL.\n\nFixes: c911fc61a7ce (""libbpf: Skip zeroed or null fields if not found in the kernel type."")\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240428030954.3918764-1-andrii@kernel.org\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Ensure libbpf handles nulled-out program callbacks in struct_ops for compatibility with older kernels.,"libbpf,struct_ops,nulled-out",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
cfd3bfe9507b4aa39f7e86772e60b50b799e490e,cfd3bfe9507b4aa39f7e86772e60b50b799e490e,Dmitrii Bundin,dmitrii.bundin.a@gmail.com,1713587097,Andrii Nakryiko,andrii@kernel.org,1714433287,7d7acbf0cc7591c094ce3445254b943236bdae04,789d9a53d2f633317c64de3eba0940f31a8f0cd6,"bpf: Include linux/types.h for u32

Inclusion of the header linux/btf_ids.h relies on indirect inclusion of
the header linux/types.h. Including it directly on the top level helps
to avoid potential problems if linux/types.h hasn't been included
before.

The main motivation to introduce this it is to avoid similar problems that
have shown up in the bpftool where GNU libc indirectly pulls
linux/types.h causing compile error of the form:

   error: unknown type name 'u32'
                             u32 cnt;
                             ^~~

The bpftool compile error was fixed in
62248b22d01e (""tools/resolve_btfids: fix build with musl libc"").

Signed-off-by: Dmitrii Bundin <dmitrii.bundin.a@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240420042457.3198883-1-dmitrii.bundin.a@gmail.com
",,Directly include linux/types.h to prevent build errors related to missing u32 type in bpftool.,"linux types, bpftool, u32",It's a build system or CI/CD change.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"[""It's not related to any of the above.""]"
25927d0a1bec5091d371693c9fdd9640478837de,25927d0a1bec5091d371693c9fdd9640478837de,Geliang Tang,tanggeliang@kylinos.cn,1714374454,Andrii Nakryiko,andrii@kernel.org,1714432635,f4e0204c8bf1d4b7ca95c274c723c5fe18e82bf1,237c522c1d5d19e8d3057a38ce690c753020c7d1,"selftests/bpf: Free strdup memory in veristat

The strdup() function returns a pointer to a new string which is a
duplicate of the string ""input"". Memory for the new string is obtained
with malloc()"," and need to be freed with free().

This patch adds these missing ""free(input)"" in parse_stats() to avoid
memory leak in veristat.c.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/bpf/ded44f8865cd7f337f52fc5fb0a5fbed7d6bd641.1714374022.git.tanggeliang@kylinos.cn
",[''],The commit fixes a memory leak by freeing strdup memory in the selftests for veristat.,"memory, leak, free",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
237c522c1d5d19e8d3057a38ce690c753020c7d1,237c522c1d5d19e8d3057a38ce690c753020c7d1,Geliang Tang,tanggeliang@kylinos.cn,1714374453,Andrii Nakryiko,andrii@kernel.org,1714432635,9c1dec9405c26bceeb19a41fb0c09e652455381e,19468ed51488dae19254e8a67c75d583b05fa5e3,"selftests/bpf: Free strdup memory in test_sockmap

The strdup() function returns a pointer to a new string which is a
duplicate of the string ""ptr"". Memory for the new string is obtained
with malloc()"," and need to be freed with free().

This patch adds these missing ""free(ptr)"" in check_whitelist() and
check_blacklist() to avoid memory leaks in test_sockmap.c.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/bpf/b76f2f4c550aebe4ab8ea73d23c4cbe4f06ea996.1714374022.git.tanggeliang@kylinos.cn
",[''],Fixes memory leaks by adding missing free calls in test_sockmap.c for strdup allocations.,"memory leak, strdup, test_sockmap",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
19468ed51488dae19254e8a67c75d583b05fa5e3,19468ed51488dae19254e8a67c75d583b05fa5e3,Viktor Malik,vmalik@redhat.com,1714389791,Andrii Nakryiko,andrii@kernel.org,1714432451,33543407c7963e4b6d72ed400dcdb4eb7bce0c9c,a3034872cd90a6881ad4e10ca6d30e1215a99ada,"selftests/bpf: Run cgroup1_hierarchy test in own mount namespace

The cgroup1_hierarchy test uses setup_classid_environment to setup
cgroupv1 environment. The problem is that the environment is set in
/sys/fs/cgroup and therefore", if not run under an own mount namespace,"['\neffectively deletes all system cgroups:\n\n    $ ls /sys/fs/cgroup | wc -l\n    27\n    $ sudo ./test_progs -t cgroup1_hierarchy\n    #41/1    cgroup1_hierarchy/test_cgroup1_hierarchy:OK\n    #41/2    cgroup1_hierarchy/test_root_cgid:OK\n    #41/3    cgroup1_hierarchy/test_invalid_level:OK\n    #41/4    cgroup1_hierarchy/test_invalid_cgid:OK\n    #41/5    cgroup1_hierarchy/test_invalid_hid:OK\n    #41/6    cgroup1_hierarchy/test_invalid_cgrp_name:OK\n    #41/7    cgroup1_hierarchy/test_invalid_cgrp_name2:OK\n    #41/8    cgroup1_hierarchy/test_sleepable_prog:OK\n    #41      cgroup1_hierarchy:OK\n    Summary: 1/8 PASSED', ' 0 SKIPPED', ' 0 FAILED\n    $ ls /sys/fs/cgroup | wc -l\n    1\n\nTo avoid this', ' run setup_cgroup_environment first which will create an\nown mount namespace. This only affects the cgroupv1_hierarchy test as\nall other cgroup1 test progs already run setup_cgroup_environment prior\nto running setup_classid_environment.\n\nAlso add a comment to the header of setup_classid_environment to warn\nagainst this invalid usage in future.\n\nFixes: 360769233cc9 (""selftests/bpf: Add selftests for cgroup1 hierarchy"")\nSigned-off-by: Viktor Malik <vmalik@redhat.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240429112311.402497-1-vmalik@redhat.com\n', '']",The commit modifies the cgroup1_hierarchy test to run in its own mount namespace to avoid environment setup conflicts.,"cgroup1_hierarchy,mount namespace,environment",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a3034872cd90a6881ad4e10ca6d30e1215a99ada,a3034872cd90a6881ad4e10ca6d30e1215a99ada,Andy Shevchenko,andriy.shevchenko@linux.intel.com,1714392005,Andrii Nakryiko,andrii@kernel.org,1714432394,4e8c7500b29b275356a9a793c60009ee59b865ee,cb01621b6d91567ac74c8b95e4db731febdbdec3,"bpf: Switch to krealloc_array()

Let the krealloc_array() copy the original data and
check for a multiplication overflow.

Signed-off-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/bpf/20240429120005.3539116-1-andriy.shevchenko@linux.intel.com
",,Switches to using krealloc_array() for memory allocation with overflow check in eBPF.,"krealloc_array,memory overflow",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
cb01621b6d91567ac74c8b95e4db731febdbdec3,cb01621b6d91567ac74c8b95e4db731febdbdec3,Andy Shevchenko,andriy.shevchenko@linux.intel.com,1714392802,Andrii Nakryiko,andrii@kernel.org,1714432323,824adabc8b3315962dc97d52a7dd79a93a3255e9,397658ddc88ce3c21d2aa3bed8e15fc69dfec946,"bpf: Use struct_size()

Use struct_size() instead of hand writing it.
This is less verbose and more robust.

Signed-off-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/bpf/20240429121323.3818497-1-andriy.shevchenko@linux.intel.com
",,Refactor code to use struct_size() for improved code robustness and clarity.,"struct_size, robust, refactor",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
397658ddc88ce3c21d2aa3bed8e15fc69dfec946,397658ddc88ce3c21d2aa3bed8e15fc69dfec946,Tao Chen,chen.dylane@gmail.com,1714320632,Andrii Nakryiko,andrii@kernel.org,1714432203,a3b94164746442be2099cba5133067d3698adbed,0db63c0b86e981a1e97d2596d64ceceba1a5470e,"samples/bpf: Add valid info for VMLINUX_BTF

When I use the command 'make M=samples/bpf' to compile samples/bpf code
in ubuntu 22.04"," the error info occured:
Cannot find a vmlinux for VMLINUX_BTF at any of ""  /home/ubuntu/code/linux/vmlinux""","['\nbuild the kernel or set VMLINUX_BTF or VMLINUX_H variable\n\nOthers often encounter this kind of issue', ' new kernel has the vmlinux', ' so we can\nset the path in error info which seems more intuitive', ' like:\nCannot find a vmlinux for VMLINUX_BTF at any of ""  /home/ubuntu/code/linux/vmlinux""', '\nbuiild the kernel or set VMLINUX_BTF like ""VMLINUX_BTF=/sys/kernel/btf/vmlinux"" or\nVMLINUX_H variable\n\nSigned-off-by: Tao Chen <chen.dylane@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240428161032.239043-1-chen.dylane@gmail.com\n', '']",Add valid information to VMLINUX_BTF in samples/bpf for compile error resolution.,"samples,bpf,VMLINUX_BTF",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['other']
0db63c0b86e981a1e97d2596d64ceceba1a5470e,0db63c0b86e981a1e97d2596d64ceceba1a5470e,Alexei Starovoitov,ast@kernel.org,1714177544,Martin KaFai Lau,martin.lau@kernel.org,1714425401,d7e6ddaca356bbd5069fe7a5a8aab2cfa0fe97d7,89de2db19317fb89a6e9163f33c3a7b23ee75a18,"bpf: Fix verifier assumptions about socket->sk

The verifier assumes that 'sk' field in 'struct socket' is valid
and non-NULL when 'socket' pointer itself is trusted and non-NULL.
That may not be the case when socket was just created and
passed to LSM socket_accept hook.
Fix this verifier assumption and adjust tests.

Reported-by: Liam Wisehart <liamwisehart@meta.com>
Acked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>
Fixes: 6fcd486b3a0a (""bpf: Refactor RCU enforcement in the verifier."")
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/r/20240427002544.68803-1-alexei.starovoitov@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Fix verifier assumptions regarding non-NULL 'sk' field in sockets when accepted by LSM hooks.,"verifier, socket, non-NULL",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['socket like programs', 'LSM like programs']"
89de2db19317fb89a6e9163f33c3a7b23ee75a18,89de2db19317fb89a6e9163f33c3a7b23ee75a18,Jakub Kicinski,kuba@kernel.org,1714417160,Jakub Kicinski,kuba@kernel.org,1714421539,6518d797d4c9a54979ace148307ba5c0c25335a5,b3f1a08fcf0dd58d99b14b9f8fbd1929f188b746 07801a24e2f18624cd2400ce15f14569eb416c9a,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next

Daniel Borkmann says:

====================
pull-request: bpf-next 2024-04-29

We've added 147 non-merge commits during the last 32 day(s) which contain
a total of 158 files changed", 9400 insertions(+),"[' 2213 deletions(-).\n\nThe main changes are:\n\n1) Add an internal-only BPF per-CPU instruction for resolving per-CPU\n   memory addresses and implement support in x86 BPF JIT. This allows\n   inlining per-CPU array and hashmap lookups\n   and the bpf_get_smp_processor_id() helper', ' from Andrii Nakryiko.\n\n2) Add BPF link support for sk_msg and sk_skb programs', "" from Yonghong Song.\n\n3) Optimize x86 BPF JIT's emit_mov_imm64"", ' and add support for various\n   atomics in bpf_arena which can be JITed as a single x86 instruction', '\n   from Alexei Starovoitov.\n\n4) Add support for passing mark with bpf_fib_lookup helper', '\n   from Anton Protopopov.\n\n5) Add a new bpf_wq API for deferring events and refactor sleepable\n   bpf_timer code to keep common code where possible', '\n   from Benjamin Tissoires.\n\n6) Fix BPF_PROG_TEST_RUN infra with regards to bpf_dummy_struct_ops programs\n   to check when NULL is passed for non-NULLable parameters', ""\n   from Eduard Zingerman.\n\n7) Harden the BPF verifier's and/or/xor value tracking"", '\n   from Harishankar Vishwanathan.\n\n8) Introduce crypto kfuncs to make BPF programs able to utilize the kernel\n   crypto subsystem', ' from Vadim Fedorenko.\n\n9) Various improvements to the BPF instruction set standardization doc', '\n   from Dave Thaler.\n\n10) Extend libbpf APIs to partially consume items from the BPF ringbuffer', '\n    from Andrea Righi.\n\n11) Bigger batch of BPF selftests refactoring to use common network helpers\n    and to drop duplicate code', ' from Geliang Tang.\n\n12) Support bpf_tail_call_static() helper for BPF programs with GCC 13', '\n    from Jose E. Marchesi.\n\n13) Add bpf_preempt_{disable', 'enable}() kfuncs in order to allow a BPF\n    program to have code sections where preemption is disabled', '\n    from Kumar Kartikeya Dwivedi.\n\n14) Allow invoking BPF kfuncs from BPF_PROG_TYPE_SYSCALL programs', '\n    from David Vernet.\n\n15) Extend the BPF verifier to allow different input maps for a given\n    bpf_for_each_map_elem() helper call in a BPF program', ' from Philo Lu.\n\n16) Add support for PROBE_MEM32 and bpf_addr_space_cast instructions\n    for riscv64 and arm64 JITs to enable BPF Arena', ' from Puranjay Mohan.\n\n17) Shut up a false-positive KMSAN splat in interpreter mode by unpoison\n    the stack memory', ' from Martin KaFai Lau.\n\n18) Improve xsk selftest coverage with new tests on maximum and minimum\n    hardware ring size configurations', ' from Tushar Vyavahare.\n\n19) Various ReST man pages fixes as well as documentation and bash completion\n    improvements for bpftool', ' from Rameez Rehman & Quentin Monnet.\n\n20) Fix libbpf with regards to dumping subsequent char arrays', ""\n    from Quentin Deslandes.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next: (147 commits)\n  bpf"", ' docs: Clarify PC use in instruction-set.rst\n  bpf_helpers.h: Define bpf_tail_call_static when building with GCC\n  bpf', ' docs: Add introduction for use in the ISA Internet Draft\n  selftests/bpf: extend BPF_SOCK_OPS_RTT_CB test for srtt and mrtt_us\n  bpf: add mrtt and srtt as BPF_SOCK_OPS_RTT_CB args\n  selftests/bpf: dummy_st_ops should reject 0 for non-nullable params\n  bpf: check bpf_dummy_struct_ops program params for test runs\n  selftests/bpf: do not pass NULL for non-nullable params in dummy_st_ops\n  selftests/bpf: adjust dummy_st_ops_success to detect additional error\n  bpf: mark bpf_dummy_struct_ops.test_1 parameter as nullable\n  selftests/bpf: Add ring_buffer__consume_n test.\n  bpf: Add bpf_guard_preempt() convenience macro\n  selftests: bpf: crypto: add benchmark for crypto functions\n  selftests: bpf: crypto skcipher algo selftests\n  bpf: crypto: add skcipher to bpf crypto\n  bpf: make common crypto API for TC/XDP programs\n  bpf: update the comment for BTF_FIELDS_MAX\n  selftests/bpf: Fix wq test.\n  selftests/bpf: Use make_sockaddr in test_sock_addr\n  selftests/bpf: Use connect_to_addr in test_sock_addr\n  ...\n====================\n\nLink: https://lore.kernel.org/r/20240429131657.19423-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Merge update includes 147 non-merge commits with multiple file changes from bpf-next branch.,"merge, commits, bpf-next",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
07801a24e2f18624cd2400ce15f14569eb416c9a,07801a24e2f18624cd2400ce15f14569eb416c9a,Dave Thaler,dthaler1968@googlemail.com,1714173086,Daniel Borkmann,daniel@iogearbox.net,1714384482,19e50ffbf18843caa1fee3e790f8a3b28ac5354d,6e25bcf06af0341691f7058e17e04800f6a19e26,bpf," docs: Clarify PC use in instruction-set.rst

This patch elaborates on the use of PC by expanding the PC acronym","['\nexplaining the units', ' and the relative position to which the offset\napplies.\n\nSigned-off-by: Dave Thaler <dthaler1968@googlemail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: David Vernet <void@manifault.com>\nLink: https://lore.kernel.org/bpf/20240426231126.5130-1-dthaler1968@gmail.com\n', '']",This commit clarifies the use of the PC acronym in the bpf instruction set documentation.,"PC,documentation,clarity",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
8524d71cebfa6ddcfbb89f0fe0e174c8d0477c6d,8524d71cebfa6ddcfbb89f0fe0e174c8d0477c6d,Ian Rogers,irogers@google.com,1710952364,Arnaldo Carvalho de Melo,acme@redhat.com,1714180390,30a010bed9cb209543edb150c652962f526a4821,e101a05f79fd4ee3e89d2f3fb716493c33a33708,"perf build: Pretend scandirat is missing with msan

Memory sanitizer lacks an interceptor for scandirat"," reporting all
memory it allocates as uninitialized. Memory sanitizer has a scandir
interceptor so use the fallback function in this case. This allows
'perf test' to run under memory sanitizer.

Additional notes from Ian on running in this mode:

Note","[' as msan needs to instrument memory allocations libraries need to\nbe compiled with it. I lacked the msan built libraries and so built\nwith:\n```\n$ make -C tools/perf O=/tmp/perf DEBUG=1 EXTRA_CFLAGS=""-O0 -g\n-fno-omit-frame-pointer -fsanitize=memory\n-fsanitize-memory-track-origins"" CC=clang CXX=clang++ HOSTCC=clang\nNO_LIBTRACEEVENT=1 NO_LIBELF=1 BUILD_BPF_SKEL=0 NO_LIBPFM=1\n```\noh', ' I disabled libbpf here as the bpf system call also lacks msan interceptors.\n\nSigned-off-by: Ian Rogers <irogers@google.com>\nCc: Adrian Hunter <adrian.hunter@intel.com>\nCc: Alexander Shishkin <alexander.shishkin@linux.intel.com>\nCc: Ingo Molnar <mingo@redhat.com>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: Mark Rutland <mark.rutland@arm.com>\nCc: Namhyung Kim <namhyung@kernel.org>\nCc: Peter Zijlstra <peterz@infradead.org>\nLink: https://lore.kernel.org/r/20240320163244.1287780-1-irogers@google.com\nSigned-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>\n', '']",The commit modifies the perf build to use a fallback function for scandirat with memory sanitizer.,"perf, msan, scandirat",It's a build system or CI/CD change.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
b2ff42c6d3abc26ef0f395fe9ee8c64364fbaa22,b2ff42c6d3abc26ef0f395fe9ee8c64364fbaa22,Jakub Kicinski,kuba@kernel.org,1714178213,Jakub Kicinski,kuba@kernel.org,1714178213,43837bf05515276032c904214ad3021693a43890,6a30653b604aaad1bf0f2e74b068ceb8b6fc7aea a86538a2efb826b9a62c7b41e0499948b04aec7d,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Daniel Borkmann says:

====================
pull-request: bpf 2024-04-26

We've added 12 non-merge commits during the last 22 day(s) which contain
a total of 14 files changed", 168 insertions(+),"[' 72 deletions(-).\n\nThe main changes are:\n\n1) Fix BPF_PROBE_MEM in verifier and JIT to skip loads from vsyscall page', '\n   from Puranjay Mohan.\n\n2) Fix a crash in XDP with devmap broadcast redirect when the latter map\n   is in process of being torn down', ' from Toke Høiland-Jørgensen.\n\n3) Fix arm64 and riscv64 BPF JITs to properly clear start time for BPF\n   program runtime stats', ' from Xu Kuohai.\n\n4) Fix a sockmap KCSAN-reported data race in sk_psock_skb_ingress_enqueue', '\n    from Jason Xing.\n\n5) Fix BPF verifier error message in resolve_pseudo_ldimm64', '\n   from Anton Protopopov.\n\n6) Fix missing DEBUG_INFO_BTF_MODULES Kconfig menu item', ""\n   from Andrii Nakryiko.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  selftests/bpf: Test PROBE_MEM of VSYSCALL_ADDR on x86-64\n  bpf"", ' x86: Fix PROBE_MEM runtime load check\n  bpf: verifier: prevent userspace memory access\n  xdp: use flags field to disambiguate broadcast redirect\n  arm32', ' bpf: Reimplement sign-extension mov instruction\n  riscv', ' bpf: Fix incorrect runtime stats\n  bpf', ' arm64: Fix incorrect runtime stats\n  bpf: Fix a verifier verbose message\n  bpf', ' skmsg: Fix NULL pointer dereference in sk_psock_skb_ingress_enqueue\n  MAINTAINERS: bpf: Add Lehui and Puranjay as riscv64 reviewers\n  MAINTAINERS: Update email address for Puranjay Mohan\n  bpf', ' kconfig: Fix DEBUG_INFO_BTF_MODULES Kconfig definition\n====================\n\nLink: https://lore.kernel.org/r/20240426224248.26197-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Merged bpf-related changes from the 'for-netdev' tag into the main branch involving 12 non-merge commits.,"bpf, netdev, merge",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
a86538a2efb826b9a62c7b41e0499948b04aec7d,a86538a2efb826b9a62c7b41e0499948b04aec7d,Alexei Starovoitov,ast@kernel.org,1714149919,Alexei Starovoitov,ast@kernel.org,1714149919,abcf803874950c1abaeacc544d3a317d2ff8d2fb,5bcf0dcbf9066348058b88a510c57f70f384c92c 7cd6750d9a560fa69bb640a7280479d6a67999ad,"Merge branch 'bpf-prevent-userspace-memory-access'

Puranjay Mohan says:

====================
bpf: prevent userspace memory access

V5: https://lore.kernel.org/bpf/20240324185356.59111-1-puranjay12@gmail.com/
Changes in V6:
- Disable the verifier's instrumentation in x86-64 and update the JIT to
  take care of vsyscall page in addition to userspace addresses.
- Update bpf_testmod to test for vsyscall addresses.

V4: https://lore.kernel.org/bpf/20240321124640.8870-1-puranjay12@gmail.com/
Changes in V5:
- Use TASK_SIZE_MAX + PAGE_SIZE"," VSYSCALL_ADDR as userspace boundary in
  x86-64 JIT.
- Added Acked-by: Ilya Leoshkevich <iii@linux.ibm.com>

V3: https://lore.kernel.org/bpf/20240321120842.78983-1-puranjay12@gmail.com/
Changes in V4:
- Disable this feature on architectures that don't define
  CONFIG_ARCH_HAS_NON_OVERLAPPING_ADDRESS_SPACE.
- By doing the above","["" we don't need anything explicitly for s390x.\n\nV2: https://lore.kernel.org/bpf/20240321101058.68530-1-puranjay12@gmail.com/\nChanges in V3:\n- Return 0 from bpf_arch_uaddress_limit() in disabled case because it\n  returns u64.\n- Modify the check in verifier to no do instrumentation when uaddress_limit\n  is 0.\n\nV1: https://lore.kernel.org/bpf/20240320105436.4781-1-puranjay12@gmail.com/\nChanges in V2:\n- Disable this feature on s390x.\n\nWith BPF_PROBE_MEM"", ' BPF allows de-referencing an untrusted pointer. To\nthwart invalid memory accesses', ' the JITs add an exception table entry for\nall such accesses. But in case the src_reg + offset is a userspace address', '\nthe BPF program might read that memory if the user has mapped it.\n\nx86-64 JIT already instruments the BPF_PROBE_MEM based loads with checks to\nskip loads from userspace addresses', "" but is doesn't check for vsyscall page\nbecause it falls in the kernel address space but is considered a userspace\npage. The second patch in this series fixes the x86-64 JIT to also skip\nloads from the vsyscall page. The last patch updates the bpf_testmod so\nthis address can be checked as part of the selftests.\n\nOther architectures don't have the complexity of the vsyscall address and\njust need to skip loads from the userspace. To make this more scalable and\nrobust"", ' the verifier is updated in the first patch to instrument\nBPF_PROBE_MEM to skip loads from the userspace addresses.\n====================\n\nLink: https://lore.kernel.org/r/20240424100210.11982-1-puranjay@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit prevents userspace memory access in eBPF by updating the verifier and JIT on x86-64.,"userspace memory access, verifier, JIT",It's a security fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7cd6750d9a560fa69bb640a7280479d6a67999ad,7cd6750d9a560fa69bb640a7280479d6a67999ad,Puranjay Mohan,puranjay@kernel.org,1713952930,Alexei Starovoitov,ast@kernel.org,1714149918,abcf803874950c1abaeacc544d3a317d2ff8d2fb,b599d7d26d6ad1fc9975218574bc2ca6d0293cfd,"selftests/bpf: Test PROBE_MEM of VSYSCALL_ADDR on x86-64

The vsyscall is a legacy API for fast execution of system calls. It maps
a page at address VSYSCALL_ADDR into the userspace program. This address
is in the top 10MB of the address space:

ffffffffff600000 - ffffffffff600fff |    4 kB | legacy vsyscall ABI

The last commit fixes the x86-64 BPF JIT to skip accessing addresses in
this memory region. Add this address to bpf_testmod_return_ptr() so we
can make sure that it is fixed.

After this change and without the previous commit"," subprogs_extable
selftest will crash the kernel.

Signed-off-by: Puranjay Mohan <puranjay@kernel.org>
Link: https://lore.kernel.org/r/20240424100210.11982-4-puranjay@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Test PROBE_MEM of VSYSCALL_ADDR in BPF selftests on x86-64 architecture.,"PROBE_MEM, VSYSCALL_ADDR, x86-64",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"[""It's an experimental feature that doesn't fit into existing categories.""]"
b599d7d26d6ad1fc9975218574bc2ca6d0293cfd,b599d7d26d6ad1fc9975218574bc2ca6d0293cfd,Puranjay Mohan,puranjay@kernel.org,1713952929,Alexei Starovoitov,ast@kernel.org,1714149918,2a49ec8ac3062864225e4d95d2906a758170b54c,66e13b615a0ce76b785d780ecc9776ba71983629,bpf," x86: Fix PROBE_MEM runtime load check

When a load is marked PROBE_MEM - e.g. due to PTR_UNTRUSTED access - the
address being loaded from is not necessarily valid. The BPF jit sets up
exception handlers for each such load which catch page faults and 0 out
the destination register.

If the address for the load is outside kernel address space","[' the load\nwill escape the exception handling and crash the kernel. To prevent this\nfrom happening', ' the emits some instruction to verify that addr is > end\nof userspace addresses.\n\nx86 has a legacy vsyscall ABI where a page at address 0xffffffffff600000\nis mapped with user accessible permissions. The addresses in this page\nare considered userspace addresses by the fault handler. Therefore', ' a\nBPF program accessing this page will crash the kernel.\n\nThis patch fixes the runtime checks to also check that the PROBE_MEM\naddress is below VSYSCALL_ADDR.\n\nExample BPF program:\n\n SEC(""fentry/tcp_v4_connect"")\n int BPF_PROG(fentry_tcp_v4_connect', ' struct sock *sk)\n {\n\t*(volatile unsigned long *)&sk->sk_tsq_flags;\n\treturn 0;\n }\n\nBPF Assembly:\n\n 0: (79) r1 = *(u64 *)(r1 +0)\n 1: (79) r1 = *(u64 *)(r1 +344)\n 2: (b7) r0 = 0\n 3: (95) exit\n\n\t\t\t       x86-64 JIT\n\t\t\t       ==========\n\n            BEFORE                                    AFTER\n\t    ------                                    -----\n\n 0:   nopl   0x0(%rax', '%rax', '1)             0:   nopl   0x0(%rax', '%rax', '1)\n 5:   xchg   %ax', '%ax                      5:   xchg   %ax', '%ax\n 7:   push   %rbp                         7:   push   %rbp\n 8:   mov    %rsp', '%rbp                    8:   mov    %rsp', '%rbp\n b:   mov    0x0(%rdi)', '%rdi               b:   mov    0x0(%rdi)', '%rdi\n-------------------------------------------------------------------------------\n f:   movabs $0x100000000000000', '%r11      f:   movabs $0xffffffffff600000', '%r10\n19:   add    $0x2a0', '%rdi                 19:   mov    %rdi', '%r11\n20:   cmp    %r11', '%rdi                   1c:   add    $0x2a0', '%r11\n23:   jae    0x0000000000000029          23:   sub    %r10', '%r11\n25:   xor    %edi', '%edi                   26:   movabs $0x100000000a00000', '%r10\n27:   jmp    0x000000000000002d          30:   cmp    %r10', '%r11\n29:   mov    0x0(%rdi)', '%rdi              33:   ja     0x0000000000000039\n--------------------------------\\        35:   xor    %edi', '%edi\n2d:   xor    %eax', '%eax           \\       37:   jmp    0x0000000000000040\n2f:   leave                       \\      39:   mov    0x2a0(%rdi)', '%rdi\n30:   ret                          \\--------------------------------------------\n                                         40:   xor    %eax', '%eax\n                                         42:   leave\n                                         43:   ret\n\nSigned-off-by: Puranjay Mohan <puranjay@kernel.org>\nLink: https://lore.kernel.org/r/20240424100210.11982-3-puranjay@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix PROBE_MEM runtime load check and exception handling in the BPF JIT compiler for untrusted pointer accesses.,"PROBE_MEM,BPF JIT,exception",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
66e13b615a0ce76b785d780ecc9776ba71983629,66e13b615a0ce76b785d780ecc9776ba71983629,Puranjay Mohan,puranjay12@gmail.com,1713952928,Alexei Starovoitov,ast@kernel.org,1714149918,946fd8a18546f2856341ad612e69e97aef4cd8b9,5bcf0dcbf9066348058b88a510c57f70f384c92c,"bpf: verifier: prevent userspace memory access

With BPF_PROBE_MEM"," BPF allows de-referencing an untrusted pointer. To
thwart invalid memory accesses","[' the JITs add an exception table entry\nfor all such accesses. But in case the src_reg + offset is a userspace\naddress', ' the BPF program might read that memory if the user has\nmapped it.\n\nMake the verifier add guard instructions around such memory accesses and\nskip the load if the address falls into the userspace region.\n\nThe JITs need to implement bpf_arch_uaddress_limit() to define where\nthe userspace addresses end for that architecture or TASK_SIZE is taken\nas default.\n\nThe implementation is as follows:\n\nREG_AX =  SRC_REG\nif(offset)\n\tREG_AX += offset;\nREG_AX >>= 32;\nif (REG_AX <= (uaddress_limit >> 32))\n\tDST_REG = 0;\nelse\n\tDST_REG = *(size *)(SRC_REG + offset);\n\nComparing just the upper 32 bits of the load address with the upper\n32 bits of uaddress_limit implies that the values are being aligned down\nto a 4GB boundary before comparison.\n\nThe above means that all loads with address <= uaddress_limit + 4GB are\nskipped. This is acceptable because there is a large hole (much larger\nthan 4GB) between userspace and kernel space memory', ' therefore a\ncorrectly functioning BPF program should not access this 4GB memory\nabove the userspace.\n\nLet\'s analyze what this patch does to the following fentry program\ndereferencing an untrusted pointer:\n\n  SEC(""fentry/tcp_v4_connect"")\n  int BPF_PROG(fentry_tcp_v4_connect', ' struct sock *sk)\n  {\n                *(volatile long *)sk;\n                return 0;\n  }\n\n    BPF Program before              |           BPF Program after\n    ------------------              |           -----------------\n\n  0: (79) r1 = *(u64 *)(r1 +0)          0: (79) r1 = *(u64 *)(r1 +0)\n  -----------------------------------------------------------------------\n  1: (79) r1 = *(u64 *)(r1 +0) --\\      1: (bf) r11 = r1\n  ----------------------------\\   \\     2: (77) r11 >>= 32\n  2: (b7) r0 = 0               \\   \\    3: (b5) if r11 <= 0x8000 goto pc+2\n  3: (95) exit                  \\   \\-> 4: (79) r1 = *(u64 *)(r1 +0)\n                                 \\      5: (05) goto pc+1\n                                  \\     6: (b7) r1 = 0\n                                   \\--------------------------------------\n                                        7: (b7) r0 = 0\n                                        8: (95) exit\n\nAs you can see from above', ' in the best case (off=0)', ' 5 extra instructions\nare emitted.\n\nNow', "" we analyze the same program after it has gone through the JITs of\nARM64 and RISC-V architectures. We follow the single load instruction\nthat has the untrusted pointer and see what instrumentation has been\nadded around it.\n\n                                x86-64 JIT\n                                ==========\n     JIT's Instrumentation\n          (upstream)\n     ---------------------\n\n   0:   nopl   0x0(%rax"", '%rax', '1)\n   5:   xchg   %ax', '%ax\n   7:   push   %rbp\n   8:   mov    %rsp', '%rbp\n   b:   mov    0x0(%rdi)', '%rdi\n  ---------------------------------\n   f:   movabs $0x800000000000', '%r11\n  19:   cmp    %r11', '%rdi\n  1c:   jb     0x000000000000002a\n  1e:   mov    %rdi', '%r11\n  21:   add    $0x0', '%r11\n  28:   jae    0x000000000000002e\n  2a:   xor    %edi', '%edi\n  2c:   jmp    0x0000000000000032\n  2e:   mov    0x0(%rdi)', '%rdi\n  ---------------------------------\n  32:   xor    %eax', ""%eax\n  34:   leave\n  35:   ret\n\nThe x86-64 JIT already emits some instructions to protect against user\nmemory access. This patch doesn't make any changes for the x86-64 JIT.\n\n                                  ARM64 JIT\n                                  =========\n\n        No Intrumentation                       Verifier's Instrumentation\n           (upstream)                                  (This patch)\n        -----------------                       --------------------------\n\n   0:   add     x9"", ' x30', ' #0x0                0:   add     x9', ' x30', ' #0x0\n   4:   nop                                  4:   nop\n   8:   paciasp                              8:   paciasp\n   c:   stp     x29', ' x30', ' [sp', ' #-16]!        c:   stp     x29', ' x30', ' [sp', ' #-16]!\n  10:   mov     x29', ' sp                     10:   mov     x29', ' sp\n  14:   stp     x19', ' x20', ' [sp', ' #-16]!       14:   stp     x19', ' x20', ' [sp', ' #-16]!\n  18:   stp     x21', ' x22', ' [sp', ' #-16]!       18:   stp     x21', ' x22', ' [sp', ' #-16]!\n  1c:   stp     x25', ' x26', ' [sp', ' #-16]!       1c:   stp     x25', ' x26', ' [sp', ' #-16]!\n  20:   stp     x27', ' x28', ' [sp', ' #-16]!       20:   stp     x27', ' x28', ' [sp', ' #-16]!\n  24:   mov     x25', ' sp                     24:   mov     x25', ' sp\n  28:   mov     x26', ' #0x0                   28:   mov     x26', ' #0x0\n  2c:   sub     x27', ' x25', ' #0x0              2c:   sub     x27', ' x25', ' #0x0\n  30:   sub     sp', ' sp', ' #0x0                30:   sub     sp', ' sp', ' #0x0\n  34:   ldr     x0', ' [x0]                    34:   ldr     x0', ' [x0]\n--------------------------------------------------------------------------------\n  38:   ldr     x0', ' [x0] ----------\\        38:   add     x9', ' x0', ' #0x0\n-----------------------------------\\\\       3c:   lsr     x9', ' x9', ' #32\n  3c:   mov     x7', ' #0x0            \\\\      40:   cmp     x9', ' #0x10', ' lsl #12\n  40:   mov     sp', ' sp               \\\\     44:   b.ls    0x0000000000000050\n  44:   ldp     x27', ' x28', ' [sp]', ' #16   \\\\--> 48:   ldr     x0', ' [x0]\n  48:   ldp     x25', ' x26', ' [sp]', ' #16    \\    4c:   b       0x0000000000000054\n  4c:   ldp     x21', ' x22', ' [sp]', ' #16     \\   50:   mov     x0', ' #0x0\n  50:   ldp     x19', ' x20', ' [sp]', ' #16      \\---------------------------------------\n  54:   ldp     x29', ' x30', ' [sp]', ' #16         54:   mov     x7', ' #0x0\n  58:   add     x0', ' x7', ' #0x0                58:   mov     sp', ' sp\n  5c:   autiasp                             5c:   ldp     x27', ' x28', ' [sp]', ' #16\n  60:   ret                                 60:   ldp     x25', ' x26', ' [sp]', ' #16\n  64:   nop                                 64:   ldp     x21', ' x22', ' [sp]', ' #16\n  68:   ldr     x10', ' 0x0000000000000070     68:   ldp     x19', ' x20', ' [sp]', ' #16\n  6c:   br      x10                         6c:   ldp     x29', ' x30', ' [sp]', ' #16\n                                            70:   add     x0', ' x7', ' #0x0\n                                            74:   autiasp\n                                            78:   ret\n                                            7c:   nop\n                                            80:   ldr     x10', "" 0x0000000000000088\n                                            84:   br      x10\n\nThere are 6 extra instructions added in ARM64 in the best case. This will\nbecome 7 in the worst case (off != 0).\n\n                           RISC-V JIT (RISCV_ISA_C Disabled)\n                           ==========\n\n        No Intrumentation           Verifier's Instrumentation\n           (upstream)                      (This patch)\n        -----------------           --------------------------\n\n   0:   nop                            0:   nop\n   4:   nop                            4:   nop\n   8:   li      a6"", ' 33                 8:   li      a6', ' 33\n   c:   addi    sp', ' sp', ' -16            c:   addi    sp', ' sp', ' -16\n  10:   sd      s0', ' 8(sp)             10:   sd      s0', ' 8(sp)\n  14:   addi    s0', ' sp', ' 16            14:   addi    s0', ' sp', ' 16\n  18:   ld      a0', ' 0(a0)             18:   ld      a0', ' 0(a0)\n---------------------------------------------------------------\n  1c:   ld      a0', ' 0(a0) --\\         1c:   mv      t0', ' a0\n--------------------------\\  \\        20:   srli    t0', ' t0', ' 32\n  20:   li      a5', ' 0      \\  \\       24:   lui     t1', ' 4096\n  24:   ld      s0', ' 8(sp)   \\  \\      28:   sext.w  t1', ' t1\n  28:   addi    sp', ' sp', ' 16   \\  \\     2c:   bgeu    t1', ' t0', ' 12\n  2c:   sext.w  a0', ' a5        \\  \\--> 30:   ld      a0', ' 0(a0)\n  30:   ret                    \\      34:   j       8\n                                \\     38:   li      a0', ' 0\n                                 \\------------------------------\n                                      3c:   li      a5', ' 0\n                                      40:   ld      s0', ' 8(sp)\n                                      44:   addi    sp', ' sp', ' 16\n                                      48:   sext.w  a0', ' a5\n                                      4c:   ret\n\nThere are 7 extra instructions added in RISC-V.\n\nFixes: 800834285361 (""bpf', ' arm64: Add BPF exception tables"")\nReported-by: Breno Leitao <leitao@debian.org>\nSuggested-by: Alexei Starovoitov <ast@kernel.org>\nAcked-by: Ilya Leoshkevich <iii@linux.ibm.com>\nSigned-off-by: Puranjay Mohan <puranjay12@gmail.com>\nLink: https://lore.kernel.org/r/20240424100210.11982-2-puranjay@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit improves memory access safety in BPF by using BPF_PROBE_MEM to prevent userspace memory access issues.,"verifier, memory, prevention",It's a security fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6e25bcf06af0341691f7058e17e04800f6a19e26,6e25bcf06af0341691f7058e17e04800f6a19e26,Jose E. Marchesi,jose.marchesi@oracle.com,1714143118,Daniel Borkmann,daniel@iogearbox.net,1714144204,28e1c6d15b6bd1941da881beaa8ca72ed4b40fa5,e51b907d40329d4b4517a155e0bc0bf593d6767d,"bpf_helpers.h: Define bpf_tail_call_static when building with GCC

The definition of bpf_tail_call_static in tools/lib/bpf/bpf_helpers.h
is guarded by a preprocessor check to assure that clang is recent
enough to support it.  This patch updates the guard so the function is
compiled when using GCC 13 or later as well.

Tested in bpf-next master. No regressions.

Signed-off-by: Jose E. Marchesi <jose.marchesi@oracle.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240426145158.14409-1-jose.marchesi@oracle.com
",,Added support for bpf_tail_call_static function in GCC 13 or later.,"bpf_tail_call_static,GCC,compile",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['other']
15fd021bc4270273d8f4b7f58fdda8a16214a377,15fd021bc4270273d8f4b7f58fdda8a16214a377,Song Yoong Siang,yoong.siang.song@intel.com,1713992574,Paolo Abeni,pabeni@redhat.com,1714137839,d199ce09d3e6cda93e327af0a037826e578a4671,dba86b7d8778102998a6a2989f6a2d935efc6d47,"igc: Add Tx hardware timestamp request for AF_XDP zero-copy packet

This patch adds support to per-packet Tx hardware timestamp request to
AF_XDP zero-copy packet via XDP Tx metadata framework. Please note that
user needs to enable Tx HW timestamp capability via igc_ioctl() with
SIOCSHWTSTAMP cmd before sending xsk Tx hardware timestamp request.

Same as implementation in RX timestamp XDP hints kfunc metadata"," Timer 0
(adjustable clock) is used in xsk Tx hardware timestamp. i225/i226 have
four sets of timestamping registers. *skb and *xsk_tx_buffer pointers
are used to indicate whether the timestamping register is already occupied.

Furthermore","[' a boolean variable named xsk_pending_ts is used to hold the\ntransmit completion until the tx hardware timestamp is ready. This is\nbecause', ' for i225/i226', ' the timestamp notification event comes some time\nafter the transmit completion event. The driver will retrigger hardware irq\nto clean the packet after retrieve the tx hardware timestamp.\n\nBesides', ' xsk_meta is added into struct igc_tx_timestamp_request as a hook\nto the metadata location of the transmit packet. When the Tx timestamp\ninterrupt is fired', "" the interrupt handler will copy the value of Tx hwts\ninto metadata location via xsk_tx_metadata_complete().\n\nThis patch is tested with tools/testing/selftests/bpf/xdp_hw_metadata\non Intel ADL-S platform. Below are the test steps and results.\n\nTest Step 1: Run xdp_hw_metadata app\n ./xdp_hw_metadata <iface> > /dev/shm/result.log\n\nTest Step 2: Enable Tx hardware timestamp\n hwstamp_ctl -i <iface> -t 1 -r 1\n\nTest Step 3: Run ptp4l and phc2sys for time synchronization\n\nTest Step 4: Generate UDP packets with 1ms interval for 10s\n trafgen --dev <iface> '{eth(da=<addr>)"", "" udp(dp=9091)}' -t 1ms -n 10000\n\nTest Step 5: Rerun Step 1-3 with 10s iperf3 as background traffic\n\nTest Step 6: Rerun Step 1-4 with 10s iperf3 as background traffic\n\nBased on iperf3 results below"", ' the impact of holding tx completion to\nthroughput is not observable.\n\nResult of last UDP packet (no. 10000) in Step 4:\npoll: 1 (0) skip=99 fail=0 redir=10000\nxsk_ring_cons__peek: 1\n0x5640a37972d0: rx_desc[9999]->addr=f2110 addr=f2110 comp_addr=f2110 EoP\nrx_hash: 0x2049BE1D with RSS type:0x1\nHW RX-time:   1679819246792971268 (sec:1679819246.7930) delta to User RX-time sec:0.0000 (14.990 usec)\nXDP RX-time:   1679819246792981987 (sec:1679819246.7930) delta to User RX-time sec:0.0000 (4.271 usec)\nNo rx_vlan_tci or rx_vlan_proto', ' err=-95\n0x5640a37972d0: ping-pong with csum=ab19 (want 315b) csum_start=34 csum_offset=6\n0x5640a37972d0: complete tx idx=9999 addr=f010\nHW TX-complete-time:   1679819246793036971 (sec:1679819246.7930) delta to User TX-complete-time sec:0.0001 (77.656 usec)\nXDP RX-time:   1679819246792981987 (sec:1679819246.7930) delta to User TX-complete-time sec:0.0001 (132.640 usec)\nHW RX-time:   1679819246792971268 (sec:1679819246.7930) delta to HW TX-complete-time sec:0.0001 (65.703 usec)\n0x5640a37972d0: complete rx idx=10127 addr=f2110\n\nResult of iperf3 without tx hwts request in step 5:\n[ ID] Interval           Transfer     Bitrate         Retr\n[  5]   0.00-10.00  sec  2.74 GBytes  2.36 Gbits/sec    0             sender\n[  5]   0.00-10.05  sec  2.74 GBytes  2.34 Gbits/sec                  receiver\n\nResult of iperf3 running parallel with trafgen command in step 6:\n[ ID] Interval           Transfer     Bitrate         Retr\n[  5]   0.00-10.00  sec  2.74 GBytes  2.36 Gbits/sec    0             sender\n[  5]   0.00-10.04  sec  2.74 GBytes  2.34 Gbits/sec                  receiver\n\nCo-developed-by: Lai Peter Jun Ann <jun.ann.lai@intel.com>\nSigned-off-by: Lai Peter Jun Ann <jun.ann.lai@intel.com>\nSigned-off-by: Song Yoong Siang <yoong.siang.song@intel.com>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nAcked-by: Vinicius Costa Gomes <vinicius.gomes@intel.com>\nTested-by: Naama Meir <naamax.meir@linux.intel.com>\nSigned-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>\nLink: https://lore.kernel.org/r/20240424210256.3440903-1-anthony.l.nguyen@intel.com\nSigned-off-by: Paolo Abeni <pabeni@redhat.com>\n', '']",The commit adds Tx hardware timestamp support for AF_XDP zero-copy packets using XDP Tx metadata framework.,"Tx hardware timestamp, AF_XDP, zero-copy",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['xdp like programs']
e51b907d40329d4b4517a155e0bc0bf593d6767d,e51b907d40329d4b4517a155e0bc0bf593d6767d,Dave Thaler,dthaler1968@googlemail.com,1713812982,Alexei Starovoitov,ast@kernel.org,1714097721,84b8f50253faec3d6b523f4ea08e621b2696cfde,876373985efb87844ca7cacd2d1d3ef4c9398c9c,bpf," docs: Add introduction for use in the ISA Internet Draft

The proposed intro paragraph text is derived from the first paragraph
of the IETF BPF WG charter at https://datatracker.ietf.org/wg/bpf/about/

Signed-off-by: Dave Thaler <dthaler1968@gmail.com>
Acked-by: David Vernet <void@manifault.com>
Link: https://lore.kernel.org/r/20240422190942.24658-1-dthaler1968@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Add introduction text for BPF ISA in the related Internet Draft documentation.,"BPF, ISA, documentation",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
876373985efb87844ca7cacd2d1d3ef4c9398c9c,876373985efb87844ca7cacd2d1d3ef4c9398c9c,Martin KaFai Lau,martin.lau@kernel.org,1714076781,Martin KaFai Lau,martin.lau@kernel.org,1714079345,90f30033f73d8801ca45d1ac453134c80b65b4db,a311c3f9c342fc12e6c8a27e22c81955ab2a336c 7eb4f66b38069eec9c86c9d115f0bba1cf73ef2c,"Merge branch 'bpf: add mrtt and srtt as ctx->args for BPF_SOCK_OPS_RTT_CB'

Philo Lu says:

====================
These provides more information about tcp RTT estimation. The selftest for
BPF_SOCK_OPS_RTT_CB is extended for the added args.

changelogs
-> v1:
- extend rtt selftest for added args (suggested by Stanislav)
====================

Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Merge branch to add mrtt and srtt as ctx->args for BPF_SOCK_OPS_RTT_CB with extended selftests.,"mrtt, srtt, BPF_SOCK_OPS_RTT_CB",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['socket like programs']
7eb4f66b38069eec9c86c9d115f0bba1cf73ef2c,7eb4f66b38069eec9c86c9d115f0bba1cf73ef2c,Philo Lu,lulie@linux.alibaba.com,1714061844,Martin KaFai Lau,martin.lau@kernel.org,1714079345,90f30033f73d8801ca45d1ac453134c80b65b4db,48e2cd3e3dcfe04f212df4fb189fa04c2a87b980,"selftests/bpf: extend BPF_SOCK_OPS_RTT_CB test for srtt and mrtt_us

Because srtt and mrtt_us are added as args in bpf_sock_ops at
BPF_SOCK_OPS_RTT_CB"," a simple check is added to make sure they are both
non-zero.

$ ./test_progs -t tcp_rtt
  #373     tcp_rtt:OK
  Summary: 1/0 PASSED","[' 0 SKIPPED', ' 0 FAILED\n\nSuggested-by: Stanislav Fomichev <sdf@google.com>\nSigned-off-by: Philo Lu <lulie@linux.alibaba.com>\nLink: https://lore.kernel.org/r/20240425161724.73707-3-lulie@linux.alibaba.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Extend BPF_SOCK_OPS_RTT_CB test to include checks for non-zero srtt and mrtt_us arguments.,"BPF_SOCK_OPS_RTT_CB,srtt,mrtt_us",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
48e2cd3e3dcfe04f212df4fb189fa04c2a87b980,48e2cd3e3dcfe04f212df4fb189fa04c2a87b980,Philo Lu,lulie@linux.alibaba.com,1714061843,Martin KaFai Lau,martin.lau@kernel.org,1714079345,25a93be2e1812044e50c7cf4909e18c8f5c8ff43,a311c3f9c342fc12e6c8a27e22c81955ab2a336c,"bpf: add mrtt and srtt as BPF_SOCK_OPS_RTT_CB args

Two important arguments in RTT estimation", mrtt and srtt,"[' are passed to\ntcp_bpf_rtt()', ' so that bpf programs get more information about RTT\ncomputation in BPF_SOCK_OPS_RTT_CB.\n\nThe difference between bpf_sock_ops->srtt_us and the srtt here is: the\nformer is an old rtt before update', ' while srtt passed by tcp_bpf_rtt()\nis that after update.\n\nSigned-off-by: Philo Lu <lulie@linux.alibaba.com>\nLink: https://lore.kernel.org/r/20240425161724.73707-2-lulie@linux.alibaba.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Add new arguments mrtt and srtt to BPF_SOCK_OPS_RTT_CB for RTT estimation.,"mrtt,srtt,RTT",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['socket like programs']
a311c3f9c342fc12e6c8a27e22c81955ab2a336c,a311c3f9c342fc12e6c8a27e22c81955ab2a336c,Alexei Starovoitov,ast@kernel.org,1714074020,Alexei Starovoitov,ast@kernel.org,1714074163,dce5b752510c9ff8741a4cac01ea49fb0a7d3d99,638a485c4996be1d38303cf25ea8d12dfd16011b 6a2d30d3c5bf9f088dcfd5f3746b04d84f2fab83,"Merge branch 'check-bpf_dummy_struct_ops-program-params-for-test-runs'

Eduard Zingerman says:

====================
check bpf_dummy_struct_ops program params for test runs

When doing BPF_PROG_TEST_RUN for bpf_dummy_struct_ops programs","
execution should be rejected when NULL is passed for non-nullable
params","["" because for such params verifier assumes that such params are\nnever NULL and thus might optimize out NULL checks.\n\nThis problem was reported by Jose E. Marchesi in off-list discussion.\nThe code generated by GCC for dummy_st_ops_success/test_1() function\ndiffers from LLVM variant in a way that allows verifier to remove the\nNULL check. The test dummy_st_ops/dummy_init_ret_value actually sets\nthe 'state' parameter to NULL"", ' thus GCC-generated version of the test\ntriggers NULL pointer dereference when BPF program is executed.\n\nThis patch-set addresses the issue in the following steps:\n- patch #1 marks bpf_dummy_struct_ops.test_1 parameter as nullable', ""\n  for verifier to have correct assumptions about test_1() programs;\n- patch #2 modifies dummy_st_ops/dummy_init_ret_value to trigger NULL\n  dereference with both GCC and LLVM (if patch #1 is not applied);\n- patch #3 adjusts a few dummy_st_ops test cases to avoid passing NULL\n  for 'state' parameter of test_2() and test_sleepable() functions"", '\n  as parameters of these functions are not marked as nullable;\n- patch #4 adjusts bpf_dummy_struct_ops to reject test execution of\n  programs if NULL is passed for non-nullable parameter;\n- patch #5 adds a test to verify logic from patch #4.\n====================\n\nLink: https://lore.kernel.org/r/20240424012821.595216-1-eddyz87@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Ensure BPF_PROG_TEST_RUN rejects NULL non-nullable parameters for bpf_dummy_struct_ops programs.,"BPF_PROG_TEST_RUN,NULL,params",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6a2d30d3c5bf9f088dcfd5f3746b04d84f2fab83,6a2d30d3c5bf9f088dcfd5f3746b04d84f2fab83,Eduard Zingerman,eddyz87@gmail.com,1713922101,Alexei Starovoitov,ast@kernel.org,1714074163,dce5b752510c9ff8741a4cac01ea49fb0a7d3d99,980ca8ceeae69ddf362870ea9183f389ae26324a,"selftests/bpf: dummy_st_ops should reject 0 for non-nullable params

Check if BPF_PROG_TEST_RUN for bpf_dummy_struct_ops programs
rejects execution if NULL is passed for non-nullable parameter.

Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20240424012821.595216-6-eddyz87@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Ensure bpf_dummy_struct_ops programs reject null parameters in BPF_PROG_TEST_RUN tests.,"selftests,bpf,rejects",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
980ca8ceeae69ddf362870ea9183f389ae26324a,980ca8ceeae69ddf362870ea9183f389ae26324a,Eduard Zingerman,eddyz87@gmail.com,1713922100,Alexei Starovoitov,ast@kernel.org,1714074163,b66c8c8eacef1fd3ce9d0dd4afa3f04643706a6b,f612210d456a0b969a0adca91e68dbea0e0ea301,"bpf: check bpf_dummy_struct_ops program params for test runs

When doing BPF_PROG_TEST_RUN for bpf_dummy_struct_ops programs","
reject execution when NULL is passed for non-nullable params.
For programs with non-nullable params verifier assumes that
such params are never NULL and thus might optimize out NULL checks.

Suggested-by: Kui-Feng Lee <sinquersw@gmail.com>
Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20240424012821.595216-5-eddyz87@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Reject BPF_PROG_TEST_RUN for bpf_dummy_struct_ops with nullable params to prevent incorrect verifier optimizations.,"bpf_dummy_struct_ops, BPF_PROG_TEST_RUN, nullable",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f612210d456a0b969a0adca91e68dbea0e0ea301,f612210d456a0b969a0adca91e68dbea0e0ea301,Eduard Zingerman,eddyz87@gmail.com,1713922099,Alexei Starovoitov,ast@kernel.org,1714074163,1158bf3d384b77d23829af05650ae92f3668c44a,3b3b84aacb4420226576c9732e7b539ca7b79633,"selftests/bpf: do not pass NULL for non-nullable params in dummy_st_ops

dummy_st_ops.test_2 and dummy_st_ops.test_sleepable do not have their
'state' parameter marked as nullable. Update dummy_st_ops.c to avoid
passing NULL for such parameters"," as the next patch would allow kernel
to enforce this restriction.

Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20240424012821.595216-4-eddyz87@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Correct selftests/bpf by avoiding NULL parameters for non-nullable 'state' params in dummy_st_ops functions.,"selftests,bpf,dummy_st_ops",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
3b3b84aacb4420226576c9732e7b539ca7b79633,3b3b84aacb4420226576c9732e7b539ca7b79633,Eduard Zingerman,eddyz87@gmail.com,1713922098,Alexei Starovoitov,ast@kernel.org,1714074163,542564b85c01b47de38e1ab91e12169f97a6c483,1479eaff1f16983d8fda7c5a08a586c21891087d,"selftests/bpf: adjust dummy_st_ops_success to detect additional error

As reported by Jose E. Marchesi in off-list discussion"," GCC and LLVM
generate slightly different code for dummy_st_ops_success/test_1():

  SEC(""struct_ops/test_1"")
  int BPF_PROG(test_1","["" struct bpf_dummy_ops_state *state)\n  {\n  \tint ret;\n\n  \tif (!state)\n  \t\treturn 0xf2f3f4f5;\n\n  \tret = state->val;\n  \tstate->val = 0x5a;\n  \treturn ret;\n  }\n\n  GCC-generated                  LLVM-generated\n  ----------------------------   ---------------------------\n  0: r1 = *(u64 *)(r1 + 0x0)     0: w0 = -0xd0c0b0b\n  1: if r1 == 0x0 goto 5f        1: r1 = *(u64 *)(r1 + 0x0)\n  2: r0 = *(s32 *)(r1 + 0x0)     2: if r1 == 0x0 goto 6f\n  3: *(u32 *)(r1 + 0x0) = 0x5a   3: r0 = *(u32 *)(r1 + 0x0)\n  4: exit                        4: w2 = 0x5a\n  5: r0 = -0xd0c0b0b             5: *(u32 *)(r1 + 0x0) = r2\n  6: exit                        6: exit\n\nIf the 'state' argument is not marked as nullable in\nnet/bpf/bpf_dummy_struct_ops.c"", "" the verifier would assume that\n'r1 == 0x0' is never true:\n- for the GCC version"", ' this means that instructions #5-6 would be\n  marked as dead and removed;\n- for the LLVM version', "" all instructions would be marked as live.\n\nThe test dummy_st_ops/dummy_init_ret_value actually sets the 'state'\nparameter to NULL.\n\nTherefore"", "" when the 'state' argument is not marked as nullable"", '\nthe GCC-generated version of the code would trigger a NULL pointer\ndereference at instruction #3.\n\nThis patch updates the test_1() test case to always follow a shape\nsimilar to the GCC-generated version above', "" in order to verify whether\nthe 'state' nullability is marked correctly.\n\nReported-by: Jose E. Marchesi <jemarch@gnu.org>\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20240424012821.595216-3-eddyz87@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",The commit adjusts selftests in bpf to detect additional error cases highlighted by Jose E. Marchesi.,"selftests,bpf,error",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tracepoints like programs']
1479eaff1f16983d8fda7c5a08a586c21891087d,1479eaff1f16983d8fda7c5a08a586c21891087d,Eduard Zingerman,eddyz87@gmail.com,1713922097,Alexei Starovoitov,ast@kernel.org,1714074163,673573b21f8fe60c3aee6bf8fc7461055d858624,638a485c4996be1d38303cf25ea8d12dfd16011b,"bpf: mark bpf_dummy_struct_ops.test_1 parameter as nullable

Test case dummy_st_ops/dummy_init_ret_value passes NULL as the first
parameter of the test_1() function. Mark this parameter as nullable to
make verifier aware of such possibility.
Otherwise"," NULL check in the test_1() code:

      SEC(""struct_ops/test_1"")
      int BPF_PROG(test_1","[' struct bpf_dummy_ops_state *state)\n      {\n            if (!state)\n                    return ...;\n\n            ... access state ...\n      }\n\nMight be removed by verifier', ' thus triggering NULL pointer dereference\nunder certain conditions.\n\nReported-by: Jose E. Marchesi <jemarch@gnu.org>\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20240424012821.595216-2-eddyz87@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit marks the bpf_dummy_struct_ops.test_1 parameter as nullable to improve verifier awareness.,"nullable,test_1,verifier",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
638a485c4996be1d38303cf25ea8d12dfd16011b,638a485c4996be1d38303cf25ea8d12dfd16011b,Andrea Righi,andrea.righi@canonical.com,1714053987,Andrii Nakryiko,andrii@kernel.org,1714070764,e37af36defb714e5389207c788c35f4ae534f837,8ec3bf5c31d2a59c320ff59397f6ac362341d9d7,"selftests/bpf: Add ring_buffer__consume_n test.

Add a testcase for the ring_buffer__consume_n() API.

The test produces multiple samples in a ring buffer"," using a
sys_getpid() fentry prog","[' and consumes them from user-space in batches', '\nrather than consuming all of them greedily', ' like ring_buffer__consume()\ndoes.\n\nSigned-off-by: Andrea Righi <andrea.righi@canonical.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/lkml/CAEf4BzaR4zqUpDmj44KNLdpJ=Tpa97GrvzuzVNO5nM6b7oWd1w@mail.gmail.com\nLink: https://lore.kernel.org/bpf/20240425140627.112728-1-andrea.righi@canonical.com\n', '']",Add a test case for ring_buffer__consume_n in selftests/bpf.,"testcase, ring_buffer, API",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
8ec3bf5c31d2a59c320ff59397f6ac362341d9d7,8ec3bf5c31d2a59c320ff59397f6ac362341d9d7,Alexei Starovoitov,ast@kernel.org,1713999329,Martin KaFai Lau,martin.lau@kernel.org,1714067320,bf3311fccbe189adc9b5c517807599e111d9da8f,52578f7f53ff8fe3a8f6f3bc8b5956615c07a16e,"bpf: Add bpf_guard_preempt() convenience macro

Add bpf_guard_preempt() macro that uses newly introduced
bpf_preempt_disable/enable() kfuncs to guard a critical section.

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Acked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>
Link: https://lore.kernel.org/r/20240424225529.16782-1-alexei.starovoitov@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Introduce bpf_guard_preempt() macro for critical section protection using new bpf_preempt_disable/enable() kfuncs.,"bpf, macro, preempt",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
caf93883f623ebd29989e3c35423f386ea4a41bb,caf93883f623ebd29989e3c35423f386ea4a41bb,David S. Miller,davem@davemloft.net,1714031532,David S. Miller,davem@davemloft.net,1714031532,3e523116c5e7de8d0a426fa022f7a4c13966e453,d806871612712f1d08eb7ce81efd4ca81ca5bca1 2bf90a57f0e682872c5cfb66ffa45e432bb9c7ae,"Merge branch 'tcp-trace-next'

Philo Lu says:

====================
tcp: update TCPCB_EVER_RETRANS after trace_tcp_retransmit_skb()

Move TCPCB_EVER_RETRANS updating after the trace_tcp_retransmit_skb()
in __tcp_retransmit_skb()"," and then we are aware of whether the skb has
ever been retransmitted in this tracepoint. This can be used","[' e.g.', ' to get\nretransmission efficiency by counting skbs w/ and w/o TCPCB_EVER_RETRANS\n(through bpf tracing programs).\n\nFor this purpose', ' TCPCB_EVER_RETRANS is also needed to be exposed to bpf.\nPreviously', ' the flags are defined as macros in struct tcp_skb_cb. I moved them\nout into a new enum', ' and then they can be accessed with vmlinux.h.\n\nWe have discussed to achieve this with BPF_SOCK_OPS in [0]', ' and using\ntracepoint is thought to be a better solution.\n\n[0]\nhttps://lore.kernel.org/all/20240417124622.35333-1-lulie@linux.alibaba.com/\n====================\n\nSigned-off-by: David S. Miller <davem@davemloft.net>\n', '']",The commit updates TCPCB_EVER_RETRANS after trace_tcp_retransmit_skb in TCP retransmission handling.,"TCP,tracepoint,retransmission",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
14b5fb2145caeb909a1cd57d9cd5e0c3cd005642,14b5fb2145caeb909a1cd57d9cd5e0c3cd005642,Philo Lu,lulie@linux.alibaba.com,1713673208,David S. Miller,davem@davemloft.net,1714031532,aa8c4baa2eae97db46536dfef4c67f067608e3b2,d806871612712f1d08eb7ce81efd4ca81ca5bca1,"tcp: move tcp_skb_cb->sacked flags to enum

Move the flag definitions for tcp_skb_cb->sacked into a new enum named
tcp_skb_cb_sacked_flags"," then we can get access to them in bpf via
vmlinux.h","[' e.g.', ' in tracepoints.\n\nThis patch does not change any existing functionality.\n\nSigned-off-by: Philo Lu <lulie@linux.alibaba.com>\nReviewed-by: Eric Dumazet <edumazet@google.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>\n', '']",Move tcp_skb_cb->sacked flags to a new enum for better access via vmlinux.h in BPF.,"tcp,flags,enum",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['tc/netfilter like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d806871612712f1d08eb7ce81efd4ca81ca5bca1,d806871612712f1d08eb7ce81efd4ca81ca5bca1,Jakub Kicinski,kuba@kernel.org,1714014947,Jakub Kicinski,kuba@kernel.org,1714014947,d66380e8a6418c7d824b07c2994fbcae96d63684,2fa809b90617817fec2802c7cfaeb2c66fd04c2b 3f584c211d8cc049848620472aaec1bebd8ddaae,"Merge branch 'selftests-net-extract-bpf-building-logic-from-the-makefile'

Jakub Kicinski says:

====================
selftests: net: extract BPF building logic from the Makefile

This has been sitting in my tree for a while. I will soon add YNL/libynl
support for networking selftests. This prompted a small cleanup of
the selftest makefile for net/. We don't want to be piling logic
for each library in there. YNL will get its own .mk file which can
be included. Do the same for the BPF building section"," already.

No funcional changes here","[' just a code move and small rename.\n====================\n\nLink: https://lore.kernel.org/r/20240423183542.3807234-1-kuba@kernel.org\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",The commit extracts BPF building logic from the network selftests Makefile for better organization.,"selftests, BPF, Makefile",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['tracepoints like programs', 'kprobe/uprobe/ftrace like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6b88ce902f0bdcb3694a6ceddc8b3d0b40db3772,6b88ce902f0bdcb3694a6ceddc8b3d0b40db3772,Jakub Kicinski,kuba@kernel.org,1713897341,Jakub Kicinski,kuba@kernel.org,1714014945,fe004b46fad8cbb08507761b6985ee10e3a8d003,2fa809b90617817fec2802c7cfaeb2c66fd04c2b,"selftests: net: name bpf objects consistently and simplify Makefile

The BPF sources moved with bpf_offload.py have a suffix of .bpf.c
which seems to be useful convention. Rename the 2 other BPF sources
we had. Use wildcard in the Makefile"," since we can match all those
files easily now.

Link: https://lore.kernel.org/r/20240423183542.3807234-2-kuba@kernel.org
Signed-off-by: Jakub Kicinski <kuba@kernel.org>
",[''],This commit renames BPF source files and simplifies the Makefile in the selftests for net.,"rename, Makefile, selftests",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8000e627dc98efc44658af6150fd81c62d936b1b,8000e627dc98efc44658af6150fd81c62d936b1b,Vadim Fedorenko,vadfed@meta.com,1713826224,Martin KaFai Lau,martin.lau@kernel.org,1713999670,788f59542e51908ad78c8fb9d32be432a2b44397,91541ab192fc7f573e6c711ba9c2ae22a299c408,"selftests: bpf: crypto: add benchmark for crypto functions

Some simple benchmarks are added to understand the baseline of
performance.

Signed-off-by: Vadim Fedorenko <vadfed@meta.com>
Link: https://lore.kernel.org/r/20240422225024.2847039-5-vadfed@meta.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Added benchmark tests for eBPF crypto functions to assess baseline performance.,"benchmark, crypto functions, performance",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
91541ab192fc7f573e6c711ba9c2ae22a299c408,91541ab192fc7f573e6c711ba9c2ae22a299c408,Vadim Fedorenko,vadfed@meta.com,1713826223,Martin KaFai Lau,martin.lau@kernel.org,1713999670,229a0f6d70ca1af847a13a6e29f737dbfeb19685,fda4f71282b21a8cf230b656781efb0a41371fd4,"selftests: bpf: crypto skcipher algo selftests

Add simple tc hook selftests to show the way to work with new crypto
BPF API. Some tricky dynptr initialization is used to provide empty iv
dynptr. Simple AES-ECB algo is used to demonstrate encryption and
decryption of fixed size buffers.

Signed-off-by: Vadim Fedorenko <vadfed@meta.com>
Link: https://lore.kernel.org/r/20240422225024.2847039-4-vadfed@meta.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Add selftests for tc hook using the new crypto BPF API with AES-ECB encryption demonstration.,"selftests, crypto, AES",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tc/netfilter like programs']
fda4f71282b21a8cf230b656781efb0a41371fd4,fda4f71282b21a8cf230b656781efb0a41371fd4,Vadim Fedorenko,vadfed@meta.com,1713826222,Martin KaFai Lau,martin.lau@kernel.org,1713999670,79d1a3e8f78b070461d92be74bf086cebc21387b,3e1c6f35409f9e447bf37f64840f5b65576bfb78,"bpf: crypto: add skcipher to bpf crypto

Implement skcipher crypto in BPF crypto framework.

Signed-off-by: Vadim Fedorenko <vadfed@meta.com>
Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
Link: https://lore.kernel.org/r/20240422225024.2847039-3-vadfed@meta.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Add skcipher cryptographic support to BPF crypto framework.,"skcipher,crypto,BPF",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3e1c6f35409f9e447bf37f64840f5b65576bfb78,3e1c6f35409f9e447bf37f64840f5b65576bfb78,Vadim Fedorenko,vadfed@meta.com,1713826221,Martin KaFai Lau,martin.lau@kernel.org,1713999670,6ff5c59d598f975728cfdd1f4d29407d4b6cae01,95c07d58250ca3ed01855c20be568cf04e15382f,"bpf: make common crypto API for TC/XDP programs

Add crypto API support to BPF to be able to decrypt or encrypt packets
in TC/XDP BPF programs. Special care should be taken for initialization
part of crypto algo because crypto alloc) doesn't work with preemtion
disabled"," it can be run only in sleepable BPF program. Also async crypto
is not supported because of the very same issue - TC/XDP BPF programs
are not sleepable.

Signed-off-by: Vadim Fedorenko <vadfed@meta.com>
Link: https://lore.kernel.org/r/20240422225024.2847039-2-vadfed@meta.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Introduce crypto API to enable packet encryption and decryption in TC/XDP BPF programs.,"crypto,API,TC/XDP",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['xdp like programs', 'tc/netfilter like programs']"
95c07d58250ca3ed01855c20be568cf04e15382f,95c07d58250ca3ed01855c20be568cf04e15382f,Haiyue Wang,haiyue.wang@intel.com,1713937507,Alexei Starovoitov,ast@kernel.org,1713999506,8dc6f962a3ed628cc02cfcd2b862a96a38c72c0f,82e38a505c9868e784ec31e743fd8a9fa5ca1084,"bpf: update the comment for BTF_FIELDS_MAX

The commit d56b63cf0c0f (""bpf: add support for bpf_wq user type"")
changes the fields support number to 11"," just sync the comment.

Signed-off-by: Haiyue Wang <haiyue.wang@intel.com>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20240424054526.8031-1-haiyue.wang@intel.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Update comment for BTF_FIELDS_MAX to reflect support for 11 fields.,"BTF_FIELDS_MAX,comment,update",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
82e38a505c9868e784ec31e743fd8a9fa5ca1084,82e38a505c9868e784ec31e743fd8a9fa5ca1084,Alexei Starovoitov,ast@kernel.org,1713992238,Alexei Starovoitov,ast@kernel.org,1713992705,90df058db0db4dde730a1aff5fb2eb4119db8634,5305b378b351dc5fd55f5f1f37ef362ae0e11d7e,"selftests/bpf: Fix wq test.

The wq test was missing destroy(skel) part which was causing bpf progs to stay
loaded. That was causing test_progs to complain with
""Failed to unload bpf_testmod.ko from kernel: -11"" message"," but adding
destroy() wasn't enough","[' since wq callback may be delayed', ' so loop on unload of\nbpf_testmod if errno is EAGAIN.\n\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nFixes: 8290dba51910 (""selftests/bpf: wq: add bpf_wq_start() checks"")\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes wq test by adding missing destroy(skel) to unload BPF programs correctly.,"wq test, destroy, unload",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e4c68bbaff1153e8730c16f566c78a25b2046372,e4c68bbaff1153e8730c16f566c78a25b2046372,Geliang Tang,tanggeliang@kylinos.cn,1713868531,Martin KaFai Lau,martin.lau@kernel.org,1713989549,2aa5dc5da492f6587ba40aea30d9f93339e18172,c6c40798428180516df80ce89da7bbfe1f6a828a,"selftests/bpf: Use make_sockaddr in test_sock_addr

This patch uses public helper make_sockaddr() exported in network_helpers.h
instead of the local defined function mk_sockaddr() in test_sock_addr.c.
This can avoid duplicate code.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/1473e189d6ca1a3925de4c5354d191a14eca0f3f.1713868264.git.tanggeliang@kylinos.cn
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,"Refactored test_sock_addr to use make_sockaddr from network_helpers.h, reducing code duplication.","selftests,bpf,make_sockaddr",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
c6c40798428180516df80ce89da7bbfe1f6a828a,c6c40798428180516df80ce89da7bbfe1f6a828a,Geliang Tang,tanggeliang@kylinos.cn,1713868530,Martin KaFai Lau,martin.lau@kernel.org,1713989548,fddfaf7dc4a7b906aa8983a699d1e007733dd977,e1cdb70d075e02b1f410b8446a8ff959fa15f0ee,"selftests/bpf: Use connect_to_addr in test_sock_addr

This patch uses public network helper connect_to_addr() exported in
network_helpers.h instead of the local defined function connect_to_server()
in test_sock_addr.c. This can avoid duplicate code.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/f263797712d93fdfaf2943585c5dfae56714a00b.1713868264.git.tanggeliang@kylinos.cn
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Replace local function connect_to_server with public helper connect_to_addr in bpf selftests.,"selftests,bpf,connect_to_addr",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
e1cdb70d075e02b1f410b8446a8ff959fa15f0ee,e1cdb70d075e02b1f410b8446a8ff959fa15f0ee,Geliang Tang,tanggeliang@kylinos.cn,1713868529,Martin KaFai Lau,martin.lau@kernel.org,1713989548,50215708f243c87eec87717cfbe66a97877325dd,285cffbaa8e6056c2595e07e3a320e55c71870ad,"selftests/bpf: Use start_server_addr in test_sock_addr

Include network_helpers.h in test_sock_addr.c"," use the newly added public
helper start_server_addr() instead of the local defined function
start_server(). This can avoid duplicate code.

In order to use functions defined in network_helpers.c in test_sock_addr.c","['\nMakefile needs to be updated and <Linux/err.h> needs to be included in\nnetwork_helpers.h to avoid compilation errors.\n\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nLink: https://lore.kernel.org/r/3101f57bde5502383eb41723c8956cc26be06893.1713868264.git.tanggeliang@kylinos.cn\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Refactor test_sock_addr to use the start_server_addr helper from network_helpers for cleaner code.,"selftests,bpf,network_helpers",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['socket like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
285cffbaa8e6056c2595e07e3a320e55c71870ad,285cffbaa8e6056c2595e07e3a320e55c71870ad,Geliang Tang,tanggeliang@kylinos.cn,1713868528,Martin KaFai Lau,martin.lau@kernel.org,1713989548,22eb34fa81d0539efda298351b62c08b15845dfb,151f7442436658ee84076681d8f52e987fe147ea,"selftests/bpf: Use log_err in open_netns/close_netns

ASSERT helpers defined in test_progs.h shouldn't be used in public
functions like open_netns() and close_netns(). Since they depend on
test__fail() which defined in test_progs.c. Public functions may be
used not only in test_progs.c"," but in other tests like test_sock_addr.c
in the next commit.

This patch uses log_err() to replace ASSERT helpers in open_netns()
and close_netns() in network_helpers.c to decouple dependencies","[' then\nuses ASSERT_OK_PTR() to check the return values of all open_netns().\n\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nLink: https://lore.kernel.org/r/d1dad22b2ff4909af3f8bfd0667d046e235303cb.1713868264.git.tanggeliang@kylinos.cn\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Replaced ASSERT helpers with log_err in open_netns and close_netns to reduce dependencies.,"log_err, open_netns, dependencies",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
151f7442436658ee84076681d8f52e987fe147ea,151f7442436658ee84076681d8f52e987fe147ea,Geliang Tang,tanggeliang@kylinos.cn,1713868527,Martin KaFai Lau,martin.lau@kernel.org,1713989548,207cd2dec61f6841b4257c91909de2b07d628490,55d30cc90fd42587594345a025b34399585e6e19,"selftests/bpf: Fix a fd leak in error paths in open_netns

As Martin mentioned in review comment"," there is an existing bug that
orig_netns_fd will be leaked in the later ""goto fail;"" case after
open(""/proc/self/ns/net"") in open_netns() in network_helpers.c. This
patch adds ""close(token->orig_netns_fd);"" before ""free(token);"" to
fix it.

Fixes: a30338840fa5 (""selftests/bpf: Move open_netns() and close_netns() into network_helpers.c"")
Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/a104040b47c3c34c67f3f125cdfdde244a870d3c.1713868264.git.tanggeliang@kylinos.cn
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Fix a file descriptor leak in open_netns() in the BPF selftests network_helpers.c file.,"fd leak,selftests,BPF",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
55d30cc90fd42587594345a025b34399585e6e19,55d30cc90fd42587594345a025b34399585e6e19,Alexei Starovoitov,ast@kernel.org,1713977269,Alexei Starovoitov,ast@kernel.org,1713977285,c5582f4ddd6e4f9bba3bf865a063d8d7ac39f45e,dc92febf7b93da5049fe177804e6b1961fcc6bd7 3134396f1cba939783b87c63dae3a54708285a9a,"Merge branch 'introduce-bpf_preempt_-disable-enable'

Kumar Kartikeya Dwivedi says:

====================
Introduce bpf_preempt_{disable","enable}

This set introduces two kfuncs","[' bpf_preempt_disable and\nbpf_preempt_enable', ' which are wrappers around preempt_disable and\npreempt_enable in the kernel. These functions allow a BPF program to\nhave code sections where preemption is disabled. There are multiple use\ncases that are served by such a feature', ' a few are listed below:\n\n1. Writing safe per-CPU alogrithms/data structures that work correctly\n   across different contexts.\n2. Writing safe per-CPU allocators similar to bpf_memalloc on top of\n   array/arena memory blobs.\n3. Writing locking algorithms in BPF programs natively.\n\nNote that local_irq_disable/enable equivalent is also needed for proper\nIRQ context protection', ' but that is a more involved change and will be\nsent later.\n\nWhile bpf_preempt_{disable', 'enable} is not sufficient for all of these\nusage scenarios on its own', ' it is still necessary.\n\nThe same effect as these kfuncs can in some sense be already achieved\nusing the bpf_spin_lock or rcu_read_lock APIs', ' therefore from the\nstandpoint of kernel functionality exposure in the verifier', ' this is\nwell understood territory.\n\nNote that these helpers do allow calling kernel helpers and kfuncs from\nwithin the non-preemptible region (unless sleepable). Otherwise', ' any\nlocks built using the preemption helpers will be as limited as\nexisting bpf_spin_lock.\n\nNesting is allowed by keeping a counter for tracking remaining enables\nrequired to be performed. Similar approach can be applied to\nrcu_read_locks in a follow up.\n\nChangelog\n=========\nv1: https://lore.kernel.org/bpf/20240423061922.2295517-1-memxor@gmail.com\n\n * Move kfunc BTF ID declerations above css task kfunc for\n   !CONFIG_CGROUPS config (Alexei)\n * Add test case for global function call in non-preemptible region\n   (Jiri)\n====================\n\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/r/20240424031315.2757363-1-memxor@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Introduce new kfuncs for managing preemption in eBPF programs.,"kfuncs,preemption,eBPF",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3134396f1cba939783b87c63dae3a54708285a9a,3134396f1cba939783b87c63dae3a54708285a9a,Kumar Kartikeya Dwivedi,memxor@gmail.com,1713928395,Alexei Starovoitov,ast@kernel.org,1713977269,c5582f4ddd6e4f9bba3bf865a063d8d7ac39f45e,fc7566ad0a826cdc8886c5dbbb39ce72a0dc6333,"selftests/bpf: Add tests for preempt kfuncs

Add tests for nested cases"," nested count preservation upon different
subprog calls that disable/enable preemption","[' and test sleepable helper\ncall in non-preemptible regions.\n\n182/1   preempt_lock/preempt_lock_missing_1:OK\n182/2   preempt_lock/preempt_lock_missing_2:OK\n182/3   preempt_lock/preempt_lock_missing_3:OK\n182/4   preempt_lock/preempt_lock_missing_3_minus_2:OK\n182/5   preempt_lock/preempt_lock_missing_1_subprog:OK\n182/6   preempt_lock/preempt_lock_missing_2_subprog:OK\n182/7   preempt_lock/preempt_lock_missing_2_minus_1_subprog:OK\n182/8   preempt_lock/preempt_balance:OK\n182/9   preempt_lock/preempt_balance_subprog_test:OK\n182/10  preempt_lock/preempt_global_subprog_test:OK\n182/11  preempt_lock/preempt_sleepable_helper:OK\n182     preempt_lock:OK\nSummary: 1/11 PASSED', ' 0 SKIPPED', ' 0 FAILED\n\nSigned-off-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nLink: https://lore.kernel.org/r/20240424031315.2757363-3-memxor@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add selftests for nested preempt kfunc cases in BPF.,"selftests, preempt, kfuncs",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fc7566ad0a826cdc8886c5dbbb39ce72a0dc6333,fc7566ad0a826cdc8886c5dbbb39ce72a0dc6333,Kumar Kartikeya Dwivedi,memxor@gmail.com,1713928394,Alexei Starovoitov,ast@kernel.org,1713977269,141b3fc7a2c4174e8d6d685a20229ffedea61846,dc92febf7b93da5049fe177804e6b1961fcc6bd7,bpf: Introduce bpf_preempt_[disable,"enable] kfuncs

Introduce two new BPF kfuncs","[' bpf_preempt_disable and\nbpf_preempt_enable. These kfuncs allow disabling preemption in BPF\nprograms. Nesting is allowed', ' since the intended use cases includes\nbuilding native BPF spin locks without kernel helper involvement. Apart\nfrom that', ' this can be used to per-CPU data structures for cases where\nprograms (or userspace) may preempt one or the other. Currently', ' while\nper-CPU access is stable', ' whether it will be consistent is not\nguaranteed', ' as only migration is disabled for BPF programs.\n\nGlobal functions are disallowed from being called', ' but support for them\nwill be added as a follow up not just preempt kfuncs', ' but rcu_read_lock\nkfuncs as well. Static subprog calls are permitted. Sleepable helpers\nand kfuncs are disallowed in non-preemptible regions.\n\nSigned-off-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nLink: https://lore.kernel.org/r/20240424031315.2757363-2-memxor@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Introduce two new BPF kfuncs for preempt disable support.,BPF kfuncs preempt,It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
dc92febf7b93da5049fe177804e6b1961fcc6bd7,dc92febf7b93da5049fe177804e6b1961fcc6bd7,Alexei Starovoitov,ast@kernel.org,1713974423,Alexei Starovoitov,ast@kernel.org,1713974810,cd49ada6055ba7c3933b03d82998efb303ec19a1,6e10b6350a67d398c795ac0b93a7bb7103633fe4,"bpf: Don't check for recursion in bpf_wq_work.

__bpf_prog_enter_sleepable_recur does recursion check which is not applicable
to wq callback. The callback function is part of bpf program and bpf prog might
be running on the same cpu. So recursion check would incorrectly prevent
callback from running. The code can call __bpf_prog_enter_sleepable()"," but
run_ctx would be fake","[' hence use explicit rcu_read_lock_trace();\nmigrate_disable(); to address this problem. Another reason to open code is\n__bpf_prog_enter* are not available in !JIT configs.\n\nReported-by: kernel test robot <lkp@intel.com>\nCloses: https://lore.kernel.org/oe-kbuild-all/202404241719.IIGdpAku-lkp@intel.com/\nCloses: https://lore.kernel.org/oe-kbuild-all/202404241811.FFV4Bku3-lkp@intel.com/\nFixes: eb48f6cd41a0 (""bpf: wq: add bpf_wq_init"")\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Remove unnecessary recursion check in bpf_wq_work callback function.,"recursion, bpf_wq_work, callback",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['other']
1adb825af946fa6b2104c1713ad4999283e09fbc,1adb825af946fa6b2104c1713ad4999283e09fbc,Joel Granados,j.granados@samsung.com,1687872619,Joel Granados,j.granados@samsung.com,1713944634,975b06017d9e24f8f150b792b3e44b8da0d1fc5e,f15843f725a55d7232aa9b699be52c2c3da06982,"bpf: Remove the now superfluous sentinel elements from ctl_table array

This commit comes at the tail end of a greater effort to remove the
empty elements at the end of the ctl_table arrays (sentinels) which
will reduce the overall build time size of the kernel and run time
memory bloat by ~64 bytes per sentinel (further information Link :
https://lore.kernel.org/all/ZO5Yx5JFogGi%2FcBo@bombadil.infradead.org/)

Remove sentinel element from bpf_syscall_table.

Acked-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Joel Granados <j.granados@samsung.com>
",,This commit removes superfluous sentinel elements from the ctl_table array to reduce kernel build size and memory usage.,"sentinel, ctl_table, bpf",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The syscall interface,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6e10b6350a67d398c795ac0b93a7bb7103633fe4,6e10b6350a67d398c795ac0b93a7bb7103633fe4,Alexei Starovoitov,ast@kernel.org,1713922286,Alexei Starovoitov,ast@kernel.org,1713926817,93ee7e7ef3781f5b19811715f4dc05a5a78c06cb,a7de265cb2d849f8986a197499ad58dca0a4f209 8290dba51910d36721ced6ccf03049ed6b7ea2ce,"Merge branch 'introduce-bpf_wq'

Benjamin Tissoires says:

====================
Introduce bpf_wq

This is a followup of sleepable bpf_timer[0].

When discussing sleepable bpf_timer"," it was thought that we should give
a try to bpf_wq","["" as the 2 APIs are similar but distinct enough to\njustify a new one.\n\nSo here it is.\n\nI tried to keep as much as possible common code in kernel/bpf/helpers.c\nbut I couldn't get away with code duplication in kernel/bpf/verifier.c.\n\nThis series introduces a basic bpf_wq support:\n- creation is supported\n- assignment is supported\n- running a simple bpf_wq is also supported.\n\nWe will probably need to extend the API further with:\n- a full delayed_work API (can be piggy backed on top with a correct\n  flag)\n- bpf_wq_cancel() <- apparently not"", ' this is shooting ourself in the\n  foot\n- bpf_wq_cancel_sync() (for sleepable programs)\n- documentation\n---\n\nFor reference', ' the use cases I have in mind:\n\n---\n\nBasically', ' I need to be able to defer a HID-BPF program for the\nfollowing reasons (from the aforementioned patch):\n1. defer an event:\n   Sometimes we receive an out of proximity event', ' but the device can not\n   be trusted enough', "" and we need to ensure that we won't receive another\n   one in the following n milliseconds. So we need to wait those n\n   milliseconds"", ' and eventually re-inject that event in the stack.\n\n2. inject new events in reaction to one given event:\n   We might want to transform one given event into several. This is the\n   case for macro keys where a single key press is supposed to send\n   a sequence of key presses. But this could also be used to patch a\n   faulty behavior', ' if a device forgets to send a release event.\n\n3. communicate with the device in reaction to one event:\n   We might want to communicate back to the device after a given event.\n   For example a device might send us an event saying that it came back\n   from sleeping state and needs to be re-initialized.\n\nCurrently we can achieve that by keeping a userspace program around', '\nraise a bpf event', ' and let that userspace program inject the events and\ncommands.\nHowever', ' we are just keeping that program alive as a daemon for just\nscheduling commands. There is no logic in it', "" so it doesn't really justify\nan actual userspace wakeup. So a kernel workqueue seems simpler to handle.\n\nbpf_timers are currently running in a soft IRQ context"", ' this patch\nseries implements a sleppable context for them.\n\nCheers', '\nBenjamin\n\n[0] https://lore.kernel.org/all/20240408-hid-bpf-sleepable-v6-0-0499ddd91b94@kernel.org/\n\nChanges in v2:\n- took previous review into account\n- mainly dropped BPF_F_WQ_SLEEPABLE\n- Link to v1: https://lore.kernel.org/r/20240416-bpf_wq-v1-0-c9e66092f842@kernel.org\n\n====================\n\nLink: https://lore.kernel.org/r/20240420-bpf_wq-v2-0-6c986a5a741f@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit introduces a new bpf_wq following the development of sleepable bpf_timer.,"bpf_wq,sleepable,bpf_timer",It's a new feature.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8290dba51910d36721ced6ccf03049ed6b7ea2ce,8290dba51910d36721ced6ccf03049ed6b7ea2ce,Benjamin Tissoires,bentiss@kernel.org,1713604156,Alexei Starovoitov,ast@kernel.org,1713926817,93ee7e7ef3781f5b19811715f4dc05a5a78c06cb,8e83da9732d91c60fdc651b2486c8e5935eb0ca2,"selftests/bpf: wq: add bpf_wq_start() checks

Allows to test if allocation/free works

Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
Link: https://lore.kernel.org/r/20240420-bpf_wq-v2-16-6c986a5a741f@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,This commit adds bpf_wq_start() checks in selftests for allocation and free operations.,"bpf_wq_start, selftests, allocation",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8e83da9732d91c60fdc651b2486c8e5935eb0ca2,8e83da9732d91c60fdc651b2486c8e5935eb0ca2,Benjamin Tissoires,bentiss@kernel.org,1713604155,Alexei Starovoitov,ast@kernel.org,1713926817,18999a6bd18485265aaa1b5767373890b899118a,01b7b1c5f3cc029bdd2652eba61e953ccd286c0e,"bpf: add bpf_wq_start

again"," copy/paste from bpf_timer_start().

Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
Link: https://lore.kernel.org/r/20240420-bpf_wq-v2-15-6c986a5a741f@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The commit adds a new function bpf_wq_start to the eBPF subsystem.,"bpf, wq, start",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
01b7b1c5f3cc029bdd2652eba61e953ccd286c0e,01b7b1c5f3cc029bdd2652eba61e953ccd286c0e,Benjamin Tissoires,bentiss@kernel.org,1713604154,Alexei Starovoitov,ast@kernel.org,1713926817,d42f14399f3586735de7a902beeb691b43ae1f24,81f1d7a583fa1fa14f0c4e6140d34b5e3d08d227,"selftests/bpf: add checks for bpf_wq_set_callback()

We assign the callback and set everything up.
The actual tests of these callbacks will be done when bpf_wq_start() is
available.

Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
Link: https://lore.kernel.org/r/20240420-bpf_wq-v2-14-6c986a5a741f@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Added selftests for bpf_wq_set_callback() function but await further tests with bpf_wq_start().,"selftests, bpf_wq_set_callback, callback",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
81f1d7a583fa1fa14f0c4e6140d34b5e3d08d227,81f1d7a583fa1fa14f0c4e6140d34b5e3d08d227,Benjamin Tissoires,bentiss@kernel.org,1713604153,Alexei Starovoitov,ast@kernel.org,1713926817,17f05f9ee42a2660f9ad0a48a2179800634fc5e9,e3d9eac99afd94980475833479332fefd74c5c2b,"bpf: wq: add bpf_wq_set_callback_impl

To support sleepable async callbacks"," we need to tell push_async_cb()
whether the cb is sleepable or not.

The verifier now detects that we are in bpf_wq_set_callback_impl and
can allow a sleepable callback to happen.

Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
Link: https://lore.kernel.org/r/20240420-bpf_wq-v2-13-6c986a5a741f@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Add bpf_wq_set_callback_impl to support sleepable async callbacks in eBPF.,"bpf, wq, sleepable",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e3d9eac99afd94980475833479332fefd74c5c2b,e3d9eac99afd94980475833479332fefd74c5c2b,Benjamin Tissoires,bentiss@kernel.org,1713604152,Alexei Starovoitov,ast@kernel.org,1713926817,574bb867d45251d887c5ace80758a5f01322909b,eb48f6cd41a0f7803770a76bbffb6bd5b1b2ae2f,"selftests/bpf: wq: add bpf_wq_init() checks

Allows to test if allocation/free works

Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
Link: https://lore.kernel.org/r/20240420-bpf_wq-v2-12-6c986a5a741f@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add selftests for bpf_wq_init to verify allocation and free operations.,"selftests,bpf_wq_init,allocation",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
eb48f6cd41a0f7803770a76bbffb6bd5b1b2ae2f,eb48f6cd41a0f7803770a76bbffb6bd5b1b2ae2f,Benjamin Tissoires,bentiss@kernel.org,1713604151,Alexei Starovoitov,ast@kernel.org,1713926817,46da490f63b2559a7d0915df149ab549f7ab0fdf,b4abee7c1ae3d59440e7915da28c6d2cd394738a,"bpf: wq: add bpf_wq_init

We need to teach the verifier about the second argument which is declared
as void * but which is of type KF_ARG_PTR_TO_MAP. We could have dropped
this extra case if we declared the second argument as struct bpf_map *","
but that means users will have to do extra casting to have their program
compile.

We also need to duplicate the timer code for the checking if the map
argument is matching the provided workqueue.

Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
Link: https://lore.kernel.org/r/20240420-bpf_wq-v2-11-6c986a5a741f@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Add bpf_wq_init with type check for the second argument to handle pointers to maps in eBPF verifier.,"bpf_wq_init,pointer,map",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b4abee7c1ae3d59440e7915da28c6d2cd394738a,b4abee7c1ae3d59440e7915da28c6d2cd394738a,Benjamin Tissoires,bentiss@kernel.org,1713604150,Alexei Starovoitov,ast@kernel.org,1713926813,a871c296f683f80a3bc59ffdcc383b357af5f497,246331e3f1eac905170a923f0ec76725c2558232,"selftests/bpf: add bpf_wq tests

We simply try in all supported map types if we can store/load a bpf_wq.

Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
Link: https://lore.kernel.org/r/20240420-bpf_wq-v2-10-6c986a5a741f@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Adds tests for storing/loading bpf_wq in all supported eBPF map types.,"bpf_wq,test,map",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
58a4c9b1e5a3e53c9148e80b90e1e43897ce77d1,58a4c9b1e5a3e53c9148e80b90e1e43897ce77d1,Eric Dumazet,edumazet@google.com,1713725006,Jakub Kicinski,kuba@kernel.org,1713924177,900327ad1156d87dc962da75decf355905324aa2,3584718cf2ec7e79b6814f2596dcf398c5fb2eca,"ipv4: check for NULL idev in ip_route_use_hint()

syzbot was able to trigger a NULL deref in fib_validate_source()
in an old tree [1].

It appears the bug exists in latest trees.

All calls to __in_dev_get_rcu() must be checked for a NULL result.

[1]
general protection fault"," probably for non-canonical address 0xdffffc0000000000: 0000 [#1] SMP KASAN
KASAN: null-ptr-deref in range [0x0000000000000000-0x0000000000000007]
CPU: 2 PID: 3257 Comm: syz-executor.3 Not tainted 5.10.0-syzkaller #0
Hardware name: QEMU Standard PC (Q35 + ICH9","[' 2009)', ' BIOS 1.16.3-debian-1.16.3-2~bpo12+1 04/01/2014\n RIP: 0010:fib_validate_source+0xbf/0x15a0 net/ipv4/fib_frontend.c:425\nCode: 18 f2 f2 f2 f2 42 c7 44 20 23 f3 f3 f3 f3 48 89 44 24 78 42 c6 44 20 27 f3 e8 5d 88 48 fc 4c 89 e8 48 c1 e8 03 48 89 44 24 18 <42> 80 3c 20 00 74 08 4c 89 ef e8 d2 15 98 fc 48 89 5c 24 10 41 bf\nRSP: 0018:ffffc900015fee40 EFLAGS: 00010246\nRAX: 0000000000000000 RBX: ffff88800f7a4000 RCX: ffff88800f4f90c0\nRDX: 0000000000000000 RSI: 0000000004001eac RDI: ffff8880160c64c0\nRBP: ffffc900015ff060 R08: 0000000000000000 R09: ffff88800f7a4000\nR10: 0000000000000002 R11: ffff88800f4f90c0 R12: dffffc0000000000\nR13: 0000000000000000 R14: 0000000000000000 R15: ffff88800f7a4000\nFS:  00007f938acfe6c0(0000) GS:ffff888058c00000(0000) knlGS:0000000000000000\nCS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\nCR2: 00007f938acddd58 CR3: 000000001248e000 CR4: 0000000000352ef0\nDR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\nDR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400\nCall Trace:\n  ip_route_use_hint+0x410/0x9b0 net/ipv4/route.c:2231\n  ip_rcv_finish_core+0x2c4/0x1a30 net/ipv4/ip_input.c:327\n  ip_list_rcv_finish net/ipv4/ip_input.c:612 [inline]\n  ip_sublist_rcv+0x3ed/0xe50 net/ipv4/ip_input.c:638\n  ip_list_rcv+0x422/0x470 net/ipv4/ip_input.c:673\n  __netif_receive_skb_list_ptype net/core/dev.c:5572 [inline]\n  __netif_receive_skb_list_core+0x6b1/0x890 net/core/dev.c:5620\n  __netif_receive_skb_list net/core/dev.c:5672 [inline]\n  netif_receive_skb_list_internal+0x9f9/0xdc0 net/core/dev.c:5764\n  netif_receive_skb_list+0x55/0x3e0 net/core/dev.c:5816\n  xdp_recv_frames net/bpf/test_run.c:257 [inline]\n  xdp_test_run_batch net/bpf/test_run.c:335 [inline]\n  bpf_test_run_xdp_live+0x1818/0x1d00 net/bpf/test_run.c:363\n  bpf_prog_test_run_xdp+0x81f/0x1170 net/bpf/test_run.c:1376\n  bpf_prog_test_run+0x349/0x3c0 kernel/bpf/syscall.c:3736\n  __sys_bpf+0x45c/0x710 kernel/bpf/syscall.c:5115\n  __do_sys_bpf kernel/bpf/syscall.c:5201 [inline]\n  __se_sys_bpf kernel/bpf/syscall.c:5199 [inline]\n  __x64_sys_bpf+0x7c/0x90 kernel/bpf/syscall.c:5199\n\nFixes: 02b24941619f (""ipv4: use dst hint for ipv4 list receive"")\nReported-by: syzbot <syzkaller@googlegroups.com>\nSigned-off-by: Eric Dumazet <edumazet@google.com>\nAcked-by: Paolo Abeni <pabeni@redhat.com>\nLink: https://lore.kernel.org/r/20240421184326.1704930-1-edumazet@google.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Fixes a NULL pointer dereference in ip_route_use_hint by ensuring __in_dev_get_rcu() results are checked for NULL.,"NULL dereference, ipv4, ip_route_use_hint",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['other']
246331e3f1eac905170a923f0ec76725c2558232,246331e3f1eac905170a923f0ec76725c2558232,Benjamin Tissoires,bentiss@kernel.org,1713604149,Alexei Starovoitov,ast@kernel.org,1713922285,1755b8cb148983f6d91ea433cbad3d2432167300,d940c9b94d7e6d9cff288623e3e8bf5fdea98b79,"bpf: allow struct bpf_wq to be embedded in arraymaps and hashmaps

Currently bpf_wq_cancel_and_free() is just a placeholder as there is
no memory allocation for bpf_wq just yet.

Again"," duplication of the bpf_timer approach

Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
Link: https://lore.kernel.org/r/20240420-bpf_wq-v2-9-6c986a5a741f@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Allow embedding of struct bpf_wq in arraymaps and hashmaps.,"bpf_wq,arraymaps,hashmaps",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d940c9b94d7e6d9cff288623e3e8bf5fdea98b79,d940c9b94d7e6d9cff288623e3e8bf5fdea98b79,Benjamin Tissoires,bentiss@kernel.org,1713604148,Alexei Starovoitov,ast@kernel.org,1713922285,2d9e3416aff6486023963dfb28622aa28f454fd4,ad2c03e691be3268eefc75ff1d892db3f0e79f62,"bpf: add support for KF_ARG_PTR_TO_WORKQUEUE

Introduce support for KF_ARG_PTR_TO_WORKQUEUE. The kfuncs will use bpf_wq
as argument and that will be recognized as workqueue argument by verifier.
bpf_wq_kern casting can happen inside kfunc"," but using bpf_wq in
argument makes life easier for users who work with non-kern type in BPF
progs.

Duplicate process_timer_func into process_wq_func.
meta argument is only needed to ensure bpf_wq_init's workqueue and map
arguments are coming from the same map (map_uid logic is necessary for
correct inner-map handling)","[' so also amend check_kfunc_args() to\nmatch what helpers functions check is doing.\n\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\nLink: https://lore.kernel.org/r/20240420-bpf_wq-v2-8-6c986a5a741f@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit adds support for KF_ARG_PTR_TO_WORKQUEUE to recognize workqueue arguments within kfuncs for eBPF programs.,"KF_ARG_PTR_TO_WORKQUEUE,bpf_wq,verifier",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ad2c03e691be3268eefc75ff1d892db3f0e79f62,ad2c03e691be3268eefc75ff1d892db3f0e79f62,Benjamin Tissoires,bentiss@kernel.org,1713604147,Alexei Starovoitov,ast@kernel.org,1713922284,915aecb9964c714c552cd7b37c765e0eb053858c,f1d0a2fbb0088675cceeab73d1f4b4308b289984,"bpf: verifier: bail out if the argument is not a map

When a kfunc is declared with a KF_ARG_PTR_TO_MAP"," we should have
reg->map_ptr set to a non NULL value","[' otherwise', ' that means that the\nunderlying type is not a map.\n\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\nLink: https://lore.kernel.org/r/20240420-bpf_wq-v2-7-6c986a5a741f@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add a check to ensure reg->map_ptr is non-NULL when kfunc declares with KF_ARG_PTR_TO_MAP.,"bpf,verifier,map",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f1d0a2fbb0088675cceeab73d1f4b4308b289984,f1d0a2fbb0088675cceeab73d1f4b4308b289984,Benjamin Tissoires,bentiss@kernel.org,1713604146,Alexei Starovoitov,ast@kernel.org,1713922284,33e61cc04c43af72b130a1e5e1d10ecf49b69cf8,d56b63cf0c0f71e1b2e04dd8220b408f049e67ff,"tools: sync include/uapi/linux/bpf.h

cp include/uapi/linux/bpf.h tools/include/uapi/linux/bpf.h

Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
Link: https://lore.kernel.org/r/20240420-bpf_wq-v2-6-6c986a5a741f@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Syncs bpf.h header files between include and tools directories.,"sync,uapi,bpf.h",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
d56b63cf0c0f71e1b2e04dd8220b408f049e67ff,d56b63cf0c0f71e1b2e04dd8220b408f049e67ff,Benjamin Tissoires,bentiss@kernel.org,1713604145,Alexei Starovoitov,ast@kernel.org,1713922284,c285bc78a8db309b3e1ec39e5881ba1477b611d9,fc22d9495f0b32d75b5d25a17b300b7aad05c55d,"bpf: add support for bpf_wq user type

Mostly a copy/paste from the bpf_timer API"," without the initialization
and free","[' as they will be done in a separate patch.\n\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\nLink: https://lore.kernel.org/r/20240420-bpf_wq-v2-5-6c986a5a741f@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']","Added support for a new bpf_wq user type in eBPF, similar to bpf_timer API.","bpf_wq,user,type",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fc22d9495f0b32d75b5d25a17b300b7aad05c55d,fc22d9495f0b32d75b5d25a17b300b7aad05c55d,Benjamin Tissoires,bentiss@kernel.org,1713604144,Alexei Starovoitov,ast@kernel.org,1713922284,0230b90cf5d85d42df5000db0ba50ea2c59e2a46,073f11b0264310b85754b6a0946afee753790c66,"bpf: replace bpf_timer_cancel_and_free with a generic helper

Same reason than most bpf_timer* functions"," we need almost the same for
workqueues.
So extract the generic part out of it so bpf_wq_cancel_and_free can reuse
it.

Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
Link: https://lore.kernel.org/r/20240420-bpf_wq-v2-4-6c986a5a741f@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Refactor bpf_timer_cancel_and_free to a generic helper for reuse in bpf_wq_cancel_and_free.,bpf timer helper,It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
073f11b0264310b85754b6a0946afee753790c66,073f11b0264310b85754b6a0946afee753790c66,Benjamin Tissoires,bentiss@kernel.org,1713604143,Alexei Starovoitov,ast@kernel.org,1713922284,e43f0fad5af09702d86484afd32511e0b6bee870,56b4a177ae6322173360a93ea828ad18570a5a14,"bpf: replace bpf_timer_set_callback with a generic helper

In the same way we have a generic __bpf_async_init()"," we also need
to share code between timer and workqueue for the set_callback call.

We just add an unused flags parameter","[' as it will be used for workqueues.\n\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\nLink: https://lore.kernel.org/r/20240420-bpf_wq-v2-3-6c986a5a741f@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit replaces bpf_timer_set_callback with a generic helper function for shared code between timer and workqueue.,"bpf,generic,helper",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
56b4a177ae6322173360a93ea828ad18570a5a14,56b4a177ae6322173360a93ea828ad18570a5a14,Benjamin Tissoires,bentiss@kernel.org,1713604142,Alexei Starovoitov,ast@kernel.org,1713922284,acb7ffd67d20b48bdce8617c3c5de6de46ecfedc,be2749beff62e0d63cf97fe63cabc79a68443139,"bpf: replace bpf_timer_init with a generic helper

No code change except for the new flags argument being stored in the
local data struct.

Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
Link: https://lore.kernel.org/r/20240420-bpf_wq-v2-2-6c986a5a741f@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit replaces bpf_timer_init with a generic helper function while adding a new flags argument.,"bpf_timer_init,generic helper,flags argument",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
be2749beff62e0d63cf97fe63cabc79a68443139,be2749beff62e0d63cf97fe63cabc79a68443139,Benjamin Tissoires,bentiss@kernel.org,1713604141,Alexei Starovoitov,ast@kernel.org,1713922284,61df1e8b730fe4ccaf8953e015e043e767f20a30,a7de265cb2d849f8986a197499ad58dca0a4f209,"bpf: make timer data struct more generic

To be able to add workqueues and reuse most of the timer code"," we need
to make bpf_hrtimer more generic.

There is no code change except that the new struct gets a new u64 flags
attribute. We are still below 2 cache lines","["" so this shouldn't impact\nthe current running codes.\n\nThe ordering is also changed. Everything related to async callback\nis now on top of bpf_hrtimer.\n\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\nLink: https://lore.kernel.org/r/20240420-bpf_wq-v2-1-6c986a5a741f@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Refactor the bpf_hrtimer to be more generic and reusable for workqueues.,"bpf_hrtimer,generic,reusable",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b240fc56b8fd5d383bd00e59ddf67a4f66b86bb8,b240fc56b8fd5d383bd00e59ddf67a4f66b86bb8,Jakub Kicinski,kuba@kernel.org,1713820815,Jakub Kicinski,kuba@kernel.org,1713820892,3892e41bc52cb28a06d3d8707db5bde6d3c36ddc,c51db4ac10d57c366f9a92121e3889bfc6c324cd 96944aafaaa64e6ead1d3d227a1493dd8196a827,"Merge branch 'net-dsa-vsc73xx-convert-to-phylink-and-do-some-cleanup'

Pawel Dembicki says:

====================
net: dsa: vsc73xx: convert to PHYLINK and do some cleanup

This patch series is a result of splitting a larger patch series [0]","
where some parts needed to be refactored.

The first patch switches from a poll loop to read_poll_timeout.

The second patch is a simple conversion to phylink because adjust_link
won't work anymore.

The third patch is preparation for future use. Using the
""phy_interface_mode_is_rgmii"" macro allows for the proper recognition
of all RGMII modes.

Patches 4-5 involve some cleanup: The fourth patch introduces
a definition with the maximum number of ports to avoid using
magic numbers. The next one fills in documentation.

[0] https://patchwork.kernel.org/project/netdevbpf/list/?series=841034&state=%2A&archive=both
====================

Link: https://lore.kernel.org/r/20240417205048.3542839-1-paweldembicki@gmail.com
Signed-off-by: Jakub Kicinski <kuba@kernel.org>
",[''],The commit converts net-dsa-vsc73xx to PHYLINK and includes code cleanup and refactoring.,"PHYLINK, cleanup, refactoring",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
584ed2f76ff5fe360d87a04d17b6520c7999e06b,584ed2f76ff5fe360d87a04d17b6520c7999e06b,Johannes Berg,johannes.berg@intel.com,1711616796,Richard Weinberger,richard@nod.at,1713817720,ecf59a02c9fd01f5d5030d404d135eedbc5b4027,e3cce8d87d6407f83a5741c3c5d54bf1365c6ac6,"um: vector: fix bpfflash parameter evaluation

With W=1 the build complains about a pointer compared to
zero"," clearly the result should've been compared.

Fixes: 9807019a62dc (""um: Loadable BPF ""Firmware"" for vector drivers"")
Signed-off-by: Johannes Berg <johannes.berg@intel.com>
Reviewed-by: Tiwei Bie <tiwei.btw@antgroup.com>
Signed-off-by: Richard Weinberger <richard@nod.at>
",[''],Fixes pointer comparison issue in bpfflash parameter evaluation for vector drivers in UML.,"bpfflash,vector,UML",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
5bcf0dcbf9066348058b88a510c57f70f384c92c,5bcf0dcbf9066348058b88a510c57f70f384c92c,Toke Høiland-Jørgensen,toke@redhat.com,1713424719,Martin KaFai Lau,martin.lau@kernel.org,1713806681,5dbacf55aeaf1098c36f41e79ed39dec96660800,c6f48506ba30c722dd9d89aa6a40eb1926277dff,"xdp: use flags field to disambiguate broadcast redirect

When redirecting a packet using XDP"," the bpf_redirect_map() helper will set
up the redirect destination information in struct bpf_redirect_info (using
the __bpf_xdp_redirect_map() helper function)","[' and the xdp_do_redirect()\nfunction will read this information after the XDP program returns and pass\nthe frame on to the right redirect destination.\n\nWhen using the BPF_F_BROADCAST flag to do multicast redirect to a whole\nmap', "" __bpf_xdp_redirect_map() sets the 'map' pointer in struct\nbpf_redirect_info to point to the destination map to be broadcast. And\nxdp_do_redirect() reacts to the value of this map pointer to decide whether\nit's dealing with a broadcast or a single-value redirect. However"", ' if the\ndestination map is being destroyed before xdp_do_redirect() is called', ' the\nmap pointer will be cleared out (by bpf_clear_redirect_map()) without\nwaiting for any XDP programs to stop running. This causes xdp_do_redirect()\nto think that the redirect was to a single target', "" but the target pointer\nis also NULL (since broadcast redirects don't have a single target)"", ' so\nthis causes a crash when a NULL pointer is passed to dev_map_enqueue().\n\nTo fix this', "" change xdp_do_redirect() to react directly to the presence of\nthe BPF_F_BROADCAST flag in the 'flags' value in struct bpf_redirect_info\nto disambiguate between a single-target and a broadcast redirect. And only\nread the 'map' pointer if the broadcast flag is set"", ' aborting if that has\nbeen cleared out in the meantime. This prevents the crash', ' while keeping\nthe atomic (cmpxchg-based) clearing of the map pointer itself', ' and without\nadding any more checks in the non-broadcast fast path.\n\nFixes: e624d4ed4aa8 (""xdp: Extend xdp_redirect_map with broadcast support"")\nReported-and-tested-by: syzbot+af9492708df9797198d6@syzkaller.appspotmail.com\nSigned-off-by: Toke Høiland-Jørgensen <toke@redhat.com>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nReviewed-by: Hangbin Liu <liuhangbin@gmail.com>\nAcked-by: Jesper Dangaard Brouer <hawk@kernel.org>\nLink: https://lore.kernel.org/r/20240418071840.156411-1-toke@redhat.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",The commit utilizes flags to clarify broadcast redirects in XDP packet redirection.,"xdp, broadcast, redirect",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['xdp like programs']
a7de265cb2d849f8986a197499ad58dca0a4f209,a7de265cb2d849f8986a197499ad58dca0a4f209,Rafael Passos,rafael@rcpassos.me,1713379754,Daniel Borkmann,daniel@iogearbox.net,1713800888,6eb07d5ab07cd7d48c1069be16c56fd7301af821,e1a7545981e2086feaa40dcb7b0db8de0bdada19,"bpf: Fix typos in comments

Found the following typos in comments"," and fixed them:

s/unpriviledged/unprivileged/
s/reponsible/responsible/
s/possiblities/possibilities/
s/Divison/Division/
s/precsion/precision/
s/havea/have a/
s/reponsible/responsible/
s/responsibile/responsible/
s/tigher/tighter/
s/respecitve/respective/

Signed-off-by: Rafael Passos <rafael@rcpassos.me>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/6af7deb4-bb24-49e8-b3f1-8dd410597337@smtp-relay.sendinblue.com
",[''],Fixed multiple typos in comments in the bpf subsystem code.,"typos, comments, bpf",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
c6f48506ba30c722dd9d89aa6a40eb1926277dff,c6f48506ba30c722dd9d89aa6a40eb1926277dff,Puranjay Mohan,puranjay@kernel.org,1713551312,Daniel Borkmann,daniel@iogearbox.net,1713799565,558174f3f15cb2a30d7468aba6518a62912ed39c,10541b374aa05c8118cc6a529a615882e53f261b,arm32," bpf: Reimplement sign-extension mov instruction

The current implementation of the mov instruction with sign extension has the
following problems:

  1. It clobbers the source register if it is not stacked because it
     sign extends the source and then moves it to the destination.
  2. If the dst_reg is stacked","["" the current code doesn't write the value\n     back in case of 64-bit mov.\n  3. There is room for improvement by emitting fewer instructions.\n\nThe steps for fixing this and the instructions emitted by the JIT are explained\nbelow with examples in all combinations:\n\nCase A: offset == 32:\n=====================\n\n  Case A.1: src and dst are stacked registers:\n  --------------------------------------------\n    1. Load src_lo into tmp_lo\n    2. Store tmp_lo into dst_lo\n    3. Sign extend tmp_lo into tmp_hi\n    4. Store tmp_hi to dst_hi\n\n    Example: r3 = (s32)r3\n\tr3 is a stacked register\n\n\tldr     r6"", ' [r11', ' #-16]\t// Load r3_lo into tmp_lo\n\t// str to dst_lo is not emitted because src_lo == dst_lo\n\tasr     r7', ' r6', ' #31\t// Sign extend tmp_lo into tmp_hi\n\tstr     r7', ' [r11', ' #-12] // Store tmp_hi into r3_hi\n\n  Case A.2: src is stacked but dst is not:\n  ----------------------------------------\n    1. Load src_lo into dst_lo\n    2. Sign extend dst_lo into dst_hi\n\n    Example: r6 = (s32)r3\n\tr6 maps to {ARM_R5', ' ARM_R4} and r3 is stacked\n\n\tldr     r4', ' [r11', ' #-16] // Load r3_lo into r6_lo\n\tasr     r5', ' r4', ' #31\t// Sign extend r6_lo into r6_hi\n\n  Case A.3: src is not stacked but dst is stacked:\n  ------------------------------------------------\n    1. Store src_lo into dst_lo\n    2. Sign extend src_lo into tmp_hi\n    3. Store tmp_hi to dst_hi\n\n    Example: r3 = (s32)r6\n\tr3 is stacked and r6 maps to {ARM_R5', ' ARM_R4}\n\n\tstr     r4', ' [r11', ' #-16] // Store r6_lo to r3_lo\n\tasr     r7', ' r4', ' #31\t// Sign extend r6_lo into tmp_hi\n\tstr     r7', ' [r11', ' #-12]\t// Store tmp_hi to dest_hi\n\n  Case A.4: Both src and dst are not stacked:\n  -------------------------------------------\n    1. Mov src_lo into dst_lo\n    2. Sign extend src_lo into dst_hi\n\n    Example: (bf) r6 = (s32)r6\n\tr6 maps to {ARM_R5', ' ARM_R4}\n\n\t// Mov not emitted because dst == src\n\tasr     r5', ' r4', ' #31 // Sign extend r6_lo into r6_hi\n\nCase B: offset != 32:\n=====================\n\n  Case B.1: src and dst are stacked registers:\n  --------------------------------------------\n    1. Load src_lo into tmp_lo\n    2. Sign extend tmp_lo according to offset.\n    3. Store tmp_lo into dst_lo\n    4. Sign extend tmp_lo into tmp_hi\n    5. Store tmp_hi to dst_hi\n\n    Example: r9 = (s8)r3\n\tr9 and r3 are both stacked registers\n\n\tldr     r6', ' [r11', ' #-16] // Load r3_lo into tmp_lo\n\tlsl     r6', ' r6', ' #24\t// Sign extend tmp_lo\n\tasr     r6', ' r6', ' #24\t// ..\n\tstr     r6', ' [r11', ' #-56] // Store tmp_lo to r9_lo\n\tasr     r7', ' r6', ' #31\t// Sign extend tmp_lo to tmp_hi\n\tstr     r7', ' [r11', ' #-52] // Store tmp_hi to r9_hi\n\n  Case B.2: src is stacked but dst is not:\n  ----------------------------------------\n    1. Load src_lo into dst_lo\n    2. Sign extend dst_lo according to offset.\n    3. Sign extend tmp_lo into dst_hi\n\n    Example: r6 = (s8)r3\n\tr6 maps to {ARM_R5', ' ARM_R4} and r3 is stacked\n\n\tldr     r4', ' [r11', ' #-16] // Load r3_lo to r6_lo\n\tlsl     r4', ' r4', ' #24\t// Sign extend r6_lo\n\tasr     r4', ' r4', ' #24\t// ..\n\tasr     r5', ' r4', ' #31\t// Sign extend r6_lo into r6_hi\n\n  Case B.3: src is not stacked but dst is stacked:\n  ------------------------------------------------\n    1. Sign extend src_lo into tmp_lo according to offset.\n    2. Store tmp_lo into dst_lo.\n    3. Sign extend src_lo into tmp_hi.\n    4. Store tmp_hi to dst_hi.\n\n    Example: r3 = (s8)r1\n\tr3 is stacked and r1 maps to {ARM_R3', ' ARM_R2}\n\n\tlsl     r6', ' r2', ' #24 \t// Sign extend r1_lo to tmp_lo\n\tasr     r6', ' r6', ' #24\t// ..\n\tstr     r6', ' [r11', ' #-16] // Store tmp_lo to r3_lo\n\tasr     r7', ' r6', ' #31\t// Sign extend tmp_lo to tmp_hi\n\tstr     r7', ' [r11', ' #-12] // Store tmp_hi to r3_hi\n\n  Case B.4: Both src and dst are not stacked:\n  -------------------------------------------\n    1. Sign extend src_lo into dst_lo according to offset.\n    2. Sign extend dst_lo into dst_hi.\n\n    Example: r6 = (s8)r1\n\tr6 maps to {ARM_R5', ' ARM_R4} and r1 maps to {ARM_R3', ' ARM_R2}\n\n\tlsl     r4', ' r2', ' #24\t// Sign extend r1_lo to r6_lo\n\tasr     r4', ' r4', ' #24\t// ..\n\tasr     r5', ' r4', ' #31\t// Sign extend r6_lo to r6_hi\n\nFixes: fc832653fa0d (""arm32', ' bpf: add support for sign-extension mov instruction"")\nReported-by: syzbot+186522670e6722692d86@syzkaller.appspotmail.com\nSigned-off-by: Puranjay Mohan <puranjay@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Russell King (Oracle) <rmk+kernel@armlinux.org.uk>\nCloses: https://lore.kernel.org/all/000000000000e9a8d80615163f2a@google.com\nLink: https://lore.kernel.org/bpf/20240419182832.27707-1-puranjay@kernel.org\n', '']",The commit reimplements the ARM32 sign-extension mov instruction to address issues with source register clobbering and stacked destination registers.,"ARM32, sign-extension, mov instruction",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e1a7545981e2086feaa40dcb7b0db8de0bdada19,e1a7545981e2086feaa40dcb7b0db8de0bdada19,Rafael Passos,rafael@rcpassos.me,1713376346,Daniel Borkmann,daniel@iogearbox.net,1713798725,065a30b2159f15e0f760d058ec7c8fb8cc45d921,735f5b8a7ccf383e50d76f7d1c25769eee474812,"bpf: Fix typo in function save_aux_ptr_type

I found this typo in the save_aux_ptr_type function.
s/allow_trust_missmatch/allow_trust_mismatch/
I did not find this anywhere else in the codebase.

Signed-off-by: Rafael Passos <rafael@rcpassos.me>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/fbe1d636-8172-4698-9a5a-5a3444b55322@smtp-relay.sendinblue.com
",,Fixes a typo in the save_aux_ptr_type function's variable name.,"typo, save_aux_ptr_type, fix",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
735f5b8a7ccf383e50d76f7d1c25769eee474812,735f5b8a7ccf383e50d76f7d1c25769eee474812,Dave Thaler,dthaler1968@googlemail.com,1713562706,Alexei Starovoitov,ast@kernel.org,1713719352,2a11d1cffa7203004e9cb150f26aa0eab671b847,db50040d09cc511889b2c949a0c93d017e44f081,bpf," docs: Fix formatting nit in instruction-set.rst

Other places that had pseudocode were prefixed with ::
so as to appear in a literal block","[' but one place was inconsistent.\nThis patch fixes that inconsistency.\n\nSigned-off-by: Dave Thaler <dthaler1968@googlemail.com>\nAcked-by: David Vernet <void@manifault.com>\nLink: https://lore.kernel.org/r/20240419213826.7301-1-dthaler1968@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit fixes formatting in the instruction-set documentation by using pseudocode blocks.,"formatting, pseudocode, documentation",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
db50040d09cc511889b2c949a0c93d017e44f081,db50040d09cc511889b2c949a0c93d017e44f081,Dave Thaler,dthaler1968@googlemail.com,1713558977,Alexei Starovoitov,ast@kernel.org,1713719336,dac684be17e5cff7f0713a1b524859fd2321ff15,2ea0aa535818622395fb55e01086ef2a490fc734,bpf," docs: Clarify helper ID and pointer terms in instruction-set.rst

Per IETF 119 meeting discussion and mailing list discussion at
https://mailarchive.ietf.org/arch/msg/bpf/2JwWQwFdOeMGv0VTbD0CKWwAOEA/
the following changes are made.

First","[' say call by ""static ID"" rather than call by ""address""\n\nSecond', ' change ""pointer"" to ""address""\n\nSigned-off-by: Dave Thaler <dthaler1968@gmail.com>\nAcked-by: David Vernet <void@manifault.com>\nLink: https://lore.kernel.org/r/20240419203617.6850-1-dthaler1968@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Clarifies helper ID and pointer terms in bpf instruction-set documentation based on IETF and mailing list discussions.,"documentation,helper ID,pointer",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
63a51820d29bdfcf52abed2db2d32b4f6843988e,63a51820d29bdfcf52abed2db2d32b4f6843988e,Geliang Tang,tanggeliang@kylinos.cn,1713427752,Martin KaFai Lau,martin.lau@kernel.org,1713572009,88100b5ba9343cdf4f30d3b7f2ce7bfe27a71569,805b4d90c0df79a88907623b2528954a0125313d,"selftests/bpf: Use connect_to_addr in sk_assign

This patch uses public helper connect_to_addr() exported in
network_helpers.h instead of the local defined function connect_to_server()
in prog_tests/sk_assign.c. This can avoid duplicate code.

The code that sets SO_SNDTIMEO timeout as timeo_sec (3s) can be dropped","
since connect_to_addr() sets default timeout as 3s.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/98fdd384872bda10b2adb052e900a2212c9047b9.1713427236.git.tanggeliang@kylinos.cn
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Refactor sk_assign test by replacing connect_to_server with connect_to_addr to reduce code duplication.,"connect_to_addr, sk_assign, refactor",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
805b4d90c0df79a88907623b2528954a0125313d,805b4d90c0df79a88907623b2528954a0125313d,Geliang Tang,tanggeliang@kylinos.cn,1713427751,Martin KaFai Lau,martin.lau@kernel.org,1713572009,61e8c8309491a7579791b04e71f5d830afe6b62d,db9994d022ecd42006354609f6e4e3f57e5a4b03,"selftests/bpf: Use connect_to_addr in cls_redirect

This patch uses public helper connect_to_addr() exported in
network_helpers.h instead of the local defined function connect_to_server()
in prog_tests/cls_redirect.c. This can avoid duplicate code.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/4a03ac92d2d392f8721f398fa449a83ac75577bc.1713427236.git.tanggeliang@kylinos.cn
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Refactor cls_redirect test to use connect_to_addr helper to avoid code duplication.,"selftests,bpf,refactor",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
db9994d022ecd42006354609f6e4e3f57e5a4b03,db9994d022ecd42006354609f6e4e3f57e5a4b03,Geliang Tang,tanggeliang@kylinos.cn,1713427750,Martin KaFai Lau,martin.lau@kernel.org,1713572008,9211f503d5d85c9add809589018f514f7e71b6f4,a2e4979536c440838794ee292955ce9ed55ad181,"selftests/bpf: Update arguments of connect_to_addr

Move the third argument ""int type"" of connect_to_addr() to the first one
which is closer to how the socket syscall is doing it. And add a
network_helper_opts argument as the fourth one. Then change its usages in
sock_addr.c too.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/088ea8a95055f93409c5f57d12f0e58d43059ac4.1713427236.git.tanggeliang@kylinos.cn
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Reorder and update arguments of connect_to_addr in selftests/bpf to match socket syscall style.,"connect_to_addr, arguments, selftests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
a2e4979536c440838794ee292955ce9ed55ad181,a2e4979536c440838794ee292955ce9ed55ad181,Geliang Tang,tanggeliang@kylinos.cn,1713427749,Martin KaFai Lau,martin.lau@kernel.org,1713572008,659e784263c0ca1f18aa6dc368796c50dc6e3c9a,9851382fb3697efb2f4234d70596bd845b3af535,"selftests/bpf: Use start_server_addr in sk_assign

Include network_helpers.h in prog_tests/sk_assign.c"," use the newly
added public helper start_server_addr() instead of the local defined
function start_server(). This can avoid duplicate code.

The code that sets SO_RCVTIMEO timeout as timeo_sec (3s) can be dropped","['\nsince start_server_addr() sets default timeout as 3s.\n\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nLink: https://lore.kernel.org/r/2af706ffbad63b4f7eaf93a426ed1076eadf1a05.1713427236.git.tanggeliang@kylinos.cn\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Refactored sk_assign.c to use public helper start_server_addr and removed duplicate timeout setting.,"refactor, sk_assign, network_helpers",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
9851382fb3697efb2f4234d70596bd845b3af535,9851382fb3697efb2f4234d70596bd845b3af535,Geliang Tang,tanggeliang@kylinos.cn,1713427748,Martin KaFai Lau,martin.lau@kernel.org,1713572008,f346ded6df39911c629138f9932a593792b29b01,9c598a83b7eab7b05002911fd25b0be7b996ce6d,"selftests/bpf: Use start_server_addr in cls_redirect

Include network_helpers.h in prog_tests/cls_redirect.c"," use the newly
added public helper start_server_addr() instead of the local defined
function start_server(). This can avoid duplicate code.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/13f336cb4c6680175d50bb963d9532e11528c758.1713427236.git.tanggeliang@kylinos.cn
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Refactor selftests to use start_server_addr in cls_redirect for code reuse.,"start_server_addr,code reuse,selftests",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tc/netfilter like programs']
9c598a83b7eab7b05002911fd25b0be7b996ce6d,9c598a83b7eab7b05002911fd25b0be7b996ce6d,Geliang Tang,tanggeliang@kylinos.cn,1713427747,Martin KaFai Lau,martin.lau@kernel.org,1713572008,d58378eebf479dc42be5fb1b1fa700f98d32f90f,462e5e2a5938d0241ad146d21dd0da1be8e7eaf0,"selftests/bpf: Add start_server_addr helper

In order to pair up with connect_to_addr()"," this patch adds a new helper
start_server_addr()","["" which is a wrapper of __start_server(). It accepts\nan argument 'addr' of 'struct sockaddr_storage' type instead of a string\ntype argument like start_server()"", ' and a network_helper_opts argument as\nthe last one.\n\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nLink: https://lore.kernel.org/r/2f01d48fa026467926738debe554ac452c19b86f.1713427236.git.tanggeliang@kylinos.cn\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Added a new helper function 'start_server_addr' to bpf selftests for pairing with 'connect_to_addr'.,"helper,selftests,bpf",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
50449ca66cc5a8cbc64749cf4b9f3d3fc5f4b457,50449ca66cc5a8cbc64749cf4b9f3d3fc5f4b457,Yaxiong Tian,tianyaxiong@kylinos.cn,1713322368,Catalin Marinas,catalin.marinas@arm.com,1713540780,775c8217a6a739148ab6be7da99de09b657e961f,34e526cb7d46726b2ae5f83f2892d00ebb088509,"arm64: hibernate: Fix level3 translation fault in swsusp_save()

On arm64 machines"," swsusp_save() faults if it attempts to access
MEMBLOCK_NOMAP memory ranges. This can be reproduced in QEMU using UEFI
when booting with rodata=off debug_pagealloc=off and CONFIG_KFENCE=n:

  Unable to handle kernel paging request at virtual address ffffff8000000000
  Mem abort info:
    ESR = 0x0000000096000007
    EC = 0x25: DABT (current EL)","[' IL = 32 bits\n    SET = 0', ' FnV = 0\n    EA = 0', ' S1PTW = 0\n    FSC = 0x07: level 3 translation fault\n  Data abort info:\n    ISV = 0', ' ISS = 0x00000007', ' ISS2 = 0x00000000\n    CM = 0', ' WnR = 0', ' TnD = 0', ' TagAccess = 0\n    GCS = 0', ' Overlay = 0', ' DirtyBit = 0', ' Xs = 0\n  swapper pgtable: 4k pages', ' 39-bit VAs', ' pgdp=00000000eeb0b000\n  [ffffff8000000000] pgd=180000217fff9803', ' p4d=180000217fff9803', ' pud=180000217fff9803', ' pmd=180000217fff8803', ' pte=0000000000000000\n  Internal error: Oops: 0000000096000007 [#1] SMP\n  Internal error: Oops: 0000000096000007 [#1] SMP\n  Modules linked in: xt_multiport ipt_REJECT nf_reject_ipv4 xt_conntrack nf_conntrack nf_defrag_ipv6 nf_defrag_ipv4 libcrc32c iptable_filter bpfilter rfkill at803x snd_hda_codec_hdmi snd_hda_intel snd_intel_dspcfg dwmac_generic stmmac_platform snd_hda_codec stmmac joydev pcs_xpcs snd_hda_core phylink ppdev lp parport ramoops reed_solomon ip_tables x_tables nls_iso8859_1 vfat multipath linear amdgpu amdxcp drm_exec gpu_sched drm_buddy hid_generic usbhid hid radeon video drm_suballoc_helper drm_ttm_helper ttm i2c_algo_bit drm_display_helper cec drm_kms_helper drm\n  CPU: 0 PID: 3663 Comm: systemd-sleep Not tainted 6.6.2+ #76\n  Source Version: 4e22ed63a0a48e7a7cff9b98b7806d8d4add7dc0\n  Hardware name: Greatwall GW-XXXXXX-XXX/GW-XXXXXX-XXX', ' BIOS KunLun BIOS V4.0 01/19/2021\n  pstate: 600003c5 (nZCv DAIF -PAN -UAO -TCO -DIT -SSBS BTYPE=--)\n  pc : swsusp_save+0x280/0x538\n  lr : swsusp_save+0x280/0x538\n  sp : ffffffa034a3fa40\n  x29: ffffffa034a3fa40 x28: ffffff8000001000 x27: 0000000000000000\n  x26: ffffff8001400000 x25: ffffffc08113e248 x24: 0000000000000000\n  x23: 0000000000080000 x22: ffffffc08113e280 x21: 00000000000c69f2\n  x20: ffffff8000000000 x19: ffffffc081ae2500 x18: 0000000000000000\n  x17: 6666662074736420 x16: 3030303030303030 x15: 3038666666666666\n  x14: 0000000000000b69 x13: ffffff9f89088530 x12: 00000000ffffffea\n  x11: 00000000ffff7fff x10: 00000000ffff7fff x9 : ffffffc08193f0d0\n  x8 : 00000000000bffe8 x7 : c0000000ffff7fff x6 : 0000000000000001\n  x5 : ffffffa0fff09dc8 x4 : 0000000000000000 x3 : 0000000000000027\n  x2 : 0000000000000000 x1 : 0000000000000000 x0 : 000000000000004e\n  Call trace:\n   swsusp_save+0x280/0x538\n   swsusp_arch_suspend+0x148/0x190\n   hibernation_snapshot+0x240/0x39c\n   hibernate+0xc4/0x378\n   state_store+0xf0/0x10c\n   kobj_attr_store+0x14/0x24\n\nThe reason is swsusp_save() -> copy_data_pages() -> page_is_saveable()\n-> kernel_page_present() assuming that a page is always present when\ncan_set_direct_map() is false (all of rodata_full', '\ndebug_pagealloc_enabled() and arm64_kfence_can_set_direct_map() false)', '\nirrespective of the MEMBLOCK_NOMAP ranges. Such MEMBLOCK_NOMAP regions\nshould not be saved during hibernation.\n\nThis problem was introduced by changes to the pfn_valid() logic in\ncommit a7d9f306ba70 (""arm64: drop pfn_valid_within() and simplify\npfn_valid()"").\n\nSimilar to other architectures', ' drop the !can_set_direct_map() check in\nkernel_page_present() so that page_is_savable() skips such pages.\n\nFixes: a7d9f306ba70 (""arm64: drop pfn_valid_within() and simplify pfn_valid()"")\nCc: <stable@vger.kernel.org> # 5.14.x\nSuggested-by: Mike Rapoport <rppt@kernel.org>\nSuggested-by: Catalin Marinas <catalin.marinas@arm.com>\nCo-developed-by: xiongxin <xiongxin@kylinos.cn>\nSigned-off-by: xiongxin <xiongxin@kylinos.cn>\nSigned-off-by: Yaxiong Tian <tianyaxiong@kylinos.cn>\nAcked-by: Mike Rapoport (IBM) <rppt@kernel.org>\nLink: https://lore.kernel.org/r/20240417025248.386622-1-tianyaxiong@kylinos.cn\n[catalin.marinas@arm.com: rework commit message]\nSigned-off-by: Catalin Marinas <catalin.marinas@arm.com>\n', '']",Fix the translation fault in swsusp_save() for arm64 during hibernation.,"arm64, hibernate, translation",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
61ba075d9911d2a6db181fbb5602762a24d5d0a9,61ba075d9911d2a6db181fbb5602762a24d5d0a9,Arnaldo Carvalho de Melo,acme@redhat.com,1713474933,Arnaldo Carvalho de Melo,acme@redhat.com,1713489772,9e6930409badd1af421c60ad9cf3b8558710d61b,c15ed4442981ccf8e7e0d885f5cb500400dde9d7,"Revert ""tools headers: Remove almost unused copy of uapi/stat.h"," add few conditional defines""

This reverts commit a672af9139a843eb7a48fd7846bb6df8f81b5f86.

By now it is not used for building tools/perf","[' but Stephen Rothwell\nreported that when building on a O= directory that had been built with\ntorvalds/master and this perf build command line:\n\n  $ make -C tools/perf -f Makefile.perf -s -O -j60 O=/home/sfr/next/perf NO_BPF_SKEL=1\n\nIf we then merge perf-tools-next', ' as he did for linux-next', "" then we end\nup with a build failure for libbpf:\n\n    PERF_VERSION = 6.9.rc3.g42c4635c8dee\n  make[3]: *** No rule to make target '/home/sfr/next/next/tools/include/uapi/linux/stat.h'"", "" needed by '/home/sfr/next/perf/libbpf/staticobjs/libbpf.o'.  Stop.\n  make[2]: *** [Makefile:157: /home/sfr/next/perf/libbpf/staticobjs/libbpf-in.o] Error 2\n  make[1]: *** [Makefile.perf:892: /home/sfr/next/perf/libbpf/libbpf.a] Error 2\n  make[1]: *** Waiting for unfinished jobs....\n  make: *** [Makefile.perf:264: sub-make] Error 2\n\nThis needs to be further investigated to figure out how to check if\nlibbpf really needs something that is in that\ntools/include/uapi/linux/stat.h file and if not to remove that file in a\nway that we don't break the build in any situation"", "" to avoid requiring\ndoing a 'make clean'.\n\nReported-by: Stephen Rothwell <sfr@canb.auug.org.au>\nTested-by: Stephen Rothwell <sfr@canb.auug.org.au> # PowerPC le incermental build\nCc: Namhyung Kim <namhyung@kernel.org>\nLink: https://lore.kernel.org/lkml/20240413124340.4d48c6d8@canb.auug.org.au\nSigned-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>\n"", '']",This commit reverts a previous removal of a uapi/stat.h copy for building perf tools.,"revert, uapi/stat, tools",It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
d9bd1d4264baddf7ab8baae86e91674d369f22de,d9bd1d4264baddf7ab8baae86e91674d369f22de,Ian Rogers,irogers@google.com,1713286814,Arnaldo Carvalho de Melo,acme@redhat.com,1713489771,55fac730e789a0ed1ede7a56eceea43442a8f388,eb4d27cf9aef3e6c9bcaf8fa1a1cadc2433d847b,"perf test bpf-counters: Add test for BPF event modifier

Refactor test to better enable sharing of logic"," to give an idea of
progress and introduce test functions. Add test of measuring both
cycles and cycles:b simultaneously.

Signed-off-by: Ian Rogers <irogers@google.com>
Cc: Adrian Hunter <adrian.hunter@intel.com>
Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
Cc: Athira Rajeev <atrajeev@linux.vnet.ibm.com>
Cc: Ingo Molnar <mingo@redhat.com>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Namhyung Kim <namhyung@kernel.org>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Song Liu <song@kernel.org>
Cc: Thomas Richter <tmricht@linux.ibm.com>
Link: https://lore.kernel.org/r/20240416170014.985191-2-irogers@google.com
Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
",[''],The commit refactors perf test to add BPF event modifier and improve test logic sharing.,"perf test, BPF event, refactor",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
eb4d27cf9aef3e6c9bcaf8fa1a1cadc2433d847b,eb4d27cf9aef3e6c9bcaf8fa1a1cadc2433d847b,Ian Rogers,irogers@google.com,1713286813,Arnaldo Carvalho de Melo,acme@redhat.com,1713489771,0cf341b78e2e5b0a37185d89649e8fe4a74fb11e,6b718ac6874c2233b8dec369a8a377d6c5b638e6,"perf docs: Document bpf event modifier

Document that 'b' is used as a modifier to make an event use a BPF
counter.

Fixes: 01bd8efcec444468 (""perf stat: Introduce ':b' modifier"")
Signed-off-by: Ian Rogers <irogers@google.com>
Cc: Adrian Hunter <adrian.hunter@intel.com>
Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
Cc: Athira Rajeev <atrajeev@linux.vnet.ibm.com>
Cc: Ingo Molnar <mingo@redhat.com>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Namhyung Kim <namhyung@kernel.org>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Song Liu <song@kernel.org>
Cc: Thomas Richter <tmricht@linux.ibm.com>
Link: https://lore.kernel.org/r/20240416170014.985191-1-irogers@google.com
Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
",,Document the 'b' modifier used in perf events for BPF counters.,"perf, BPF, event",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
462e5e2a5938d0241ad146d21dd0da1be8e7eaf0,462e5e2a5938d0241ad146d21dd0da1be8e7eaf0,Alexei Starovoitov,ast@kernel.org,1713390246,Andrii Nakryiko,andrii@kernel.org,1713456201,1c446c24e177d405d9aa60cb2c16c7ff271593e1,e739e01d8df8bf26dbc9dcaeaee3c8c55e8ffa71,"bpf: Fix JIT of is_mov_percpu_addr instruction.

The codegen for is_mov_percpu_addr instruction works for rax/r8 registers
only. Fix it to generate proper x86 byte code for other registers.

Fixes: 7bdbf7446305 (""bpf: add special internal-only MOV instruction to resolve per-CPU addrs"")
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240417214406.15788-1-alexei.starovoitov@gmail.com
",,Fix JIT to properly handle is_mov_percpu_addr instruction for x86 registers other than rax/r8.,"JIT, x86, percpu",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6fc6d7f59376c7cda4d866159b29fe96d96afe83,6fc6d7f59376c7cda4d866159b29fe96d96afe83,Jakub Kicinski,kuba@kernel.org,1712862334,Jakub Kicinski,kuba@kernel.org,1713403119,0f35dacc415ed7d9db743de4fee431c62adb7e6f,2bd99aef1b19e6da09eff692bc0a09d61d785782,"selftests: adopt BPF's approach to quieter builds

selftest build is fairly noisy"," it's easy to miss warnings.
It's standard practice to add alternative messages in
the Makefile. I was grepping for existing solutions","['\nand found that bpf already has the right knobs.\n\nMove them to lib.mk and adopt in net.\nConvert the basic rules in lib.mk.\n\nAcked-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/r/20240411190534.444918-1-kuba@kernel.org\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",The commit reduces noise in selftest builds by adopting BPF's approach to quieter build outputs.,"selftests, quieter builds, Makefile",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
e739e01d8df8bf26dbc9dcaeaee3c8c55e8ffa71,e739e01d8df8bf26dbc9dcaeaee3c8c55e8ffa71,Quentin Deslandes,qde@naccy.de,1713042778,Daniel Borkmann,daniel@iogearbox.net,1713360242,08e655908b0931d387a2e3f9db063e6b32ae5da4,9213e52970a5997c9eb176c7afcc6ec67b1b1e6f,"libbpf: Fix dump of subsequent char arrays

When dumping a character array"," libbpf will watch for a '\0' and set
is_array_terminated=true if found. This prevents libbpf from printing
the remaining characters of the array","[' treating it as a nul-terminated\nstring.\n\nHowever', ' once this flag is set', "" it's never reset"", "" leading to subsequent\ncharacters array not being printed properly:\n\n.str_multi = (__u8[2][16])[\n    [\n        'H'"", ""\n        'e'"", ""\n        'l'"", '\n    ]', '\n]', '\n\nThis patch saves the is_array_terminated flag and restores its\ndefault (false) value before looping over the elements of an array', '\nthen restores it afterward. This way', "" libbpf's behavior is unchanged\nwhen dumping the characters of an array"", "" but subsequent arrays are\nprinted properly:\n\n.str_multi = (__u8[2][16])[\n    [\n        'H'"", ""\n        'e'"", ""\n        'l'"", '\n    ]', ""\n    [\n        'l'"", ""\n        'o'"", '\n    ]', '\n]', '\n\nSigned-off-by: Quentin Deslandes <qde@naccy.de>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240413211258.134421-3-qde@naccy.de\n', '']",Fixes libbpf to correctly handle termination of character arrays when dumping.,"libbpf, character, arrays",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9213e52970a5997c9eb176c7afcc6ec67b1b1e6f,9213e52970a5997c9eb176c7afcc6ec67b1b1e6f,Quentin Deslandes,qde@naccy.de,1713042777,Daniel Borkmann,daniel@iogearbox.net,1713360224,5df119d0d36dee376c9b85bc0791b43fc44bc3db,ad2d22b617b7c0ca2cff4da6dc063183822484bb,"libbpf: Fix misaligned array closing bracket

In btf_dump_array_data()"," libbpf will call btf_dump_dump_type_data() for
each element. For an array of characters","[' each element will be\nprocessed the following way:\n\n- btf_dump_dump_type_data() is called to print the character\n- btf_dump_data_pfx() prefixes the current line with the proper number\n  of indentations\n- btf_dump_int_data() is called to print the character\n- After the last character is printed', ' btf_dump_dump_type_data() calls\n  btf_dump_data_pfx() before writing the closing bracket\n\nHowever', ' for an array containing characters', "" btf_dump_int_data() won't\nprint any '\\0' and subsequent characters. This leads to situations where\nthe line prefix is written"", ' no character is added', "" then the prefix is\nwritten again before adding the closing bracket:\n\n(struct sk_metadata){\n    .str_array = (__u8[14])[\n        'H'"", ""\n        'e'"", ""\n        'l'"", ""\n        'l'"", ""\n        'o'"", '\n                ]', ""\n\nThis change solves this issue by printing the '\\0' character"", "" which\nhas two benefits:\n\n- The bracket closing the array is properly aligned\n- It's clear from a user point of view that libbpf uses '\\0' as a\n  terminator for arrays of characters.\n\nSigned-off-by: Quentin Deslandes <qde@naccy.de>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240413211258.134421-2-qde@naccy.de\n"", '']",Fixes misaligned array closing bracket in libbpf's btf_dump_array_data function.,"libbpf, array, fix",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"[""It's not related to any of the above.""]"
fc29e04ae1ad4c99422c0b8ae4b43cfe99c70429,fc29e04ae1ad4c99422c0b8ae4b43cfe99c70429,Jesper Dangaard Brouer,hawk@kernel.org,1713289886,Tejun Heo,tj@kernel.org,1713305442,0e253e08ac5881d265f82bf64faa2c8c5c1b558e,15b8b9ab5081d8dce9aa27a594ba4db2c29cefc0,"cgroup/rstat: add cgroup_rstat_lock helpers and tracepoints

This commit enhances the ability to troubleshoot the global
cgroup_rstat_lock by introducing wrapper helper functions for the lock
along with associated tracepoints.

Although global"," the cgroup_rstat_lock helper APIs and tracepoints take
arguments such as cgroup pointer and cpu_in_loop variable. This
adjustment is made because flushing occurs per cgroup despite the lock
being global. Hence","[' when troubleshooting', "" it's important to identify the\nrelevant cgroup. The cpu_in_loop variable is necessary because the global\nlock may be released within the main flushing loop that traverses CPUs.\nIn the tracepoints"", ' the cpu_in_loop value is set to -1 when acquiring the\nmain lock; otherwise', ' it denotes the CPU number processed last.\n\nThe new feature in this patchset is detecting when lock is contended. The\ntracepoints are implemented with production in mind. For minimum overhead\nattach to cgroup:cgroup_rstat_lock_contended', ' which only gets activated\nwhen trylock detects lock is contended. A quick production check for\nissues could be done via this perf commands:\n\n perf record -g -e cgroup:cgroup_rstat_lock_contended\n\nNext natural question would be asking how long time do lock contenders\nwait for obtaining the lock. This can be answered by measuring the time\nbetween cgroup:cgroup_rstat_lock_contended and cgroup:cgroup_rstat_locked\nwhen args->contended is set.  Like this bpftrace script:\n\n bpftrace -e \'\n   tracepoint:cgroup:cgroup_rstat_lock_contended {@start[tid]=nsecs}\n   tracepoint:cgroup:cgroup_rstat_locked {\n     if (args->contended) {\n       @wait_ns=hist(nsecs-@start[tid]); delete(@start[tid]);}}\n   interval:s:1 {time(""%H:%M:%S ""); print(@wait_ns); }\'\n\nExtending with time spend holding the lock will be more expensive as this\nalso looks at all the non-contended cases.\nLike this bpftrace script:\n\n bpftrace -e \'\n   tracepoint:cgroup:cgroup_rstat_lock_contended {@start[tid]=nsecs}\n   tracepoint:cgroup:cgroup_rstat_locked { @locked[tid]=nsecs;\n     if (args->contended) {\n       @wait_ns=hist(nsecs-@start[tid]); delete(@start[tid]);}}\n   tracepoint:cgroup:cgroup_rstat_unlock {\n       @locked_ns=hist(nsecs-@locked[tid]); delete(@locked[tid]);}\n   interval:s:1 {time(""%H:%M:%S "");  print(@wait_ns);print(@locked_ns); }\'\n\nSigned-off-by: Jesper Dangaard Brouer <hawk@kernel.org>\nSigned-off-by: Tejun Heo <tj@kernel.org>\n', '']",The commit adds helper functions and tracepoints for better management and troubleshooting of cgroup_rstat_lock.,"cgroup,rstat,tracepoints",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['cgroup like programs']
ad2d22b617b7c0ca2cff4da6dc063183822484bb,ad2d22b617b7c0ca2cff4da6dc063183822484bb,Quentin Monnet,qmo@kernel.org,1712970867,Daniel Borkmann,daniel@iogearbox.net,1713283105,84c66b43645315de17e0cde4ef7ac3bf93ad92e6,986e7663f98ec7441d9d948263ec0dda71e7479f,"bpftool: Address minor issues in bash completion

This commit contains a series of clean-ups and fixes for bpftool's bash
completion file:

- Make sure all local variables are declared as such.
- Make sure variables are initialised before being read.
- Update ELF section (""maps"" -> "".maps"") for looking up map names in
  object files.
- Fix call to _init_completion.
- Move definition for MAP_TYPE and PROG_TYPE higher up in the scope to
  avoid defining them multiple times"," reuse MAP_TYPE where relevant.
- Simplify completion for ""duration"" keyword in ""bpftool prog profile"".
- Fix completion for ""bpftool struct_ops register"" and ""bpftool link
  (pin|detach)"" where we would repeatedly suggest file names instead of
  suggesting just one name.
- Fix completion for ""bpftool iter pin ... map MAP"" to account for the
  ""map"" keyword.
- Add missing ""detach"" suggestion for ""bpftool link"".

Signed-off-by: Quentin Monnet <qmo@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240413011427.14402-3-qmo@kernel.org
",[''],"The commit fixes and refines bash completion in bpftool by addressing variable declarations, initialization, and improving command completion suggestions.","bash completion, bpftool, fixes",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"[""It's not related to any of the above.""]"
986e7663f98ec7441d9d948263ec0dda71e7479f,986e7663f98ec7441d9d948263ec0dda71e7479f,Quentin Monnet,qmo@kernel.org,1712970866,Daniel Borkmann,daniel@iogearbox.net,1713283105,cd7b8920e9940a6a8daec85ed3a3b050a63641af,1f586614f3ffa80fdf2116b2a1bebcdb5969cef8,"bpftool: Update documentation where progs/maps can be passed by name

When using references to BPF programs"," bpftool supports passing programs
by name on the command line. The manual pages for ""bpftool prog"" and
""bpftool map"" (for prog_array updates) mention it","[' but we have a few\nadditional subcommands that support referencing programs by name but do\nnot mention it in their documentation. Let\'s update the pages for\nsubcommands ""btf""', ' ""cgroup""', ' and ""net"".\n\nSimilarly', ' we can reference maps by name when passing them to ""bpftool\nprog load""', ' so we update the page for ""bpftool prog"" as well.\n\nSigned-off-by: Quentin Monnet <qmo@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240413011427.14402-2-qmo@kernel.org\n', '']",Update bpftool documentation to include support for passing programs and maps by name on the command line.,"bpftool, documentation, command-line",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1f586614f3ffa80fdf2116b2a1bebcdb5969cef8,1f586614f3ffa80fdf2116b2a1bebcdb5969cef8,Harishankar Vishwanathan,harishankar.vishwanathan@gmail.com,1713268382,Daniel Borkmann,daniel@iogearbox.net,1713282927,7b5f4fa20fcbbdf316f4832c33d79dc8d4e8723d,dac045fc9fa653e250f991ea8350b32cfec690d2,"bpf: Harden and/or/xor value tracking in verifier

This patch addresses a latent unsoundness issue in the
scalar(32)_min_max_and/or/xor functions. While it is not a bugfix","
it ensures that the functions produce sound outputs for all inputs.

The issue occurs in these functions when setting signed bounds. The
following example illustrates the issue for scalar_min_max_and()","['\nbut it applies to the other functions.\n\nIn scalar_min_max_and() the following clause is executed when ANDing\npositive numbers:\n\n  /* ANDing two positives gives a positive', ' so safe to\n   * cast result into s64.\n   */\n  dst_reg->smin_value = dst_reg->umin_value;\n  dst_reg->smax_value = dst_reg->umax_value;\n\nHowever', ' if umin_value and umax_value of dst_reg cross the sign boundary\n(i.e.', ' if (s64)dst_reg->umin_value > (s64)dst_reg->umax_value)', ' then we\nwill end up with smin_value > smax_value', ' which is unsound.\n\nPrevious works [1', ' 2] have discovered and reported this issue. Our tool\nAgni [2', ' 3] consideres it a false positive. This is because', ' during the\nverification of the abstract operator scalar_min_max_and()', ' Agni restricts\nits inputs to those passing through reg_bounds_sync(). This mimics\nreal-world verifier behavior', ' as reg_bounds_sync() is invariably executed\nat the tail of every abstract operator. Therefore', ' such behavior is\nunlikely in an actual verifier execution.\n\nHowever', ' it is still unsound for an abstract operator to set signed bounds\nsuch that smin_value > smax_value. This patch fixes it', ' making the abstract\noperator sound for all (well-formed) inputs.\n\nIt is worth noting that while the previous code updated the signed bounds\n(using the output unsigned bounds) only when the *input signed* bounds\nwere positive', ' the new code updates them whenever the *output unsigned*\nbounds do not cross the sign boundary.\n\nAn alternative approach to fix this latent unsoundness would be to\nunconditionally set the signed bounds to unbounded [S64_MIN', ' S64_MAX]', ' and\nlet reg_bounds_sync() refine the signed bounds using the unsigned bounds\nand the tnum. We found that our approach produces more precise (tighter)\nbounds.\n\nFor example', ' consider these inputs to BPF_AND:\n\n  /* dst_reg */\n  var_off.value: 8608032320201083347\n  var_off.mask: 615339716653692460\n  smin_value: 8070450532247928832\n  smax_value: 8070450532247928832\n  umin_value: 13206380674380886586\n  umax_value: 13206380674380886586\n  s32_min_value: -2110561598\n  s32_max_value: -133438816\n  u32_min_value: 4135055354\n  u32_max_value: 4135055354\n\n  /* src_reg */\n  var_off.value: 8584102546103074815\n  var_off.mask: 9862641527606476800\n  smin_value: 2920655011908158522\n  smax_value: 7495731535348625717\n  umin_value: 7001104867969363969\n  umax_value: 8584102543730304042\n  s32_min_value: -2097116671\n  s32_max_value: 71704632\n  u32_min_value: 1047457619\n  u32_max_value: 4268683090\n\nAfter going through tnum_and() -> scalar32_min_max_and() ->\nscalar_min_max_and() -> reg_bounds_sync()', ' our patch produces the following\nbounds for s32:\n\n  s32_min_value: -1263875629\n  s32_max_value: -159911942\n\nWhereas', ' setting the signed bounds to unbounded in scalar_min_max_and()\nproduces:\n\n  s32_min_value: -1263875629\n  s32_max_value: -1\n\nAs observed', ' our patch produces a tighter s32 bound. We also confirmed\nusing Agni and SMT verification that our patch always produces signed\nbounds that are equal to or more precise than setting the signed bounds to\nunbounded in scalar_min_max_and().\n\n  [1] https://sanjit-bhat.github.io/assets/pdf/ebpf-verifier-range-analysis22.pdf\n  [2] https://link.springer.com/chapter/10.1007/978-3-031-37709-9_12\n  [3] https://github.com/bpfverif/agni\n\nCo-developed-by: Matan Shachnai <m.shachnai@rutgers.edu>\nSigned-off-by: Matan Shachnai <m.shachnai@rutgers.edu>\nCo-developed-by: Srinivas Narayana <srinivas.narayana@rutgers.edu>\nSigned-off-by: Srinivas Narayana <srinivas.narayana@rutgers.edu>\nCo-developed-by: Santosh Nagarakatte <santosh.nagarakatte@rutgers.edu>\nSigned-off-by: Santosh Nagarakatte <santosh.nagarakatte@rutgers.edu>\nSigned-off-by: Harishankar Vishwanathan <harishankar.vishwanathan@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240402212039.51815-1-harishankar.vishwanathan@gmail.com\nLink: https://lore.kernel.org/bpf/20240416115303.331688-1-harishankar.vishwanathan@gmail.com\n', '']",This commit hardens the and/or/xor value tracking in the eBPF verifier to address potential unsoundness.,"harden, verifier, tracking",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
dac045fc9fa653e250f991ea8350b32cfec690d2,dac045fc9fa653e250f991ea8350b32cfec690d2,Chen Pei,cp0613@linux.alibaba.com,1713169168,Daniel Borkmann,daniel@iogearbox.net,1713280938,5d24b197f04fa291aa420db01770b791079e8a1c,fc5eb4a84e4c063e75a6a6e92308e9533c0f19b5,bpf," tests: Fix typos in comments

Currently","[' there are two comments with same name ""64-bit ATOMIC magnitudes""', '\nthe second one should be ""32-bit ATOMIC magnitudes"" based on the context.\n\nSigned-off-by: Chen Pei <cp0613@linux.alibaba.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/bpf/20240415081928.17440-1-cp0613@linux.alibaba.com\n', '']",Fix typographical errors in test comment documentation for clarity.,"typos,test,comments",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
10541b374aa05c8118cc6a529a615882e53f261b,10541b374aa05c8118cc6a529a615882e53f261b,Xu Kuohai,xukuohai@huawei.com,1713249728,Daniel Borkmann,daniel@iogearbox.net,1713280781,59373141f5538e6004c743c0a6c0493ce6b7ca79,dc7d7447b56bcc9cf79a9c22e4edad200a298e4c,riscv," bpf: Fix incorrect runtime stats

When __bpf_prog_enter() returns zero","[' the s1 register is not set to zero', '\nresulting in incorrect runtime stats. Fix it by setting s1 immediately upon\nthe return of __bpf_prog_enter().\n\nFixes: 49b5e77ae3e2 (""riscv', ' bpf: Add bpf trampoline support for RV64"")\nSigned-off-by: Xu Kuohai <xukuohai@huawei.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Pu Lehui <pulehui@huawei.com>\nAcked-by: Björn Töpel <bjorn@kernel.org>\nLink: https://lore.kernel.org/bpf/20240416064208.2919073-3-xukuohai@huaweicloud.com\n', '']",Fixed incorrect runtime statistics when __bpf_prog_enter() returns zero for riscv architecture.,"runtime, stats, fix",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
dc7d7447b56bcc9cf79a9c22e4edad200a298e4c,dc7d7447b56bcc9cf79a9c22e4edad200a298e4c,Xu Kuohai,xukuohai@huawei.com,1713249727,Daniel Borkmann,daniel@iogearbox.net,1713280770,584898bf8b410c67966a7586f587c09eeb7d0a5c,37eacb9f6e89fb399a79e952bc9c78eb3e16290e,bpf," arm64: Fix incorrect runtime stats

When __bpf_prog_enter() returns zero","[' the arm64 register x20 that stores\nprog start time is not assigned to zero', ' causing incorrect runtime stats.\n\nTo fix it', ' assign the return value of bpf_prog_enter() to x20 register\nimmediately upon its return.\n\nFixes: efc9909fdce0 (""bpf', ' arm64: Add bpf trampoline for arm64"")\nReported-by: Ivan Babrou <ivan@cloudflare.com>\nSigned-off-by: Xu Kuohai <xukuohai@huawei.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Ivan Babrou <ivan@cloudflare.com>\nAcked-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240416064208.2919073-2-xukuohai@huaweicloud.com\n', '']",Fix incorrect runtime statistics on ARM64 when __bpf_prog_enter() returns zero.,"ARM64, fix, runtime",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fc5eb4a84e4c063e75a6a6e92308e9533c0f19b5,fc5eb4a84e4c063e75a6a6e92308e9533c0f19b5,Ard Biesheuvel,ardb@kernel.org,1713198045,Daniel Borkmann,daniel@iogearbox.net,1713278113,a5e08b469477b03deed0c6a87e51ca925c53fc3c,4d4992ff587604455e8843a0e76dce0b99175319,"btf: Avoid weak external references

If the BTF code is enabled in the build configuration"," the start/stop
BTF markers are guaranteed to exist. Only when CONFIG_DEBUG_INFO_BTF=n","['\nthe references in btf_parse_vmlinux() will remain unsatisfied', ' relying\non the weak linkage of the external references to avoid breaking the\nbuild.\n\nAvoid GOT based relocations to these markers in the final executable by\ndropping the weak attribute and instead', ' make btf_parse_vmlinux() return\nERR_PTR(-ENOENT) directly if CONFIG_DEBUG_INFO_BTF is not enabled to\nbegin with.  The compiler will drop any subsequent references to\n__start_BTF and __stop_BTF in that case', ' allowing the link to succeed.\n\nNote that Clang will notice that taking the address of __start_BTF can\nno longer yield NULL', ' so testing for that condition becomes unnecessary.\n\nSigned-off-by: Ard Biesheuvel <ardb@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Arnd Bergmann <arnd@arndb.de>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/bpf/20240415162041.2491523-8-ardb+git@google.com\n', '']",The commit modifies BTF code to avoid weak external references when CONFIG_DEBUG_INFO_BTF is not set.,"BTF, weak references, CONFIG_DEBUG_INFO_BTF",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
854dd99b5ddc9d90e31e5f112462a5994dd31810,854dd99b5ddc9d90e31e5f112462a5994dd31810,Ingo Molnar,mingo@kernel.org,1713126807,Ingo Molnar,mingo@kernel.org,1713126926,25cba84a41ae9d6cd5f38e26cc4dc42efe00422f,e224d1c1fb93f258030186b4878abe105c296ac1,"perf/bpf: Mark perf_event_set_bpf_handler() and perf_event_free_bpf_handler() as inline too

They can be unused with certain Kconfig variations:

  kernel/events/core.c:9622:13: warning: ‘perf_event_free_bpf_handler’ defined but not used [-Wunused-function]
  kernel/events/core.c:9586:12: warning: ‘perf_event_set_bpf_handler’ defined but not used [-Wunused-function]

Since they are both single-use"," mark them inline.

Signed-off-by: Ingo Molnar <mingo@kernel.org>
Cc: linux-kernel@vger.kernel.org
Cc: Kyle Huey <khuey@kylehuey.com>
",[''],Marking perf_event_set_bpf_handler and perf_event_free_bpf_handler as inline to avoid unused function warnings.,"inline, perf_event, unused",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
459fee7b508231cd4622b3bd94aaa85e8e16b888,459fee7b508231cd4622b3bd94aaa85e8e16b888,Ian Rogers,irogers@google.com,1712376550,Arnaldo Carvalho de Melo,acme@redhat.com,1712955242,12a520c6e1c1a20d144ae24139bb34e04e9dc831,2b8c43e7688fa61b842ea2b21d4159c67d6f2fd1,"perf bench uprobe: Remove lib64 from libc.so.6 binary path

bpf_program__attach_uprobe_opts will search LD_LIBRARY_PATH and so
specifying `/lib64` is unnecessary and causes failures for libc.so.6
paths like `/lib/x86_64-linux-gnu/libc.so.6`.

Fixes: 7b47623b8cae8149 (""perf bench uprobe trace_printk: Add entry attaching an BPF program that does a trace_printk"")
Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Cc: Adrian Hunter <adrian.hunter@intel.com>
Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
Cc: Andrei Vagin <avagin@google.com>
Cc: Ingo Molnar <mingo@redhat.com>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: Kees Kook <keescook@chromium.org>
Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Namhyung Kim <namhyung@kernel.org>
Cc: Peter Zijlstra <peterz@infradead.org>
Link: https://lore.kernel.org/r/20240406040911.1603801-1-irogers@google.com
Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
",,Removed unnecessary /lib64 directory from libc.so.6 path to prevent failures in perf bench uprobe.,"libc.so.6, LD_LIBRARY_PATH, uprobe",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
37eacb9f6e89fb399a79e952bc9c78eb3e16290e,37eacb9f6e89fb399a79e952bc9c78eb3e16290e,Anton Protopopov,aspsk@isovalent.com,1712931060,Daniel Borkmann,daniel@iogearbox.net,1712939840,58df1bb3ed11511fa6c3fd8f7f56f9ff13b6e2d9,6648e613226e18897231ab5e42ffc29e63fa3365,"bpf: Fix a verifier verbose message

Long ago a map file descriptor in a pseudo ldimm64 instruction could
only be present as an immediate value insn[0].imm"," and thus this value
was used in a verbose verifier message printed when the file descriptor
wasn't valid. Since addition of BPF_PSEUDO_MAP_IDX_VALUE/BPF_PSEUDO_MAP_IDX
the insn[0].imm field can also contain an index pointing to the file
descriptor in the attr.fd_array array. However","[' if the file descriptor\nis invalid', ' the verifier still prints the verbose message containing\nvalue of insn[0].imm. Patch the verifier message to always print the\nactual file descriptor value.\n\nFixes: 387544bfa291 (""bpf: Introduce fd_idx"")\nSigned-off-by: Anton Protopopov <aspsk@isovalent.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240412141100.3562942-1-aspsk@isovalent.com\n', '']",Fixes a verbose message issue in the eBPF verifier for map descriptors.,"fix, verifier, message",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4d4992ff587604455e8843a0e76dce0b99175319,4d4992ff587604455e8843a0e76dce0b99175319,Jiri Olsa,jolsa@kernel.org,1712758192,Daniel Borkmann,daniel@iogearbox.net,1712939121,b6bc29b0220753ef4eaa63910d935df69e0373cd,23cc4fe44f1df5ccce088a7c9398f96794047c2a,"selftests/bpf: Add read_trace_pipe_iter function

We have two printk tests reading trace_pipe in non blocking way","
with the very same code. Moving that in new read_trace_pipe_iter
function.

Current read_trace_pipe is used from samples/bpf and needs to
do blocking read and printf of the trace_pipe data","[' using new\nread_trace_pipe_iter to implement that.\n\nBoth printk tests do early checks for the number of found messages\nand can bail earlier', ' but I did not find any speed difference w/o\nthat condition', ' so I did not complicate the change more for that.\n\nSome of the samples/bpf programs use read_trace_pipe function', ""\nso I kept that interface untouched. I did not see any issues with\naffected samples/bpf programs other than there's slight change in\nread_trace_pipe output. The current code uses puts that adds new\nline after the printed string"", ' so we would occasionally see extra\nnew line. With this patch we read output per lines', "" so there's no\nneed to use puts and we can use just printf instead without extra\nnew line.\n\nSigned-off-by: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/bpf/20240410140952.292261-1-jolsa@kernel.org\n"", '']",Refactor selftests/bpf to introduce a new non-blocking read_trace_pipe_iter function.,"read_trace_pipe_iter, selftests, non-blocking",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tracepoints like programs']
23cc4fe44f1df5ccce088a7c9398f96794047c2a,23cc4fe44f1df5ccce088a7c9398f96794047c2a,Thorsten Blum,thorsten.blum@toblux.com,1712853780,Daniel Borkmann,daniel@iogearbox.net,1712938749,c9b26ebf897f7fc36b75b88405bb5df4a8a2cbd9,c53e853c2d8145859f57c63662030f7aaa61cfdc,"bpftool: Fix typo in error message

s/at at/at a/

Signed-off-by: Thorsten Blum <thorsten.blum@toblux.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Quentin Monnet <qmo@kernel.org>
Link: https://lore.kernel.org/bpf/20240411164258.533063-3-thorsten.blum@toblux.com
",,Fix a typo in the error message within bpftool utility.,"bpftool, typo, error message",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"[""It's not related to any of the above.""]"
93d3fde7fd19c2e2cde7220e7986f9a75e9c5680,93d3fde7fd19c2e2cde7220e7986f9a75e9c5680,Ingo Molnar,mingo@kernel.org,1712915700,Ingo Molnar,mingo@kernel.org,1712915760,ca51ab80642af28284795b90cb93235493e752cb,a265c9f6d52ac760e6e572bac73a11b60b998779,"perf/bpf: Change the !CONFIG_BPF_SYSCALL stubs to static inlines

Otherwise the compiler will be unhappy if they go unused","
which they do on allnoconfigs.

Signed-off-by: Ingo Molnar <mingo@kernel.org>
Cc: Kyle Huey <me@kylehuey.com>
Link: https://lore.kernel.org/r/ZhkE9F4dyfR2dH2D@gmail.com
",[''],Change stubs to static inlines in perf/bpf to avoid compiler warnings with !CONFIG_BPF_SYSCALL.,"perf,bpf,stubs",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The syscall interface,"[""It's not related to any of the above.""]"
a265c9f6d52ac760e6e572bac73a11b60b998779,a265c9f6d52ac760e6e572bac73a11b60b998779,Kyle Huey,me@kylehuey.com,1712886619,Ingo Molnar,mingo@kernel.org,1712915391,ca0cdf253184f1af3a265b9e5a5e9aee67855988,c4fcc7d1f41532e878087c7c43f4cf247604d68b,"selftest/bpf: Test a perf BPF program that suppresses side effects

The test sets a hardware breakpoint and uses a BPF program to suppress the
side effects of a perf event sample", including I/O availability signals,"['\nSIGTRAPs', ' and decrementing the event counter limit', ' if the IP matches the\nexpected value. Then the function with the breakpoint is executed multiple\ntimes to test that all effects behave as expected.\n\nSigned-off-by: Kyle Huey <khuey@kylehuey.com>\nSigned-off-by: Ingo Molnar <mingo@kernel.org>\nAcked-by: Song Liu <song@kernel.org>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240412015019.7060-8-khuey@kylehuey.com\n', '']",Add a selftest for perf BPF program to suppress side effects of perf event samples.,"selftest, perf, side-effects",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tracepoints like programs']
c4fcc7d1f41532e878087c7c43f4cf247604d68b,c4fcc7d1f41532e878087c7c43f4cf247604d68b,Kyle Huey,me@kylehuey.com,1712886618,Ingo Molnar,mingo@kernel.org,1712915390,42d5d279844896a20d768199e71ca22cb84671a5,76f6d58845829e5d6ef55532e67a323e7d30c26e,"perf/bpf: Allow a BPF program to suppress all sample side effects

Returning zero from a BPF program attached to a perf event already
suppresses any data output. Return early from __perf_event_overflow() in
this case so it will also suppress event_limit accounting"," SIGTRAP
generation","[' and F_ASYNC signalling.\n\nSigned-off-by: Kyle Huey <khuey@kylehuey.com>\nSigned-off-by: Ingo Molnar <mingo@kernel.org>\nAcked-by: Song Liu <song@kernel.org>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nAcked-by: Namhyung Kim <namhyung@kernel.org>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240412015019.7060-7-khuey@kylehuey.com\n', '']",The commit allows BPF programs to suppress all sample side effects by returning zero from __perf_event_overflow.,"BPF program, perf event, suppress",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['tracepoints like programs', 'profile like programs']"
76f6d58845829e5d6ef55532e67a323e7d30c26e,76f6d58845829e5d6ef55532e67a323e7d30c26e,Kyle Huey,me@kylehuey.com,1712886617,Ingo Molnar,mingo@kernel.org,1712915390,515b94130689238f4a39e396f311d35c0870a7c2,f11f10bfa1ca23b32020b2073aa13131a27978fe,"perf/bpf: Remove unneeded uses_default_overflow_handler()

Now that struct perf_event's orig_overflow_handler is gone"," there's no need
for the functions and macros to support looking past overflow_handler to
orig_overflow_handler.

This patch is solely a refactoring and results in no behavior change.

Signed-off-by: Kyle Huey <khuey@kylehuey.com>
Signed-off-by: Ingo Molnar <mingo@kernel.org>
Acked-by: Will Deacon <will@kernel.org>
Acked-by: Song Liu <song@kernel.org>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240412015019.7060-6-khuey@kylehuey.com
",[''],Remove unneeded functions in perf/bpf after orig_overflow_handler removal.,"refactoring, perf, overflow_handler",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
f11f10bfa1ca23b32020b2073aa13131a27978fe,f11f10bfa1ca23b32020b2073aa13131a27978fe,Kyle Huey,me@kylehuey.com,1712886616,Ingo Molnar,mingo@kernel.org,1712915389,1657fdb40278f77e27436ee5a56855a9983873c9,14e40a9578b70cc5323e55f61292a7e021f6037c,perf/bpf: Call BPF handler directly," not through overflow machinery

To ultimately allow BPF programs attached to perf events to completely
suppress all of the effects of a perf event overflow (rather than just the
sample output","[' as they do today)', "" call bpf_overflow_handler() from\n__perf_event_overflow() directly rather than modifying struct perf_event's\noverflow_handler. Return the BPF program's return value from\nbpf_overflow_handler() so that __perf_event_overflow() knows how to\nproceed. Remove the now unnecessary orig_overflow_handler from struct\nperf_event.\n\nThis patch is solely a refactoring and results in no behavior change.\n\nSuggested-by: Namhyung Kim <namhyung@kernel.org>\nSigned-off-by: Kyle Huey <khuey@kylehuey.com>\nSigned-off-by: Ingo Molnar <mingo@kernel.org>\nAcked-by: Song Liu <song@kernel.org>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240412015019.7060-5-khuey@kylehuey.com\n"", '']",This commit allows BPF programs to suppress all effects of perf event overflow by calling the handler directly.,"BPF, perf, overflow",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
14e40a9578b70cc5323e55f61292a7e021f6037c,14e40a9578b70cc5323e55f61292a7e021f6037c,Kyle Huey,me@kylehuey.com,1712886615,Ingo Molnar,mingo@kernel.org,1712915389,7c86fb11ad61a5e7d6ada7248495da6409c72082,924d934393f98fa6a41d6ea27352faf79c2bbaf6,"perf/bpf: Remove #ifdef CONFIG_BPF_SYSCALL from struct perf_event members

This will allow __perf_event_overflow() (which is independent of
CONFIG_BPF_SYSCALL) to use struct perf_event's prog to decide whether to
call bpf_overflow_handler().

Suggested-by: Ingo Molnar <mingo@kernel.org>
Signed-off-by: Kyle Huey <khuey@kylehuey.com>
Signed-off-by: Ingo Molnar <mingo@kernel.org>
Link: https://lore.kernel.org/r/20240412015019.7060-4-khuey@kylehuey.com
",,Remove CONFIG_BPF_SYSCALL dependency from perf_event structure to enable independent functionality.,"perf_event,BPF_SYSCALL,bpf_overflow_handler",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
924d934393f98fa6a41d6ea27352faf79c2bbaf6,924d934393f98fa6a41d6ea27352faf79c2bbaf6,Kyle Huey,me@kylehuey.com,1712886614,Ingo Molnar,mingo@kernel.org,1712915388,451e56cb147c607c21f1f4542e895b84a1c6ae7d,4c03fe11b96bda60610aca77002e83f37b4a2242,"perf/bpf: Create bpf_overflow_handler() stub for !CONFIG_BPF_SYSCALL

This will allow __perf_event_overflow() (which is independent of
CONFIG_BPF_SYSCALL) to call bpf_overflow_handler().

Signed-off-by: Kyle Huey <khuey@kylehuey.com>
Signed-off-by: Ingo Molnar <mingo@kernel.org>
Link: https://lore.kernel.org/r/20240412015019.7060-3-khuey@kylehuey.com
",,Create a bpf_overflow_handler stub for systems without CONFIG_BPF_SYSCALL.,"bpf_overflow_handler, CONFIG_BPF_SYSCALL, perf_event_overflow",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['other']
4c03fe11b96bda60610aca77002e83f37b4a2242,4c03fe11b96bda60610aca77002e83f37b4a2242,Kyle Huey,me@kylehuey.com,1712886613,Ingo Molnar,mingo@kernel.org,1712915388,6e3d71e85c016b3a0b5d034b07d6bb51189f20fc,acf68d98cae8a60dc4af2e9feaaa799bf0aa5c04,"perf/bpf: Reorder bpf_overflow_handler() ahead of __perf_event_overflow()

This will allow __perf_event_overflow() to call bpf_overflow_handler().

Signed-off-by: Kyle Huey <khuey@kylehuey.com>
Signed-off-by: Ingo Molnar <mingo@kernel.org>
Link: https://lore.kernel.org/r/20240412015019.7060-2-khuey@kylehuey.com
",,Reorders function definitions to allow __perf_event_overflow() to call bpf_overflow_handler().,bpf reordering overflow,It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1e52af7f023c44859868306fac1a4b6b556cf47b,1e52af7f023c44859868306fac1a4b6b556cf47b,Paul E. McKenney,paulmck@kernel.org,1709147848,Uladzislau Rezki (Sony),urezki@gmail.com,1712913805,8b987ba452c39fb944f4ee4d882b1ef079d86cab,02b3c5fcdfe46f9c9dd5d3fc199612b13bf47c06,"bpf: Choose RCU Tasks based on TASKS_RCU rather than PREEMPTION

The advent of CONFIG_PREEMPT_AUTO", AKA lazy preemption,"[' will mean that\neven kernels built with CONFIG_PREEMPT_NONE or CONFIG_PREEMPT_VOLUNTARY\nmight see the occasional preemption', ' and that this preemption just might\nhappen within a trampoline.\n\nTherefore', ' update bpf_tramp_image_put() to choose call_rcu_tasks()\nbased on CONFIG_TASKS_RCU instead of CONFIG_PREEMPTION.\n\nThis change might enable further simplifications', ' but the goal of this\neffort is to make the code safe', ' not necessarily optimal.\n\nSigned-off-by: Paul E. McKenney <paulmck@kernel.org>\nCc: Alexei Starovoitov <ast@kernel.org>\nCc: Daniel Borkmann <daniel@iogearbox.net>\nCc: John Fastabend <john.fastabend@gmail.com>\nCc: Andrii Nakryiko <andrii@kernel.org>\nCc: Martin KaFai Lau <martin.lau@linux.dev>\nCc: Song Liu <song@kernel.org>\nCc: Yonghong Song <yonghong.song@linux.dev>\nCc: KP Singh <kpsingh@kernel.org>\nCc: Stanislav Fomichev <sdf@google.com>\nCc: Hao Luo <haoluo@google.com>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: Ankur Arora <ankur.a.arora@oracle.com>\nCc: Thomas Gleixner <tglx@linutronix.de>\nCc: <bpf@vger.kernel.org>\nSigned-off-by: Uladzislau Rezki (Sony) <urezki@gmail.com>\n', '']",The commit updates eBPF RCU tasks selection to use TASKS_RCU instead of preemption settings.,"RCU,TASKS_RCU,PREEMPTION",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c53e853c2d8145859f57c63662030f7aaa61cfdc,c53e853c2d8145859f57c63662030f7aaa61cfdc,Martin KaFai Lau,martin.lau@kernel.org,1712859476,Martin KaFai Lau,martin.lau@kernel.org,1712862407,eee55c541945cc7bccee82edc0794d75e469637c,d75142dbeb2bd1587b9cc19f841578f541275a64 dc34e44ea6a1c11cc517adc6df527b457acb9eaf,"Merge branch 'export send_recv_data'

Geliang Tang says:

====================
v5:
 - address Martin's comments for v4 (thanks).
 - update patch 2"," use 'return err' instead of 'return -1/0'.
 - drop patch 3 in v4.

v4:
 - fix a bug in v3","["" it should be 'if (err)'"", ' not \'if (!err)\'.\n - move ""selftests/bpf: Use log_err in network_helpers"" out of this\n   series.\n\nv3:\n - add two more patches.\n - use log_err instead of ASSERT in v3.\n - let send_recv_data return int as Martin suggested.\n\nv2:\n\nAddress Martin\'s comments for v1 (thanks.)\n - drop patch 1', ' ""export send_byte helper"".\n - drop ""WRITE_ONCE(arg.stop', ' 0)"".\n - rebased.\n\nsend_recv_data will be re-used in MPTCP bpf tests', ' but not included\nin this set because it depends on other patches that have not been\nin the bpf-next yet. It will be sent as another set soon.\n====================\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",The commit merges branch updates to export send and receive data functions with bug fixes and code improvements.,"merge, bugfix, export",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['other']
dc34e44ea6a1c11cc517adc6df527b457acb9eaf,dc34e44ea6a1c11cc517adc6df527b457acb9eaf,Geliang Tang,tanggeliang@kylinos.cn,1712814192,Martin KaFai Lau,martin.lau@kernel.org,1712862402,eee55c541945cc7bccee82edc0794d75e469637c,68acca6e6f99b1f928a2c05b92bb1c272edb8ae7,"selftests/bpf: Export send_recv_data helper

This patch extracts the code to send and receive data into a new
helper named send_recv_data() in network_helpers.c and export it
in network_helpers.h.

This helper will be used for MPTCP BPF selftests.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Link: https://lore.kernel.org/r/5231103be91fadcce3674a589542c63b6a5eedd4.1712813933.git.tanggeliang@kylinos.cn
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Export send_recv_data helper for MPTCP BPF selftests in network_helpers files.,"send_recv_data,BPF,selftests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
68acca6e6f99b1f928a2c05b92bb1c272edb8ae7,68acca6e6f99b1f928a2c05b92bb1c272edb8ae7,Geliang Tang,tanggeliang@kylinos.cn,1712814191,Martin KaFai Lau,martin.lau@kernel.org,1712859476,3767bece7681558b7ac282a88a2cc74070123365,d75142dbeb2bd1587b9cc19f841578f541275a64,"selftests/bpf: Add struct send_recv_arg

Avoid setting total_bytes and stop as global variables"," this patch adds
a new struct named send_recv_arg to pass arguments between threads. Put
these two variables together with fd into this struct and pass it to
server thread","[' so that server thread can access these two variables without\nsetting them as global ones.\n\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nLink: https://lore.kernel.org/r/ca1dd703b796f6810985418373e750f7068b4186.1712813933.git.tanggeliang@kylinos.cn\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Add struct send_recv_arg to pass arguments between threads in selftests/bpf.,"selftests,bpf,struct",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f3408580bac8ce5cd76e7391e529c0a22e7c7eb2,f3408580bac8ce5cd76e7391e529c0a22e7c7eb2,Namhyung Kim,namhyung@kernel.org,1712703342,Namhyung Kim,namhyung@kernel.org,1712856606,49215554c047a3aed647c2c8b5da1217fe658ae3,2b8dbf69ec60faf6c7db49e57d7f316409ccec92,"perf lock contention: Add a missing NULL check

I got a report for a failure in BPF verifier on a recent kernel with
perf lock contention command.  It checks task->sighand->siglock without
checking if sighand is NULL or not.  Let's add one.

  ; if (&curr->sighand->siglock == (void *)lock)
  265: (79) r1 = *(u64 *)(r0 +2624)     ; frame1: R0_w=trusted_ptr_task_struct(off=0","imm=0)
                                        ;         R1_w=rcu_ptr_or_null_sighand_struct(off=0","['imm=0)\n  266: (b7) r2 = 0                      ; frame1: R2_w=0\n  267: (0f) r1 += r2\n  R1 pointer arithmetic on rcu_ptr_or_null_ prohibited', ' null-check it first\n  processed 164 insns (limit 1000000) max_states_per_insn 1 total_states 15 peak_states 15 mark_read 5\n  -- END PROG LOAD LOG --\n  libbpf: prog \'contention_end\': failed to load: -13\n  libbpf: failed to load object \'lock_contention_bpf\'\n  libbpf: failed to load BPF skeleton \'lock_contention_bpf\': -13\n  Failed to load lock-contention BPF skeleton\n  lock contention BPF setup failed\n  lock contention did not detect any lock contention\n\nFixes: 1811e82767dcc (""perf lock contention: Track and show siglock with address"")\nReviewed-by: Ian Rogers <irogers@google.com>\nAcked-by: Arnaldo Carvalho de Melo <acme@redhat.com>\nCc: Song Liu <song@kernel.org>\nCc: bpf@vger.kernel.org\nSigned-off-by: Namhyung Kim <namhyung@kernel.org>\nLink: https://lore.kernel.org/r/20240409225542.1870999-1-namhyung@kernel.org\n', '']",The commit adds a NULL check in the perf lock contention command for a potential BPF verifier failure.,"NULL check, BPF verifier, perf lock",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d75142dbeb2bd1587b9cc19f841578f541275a64,d75142dbeb2bd1587b9cc19f841578f541275a64,Geliang Tang,tanggeliang@kylinos.cn,1712639920,Martin KaFai Lau,martin.lau@kernel.org,1712856565,5590ecccac81480f8d3ec256d7d554e2055f30b5,ffa6b26b4d8a0520b78636ca9373ab842cb3b1a8,"selftests/bpf: Fix umount cgroup2 error in test_sockmap

This patch fixes the following ""umount cgroup2"" error in test_sockmap.c:

 (cgroup_helpers.c:353: errno: Device or resource busy) umount cgroup2

Cgroup fd cg_fd should be closed before cleanup_cgroup_environment().

Fixes: 13a5f3ffd202 (""bpf: Selftests"," sockmap test prog run without setting cgroup"")
Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/0399983bde729708773416b8488bac2cd5e022b8.1712639568.git.tanggeliang@kylinos.cn
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],The commit fixes an 'umount cgroup2' error in selftests related to BPF test_sockmap.,"fix,selftests,cgroup2",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['cgroup like programs']
b912cf042072e12e93faa874265b30cc0aa521b9,b912cf042072e12e93faa874265b30cc0aa521b9,Benjamin Tissoires,bentiss@kernel.org,1712819156,Benjamin Tissoires,bentiss@kernel.org,1712844121,b747f244d5aa8f1fa8ce48ea505995ca2217b74b,685dadafbde29dc3d6b7a13be284d684b06d4d4f,"HID: bpf: fix hid_bpf_input_report() when hid-core is not ready

Reported by linux-next:
After merging the hid tree"," today's linux-next build (x86_64 allmodconfig)
failed like this:

x86_64-linux-gnu-ld: vmlinux.o: in function `hid_bpf_input_report':
(.text+0x1c75181): undefined reference to `hid_input_report'

Caused by commit 9be50ac30a83 (""HID: bpf: allow to inject HID event
from BPF"")

I just forgot to put the indirection in place.

Link: https://lore.kernel.org/linux-kernel/20240411105131.7830f966@canb.auug.org.au/
Fixes: 9be50ac30a83 (""HID: bpf: allow to inject HID event from BPF"")
Link: https://lore.kernel.org/r/20240411-fix-hid-bpf-v1-1-4ae913031a8c@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Fixes HID BPF input report handling by adding necessary indirection when hid-core is not ready.,"HID,BPF,fix",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['HID driver like programs']
ffa6b26b4d8a0520b78636ca9373ab842cb3b1a8,ffa6b26b4d8a0520b78636ca9373ab842cb3b1a8,Yonghong Song,yonghong.song@linux.dev,1712763206,Alexei Starovoitov,ast@kernel.org,1712804335,122eb6935e01f480f3dffdbb92f6327024d56956,ded8c00990b9f84e4daf4b3f4c881bace6cc990e,"selftests/bpf: Enable tests for atomics with cpuv4

When looking at Alexei's patch ([1]) which added tests for atomics","
I noticed that the tests will be skipped with cpuv4. For example","['\nwith latest llvm19', ' I see:\n  [root@arch-fb-vm1 bpf]# ./test_progs -t arena_atomics\n  #3/1     arena_atomics/add:OK\n  ...\n  #3/7     arena_atomics/xchg:OK\n  #3       arena_atomics:OK\n  Summary: 1/7 PASSED', ' 0 SKIPPED', ' 0 FAILED\n  [root@arch-fb-vm1 bpf]# ./test_progs-cpuv4 -t arena_atomics\n  #3       arena_atomics:SKIP\n  Summary: 1/0 PASSED', ' 1 SKIPPED', ' 0 FAILED\n  [root@arch-fb-vm1 bpf]#\n\nIt is perfectly fine to enable atomics-related tests for cpuv4.\nWith this patch', ' I have\n  [root@arch-fb-vm1 bpf]# ./test_progs-cpuv4 -t arena_atomics\n  #3/1     arena_atomics/add:OK\n  ...\n  #3/7     arena_atomics/xchg:OK\n  #3       arena_atomics:OK\n  Summary: 1/7 PASSED', ' 0 SKIPPED', ' 0 FAILED\n\n  [1] https://lore.kernel.org/r/20240405231134.17274-2-alexei.starovoitov@gmail.com\n\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240410153326.1851055-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Enable selftests for atomic operations compatibility with cpuv4 in BPF.,"selftests, atomics, cpuv4",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ded8c00990b9f84e4daf4b3f4c881bace6cc990e,ded8c00990b9f84e4daf4b3f4c881bace6cc990e,Alexei Starovoitov,ast@kernel.org,1712803946,Alexei Starovoitov,ast@kernel.org,1712803946,c6b821d619c3bd94494c91cdca2e1fb4b7147eec,d0a2ba197bcbeaa795c5c961d927bcaf55964669 8ba218e625f0dfb3ef46fe0721dcdf565726ff76,"Merge branch 'bpf-add-bpf_link-support-for-sk_msg-and-sk_skb-progs'

Yonghong Song says:

====================
bpf: Add bpf_link support for sk_msg and sk_skb progs

One of our internal services started to use sk_msg program and currently
it used existing prog attach/detach2 as demonstrated in selftests.
But attach/detach of all other bpf programs are based on bpf_link.
Consistent attach/detach APIs for all programs will make things easy to
undersand and less error prone. So this patch added bpf_link
support for BPF_PROG_TYPE_SK_MSG. Based on comments from
previous RFC patch"," I added BPF_PROG_TYPE_SK_SKB support as well
as both program types have similar treatment w.r.t. bpf_link
handling.

For the patch series","[' patch 1 added kernel support. Patch 2\nadded libbpf support. Patch 3 added bpftool support and\npatches 4/5 added some new tests.\n\nChangelogs:\n  v6 -> v7:\n    - fix an missing-mutex_unlock error.\n  v5 -> v6:\n    - resolve libbpf conflict due to recent upstream change.\n    - add a bpf_link_create() test.\n    - some code refactoring for better code quality.\n  v4 -> v5:\n    - increase scope of mutex protection in link_release.\n    - remove previous-leftover entry in libbpf.map.\n    - make some code changes for better understanding.\n  v3 -> v4:\n    - use a single mutex lock to protect both attach/detach/update\n      and release/fill_info/show_fdinfo.\n    - simplify code for sock_map_link_lookup().\n    - fix a few bugs.\n    - add more tests.\n  v2 -> v3:\n    - consolidate link types of sk_msg and sk_skb to\n      a single link type BPF_PROG_TYPE_SOCKMAP.\n    - fix bpf_link lifecycle issue. in v2', ' after bpf_link\n      is attached', "" a subsequent prog_attach could change\n      that bpf_link. this patch makes bpf_link having\n      correct behavior such that it won't go away facing\n      other prog/link attach for the same map and the same\n      attach type.\n====================\n\nLink: https://lore.kernel.org/r/20240410043522.3736912-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Added bpf_link support for sk_msg and sk_skb programs for consistent API usage.,"bpf_link, sk_msg, sk_skb",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['socket like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8ba218e625f0dfb3ef46fe0721dcdf565726ff76,8ba218e625f0dfb3ef46fe0721dcdf565726ff76,Yonghong Song,yonghong.song@linux.dev,1712723747,Alexei Starovoitov,ast@kernel.org,1712803945,c6b821d619c3bd94494c91cdca2e1fb4b7147eec,a15d58b2bc82abd8c4c994af158b0410424a18d3,"selftests/bpf: Add some tests with new bpf_program__attach_sockmap() APIs

Add a few more tests in sockmap_basic.c and sockmap_listen.c to
test bpf_link based APIs for SK_MSG and SK_SKB programs.
Link attach/detach/update are all tested.

All tests are passed.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Reviewed-by: John Fastabend <john.fastabend@gmail.com>
Signed-off-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20240410043547.3738448-1-yonghong.song@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add new tests for bpf_program__attach_sockmap() APIs in the selftests suite.,"selftests, sockmap, APIs",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
a15d58b2bc82abd8c4c994af158b0410424a18d3,a15d58b2bc82abd8c4c994af158b0410424a18d3,Yonghong Song,yonghong.song@linux.dev,1712723742,Alexei Starovoitov,ast@kernel.org,1712803945,f5ccabb7cd293ca28b2663bed8ca11e0894ca8a6,1f3e2091d25b2b140967480177fcaee2f0eebfb1,"selftests/bpf: Refactor out helper functions for a few tests

These helper functions will be used later new tests as well.
There are no functionality change.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Reviewed-by: John Fastabend <john.fastabend@gmail.com>
Signed-off-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20240410043542.3738166-1-yonghong.song@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Refactor test cases by extracting helper functions for reuse in future tests without changing functionality.,"selftests, refactor, helper",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
1f3e2091d25b2b140967480177fcaee2f0eebfb1,1f3e2091d25b2b140967480177fcaee2f0eebfb1,Yonghong Song,yonghong.song@linux.dev,1712723737,Alexei Starovoitov,ast@kernel.org,1712803945,9619179c3efcd122f536db43153b47fc5b03356b,849989af61added13b2a9005608b1cf46f36f88b,"bpftool: Add link dump support for BPF_LINK_TYPE_SOCKMAP

An example output looks like:
  $ bpftool link
    1776: sk_skb  prog 49730
            map_id 0  attach_type sk_skb_verdict
            pids test_progs(8424)
    1777: sk_skb  prog 49755
            map_id 0  attach_type sk_skb_stream_verdict
            pids test_progs(8424)
    1778: sk_msg  prog 49770
            map_id 8208  attach_type sk_msg_verdict
            pids test_progs(8424)

Reviewed-by: John Fastabend <john.fastabend@gmail.com>
Reviewed-by: Quentin Monnet <qmo@kernel.org>
Signed-off-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20240410043537.3737928-1-yonghong.song@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,This commit adds support for link dumping of BPF_LINK_TYPE_SOCKMAP to bpftool.,"bpftool, link dump, SOCKMAP",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The bpftool utility,"['socket like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
849989af61added13b2a9005608b1cf46f36f88b,849989af61added13b2a9005608b1cf46f36f88b,Yonghong Song,yonghong.song@linux.dev,1712723732,Alexei Starovoitov,ast@kernel.org,1712803945,23f4a8da6a053d120de73ac37f996fd3ac23d5b7,699c23f02c65cbfc3e638f14ce0d70c23a2e1f02,"libbpf: Add bpf_link support for BPF_PROG_TYPE_SOCKMAP

Introduce a libbpf API function bpf_program__attach_sockmap()
which allow user to get a bpf_link for their corresponding programs.

Acked-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Reviewed-by: John Fastabend <john.fastabend@gmail.com>
Signed-off-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20240410043532.3737722-1-yonghong.song@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Introduces a new libbpf API function to attach BPF_PROG_TYPE_SOCKMAP using bpf_link.,"bpf_link, sockmap, libbpf",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,['socket like programs']
699c23f02c65cbfc3e638f14ce0d70c23a2e1f02,699c23f02c65cbfc3e638f14ce0d70c23a2e1f02,Yonghong Song,yonghong.song@linux.dev,1712723727,Alexei Starovoitov,ast@kernel.org,1712803945,070b277b3ca08c33c240a73d794ce2226dd6a719,d0a2ba197bcbeaa795c5c961d927bcaf55964669,"bpf: Add bpf_link support for sk_msg and sk_skb progs

Add bpf_link support for sk_msg and sk_skb programs. We have an
internal request to support bpf_link for sk_msg programs so user
space can have a uniform handling with bpf_link based libbpf
APIs. Using bpf_link based libbpf API also has a benefit which
makes system robust by decoupling prog life cycle and
attachment life cycle.

Reviewed-by: John Fastabend <john.fastabend@gmail.com>
Signed-off-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20240410043527.3737160-1-yonghong.song@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add bpf_link support for sk_msg and sk_skb programs to enhance robustness and uniform handling with libbpf APIs.,"bpf_link, sk_msg, sk_skb",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['socket like programs']
414e576fb08f108b061cbc1fb964e51ff3467985,414e576fb08f108b061cbc1fb964e51ff3467985,Jakub Kicinski,kuba@kernel.org,1712782994,Jakub Kicinski,kuba@kernel.org,1712782994,899e0e02adfddd8a8072e782c2a1c4e3dc7887b4,2ecd487b670fcbb1ad4893fff1af4aafdecb6023 6ce2b689932ba8288ceef9a82c1caf029b0b23f9,"Merge branch 'selftests-move-bpf-offload-test-from-bpf-to-net'

Jakub Kicinski says:

====================
selftests: move bpf-offload test from bpf to net

The test_offload.py test fits in networking and bpf equally
well. We started adding more Python tests in networking
and some of the code in test_offload.py can be reused","
so move it to networking. Looks like it bit rotted over
time and some fixes are needed.

Admittedly more code could be extracted but I only had
the time for a minor cleanup :(
====================

Link: https://lore.kernel.org/r/20240409031549.3531084-1-kuba@kernel.org
Signed-off-by: Jakub Kicinski <kuba@kernel.org>
",[''],Move bpf-offload test from bpf to networking for better code reuse and minor cleanup.,"bpf-offload, test, networking",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6ce2b689932ba8288ceef9a82c1caf029b0b23f9,6ce2b689932ba8288ceef9a82c1caf029b0b23f9,Jakub Kicinski,kuba@kernel.org,1712632549,Jakub Kicinski,kuba@kernel.org,1712782992,899e0e02adfddd8a8072e782c2a1c4e3dc7887b4,b1c2ce11d42886d08cfa28e38ee07f2b606ced0b,"selftests: net: reuse common code in bpf_offload

net/lib/py/nsim.py already contains the most useful parts
of the netdevsim wrapper classes. Reuse them.

Acked-by: Stanislav Fomichev <sdf@google.com>
Acked-by: Martin KaFai Lau <martin.lau@kernel.org>
Link: https://lore.kernel.org/r/20240409031549.3531084-5-kuba@kernel.org
Signed-off-by: Jakub Kicinski <kuba@kernel.org>
",,Refactor bpf_offload self-tests to reuse existing code from netdevsim wrapper classes.,"selftests, bpf_offload, netdevsim",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
b1c2ce11d42886d08cfa28e38ee07f2b606ced0b,b1c2ce11d42886d08cfa28e38ee07f2b606ced0b,Jakub Kicinski,kuba@kernel.org,1712632548,Jakub Kicinski,kuba@kernel.org,1712782992,9ef005b821557497573639effbb565b93958d101,fc50c698c28bcf307dfb14ba9d0b3cacb091c1cb,"selftests: net: declare section names for bpf_offload

Non-ancient ip (iproute2-5.15.0"," libbpf 0.7.0) refuses to load
the sample with maps because we don't generate BTF:

   libbpf: BTF is required","["" but is missing or corrupted.\n   ERROR: opening BPF object file failed\n\nEnable BTF by adding -g to clang flags. With that done\nneither of the programs load:\n\n  libbpf: prog 'func': error relocating .BTF.ext function info: -22\n  libbpf: prog 'func': failed to relocate calls: -22\n  libbpf: failed to load object 'ksft-net-drv/net/sample_ret0.bpf.o'\n\nAndrii explains that this is because we don't specify\nsection names for the code. Add the section names"", ' too.\n\nAcked-by: Alexei Starovoitov <ast@kernel.org>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nAcked-by: Martin KaFai Lau <martin.lau@kernel.org>\nLink: https://lore.kernel.org/r/20240409031549.3531084-4-kuba@kernel.org\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Declare section names for bpf_offload in selftests to ensure compatibility with newer iproute2 versions requiring BTF.,"selftests, bpf_offload, BTF",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fc50c698c28bcf307dfb14ba9d0b3cacb091c1cb,fc50c698c28bcf307dfb14ba9d0b3cacb091c1cb,Jakub Kicinski,kuba@kernel.org,1712632547,Jakub Kicinski,kuba@kernel.org,1712782992,3199f053af40b837c209b866d3777831b475ce62,e59f0e93e92e0ddfd17e3373d586218cf638571e,"selftests: net: bpf_offload: wait for maps

Maps are removed asynchronously. Either there's a bigger delay
now or the test has always been flaky. Retry waiting in the loop.

Acked-by: Stanislav Fomichev <sdf@google.com>
Acked-by: Martin KaFai Lau <martin.lau@kernel.org>
Link: https://lore.kernel.org/r/20240409031549.3531084-3-kuba@kernel.org
Signed-off-by: Jakub Kicinski <kuba@kernel.org>
",,This commit modifies self-tests to add a wait loop for map removals due to asynchronous behavior.,"selftests, maps, asynchronous",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e59f0e93e92e0ddfd17e3373d586218cf638571e,e59f0e93e92e0ddfd17e3373d586218cf638571e,Jakub Kicinski,kuba@kernel.org,1712632546,Jakub Kicinski,kuba@kernel.org,1712782992,4d58b8dd5199a67c1d9d23c841e00c41f2b28e60,2ecd487b670fcbb1ad4893fff1af4aafdecb6023,"selftests: move bpf-offload test from bpf to net

We're building more python tests on the netdev side"," and some
of the classes from the venerable BPF offload tests can be reused.

Acked-by: Stanislav Fomichev <sdf@google.com>
Acked-by: Martin KaFai Lau <martin.lau@kernel.org>
Link: https://lore.kernel.org/r/20240409031549.3531084-2-kuba@kernel.org
Signed-off-by: Jakub Kicinski <kuba@kernel.org>
",[''],This commit moves the bpf-offload test from bpf to net for improved reusability.,"selftests,bpf-offload,net",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
685dadafbde29dc3d6b7a13be284d684b06d4d4f,685dadafbde29dc3d6b7a13be284d684b06d4d4f,Benjamin Tissoires,bentiss@kernel.org,1710513884,Benjamin Tissoires,bentiss@kernel.org,1712759917,a3c3ea15f7998a7c241e8d8a8561e94f4e9a52bf,2c0e8ced7d4bf746923fc424415844d695f07808,"HID: bpf: allow to use bpf_timer_set_sleepable_cb() in tracing callbacks.

Export the sleepable kfuncs we have on HID-BPF in tracing bpf programs","
but with the condition of being used in a sleepable context.
This allows to use the bpf_timer when used in a sleepable context
through bpf_timer_set_sleepable_cb() and initiate work from a device event.

Link: https://lore.kernel.org/r/20240315-b4-hid-bpf-new-funcs-v4-7-079c282469d3@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Enable use of bpf_timer_set_sleepable_cb() in HID tracing bpf programs for sleepable contexts.,"HID,BPF,sleepable",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['HID driver like programs']
2c0e8ced7d4bf746923fc424415844d695f07808,2c0e8ced7d4bf746923fc424415844d695f07808,Benjamin Tissoires,bentiss@kernel.org,1710513883,Benjamin Tissoires,bentiss@kernel.org,1712759917,1f66356c79242fa9b030d75c07f754e765b107bd,9be50ac30a83896a753ab9f64e941763bb7900be,"selftests/hid: add tests for hid_bpf_input_report

Usual way of testing"," we call the function and ensures we receive
the event

Link: https://lore.kernel.org/r/20240315-b4-hid-bpf-new-funcs-v4-6-079c282469d3@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Add self-tests for the hid_bpf_input_report function in HID driver.,"selftests,hid_bpf_input_report,HID",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['HID driver like programs']
9be50ac30a83896a753ab9f64e941763bb7900be,9be50ac30a83896a753ab9f64e941763bb7900be,Benjamin Tissoires,bentiss@kernel.org,1710513882,Benjamin Tissoires,bentiss@kernel.org,1712759891,be748108a980cf8f48685694d8b3ffee573c6ee5,db624e82c55f227b84ac9ebfa3de2f6f5fad666b,"HID: bpf: allow to inject HID event from BPF

It can be interesting to inject events from BPF as if the event were
to come from the device.
For example"," some multitouch devices do not all the time send a proximity
out event","[' and we might want to send it for the physical device.\n\nCompared to uhid', ' we can now inject events on any physical device', ' not\njust uhid virtual ones.\n\nLink: https://lore.kernel.org/r/20240315-b4-hid-bpf-new-funcs-v4-5-079c282469d3@kernel.org\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']","Introduces the capability to inject HID events from eBPF, simulating device-originated events.","HID,BPF,event",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['HID driver like programs']
db624e82c55f227b84ac9ebfa3de2f6f5fad666b,db624e82c55f227b84ac9ebfa3de2f6f5fad666b,Benjamin Tissoires,bentiss@kernel.org,1710513881,Benjamin Tissoires,bentiss@kernel.org,1712759843,1438da0dcbf4dd544aff72be81546e32a51d6257,c8a1495947ffcab18d9a85144ab4abc570720e65,"selftests/hid: Add test for hid_bpf_hw_output_report

This time we need to ensure uhid receives it"," thus the new mutex and
condition.

Link: https://lore.kernel.org/r/20240315-b4-hid-bpf-new-funcs-v4-4-079c282469d3@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Added a selftest for HID to ensure uhid receives hid_bpf_hw_output_report correctly.,"selftests,HID,uhid",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['HID driver like programs']
c8a1495947ffcab18d9a85144ab4abc570720e65,c8a1495947ffcab18d9a85144ab4abc570720e65,Benjamin Tissoires,bentiss@kernel.org,1710513880,Benjamin Tissoires,bentiss@kernel.org,1712759843,9040a86ccf2218135cf1b7ff1001c373ad7eac2e,5599f80196612efde96dbe6ef18f6ecc0cb4ba19,"selftests/hid: add KASAN to the VM tests

It's always a good idea to have KASAN in tests.

Link: https://lore.kernel.org/r/20240315-b4-hid-bpf-new-funcs-v4-3-079c282469d3@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",,The commit adds KASAN to the selftests for HID drivers in virtual machines.,"KASAN,selftests,HID",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['HID driver like programs']
5599f80196612efde96dbe6ef18f6ecc0cb4ba19,5599f80196612efde96dbe6ef18f6ecc0cb4ba19,Benjamin Tissoires,bentiss@kernel.org,1710513879,Benjamin Tissoires,bentiss@kernel.org,1712759834,0176fb7c39f14a4f325742deec12adcbf4c38892,4171954f56fb6da8cc8ceebf54b78b874278a198,"HID: bpf: export hid_hw_output_report as a BPF kfunc

We currently only export hid_hw_raw_request() as a BPF kfunc.
However"," some devices require an explicit write on the Output Report
instead of the use of the control channel.

So also export hid_hw_output_report to BPF

Link: https://lore.kernel.org/r/20240315-b4-hid-bpf-new-funcs-v4-2-079c282469d3@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Export hid_hw_output_report as a BPF kfunc for HID support in eBPF.,"HID,BPF,kfunc",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['HID driver like programs']
4171954f56fb6da8cc8ceebf54b78b874278a198,4171954f56fb6da8cc8ceebf54b78b874278a198,Benjamin Tissoires,bentiss@kernel.org,1710513878,Benjamin Tissoires,bentiss@kernel.org,1712759725,337e7414ac51e42285843dd0d70727116d3d0ba8,3e78a6c0d3e02e4cf881dc84c5127e9990f939d6,"HID: bpf/dispatch: regroup kfuncs definitions

No code change"," just move down the hid_bpf_get_data() kfunc definition
so we have only one block of __bpf_kfunc_start/end_defs()

Link: https://lore.kernel.org/r/20240315-b4-hid-bpf-new-funcs-v4-1-079c282469d3@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],The commit reorganizes HID BPF kfuncs definitions for cleaner code structure.,"HID,bpf,kfuncs",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,['HID driver like programs']
d0a2ba197bcbeaa795c5c961d927bcaf55964669,d0a2ba197bcbeaa795c5c961d927bcaf55964669,Alexei Starovoitov,ast@kernel.org,1712358694,Martin KaFai Lau,martin.lau@kernel.org,1712683466,e533f9b8283c71b56ea7aaa3ae83c2620d28d788,d503a04f8bc0c75dc9db9452d8cc79d748afb752,"selftests/bpf: Add tests for atomics in bpf_arena.

Add selftests for atomic instructions in bpf_arena.

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20240405231134.17274-2-alexei.starovoitov@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Add selftests for atomic instructions used within bpf_arena.,"selftests, atomics, bpf_arena",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d503a04f8bc0c75dc9db9452d8cc79d748afb752,d503a04f8bc0c75dc9db9452d8cc79d748afb752,Alexei Starovoitov,ast@kernel.org,1712358693,Martin KaFai Lau,martin.lau@kernel.org,1712683466,54f3e9a2c1954e9e916989a454233fe56ce5ba25,bb761fcb821738e8d3b720e1460d3783db74c68a,"bpf: Add support for certain atomics in bpf_arena to x86 JIT

Support atomics in bpf_arena that can be JITed as a single x86 instruction.
Instructions that are JITed as loops are not supported at the moment","
since they require more complex extable and loop logic.

JITs can choose to do smarter things with bpf_jit_supports_insn().
Like arm64 may decide to support all bpf atomics instructions
when emit_lse_atomic is available and none in ll_sc mode.

bpf_jit_supports_percpu_insn()","[' bpf_jit_supports_ptr_xchg() and\nother such callbacks can be replaced with bpf_jit_supports_insn()\nin the future.\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20240405231134.17274-1-alexei.starovoitov@gmail.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Add support for atomics in bpf_arena to x86 JIT for single instruction execution.,"atomics,JIT,bpf_arena",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b993115b44d769cb34b394d92658226df81a6c89,b993115b44d769cb34b394d92658226df81a6c89,Paul E. McKenney,paulmck@kernel.org,1708625777,Uladzislau Rezki (Sony),urezki@gmail.com,1712668385,d409e95f06f10e64cb436db1ba36bccab73ca5f2,179f4ce102eb62b4b8efbd8371ee7d25c1082467,"bpf: Select new NEED_TASKS_RCU Kconfig option

Currently", if a Kconfig option depends on TASKS_RCU,"[' it conditionally does\n""select TASKS_RCU if PREEMPTION"".  This works', ' but requires any change in\nthis enablement logic to be replicated across all such ""select"" clauses.\nA new NEED_TASKS_RCU Kconfig option has been created to allow this\nenablement logic to be in one place in kernel/rcu/Kconfig.\n\nTherefore', ' make BPF select the new NEED_TASKS_RCU Kconfig option.\n\nSigned-off-by: Paul E. McKenney <paulmck@kernel.org>\nCc: Alexei Starovoitov <ast@kernel.org>\nCc: Daniel Borkmann <daniel@iogearbox.net>\nCc: Andrii Nakryiko <andrii@kernel.org>\nCc: Martin KaFai Lau <martin.lau@linux.dev>\nCc: Song Liu <song@kernel.org>\nCc: Yonghong Song <yonghong.song@linux.dev>\nCc: John Fastabend <john.fastabend@gmail.com>\nCc: KP Singh <kpsingh@kernel.org>\nCc: Stanislav Fomichev <sdf@google.com>\nCc: Hao Luo <haoluo@google.com>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: <bpf@vger.kernel.org>\nCc: Ankur Arora <ankur.a.arora@oracle.com>\nCc: Thomas Gleixner <tglx@linutronix.de>\nCc: Steven Rostedt <rostedt@goodmis.org>\nAcked-by: Mark Rutland <mark.rutland@arm.com>\nSigned-off-by: Uladzislau Rezki (Sony) <urezki@gmail.com>\n', '']",The commit selects the new Kconfig option NEED_TASKS_RCU for bpf.,"Kconfig, NEED_TASKS_RCU, bpf",It's a build system or CI/CD change.,"Simple, can be used without much configuration. For example, a simple helper function.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
bb761fcb821738e8d3b720e1460d3783db74c68a,bb761fcb821738e8d3b720e1460d3783db74c68a,Jason Xing,kernelxing@tencent.com,1712414773,Martin KaFai Lau,martin.lau@kernel.org,1712619078,0e5f7a99764b05e0ef868abce7a5f4889480abcd,50408d7abea68e2d1ae3a9328e1a468b7089b11c,"selftests/bpf: eliminate warning of get_cgroup_id_from_path()

The output goes like this if I make samples/bpf:
...warning: no previous prototype for ‘get_cgroup_id_from_path’...

Make this function static could solve the warning problem since
no one outside of the file calls it.

Signed-off-by: Jason Xing <kernelxing@tencent.com>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20240406144613.4434-1-kerneljasonxing@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,The commit eliminates a prototype warning by making get_cgroup_id_from_path static in selftests/bpf.,"selftests,bpf,warning",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['cgroup like programs']
6648e613226e18897231ab5e42ffc29e63fa3365,6648e613226e18897231ab5e42ffc29e63fa3365,Jason Xing,kernelxing@tencent.com,1712196601,Daniel Borkmann,daniel@iogearbox.net,1712560702,dc6a8373e176b33f6d3678272bd30a10293cc6ff,76cd338994778c552c51086fc056819b5cdda2e7,bpf," skmsg: Fix NULL pointer dereference in sk_psock_skb_ingress_enqueue

Fix NULL pointer data-races in sk_psock_skb_ingress_enqueue() which
syzbot reported [1].

[1]
BUG: KCSAN: data-race in sk_psock_drop / sk_psock_skb_ingress_enqueue

write to 0xffff88814b3278b8 of 8 bytes by task 10724 on cpu 1:
 sk_psock_stop_verdict net/core/skmsg.c:1257 [inline]
 sk_psock_drop+0x13e/0x1f0 net/core/skmsg.c:843
 sk_psock_put include/linux/skmsg.h:459 [inline]
 sock_map_close+0x1a7/0x260 net/core/sock_map.c:1648
 unix_release+0x4b/0x80 net/unix/af_unix.c:1048
 __sock_release net/socket.c:659 [inline]
 sock_close+0x68/0x150 net/socket.c:1421
 __fput+0x2c1/0x660 fs/file_table.c:422
 __fput_sync+0x44/0x60 fs/file_table.c:507
 __do_sys_close fs/open.c:1556 [inline]
 __se_sys_close+0x101/0x1b0 fs/open.c:1541
 __x64_sys_close+0x1f/0x30 fs/open.c:1541
 do_syscall_64+0xd3/0x1d0
 entry_SYSCALL_64_after_hwframe+0x6d/0x75

read to 0xffff88814b3278b8 of 8 bytes by task 10713 on cpu 0:
 sk_psock_data_ready include/linux/skmsg.h:464 [inline]
 sk_psock_skb_ingress_enqueue+0x32d/0x390 net/core/skmsg.c:555
 sk_psock_skb_ingress_self+0x185/0x1e0 net/core/skmsg.c:606
 sk_psock_verdict_apply net/core/skmsg.c:1008 [inline]
 sk_psock_verdict_recv+0x3e4/0x4a0 net/core/skmsg.c:1202
 unix_read_skb net/unix/af_unix.c:2546 [inline]
 unix_stream_read_skb+0x9e/0xf0 net/unix/af_unix.c:2682
 sk_psock_verdict_data_ready+0x77/0x220 net/core/skmsg.c:1223
 unix_stream_sendmsg+0x527/0x860 net/unix/af_unix.c:2339
 sock_sendmsg_nosec net/socket.c:730 [inline]
 __sock_sendmsg+0x140/0x180 net/socket.c:745
 ____sys_sendmsg+0x312/0x410 net/socket.c:2584
 ___sys_sendmsg net/socket.c:2638 [inline]
 __sys_sendmsg+0x1e9/0x280 net/socket.c:2667
 __do_sys_sendmsg net/socket.c:2676 [inline]
 __se_sys_sendmsg net/socket.c:2674 [inline]
 __x64_sys_sendmsg+0x46/0x50 net/socket.c:2674
 do_syscall_64+0xd3/0x1d0
 entry_SYSCALL_64_after_hwframe+0x6d/0x75

value changed: 0xffffffff83d7feb0 -> 0x0000000000000000

Reported by Kernel Concurrency Sanitizer on:
CPU: 0 PID: 10713 Comm: syz-executor.4 Tainted: G        W          6.8.0-syzkaller-08951-gfe46a7dd189e #0
Hardware name: Google Google Compute Engine/Google Compute Engine","[' BIOS Google 02/29/2024\n\nPrior to this', ' commit 4cd12c6065df (""bpf', ' sockmap: Fix NULL pointer\ndereference in sk_psock_verdict_data_ready()"") fixed one NULL pointer\nsimilarly due to no protection of saved_data_ready. Here is another\ndifferent caller causing the same issue because of the same reason. So\nwe should protect it with sk_callback_lock read lock because the writer\nside in the sk_psock_drop() uses ""write_lock_bh(&sk->sk_callback_lock);"".\n\nTo avoid errors that could happen in future', ' I move those two pairs of\nlock into the sk_psock_data_ready()', ' which is suggested by John Fastabend.\n\nFixes: 604326b41a6f (""bpf', ' sockmap: convert to generic sk_msg interface"")\nReported-by: syzbot+aa8c8ec2538929f18f2d@syzkaller.appspotmail.com\nSigned-off-by: Jason Xing <kernelxing@tencent.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: John Fastabend <john.fastabend@gmail.com>\nCloses: https://syzkaller.appspot.com/bug?extid=aa8c8ec2538929f18f2d\nLink: https://lore.kernel.org/all/20240329134037.92124-1-kerneljasonxing@gmail.com\nLink: https://lore.kernel.org/bpf/20240404021001.94815-1-kerneljasonxing@gmail.com\n', '']",Fixes data-race issues in sk_psock_skb_ingress_enqueue function to prevent NULL pointer dereference.,"data-race,NULL pointer,sk_psock",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['socket like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
50408d7abea68e2d1ae3a9328e1a468b7089b11c,50408d7abea68e2d1ae3a9328e1a468b7089b11c,Andrii Nakryiko,andrii@kernel.org,1712419871,Andrii Nakryiko,andrii@kernel.org,1712423795,be1f6764f6ef5a655bb0d2e5d60bf7c99659a9ae,d564ffde5c832c46513e0189647abfde9833e590 4d22ea94ea33550538b3b14429d52cb9f96ad2c3,"Merge branch 'libbpf-api-to-partially-consume-items-from-ringbuffer'

Andrea Righi says:

====================
libbpf: API to partially consume items from ringbuffer

Introduce ring__consume_n() and ring_buffer__consume_n() API to
partially consume items from one (or more) ringbuffer(s).

This can be useful", for example,"["" to consume just a single item or when\nwe need to copy multiple items to a limited user-space buffer from the\nringbuffer callback.\n\nPractical example (where this API can be used):\nhttps://github.com/sched-ext/scx/blob/b7c06b9ed9f72cad83c31e39e9c4e2cfd8683a55/rust/scx_rustland_core/src/bpf.rs#L217\n\nSee also:\nhttps://lore.kernel.org/lkml/20240310154726.734289-1-andrea.righi@canonical.com/T/#u\n\nv4:\n - open a new 1.5.0 cycle\n\nv3:\n - rename ring__consume_max() -> ring__consume_n() and\n   ring_buffer__consume_max() -> ring_buffer__consume_n()\n - add new API to a new 1.5.0 cycle\n - fixed minor nits / comments\n\nv2:\n - introduce a new API instead of changing the callback's retcode\n   behavior\n====================\n\nLink: https://lore.kernel.org/r/20240406092005.92399-1-andrea.righi@canonical.com\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n"", '']",Introduce API to partially consume items from ringbuffer in libbpf.,"libbpf, API, ringbuffer",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4d22ea94ea33550538b3b14429d52cb9f96ad2c3,4d22ea94ea33550538b3b14429d52cb9f96ad2c3,Andrea Righi,andrea.righi@canonical.com,1712394943,Andrii Nakryiko,andrii@kernel.org,1712419915,be1f6764f6ef5a655bb0d2e5d60bf7c99659a9ae,13e8125a22763557d719db996f70c71f77c9509c,"libbpf: Add ring__consume_n / ring_buffer__consume_n

Introduce a new API to consume items from a ring buffer"," limited to a
specified amount","[' and return to the caller the actual number of items\nconsumed.\n\nSigned-off-by: Andrea Righi <andrea.righi@canonical.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/lkml/20240310154726.734289-1-andrea.righi@canonical.com/T\nLink: https://lore.kernel.org/bpf/20240406092005.92399-4-andrea.righi@canonical.com\n', '']",Introduces a new API to consume multiple items from a ring buffer in libbpf.,"libbpf,ring buffer,API",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['tracepoints like programs', 'kprobe/uprobe/ftrace like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
13e8125a22763557d719db996f70c71f77c9509c,13e8125a22763557d719db996f70c71f77c9509c,Andrea Righi,andrea.righi@canonical.com,1712394942,Andrii Nakryiko,andrii@kernel.org,1712419914,55cc123f3de1470b1741461a5812b14dba737031,5bd2ed658231b0698211e94efb06393836a4539d,"libbpf: ringbuf: Allow to consume up to a certain amount of items

In some cases"," instead of always consuming all items from ring buffers
in a greedy way","[' we may want to consume up to a certain amount of items', '\nfor example when we need to copy items from the BPF ring buffer to a\nlimited user buffer.\n\nThis change allows to set an upper limit to the amount of items consumed\nfrom one or more ring buffers.\n\nSigned-off-by: Andrea Righi <andrea.righi@canonical.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240406092005.92399-3-andrea.righi@canonical.com\n', '']",The commit adds an option to consume a specific number of items from libbpf ring buffers instead of all.,"libbpf, ringbuf, consume",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5bd2ed658231b0698211e94efb06393836a4539d,5bd2ed658231b0698211e94efb06393836a4539d,Andrea Righi,andrea.righi@canonical.com,1712394941,Andrii Nakryiko,andrii@kernel.org,1712419870,ee106da1a8ead37abe175b28b0cf64d9db2d7067,d564ffde5c832c46513e0189647abfde9833e590,"libbpf: Start v1.5 development cycle

Bump libbpf.map to v1.5.0 to start a new libbpf version cycle.

Signed-off-by: Andrea Righi <andrea.righi@canonical.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240406092005.92399-2-andrea.righi@canonical.com
",,Bump libbpf.map to v1.5.0 to initiate the new development cycle for libbpf.,libbpf development cycle,It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
237f3cf13b20db183d3706d997eedc3c49eacd44,237f3cf13b20db183d3706d997eedc3c49eacd44,Eric Dumazet,edumazet@google.com,1712262458,Jakub Kicinski,kuba@kernel.org,1712382442,9ae99305c845c825f78e992d069b908033897b22,38a15d0a50e0a43778561a5861403851f0b0194c,"xsk: validate user input for XDP_{UMEM|COMPLETION}_FILL_RING

syzbot reported an illegal copy in xsk_setsockopt() [1]

Make sure to validate setsockopt() @optlen parameter.

[1]

 BUG: KASAN: slab-out-of-bounds in copy_from_sockptr_offset include/linux/sockptr.h:49 [inline]
 BUG: KASAN: slab-out-of-bounds in copy_from_sockptr include/linux/sockptr.h:55 [inline]
 BUG: KASAN: slab-out-of-bounds in xsk_setsockopt+0x909/0xa40 net/xdp/xsk.c:1420
Read of size 4 at addr ffff888028c6cde3 by task syz-executor.0/7549

CPU: 0 PID: 7549 Comm: syz-executor.0 Not tainted 6.8.0-syzkaller-08951-gfe46a7dd189e #0
Hardware name: Google Google Compute Engine/Google Compute Engine"," BIOS Google 03/27/2024
Call Trace:
 <TASK>
  __dump_stack lib/dump_stack.c:88 [inline]
  dump_stack_lvl+0x241/0x360 lib/dump_stack.c:114
  print_address_description mm/kasan/report.c:377 [inline]
  print_report+0x169/0x550 mm/kasan/report.c:488
  kasan_report+0x143/0x180 mm/kasan/report.c:601
  copy_from_sockptr_offset include/linux/sockptr.h:49 [inline]
  copy_from_sockptr include/linux/sockptr.h:55 [inline]
  xsk_setsockopt+0x909/0xa40 net/xdp/xsk.c:1420
  do_sock_setsockopt+0x3af/0x720 net/socket.c:2311
  __sys_setsockopt+0x1ae/0x250 net/socket.c:2334
  __do_sys_setsockopt net/socket.c:2343 [inline]
  __se_sys_setsockopt net/socket.c:2340 [inline]
  __x64_sys_setsockopt+0xb5/0xd0 net/socket.c:2340
 do_syscall_64+0xfb/0x240
 entry_SYSCALL_64_after_hwframe+0x6d/0x75
RIP: 0033:0x7fb40587de69
Code: 28 00 00 00 75 05 48 83 c4 28 c3 e8 e1 20 00 00 90 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 73 01 c3 48 c7 c1 b0 ff ff ff f7 d8 64 89 01 48
RSP: 002b:00007fb40665a0c8 EFLAGS: 00000246 ORIG_RAX: 0000000000000036
RAX: ffffffffffffffda RBX: 00007fb4059abf80 RCX: 00007fb40587de69
RDX: 0000000000000005 RSI: 000000000000011b RDI: 0000000000000006
RBP: 00007fb4058ca47a R08: 0000000000000002 R09: 0000000000000000
R10: 0000000020001980 R11: 0000000000000246 R12: 0000000000000000
R13: 000000000000000b R14: 00007fb4059abf80 R15: 00007fff57ee4d08
 </TASK>

Allocated by task 7549:
  kasan_save_stack mm/kasan/common.c:47 [inline]
  kasan_save_track+0x3f/0x80 mm/kasan/common.c:68
  poison_kmalloc_redzone mm/kasan/common.c:370 [inline]
  __kasan_kmalloc+0x98/0xb0 mm/kasan/common.c:387
  kasan_kmalloc include/linux/kasan.h:211 [inline]
  __do_kmalloc_node mm/slub.c:3966 [inline]
  __kmalloc+0x233/0x4a0 mm/slub.c:3979
  kmalloc include/linux/slab.h:632 [inline]
  __cgroup_bpf_run_filter_setsockopt+0xd2f/0x1040 kernel/bpf/cgroup.c:1869
  do_sock_setsockopt+0x6b4/0x720 net/socket.c:2293
  __sys_setsockopt+0x1ae/0x250 net/socket.c:2334
  __do_sys_setsockopt net/socket.c:2343 [inline]
  __se_sys_setsockopt net/socket.c:2340 [inline]
  __x64_sys_setsockopt+0xb5/0xd0 net/socket.c:2340
 do_syscall_64+0xfb/0x240
 entry_SYSCALL_64_after_hwframe+0x6d/0x75

The buggy address belongs to the object at ffff888028c6cde0
 which belongs to the cache kmalloc-8 of size 8
The buggy address is located 1 bytes to the right of
 allocated 2-byte region [ffff888028c6cde0","[' ffff888028c6cde2)\n\nThe buggy address belongs to the physical page:\npage:ffffea0000a31b00 refcount:1 mapcount:0 mapping:0000000000000000 index:0xffff888028c6c9c0 pfn:0x28c6c\nanon flags: 0xfff00000000800(slab|node=0|zone=1|lastcpupid=0x7ff)\npage_type: 0xffffffff()\nraw: 00fff00000000800 ffff888014c41280 0000000000000000 dead000000000001\nraw: ffff888028c6c9c0 0000000080800057 00000001ffffffff 0000000000000000\npage dumped because: kasan: bad access detected\npage_owner tracks the page as allocated\npage last allocated via order 0', ' migratetype Unmovable', ' gfp_mask 0x112cc0(GFP_USER|__GFP_NOWARN|__GFP_NORETRY)', ' pid 6648', ' tgid 6644 (syz-executor.0)', ' ts 133906047828', ' free_ts 133859922223\n  set_page_owner include/linux/page_owner.h:31 [inline]\n  post_alloc_hook+0x1ea/0x210 mm/page_alloc.c:1533\n  prep_new_page mm/page_alloc.c:1540 [inline]\n  get_page_from_freelist+0x33ea/0x3580 mm/page_alloc.c:3311\n  __alloc_pages+0x256/0x680 mm/page_alloc.c:4569\n  __alloc_pages_node include/linux/gfp.h:238 [inline]\n  alloc_pages_node include/linux/gfp.h:261 [inline]\n  alloc_slab_page+0x5f/0x160 mm/slub.c:2175\n  allocate_slab mm/slub.c:2338 [inline]\n  new_slab+0x84/0x2f0 mm/slub.c:2391\n  ___slab_alloc+0xc73/0x1260 mm/slub.c:3525\n  __slab_alloc mm/slub.c:3610 [inline]\n  __slab_alloc_node mm/slub.c:3663 [inline]\n  slab_alloc_node mm/slub.c:3835 [inline]\n  __do_kmalloc_node mm/slub.c:3965 [inline]\n  __kmalloc_node+0x2db/0x4e0 mm/slub.c:3973\n  kmalloc_node include/linux/slab.h:648 [inline]\n  __vmalloc_area_node mm/vmalloc.c:3197 [inline]\n  __vmalloc_node_range+0x5f9/0x14a0 mm/vmalloc.c:3392\n  __vmalloc_node mm/vmalloc.c:3457 [inline]\n  vzalloc+0x79/0x90 mm/vmalloc.c:3530\n  bpf_check+0x260/0x19010 kernel/bpf/verifier.c:21162\n  bpf_prog_load+0x1667/0x20f0 kernel/bpf/syscall.c:2895\n  __sys_bpf+0x4ee/0x810 kernel/bpf/syscall.c:5631\n  __do_sys_bpf kernel/bpf/syscall.c:5738 [inline]\n  __se_sys_bpf kernel/bpf/syscall.c:5736 [inline]\n  __x64_sys_bpf+0x7c/0x90 kernel/bpf/syscall.c:5736\n do_syscall_64+0xfb/0x240\n entry_SYSCALL_64_after_hwframe+0x6d/0x75\npage last free pid 6650 tgid 6647 stack trace:\n  reset_page_owner include/linux/page_owner.h:24 [inline]\n  free_pages_prepare mm/page_alloc.c:1140 [inline]\n  free_unref_page_prepare+0x95d/0xa80 mm/page_alloc.c:2346\n  free_unref_page_list+0x5a3/0x850 mm/page_alloc.c:2532\n  release_pages+0x2117/0x2400 mm/swap.c:1042\n  tlb_batch_pages_flush mm/mmu_gather.c:98 [inline]\n  tlb_flush_mmu_free mm/mmu_gather.c:293 [inline]\n  tlb_flush_mmu+0x34d/0x4e0 mm/mmu_gather.c:300\n  tlb_finish_mmu+0xd4/0x200 mm/mmu_gather.c:392\n  exit_mmap+0x4b6/0xd40 mm/mmap.c:3300\n  __mmput+0x115/0x3c0 kernel/fork.c:1345\n  exit_mm+0x220/0x310 kernel/exit.c:569\n  do_exit+0x99e/0x27e0 kernel/exit.c:865\n  do_group_exit+0x207/0x2c0 kernel/exit.c:1027\n  get_signal+0x176e/0x1850 kernel/signal.c:2907\n  arch_do_signal_or_restart+0x96/0x860 arch/x86/kernel/signal.c:310\n  exit_to_user_mode_loop kernel/entry/common.c:105 [inline]\n  exit_to_user_mode_prepare include/linux/entry-common.h:328 [inline]\n  __syscall_exit_to_user_mode_work kernel/entry/common.c:201 [inline]\n  syscall_exit_to_user_mode+0xc9/0x360 kernel/entry/common.c:212\n  do_syscall_64+0x10a/0x240 arch/x86/entry/common.c:89\n entry_SYSCALL_64_after_hwframe+0x6d/0x75\n\nMemory state around the buggy address:\n ffff888028c6cc80: fa fc fc fc fa fc fc fc fa fc fc fc fa fc fc fc\n ffff888028c6cd00: fa fc fc fc fa fc fc fc 00 fc fc fc 06 fc fc fc\n>ffff888028c6cd80: fa fc fc fc fa fc fc fc fa fc fc fc 02 fc fc fc\n                                                       ^\n ffff888028c6ce00: fa fc fc fc fa fc fc fc fa fc fc fc fa fc fc fc\n ffff888028c6ce80: fa fc fc fc fa fc fc fc fa fc fc fc fa fc fc fc\n\nFixes: 423f38329d26 (""xsk: add umem fill queue support and mmap"")\nReported-by: syzbot <syzkaller@googlegroups.com>\nSigned-off-by: Eric Dumazet <edumazet@google.com>\nCc: ""Björn Töpel"" <bjorn@kernel.org>\nCc: Magnus Karlsson <magnus.karlsson@intel.com>\nCc: Maciej Fijalkowski <maciej.fijalkowski@intel.com>\nCc: Jonathan Lemon <jonathan.lemon@gmail.com>\nAcked-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/r/20240404202738.3634547-1-edumazet@google.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",The commit fixes a bug by validating the optlen parameter in xsk_setsockopt to prevent slab-out-of-bounds errors.,"validation, bugfix, xsk_setsockopt",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The syscall interface,['xdp like programs']
d564ffde5c832c46513e0189647abfde9833e590,d564ffde5c832c46513e0189647abfde9833e590,Andrii Nakryiko,andrii@kernel.org,1712339769,Andrii Nakryiko,andrii@kernel.org,1712339944,654f4867da71174bdb8586e55af19feae16fd6f8,00d5d22a5b42c3ffdfd1b29526885bbcec2d2231 1bc724af00cc48ef03e3fa6d7a2f6731ac915c37,"Merge branch 'bpf-allow-invoking-kfuncs-from-bpf_prog_type_syscall-progs'

David Vernet says:

====================
bpf: Allow invoking kfuncs from BPF_PROG_TYPE_SYSCALL progs

Currently", a set of core BPF kfuncs (e.g. bpf_task_*,"[' bpf_cgroup_*', '\nbpf_cpumask_*', ' etc) cannot be invoked from BPF_PROG_TYPE_SYSCALL\nprograms. The whitelist approach taken for enabling kfuncs makes sense:\nit not safe to call these kfuncs from every program type. For example', '\nit may not be safe to call bpf_task_acquire() in an fentry to\nfree_task().\n\nBPF_PROG_TYPE_SYSCALL', ' on the other hand', ' is a perfectly safe program\ntype from which to invoke these kfuncs', "" as it's a very controlled\nenvironment"", ' and we should never be able to run into any of the typical\nproblems such as recursive invoations', ' acquiring references on freeing\nkptrs', ' etc. Being able to invoke these kfuncs would be useful', ' as\nBPF_PROG_TYPE_SYSCALL can be invoked with BPF_PROG_RUN', ' and would\ntherefore enable user space programs to synchronously call into BPF to\nmanipulate these kptrs.\n---\n\nv1: https://lore.kernel.org/all/20240404010308.334604-1-void@manifault.com/\nv1 -> v2:\n\n- Create new verifier_kfunc_prog_types testcase meant to specifically\n  validate calling core kfuncs from various program types. Remove the\n  macros and testcases that had been added to the task', ' cgrp', ' and\n  cpumask kfunc testcases (Andrii and Yonghong)\n====================\n\nLink: https://lore.kernel.org/r/20240405143041.632519-1-void@manifault.com\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n', '']",The commit enables invoking kfuncs from BPF_PROG_TYPE_SYSCALL programs.,"kfuncs,BPF_PROG_TYPE_SYSCALL,invoke",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"[""It's not related to any of the above.""]"
1bc724af00cc48ef03e3fa6d7a2f6731ac915c37,1bc724af00cc48ef03e3fa6d7a2f6731ac915c37,David Vernet,void@manifault.com,1712327441,Andrii Nakryiko,andrii@kernel.org,1712339890,654f4867da71174bdb8586e55af19feae16fd6f8,a8e03b6bbb2cc7cf387d1ce335e4ce4c3bdfef9b,"selftests/bpf: Verify calling core kfuncs from BPF_PROG_TYPE_SYCALL

Now that we can call some kfuncs from BPF_PROG_TYPE_SYSCALL progs"," let's
add some selftests that verify as much. As a bonus","["" let's also verify\nthat we can't call the progs from raw tracepoints. Do do this"", ' we add a\nnew selftest suite called verifier_kfunc_prog_types.\n\nSigned-off-by: David Vernet <void@manifault.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/bpf/20240405143041.632519-3-void@manifault.com\n', '']",Add selftests to verify calling core kfuncs from BPF_PROG_TYPE_SYSCALL programs.,"selftests,kfuncs,BPF_PROG_TYPE_SYSCALL",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a8e03b6bbb2cc7cf387d1ce335e4ce4c3bdfef9b,a8e03b6bbb2cc7cf387d1ce335e4ce4c3bdfef9b,David Vernet,void@manifault.com,1712327440,Andrii Nakryiko,andrii@kernel.org,1712339769,b3cc4c808a9367175e898d47b876ed5bddfc0298,00d5d22a5b42c3ffdfd1b29526885bbcec2d2231,"bpf: Allow invoking kfuncs from BPF_PROG_TYPE_SYSCALL progs

Currently", a set of core BPF kfuncs (e.g. bpf_task_*,"[' bpf_cgroup_*', '\nbpf_cpumask_*', ' etc) cannot be invoked from BPF_PROG_TYPE_SYSCALL\nprograms. The whitelist approach taken for enabling kfuncs makes sense:\nit not safe to call these kfuncs from every program type. For example', '\nit may not be safe to call bpf_task_acquire() in an fentry to\nfree_task().\n\nBPF_PROG_TYPE_SYSCALL', ' on the other hand', ' is a perfectly safe program\ntype from which to invoke these kfuncs', "" as it's a very controlled\nenvironment"", ' and we should never be able to run into any of the typical\nproblems such as recursive invoations', ' acquiring references on freeing\nkptrs', ' etc. Being able to invoke these kfuncs would be useful', ' as\nBPF_PROG_TYPE_SYSCALL can be invoked with BPF_PROG_RUN', ' and would\ntherefore enable user space programs to synchronously call into BPF to\nmanipulate these kptrs.\n\nThis patch therefore enables invoking the aforementioned core kfuncs\nfrom BPF_PROG_TYPE_SYSCALL progs.\n\nSigned-off-by: David Vernet <void@manifault.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/bpf/20240405143041.632519-2-void@manifault.com\n', '']",Enable kfunc invocation from BPF_PROG_TYPE_SYSCALL programs in eBPF.,"kfuncs, BPF_PROG_TYPE_SYSCALL, eBPF",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"[""It's not related to any of the above.""]"
00d5d22a5b42c3ffdfd1b29526885bbcec2d2231,00d5d22a5b42c3ffdfd1b29526885bbcec2d2231,Dave Thaler,dthaler1968@googlemail.com,1712332365,Alexei Starovoitov,ast@kernel.org,1712338950,e7b4bef37d5c3d66752111b1b90c7e9654084cd3,ba0cbe2bb4ab8aa266e48c6399bebf6e1217828a,bpf," docs: Editorial nits in instruction-set.rst

This patch addresses a number of editorial nits including
spelling","[' punctuation', ' grammar', ' and wording consistency issues\nin instruction-set.rst.\n\nSigned-off-by: Dave Thaler <dthaler1968@gmail.com>\nAcked-by: David Vernet <void@manifault.com>\nLink: https://lore.kernel.org/r/20240405155245.3618-1-dthaler1968@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit addresses editorial nits and spelling corrections in the instruction-set documentation.,"editorial, nits, spelling",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
76cd338994778c552c51086fc056819b5cdda2e7,76cd338994778c552c51086fc056819b5cdda2e7,Björn Töpel,bjorn@rivosinc.com,1712320431,Alexei Starovoitov,ast@kernel.org,1712338497,eed5d82cd53ab9f7f535d373b5d993ecdd5b942b,cfddb048040b598fa7df0e51ca361289fc7abf28,"MAINTAINERS: bpf: Add Lehui and Puranjay as riscv64 reviewers

Lehui and Puranjay have been active RISC-V 64-bit BPF JIT
contributors/reviewers for a long time!

Let's make it more official by adding them as reviewers in
MAINTAINERS.

Thank you for your hard work!

Signed-off-by: Björn Töpel <bjorn@kernel.org>
Link: https://lore.kernel.org/r/20240405123352.2852393-1-bjorn@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit adds Lehui and Puranjay as official reviewers for the riscv64 BPF JIT in the MAINTAINERS file.,"MAINTAINERS, riscv64, reviewers",It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
ba0cbe2bb4ab8aa266e48c6399bebf6e1217828a,ba0cbe2bb4ab8aa266e48c6399bebf6e1217828a,Kui-Feng Lee,thinker.li@gmail.com,1712273022,Andrii Nakryiko,andrii@kernel.org,1712338398,318c36052520f655e96c0b6391e27c75b3be39f1,270954791c706b133a03b01e4b2d063dc870f704,"selftests/bpf: Make sure libbpf doesn't enforce the signature of a func pointer.

The verifier in the kernel ensures that the struct_ops operators behave
correctly by checking that they access parameters and context
appropriately. The verifier will approve a program as long as it correctly
accesses the context/parameters"," regardless of its function signature. In
contrast","[' libbpf should not verify the signature of function pointers and\nfunctions to enable flexibility in loading various implementations of an\noperator even if the signature of the function pointer does not match those\nin the implementations or the kernel.\n\nWith this flexibility', ' user space applications can adapt to different\nkernel versions by loading a specific implementation of an operator based\non feature detection.\n\nThis is a follow-up of the commit c911fc61a7ce (""libbpf: Skip zeroed or\nnull fields if not found in the kernel type."")\n\nSigned-off-by: Kui-Feng Lee <thinker.li@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240404232342.991414-1-thinker.li@gmail.com\n', '']",The commit ensures libbpf does not enforce function pointer signatures in selftests.,"libbpf,verifier,signature",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
270954791c706b133a03b01e4b2d063dc870f704,270954791c706b133a03b01e4b2d063dc870f704,Alexei Starovoitov,ast@kernel.org,1712338278,Alexei Starovoitov,ast@kernel.org,1712338278,bcbe65991403b2834a860dd962a1a13083b06f75,58babe27180c8d4cb54d831589cf801bd9268876 fecb1597cc11a23f32faa90d70a199533871686a,"Merge branch 'bpf-allow-bpf_for_each_map_elem-helper-with-different-input-maps'

Philo Lu says:

====================
bpf: allow bpf_for_each_map_elem() helper with different input maps

Currently"," taking different maps within a single bpf_for_each_map_elem
call is not allowed. For example the following codes cannot pass the
verifier (with error ""tail_call abusing map_ptr""):
```
static void test_by_pid(int pid)
{
	if (pid <= 100)
		bpf_for_each_map_elem(&map1","[' map_elem_cb', ' NULL', ' 0);\n\telse\n\t\tbpf_for_each_map_elem(&map2', ' map_elem_cb', ' NULL', ' 0);\n}\n```\n\nThis is because during bpf_for_each_map_elem verifying', '\nbpf_insn_aux_data->map_ptr_state is expected as map_ptr (instead of poison\nstate)', ' which is then needed by set_map_elem_callback_state. However', ' as\nthere are two different map ptr input', ' map_ptr_state is marked as\nBPF_MAP_PTR_POISON', ' and thus the second map_ptr would be lost.\nBPF_MAP_PTR_POISON is also needed by bpf_for_each_map_elem to skip\nretpoline optimization in do_misc_fixups(). Therefore', ' map_ptr_state and\nmap_ptr are both needed for bpf_for_each_map_elem.\n\nThis patchset solves it by transform bpf_insn_aux_data->map_ptr_state as a\nnew struct', ' storing poison/unpriv state and map pointer together without\nadditional memory overhead. Then bpf_for_each_map_elem works well with\ndifferent input maps. It also makes map_ptr_state logic clearer.\n\nA test case is added to selftest', ' which would fail to load without this\npatchset.\n\nChangelogs\n-> v1:\n- PATCH 1/3:\n  - make the commit log clearer\n  - change poison and unpriv to bool in struct bpf_map_ptr_state', ' also the\n    return value in bpf_map_ptr_poisoned() and bpf_map_ptr_unpriv()\n- PATCH 2/3:\n  - change the comments in set_map_elem_callback_state()\n- PATCH 3/3:\n  - remove the ""skipping the last element"" logic during map updating\n  - change if() to ASSERT_OK()\n\nPlease review', ' thanks.\n====================\n\nLink: https://lore.kernel.org/r/20240405025536.18113-1-lulie@linux.alibaba.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit allows the use of bpf_for_each_map_elem() with different input maps in eBPF programs.,"bpf, helper, maps",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fecb1597cc11a23f32faa90d70a199533871686a,fecb1597cc11a23f32faa90d70a199533871686a,Philo Lu,lulie@linux.alibaba.com,1712285736,Alexei Starovoitov,ast@kernel.org,1712338278,bcbe65991403b2834a860dd962a1a13083b06f75,9d482da9e17a4ddd5563428f74302a36b2610306,"selftests/bpf: add test for bpf_for_each_map_elem() with different maps

A test is added for bpf_for_each_map_elem() with either an arraymap or a
hashmap.
$ tools/testing/selftests/bpf/test_progs -t for_each
 #93/1    for_each/hash_map:OK
 #93/2    for_each/array_map:OK
 #93/3    for_each/write_map_key:OK
 #93/4    for_each/multi_maps:OK
 #93      for_each:OK
Summary: 1/4 PASSED", 0 SKIPPED,"[' 0 FAILED\n\nSigned-off-by: Philo Lu <lulie@linux.alibaba.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240405025536.18113-4-lulie@linux.alibaba.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Added selftests for bpf_for_each_map_elem() using arraymap and hashmap.,"selftests,arraymap,hashmap",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9d482da9e17a4ddd5563428f74302a36b2610306,9d482da9e17a4ddd5563428f74302a36b2610306,Philo Lu,lulie@linux.alibaba.com,1712285735,Alexei Starovoitov,ast@kernel.org,1712338277,daa373372a1c4edf856de49c047898273a7141f5,0a525621b7e5b49202b19d8f75382c6778fdd0c1,"bpf: allow invoking bpf_for_each_map_elem with different maps

Taking different maps within a single bpf_for_each_map_elem call is not
allowed before", because from the second map,"['\nbpf_insn_aux_data->map_ptr_state will be marked as *poison*. In fact\nboth map_ptr and state are needed to support this use case: map_ptr is\nused by set_map_elem_callback_state() while poison state is needed to\ndetermine whether to use direct call.\n\nSigned-off-by: Philo Lu <lulie@linux.alibaba.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240405025536.18113-3-lulie@linux.alibaba.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit allows invoking bpf_for_each_map_elem with different maps within a single use.,"bpf,map,elements",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0a525621b7e5b49202b19d8f75382c6778fdd0c1,0a525621b7e5b49202b19d8f75382c6778fdd0c1,Philo Lu,lulie@linux.alibaba.com,1712285734,Alexei Starovoitov,ast@kernel.org,1712338277,15aca0b681bfa152ff7768390965942dcbe6026b,58babe27180c8d4cb54d831589cf801bd9268876,"bpf: store both map ptr and state in bpf_insn_aux_data

Currently"," bpf_insn_aux_data->map_ptr_state is used to store either
map_ptr or its poison state (i.e.","[' BPF_MAP_PTR_POISON). Thus\nBPF_MAP_PTR_POISON must be checked before reading map_ptr. In certain\ncases', "" we may need valid map_ptr even in case of poison state.\nThis will be explained in next patch with bpf_for_each_map_elem()\nhelper.\n\nThis patch changes map_ptr_state into a new struct including both map\npointer and its state (poison/unpriv). It's in the same union with\nstruct bpf_loop_inline_state"", ' so there is no extra memory overhead.\nBesides', ' macros BPF_MAP_PTR_UNPRIV/BPF_MAP_PTR_POISON/BPF_MAP_PTR are no\nlonger needed.\n\nThis patch does not change any existing functionality.\n\nSigned-off-by: Philo Lu <lulie@linux.alibaba.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240405025536.18113-2-lulie@linux.alibaba.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit modifies bpf_insn_aux_data to store both map pointer and state.,"bpf, map_ptr, state",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
58babe27180c8d4cb54d831589cf801bd9268876,58babe27180c8d4cb54d831589cf801bd9268876,Arnd Bergmann,arnd@arndb.de,1712327185,Alexei Starovoitov,ast@kernel.org,1712331555,12f127e841b9ec5ed30394da5376a8952c08c489,343ca8131c35ba132d200fd9752b60e65357924d,"bpf: fix perf_snapshot_branch_stack link failure

The newly added code to handle bpf_get_branch_snapshot fails to link when
CONFIG_PERF_EVENTS is disabled:

aarch64-linux-ld: kernel/bpf/verifier.o: in function `do_misc_fixups':
verifier.c:(.text+0x1090c): undefined reference to `__SCK__perf_snapshot_branch_stack'

Add a build-time check for that Kconfig symbol around the code to
remove the link time dependency.

Fixes: 314a53623cd4 (""bpf: inline bpf_get_branch_snapshot() helper"")
Signed-off-by: Arnd Bergmann <arnd@arndb.de>
Link: https://lore.kernel.org/r/20240405142637.577046-1-arnd@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Fixes a linking error for bpf_get_branch_snapshot when CONFIG_PERF_EVENTS is disabled by adding a build-time check.,"linking error, CONFIG_PERF_EVENTS, bpf_get_branch_snapshot",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
cfddb048040b598fa7df0e51ca361289fc7abf28,cfddb048040b598fa7df0e51ca361289fc7abf28,Puranjay Mohan,puranjay@kernel.org,1712323417,Daniel Borkmann,daniel@iogearbox.net,1712324760,41e719e8b2ddcf955a0f2437001fdc0447975b3b,229087f6f1dc2d0c38feba805770f28529980ec0,"MAINTAINERS: Update email address for Puranjay Mohan

I would like to use the kernel.org address for kernel development from
now on.

Signed-off-by: Puranjay Mohan <puranjay@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240405132337.71950-1-puranjay@kernel.org
",,Update email address for Puranjay Mohan in the MAINTAINERS file.,MAINTAINERS update email,It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
229087f6f1dc2d0c38feba805770f28529980ec0,229087f6f1dc2d0c38feba805770f28529980ec0,Andrii Nakryiko,andrii@kernel.org,1712268224,Daniel Borkmann,daniel@iogearbox.net,1712322767,a3b0f78be6342fe4393e4d345cbb0a2d282ead46,c88b9b4cde17aec34fb9bfaf69f9f72a1c44f511,bpf," kconfig: Fix DEBUG_INFO_BTF_MODULES Kconfig definition

Turns out that due to CONFIG_DEBUG_INFO_BTF_MODULES not having an
explicitly specified ""menu item name"" in Kconfig","["" it's basically\nimpossible to turn it off (see [0]).\n\nThis patch fixes the issue by defining menu name for\nCONFIG_DEBUG_INFO_BTF_MODULES"", ' which makes it actually adjustable\nand independent of CONFIG_DEBUG_INFO_BTF', ' in the sense that one can\nhave DEBUG_INFO_BTF=y and DEBUG_INFO_BTF_MODULES=n.\n\nWe still keep it as defaulting to Y', ' of course.\n\nFixes: 5f9ae91f7c0d (""kbuild: Build kernel module BTFs if BTF is enabled and pahole supports it"")\nReported-by: Vincent Li <vincent.mc.li@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/CAK3+h2xiFfzQ9UXf56nrRRP=p1+iUxGoEP5B+aq9MDT5jLXDSg@mail.gmail.com [0]\nLink: https://lore.kernel.org/bpf/20240404220344.3879270-1-andrii@kernel.org\n', '']",Fixed the Kconfig definition by specifying the menu item name for CONFIG_DEBUG_INFO_BTF_MODULES.,"Kconfig, DEBUG_INFO_BTF_MODULES, fix",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),"[""It's not related to any of the above.""]"
343ca8131c35ba132d200fd9752b60e65357924d,343ca8131c35ba132d200fd9752b60e65357924d,Andrii Nakryiko,andrii@kernel.org,1712267136,Alexei Starovoitov,ast@kernel.org,1712280668,46767f1cae8d92aea0b1492ceb2777d42fc872d9,1f2a74b41ea8b902687eb97c4e7e3f558801865b,"selftests/bpf: add fp-leaking precise subprog result tests

Add selftests validating that BPF verifier handles precision marking
for SCALAR registers derived from r10 (fp) register correctly.

Given `r0 = (s8)r10;` syntax is not supported by older Clang compilers","
use the raw BPF instruction syntax to maximize compatibility.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20240404214536.3551295-2-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Add selftests to ensure BPF verifier handles precision for SCALAR registers from r10 correctly.,"selftests,BPF verifier,precision",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1f2a74b41ea8b902687eb97c4e7e3f558801865b,1f2a74b41ea8b902687eb97c4e7e3f558801865b,Andrii Nakryiko,andrii@kernel.org,1712267135,Alexei Starovoitov,ast@kernel.org,1712280668,118282cc4c739cc119bf3428482f8433f9b72317,f91717007217d975aa975ddabd91ae1a107b9bff,"bpf: prevent r10 register from being marked as precise

r10 is a special register that is not under BPF program's control and is
always effectively precise. The rest of precision logic assumes that
only r0-r9 SCALAR registers are marked as precise"," so prevent r10 from
being marked precise.

This can happen due to signed cast instruction allowing to do something
like `r0 = (s8)r10;`","[' which later', ' if r0 needs to be precise', ' would lead\nto an attempt to mark r10 as precise.\n\nPrevent this with an extra check during instruction backtracking.\n\nFixes: 8100928c8814 (""bpf: Support new sign-extension mov insns"")\nReported-by: syzbot+148110ee7cf72f39f33e@syzkaller.appspotmail.com\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240404214536.3551295-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Prevent r10 register from being incorrectly marked as precise in BPF programs.,"r10, register, precise",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f91717007217d975aa975ddabd91ae1a107b9bff,f91717007217d975aa975ddabd91ae1a107b9bff,Anton Protopopov,aspsk@isovalent.com,1712147583,Andrii Nakryiko,andrii@kernel.org,1712271152,156eb293afe40bf820c53c5e9222db5a0f38844a,478a535ae54ad3831371904d93b5dfc403222e17,"bpf: Pack struct bpf_fib_lookup

The struct bpf_fib_lookup is supposed to be of size 64. A recent commit
59b418c7063d (""bpf: Add a check for struct bpf_fib_lookup size"") added
a static assertion to check this property so that future changes to the
structure will not accidentally break this assumption.

As it immediately turned out", on some 32-bit arm systems,"[' when AEABI=n', '\nthe total size of the structure was equal to 68', ' see [1]. This happened\nbecause the bpf_fib_lookup structure contains a union of two 16-bit\nfields:\n\n    union {\n            __u16 tot_len;\n            __u16 mtu_result;\n    };\n\nwhich was supposed to compile to a 16-bit-aligned 16-bit field. On the\naforementioned setups it was instead both aligned and padded to 32-bits.\n\nDeclare this inner union as __attribute__((packed', ' aligned(2))) such\nthat it always is of size 2 and is aligned to 16 bits.\n\n  [1] https://lore.kernel.org/all/CA+G9fYtsoP51f-oP_Sp5MOq-Ffv8La2RztNpwvE6+R1VtFiLrw@mail.gmail.com/#t\n\nReported-by: Naresh Kamboju <naresh.kamboju@linaro.org>\nFixes: e1850ea9bd9e (""bpf: bpf_fib_lookup return MTU value as output when looked up"")\nSigned-off-by: Anton Protopopov <aspsk@isovalent.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nReviewed-by: Alexander Lobakin <aleksander.lobakin@intel.com>\nAcked-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240403123303.1452184-1-aspsk@isovalent.com\n', '']",The commit ensures that struct bpf_fib_lookup remains size 64 by packing it for compatibility with 32-bit systems.,"struct bpf_fib_lookup, size 64, pack",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,['tc/netfilter like programs']
478a535ae54ad3831371904d93b5dfc403222e17,478a535ae54ad3831371904d93b5dfc403222e17,Sahil Siddiq,icegambit91@gmail.com,1712258539,Andrii Nakryiko,andrii@kernel.org,1712270232,73d246fb5bb29edc494e747072af4ce36a4e22ff,d82c045f9dfde6b9ea220d7f8310c98210dfc8cb,"bpftool: Mount bpffs on provided dir instead of parent dir

When pinning programs/objects under PATH (eg: during ""bpftool prog
loadall"") the bpffs is mounted on the parent dir of PATH in the
following situations:
- the given dir exists but it is not bpffs.
- the given dir doesn't exist and the parent dir is not bpffs.

Mounting on the parent dir can also have the unintentional side-
effect of hiding other files located under the parent dir.

If the given dir exists but is not bpffs"," then the bpffs should
be mounted on the given dir and not its parent dir.

Similarly","["" if the given dir doesn't exist and its parent dir is not\nbpffs"", ' then the given dir should be created and the bpffs should be\nmounted on this new dir.\n\nFixes: 2a36c26fe3b8 (""bpftool: Support bpffs mountpoint as pin path for prog loadall"")\nSigned-off-by: Sahil Siddiq <icegambit91@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/2da44d24-74ae-a564-1764-afccf395eeec@isovalent.com/T/#t\nLink: https://lore.kernel.org/bpf/20240404192219.52373-1-icegambit91@gmail.com\n\nCloses: https://github.com/libbpf/bpftool/issues/100\n\nChanges since v1:\n - Split ""mount_bpffs_for_pin"" into two functions.\n   This is done to improve maintainability and readability.\n\nChanges since v2:\n- mount_bpffs_for_pin: rename to ""create_and_mount_bpffs_dir"".\n- mount_bpffs_given_file: rename to ""mount_bpffs_given_file"".\n- create_and_mount_bpffs_dir:\n  - introduce ""dir_exists"" boolean.\n  - remove new dir if ""mnt_fs"" fails.\n- improve error handling and error messages.\n\nChanges since v3:\n- Rectify function name.\n- Improve error messages and formatting.\n- mount_bpffs_for_file:\n  - Check if dir exists before block_mount check.\n\nChanges since v4:\n- Use strdup instead of strcpy.\n- create_and_mount_bpffs_dir:\n  - Use S_IRWXU instead of 0700.\n- Improve error handling and formatting.\n', '']",Modified bpftool to mount bpffs on the provided directory instead of the parent directory when pinning programs.,"bpftool, mount, bpffs",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The bpftool utility,"['xdp like programs', 'socket like programs', 'cgroup like programs']"
c88b9b4cde17aec34fb9bfaf69f9f72a1c44f511,c88b9b4cde17aec34fb9bfaf69f9f72a1c44f511,Linus Torvalds,torvalds@linux-foundation.org,1712267350,Linus Torvalds,torvalds@linux-foundation.org,1712267350,fd9527e34d0243438825ab67116b33bdbf0f8ca2,ec25bd8d981d910cdcc84914bf57e2cff9e7d63b 1cfa2f10f4e90a353c3ee2150866b4cf72579153,"Merge tag 'net-6.9-rc3' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Jakub Kicinski:
 ""Including fixes from netfilter"," bluetooth and bpf.

  Fairly usual collection of driver and core fixes. The large selftest
  accompanying one of the fixes is also becoming a common occurrence.

  Current release - regressions:

   - ipv6: fix infinite recursion in fib6_dump_done()

   - net/rds: fix possible null-deref in newly added error path

  Current release - new code bugs:

   - net: do not consume a full cacheline for system_page_pool

   - bpf: fix bpf_arena-related file descriptor leaks in the verifier

   - drv: ice: fix freeing uninitialized pointers","[' fixing misuse of the\n     newfangled __free() auto-cleanup\n\n  Previous releases - regressions:\n\n   - x86/bpf: fixes the BPF JIT with retbleed=stuff\n\n   - xen-netfront: add missing skb_mark_for_recycle', ' fix page pool\n     accounting leaks', ' revealed by recently added explicit warning\n\n   - tcp: fix bind() regression for v6-only wildcard and v4-mapped-v6\n     non-wildcard addresses\n\n   - Bluetooth:\n      - replace ""hci_qca: Set BDA quirk bit if fwnode exists in DT"" with\n        better workarounds to un-break some buggy Qualcomm devices\n      - set conn encrypted before conn establishes', "" fix re-connecting to\n        some headsets which use slightly unusual sequence of msgs\n\n   - mptcp:\n      - prevent BPF accessing lowat from a subflow socket\n      - don't account accept() of non-MPC client as fallback to TCP\n\n   - drv: mana: fix Rx DMA datasize and skb_over_panic\n\n   - drv: i40e: fix VF MAC filter removal\n\n  Previous releases - always broken:\n\n   - gro: various fixes related to UDP tunnels - netns crossing\n     problems"", ' incorrect checksum conversions', ' and incorrect packet\n     transformations which may lead to panics\n\n   - bpf: support deferring bpf_link dealloc to after RCU grace period\n\n   - nf_tables:\n      - release batch on table validation from abort path\n      - release mutex after nft_gc_seq_end from abort path\n      - flush pending destroy work before exit_net release\n\n   - drv: r8169: skip DASH fw status checks when DASH is disabled""\n\n* tag \'net-6.9-rc3\' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (81 commits)\n  netfilter: validate user input for expected length\n  net/sched: act_skbmod: prevent kernel-infoleak\n  net: usb: ax88179_178a: avoid the interface always configured as random address\n  net: dsa: sja1105: Fix parameters order in sja1110_pcs_mdio_write_c45()\n  net: ravb: Always update error counters\n  net: ravb: Always process TX descriptor ring\n  netfilter: nf_tables: discard table flag update with pending basechain deletion\n  netfilter: nf_tables: Fix potential data-race in __nft_flowtable_type_get()\n  netfilter: nf_tables: reject new basechain after table flag update\n  netfilter: nf_tables: flush pending destroy work before exit_net release\n  netfilter: nf_tables: release mutex after nft_gc_seq_end from abort path\n  netfilter: nf_tables: release batch on table validation from abort path\n  Revert ""tg3: Remove residual error handling in tg3_suspend""\n  tg3: Remove residual error handling in tg3_suspend\n  net: mana: Fix Rx DMA datasize and skb_over_panic\n  net/sched: fix lockdep splat in qdisc_tree_reduce_backlog()\n  net: phy: micrel: lan8814: Fix when enabling/disabling 1-step timestamping\n  net: stmmac: fix rx queue priority assignment\n  net: txgbe: fix i2c dev name cannot match clkdev\n  net: fec: Set mac_managed_pm during probe\n  ...\n', '']","Merge networking fixes including netfilter and driver core issues for ipv6, net, bpf, and ice.","networking, netfilter, bpf",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d82c045f9dfde6b9ea220d7f8310c98210dfc8cb,d82c045f9dfde6b9ea220d7f8310c98210dfc8cb,Alexei Starovoitov,ast@kernel.org,1712261281,Alexei Starovoitov,ast@kernel.org,1712261281,05376a14c790f914df2197a0431c3608ac025e66,21ab0b6d0cfcb8aa98e33baa83f933f963514027 314a53623cd4e62e1b88126e5ed2bc87073d90ee,"Merge branch 'inline-bpf_get_branch_snapshot-bpf-helper'

Andrii Nakryiko says:

====================
Inline bpf_get_branch_snapshot() BPF helper

Implement inlining of bpf_get_branch_snapshot() BPF helper using generic BPF
assembly approach. This allows to reduce LBR record usage right before LBR
records are captured from inside BPF program.

See v1 cover letter ([0]) for some visual examples. I dropped them from v2
because there are multiple independent changes landing and being reviewed"," all
of which remove different parts of LBR record waste","[' so presenting final state\nof LBR ""waste"" gets more complicated until all of the pieces land.\n\n  [0] https://lore.kernel.org/bpf/20240321180501.734779-1-andrii@kernel.org/\n\nv2->v3:\n  - fix BPF_MUL instruction definition;\nv1->v2:\n  - inlining of bpf_get_smp_processor_id() split out into a separate patch set\n    implementing internal per-CPU BPF instruction;\n  - add efficient divide-by-24 through multiplication logic', ' and leave\n    comments to explain the idea behind it; this way inlined version of\n    bpf_get_branch_snapshot() has no compromises compared to non-inlined\n    version of the helper  (Alexei).\n====================\n\nLink: https://lore.kernel.org/r/20240404002640.1774210-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit merges inline implementation of bpf_get_branch_snapshot BPF helper to optimize LBR record usage in BPF programs.,"inline, BPF helper, LBR",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['tracepoints like programs', 'kprobe/uprobe/ftrace like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
314a53623cd4e62e1b88126e5ed2bc87073d90ee,314a53623cd4e62e1b88126e5ed2bc87073d90ee,Andrii Nakryiko,andrii@kernel.org,1712190400,Alexei Starovoitov,ast@kernel.org,1712261281,05376a14c790f914df2197a0431c3608ac025e66,5e6a3c1ee693da1793739bb378b224bcf33d7f14,"bpf: inline bpf_get_branch_snapshot() helper

Inline bpf_get_branch_snapshot() helper using architecture-agnostic
inline BPF code which calls directly into underlying callback of
perf_snapshot_branch_stack static call. This callback is set early
during kernel initialization and is never updated or reset"," so it's ok
to fetch actual implementation using static_call_query() and call
directly into it.

This change eliminates a full function call and saves one LBR entry
in PERF_SAMPLE_BRANCH_ANY LBR mode.

Acked-by: John Fastabend <john.fastabend@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20240404002640.1774210-3-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Inline bpf_get_branch_snapshot() helper to improve performance by reducing function calls and saving LBR entries.,inline helper performance,It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).', ""It's not related to any of the above.""]"
5e6a3c1ee693da1793739bb378b224bcf33d7f14,5e6a3c1ee693da1793739bb378b224bcf33d7f14,Andrii Nakryiko,andrii@kernel.org,1712190399,Alexei Starovoitov,ast@kernel.org,1712261281,5d002e2fc869c08b88a93da73a604dbab6907ef1,21ab0b6d0cfcb8aa98e33baa83f933f963514027,"bpf: make bpf_get_branch_snapshot() architecture-agnostic

perf_snapshot_branch_stack is set up in an architecture-agnostic way"," so
there is no reason for BPF subsystem to keep track of which
architectures do support LBR or not. E.g.","[' it looks like ARM64 might soon\nget support for BRBE ([0])', ' which (with proper integration) should be\npossible to utilize using this BPF helper.\n\nperf_snapshot_branch_stack static call will point to\n__static_call_return0() by default', ' which just returns zero', ' which will\nlead to -ENOENT', ' as expected. So no need to guard anything here.\n\n  [0] https://lore.kernel.org/linux-arm-kernel/20240125094119.2542332-1-anshuman.khandual@arm.com/\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240404002640.1774210-2-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']","The commit refactors bpf_get_branch_snapshot to be architecture-agnostic, eliminating architecture-specific tracking for LBR support.","architecture-agnostic, bpf_get_branch_snapshot, LBR",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1cfa2f10f4e90a353c3ee2150866b4cf72579153,1cfa2f10f4e90a353c3ee2150866b4cf72579153,Jakub Kicinski,kuba@kernel.org,1712255859,Jakub Kicinski,kuba@kernel.org,1712255859,387d095e70156ded683464f08e33c7c0f8f876d8,0c83842df40f86e529db6842231154772c20edcc ff91059932401894e6c86341915615c5eb0eca48,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Daniel Borkmann says:

====================
pull-request: bpf 2024-04-04

We've added 7 non-merge commits during the last 5 day(s) which contain
a total of 9 files changed", 75 insertions(+),"[' 24 deletions(-).\n\nThe main changes are:\n\n1) Fix x86 BPF JIT under retbleed=stuff which causes kernel panics due to\n   incorrect destination IP calculation and incorrect IP for relocations', '\n   from Uros Bizjak and Joan Bruguera Micó.\n\n2) Fix BPF arena file descriptor leaks in the verifier', '\n   from Anton Protopopov.\n\n3) Defer bpf_link deallocation to after RCU grace period as currently\n   running multi-{kprobes', 'uprobes} programs might still access cookie\n   information from the link', ' from Andrii Nakryiko.\n\n4) Fix a BPF sockmap lock inversion deadlock in map_delete_elem reported\n   by syzkaller', ' from Jakub Sitnicki.\n\n5) Fix resolve_btfids build with musl libc due to missing linux/types.h\n   include', "" from Natanael Copa.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  bpf"", "" sockmap: Prevent lock inversion deadlock in map delete elem\n  x86/bpf: Fix IP for relocating call depth accounting\n  x86/bpf: Fix IP after emitting call depth accounting\n  bpf: fix possible file descriptor leaks in verifier\n  tools/resolve_btfids: fix build with musl libc\n  bpf: support deferring bpf_link dealloc to after RCU grace period\n  bpf: put uprobe link's path and task in release callback\n====================\n\nLink: https://lore.kernel.org/r/20240404183258.4401-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n"", '']",This commit merges the 'for-netdev' branch from the BPF repository into the mainline.,"merge, netdev, bpf",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0c83842df40f86e529db6842231154772c20edcc,0c83842df40f86e529db6842231154772c20edcc,Eric Dumazet,edumazet@google.com,1712233251,Jakub Kicinski,kuba@kernel.org,1712248792,48a6e18f96fa362df778181e8ba0258bb1df5663,d432f7bdc1cddd37e73dbe6b53b48785ab789e92,"netfilter: validate user input for expected length

I got multiple syzbot reports showing old bugs exposed
by BPF after commit 20f2505fb436 (""bpf: Try to avoid kzalloc
in cgroup/{s","g}etsockopt"")

setsockopt() @optlen argument should be taken into account
before copying data.

 BUG: KASAN: slab-out-of-bounds in copy_from_sockptr_offset include/linux/sockptr.h:49 [inline]
 BUG: KASAN: slab-out-of-bounds in copy_from_sockptr include/linux/sockptr.h:55 [inline]
 BUG: KASAN: slab-out-of-bounds in do_replace net/ipv4/netfilter/ip_tables.c:1111 [inline]
 BUG: KASAN: slab-out-of-bounds in do_ipt_set_ctl+0x902/0x3dd0 net/ipv4/netfilter/ip_tables.c:1627
Read of size 96 at addr ffff88802cd73da0 by task syz-executor.4/7238

CPU: 1 PID: 7238 Comm: syz-executor.4 Not tainted 6.9.0-rc2-next-20240403-syzkaller #0
Hardware name: Google Google Compute Engine/Google Compute Engine","[' BIOS Google 03/27/2024\nCall Trace:\n <TASK>\n  __dump_stack lib/dump_stack.c:88 [inline]\n  dump_stack_lvl+0x241/0x360 lib/dump_stack.c:114\n  print_address_description mm/kasan/report.c:377 [inline]\n  print_report+0x169/0x550 mm/kasan/report.c:488\n  kasan_report+0x143/0x180 mm/kasan/report.c:601\n  kasan_check_range+0x282/0x290 mm/kasan/generic.c:189\n  __asan_memcpy+0x29/0x70 mm/kasan/shadow.c:105\n  copy_from_sockptr_offset include/linux/sockptr.h:49 [inline]\n  copy_from_sockptr include/linux/sockptr.h:55 [inline]\n  do_replace net/ipv4/netfilter/ip_tables.c:1111 [inline]\n  do_ipt_set_ctl+0x902/0x3dd0 net/ipv4/netfilter/ip_tables.c:1627\n  nf_setsockopt+0x295/0x2c0 net/netfilter/nf_sockopt.c:101\n  do_sock_setsockopt+0x3af/0x720 net/socket.c:2311\n  __sys_setsockopt+0x1ae/0x250 net/socket.c:2334\n  __do_sys_setsockopt net/socket.c:2343 [inline]\n  __se_sys_setsockopt net/socket.c:2340 [inline]\n  __x64_sys_setsockopt+0xb5/0xd0 net/socket.c:2340\n do_syscall_64+0xfb/0x240\n entry_SYSCALL_64_after_hwframe+0x72/0x7a\nRIP: 0033:0x7fd22067dde9\nCode: 28 00 00 00 75 05 48 83 c4 28 c3 e8 e1 20 00 00 90 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 73 01 c3 48 c7 c1 b0 ff ff ff f7 d8 64 89 01 48\nRSP: 002b:00007fd21f9ff0c8 EFLAGS: 00000246 ORIG_RAX: 0000000000000036\nRAX: ffffffffffffffda RBX: 00007fd2207abf80 RCX: 00007fd22067dde9\nRDX: 0000000000000040 RSI: 0000000000000000 RDI: 0000000000000003\nRBP: 00007fd2206ca47a R08: 0000000000000001 R09: 0000000000000000\nR10: 0000000020000880 R11: 0000000000000246 R12: 0000000000000000\nR13: 000000000000000b R14: 00007fd2207abf80 R15: 00007ffd2d0170d8\n </TASK>\n\nAllocated by task 7238:\n  kasan_save_stack mm/kasan/common.c:47 [inline]\n  kasan_save_track+0x3f/0x80 mm/kasan/common.c:68\n  poison_kmalloc_redzone mm/kasan/common.c:370 [inline]\n  __kasan_kmalloc+0x98/0xb0 mm/kasan/common.c:387\n  kasan_kmalloc include/linux/kasan.h:211 [inline]\n  __do_kmalloc_node mm/slub.c:4069 [inline]\n  __kmalloc_noprof+0x200/0x410 mm/slub.c:4082\n  kmalloc_noprof include/linux/slab.h:664 [inline]\n  __cgroup_bpf_run_filter_setsockopt+0xd47/0x1050 kernel/bpf/cgroup.c:1869\n  do_sock_setsockopt+0x6b4/0x720 net/socket.c:2293\n  __sys_setsockopt+0x1ae/0x250 net/socket.c:2334\n  __do_sys_setsockopt net/socket.c:2343 [inline]\n  __se_sys_setsockopt net/socket.c:2340 [inline]\n  __x64_sys_setsockopt+0xb5/0xd0 net/socket.c:2340\n do_syscall_64+0xfb/0x240\n entry_SYSCALL_64_after_hwframe+0x72/0x7a\n\nThe buggy address belongs to the object at ffff88802cd73da0\n which belongs to the cache kmalloc-8 of size 8\nThe buggy address is located 0 bytes inside of\n allocated 1-byte region [ffff88802cd73da0', ' ffff88802cd73da1)\n\nThe buggy address belongs to the physical page:\npage: refcount:1 mapcount:0 mapping:0000000000000000 index:0xffff88802cd73020 pfn:0x2cd73\nflags: 0xfff80000000000(node=0|zone=1|lastcpupid=0xfff)\npage_type: 0xffffefff(slab)\nraw: 00fff80000000000 ffff888015041280 dead000000000100 dead000000000122\nraw: ffff88802cd73020 000000008080007f 00000001ffffefff 0000000000000000\npage dumped because: kasan: bad access detected\npage_owner tracks the page as allocated\npage last allocated via order 0', ' migratetype Unmovable', ' gfp_mask 0x12cc0(GFP_KERNEL|__GFP_NOWARN|__GFP_NORETRY)', ' pid 5103', ' tgid 2119833701 (syz-executor.4)', ' ts 5103', ' free_ts 70804600828\n  set_page_owner include/linux/page_owner.h:32 [inline]\n  post_alloc_hook+0x1f3/0x230 mm/page_alloc.c:1490\n  prep_new_page mm/page_alloc.c:1498 [inline]\n  get_page_from_freelist+0x2e7e/0x2f40 mm/page_alloc.c:3454\n  __alloc_pages_noprof+0x256/0x6c0 mm/page_alloc.c:4712\n  __alloc_pages_node_noprof include/linux/gfp.h:244 [inline]\n  alloc_pages_node_noprof include/linux/gfp.h:271 [inline]\n  alloc_slab_page+0x5f/0x120 mm/slub.c:2249\n  allocate_slab+0x5a/0x2e0 mm/slub.c:2412\n  new_slab mm/slub.c:2465 [inline]\n  ___slab_alloc+0xcd1/0x14b0 mm/slub.c:3615\n  __slab_alloc+0x58/0xa0 mm/slub.c:3705\n  __slab_alloc_node mm/slub.c:3758 [inline]\n  slab_alloc_node mm/slub.c:3936 [inline]\n  __do_kmalloc_node mm/slub.c:4068 [inline]\n  kmalloc_node_track_caller_noprof+0x286/0x450 mm/slub.c:4089\n  kstrdup+0x3a/0x80 mm/util.c:62\n  device_rename+0xb5/0x1b0 drivers/base/core.c:4558\n  dev_change_name+0x275/0x860 net/core/dev.c:1232\n  do_setlink+0xa4b/0x41f0 net/core/rtnetlink.c:2864\n  __rtnl_newlink net/core/rtnetlink.c:3680 [inline]\n  rtnl_newlink+0x180b/0x20a0 net/core/rtnetlink.c:3727\n  rtnetlink_rcv_msg+0x89b/0x10d0 net/core/rtnetlink.c:6594\n  netlink_rcv_skb+0x1e3/0x430 net/netlink/af_netlink.c:2559\n  netlink_unicast_kernel net/netlink/af_netlink.c:1335 [inline]\n  netlink_unicast+0x7ea/0x980 net/netlink/af_netlink.c:1361\npage last free pid 5146 tgid 5146 stack trace:\n  reset_page_owner include/linux/page_owner.h:25 [inline]\n  free_pages_prepare mm/page_alloc.c:1110 [inline]\n  free_unref_page+0xd3c/0xec0 mm/page_alloc.c:2617\n  discard_slab mm/slub.c:2511 [inline]\n  __put_partials+0xeb/0x130 mm/slub.c:2980\n  put_cpu_partial+0x17c/0x250 mm/slub.c:3055\n  __slab_free+0x2ea/0x3d0 mm/slub.c:4254\n  qlink_free mm/kasan/quarantine.c:163 [inline]\n  qlist_free_all+0x9e/0x140 mm/kasan/quarantine.c:179\n  kasan_quarantine_reduce+0x14f/0x170 mm/kasan/quarantine.c:286\n  __kasan_slab_alloc+0x23/0x80 mm/kasan/common.c:322\n  kasan_slab_alloc include/linux/kasan.h:201 [inline]\n  slab_post_alloc_hook mm/slub.c:3888 [inline]\n  slab_alloc_node mm/slub.c:3948 [inline]\n  __do_kmalloc_node mm/slub.c:4068 [inline]\n  __kmalloc_node_noprof+0x1d7/0x450 mm/slub.c:4076\n  kmalloc_node_noprof include/linux/slab.h:681 [inline]\n  kvmalloc_node_noprof+0x72/0x190 mm/util.c:634\n  bucket_table_alloc lib/rhashtable.c:186 [inline]\n  rhashtable_rehash_alloc+0x9e/0x290 lib/rhashtable.c:367\n  rht_deferred_worker+0x4e1/0x2440 lib/rhashtable.c:427\n  process_one_work kernel/workqueue.c:3218 [inline]\n  process_scheduled_works+0xa2c/0x1830 kernel/workqueue.c:3299\n  worker_thread+0x86d/0xd70 kernel/workqueue.c:3380\n  kthread+0x2f0/0x390 kernel/kthread.c:388\n  ret_from_fork+0x4b/0x80 arch/x86/kernel/process.c:147\n  ret_from_fork_asm+0x1a/0x30 arch/x86/entry/entry_64.S:243\n\nMemory state around the buggy address:\n ffff88802cd73c80: 07 fc fc fc 05 fc fc fc 05 fc fc fc fa fc fc fc\n ffff88802cd73d00: fa fc fc fc fa fc fc fc fa fc fc fc fa fc fc fc\n>ffff88802cd73d80: fa fc fc fc 01 fc fc fc fa fc fc fc fa fc fc fc\n                               ^\n ffff88802cd73e00: fa fc fc fc fa fc fc fc 05 fc fc fc 07 fc fc fc\n ffff88802cd73e80: 07 fc fc fc 07 fc fc fc 07 fc fc fc 07 fc fc fc\n\nFixes: 1da177e4c3f4 (""Linux-2.6.12-rc2"")\nReported-by: syzbot <syzkaller@googlegroups.com>\nSigned-off-by: Eric Dumazet <edumazet@google.com>\nReviewed-by: Pablo Neira Ayuso <pablo@netfilter.org>\nLink: https://lore.kernel.org/r/20240404122051.2303764-1-edumazet@google.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",This commit adds validation for user input length in the netfilter to prevent buffer overflows.,"netfilter,validation,buffer overflow",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.",['other']
21ab0b6d0cfcb8aa98e33baa83f933f963514027,21ab0b6d0cfcb8aa98e33baa83f933f963514027,Puranjay Mohan,puranjay12@gmail.com,1712230923,Daniel Borkmann,daniel@iogearbox.net,1712242122,95efbd4fc58efc0831780ed0dd79305f136e4375,633a6e01d1a20b24a16899094c249a8cb2aad4b2,bpf," riscv: Implement bpf_addr_space_cast instruction

LLVM generates bpf_addr_space_cast instruction while translating
pointers between native (zero) address space and
__attribute__((address_space(N))). The addr_space=0 is reserved as
bpf_arena address space.

rY = addr_space_cast(rX","[' 0', ' 1) is processed by the verifier and\nconverted to normal 32-bit move: wX = wY\n\nrY = addr_space_cast(rX', ' 1', ' 0) has to be converted by JIT.\n\nSigned-off-by: Puranjay Mohan <puranjay12@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Björn Töpel <bjorn@rivosinc.com>\nTested-by: Pu Lehui <pulehui@huawei.com>\nReviewed-by: Pu Lehui <pulehui@huawei.com>\nAcked-by: Björn Töpel <bjorn@kernel.org>\nLink: https://lore.kernel.org/bpf/20240404114203.105970-3-puranjay12@gmail.com\n', '']",Implement bpf_addr_space_cast instruction for RISC-V in LLVM for handling address space translations.,"bpf, addr_space_cast, RISC-V",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
633a6e01d1a20b24a16899094c249a8cb2aad4b2,633a6e01d1a20b24a16899094c249a8cb2aad4b2,Puranjay Mohan,puranjay12@gmail.com,1712230922,Daniel Borkmann,daniel@iogearbox.net,1712242090,8dee43335ab942606e838b9e70beb506ec85ace1,af682b767a41772499f8e54ca7d7e1deb3395f44,bpf," riscv: Implement PROBE_MEM32 pseudo instructions

Add support for [LDX | STX | ST]","[' PROBE_MEM32', ' [B | H | W | DW]\ninstructions. They are similar to PROBE_MEM instructions with the\nfollowing differences:\n\n- PROBE_MEM32 supports store.\n- PROBE_MEM32 relies on the verifier to clear upper 32-bit of the\n  src/dst register\n- PROBE_MEM32 adds 64-bit kern_vm_start address (which is stored in S7\n  in the prologue). Due to bpf_arena constructions such S7 + reg +\n  off16 access is guaranteed to be within arena virtual range', ' so no\n  address check at run-time.\n- S11 is a free callee-saved register', ' so it is used to store kern_vm_start\n- PROBE_MEM32 allows STX and ST. If they fault the store is a nop. When\n  LDX faults the destination register is zeroed.\n\nTo support these on riscv', ' we do tmp = S7 + src/dst reg and then use\ntmp2 as the new src/dst register. This allows us to reuse most of the\ncode for normal [LDX | STX | ST].\n\nSigned-off-by: Puranjay Mohan <puranjay12@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Björn Töpel <bjorn@rivosinc.com>\nTested-by: Pu Lehui <pulehui@huawei.com>\nReviewed-by: Pu Lehui <pulehui@huawei.com>\nAcked-by: Björn Töpel <bjorn@kernel.org>\nLink: https://lore.kernel.org/bpf/20240404114203.105970-2-puranjay12@gmail.com\n', '']",Implement PROBE_MEM32 pseudo instructions for riscv architecture in bpf.,"riscv, PROBE_MEM32, pseudo",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
af682b767a41772499f8e54ca7d7e1deb3395f44,af682b767a41772499f8e54ca7d7e1deb3395f44,Alexei Starovoitov,ast@kernel.org,1712014680,Daniel Borkmann,daniel@iogearbox.net,1712240006,6d1b833f7a32bae58032ff46b09ffea035ef5147,1e9e0b85255e6eca6036b59d8a5fbca6501905ac,"bpf: Optimize emit_mov_imm64().

Turned out that bpf prog callback addresses"," bpf prog addresses
used in bpf_trampoline","[' and in other cases the 64-bit address\ncan be represented as sign extended 32-bit value.\n\nAccording to https://gcc.gnu.org/bugzilla/show_bug.cgi?id=82339\n""Skylake has 0.64c throughput for mov r64', ' imm64', ' vs. 0.25 for mov r32', ' imm32.""\nSo use shorter encoding and faster instruction when possible.\n\nSpecial care is needed in jit_subprogs()', ' since bpf_pseudo_func()\ninstruction cannot change its size during the last step of JIT.\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/CAADnVQKFfpY-QZBrOU2CG8v2du8Lgyb7MNVmOZVK_yTyOdNbBA@mail.gmail.com\nLink: https://lore.kernel.org/bpf/20240401233800.42737-1-alexei.starovoitov@gmail.com\n', '']",Optimize bpf_trampoline by improving emit_mov_imm64 function for bpf prog callback addresses.,"Optimize, emit_mov_imm64, bpf_trampoline",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1e9e0b85255e6eca6036b59d8a5fbca6501905ac,1e9e0b85255e6eca6036b59d8a5fbca6501905ac,Andrii Nakryiko,andrii@kernel.org,1712202446,Alexei Starovoitov,ast@kernel.org,1712205395,0b90da08e9a36a61517c7e31b761e140234e82b7,519e1de94b719f741e0de42b085b9a4551c5b15c,"bpf: handle CONFIG_SMP=n configuration in x86 BPF JIT

On non-SMP systems"," there is no ""per-CPU"" data","[' it\'s just global data.\nSo in such case just don\'t do this_cpu_off-based per-CPU address adjustment.\n\nReported-by: kernel test robot <lkp@intel.com>\nCloses: https://lore.kernel.org/oe-kbuild-all/202404040951.d4CUx5S6-lkp@intel.com/\nFixes: 7bdbf7446305 (""bpf: add special internal-only MOV instruction to resolve per-CPU addrs"")\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240404034726.2766740-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix handling of per-CPU data in the x86 BPF JIT for non-SMP systems.,"x86, BPF JIT, non-SMP",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4793cb599b1bdc3d356f0374c2c99ffe890ae876,4793cb599b1bdc3d356f0374c2c99ffe890ae876,Tianchen Ding,dtcccc@linux.alibaba.com,1711507477,Tejun Heo,tj@kernel.org,1712173333,9c3e0e58082806555b2a4cf7afa69cdaaa5f825e,20d46283f5d679338ec2bbd734f46f900557fb97,"selftests: cgroup: skip test_cgcore_lesser_ns_open when cgroup2 mounted without nsdelegate

The test case test_cgcore_lesser_ns_open only tasks effect when cgroup2
is mounted with ""nsdelegate"" mount option. If it misses this option"," or
is remounted without ""nsdelegate""","[' the test case will fail. For example', '\nrunning bpf/test_cgroup_storage first', ' and then run cgroup/test_core will\nfail on test_cgcore_lesser_ns_open. Skip it if ""nsdelegate"" is not\ndetected in cgroup2 mount options.\n\nFixes: bf35a7879f1d (""selftests: cgroup: Test open-time cgroup namespace usage for migration checks"")\nSigned-off-by: Tianchen Ding <dtcccc@linux.alibaba.com>\nReviewed-by: Muhammad Usama Anjum <usama.anjum@collabora.com>\nSigned-off-by: Tejun Heo <tj@kernel.org>\n', '']",Skip test_cgcore_lesser_ns_open if cgroup2 is mounted without nsdelegate.,"skip,cgroup2,nsdelegate",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['cgroup like programs']
519e1de94b719f741e0de42b085b9a4551c5b15c,519e1de94b719f741e0de42b085b9a4551c5b15c,Alexei Starovoitov,ast@kernel.org,1712165396,Alexei Starovoitov,ast@kernel.org,1712165413,d854878120567fc94dbc26d31c8238caffe88c2a,2e114248e086fb376405ed3f89b220f8586a2541 0b56e637f705836b9aa51e2b1058c3c814c121a8,"Merge branch 'add-internal-only-bpf-per-cpu-instruction'

Andrii Nakryiko says:

====================
Add internal-only BPF per-CPU instruction

Add a new BPF instruction for resolving per-CPU memory addresses.

New instruction is a special form of BPF_ALU64 | BPF_MOV | BPF_X"," with
insns->off set to BPF_ADDR_PERCPU (== -1). It resolves provided per-CPU offset
to an absolute address where per-CPU data resides for ""this"" CPU.

This patch set implements support for it in x86-64 BPF JIT only.

Using the new instruction","[' we also implement inlining for three cases:\n  - bpf_get_smp_processor_id()', ' which allows to avoid unnecessary trivial\n    function call', "" saving a bit of performance and also not polluting LBR\n    records with unnecessary function call/return records;\n  - PERCPU_ARRAY's bpf_map_lookup_elem() is completely inlined"", ' bringing its\n    performance to implementing per-CPU data structures using global variables\n    in BPF (which is an awesome improvement', "" see benchmarks below);\n  - PERCPU_HASH's bpf_map_lookup_elem() is partially inlined"", ' just like the\n    same for non-PERCPU HASH map; this still saves a bit of overhead.\n\nTo validate performance benefits', ' I hacked together a tiny benchmark doing\nonly bpf_map_lookup_elem() and incrementing the value by 1 for PERCPU_ARRAY\n(arr-inc benchmark below) and PERCPU_HASH (hash-inc benchmark below) maps. To\nestablish a baseline', ' I also implemented logic similar to PERCPU_ARRAY based\non global variable array using bpf_get_smp_processor_id() to index array for\ncurrent CPU (glob-arr-inc benchmark below).\n\nBEFORE\n======\nglob-arr-inc   :  163.685 ± 0.092M/s\narr-inc        :  138.096 ± 0.160M/s\nhash-inc       :   66.855 ± 0.123M/s\n\nAFTER\n=====\nglob-arr-inc   :  173.921 ± 0.039M/s (+6%)\narr-inc        :  170.729 ± 0.210M/s (+23.7%)\nhash-inc       :   68.673 ± 0.070M/s (+2.7%)\n\nAs can be seen', ' PERCPU_HASH gets a modest +2.7% improvement', "" while global\narray-based gets a nice +6% due to inlining of bpf_get_smp_processor_id().\n\nBut what's really important is that arr-inc benchmark basically catches up\nwith glob-arr-inc"", "" resulting in +23.7% improvement. This means that in\npractice it won't be necessary to avoid PERCPU_ARRAY anymore if performance is\ncritical (e.g."", ' high-frequent stats collection', ' which is often a practical use\nfor PERCPU_ARRAY today).\n\nv1->v2:\n  - use BPF_ALU64 | BPF_MOV instruction instead of LDX (Alexei);\n  - dropped the direct per-CPU memory read instruction', ' it can always be added\n    back', ' if necessary;\n  - guarded bpf_get_smp_processor_id() behind x86-64 check (Alexei);\n  - switched all per-cpu addr casts to (unsigned long) to avoid sparse\n    warnings.\n====================\n\nLink: https://lore.kernel.org/r/20240402021307.1012571-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Added an internal-only BPF instruction for resolving per-CPU memory addresses in x86-64 BPF JIT.,"BPF instruction, per-CPU address, x86-64 JIT",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0b56e637f705836b9aa51e2b1058c3c814c121a8,0b56e637f705836b9aa51e2b1058c3c814c121a8,Andrii Nakryiko,andrii@kernel.org,1712023985,Alexei Starovoitov,ast@kernel.org,1712165396,d854878120567fc94dbc26d31c8238caffe88c2a,db69718b8efac802c7cc20d5a6c7dfc913f99c43,"bpf: inline bpf_map_lookup_elem() helper for PERCPU_HASH map

Using new per-CPU BPF instruction"," partially inline
bpf_map_lookup_elem() helper for per-CPU hashmap BPF map. Just like for
normal HASH map","[' we still generate a call into __htab_map_lookup_elem()', '\nbut after that we resolve per-CPU element address using a new\ninstruction', ' saving on extra functions calls.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nLink: https://lore.kernel.org/r/20240402021307.1012571-5-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Inline the bpf_map_lookup_elem() helper for per-CPU HASH maps using a new BPF instruction.,"inline, per-CPU, BPF map",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['tracepoints like programs', 'kprobe/uprobe/ftrace like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
db69718b8efac802c7cc20d5a6c7dfc913f99c43,db69718b8efac802c7cc20d5a6c7dfc913f99c43,Andrii Nakryiko,andrii@kernel.org,1712023984,Alexei Starovoitov,ast@kernel.org,1712165396,9ba96e9d3e65a2d0731b14e6bfb5525de3102ecd,1ae6921009e5d72787e07ccc04754514ccf6bc99,"bpf: inline bpf_map_lookup_elem() for PERCPU_ARRAY maps

Using new per-CPU BPF instruction implement inlining for per-CPU ARRAY
map lookup helper"," if BPF JIT support is present.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/r/20240402021307.1012571-4-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Implemented inlining of bpf_map_lookup_elem() for PERCPU_ARRAY maps using new per-CPU BPF instruction.,"inline,elements,PERCPU_ARRAY",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1ae6921009e5d72787e07ccc04754514ccf6bc99,1ae6921009e5d72787e07ccc04754514ccf6bc99,Andrii Nakryiko,andrii@kernel.org,1712023983,Alexei Starovoitov,ast@kernel.org,1712165396,1ef59b0a783c0ac47d1ba63d5aaa3c932ec9dcd5,7bdbf7446305cb65c510c16d57cde82bc76b234a,"bpf: inline bpf_get_smp_processor_id() helper

If BPF JIT supports per-CPU MOV instruction"," inline bpf_get_smp_processor_id()
to eliminate unnecessary function calls.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/r/20240402021307.1012571-3-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Inlined bpf_get_smp_processor_id() helper in BPF for efficiency if JIT supports per-CPU MOV instruction.,"BPF, inline, efficiency",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7bdbf7446305cb65c510c16d57cde82bc76b234a,7bdbf7446305cb65c510c16d57cde82bc76b234a,Andrii Nakryiko,andrii@kernel.org,1712023982,Alexei Starovoitov,ast@kernel.org,1712165395,76980484fb19439a158181f99fa1f29f553ab189,2e114248e086fb376405ed3f89b220f8586a2541,"bpf: add special internal-only MOV instruction to resolve per-CPU addrs

Add a new BPF instruction for resolving absolute addresses of per-CPU
data from their per-CPU offsets. This instruction is internal-only and
users are not allowed to use them directly. They will only be used for
internal inlining optimizations for now between BPF verifier and BPF JITs.

We use a special BPF_MOV | BPF_ALU64 | BPF_X form with insn->off field
set to BPF_ADDR_PERCPU = -1. I used negative offset value to distinguish
them from positive ones used by user-exposed instructions.

Such instruction performs a resolution of a per-CPU offset stored in
a register to a valid kernel address which can be dereferenced. It is
useful in any use case where absolute address of a per-CPU data has to
be resolved (e.g."," in inlining bpf_map_lookup_elem()).

BPF disassembler is also taught to recognize them to support dumping
final BPF assembly code (non-JIT'ed version).

Add arch-specific way for BPF JITs to mark support for this instructions.

This patch also adds support for these instructions in x86-64 BPF JIT.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/r/20240402021307.1012571-2-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],This commit adds a special internal-only MOV instruction for per-CPU address resolution in eBPF.,"BPF instruction, per-CPU, MOV",It's a new feature.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2e114248e086fb376405ed3f89b220f8586a2541,2e114248e086fb376405ed3f89b220f8586a2541,Justin Stitt,justinstitt@google.com,1712101970,Daniel Borkmann,daniel@iogearbox.net,1712156261,3cbcfd5ea628f560c4d4156051ea34fa00509a76,c53908b254fcf25b05bcdf6634adb36eaccac111,"bpf: Replace deprecated strncpy with strscpy

strncpy() is deprecated for use on NUL-terminated destination strings
[1] and as such we should prefer more robust and less ambiguous string
interfaces.

bpf sym names get looked up and compared/cleaned with various string
apis. This suggests they need to be NUL-terminated (strncpy() suggests
this but does not guarantee it).

|	static int compare_symbol_name(const char *name"," char *namebuf)
|	{
|		cleanup_symbol_name(namebuf);
|		return strcmp(name","[' namebuf);\n|\t}\n\n|\tstatic void cleanup_symbol_name(char *s)\n|\t{\n|\t\t...\n|\t\tres = strstr(s', ' "".llvm."");\n|\t\t...\n|\t}\n\nUse strscpy() as this method guarantees NUL-termination on the\ndestination buffer.\n\nThis patch also replaces two uses of strncpy() used in log.c. These are\nsimple replacements as postfix has been zero-initialized on the stack\nand has source arguments with a size less than the destination\'s size.\n\nNote that this patch uses the new 2-argument version of strscpy\nintroduced in commit e6584c3964f2f (""string: Allow 2-argument strscpy()"").\n\nSigned-off-by: Justin Stitt <justinstitt@google.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://www.kernel.org/doc/html/latest/process/deprecated.html#strncpy-on-nul-terminated-strings [1]\nLink: https://manpages.debian.org/testing/linux-manual-4.8/strscpy.9.en.html [2]\nLink: https://github.com/KSPP/linux/issues/90\nLink: https://lore.kernel.org/bpf/20240402-strncpy-kernel-bpf-core-c-v1-1-7cb07a426e78@google.com\n', '']",Replaced deprecated strncpy with strscpy for safer string handling in bpf symbol names.,"deprecated, strncpy, strscpy",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
98f69a573c668a18cfda41b3976118e04521a196,98f69a573c668a18cfda41b3976118e04521a196,Namhyung Kim,namhyung@kernel.org,1711749490,Arnaldo Carvalho de Melo,acme@redhat.com,1712155737,b4bd68a7eaecf2a677bd0d64fa3fd46b1614ebce,10adbf777622e22323abbf9f7861c26deb373199,"perf annotate: Split out util/disasm.c

The util/annotate.c code has both disassembly and sample annotation
related codes.  Factor out the disasm part so that it can be handled
more easily.

No functional changes intended.

Committer notes:

Add missing include env.h", util.h,"[' bpf-event.h and bpf-util.h to\ndisasm.c', ' to fix things like:\n\n  util/disasm.c: In function ‘symbol__disassemble_bpf’:\n  util/disasm.c:1203:9: error: implicit declaration of function ‘perf_exe’ [-Werror=implicit-function-declaration]\n   1203 |         perf_exe(tpath', ' sizeof(tpath));\n        |         ^~~~~~~~\n\nSigned-off-by: Namhyung Kim <namhyung@kernel.org>\nTested-by: Ian Rogers <irogers@google.com>\nCc: Adrian Hunter <adrian.hunter@intel.com>\nCc: Ingo Molnar <mingo@kernel.org>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: Kan Liang <kan.liang@linux.intel.com>\nCc: Peter Zijlstra <peterz@infradead.org>\nLink: https://lore.kernel.org/r/20240329215812.537846-4-namhyung@kernel.org\nSigned-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>\n', '']",The commit refactors the code by splitting disassembly logic from util/annotate.c into util/disasm.c for better maintainability.,"refactor, disassembly, annotate",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
09d2056efe0c02b7a589915c004c6e925735d081,09d2056efe0c02b7a589915c004c6e925735d081,Yang Jihong,yangjihong@bytedance.com,1711952844,Arnaldo Carvalho de Melo,acme@redhat.com,1712155736,502d6ae05ac14c9da2391f6c0b609b713e34e08d,6e4b398770d5023eb6383da9360a23bd537c155b,"perf evsel: Use evsel__name_is() helper

Code cleanup", replace strcmp(evsel__name(evsel,"[' {NAME})) with\nevsel__name_is() helper.\n\nNo functional change.\n\nCommitter notes:\n\nFix this build error:\n\n          trace.syscalls.events.bpf_output = evlist__last(trace.evlist);\n  -       assert(evsel__name_is(trace.syscalls.events.bpf_output)', ' ""__augmented_syscalls__"");\n  +       assert(evsel__name_is(trace.syscalls.events.bpf_output', ' ""__augmented_syscalls__""));\n\nReviewed-by: Ian Rogers <irogers@google.com>\nSigned-off-by: Yang Jihong <yangjihong@bytedance.com>\nCc: Adrian Hunter <adrian.hunter@intel.com>\nCc: Alexander Shishkin <alexander.shishkin@linux.intel.com>\nCc: Ingo Molnar <mingo@redhat.com>\nCc: James Clark <james.clark@arm.com>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: Kan Liang <kan.liang@linux.intel.com>\nCc: Mark Rutland <mark.rutland@arm.com>\nCc: Namhyung Kim <namhyung@kernel.org>\nCc: Peter Zijlstra <peterz@infradead.org>\nLink: https://lore.kernel.org/r/20240401062724.1006010-3-yangjihong@bytedance.com\nSigned-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>\n', '']",The commit refactors code by replacing `strcmp` with the `evsel__name_is()` helper for improved code readability.,"perf, evsel, helper",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The JIT compiler,"[""It's not related to any of the above.""]"
c53908b254fcf25b05bcdf6634adb36eaccac111,c53908b254fcf25b05bcdf6634adb36eaccac111,Tushar Vyavahare,tushar.vyavahare@intel.com,1712058329,Daniel Borkmann,daniel@iogearbox.net,1712153054,a122671ae8298b2f23d3f86ebd86a878260648ff,c4f960539fae6f04617d3909cc0dfdb88e7d197b,"selftests/xsk: Add new test case for AF_XDP under max ring sizes

Introduce a test case to evaluate AF_XDP's robustness by pushing hardware
and software ring sizes to their limits. This test ensures AF_XDP's
reliability amidst potential producer/consumer throttling due to maximum
ring utilization. The testing strategy includes:

1. Configuring rings to their maximum allowable sizes.
2. Executing a series of tests across diverse batch sizes to assess
   system's behavior under different configurations.

Signed-off-by: Tushar Vyavahare <tushar.vyavahare@intel.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Magnus Karlsson <magnus.karlsson@intel.com>
Link: https://lore.kernel.org/bpf/20240402114529.545475-8-tushar.vyavahare@intel.com
",,A new test case evaluates AF_XDP's robustness under maximum ring sizes in selftests.,"AF_XDP, test case, ring sizes",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
c4f960539fae6f04617d3909cc0dfdb88e7d197b,c4f960539fae6f04617d3909cc0dfdb88e7d197b,Tushar Vyavahare,tushar.vyavahare@intel.com,1712058328,Daniel Borkmann,daniel@iogearbox.net,1712153045,95210b92842cde8f016bb3c017ffe0ed546dc1da,776021e07fd0d7592c767e60929b954e82676186,"selftests/xsk: Test AF_XDP functionality under minimal ring configurations

Add a new test case that stresses AF_XDP and the driver by configuring
small hardware and software ring sizes. This verifies that AF_XDP continues
to function properly even with insufficient ring space that could lead
to frequent producer/consumer throttling. The test procedure involves:

1. Set the minimum possible ring configuration(tx 64 and rx 128).
2. Run tests with various batch sizes(1 and 63) to validate the system's
   behavior under different configurations.

Update Makefile to include network_helpers.o in the build process for
xskxceiver.

Signed-off-by: Tushar Vyavahare <tushar.vyavahare@intel.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Magnus Karlsson <magnus.karlsson@intel.com>
Link: https://lore.kernel.org/bpf/20240402114529.545475-7-tushar.vyavahare@intel.com
",,Adds a test for AF_XDP functionality under minimal ring configurations by updating Makefile and testing with various batch sizes.,"AF_XDP,minimal ring,test case",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"[""It's not related to any of the above.""]"
776021e07fd0d7592c767e60929b954e82676186,776021e07fd0d7592c767e60929b954e82676186,Tushar Vyavahare,tushar.vyavahare@intel.com,1712058327,Daniel Borkmann,daniel@iogearbox.net,1712153037,cf116fab1b4f5ca6f3aa7e25c7b2fae5c8c6c592,bee3a7b07624223526c1fea465557068546d3b3c,"selftests/xsk: Introduce set_ring_size function with a retry mechanism for handling AF_XDP socket closures

Introduce a new function", set_ring_size(),"[' to manage asynchronous AF_XDP\nsocket closure. Retry set_hw_ring_size up to SOCK_RECONF_CTR times if it\nfails due to an active AF_XDP socket. Return an error immediately for\nnon-EBUSY errors. This enhances robustness against asynchronous AF_XDP\nsocket closures during ring size changes.\n\nSigned-off-by: Tushar Vyavahare <tushar.vyavahare@intel.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Magnus Karlsson <magnus.karlsson@intel.com>\nLink: https://lore.kernel.org/bpf/20240402114529.545475-6-tushar.vyavahare@intel.com\n', '']",Introduce a set_ring_size function with retry mechanism for AF_XDP socket closures in selftests.,"set_ring_size,retry mechanism,AF_XDP",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
bee3a7b07624223526c1fea465557068546d3b3c,bee3a7b07624223526c1fea465557068546d3b3c,Tushar Vyavahare,tushar.vyavahare@intel.com,1712058326,Daniel Borkmann,daniel@iogearbox.net,1712153033,6b531c2c32d8b9a061a3f071eddf24f810c05287,90a695c3d31e1c9f0adb8c4c80028ed4ea7ed5ab,"selftests/bpf: Implement set_hw_ring_size function to configure interface ring size

Introduce a new function called set_hw_ring_size that allows for the
dynamic configuration of the ring size within the interface.

Signed-off-by: Tushar Vyavahare <tushar.vyavahare@intel.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Magnus Karlsson <magnus.karlsson@intel.com>
Link: https://lore.kernel.org/bpf/20240402114529.545475-5-tushar.vyavahare@intel.com
",,Implement set_hw_ring_size function to adjust interface ring size dynamically.,"set_hw_ring_size, interface, ring size",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
90a695c3d31e1c9f0adb8c4c80028ed4ea7ed5ab,90a695c3d31e1c9f0adb8c4c80028ed4ea7ed5ab,Tushar Vyavahare,tushar.vyavahare@intel.com,1712058325,Daniel Borkmann,daniel@iogearbox.net,1712153017,40812917dd304d100179d6e8e8b63f292ed5d0c4,c3bd015090f24dcd2e839db1401e948ad95ce803,"selftests/bpf: Implement get_hw_ring_size function to retrieve current and max interface size

Introduce a new function called get_hw_size that retrieves both the
current and maximum size of the interface and stores this information
in the 'ethtool_ringparam' structure.

Remove ethtool_channels struct from xdp_hw_metadata.c due to redefinition
error. Remove unused linux/if.h include from flow_dissector BPF test to
address CI pipeline failure.

Signed-off-by: Tushar Vyavahare <tushar.vyavahare@intel.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Magnus Karlsson <magnus.karlsson@intel.com>
Link: https://lore.kernel.org/bpf/20240402114529.545475-4-tushar.vyavahare@intel.com
",,Implemented get_hw_ring_size function in BPF selftests to manage interface size configurations and resolved CI-related issues.,"get_hw_ring_size, ethtool_ringparam, selftests",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['xdp like programs', 'tc/netfilter like programs']"
c3bd015090f24dcd2e839db1401e948ad95ce803,c3bd015090f24dcd2e839db1401e948ad95ce803,Tushar Vyavahare,tushar.vyavahare@intel.com,1712058324,Daniel Borkmann,daniel@iogearbox.net,1712152857,778b04e30d8b6a1e4f71f4a5bb13fd811b567dcc,7effe3fdc049a34c56a68671100b5570e53e8f0a,"selftests/xsk: Make batch size variable

Convert the constant BATCH_SIZE into a variable named batch_size to allow
dynamic modification at runtime. This is required for the forthcoming
changes to support testing different hardware ring sizes.

While running these tests"," a bug was identified when the batch size is
roughly the same as the NIC ring size. This has now been addressed by
Maciej's fix in commit 913eda2b08cc (""i40e: xsk: remove count_mask"").

Signed-off-by: Tushar Vyavahare <tushar.vyavahare@intel.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Magnus Karlsson <magnus.karlsson@intel.com>
Link: https://lore.kernel.org/bpf/20240402114529.545475-3-tushar.vyavahare@intel.com
",[''],This commit changes the BATCH_SIZE constant to a variable to support dynamic modification for testing different hardware ring sizes.,"batch_size,dynamic,testing",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
7effe3fdc049a34c56a68671100b5570e53e8f0a,7effe3fdc049a34c56a68671100b5570e53e8f0a,Tushar Vyavahare,tushar.vyavahare@intel.com,1712058323,Daniel Borkmann,daniel@iogearbox.net,1712152814,779ab1f73061340d368ae8a95eaf7a8f45227b01,49b73fa623c47302befecba0c2c310739ed0a088,"tools: Add ethtool.h header to tooling infra

This commit duplicates the ethtool.h file from the include/uapi/linux
directory in the kernel source to the tools/include/uapi/linux directory.

This action ensures that the ethtool.h file used in the tools directory
is in sync with the kernel's version"," maintaining consistency across the
codebase.

There are some checkpatch warnings in this file that could be cleaned up","['\nbut I preferred to move it over as-is for now to avoid disrupting the code.\n\nSigned-off-by: Tushar Vyavahare <tushar.vyavahare@intel.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Magnus Karlsson <magnus.karlsson@intel.com>\nLink: https://lore.kernel.org/bpf/20240402114529.545475-2-tushar.vyavahare@intel.com\n', '']",Duplicate ethtool.h header to sync tools with kernel version.,"ethtool,sync,header",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
49b73fa623c47302befecba0c2c310739ed0a088,49b73fa623c47302befecba0c2c310739ed0a088,Alexei Starovoitov,ast@kernel.org,1712112350,Alexei Starovoitov,ast@kernel.org,1712112351,a4016b11eba0c4d9f47f5ad4e3a0c327a50d0b66,c07b4bcd5163c2929d8bfc55140325fc15afb4eb 4dd31243e30843d5f63bccfb0369146e4de1a130,"Merge branch 'bpf-arm64-add-support-for-bpf-arena'

Puranjay Mohan says:

====================
bpf","arm64: Add support for BPF Arena

Changes in V4
V3: https://lore.kernel.org/bpf/20240323103057.26499-1-puranjay12@gmail.com/
- Use more descriptive variable names.
- Use insn_is_cast_user() helper.

Changes in V3
V2: https://lore.kernel.org/bpf/20240321153102.103832-1-puranjay12@gmail.com/
- Optimize bpf_addr_space_cast as suggested by Xu Kuohai

Changes in V2
V1: https://lore.kernel.org/bpf/20240314150003.123020-1-puranjay12@gmail.com/
- Fix build warnings by using 5 in place of 32 as DONT_CLEAR marker.
  R5 is not mapped to any BPF register so it can safely be used here.

This series adds the support for PROBE_MEM32 and bpf_addr_space_cast
instructions to the ARM64 BPF JIT. These two instructions allow the
enablement of BPF Arena.

All arena related selftests are passing.

  [root@ip-172-31-6-62 bpf]# ./test_progs -a ""*arena*""
  #3/1     arena_htab/arena_htab_llvm:OK
  #3/2     arena_htab/arena_htab_asm:OK
  #3       arena_htab:OK
  #4/1     arena_list/arena_list_1:OK
  #4/2     arena_list/arena_list_1000:OK
  #4       arena_list:OK
  #434/1   verifier_arena/basic_alloc1:OK
  #434/2   verifier_arena/basic_alloc2:OK
  #434/3   verifier_arena/basic_alloc3:OK
  #434/4   verifier_arena/iter_maps1:OK
  #434/5   verifier_arena/iter_maps2:OK
  #434/6   verifier_arena/iter_maps3:OK
  #434     verifier_arena:OK
  Summary: 3/10 PASSED","[' 0 SKIPPED', ' 0 FAILED\n\nThis will need the patch [1] that introduced insn_is_cast_user() helper to\nbuild.\n\nThe verifier_arena selftest could fail in the CI because the following\ncommit[2] is missing from bpf-next:\n\n[1] https://lore.kernel.org/bpf/20240324183226.29674-1-puranjay12@gmail.com/\n[2] https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf.git/commit/?id=fa3550dca8f02ec312727653a94115ef3ab68445\n\nHere is a CI run with all dependencies added: https://github.com/kernel-patches/bpf/pull/6641\n====================\n\nLink: https://lore.kernel.org/r/20240325150716.4387-1-puranjay12@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit merges support for BPF Arena into the ARM64 BPF JIT with successful selftests.,"BPF Arena, ARM64, JIT",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4dd31243e30843d5f63bccfb0369146e4de1a130,4dd31243e30843d5f63bccfb0369146e4de1a130,Puranjay Mohan,puranjay12@gmail.com,1711379236,Alexei Starovoitov,ast@kernel.org,1712112350,a4016b11eba0c4d9f47f5ad4e3a0c327a50d0b66,339af577ec05c8fc0b96f23579614ae853d913ab,"bpf: Add arm64 JIT support for bpf_addr_space_cast instruction.

LLVM generates bpf_addr_space_cast instruction while translating
pointers between native (zero) address space and
__attribute__((address_space(N))). The addr_space=0 is reserved as
bpf_arena address space.

rY = addr_space_cast(rX", 0,"[' 1) is processed by the verifier and\nconverted to normal 32-bit move: wX = wY.\n\nrY = addr_space_cast(rX', ' 1', ' 0) : used to convert a bpf arena pointer to\na pointer in the userspace vma. This has to be converted by the JIT.\n\nSigned-off-by: Puranjay Mohan <puranjay12@gmail.com>\nLink: https://lore.kernel.org/r/20240325150716.4387-3-puranjay12@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add ARM64 JIT support for the bpf_addr_space_cast instruction.,"ARM64,JIT,bpf_addr_space_cast",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
339af577ec05c8fc0b96f23579614ae853d913ab,339af577ec05c8fc0b96f23579614ae853d913ab,Puranjay Mohan,puranjay12@gmail.com,1711379235,Alexei Starovoitov,ast@kernel.org,1712112350,55a6bd47a5ec69990897fd482941a0a27b2cb78a,c07b4bcd5163c2929d8bfc55140325fc15afb4eb,"bpf: Add arm64 JIT support for PROBE_MEM32 pseudo instructions.

Add support for [LDX | STX | ST]", PROBE_MEM32,"[' [B | H | W | DW]\ninstructions.  They are similar to PROBE_MEM instructions with the\nfollowing differences:\n- PROBE_MEM32 supports store.\n- PROBE_MEM32 relies on the verifier to clear upper 32-bit of the\n  src/dst register\n- PROBE_MEM32 adds 64-bit kern_vm_start address (which is stored in R28\n  in the prologue). Due to bpf_arena constructions such R28 + reg +\n  off16 access is guaranteed to be within arena virtual range', ' so no\n  address check at run-time.\n- PROBE_MEM32 allows STX and ST. If they fault the store is a nop. When\n  LDX faults the destination register is zeroed.\n\nTo support these on arm64', ' we do tmp2 = R28 + src/dst reg and then use\ntmp2 as the new src/dst register. This allows us to reuse most of the\ncode for normal [LDX | STX | ST].\n\nSigned-off-by: Puranjay Mohan <puranjay12@gmail.com>\nLink: https://lore.kernel.org/r/20240325150716.4387-2-puranjay12@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Added support for arm64 JIT for PROBE_MEM32 pseudo instructions in eBPF.,"arm64,JIT,PROBE_MEM32",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c07b4bcd5163c2929d8bfc55140325fc15afb4eb,c07b4bcd5163c2929d8bfc55140325fc15afb4eb,Geliang Tang,tanggeliang@kylinos.cn,1712055021,Andrii Nakryiko,andrii@kernel.org,1712077549,44f98f800a59f3e4ac212a4041c41e7204a4fd82,15ea39ad7e83af16480bbf20144fcc6edf4757f9,"selftests/bpf: Add pid limit for mptcpify prog

In order to prevent mptcpify prog from affecting the running results
of other BPF tests"," a pid limit was added to restrict it from only
modifying its own program.

Suggested-by: Martin KaFai Lau <martin.lau@kernel.org>
Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/8987e2938e15e8ec390b85b5dcbee704751359dc.1712054986.git.tanggeliang@kylinos.cn
",[''],Added a pid limit to mptcpify program to prevent interference with other BPF tests.,"pid limit, mptcpify, selftests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
15ea39ad7e83af16480bbf20144fcc6edf4757f9,15ea39ad7e83af16480bbf20144fcc6edf4757f9,Tobias Böhm,tobias@aibor.de,1712070652,Andrii Nakryiko,andrii@kernel.org,1712075314,15c6baaf38cce92073869dad56108d7a1255a2e1,ce09cbdd988887662546a1175bcfdfc6c8fdd150,"libbpf: Use local bpf_helpers.h include

Commit 20d59ee55172fdf6 (""libbpf: add bpf_core_cast() macro"") added a
bpf_helpers include in bpf_core_read.h as a system include. Usually"," the
includes are local","[' though', ' like in bpf_tracing.h. This commit adjusts\nthe include to be local as well.\n\nSigned-off-by: Tobias Böhm <tobias@aibor.de>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/q5d5bgc6vty2fmaazd5e73efd6f5bhiru2le6fxn43vkw45bls@fhlw2s5ootdb\n', '']",Change the inclusion of bpf_helpers.h to a local include in libbpf.,"local, bpf_helpers, include",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ce09cbdd988887662546a1175bcfdfc6c8fdd150,ce09cbdd988887662546a1175bcfdfc6c8fdd150,Jose Fernandez,josef@netflix.com,1712029210,Daniel Borkmann,daniel@iogearbox.net,1712069475,13d5602cfc7f3f1463cb88f05adbecd2a6709b3c,c186ed12a8ec498532d13de43094bdec9ac6f121,"bpf: Improve program stats run-time calculation

This patch improves the run-time calculation for program stats by
capturing the duration as soon as possible after the program returns.

Previously"," the duration included u64_stats_t operations. While the
instrumentation overhead is part of the total time spent when stats are
enabled","["" distinguishing between the program's native execution time and\nthe time spent due to instrumentation is crucial for accurate\nperformance analysis.\n\nBy making this change"", ' the patch facilitates more precise optimization\nof BPF programs', ' enabling users to understand their performance in\nenvironments without stats enabled.\n\nI used a virtualized environment to measure the run-time over one minute\nfor a basic raw_tracepoint/sys_enter program', ' which just increments a\nlocal counter. Although the virtualization introduced some performance\ndegradation that could affect the results', ' I observed approximately a\n16% decrease in average run-time reported by stats with this change\n(310 -> 260 nsec).\n\nSigned-off-by: Jose Fernandez <josef@netflix.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240402034010.25060-1-josef@netflix.com\n', '']",Improve run-time calculation by capturing program stats duration earlier.,"run-time,program,stats",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ff91059932401894e6c86341915615c5eb0eca48,ff91059932401894e6c86341915615c5eb0eca48,Jakub Sitnicki,jakub@cloudflare.com,1712054781,Daniel Borkmann,daniel@iogearbox.net,1712068265,2a7b401e3f18c6df1de80a3833228250aaaa9211,8c3fe029d79ada599fa558fdf3da0322fc38de36,bpf," sockmap: Prevent lock inversion deadlock in map delete elem

syzkaller started using corpuses where a BPF tracing program deletes
elements from a sockmap/sockhash map. Because BPF tracing programs can be
invoked from any interrupt context","[' locks taken during a map_delete_elem\noperation must be hardirq-safe. Otherwise a deadlock due to lock inversion\nis possible', ' as reported by lockdep:\n\n       CPU0                    CPU1\n       ----                    ----\n  lock(&htab->buckets[i].lock);\n                               local_irq_disable();\n                               lock(&host->lock);\n                               lock(&htab->buckets[i].lock);\n  <Interrupt>\n    lock(&host->lock);\n\nLocks in sockmap are hardirq-unsafe by design. We expects elements to be\ndeleted from sockmap/sockhash only in task (normal) context with interrupts\nenabled', ' or in softirq context.\n\nDetect when map_delete_elem operation is invoked from a context which is\n_not_ hardirq-unsafe', ' that is interrupts are disabled', ' and bail out with an\nerror.\n\nNote that map updates are not affected by this issue. BPF verifier does not\nallow updating sockmap/sockhash from a BPF tracing program today.\n\nFixes: 604326b41a6f (""bpf', ' sockmap: convert to generic sk_msg interface"")\nReported-by: xingwei lee <xrivendell7@gmail.com>\nReported-by: yue sun <samsun1006219@gmail.com>\nReported-by: syzbot+bc922f476bd65abbd466@syzkaller.appspotmail.com\nReported-by: syzbot+d4066896495db380182e@syzkaller.appspotmail.com\nSigned-off-by: Jakub Sitnicki <jakub@cloudflare.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: syzbot+d4066896495db380182e@syzkaller.appspotmail.com\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nCloses: https://syzkaller.appspot.com/bug?extid=d4066896495db380182e\nCloses: https://syzkaller.appspot.com/bug?extid=bc922f476bd65abbd466\nLink: https://lore.kernel.org/bpf/20240402104621.1050319-1-jakub@cloudflare.com\n', '']",Prevent lock inversion deadlock in sockmap/sockhash map element deletion by BPF tracing programs.,"lock inversion, deadlock, sockmap",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c186ed12a8ec498532d13de43094bdec9ac6f121,c186ed12a8ec498532d13de43094bdec9ac6f121,Pu Lehui,pulehui@huawei.com,1712043029,Daniel Borkmann,daniel@iogearbox.net,1712068168,cd4e4d266cd85e9425e0b06d47598187f30bbc1c,2a24e2485722b0e12e17a2bd473bd15c9e420bdb,"selftests/bpf: Skip test when perf_event_open returns EOPNOTSUPP

When testing send_signal and stacktrace_build_id_nmi using the riscv sbi
pmu driver without the sscofpmf extension or the riscv legacy pmu driver","
then failures as follows are encountered:

    test_send_signal_common:FAIL:perf_event_open unexpected perf_event_open: actual -1 < expected 0
    #272/3   send_signal/send_signal_nmi:FAIL

    test_stacktrace_build_id_nmi:FAIL:perf_event_open err -1 errno 95
    #304     stacktrace_build_id_nmi:FAIL

The reason is that the above pmu driver or hardware does not support
sampling events","[' that is', ' PERF_PMU_CAP_NO_INTERRUPT is set to pmu\ncapabilities', ' and then perf_event_open returns EOPNOTSUPP. Since\nPERF_PMU_CAP_NO_INTERRUPT is not only set in the riscv-related pmu driver', '\nit is better to skip testing when this capability is set.\n\nSigned-off-by: Pu Lehui <pulehui@huawei.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240402073029.1299085-1-pulehui@huaweicloud.com\n', '']",The commit modifies test scripts to skip tests when perf_event_open returns EOPNOTSUPP due to unsupported sampling events in certain RISC-V configurations.,"selftests,bpf,EOPNOTSUPP",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
2a24e2485722b0e12e17a2bd473bd15c9e420bdb,2a24e2485722b0e12e17a2bd473bd15c9e420bdb,Andrii Nakryiko,andrii@kernel.org,1711991233,Daniel Borkmann,daniel@iogearbox.net,1712067649,16ee10833bd56cd22649735060b9f810510a5526,965c6167c93f3fac53e25807f83c07e87b3c085a,"bpftool: Use __typeof__() instead of typeof() in BPF skeleton

When generated BPF skeleton header is included in C++ code base"," some
compiler setups will emit warning about using language extensions due to
typeof() usage","[' resulting in something like:\n\n  error: extension used [-Werror', '-Wlanguage-extension-token]\n  obj->struct_ops.empty_tcp_ca = (typeof(obj->struct_ops.empty_tcp_ca))\n                                  ^\n\nIt looks like __typeof__() is a preferred way to do typeof() with better\nC++ compatibility behavior', ' so switch to that. With __typeof__() we get\nno such warning.\n\nFixes: c2a0257c1edf (""bpftool: Cast pointers for shadow types explicitly."")\nFixes: 00389c58ffe9 (""bpftool: Add support for subskeletons"")\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Kui-Feng Lee <thinker.li@gmail.com>\nAcked-by: Quentin Monnet <qmo@kernel.org>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nLink: https://lore.kernel.org/bpf/20240401170713.2081368-1-andrii@kernel.org\n', '']",Replaces typeof() with __typeof__() in BPF skeleton to avoid compiler warnings in C++ code.,"bpftool, compiler, BPF",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"['tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
965c6167c93f3fac53e25807f83c07e87b3c085a,965c6167c93f3fac53e25807f83c07e87b3c085a,Yonghong Song,yonghong.song@linux.dev,1712026486,Daniel Borkmann,daniel@iogearbox.net,1712067240,611ec4261565516c148aa485c4517b7af8c179fe,9dc182c58b5f5d4ac125ac85ad553f7142aa08d4,"selftests/bpf: Using llvm may_goto inline asm for cond_break macro

Currently"," cond_break macro uses bytes to encode the may_goto insn.
Patch [1] in llvm implemented may_goto insn in BPF backend.
Replace byte-level encoding with llvm inline asm for better usability.
Using llvm may_goto insn is controlled by macro __BPF_FEATURE_MAY_GOTO.

  [1] https://github.com/llvm/llvm-project/commit/0e0bfacff71859d1f9212205f8f873d47029d3fb

Signed-off-by: Yonghong Song <yonghong.song@linux.dev>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/bpf/20240402025446.3215182-1-yonghong.song@linux.dev
",[''],The commit updates the cond_break macro to use llvm inline assembly for better usability.,"llvm, inline asm, may_goto",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"[""It's not related to any of the above.""]"
9dc182c58b5f5d4ac125ac85ad553f7142aa08d4,9dc182c58b5f5d4ac125ac85ad553f7142aa08d4,Anton Protopopov,aspsk@isovalent.com,1712043227,Daniel Borkmann,daniel@iogearbox.net,1712067120,71232931a9632e6e627d99f63d2b54e19fcabc69,ca4ddc26f8acaa9cb451fcb20f7ab0f02e4970cb,"bpf: Add a verbose message if map limit is reached

When more than 64 maps are used by a program and its subprograms the
verifier returns -E2BIG. Add a verbose message which highlights the
source of the error and also print the actual limit.

Signed-off-by: Anton Protopopov <aspsk@isovalent.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/bpf/20240402073347.195920-1-aspsk@isovalent.com
",,Adds a verbose message for map limit exceeded errors in the bpf verifier.,"verbose, verifier, maps",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ca4ddc26f8acaa9cb451fcb20f7ab0f02e4970cb,ca4ddc26f8acaa9cb451fcb20f7ab0f02e4970cb,David Lechner,dlechner@baylibre.com,1711726126,Daniel Borkmann,daniel@iogearbox.net,1712066674,0dbbbebbd2e666ccda3a868dc15c52d3e70282a7,a70f5d840a56a82c576385ca79ee55c1598f1bc3,"bpf: Fix typo in uapi doc comments

In a few places in the bpf uapi headers"," EOPNOTSUPP is missing a ""P"" in
the doc comments. This adds the missing ""P"".

Signed-off-by: David Lechner <dlechner@baylibre.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240329152900.398260-2-dlechner@baylibre.com
",[''],"Fixed a typo in the bpf uapi doc comments by adding a missing ""P"".","bpf, typo, doc comments",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The syscall interface,"[""It's not related to any of the above.""]"
a70f5d840a56a82c576385ca79ee55c1598f1bc3,a70f5d840a56a82c576385ca79ee55c1598f1bc3,Rameez Rehman,rameezrehman408@hotmail.com,1711915426,Daniel Borkmann,daniel@iogearbox.net,1712065823,88b41a8bc9a8f29aec36b5efb160603e5cec0a01,ea379b3ccc2e4dff9c3d616f0611b5312fe389ad,bpftool: Clean-up typos, punctuation,"[' list formatting in docs\n\nImprove the formatting of the attach flags for cgroup programs in the\nrelevant man page', ' and fix typos (""can be on of""', ' ""an userspace inet\nsocket"") when introducing that list. Also fix a couple of other trivial\nissues in docs.\n\n[ Quentin: Fixed trival issues in bpftool-gen.rst and bpftool-iter.rst ]\n\nSigned-off-by: Rameez Rehman <rameezrehman408@hotmail.com>\nSigned-off-by: Quentin Monnet <qmo@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240331200346.29118-4-qmo@kernel.org\n', '']",The commit cleans up typographical errors in the bpftool utility.,"bpftool,cleanup,typos",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"[""It's not related to any of the above.""]"
ea379b3ccc2e4dff9c3d616f0611b5312fe389ad,ea379b3ccc2e4dff9c3d616f0611b5312fe389ad,Rameez Rehman,rameezrehman408@hotmail.com,1711915425,Daniel Borkmann,daniel@iogearbox.net,1712065823,8c6af315030eb6a793a2cb362711322c14a05f35,f7b68543642136164ce7348945d3ada707c4e635,"bpftool: Remove useless emphasis on command description in man pages

As it turns out"," the terms in definition lists in the rST file are
already rendered with bold-ish formatting when generating the man pages;
all double-star sequences we have in the commands for the command
description are unnecessary","["" and can be removed to make the\ndocumentation easier to read.\n\nThe rST files were automatically processed with:\n\n    sed -i '/DESCRIPTION/"", ""/OPTIONS/ { /^\\*/ s/\\*\\*//g }' b*.rst\n\nSigned-off-by: Rameez Rehman <rameezrehman408@hotmail.com>\nSigned-off-by: Quentin Monnet <qmo@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240331200346.29118-3-qmo@kernel.org\n"", '']",This commit removes unnecessary bold formatting from command descriptions in bpftool man pages.,"bpftool,man pages,formatting",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"[""It's not related to any of the above.""]"
f7b68543642136164ce7348945d3ada707c4e635,f7b68543642136164ce7348945d3ada707c4e635,Rameez Rehman,rameezrehman408@hotmail.com,1711915424,Daniel Borkmann,daniel@iogearbox.net,1712065823,2505ca965a9fed991aacf0086b220d3d41d15825,623bdd58be3727318d374f0052f9dfff1e87b854,"bpftool: Use simpler indentation in source rST for documentation

The rST manual pages for bpftool would use a mix of tabs and spaces for
indentation. While this is the norm in C code"," this is rather unusual
for rST documents","["" and over time we've seen many contributors use a\nwrong level of indentation for documentation update.\n\nLet's fix bpftool's indentation in docs once and for all:\n\n- Let's use spaces"", ' that are more common in rST files.\n- Remove one level of indentation for the synopsis', ' the command\n  description', ' and the ""see also"" section. As a result', ' all sections\n  start with the same indentation level in the generated man page.\n- Rewrap the paragraphs after the changes.\n\nThere is no content change in this patch', ' only indentation and\nrewrapping changes. The wrapping in the generated source files for the\nmanual pages is changed', ' but the pages displayed with ""man"" remain the\nsame', ' apart from the adjusted indentation level on relevant sections.\n\n[ Quentin: rebased on bpf-next', ' removed indent level for command\n  description and options', ' updated synopsis', ' command summary', ' and ""see\n  also"" sections. ]\n\nSigned-off-by: Rameez Rehman <rameezrehman408@hotmail.com>\nSigned-off-by: Quentin Monnet <qmo@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240331200346.29118-2-qmo@kernel.org\n', '']",Simplified indentation in bpftool's rST documentation by standardizing to spaces.,"bpftool, rST, indentation",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"[""It's not related to any of the above.""]"
fcf4692fa39e86a590c14a4af2de704e1d20a3b5,fcf4692fa39e86a590c14a4af2de704e1d20a3b5,Paolo Abeni,pabeni@redhat.com,1711738236,Jakub Kicinski,kuba@kernel.org,1712029404,b8333ea8be6d6127cc159ac2d89e1ef979ccf2d7,31974122cfdeaf56abc18d8ab740d580d9833e90,"mptcp: prevent BPF accessing lowat from a subflow socket.

Alexei reported the following splat:

 WARNING: CPU: 32 PID: 3276 at net/mptcp/subflow.c:1430 subflow_data_ready+0x147/0x1c0
 Modules linked in: dummy bpf_testmod(O) [last unloaded: bpf_test_no_cfi(O)]
 CPU: 32 PID: 3276 Comm: test_progs Tainted: GO       6.8.0-12873-g2c43c33bfd23
 Call Trace:
  <TASK>
  mptcp_set_rcvlowat+0x79/0x1d0
  sk_setsockopt+0x6c0/0x1540
  __bpf_setsockopt+0x6f/0x90
  bpf_sock_ops_setsockopt+0x3c/0x90
  bpf_prog_509ce5db2c7f9981_bpf_test_sockopt_int+0xb4/0x11b
  bpf_prog_dce07e362d941d2b_bpf_test_socket_sockopt+0x12b/0x132
  bpf_prog_348c9b5faaf10092_skops_sockopt+0x954/0xe86
  __cgroup_bpf_run_filter_sock_ops+0xbc/0x250
  tcp_connect+0x879/0x1160
  tcp_v6_connect+0x50c/0x870
  mptcp_connect+0x129/0x280
  __inet_stream_connect+0xce/0x370
  inet_stream_connect+0x36/0x50
  bpf_trampoline_6442491565+0x49/0xef
  inet_stream_connect+0x5/0x50
  __sys_connect+0x63/0x90
  __x64_sys_connect+0x14/0x20

The root cause of the issue is that bpf allows accessing mptcp-level
proto_ops from a tcp subflow scope.

Fix the issue detecting the problematic call and preventing any action.

Reported-by: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Closes: https://github.com/multipath-tcp/mptcp_net-next/issues/482
Fixes: 5684ab1a0eff (""mptcp: give rcvlowat some love"")
Signed-off-by: Paolo Abeni <pabeni@redhat.com>
Reviewed-by: Mat Martineau <martineau@kernel.org>
Reviewed-by: Matthieu Baerts (NGI0) <matttbe@kernel.org>
Link: https://lore.kernel.org/r/d8cb7d8476d66cb0812a6e29cd1e626869d9d53e.1711738080.git.pabeni@redhat.com
Signed-off-by: Jakub Kicinski <kuba@kernel.org>
",,Fix to prevent BPF from accessing lowat from a subflow socket in MPTCP.,"MPTCP,BPF,lowat",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['socket like programs']
8c3fe029d79ada599fa558fdf3da0322fc38de36,8c3fe029d79ada599fa558fdf3da0322fc38de36,Alexei Starovoitov,ast@kernel.org,1712029076,Alexei Starovoitov,ast@kernel.org,1712029077,69ebdb5ddaa504511a9b2f1e327246b1591ba08e,6dae957c8eef6eae5b386462767de97303235d5c 6a537453000a916392fcac1acb96c1d9d1e05b74,"Merge branch 'x86-bpf-fixes-for-the-bpf-jit-with-retbleed-stuff'

Joan Bruguera Micó says:

====================
x86/bpf: Fixes for the BPF JIT with retbleed=stuff

From: Joan Bruguera Micó <joanbrugueram@gmail.com>

Fixes two issues that cause kernels panic when using the BPF JIT with
the call depth tracking / stuffing mitigation for Skylake processors
(`retbleed=stuff`). Both issues can be triggered by running simple
BPF programs (e.g. running the test suite should trigger both).

The first (resubmit) fixes a trivial issue related to calculating the
destination IP for call instructions with call depth tracking.

The second is related to using the correct IP for relocations"," related
to the recently introduced %rip-relative addressing for PER_CPU_VAR.

Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
---
v2:
  Simplify calculation of ""ip"".
  Add more details to the commit message.

Joan Bruguera Micó (1):
  x86/bpf: Fix IP for relocating call depth accounting
====================

Link: https://lore.kernel.org/r/20240401185821.224068-1-ubizjak@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Fixes issues causing kernel crashes when using BPF JIT with retbleed mitigation on Skylake processors.,"BPF JIT, retbleed, Skylake",It's a bug fix.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6a537453000a916392fcac1acb96c1d9d1e05b74,6a537453000a916392fcac1acb96c1d9d1e05b74,Joan Bruguera Micó,joanbrugueram@gmail.com,1711997730,Alexei Starovoitov,ast@kernel.org,1712029076,69ebdb5ddaa504511a9b2f1e327246b1591ba08e,9d98aa088386aee3db1b7b60b800c0fde0654a4a,"x86/bpf: Fix IP for relocating call depth accounting

The commit:

  59bec00ace28 (""x86/percpu: Introduce %rip-relative addressing to PER_CPU_VAR()"")

made PER_CPU_VAR() to use rip-relative addressing"," hence
INCREMENT_CALL_DEPTH macro and skl_call_thunk_template got rip-relative
asm code inside of it. A follow up commit:

  17bce3b2ae2d (""x86/callthunks: Handle %rip-relative relocations in call thunk template"")

changed x86_call_depth_emit_accounting() to use apply_relocation()","['\nbut mistakenly assumed that the code is being patched in-place (where\nthe destination of the relocation matches the address of the code)', '\nusing *pprog as the destination ip. This is not true for the call depth\naccounting', ' emitted by the BPF JIT', ' so the calculated address was wrong', '\nJIT-ed BPF progs on kernels with call depth tracking got broken and\nusually caused a page fault.\n\nPass the destination IP when the BPF JIT emits call depth accounting.\n\nFixes: 17bce3b2ae2d (""x86/callthunks: Handle %rip-relative relocations in call thunk template"")\nSigned-off-by: Joan Bruguera Micó <joanbrugueram@gmail.com>\nReviewed-by: Uros Bizjak <ubizjak@gmail.com>\nAcked-by: Ingo Molnar <mingo@kernel.org>\nCc: Alexei Starovoitov <ast@kernel.org>\nCc: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/r/20240401185821.224068-3-ubizjak@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix IP alignment in x86 BPF by handling RIP-relative relocations in call depth accounting.,"x86, BPF, relocation",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9d98aa088386aee3db1b7b60b800c0fde0654a4a,9d98aa088386aee3db1b7b60b800c0fde0654a4a,Uros Bizjak,ubizjak@gmail.com,1711997729,Alexei Starovoitov,ast@kernel.org,1712029076,e5317af7b7e8a7384b76a071b5996c98c568e6db,6dae957c8eef6eae5b386462767de97303235d5c,"x86/bpf: Fix IP after emitting call depth accounting

Adjust the IP passed to `emit_patch` so it calculates the correct offset
for the CALL instruction if `x86_call_depth_emit_accounting` emits code.
Otherwise we will skip some instructions and most likely crash.

Fixes: b2e9dfe54be4 (""x86/bpf: Emit call depth accounting if required"")
Link: https://lore.kernel.org/lkml/20230105214922.250473-1-joanbrugueram@gmail.com/
Co-developed-by: Joan Bruguera Micó <joanbrugueram@gmail.com>
Signed-off-by: Joan Bruguera Micó <joanbrugueram@gmail.com>
Signed-off-by: Uros Bizjak <ubizjak@gmail.com>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/r/20240401185821.224068-2-ubizjak@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Fixes instruction pointer offset calculation for x86 BPF call depth accounting.,"IP,call depth,x86",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,['tracepoints like programs']
d29a8134c78232213fb88f20d7ae865ec364e367,d29a8134c78232213fb88f20d7ae865ec364e367,Michal Schmidt,mschmidt@redhat.com,1711408838,Tony Nguyen,anthony.l.nguyen@intel.com,1711987089,290f1daf4c297a3cd23d6a76ca298ea600e8ab5a,0e2bddf9e5f926ce32ed635012d0f8a0b54075d5,"ice: avoid the PTP hardware semaphore in gettimex64 path

The PTP hardware semaphore (PFTSYN_SEM) is used to synchronize
operations that program the PTP timers. The operations involve issuing
commands to the sideband queue. The E810 does not have a hardware
sideband queue"," so the admin queue is used. The admin queue is slow.
I have observed delays in hundreds of milliseconds waiting for
ice_sq_done.

When phc2sys reads the time from the ice PTP clock and PFTSYN_SEM is
held by a task performing one of the slow operations","[' ice_ptp_lock can\neasily time out. phc2sys gets -EBUSY and the kernel prints:\n  ice 0000:XX:YY.0: PTP failed to get time\nThese messages appear once every few seconds', "" causing log spam.\n\nThe E810 datasheet recommends an algorithm for reading the upper 64 bits\nof the GLTSYN_TIME register. It matches what's implemented in\nice_ptp_read_src_clk_reg. It is robust against wrap-around"", ' but not\nnecessarily against the concurrent setting of the register (with\nGLTSYN_CMD_{INIT', 'ADJ}_TIME commands). Perhaps that\'s why\nice_ptp_gettimex64 also takes PFTSYN_SEM.\n\nThe race with time setters can be prevented without relying on the PTP\nhardware semaphore. Using the ""ice_adapter"" from the previous patch', '\nwe can have a common spinlock for the PFs that share the clock hardware.\nIt will protect the reading and writing to the GLTSYN_TIME register.\nThe writing is performed indirectly', ' by the hardware', "" as a result of\nthe driver writing GLTSYN_CMD_SYNC in ice_ptp_exec_tmr_cmd. I wasn't\nsure if the ice_flush there is enough to make sure GLTSYN_TIME has been\nupdated"", ' but it works well in my testing.\n\nMy test code can be seen here:\nhttps://gitlab.com/mschmidt2/linux/-/commits/ice-ptp-host-side-lock-10\nIt consists of:\n - kernel threads reading the time in a busy loop and looking at the\n   deltas between consecutive values', ' reporting new maxima.\n - a shell script that sets the time repeatedly;\n - a bpftrace probe to produce a histogram of the measured deltas.\nWithout the spinlock ptp_gltsyn_time_lock', ' it is easy to see tearing.\nDeltas in the [2G', ' 4G) range appear in the histograms.\nWith the spinlock added', ' there is no tearing and the biggest delta I saw\nwas in the range [1M', ' 2M)', ' that is under 2 ms.\n\nReviewed-by: Jacob Keller <jacob.e.keller@intel.com>\nReviewed-by: Przemek Kitszel <przemyslaw.kitszel@intel.com>\nSigned-off-by: Michal Schmidt <mschmidt@redhat.com>\nTested-by: Pucha Himasekhar Reddy <himasekharx.reddy.pucha@intel.com> (A Contingent worker at Intel)\nSigned-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>\n', '']",Improve gettimex64 path by avoiding PTP hardware semaphore in ice driver to reduce delays.,"PTP hardware, ice driver, semaphore",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
623bdd58be3727318d374f0052f9dfff1e87b854,623bdd58be3727318d374f0052f9dfff1e87b854,Andrii Nakryiko,andrii@kernel.org,1711739050,Alexei Starovoitov,ast@kernel.org,1711757910,4fa897fca4d3678d7fe97924daa9a2c7d1f3ff73,59f2f841179aa6a0899cb9cf53659149a35749b7,"selftests/bpf: make multi-uprobe tests work in RELEASE=1 mode

When BPF selftests are built in RELEASE=1 mode with -O2 optimization
level", uprobe_multi binary,"[' called from multi-uprobe tests is optimized\nto the point that all the thousands of target uprobe_multi_func_XXX\nfunctions are eliminated', ' breaking tests.\n\nSo ensure they are preserved by using weak attribute.\n\nBut', ' actually', ' compiling uprobe_multi binary with -O2 takes a really\nlong time', "" and is quite useless (it's not a benchmark). So in addition\nto ensuring that uprobe_multi_func_XXX functions are preserved"", ' opt-out\nof -O2 explicitly in Makefile and stick to -O0. This saves a lot of\ncompilation time.\n\nWith -O2', ' just recompiling uprobe_multi:\n\n  $ touch uprobe_multi.c\n  $ time make RELEASE=1 -j90\n  make RELEASE=1 -j90  291.66s user 2.54s system 99% cpu 4:55.52 total\n\nWith -O0:\n  $ touch uprobe_multi.c\n  $ time make RELEASE=1 -j90\n  make RELEASE=1 -j90  22.40s user 1.91s system 99% cpu 24.355 total\n\n5 minutes vs (still slow', ' but...) 24 seconds.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240329190410.4191353-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Improve multi-uprobe tests compatibility with RELEASE=1 optimization mode.,"selftests,uprobe,RELEASE",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
59f2f841179aa6a0899cb9cf53659149a35749b7,59f2f841179aa6a0899cb9cf53659149a35749b7,Alexei Starovoitov,ast@kernel.org,1711732479,Andrii Nakryiko,andrii@kernel.org,1711735841,6062529deb60350ea15098e82d721feda3661b6a,201874fc064ef14c26ea87a890b3f58296750d2d,"bpf: Avoid kfree_rcu() under lock in bpf_lpm_trie.

syzbot reported the following lock sequence:
cpu 2:
  grabs timer_base lock
    spins on bpf_lpm lock

cpu 1:
  grab rcu krcp lock
    spins on timer_base lock

cpu 0:
  grab bpf_lpm lock
    spins on rcu krcp lock

bpf_lpm lock can be the same.
timer_base lock can also be the same due to timer migration.
but rcu krcp lock is always per-cpu"," so it cannot be the same lock.
Hence it's a false positive.
To avoid lockdep complaining move kfree_rcu() after spin_unlock.

Reported-by: syzbot+1fa663a2100308ab6eab@syzkaller.appspotmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240329171439.37813-1-alexei.starovoitov@gmail.com
",[''],The commit fixes a lock ordering issue by moving kfree_rcu() outside of the spinlock in bpf_lpm_trie.,"bpf_lpm_trie, lock, kfree_rcu",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,['other']
6dae957c8eef6eae5b386462767de97303235d5c,6dae957c8eef6eae5b386462767de97303235d5c,Anton Protopopov,aspsk@isovalent.com,1711696266,Alexei Starovoitov,ast@kernel.org,1711729195,8f4fc7437c90ad0f729dee0bbeb214ccea6d794e,62248b22d01e96a4d669cde0d7005bd51ebf9e76,"bpf: fix possible file descriptor leaks in verifier

The resolve_pseudo_ldimm64() function might have leaked file
descriptors when BPF_MAP_TYPE_ARENA was used in a program (some
error paths missed a corresponding fdput). Add missing fdputs.

v2:
  remove unrelated changes from the fix

Fixes: 6082b6c328b5 (""bpf: Recognize addr_space_cast instruction in the verifier."")
Signed-off-by: Anton Protopopov <aspsk@isovalent.com>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Acked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>
Link: https://lore.kernel.org/r/20240329071106.67968-1-aspsk@isovalent.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Fixes file descriptor leaks in verifier for BPF_MAP_TYPE_ARENA programs.,"verifier, file descriptors, BPF_MAP_TYPE_ARENA",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
201874fc064ef14c26ea87a890b3f58296750d2d,201874fc064ef14c26ea87a890b3f58296750d2d,Martin KaFai Lau,martin.lau@kernel.org,1711677865,Martin KaFai Lau,martin.lau@kernel.org,1711678335,b1eea389e165399816ff726962efc56e875459ca,e8742081db7d01f980c6161ae1e8a1dbc1e30979 426670929fda4485a23094e03cea5d9b3ca918aa,"Merge branch 'Use start_server and connect_fd_to_fd'

Geliang Tang says:

====================
Simplify bpf_tcp_ca test by using connect_fd_to_fd and start_server
helpers.

v4:
 - Matt reminded me that I shouldn't send a square-to patch to BPF (thanks)","
   so I update them into two patches in v4.

v3:
 - split v2 as two patches as Daniel suggested.
 - The patch ""selftests/bpf: Use start_server in bpf_tcp_ca"" is merged
   by Daniel (thanks)","["" but I forgot to drop 'settimeo(lfd"", "" 0)' in it"", ' so\n   I send a squash-to patch to fix this.\n====================\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Simplify bpf_tcp_ca test using connect_fd_to_fd and start_server helpers.,"simplify, bpf_tcp_ca, helpers",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tc/netfilter like programs']
426670929fda4485a23094e03cea5d9b3ca918aa,426670929fda4485a23094e03cea5d9b3ca918aa,Geliang Tang,tanggeliang@kylinos.cn,1711447419,Martin KaFai Lau,martin.lau@kernel.org,1711678335,b1eea389e165399816ff726962efc56e875459ca,e5e1a3aa56773d55dfb71c4d58176bc19ecfa739,"selftests/bpf: Drop settimeo in do_test

settimeo is invoked in start_server() and in connect_fd_to_fd() already","
no need to invoke settimeo(lfd","[' 0) and settimeo(fd', ' 0) in do_test()\nanymore. This patch drops them.\n\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nLink: https://lore.kernel.org/r/dbc3613bee3b1c78f95ac9ff468bf47c92f106ea.1711447102.git.tanggeliang@kylinos.cn\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Remove unnecessary settimeo invocation from selftests in BPF test suite.,"settimeo,test,removal",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
e5e1a3aa56773d55dfb71c4d58176bc19ecfa739,e5e1a3aa56773d55dfb71c4d58176bc19ecfa739,Geliang Tang,tanggeliang@kylinos.cn,1711447418,Martin KaFai Lau,martin.lau@kernel.org,1711678334,54393377c996ac3fece9b20b2d9cc5c008fac3db,e8742081db7d01f980c6161ae1e8a1dbc1e30979,"selftests/bpf: Use connect_fd_to_fd in bpf_tcp_ca

To simplify the code"," use BPF selftests helper connect_fd_to_fd() in
bpf_tcp_ca.c instead of open-coding it. This helper is defined in
network_helpers.c","[' and exported in network_helpers.h', ' which is already\nincluded in bpf_tcp_ca.c.\n\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nLink: https://lore.kernel.org/r/e105d1f225c643bee838409378dd90fd9aabb6dc.1711447102.git.tanggeliang@kylinos.cn\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Simplifies bpf_tcp_ca selftest by using connect_fd_to_fd helper from network_helpers.,"selftests, connect_fd_to_fd, simplify",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e8742081db7d01f980c6161ae1e8a1dbc1e30979,e8742081db7d01f980c6161ae1e8a1dbc1e30979,Martin KaFai Lau,martin.lau@kernel.org,1711652281,Alexei Starovoitov,ast@kernel.org,1711677659,452aea3442eddfe5248914ebd4680a45759104c2,e478cf26c556e4ab572ab0ab2306c986901dcd61,"bpf: Mark bpf prog stack with kmsan_unposion_memory in interpreter mode

syzbot reported uninit memory usages during map_{lookup","delete}_elem.

==========
BUG: KMSAN: uninit-value in __dev_map_lookup_elem kernel/bpf/devmap.c:441 [inline]
BUG: KMSAN: uninit-value in dev_map_lookup_elem+0xf3/0x170 kernel/bpf/devmap.c:796
__dev_map_lookup_elem kernel/bpf/devmap.c:441 [inline]
dev_map_lookup_elem+0xf3/0x170 kernel/bpf/devmap.c:796
____bpf_map_lookup_elem kernel/bpf/helpers.c:42 [inline]
bpf_map_lookup_elem+0x5c/0x80 kernel/bpf/helpers.c:38
___bpf_prog_run+0x13fe/0xe0f0 kernel/bpf/core.c:1997
__bpf_prog_run256+0xb5/0xe0 kernel/bpf/core.c:2237
==========

The reproducer should be in the interpreter mode.

The C reproducer is trying to run the following bpf prog:

    0: (18) r0 = 0x0
    2: (18) r1 = map[id:49]
    4: (b7) r8 = 16777216
    5: (7b) *(u64 *)(r10 -8) = r8
    6: (bf) r2 = r10
    7: (07) r2 += -229
            ^^^^^^^^^^

    8: (b7) r3 = 8
    9: (b7) r4 = 0
   10: (85) call dev_map_lookup_elem#1543472
   11: (95) exit

It is due to the ""void *key"" (r2) passed to the helper. bpf allows uninit
stack memory access for bpf prog with the right privileges. This patch
uses kmsan_unpoison_memory() to mark the stack as initialized.

This should address different syzbot reports on the uninit ""void *key""
argument during map_{lookup","['delete}_elem.\n\nReported-by: syzbot+603bcd9b0bf1d94dbb9b@syzkaller.appspotmail.com\nCloses: https://lore.kernel.org/bpf/000000000000f9ce6d061494e694@google.com/\nReported-by: syzbot+eb02dc7f03dce0ef39f3@syzkaller.appspotmail.com\nCloses: https://lore.kernel.org/bpf/000000000000a5c69c06147c2238@google.com/\nReported-by: syzbot+b4e65ca24fd4d0c734c3@syzkaller.appspotmail.com\nCloses: https://lore.kernel.org/bpf/000000000000ac56fb06143b6cfa@google.com/\nReported-by: syzbot+d2b113dc9fea5e1d2848@syzkaller.appspotmail.com\nCloses: https://lore.kernel.org/bpf/0000000000000d69b206142d1ff7@google.com/\nReported-by: syzbot+1a3cf6f08d68868f9db3@syzkaller.appspotmail.com\nCloses: https://lore.kernel.org/bpf/0000000000006f876b061478e878@google.com/\nTested-by: syzbot+1a3cf6f08d68868f9db3@syzkaller.appspotmail.com\nSuggested-by: Yonghong Song <yonghong.song@linux.dev>\nSuggested-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nLink: https://lore.kernel.org/r/20240328185801.1843078-1-martin.lau@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit marks BPF program stack with kmsan_unpoison_memory in interpreter mode to address uninitialized memory usage during map lookups.,"kmsan_unpoison_memory, uninit-memory, interpreter",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1a80dbcb2dbaf6e4c216e62e30fa7d3daa8001ce,1a80dbcb2dbaf6e4c216e62e30fa7d3daa8001ce,Andrii Nakryiko,andrii@kernel.org,1711603466,Alexei Starovoitov,ast@kernel.org,1711676865,7276f8f65e83ccafdc154e29f5db8bc9821272f1,e9c856cabefb71d47b2eeb197f72c9c88e9b45b0,"bpf: support deferring bpf_link dealloc to after RCU grace period

BPF link for some program types is passed as a ""context"" which can be
used by those BPF programs to look up additional information. E.g."," for
multi-kprobes and multi-uprobes","[' link is used to fetch BPF cookie values.\n\nBecause of this runtime dependency', ' when bpf_link refcnt drops to zero\nthere could still be active BPF programs running accessing link data.\n\nThis patch adds generic support to defer bpf_link dealloc callback to\nafter RCU GP', ' if requested. This is done by exposing two different\ndeallocation callbacks', ' one synchronous and one deferred. If deferred\none is provided', ' bpf_link_free() will schedule dealloc_deferred()\ncallback to happen after RCU GP.\n\nBPF is using two flavors of RCU: ""classic"" non-sleepable one and RCU\ntasks trace one. The latter is used when sleepable BPF programs are\nused. bpf_link_free() accommodates that by checking underlying BPF\nprogram\'s sleepable flag', ' and goes either through normal RCU GP only for\nnon-sleepable', ' or through RCU tasks trace GP *and* then normal RCU GP\n(taking into account rcu_trace_implies_rcu_gp() optimization)', ' if BPF\nprogram is sleepable.\n\nWe use this for multi-kprobe and multi-uprobe links', ' which dereference\nlink during program run. We also preventively switch raw_tp link to use\ndeferred dealloc callback', ' as upcoming changes in bpf-next tree expose\nraw_tp link data (specifically', ' cookie value) to BPF program at runtime\nas well.\n\nFixes: 0dcac2725406 (""bpf: Add multi kprobe link"")\nFixes: 89ae89f53d20 (""bpf: Add multi uprobe link"")\nReported-by: syzbot+981935d9485a560bfbcb@syzkaller.appspotmail.com\nReported-by: syzbot+2cb5a6c573e98db598cc@syzkaller.appspotmail.com\nReported-by: syzbot+62d8b26793e8a2bd0516@syzkaller.appspotmail.com\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/r/20240328052426.3042617-2-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Support added for deferring bpf_link deallocation to post RCU grace period in eBPF.,"bpf_link, RCU, deallocation",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
e9c856cabefb71d47b2eeb197f72c9c88e9b45b0,e9c856cabefb71d47b2eeb197f72c9c88e9b45b0,Andrii Nakryiko,andrii@kernel.org,1711603465,Alexei Starovoitov,ast@kernel.org,1711676865,29cf5df350ae5d3441fc6dcd010bc06e21509659,037965402a010898d34f4e35327d22c0a95cd51f,"bpf: put uprobe link's path and task in release callback

There is no need to delay putting either path or task to deallocation
step. It can be done right after bpf_uprobe_unregister. Between release
and dealloc", there could be still some running BPF programs,"["" but they\ndon't access either task or path"", ' only data in link->uprobes', ' so it is\nsafe to do.\n\nOn the other hand', "" doing path_put() in dealloc callback makes this\ndealloc sleepable because path_put() itself might sleep. Which is\nproblematic due to the need to call uprobe's dealloc through call_rcu()"", '\nwhich is what is done in the next bug fix patch. So solve the problem by\nreleasing these resources early.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240328052426.3042617-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Optimize allocation timing for uprobe link's path and task in BPF.,"uprobe,release,deallocation",It's a performance optimization.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
e478cf26c556e4ab572ab0ab2306c986901dcd61,e478cf26c556e4ab572ab0ab2306c986901dcd61,Alexei Starovoitov,ast@kernel.org,1711590829,Alexei Starovoitov,ast@kernel.org,1711675901,a9404bc5f4df93821255a1867c7365b5ddae9d1e,5da7fb04902b0f0fcd13bc5ef216e232fa971efa 6302bdeb91df9b4484b9d537c29f8b6117f3f73d,"Merge branch 'bpf-fix-a-couple-of-test-failures-with-lto-kernel'

Yonghong Song says:

====================
bpf: Fix a couple of test failures with LTO kernel

With a LTO kernel built with clang", with one of earlier version of kernel,"['\nI encountered two test failures', ' ksyms and kprobe_multi_bench_attach/kernel.\nNow with latest bpf-next', ' only kprobe_multi_bench_attach/kernel failed.\nBut it is possible in the future ksyms selftest may fail again.\n\nBoth test failures are due to static variable/function renaming\ndue to cross-file inlining. For Ksyms failure', ' the solution is\nto strip .llvm.<hash> suffixes for symbols in /proc/kallsyms before\ncomparing against the ksym in bpf program.\nFor kprobe_multi_bench_attach/kernel failure', ' the solution is\nto either provide names in /proc/kallsyms to the kernel or\nignore those names who have .llvm.<hash> suffix since the kernel\nsym name comparison is against /proc/kallsyms.\n\nPlease see each individual patches for details.\n\nChangelogs:\n  v2 -> v3:\n    - no need to check config file', "" directly so strstr with '.llvm.'.\n    - for kprobe_multi_bench with syms"", ' instead of skipping the syms', '\n      consult /proc/kallyms to find corresponding names.\n    - add a test with populating addrs to the kernel for kprobe\n      multi attach.\n  v1 -> v2:\n    - Let libbpf handle .llvm.<hash suffixes since it may impact\n      bpf program ksym.\n====================\n\nLink: https://lore.kernel.org/r/20240326041443.1197498-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix test failures in BPF with LTO kernel built using clang.,"fix, LTO, test failures",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6302bdeb91df9b4484b9d537c29f8b6117f3f73d,6302bdeb91df9b4484b9d537c29f8b6117f3f73d,Yonghong Song,yonghong.song@linux.dev,1711426523,Alexei Starovoitov,ast@kernel.org,1711675901,a9404bc5f4df93821255a1867c7365b5ddae9d1e,9edaafadc2c50f2af99ee5b3bad6831e1b6ad54f,"selftests/bpf: Add a kprobe_multi subtest to use addrs instead of syms

Get addrs directly from available_filter_functions_addrs and
send to the kernel during kprobe_multi_attach. This avoids
consultation of /proc/kallsyms. But available_filter_functions_addrs
is introduced in 6.5", i.e.,"[' it is introduced recently', '\nso I skip the test if the kernel does not support it.\n\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240326041523.1200301-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Added a subtest for kprobe_multi using direct addresses instead of symbols in selftests/bpf.,"kprobe_multi, addresses, selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
9edaafadc2c50f2af99ee5b3bad6831e1b6ad54f,9edaafadc2c50f2af99ee5b3bad6831e1b6ad54f,Yonghong Song,yonghong.song@linux.dev,1711426518,Alexei Starovoitov,ast@kernel.org,1711675901,cb8822b47b8f6f1ceb2d377089538dcbaf3fdff0,d1f02581059e42d8daf944aae2a296254cc7a5d5,"selftests/bpf: Fix kprobe_multi_bench_attach test failure with LTO kernel

In my locally build clang LTO kernel (enabling CONFIG_LTO and
CONFIG_LTO_CLANG_THIN)"," kprobe_multi_bench_attach/kernel subtest
failed like:
  test_kprobe_multi_bench_attach:PASS:get_syms 0 nsec
  test_kprobe_multi_bench_attach:PASS:kprobe_multi_empty__open_and_load 0 nsec
  libbpf: prog 'test_kprobe_empty': failed to attach: No such process
  test_kprobe_multi_bench_attach:FAIL:bpf_program__attach_kprobe_multi_opts unexpected error: -3
  #117/1   kprobe_multi_bench_attach/kernel:FAIL

There are multiple symbols in /sys/kernel/debug/tracing/available_filter_functions
are renamed in /proc/kallsyms due to cross file inlining. One example is for
  static function __access_remote_vm in mm/memory.c.
In a non-LTO kernel","[' we have the following call stack:\n  ptrace_access_vm (global', ' kernel/ptrace.c)\n    access_remote_vm (global', ' mm/memory.c)\n      __access_remote_vm (static', ' mm/memory.c)\n\nWith LTO kernel', ' it is possible that access_remote_vm() is inlined by\nptrace_access_vm(). So we end up with the following call stack:\n  ptrace_access_vm (global', ' kernel/ptrace.c)\n    __access_remote_vm (static', ' mm/memory.c)\nThe compiler renames __access_remote_vm to __access_remote_vm.llvm.<hash>\nto prevent potential name collision.\n\nThe kernel bpf_kprobe_multi_link_attach() and ftrace_lookup_symbols() try\nto find addresses based on /proc/kallsyms', ' hence the current test failed\nwith LTO kenrel.\n\nThis patch consulted /proc/kallsyms to find the corresponding entries\nfor the ksym and this solved the issue.\n\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240326041518.1199758-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes test failure in kprobe_multi_bench_attach due to symbol renaming in LTO kernels.,"kprobe_multi,LTO,fix",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
d1f02581059e42d8daf944aae2a296254cc7a5d5,d1f02581059e42d8daf944aae2a296254cc7a5d5,Yonghong Song,yonghong.song@linux.dev,1711426513,Alexei Starovoitov,ast@kernel.org,1711675901,f922a82d4fd55aca85b68c3b69c53468a05221a3,9475dacb75e0b5efae086dc904f4d27c31f15157,selftests/bpf: Add {load,"search}_kallsyms_custom_local()

These two functions allow selftests to do loading/searching
kallsyms based on their specific compare functions.

Signed-off-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20240326041513.1199440-1-yonghong.song@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],New functions added for loading and searching kallsyms for selftests in the BPF subsystem.,"selftests, kallsyms, functions",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9475dacb75e0b5efae086dc904f4d27c31f15157,9475dacb75e0b5efae086dc904f4d27c31f15157,Yonghong Song,yonghong.song@linux.dev,1711426508,Alexei Starovoitov,ast@kernel.org,1711675901,134bb369d3b7db7ce1d8b226a2fdee42a09d21b3,d1320649346c36c5ba7b579533bf518960ef71e1,"selftests/bpf: Refactor trace helper func load_kallsyms_local()

Refactor trace helper function load_kallsyms_local() such that
it invokes a common function with a compare function as input.
The common function will be used later for other local functions.

Signed-off-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20240326041508.1199239-1-yonghong.song@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Refactor trace helper function to use a common function with a comparison input for future usage.,"refactor, trace, helper",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tracepoints like programs']
d1320649346c36c5ba7b579533bf518960ef71e1,d1320649346c36c5ba7b579533bf518960ef71e1,Yonghong Song,yonghong.song@linux.dev,1711426503,Alexei Starovoitov,ast@kernel.org,1711675901,6bd684eab2b47aa198dae507140d52e72ac3231d,c56e59776f46d77984329488878a52baf4969457,"selftests/bpf: Refactor some functions for kprobe_multi_test

Refactor some functions in kprobe_multi_test.c to extract
some helper functions who will be used in later patches
to avoid code duplication.

Signed-off-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20240326041503.1198982-1-yonghong.song@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,"Refactor functions in kprobe_multi_test.c to create reusable helpers for future patches, reducing code duplication.","refactor, kprobe, helper",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
c56e59776f46d77984329488878a52baf4969457,c56e59776f46d77984329488878a52baf4969457,Yonghong Song,yonghong.song@linux.dev,1711426498,Alexei Starovoitov,ast@kernel.org,1711675901,be758cc08439721f96824d76eec134e6c89ac741,ad2b05286e94485070475e473963724fa657491c,"libbpf: Handle <orig_name>.llvm.<hash> symbol properly

With CONFIG_LTO_CLANG_THIN enabled"," with some of previous
version of kernel code base ([1])","["" I hit the following\nerror:\n   test_ksyms:PASS:kallsyms_fopen 0 nsec\n   test_ksyms:FAIL:ksym_find symbol 'bpf_link_fops' not found\n   #118     ksyms:FAIL\n\nThe reason is that 'bpf_link_fops' is renamed to\n   bpf_link_fops.llvm.8325593422554671469\nDue to cross-file inlining"", "" the static variable 'bpf_link_fops'\nin syscall.c is used by a function in another file. To avoid\npotential duplicated names"", "" the llvm added suffix\n'.llvm.<hash>' ([2]) to 'bpf_link_fops' variable.\nSuch renaming caused a problem in libbpf if 'bpf_link_fops'\nis used in bpf prog as a ksym but 'bpf_link_fops' does not\nmatch any symbol in /proc/kallsyms.\n\nTo fix this issue"", "" libbpf needs to understand that suffix '.llvm.<hash>'\nis caused by clang lto kernel and to process such symbols properly.\n\nWith latest bpf-next code base built with CONFIG_LTO_CLANG_THIN"", '\nI cannot reproduce the above failure any more. But such an issue\ncould happen with other symbols or in the future for bpf_link_fops symbol.\n\nFor example', ' with my current kernel', ' I got the following from\n/proc/kallsyms:\n  ffffffff84782154 d __func__.net_ratelimit.llvm.6135436931166841955\n  ffffffff85f0a500 d tk_core.llvm.726630847145216431\n  ffffffff85fdb960 d __fs_reclaim_map.llvm.10487989720912350772\n  ffffffff864c7300 d fake_dst_ops.llvm.54750082607048300\n\nI could not easily create a selftest to test newly-added\nlibbpf functionality with a static C test since I do not know\nwhich symbol is cross-file inlined. But based on my particular kernel', '\nthe following test change can run successfully.\n\n>  diff --git a/tools/testing/selftests/bpf/prog_tests/ksyms.c b/tools/testing/selftests/bpf/prog_tests/ksyms.c\n>  index 6a86d1f07800..904a103f7b1d 100644\n>  --- a/tools/testing/selftests/bpf/prog_tests/ksyms.c\n>  +++ b/tools/testing/selftests/bpf/prog_tests/ksyms.c\n>  @@ -42', '6 +42', '7 @@ void test_ksyms(void)\n>          ASSERT_EQ(data->out__bpf_link_fops', ' link_fops_addr', ' ""bpf_link_fops"");\n>          ASSERT_EQ(data->out__bpf_link_fops1', ' 0', ' ""bpf_link_fops1"");\n>          ASSERT_EQ(data->out__btf_size', ' btf_size', ' ""btf_size"");\n>  +       ASSERT_NEQ(data->out__fake_dst_ops', ' 0', ' ""fake_dst_ops"");\n>          ASSERT_EQ(data->out__per_cpu_start', ' per_cpu_start_addr', ' ""__per_cpu_start"");\n>\n>   cleanup:\n>  diff --git a/tools/testing/selftests/bpf/progs/test_ksyms.c b/tools/testing/selftests/bpf/progs/test_ksyms.c\n>  index 6c9cbb5a3bdf..fe91eef54b66 100644\n>  --- a/tools/testing/selftests/bpf/progs/test_ksyms.c\n>  +++ b/tools/testing/selftests/bpf/progs/test_ksyms.c\n>  @@ -9', '11 +9', '13 @@ __u64 out__bpf_link_fops = -1;\n>   __u64 out__bpf_link_fops1 = -1;\n>   __u64 out__btf_size = -1;\n>   __u64 out__per_cpu_start = -1;\n>  +__u64 out__fake_dst_ops = -1;\n>\n>   extern const void bpf_link_fops __ksym;\n>   extern const void __start_BTF __ksym;\n>   extern const void __stop_BTF __ksym;\n>   extern const void __per_cpu_start __ksym;\n>  +extern const void fake_dst_ops __ksym;\n>   /* non-existing symbol', ' weak', ' default to zero */\n>   extern const void bpf_link_fops1 __ksym __weak;\n>\n>  @@ -23', '6 +25', ""7 @@ int handler(const void *ctx)\n>          out__bpf_link_fops = (__u64)&bpf_link_fops;\n>          out__btf_size = (__u64)(&__stop_BTF - &__start_BTF);\n>          out__per_cpu_start = (__u64)&__per_cpu_start;\n>  +       out__fake_dst_ops = (__u64)&fake_dst_ops;\n>\n>          out__bpf_link_fops1 = (__u64)&bpf_link_fops1;\n\nThis patch fixed the issue in libbpf such that\nthe suffix '.llvm.<hash>' will be ignored during comparison of\nbpf prog ksym vs. symbols in /proc/kallsyms"", ' this resolved the issue.\nCurrently', "" only static variables in /proc/kallsyms are checked\nwith '.llvm.<hash>' suffix since in bpf programs function ksyms\nwith '.llvm.<hash>' suffix are most likely kfunc's and unlikely\nto be cross-file inlined.\n\nNote that currently kernel does not support gcc build with lto.\n\n  [1] https://lore.kernel.org/bpf/20240302165017.1627295-1-yonghong.song@linux.dev/\n  [2] https://github.com/llvm/llvm-project/blob/release/18.x/llvm/include/llvm/IR/ModuleSummaryIndex.h#L1714-L1719\n\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240326041458.1198161-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Handles the <orig_name>.llvm.<hash> symbol properly in libbpf with CONFIG_LTO_CLANG_THIN enabled.,libbpf symbol handling,It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ad2b05286e94485070475e473963724fa657491c,ad2b05286e94485070475e473963724fa657491c,Yonghong Song,yonghong.song@linux.dev,1711426493,Alexei Starovoitov,ast@kernel.org,1711675901,68d8f28e5f7d7dbf306cc20d2961125248372bbe,cdfd9cc3ba147ceea650afa6b7031e31a98d500e,"libbpf: Mark libbpf_kallsyms_parse static function

Currently libbpf_kallsyms_parse() function is declared as a global
function but actually it is not a API and there is no external
users in bpftool/bpf-selftests. So let us mark the function as
static.

Signed-off-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20240326041453.1197949-1-yonghong.song@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit marks libbpf_kallsyms_parse function as static since it is not used externally.,"libbpf,static,function",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
cdfd9cc3ba147ceea650afa6b7031e31a98d500e,cdfd9cc3ba147ceea650afa6b7031e31a98d500e,Yonghong Song,yonghong.song@linux.dev,1711426488,Alexei Starovoitov,ast@kernel.org,1711675901,88e523f9118aefb1d02fc15de5a794d14e670d6a,5da7fb04902b0f0fcd13bc5ef216e232fa971efa,"selftests/bpf: Replace CHECK with ASSERT macros for ksyms test

Replace CHECK with ASSERT macros for ksyms tests.
This test failed earlier with clang lto kernel"," but the
issue is gone with latest code base. But replacing
CHECK with ASSERT still improves code as ASSERT is
preferred in selftests.

Signed-off-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20240326041448.1197812-1-yonghong.song@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Replaced CHECK with ASSERT macros in ksyms test for improved code quality in selftests.,"ASSERT, ksyms, selftests",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
5da7fb04902b0f0fcd13bc5ef216e232fa971efa,5da7fb04902b0f0fcd13bc5ef216e232fa971efa,Martin KaFai Lau,martin.lau@kernel.org,1711134873,Alexei Starovoitov,ast@kernel.org,1711675900,6e4de114a369c8e76c53496249cf16f07682d4db,42e4ebd390be8e0090d64d58433b6cba45d919e9,"selftests/bpf: Test loading bpf-tcp-cc prog calling the kernel tcp-cc kfuncs

This patch adds a test to ensure all static tcp-cc kfuncs is visible to
the struct_ops bpf programs. It is checked by successfully loading
the struct_ops programs calling these tcp-cc kfuncs.

This patch needs to enable the CONFIG_TCP_CONG_DCTCP and
the CONFIG_TCP_CONG_BBR.

Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
Link: https://lore.kernel.org/r/20240322191433.4133280-2-martin.lau@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add test for bpf-tcp-cc programs using kernel tcp-cc kfuncs.,"bpf-tcp-cc,kfuncs,struct_ops",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tc/netfilter like programs']
42e4ebd390be8e0090d64d58433b6cba45d919e9,42e4ebd390be8e0090d64d58433b6cba45d919e9,Martin KaFai Lau,martin.lau@kernel.org,1711134872,Alexei Starovoitov,ast@kernel.org,1711675900,0fc02fbb41ee2a8833f9f4fe12c16b43e5e08942,ee3bad033d01066348913f3220ea81987721ed53,"bpf: Remove CONFIG_X86 and CONFIG_DYNAMIC_FTRACE guard from the tcp-cc kfuncs

The commit 7aae231ac93b (""bpf: tcp: Limit calling some tcp cc functions to CONFIG_DYNAMIC_FTRACE"")
added CONFIG_DYNAMIC_FTRACE guard because pahole was only generating
btf for ftrace-able functions. The ftrace filter had already been
removed from pahole"," so the CONFIG_DYNAMIC_FTRACE guard can be
removed.

The commit 569c484f9995 (""bpf: Limit static tcp-cc functions in the .BTF_ids list to x86"")
has added CONFIG_X86 guard because it failed the powerpc arch which
prepended a ""."" to the local static function","[' so ""cubictcp_init"" becomes\n"".cubictcp_init"". ""__bpf_kfunc"" has been added to kfunc\nsince then and it uses the __unused compiler attribute.\nThere is an existing\n""__bpf_kfunc static u32 bpf_kfunc_call_test_static_unused_arg(u32 arg', ' u32 unused)""\ntest in bpf_testmod.c to cover the static kfunc case.\n\ncross compile on ppc64 with CONFIG_DYNAMIC_FTRACE disabled:\n> readelf -s vmlinux | grep cubictcp_\n56938: c00000000144fd00   184 FUNC    LOCAL  DEFAULT    2 cubictcp_cwnd_event \t    [<localentry>: 8]\n56939: c00000000144fdb8   200 FUNC    LOCAL  DEFAULT    2 cubictcp_recalc_[...]   [<localentry>: 8]\n56940: c00000000144fe80   296 FUNC    LOCAL  DEFAULT    2 cubictcp_init \t    [<localentry>: 8]\n56941: c00000000144ffa8   228 FUNC    LOCAL  DEFAULT    2 cubictcp_state \t    [<localentry>: 8]\n56942: c00000000145008c  1908 FUNC    LOCAL  DEFAULT    2 cubictcp_cong_avoid  [<localentry>: 8]\n56943: c000000001450800  1644 FUNC    LOCAL  DEFAULT    2 cubictcp_acked \t    [<localentry>: 8]\n\n> bpftool btf dump file vmlinux | grep cubictcp_\n[51540] FUNC \'cubictcp_acked\' type_id=38137 linkage=static\n[51541] FUNC \'cubictcp_cong_avoid\' type_id=38122 linkage=static\n[51543] FUNC \'cubictcp_cwnd_event\' type_id=51542 linkage=static\n[51544] FUNC \'cubictcp_init\' type_id=9186 linkage=static\n[51545] FUNC \'cubictcp_recalc_ssthresh\' type_id=35021 linkage=static\n[51547] FUNC \'cubictcp_state\' type_id=38141 linkage=static\n\nThe patch removed both config guards.\n\nCc: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nLink: https://lore.kernel.org/r/20240322191433.4133280-1-martin.lau@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit removes configuration guards from tcp-cc kfuncs due to changes in ftrace requirements.,"CONFIG_X86,CONFIG_DYNAMIC_FTRACE,kfuncs",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,['tc/netfilter like programs']
ee3bad033d01066348913f3220ea81987721ed53,ee3bad033d01066348913f3220ea81987721ed53,Yafang Shao,laoar.shao@gmail.com,1711509622,Alexei Starovoitov,ast@kernel.org,1711675900,1a48e38c1129daf5ac5a5a62a61a04016db06dcf,a461a51e519aedee8aff518167451b250ce913b3,"bpf: Mitigate latency spikes associated with freeing non-preallocated htab

Following the recent upgrade of one of our BPF programs"," we encountered
significant latency spikes affecting other applications running on the same
host. After thorough investigation","[' we identified that these spikes were\nprimarily caused by the prolonged duration required to free a\nnon-preallocated htab with approximately 2 million keys.\n\nNotably', ' our kernel configuration lacks the presence of CONFIG_PREEMPT. In\nscenarios where kernel execution extends excessively', ' other threads might\nbe starved of CPU time', ' resulting in latency issues across the system. To\nmitigate this', "" we've adopted a proactive approach by incorporating\ncond_resched() calls within the kernel code. This ensures that during\nlengthy kernel operations"", ' the scheduler is invoked periodically to provide\nopportunities for other threads to execute.\n\nSigned-off-by: Yafang Shao <laoar.shao@gmail.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240327032022.78391-1-laoar.shao@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Mitigate latency spikes when freeing non-preallocated htab in a BPF program.,"latency, spikes, htab",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
985d0681b46be7db5ccc330d9a7f318b96ce0029,985d0681b46be7db5ccc330d9a7f318b96ce0029,Andrii Nakryiko,andrii@kernel.org,1711470111,Alexei Starovoitov,ast@kernel.org,1711675900,9930d2880ee3a9d0acc2575b52f6a868992b99e6,3124591f686115aca25d772c2ccb7b1e202c3197,"selftests/bpf: add batched tp/raw_tp/fmodret tests

Utilize bpf_modify_return_test_tp() kfunc to have a fast way to trigger
tp/raw_tp/fmodret programs from another BPF program"," which gives us
comparable batched benchmarks to (batched) kprobe/fentry benchmarks.

We don't switch kprobe/fentry batched benchmarks to this kfunc to make
bench tool usable on older kernels as well.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240326162151.3981687-7-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Added batched tests for tp/raw_tp/fmodret programs using bpf_modify_return_test_tp() kfunc.,"batched tests,kfunc,tp programs",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['tracepoints like programs', 'kprobe/uprobe/ftrace like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3124591f686115aca25d772c2ccb7b1e202c3197,3124591f686115aca25d772c2ccb7b1e202c3197,Andrii Nakryiko,andrii@kernel.org,1711470110,Alexei Starovoitov,ast@kernel.org,1711675900,e761705a15312f4cf7423a40035c3e78bb8e4901,b4ccf9158f5893dedb898687272fabfe80f58907,"bpf: add bpf_modify_return_test_tp() kfunc triggering tracepoint

Add a simple bpf_modify_return_test_tp() kfunc"," available to all program
types","[' that is useful for various testing and benchmarking scenarios', ' as\nit allows to trigger most tracing BPF program types from BPF side', '\nallowing to do complex testing and benchmarking scenarios.\n\nIt is also attachable to for fmod_ret programs', ' making it a good and\nsimple way to trigger fmod_ret program under test/benchmark.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240326162151.3981687-6-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Added new kfunc bpf_modify_return_test_tp() for triggering tracepoints in eBPF.,"bpf,kfunc,tracepoint",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,['tracepoints like programs']
b4ccf9158f5893dedb898687272fabfe80f58907,b4ccf9158f5893dedb898687272fabfe80f58907,Andrii Nakryiko,andrii@kernel.org,1711470109,Alexei Starovoitov,ast@kernel.org,1711675900,83864944c3c44f20a8e26b779ea7bb7b10f4e57b,208c4391204d25d9178fbc87f216daffad00cd15,"selftests/bpf: lazy-load trigger bench BPF programs

Instead of front-loading all possible benchmarking BPF programs for
trigger benchmarks"," explicitly specify which BPF programs are used by
specific benchmark and load only it.

This allows to be more flexible in supporting older kernels","[' where some\nprogram types might not be possible to load (e.g.', ' those that rely on\nnewly added kfunc).\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240326162151.3981687-5-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Implemented lazy-loading mechanism for BPF programs in selftests to support trigger benchmarks on older kernels.,"selftests, lazy-load, benchmarks",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tracepoints like programs']
208c4391204d25d9178fbc87f216daffad00cd15,208c4391204d25d9178fbc87f216daffad00cd15,Andrii Nakryiko,andrii@kernel.org,1711470108,Alexei Starovoitov,ast@kernel.org,1711675900,a0eec206f8fb9c15dec0c1fbdc4b1a25b30f94e3,7df4e597ea2cfd677e65730948153d5544986a10,selftests/bpf: remove syscall-driven benchs," keep syscall-count only

Remove ""legacy"" benchmarks triggered by syscalls in favor of newly added
in-kernel/batched benchmarks. Drop -batched suffix now as well.
Next patch will restore ""feature parity"" by adding back
tp/raw_tp/fmodret benchmarks based on in-kernel kfunc approach.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240326162151.3981687-4-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Removed syscall-driven benchmarks in favor of in-kernel batched benchmarks in selftests for BPF.,"benchmarks, syscall, batched",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7df4e597ea2cfd677e65730948153d5544986a10,7df4e597ea2cfd677e65730948153d5544986a10,Andrii Nakryiko,andrii@kernel.org,1711470107,Alexei Starovoitov,ast@kernel.org,1711675900,d1e7e35d4fd5d276b2a207a6eca1b39ae11a6a8f,1175f8dea349e5999d99727346db24f38306a793,selftests/bpf: add batched," mostly in-kernel BPF triggering benchmarks

Existing kprobe/fentry triggering benchmarks have 1-to-1 mapping between
one syscall execution and BPF program run. While we use a fast
get_pgid() syscall","[' syscall overhead can still be non-trivial.\n\nThis patch adds kprobe/fentry set of benchmarks significantly amortizing\nthe cost of syscall vs actual BPF triggering overhead. We do this by\nemploying BPF_PROG_TEST_RUN command to trigger ""driver"" raw_tp program\nwhich does a tight parameterized loop calling cheap BPF helper\n(bpf_get_numa_node_id())', ' to which kprobe/fentry programs are\nattached for benchmarking.\n\nThis way 1 bpf() syscall causes N executions of BPF program being\nbenchmarked. N defaults to 100', ' but can be adjusted with\n--trig-batch-iters CLI argument.\n\nFor comparison we also implement a new baseline program that instead of\ntriggering another BPF program just does N atomic per-CPU counter\nincrements', ' establishing the limit for all other types of program within\nthis batched benchmarking setup.\n\nTaking the final set of benchmarks added in this patch set (including\ntp/raw_tp/fmodret', ' added in later patch)', ' and keeping for now ""legacy""\nsyscall-driven benchmarks', ' we can capture all triggering benchmarks in\none place for comparison', ' before we remove the legacy ones (and rename\nxxx-batched into just xxx).\n\n$ benchs/run_bench_trigger.sh\nusermode-count       :   79.500 ± 0.024M/s\nkernel-count         :   49.949 ± 0.081M/s\nsyscall-count        :    9.009 ± 0.007M/s\n\nfentry-batch         :   31.002 ± 0.015M/s\nfexit-batch          :   20.372 ± 0.028M/s\nfmodret-batch        :   21.651 ± 0.659M/s\nrawtp-batch          :   36.775 ± 0.264M/s\ntp-batch             :   19.411 ± 0.248M/s\nkprobe-batch         :   12.949 ± 0.220M/s\nkprobe-multi-batch   :   15.400 ± 0.007M/s\nkretprobe-batch      :    5.559 ± 0.011M/s\nkretprobe-multi-batch:    5.861 ± 0.003M/s\n\nfentry-legacy        :    8.329 ± 0.004M/s\nfexit-legacy         :    6.239 ± 0.003M/s\nfmodret-legacy       :    6.595 ± 0.001M/s\nrawtp-legacy         :    8.305 ± 0.004M/s\ntp-legacy            :    6.382 ± 0.001M/s\nkprobe-legacy        :    5.528 ± 0.003M/s\nkprobe-multi-legacy  :    5.864 ± 0.022M/s\nkretprobe-legacy     :    3.081 ± 0.001M/s\nkretprobe-multi-legacy:   3.193 ± 0.001M/s\n\nNote how xxx-batch variants are measured with significantly higher\nthroughput', "" even though it's exactly the same in-kernel overhead. As\nsuch"", ' results can be compared only between benchmarks of the same kind\n(syscall vs batched):\n\nfentry-legacy        :    8.329 ± 0.004M/s\nfentry-batch         :   31.002 ± 0.015M/s\n\nkprobe-multi-legacy  :    5.864 ± 0.022M/s\nkprobe-multi-batch   :   15.400 ± 0.007M/s\n\nNote also that syscall-count is setting a theoretical limit for\nsyscall-triggered benchmarks', ' while kernel-count is setting similar\nlimits for batch variants. usermode-count is a happy and unachievable\ncase of user space counting without doing any syscalls', ' and is mostly\nthe measure of CPU speed for such a trivial benchmark.\n\nAs was mentioned', ' tp/raw_tp/fmodret require kernel-side kfunc to produce\nsimilar benchmark', ' which we address in a separate patch.\n\nNote that run_bench_trigger.sh allows to override a list of benchmarks\nto run', ' which is very useful for performance work.\n\nCc: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240326162151.3981687-3-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add batched benchmarks for selftests/bpf focusing on kprobe/fentry with faster syscall execution.,"batched, benchmarks, kprobe",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
1175f8dea349e5999d99727346db24f38306a793,1175f8dea349e5999d99727346db24f38306a793,Andrii Nakryiko,andrii@kernel.org,1711470106,Alexei Starovoitov,ast@kernel.org,1711675899,761ac31c678a6740f3912f08c6e514ee4fd5a559,55fc888ded83ed542f3de3e51bae03936a998349,"selftests/bpf: rename and clean up userspace-triggered benchmarks

Rename uprobe-base to more precise usermode-count (it will match other
baseline-like benchmarks"," kernel-count and syscall-count). Also use
BENCH_TRIG_USERMODE() macro to define all usermode-based triggering
benchmarks","[' which include usermode-count and uprobe/uretprobe benchmarks.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240326162151.3981687-2-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Rename and clean up userspace-triggered benchmarks in selftests/bpf and use BENCH_TRIG_USERMODE macro.,"selftests, benchmarks, rename",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
55fc888ded83ed542f3de3e51bae03936a998349,55fc888ded83ed542f3de3e51bae03936a998349,Haiyue Wang,haiyue.wang@intel.com,1711522409,Alexei Starovoitov,ast@kernel.org,1711675896,bb602f9e29f284dcfb6a789e1d99624cb3810fc9,786bf0e7e2ec90b349a7bab6e97947982ab31f2c,bpf,"arena: Use helper sizeof_field in struct accessors

Use the well defined helper sizeof_field() to calculate the size of a
struct member","[' instead of doing custom calculations.\n\nSigned-off-by: Haiyue Wang <haiyue.wang@intel.com>\nLink: https://lore.kernel.org/r/20240327065334.8140-1-haiyue.wang@intel.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Use the sizeof_field helper for calculating struct member size within the arena.,"helper, struct, sizeof_field",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
786bf0e7e2ec90b349a7bab6e97947982ab31f2c,786bf0e7e2ec90b349a7bab6e97947982ab31f2c,Mykyta Yatsenko,yatsenko@meta.com,1711380130,Alexei Starovoitov,ast@kernel.org,1711675853,06035090d80edace56555e7454bc414989f07903,59b418c7063d30e0a3e1f592d47df096db83185c,"bpf: improve error message for unsupported helper

BPF verifier emits ""unknown func"" message when given BPF program type
does not support BPF helper. This message may be confusing for users"," as
important context that helper is unknown only to current program type is
not provided.

This patch changes message to ""program of this type cannot use helper ""
and aligns dependent code in libbpf and tests. Any suggestions on
improving/changing this message are welcome.

Signed-off-by: Mykyta Yatsenko <yatsenko@meta.com>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Quentin Monnet <qmo@kernel.org>
Link: https://lore.kernel.org/r/20240325152210.377548-1-yatsenko@meta.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Improves error message clarity in BPF verifier when unsupported helpers are used by certain BPF program types.,"error message, BPF verifier, helper",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
59b418c7063d30e0a3e1f592d47df096db83185c,59b418c7063d30e0a3e1f592d47df096db83185c,Anton Protopopov,aspsk@isovalent.com,1711448262,Alexei Starovoitov,ast@kernel.org,1711675853,43e256562b0e3e39ddc2f7acc35f44903dde0295,6efec2cb06411a577125b5f531a852c08ead1209,"bpf: Add a check for struct bpf_fib_lookup size

The struct bpf_fib_lookup should not grow outside of its 64 bytes.
Add a static assert to validate this.

Suggested-by: David Ahern <dsahern@kernel.org>
Signed-off-by: Anton Protopopov <aspsk@isovalent.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240326101742.17421-4-aspsk@isovalent.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add a static check to ensure struct bpf_fib_lookup size remains 64 bytes.,"bpf_fib_lookup, static_assert, size_check",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6efec2cb06411a577125b5f531a852c08ead1209,6efec2cb06411a577125b5f531a852c08ead1209,Anton Protopopov,aspsk@isovalent.com,1711448261,Alexei Starovoitov,ast@kernel.org,1711675853,e9fff17ce16562758b4d40486ce3a96ee5b78431,5311591fbb349fe9f5c555dcba3b13a5831aa72d,"selftests/bpf: Add BPF_FIB_LOOKUP_MARK tests

This patch extends the fib_lookup test suite by adding a few test
cases for each IP family to test the new BPF_FIB_LOOKUP_MARK flag
to the bpf_fib_lookup:

  * Test destination IP address selection with and without a mark
    and/or the BPF_FIB_LOOKUP_MARK flag set

Signed-off-by: Anton Protopopov <aspsk@isovalent.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240326101742.17421-3-aspsk@isovalent.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Extend the fib_lookup test suite with new test cases for BPF_FIB_LOOKUP_MARK flag.,"fib_lookup, BPF_FIB_LOOKUP_MARK, tests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tc/netfilter like programs']
5311591fbb349fe9f5c555dcba3b13a5831aa72d,5311591fbb349fe9f5c555dcba3b13a5831aa72d,Anton Protopopov,aspsk@isovalent.com,1711448260,Alexei Starovoitov,ast@kernel.org,1711675852,a6cbe52ccc21dc1c9abb12eb64a9494e69ffcd0d,c602f4ca13a529b45692de4fdec96b4cdec866da,"bpf: Add support for passing mark with bpf_fib_lookup

Extend the bpf_fib_lookup() helper by making it to utilize mark if
the BPF_FIB_LOOKUP_MARK flag is set. In order to pass the mark the
four bytes of struct bpf_fib_lookup are used"," shared with the
output-only smac/dmac fields.

Signed-off-by: Anton Protopopov <aspsk@isovalent.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Reviewed-by: David Ahern <dsahern@kernel.org>
Acked-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240326101742.17421-2-aspsk@isovalent.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Add support for passing mark with bpf_fib_lookup helper using BPF_FIB_LOOKUP_MARK flag.,"bpf_fib_lookup, mark, helper",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['tc/netfilter like programs']
50108c352db70405b3d71d8099d0b3adc3b3352c,50108c352db70405b3d71d8099d0b3adc3b3352c,Linus Torvalds,torvalds@linux-foundation.org,1711656577,Linus Torvalds,torvalds@linux-foundation.org,1711656577,61ae73b4f540704f9727b6c24ef306de6a7da5fd,8d025e2092e29bfd13e56c78e22af25fac83c8ec 18685451fc4e546fc0e718580d32df3c0e5c8272,"Merge tag 'net-6.9-rc2' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Paolo Abeni:
 ""Including fixes from bpf"," WiFi and netfilter.

  Current release - regressions:

   - ipv6: fix address dump when IPv6 is disabled on an interface

  Current release - new code bugs:

   - bpf: temporarily disable atomic operations in BPF arena

   - nexthop: fix uninitialized variable in nla_put_nh_group_stats()

  Previous releases - regressions:

   - bpf: protect against int overflow for stack access size

   - hsr: fix the promiscuous mode in offload mode

   - wifi: don't always use FW dump trig

   - tls: adjust recv return with async crypto and failed copy to
     userspace

   - tcp: properly terminate timers for kernel sockets

   - ice: fix memory corruption bug with suspend and rebuild

   - at803x: fix kernel panic with at8031_probe

   - qeth: handle deferred cc1

  Previous releases - always broken:

   - bpf: fix bug in BPF_LDX_MEMSX

   - netfilter: reject table flag and netdev basechain updates

   - inet_defrag: prevent sk release while still in use

   - wifi: pick the version of SESSION_PROTECTION_NOTIF

   - wwan: t7xx: split 64bit accesses to fix alignment issues

   - mlxbf_gige: call request_irq() after NAPI initialized

   - hns3: fix kernel crash when devlink reload during pf
     initialization""

* tag 'net-6.9-rc2' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (81 commits)
  inet: inet_defrag: prevent sk release while still in use
  Octeontx2-af: fix pause frame configuration in GMP mode
  net: lan743x: Add set RFE read fifo threshold for PCI1x1x chips
  net: bcmasp: Remove phy_{suspend/resume}
  net: bcmasp: Bring up unimac after PHY link up
  net: phy: qcom: at803x: fix kernel panic with at8031_probe
  netfilter: arptables: Select NETFILTER_FAMILY_ARP when building arp_tables.c
  netfilter: nf_tables: skip netdev hook unregistration if table is dormant
  netfilter: nf_tables: reject table flag and netdev basechain updates
  netfilter: nf_tables: reject destroy command to remove basechain hooks
  bpf: update BPF LSM designated reviewer list
  bpf: Protect against int overflow for stack access size
  bpf: Check bloom filter map value size
  bpf: fix warning for crash_kexec
  selftests: netdevsim: set test timeout to 10 minutes
  net: wan: framer: Add missing static inline qualifiers
  mlxbf_gige: call request_irq() after NAPI initialized
  tls: get psock ref after taking rxlock to avoid leak
  selftests: tls: add test with a partially invalid iov
  tls: adjust recv return with async crypto and failed copy to userspace
  ...
",[''],Merge networking fixes including BPF and various bug resolutions for the 6.9-rc2 release.,"networking, BPF, fixes",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['tc/netfilter like programs', 'LSM like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7e6f4b2af5b8cfe028386bc439c9bad1eddff9a6,7e6f4b2af5b8cfe028386bc439c9bad1eddff9a6,Paolo Abeni,pabeni@redhat.com,1711616879,Paolo Abeni,pabeni@redhat.com,1711616880,50e1f79928073c9b2a70881a01f0a2eaf4367281,56d2f48ed8f857f2765575a6a25b9655765edd41 4dd651076ef0e5f09940f763a1b4e8a209dab7ab,"Merge tag 'for-net' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Alexei Starovoitov says:

====================
pull-request: bpf 2024-03-27

The following pull-request contains BPF updates for your *net* tree.

We've added 4 non-merge commits during the last 1 day(s) which contain
a total of 5 files changed", 26 insertions(+),"[' 3 deletions(-).\n\nThe main changes are:\n\n1) Fix bloom filter value size validation and protect the verifier\n   against such mistakes', ' from Andrei.\n\n2) Fix build due to CONFIG_KEXEC_CORE/CRASH_DUMP split', ' from Hari.\n\n3) Update bpf_lsm maintainers entry', "" from Matt.\n\n* tag 'for-net' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  bpf: update BPF LSM designated reviewer list\n  bpf: Protect against int overflow for stack access size\n  bpf: Check bloom filter map value size\n  bpf: fix warning for crash_kexec\n====================\n\nLink: https://lore.kernel.org/r/20240328012938.24249-1-alexei.starovoitov@gmail.com\nSigned-off-by: Paolo Abeni <pabeni@redhat.com>\n"", '']",Merge BPF updates for net tree with 4 non-merge commits affecting 5 files.,"BPF, net, updates",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4dd651076ef0e5f09940f763a1b4e8a209dab7ab,4dd651076ef0e5f09940f763a1b4e8a209dab7ab,Matt Bobrowski,mattbobrowski@google.com,1711482619,Alexei Starovoitov,ast@kernel.org,1711563036,3ef103c9a06584bfc4293df39e189aa3e294eedf,a4e02d6b91c5e57f820032ec6ad794694c86f327,"bpf: update BPF LSM designated reviewer list

Adding myself in place of both Brendan and Florent as both have since
moved on from working on the BPF LSM and will no longer be devoting
their time to maintaining the BPF LSM.

Signed-off-by: Matt Bobrowski <mattbobrowski@google.com>
Acked-by: KP Singh <kpsingh@kernel.org>
Link: https://lore.kernel.org/r/ZgMhWF_egdYF8t4D@google.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Added Matt Bobrowski to BPF LSM designated reviewer list replacing Brendan and Florent.,"BPF, LSM, reviewer",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['LSM like programs']
ecc6a2101840177e57c925c102d2d29f260d37c8,ecc6a2101840177e57c925c102d2d29f260d37c8,Andrei Matei,andreimatei1@gmail.com,1711507365,Alexei Starovoitov,ast@kernel.org,1711558596,bf6977a9ab0b8a0c54accee088371e52c6d6d08d,a8d89feba7e54e691ca7c4efc2a6264fa83f3687,"bpf: Protect against int overflow for stack access size

This patch re-introduces protection against the size of access to stack
memory being negative; the access size can appear negative as a result
of overflowing its signed int representation. This should not actually
happen", as there are other protections along the way,"[' but we should\nprotect against it anyway. One code path was missing such protections\n(fixed in the previous patch in the series)', ' causing out-of-bounds array\naccesses in check_stack_range_initialized(). This patch causes the\nverification of a program with such a non-sensical access size to fail.\n\nThis check used to exist in a more indirect way', ' but was inadvertendly\nremoved in a833a17aeac7.\n\nFixes: a833a17aeac7 (""bpf: Fix verification of indirect var-off stack access"")\nReported-by: syzbot+33f4297b5f927648741a@syzkaller.appspotmail.com\nReported-by: syzbot+aafd0513053a1cbf52ef@syzkaller.appspotmail.com\nCloses: https://lore.kernel.org/bpf/CAADnVQLORV5PT0iTAhRER+iLBTkByCYNBYyvBSgjN1T31K+gOw@mail.gmail.com/\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Andrei Matei <andreimatei1@gmail.com>\nLink: https://lore.kernel.org/r/20240327024245.318299-3-andreimatei1@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit reintroduces protection against int overflow for stack access size in the eBPF subsystem.,"int overflow,stack access,protection",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a8d89feba7e54e691ca7c4efc2a6264fa83f3687,a8d89feba7e54e691ca7c4efc2a6264fa83f3687,Andrei Matei,andreimatei1@gmail.com,1711507364,Alexei Starovoitov,ast@kernel.org,1711558577,087d15f18cc99fa5355fe72cb0b91188b6c1d858,96b98a6552a90690d7bc18dd71b66312c9ded1fb,"bpf: Check bloom filter map value size

This patch adds a missing check to bloom filter creating"," rejecting
values above KMALLOC_MAX_SIZE. This brings the bloom map in line with
many other map types.

The lack of this protection can cause kernel crashes for value sizes
that overflow int's. Such a crash was caught by syzkaller. The next
patch adds more guard-rails at a lower level.

Signed-off-by: Andrei Matei <andreimatei1@gmail.com>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240327024245.318299-2-andreimatei1@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],This commit adds a check to prevent kernel crashes by ensuring bloom filter map values don't exceed KMALLOC_MAX_SIZE.,"bloom filter, kernel crash, KMALLOC_MAX_SIZE",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
96b98a6552a90690d7bc18dd71b66312c9ded1fb,96b98a6552a90690d7bc18dd71b66312c9ded1fb,Hari Bathini,hbathini@linux.ibm.com,1710835312,Alexei Starovoitov,ast@kernel.org,1711554744,8cca34488bc16a09f87a152a384eea495be68483,afbf75e8da8ce8a0698212953d350697bb4355a6,"bpf: fix warning for crash_kexec

With [1]"," crash dump specific code is moved out of CONFIG_KEXEC_CORE
and placed under CONFIG_CRASH_DUMP","[' where it is more appropriate.\nAnd since CONFIG_KEXEC & !CONFIG_CRASH_DUMP build option is supported\nwith that', ' it led to the below warning:\n\n  ""WARN: resolve_btfids: unresolved symbol crash_kexec""\n\nFix it by using the appropriate #ifdef.\n\n[1] https://lore.kernel.org/all/20240124051254.67105-1-bhe@redhat.com/\n\nAcked-by: Baoquan He <bhe@redhat.com>\nFixes: 02aff8480533 (""crash: split crash dumping code out from kexec_core.c"")\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nSigned-off-by: Hari Bathini <hbathini@linux.ibm.com>\nLink: https://lore.kernel.org/r/20240319080152.36987-1-hbathini@linux.ibm.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix warning by moving crash dump specific code to CONFIG_CRASH_DUMP for proper configuration linkage.,"fix, warning, crash",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
2a702c2e57908e7bb5c814afeac577a14815c2f2,2a702c2e57908e7bb5c814afeac577a14815c2f2,Jakub Kicinski,kuba@kernel.org,1711551154,Jakub Kicinski,kuba@kernel.org,1711551154,7e6dfd1d0022eb8c3282bc652f450e51abfca630,ee36b1e93b11b980e0156bd07cbb9866b7d3e29e 14bb1e8c8d4ad5d9d2febb7d19c70a3cf536e1e5,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next

Daniel Borkmann says:

====================
pull-request: bpf-next 2024-03-25

We've added 38 non-merge commits during the last 13 day(s) which contain
a total of 50 files changed", 867 insertions(+),"[' 274 deletions(-).\n\nThe main changes are:\n\n1) Add the ability to specify and retrieve BPF cookie also for raw\n   tracepoint programs in order to ease migration from classic to raw\n   tracepoints', ' from Andrii Nakryiko.\n\n2) Allow the use of bpf_get_{ns_', '}current_pid_tgid() helper for all\n   program types and add additional BPF selftests', ' from Yonghong Song.\n\n3) Several improvements to bpftool and its build', ' for example', ' enabling\n   libbpf logs when loading pid_iter in debug mode', ' from Quentin Monnet.\n\n4) Check the return code of all BPF-related set_memory_*() functions during\n   load and bail out in case they fail', "" from Christophe Leroy.\n\n5) Avoid a goto in regs_refine_cond_op() such that the verifier can\n   be better integrated into Agni tool which doesn't support backedges\n   yet"", ' from Harishankar Vishwanathan.\n\n6) Add a small BPF trie perf improvement by always inlining\n   longest_prefix_match', ' from Jesper Dangaard Brouer.\n\n7) Small BPF selftest refactor in bpf_tcp_ca.c to utilize start_server()\n   helper instead of open-coding it', ' from Geliang Tang.\n\n8) Improve test_tc_tunnel.sh BPF selftest to prevent client connect\n   before the server bind', ' from Alessandro Carminati.\n\n9) Fix BPF selftest benchmark for older glibc and use syscall(SYS_gettid)\n   instead of gettid()', ' from Alan Maguire.\n\n10) Implement a backward-compatible method for struct_ops types with\n    additional fields which are not present in older kernels', '\n    from Kui-Feng Lee.\n\n11) Add a small helper to check if an instruction is addr_space_cast\n    from as(0) to as(1) and utilize it in x86-64 JIT', ' from Puranjay Mohan.\n\n12) Small cleanup to remove unnecessary error check in\n    bpf_struct_ops_map_update_elem', ' from Martin KaFai Lau.\n\n13) Improvements to libbpf fd validity checks for BPF map/programs', '\n    from Mykyta Yatsenko.\n\n* tag \'for-netdev\' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next: (38 commits)\n  selftests/bpf: Fix flaky test btf_map_in_map/lookup_update\n  bpf: implement insn_is_cast_user() helper for JITs\n  bpf: Avoid get_kernel_nofault() to fetch kprobe entry IP\n  selftests/bpf: Use start_server in bpf_tcp_ca\n  bpf: Sync uapi bpf.h to tools directory\n  libbpf: Add new sec_def ""sk_skb/verdict""\n  selftests/bpf: Mark uprobe trigger functions with nocf_check attribute\n  selftests/bpf: Use syscall(SYS_gettid) instead of gettid() wrapper in bench\n  bpf-next: Avoid goto in regs_refine_cond_op()\n  bpftool: Clean up HOST_CFLAGS', ' HOST_LDFLAGS for bootstrap bpftool\n  selftests/bpf: scale benchmark counting by using per-CPU counters\n  bpftool: Remove unnecessary source files from bootstrap version\n  bpftool: Enable libbpf logs when loading pid_iter in debug mode\n  selftests/bpf: add raw_tp/tp_btf BPF cookie subtests\n  libbpf: add support for BPF cookie for raw_tp/tp_btf programs\n  bpf: support BPF cookie in raw tracepoint (raw_tp', ' tp_btf) programs\n  bpf: pass whole link instead of prog when triggering raw tracepoint\n  bpf: flatten bpf_probe_register call chain\n  selftests/bpf: Prevent client connect before server bind in test_tc_tunnel.sh\n  selftests/bpf: Add a sk_msg prog bpf_get_ns_current_pid_tgid() test\n  ...\n====================\n\nLink: https://lore.kernel.org/r/20240325233940.7154-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Merge pull request for bpf-next with 38 non-merge commits and 50 files changed.,"merge,pull request,bpf-next",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
ea6873118493019474abbf57d5a800da365734df,ea6873118493019474abbf57d5a800da365734df,Pu Lehui,pulehui@huawei.com,1710206453,Palmer Dabbelt,palmer@rivosinc.com,1711487358,e9f7091a893941b07b47c536ff37bcc58a43ce1a,4b0bf9a0127029054c2fa18ba5b3f3ddc45f54ed,"drivers/perf: riscv: Disable PERF_SAMPLE_BRANCH_* while not supported

RISC-V perf driver does not yet support branch sampling. Although the
specification is in the works [0]"," it is best to disable such events
until support is available","[' otherwise we will get unexpected results.\nDue to this reason', ' two riscv bpf testcases get_branch_snapshot and\nperf_branches/perf_branches_hw fail.\n\nLink: https://github.com/riscv/riscv-control-transfer-records [0]\nFixes: f5bfa23f576f (""RISC-V: Add a perf core library for pmu drivers"")\nSigned-off-by: Pu Lehui <pulehui@huawei.com>\nReviewed-by: Atish Patra <atishp@rivosinc.com>\nReviewed-by: Conor Dooley <conor.dooley@microchip.com>\nLink: https://lore.kernel.org/r/20240312012053.1178140-1-pulehui@huaweicloud.com\nSigned-off-by: Palmer Dabbelt <palmer@rivosinc.com>\n', '']",Disable unsupported branch sampling in RISC-V perf driver.,"Disable, RISC-V, branch sampling",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
37ccdf7f11b12f987c5d9ff99e67104264016c8d,37ccdf7f11b12f987c5d9ff99e67104264016c8d,Paolo Abeni,pabeni@redhat.com,1711454118,Paolo Abeni,pabeni@redhat.com,1711454118,d31b9789f55c6e186e14e10e2f72671e0d623863,f1425529c33def8b46faae4400dd9e2bbaf16a05 443574b033876c85a35de4c65c14f7fe092222b2,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Daniel Borkmann says:

====================
pull-request: bpf 2024-03-25

The following pull-request contains BPF updates for your *net* tree.

We've added 17 non-merge commits during the last 12 day(s) which contain
a total of 19 files changed", 184 insertions(+),"["" 61 deletions(-).\n\nThe main changes are:\n\n1) Fix an arm64 BPF JIT bug in BPF_LDX_MEMSX implementation's offset handling\n   found via test_bpf module"", ' from Puranjay Mohan.\n\n2) Various fixups to the BPF arena code in particular in the BPF verifier and\n   around BPF selftests to match latest corresponding LLVM implementation', '\n   from Puranjay Mohan and Alexei Starovoitov.\n\n3) Fix xsk to not assume that metadata is always requested in TX completion', ""\n   from Stanislav Fomichev.\n\n4) Fix riscv BPF JIT's kfunc parameter incompatibility between BPF and the riscv\n   ABI which requires sign-extension on int/uint"", "" from Pu Lehui.\n\n5) Fix s390x BPF JIT's bpf_plt pointer arithmetic which triggered a crash when\n   testing struct_ops"", "" from Ilya Leoshkevich.\n\n6) Fix libbpf's arena mmap handling which had incorrect u64-to-pointer cast on\n   32-bit architectures"", ' from Andrii Nakryiko.\n\n7) Fix libbpf to define MFD_CLOEXEC when not available', ' from Arnaldo Carvalho de Melo.\n\n8) Fix arm64 BPF JIT implementation for 32bit unconditional bswap which\n   resulted in an incorrect swap as indicated by test_bpf', ' from Artem Savkov.\n\n9) Fix BPF man page build script to use silent mode', "" from Hangbin Liu.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  riscv"", ' bpf: Fix kfunc parameters incompatibility between bpf and riscv abi\n  bpf: verifier: reject addr_space_cast insn without arena\n  selftests/bpf: verifier_arena: fix mmap address for arm64\n  bpf: verifier: fix addr_space_cast from as(1) to as(0)\n  libbpf: Define MFD_CLOEXEC if not available\n  arm64: bpf: fix 32bit unconditional bswap\n  bpf', "" arm64: fix bug in BPF_LDX_MEMSX\n  libbpf: fix u64-to-pointer cast on 32-bit arches\n  s390/bpf: Fix bpf_plt pointer arithmetic\n  xsk: Don't assume metadata is always requested in TX completion\n  selftests/bpf: Add arena test case for 4Gbyte corner case\n  selftests/bpf: Remove hard coded PAGE_SIZE macro.\n  libbpf"", ' selftests/bpf: Adjust libbpf', ' bpftool', ' selftests to match LLVM\n  bpf: Clarify bpf_arena comments.\n  MAINTAINERS: Update email address for Quentin Monnet\n  scripts/bpf_doc: Use silent mode when exec make cmd\n  bpf: Temporarily disable atomic operations in BPF arena\n====================\n\nLink: https://lore.kernel.org/r/20240325213520.26688-1-daniel@iogearbox.net\nSigned-off-by: Paolo Abeni <pabeni@redhat.com>\n', '']",Merges updates for BPF in linux net tree with 17 non-merge commits and 184 insertions.,"BPF updates, net tree, merge",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
151c9c724d05d5b0dd8acd3e11cb69ef1f2dbada,151c9c724d05d5b0dd8acd3e11cb69ef1f2dbada,Eric Dumazet,edumazet@google.com,1711115852,Jakub Kicinski,kuba@kernel.org,1711421517,2898f08d52d867b9e185380de9ce66d961469058,b11c81731c810efe592e510bb0110e0db6877419,"tcp: properly terminate timers for kernel sockets

We had various syzbot reports about tcp timers firing after
the corresponding netns has been dismantled.

Fortunately Josef Bacik could trigger the issue more often","
and could test a patch I wrote two years ago.

When TCP sockets are closed","["" we call inet_csk_clear_xmit_timers()\nto 'stop' the timers.\n\ninet_csk_clear_xmit_timers() can be called from any context"", '\nincluding when socket lock is held.\nThis is the reason it uses sk_stop_timer()', ' aka del_timer().\nThis means that ongoing timers might finish much later.\n\nFor user sockets', ' this is fine because each running timer\nholds a reference on the socket', ' and the user socket holds\na reference on the netns.\n\nFor kernel sockets', ' we risk that the netns is freed before\ntimer can complete', ' because kernel sockets do not hold\nreference on the netns.\n\nThis patch adds inet_csk_clear_xmit_timers_sync() function\nthat using sk_stop_timer_sync() to make sure all timers\nare terminated before the kernel socket is released.\nModules using kernel sockets close them in their netns exit()\nhandler.\n\nAlso add sock_not_owned_by_me() helper to get LOCKDEP\nsupport : inet_csk_clear_xmit_timers_sync() must not be called\nwhile socket lock is held.\n\nIt is very possible we can revert in the future commit\n3a58f13a881e (""net: rds: acquire refcount on TCP sockets"")\nwhich attempted to solve the issue in rds only.\n(net/smc/af_smc.c and net/mptcp/subflow.c have similar code)\n\nWe probably can remove the check_net() tests from\ntcp_out_of_resources() and __tcp_close() in the future.\n\nReported-by: Josef Bacik <josef@toxicpanda.com>\nCloses: https://lore.kernel.org/netdev/20240314210740.GA2823176@perftesting/\nFixes: 26abe14379f8 (""net: Modify sk_alloc to not reference count the netns of kernel sockets."")\nFixes: 8a68173691f0 (""net: sk_clone_lock() should only do get_net() if the parent is not a kernel socket"")\nLink: https://lore.kernel.org/bpf/CANn89i+484ffqb93aQm1N-tjxxvb3WDKX0EbD7318RwRgsatjw@mail.gmail.com/\nSigned-off-by: Eric Dumazet <edumazet@google.com>\nTested-by: Josef Bacik <josef@toxicpanda.com>\nCc: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>\nLink: https://lore.kernel.org/r/20240322135732.1535772-1-edumazet@google.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Fix termination of TCP timers in kernel sockets after netns dismantling.,"TCP, timers, netns",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['tracepoints like programs', 'kprobe/uprobe/ftrace like programs', ""It's not related to any of the above.""]"
443574b033876c85a35de4c65c14f7fe092222b2,443574b033876c85a35de4c65c14f7fe092222b2,Pu Lehui,pulehui@huawei.com,1711276386,Alexei Starovoitov,ast@kernel.org,1711391971,6f8415231e5bb5407d6bc803e8f846c9d6379d04,122fdbd2a030a95128737fc77e47df15a8f170c3,riscv," bpf: Fix kfunc parameters incompatibility between bpf and riscv abi

We encountered a failing case when running selftest in no_alu32 mode:

The failure case is `kfunc_call/kfunc_call_test4` and its source code is
like bellow:
```
long bpf_kfunc_call_test4(signed char a","[' short b', ' int c', ' long d) __ksym;\nint kfunc_call_test4(struct __sk_buff *skb)\n{\n\t...\n\ttmp = bpf_kfunc_call_test4(-3', ' -30', ' -200', ' -1000);\n\t...\n}\n```\n\nAnd its corresponding asm code is:\n```\n0: r1 = -3\n1: r2 = -30\n2: r3 = 0xffffff38 # opcode: 18 03 00 00 38 ff ff ff 00 00 00 00 00 00 00 00\n4: r4 = -1000\n5: call bpf_kfunc_call_test4\n```\n\ninsn 2 is parsed to ld_imm64 insn to emit 0x00000000ffffff38 imm', ' and\nconverted to int type and then send to bpf_kfunc_call_test4. But since\nit is zero-extended in the bpf calling convention', ' riscv jit will\ndirectly treat it as an unsigned 32-bit int value', ' and then fails with\nthe message ""actual 4294966063 != expected -1234"".\n\nThe reason is the incompatibility between bpf and riscv abi', ' that is', '\nbpf will do zero-extension on uint', ' but riscv64 requires sign-extension\non int or uint. We can solve this problem by sign extending the 32-bit\nparameters in kfunc.\n\nThe issue is related to [0]', ' and thanks to Yonghong and Alexei.\n\nLink: https://github.com/llvm/llvm-project/pull/84874 [0]\nFixes: d40c3847b485 (""riscv', ' bpf: Add kfunc support for RV64"")\nSigned-off-by: Pu Lehui <pulehui@huawei.com>\nTested-by: Puranjay Mohan <puranjay12@gmail.com>\nReviewed-by: Puranjay Mohan <puranjay12@gmail.com>\nLink: https://lore.kernel.org/r/20240324103306.2202954-1-pulehui@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix incompatibility of kfunc parameters between bpf and riscv ABI.,"kfunc, incompatibility, riscv",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
14bb1e8c8d4ad5d9d2febb7d19c70a3cf536e1e5,14bb1e8c8d4ad5d9d2febb7d19c70a3cf536e1e5,Yonghong Song,yonghong.song@linux.dev,1711088033,Daniel Borkmann,daniel@iogearbox.net,1711383954,5beab7217bc5c3bfadba05c5aff751e20450502f,770546ae9f4c1ae1ebcaf0874f0dd9631d77ec97,"selftests/bpf: Fix flaky test btf_map_in_map/lookup_update

Recently"," I frequently hit the following test failure:

  [root@arch-fb-vm1 bpf]# ./test_progs -n 33/1
  test_lookup_update:PASS:skel_open 0 nsec
  [...]
  test_lookup_update:PASS:sync_rcu 0 nsec
  test_lookup_update:FAIL:map1_leak inner_map1 leaked!
  #33/1    btf_map_in_map/lookup_update:FAIL
  #33      btf_map_in_map:FAIL

In the test","[' after map is closed and then after two rcu grace periods', '\nit is assumed that map_id is not available to user space.\n\nBut the above assumption cannot be guaranteed. After zero or one\nor two rcu grace periods in different siturations', ' the actual\nfreeing-map-work is put into a workqueue. Later on', ' when the work\nis dequeued', ' the map will be actually freed.\nSee bpf_map_put() in kernel/bpf/syscall.c.\n\nBy using workqueue', ' there is no ganrantee that map will be actually\nfreed after a couple of rcu grace periods. This patch removed\nsuch map leak detection and then the test can pass consistently.\n\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240322061353.632136-1-yonghong.song@linux.dev\n', '']",Fixes a flaky test in the bpf selftests related to btf_map_in_map and lookup_update.,"flaky,test,fix",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
770546ae9f4c1ae1ebcaf0874f0dd9631d77ec97,770546ae9f4c1ae1ebcaf0874f0dd9631d77ec97,Puranjay Mohan,puranjay12@gmail.com,1711305146,Alexei Starovoitov,ast@kernel.org,1711383051,3a7bbdf305e2c5ab7154fdd2c40216f17f3e4e69,a8497506cd2c0fc90a64f6f5d2744a0ddb2c81eb,"bpf: implement insn_is_cast_user() helper for JITs

Implement a helper function to check if an instruction is
addr_space_cast from as(0) to as(1). Use this helper in the x86 JIT.

Other JITs can use this helper when they add support for this instruction.

Signed-off-by: Puranjay Mohan <puranjay12@gmail.com>
Link: https://lore.kernel.org/r/20240324183226.29674-1-puranjay12@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,"Add a helper function insn_is_cast_user() for checking address space casts, integrated into x86 JIT.","helper,function,JIT",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a8497506cd2c0fc90a64f6f5d2744a0ddb2c81eb,a8497506cd2c0fc90a64f6f5d2744a0ddb2c81eb,Andrii Nakryiko,andrii@kernel.org,1710883213,Daniel Borkmann,daniel@iogearbox.net,1711382748,8f76c6f63acd573e2bf281accc765b100e06f5ef,c29083f3f5069d811b3f3c7592a0dc45ec42960c,"bpf: Avoid get_kernel_nofault() to fetch kprobe entry IP

get_kernel_nofault() (or", rather,"["" underlying copy_from_kernel_nofault())\nis not free and it does pop up in performance profiles when\nkprobes are heavily utilized with CONFIG_X86_KERNEL_IBT=y config.\n\nLet's avoid using it if we know that fentry_ip - 4 can't cross page\nboundary. We do that by masking lowest 12 bits and checking if they are\n\nAnother benefit (and actually what caused a closer look at this part of\ncode) is that now LBR record is (typically) not wasted on\ncopy_from_kernel_nofault() call and code"", ' which helps tools like\nretsnoop that grab LBR records from inside BPF code in kretprobes.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nAcked-by: Masami Hiramatsu (Google) <mhiramat@kernel.org>\nLink: https://lore.kernel.org/bpf/20240319212013.1046779-1-andrii@kernel.org\n', '']",Avoid using get_kernel_nofault() to fetch kprobe entry IP for eBPF programs.,"get_kernel_nofault,kprobe,eBPF",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
c29083f3f5069d811b3f3c7592a0dc45ec42960c,c29083f3f5069d811b3f3c7592a0dc45ec42960c,Geliang Tang,tanggeliang@kylinos.cn,1711331775,Daniel Borkmann,daniel@iogearbox.net,1711381793,8d7e988c66625e2a057a2ce58c57fcf3d6e351c4,476a5e929119725fbfcf1307cc8517d9dd2a014d,"selftests/bpf: Use start_server in bpf_tcp_ca

To simplify the code"," use BPF selftests helper start_server() in
bpf_tcp_ca.c instead of open-coding it. This helper is defined in
network_helpers.c","[' and exported in network_helpers.h', ' which is already\nincluded in bpf_tcp_ca.c.\n\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/9926a79118db27dd6d91c4854db011c599cabd0e.1711331517.git.tanggeliang@kylinos.cn\n', '']",Refactor bpf_tcp_ca.c to use start_server from network_helpers.c for simplicity.,"selftests,bpf_tcp_ca,refactor",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tc/netfilter like programs']
476a5e929119725fbfcf1307cc8517d9dd2a014d,476a5e929119725fbfcf1307cc8517d9dd2a014d,Yonghong Song,yonghong.song@linux.dev,1711337922,Daniel Borkmann,daniel@iogearbox.net,1711381016,129c86adeef179db6b02f6e9ff58f925677b9dc8,61df575632d6b39213f47810c441bddbd87c3606,"bpf: Sync uapi bpf.h to tools directory

There is a difference between kernel uapi bpf.h and tools
uapi bpf.h. There is no functionality difference"," but let
us sync properly to make it easy for later bpf.h update.

Signed-off-by: Yonghong Song <yonghong.song@linux.dev>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240325033842.1693553-1-yonghong.song@linux.dev
",[''],The commit synchronizes the uapi bpf.h between the kernel and tools directory.,"sync,uapi,tools",It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
122fdbd2a030a95128737fc77e47df15a8f170c3,122fdbd2a030a95128737fc77e47df15a8f170c3,Puranjay Mohan,puranjay12@gmail.com,1711121718,Alexei Starovoitov,ast@kernel.org,1711165449,1fe529947757590ccdc1537f14cb712f054b5141,fa3550dca8f02ec312727653a94115ef3ab68445,"bpf: verifier: reject addr_space_cast insn without arena

The verifier allows using the addr_space_cast instruction in a program
that doesn't have an associated arena. This was caught in the form an
invalid memory access in do_misc_fixups() when while converting
addr_space_cast to a normal 32-bit mov"," env->prog->aux->arena was
dereferenced to check for BPF_F_NO_USER_CONV flag.

Reject programs that include the addr_space_cast instruction but don't
have an associated arena.

root@rv-tester:~# ./reproducer
 Unable to handle kernel access to user memory without uaccess routines at virtual address 0000000000000030
 Oops [#1]
 [<ffffffff8017eeaa>] do_misc_fixups+0x43c/0x1168
 [<ffffffff801936d6>] bpf_check+0xda8/0x22b6
 [<ffffffff80174b32>] bpf_prog_load+0x486/0x8dc
 [<ffffffff80176566>] __sys_bpf+0xbd8/0x214e
 [<ffffffff80177d14>] __riscv_sys_bpf+0x22/0x2a
 [<ffffffff80d2493a>] do_trap_ecall_u+0x102/0x17c
 [<ffffffff80d3048c>] ret_from_exception+0x0/0x64

Fixes: 6082b6c328b5 (""bpf: Recognize addr_space_cast instruction in the verifier."")
Reported-by: xingwei lee <xrivendell7@gmail.com>
Reported-by: yue sun <samsun1006219@gmail.com>
Closes: https://lore.kernel.org/bpf/CABOYnLz09O1+2gGVJuCxd_24a-7UueXzV-Ff+Fr+h5EKFDiYCQ@mail.gmail.com/
Signed-off-by: Puranjay Mohan <puranjay12@gmail.com>
Link: https://lore.kernel.org/r/20240322153518.11555-1-puranjay12@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The commit fixes a memory access issue by rejecting programs using addr_space_cast without an associated arena.,"verifier, addr_space_cast, arena",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fa3550dca8f02ec312727653a94115ef3ab68445,fa3550dca8f02ec312727653a94115ef3ab68445,Puranjay Mohan,puranjay12@gmail.com,1711114552,Alexei Starovoitov,ast@kernel.org,1711165059,1fb389cc55b931a0899ff34b0aa8ab8c35c9128b,f7f5d1808b1b66935a24dd796dd1a0612ca9c147,"selftests/bpf: verifier_arena: fix mmap address for arm64

The arena_list selftest uses (1ull << 32) in the mmap address
computation for arm64. Use the same in the verifier_arena selftest.

This makes the selftest pass for arm64 on the CI[1].

[1] https://github.com/kernel-patches/bpf/pull/6622

Signed-off-by: Puranjay Mohan <puranjay12@gmail.com>
Link: https://lore.kernel.org/r/20240322133552.70681-1-puranjay12@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Fixes mmap address computation for arm64 in the bpf selftest verifier_arena.,"mmap,arm64,selftest",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f7f5d1808b1b66935a24dd796dd1a0612ca9c147,f7f5d1808b1b66935a24dd796dd1a0612ca9c147,Puranjay Mohan,puranjay12@gmail.com,1711035579,Alexei Starovoitov,ast@kernel.org,1711164996,620605b401cc5a3c90e78fe3620ab2a1c8d72c29,ddb2ffdc474a3000887dc776b971d04bde29decc,"bpf: verifier: fix addr_space_cast from as(1) to as(0)

The verifier currently converts addr_space_cast from as(1) to as(0) that
is: BPF_ALU64 | BPF_MOV | BPF_X with off=1 and imm=1
to
BPF_ALU | BPF_MOV | BPF_X with imm=1 (32-bit mov)

Because of this imm=1", the JITs that have bpf_jit_needs_zext() == true,"['\ninterpret the converted instruction as BPF_ZEXT_REG(DST) which is a\nspecial form of mov32', ' used for doing explicit zero extension on dst.\nThese JITs will just zero extend the dst reg and will not move the src to\ndst before the zext.\n\nFix do_misc_fixups() to set imm=0 when converting addr_space_cast to a\nnormal mov32.\n\nThe JITs that have bpf_jit_needs_zext() == true rely on the verifier to\nemit zext instructions. Mark dst_reg as subreg when doing cast from\nas(1) to as(0) so the verifier emits a zext instruction after the mov.\n\nFixes: 6082b6c328b5 (""bpf: Recognize addr_space_cast instruction in the verifier."")\nSigned-off-by: Puranjay Mohan <puranjay12@gmail.com>\nLink: https://lore.kernel.org/r/20240321153939.113996-1-puranjay12@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit fixes the address space cast issue in eBPF verifier from as(1) to as(0).,"verifier, addr_space_cast, fix",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
61df575632d6b39213f47810c441bddbd87c3606,61df575632d6b39213f47810c441bddbd87c3606,Yonghong Song,yonghong.song@linux.dev,1710870852,Andrii Nakryiko,andrii@kernel.org,1711143429,3e333b6d1428fde18b8b7e7ca9e4acf77e3769a3,af8d27bf15c8d68c60d830552055fcdba5b5f045,"libbpf: Add new sec_def ""sk_skb/verdict""

The new sec_def specifies sk_skb program type with
BPF_SK_SKB_VERDICT attachment type. This way"," libbpf
will set expected_attach_type properly for the program.

Signed-off-by: Yonghong Song <yonghong.song@linux.dev>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240319175412.2941149-1-yonghong.song@linux.dev
",[''],The commit adds a new sec_def specifying sk_skb program type with BPF_SK_SKB_VERDICT to set expected_attach_type in libbpf.,"sec_def, sk_skb, libbpf",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,['socket like programs']
af8d27bf15c8d68c60d830552055fcdba5b5f045,af8d27bf15c8d68c60d830552055fcdba5b5f045,Jiri Olsa,jolsa@kernel.org,1711115376,Andrii Nakryiko,andrii@kernel.org,1711126877,1cf13aac3cf073e16278b5a97614019bca93123e,1684d6eb99e480ff653af60e20ff5e7e55e69ccd,"selftests/bpf: Mark uprobe trigger functions with nocf_check attribute

Some distros seem to enable the -fcf-protection=branch by default","
which breaks our setup on first instruction of uprobe trigger
functions and place there endbr64 instruction.

Marking them with nocf_check attribute to skip that.

Ignoring unknown attribute warning in gcc for bench objects","[' because\nnocf_check can be used only when -fcf-protection=branch is enabled', '\notherwise we get a warning and break compilation.\n\nSigned-off-by: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240322134936.1075395-1-jolsa@kernel.org\n', '']",Mark uprobe trigger functions with nocf_check attribute to avoid branch protection conflicts.,"uprobe,nocf_check,protection",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
1684d6eb99e480ff653af60e20ff5e7e55e69ccd,1684d6eb99e480ff653af60e20ff5e7e55e69ccd,Alan Maguire,alan.maguire@oracle.com,1711101448,Andrii Nakryiko,andrii@kernel.org,1711126817,9a1d84164c898b093754a35a9740d3fd0fba6bc5,4c2a26fc80bcb851dc630590f2eec157991eccbf,"selftests/bpf: Use syscall(SYS_gettid) instead of gettid() wrapper in bench

With glibc 2.28"," selftests compilation fails for benchs/bench_trigger.c:

benchs/bench_trigger.c: In function ‘inc_counter’:
benchs/bench_trigger.c:25:23: error: implicit declaration of function ‘gettid’; did you mean ‘getgid’? [-Werror=implicit-function-declaration]
   25 |                 tid = gettid();
      |                       ^~~~~~
      |                       getgid
cc1: all warnings being treated as errors

It appears support for the gettid() wrapper is variable across glibc
versions","[' so may be safer to use syscall(SYS_gettid) instead.\n\nFixes: 520fad2e3206 (""selftests/bpf: scale benchmark counting by using per-CPU counters"")\nSigned-off-by: Alan Maguire <alan.maguire@oracle.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240322095728.95671-1-alan.maguire@oracle.com\n', '']",Replace gettid() with syscall(SYS_gettid) for compatibility in bench_trigger selftest.,"gettid,system call,selftests",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['other']
b3ad832d8da583ff4237b04a1ba23cdbf8918907,b3ad832d8da583ff4237b04a1ba23cdbf8918907,Ian Rogers,irogers@google.com,1711036968,Arnaldo Carvalho de Melo,acme@redhat.com,1711064675,0963f923ffcf17fed09b08440cf6af094c2f260c,2a5049b75d22c971e73501784f10548c1d69c407,"perf dso: Reorder members to save space in 'struct dso'

Save 40 bytes and move from 8 to 7 cache lines. Make member dwfl
dependent on being a powerpc build. Squeeze bits of int/enum types
when appropriate. Remove holes/padding by reordering variables.

Before:

  struct dso {
          struct mutex               lock;                 /*     0    40 */
          struct list_head           node;                 /*    40    16 */
          struct rb_node             rb_node __attribute__((__aligned__(8))); /*    56    24 */
          /* --- cacheline 1 boundary (64 bytes) was 16 bytes ago --- */
          struct rb_root *           root;                 /*    80     8 */
          struct rb_root_cached      symbols;              /*    88    16 */
          struct symbol * *          symbol_names;         /*   104     8 */
          size_t                     symbol_names_len;     /*   112     8 */
          struct rb_root_cached      inlined_nodes;        /*   120    16 */
          /* --- cacheline 2 boundary (128 bytes) was 8 bytes ago --- */
          struct rb_root_cached      srclines;             /*   136    16 */
          struct {
                  u64                addr;                 /*   152     8 */
                  struct symbol *    symbol;               /*   160     8 */
          } last_find_result;                              /*   152    16 */
          void *                     a2l;                  /*   168     8 */
          char *                     symsrc_filename;      /*   176     8 */
          unsigned int               a2l_fails;            /*   184     4 */
          enum dso_space_type        kernel;               /*   188     4 */
          /* --- cacheline 3 boundary (192 bytes) --- */
          _Bool                      is_kmod;              /*   192     1 */

          /* XXX 3 bytes hole"," try to pack */

          enum dso_swap_type         needs_swap;           /*   196     4 */
          enum dso_binary_type       symtab_type;          /*   200     4 */
          enum dso_binary_type       binary_type;          /*   204     4 */
          enum dso_load_errno        load_errno;           /*   208     4 */
          u8                         adjust_symbols:1;     /*   212: 0  1 */
          u8                         has_build_id:1;       /*   212: 1  1 */
          u8                         header_build_id:1;    /*   212: 2  1 */
          u8                         has_srcline:1;        /*   212: 3  1 */
          u8                         hit:1;                /*   212: 4  1 */
          u8                         annotate_warned:1;    /*   212: 5  1 */
          u8                         auxtrace_warned:1;    /*   212: 6  1 */
          u8                         short_name_allocated:1; /*   212: 7  1 */
          u8                         long_name_allocated:1; /*   213: 0  1 */
          u8                         is_64_bit:1;          /*   213: 1  1 */

          /* XXX 6 bits hole","[' try to pack */\n\n          _Bool                      sorted_by_name;       /*   214     1 */\n          _Bool                      loaded;               /*   215     1 */\n          u8                         rel;                  /*   216     1 */\n\n          /* XXX 7 bytes hole', ' try to pack */\n\n          struct build_id            bid;                  /*   224    32 */\n          /* --- cacheline 4 boundary (256 bytes) --- */\n          u64                        text_offset;          /*   256     8 */\n          u64                        text_end;             /*   264     8 */\n          const char  *              short_name;           /*   272     8 */\n          const char  *              long_name;            /*   280     8 */\n          u16                        long_name_len;        /*   288     2 */\n          u16                        short_name_len;       /*   290     2 */\n\n          /* XXX 4 bytes hole', ' try to pack */\n\n          void *                     dwfl;                 /*   296     8 */\n          struct auxtrace_cache *    auxtrace_cache;       /*   304     8 */\n          int                        comp;                 /*   312     4 */\n\n          /* XXX 4 bytes hole', ' try to pack */\n\n          /* --- cacheline 5 boundary (320 bytes) --- */\n          struct {\n                  struct rb_root     cache;                /*   320     8 */\n                  int                fd;                   /*   328     4 */\n                  int                status;               /*   332     4 */\n                  u32                status_seen;          /*   336     4 */\n\n                  /* XXX 4 bytes hole', ' try to pack */\n\n                  u64                file_size;            /*   344     8 */\n                  struct list_head   open_entry;           /*   352    16 */\n                  u64                elf_base_addr;        /*   368     8 */\n                  u64                debug_frame_offset;   /*   376     8 */\n                  /* --- cacheline 6 boundary (384 bytes) --- */\n                  u64                eh_frame_hdr_addr;    /*   384     8 */\n                  u64                eh_frame_hdr_offset;  /*   392     8 */\n          } data;                                          /*   320    80 */\n          struct {\n                  u32                id;                   /*   400     4 */\n                  u32                sub_id;               /*   404     4 */\n                  struct perf_env *  env;                  /*   408     8 */\n          } bpf_prog;                                      /*   400    16 */\n          union {\n                  void *             priv;                 /*   416     8 */\n                  u64                db_id;                /*   416     8 */\n          };                                               /*   416     8 */\n          struct nsinfo *            nsinfo;               /*   424     8 */\n          struct dso_id              id;                   /*   432    24 */\n          /* --- cacheline 7 boundary (448 bytes) was 8 bytes ago --- */\n          refcount_t                 refcnt;               /*   456     4 */\n          char                       name[];               /*   460     0 */\n\n          /* size: 464', ' cachelines: 8', ' members: 49 */\n          /* sum members: 440', ' holes: 4', ' sum holes: 18 */\n          /* sum bitfield members: 10 bits', ' bit holes: 1', ' sum bit holes: 6 bits */\n          /* padding: 4 */\n          /* forced alignments: 1 */\n          /* last cacheline: 16 bytes */\n  } __attribute__((__aligned__(8)));\n\nAfter:\n\n  struct dso {\n          struct mutex               lock;                 /*     0    40 */\n          struct list_head           node;                 /*    40    16 */\n          struct rb_node             rb_node __attribute__((__aligned__(8))); /*    56    24 */\n          /* --- cacheline 1 boundary (64 bytes) was 16 bytes ago --- */\n          struct rb_root *           root;                 /*    80     8 */\n          struct rb_root_cached      symbols;              /*    88    16 */\n          struct symbol * *          symbol_names;         /*   104     8 */\n          size_t                     symbol_names_len;     /*   112     8 */\n          struct rb_root_cached      inlined_nodes;        /*   120    16 */\n          /* --- cacheline 2 boundary (128 bytes) was 8 bytes ago --- */\n          struct rb_root_cached      srclines;             /*   136    16 */\n          struct {\n                  u64                addr;                 /*   152     8 */\n                  struct symbol *    symbol;               /*   160     8 */\n          } last_find_result;                              /*   152    16 */\n          struct build_id            bid;                  /*   168    32 */\n          /* --- cacheline 3 boundary (192 bytes) was 8 bytes ago --- */\n          u64                        text_offset;          /*   200     8 */\n          u64                        text_end;             /*   208     8 */\n          const char  *              short_name;           /*   216     8 */\n          const char  *              long_name;            /*   224     8 */\n          void *                     a2l;                  /*   232     8 */\n          char *                     symsrc_filename;      /*   240     8 */\n          struct nsinfo *            nsinfo;               /*   248     8 */\n          /* --- cacheline 4 boundary (256 bytes) --- */\n          struct auxtrace_cache *    auxtrace_cache;       /*   256     8 */\n          union {\n                  void *             priv;                 /*   264     8 */\n                  u64                db_id;                /*   264     8 */\n          };                                               /*   264     8 */\n          struct {\n                  struct perf_env *  env;                  /*   272     8 */\n                  u32                id;                   /*   280     4 */\n                  u32                sub_id;               /*   284     4 */\n          } bpf_prog;                                      /*   272    16 */\n          struct {\n                  struct rb_root     cache;                /*   288     8 */\n                  struct list_head   open_entry;           /*   296    16 */\n                  u64                file_size;            /*   312     8 */\n                  /* --- cacheline 5 boundary (320 bytes) --- */\n                  u64                elf_base_addr;        /*   320     8 */\n                  u64                debug_frame_offset;   /*   328     8 */\n                  u64                eh_frame_hdr_addr;    /*   336     8 */\n                  u64                eh_frame_hdr_offset;  /*   344     8 */\n                  int                fd;                   /*   352     4 */\n                  int                status;               /*   356     4 */\n                  u32                status_seen;          /*   360     4 */\n          } data;                                          /*   288    80 */\n\n          /* XXX last struct has 4 bytes of padding */\n\n          struct dso_id              id;                   /*   368    24 */\n          /* --- cacheline 6 boundary (384 bytes) was 8 bytes ago --- */\n          unsigned int               a2l_fails;            /*   392     4 */\n          int                        comp;                 /*   396     4 */\n          refcount_t                 refcnt;               /*   400     4 */\n          enum dso_load_errno        load_errno;           /*   404     4 */\n          u16                        long_name_len;        /*   408     2 */\n          u16                        short_name_len;       /*   410     2 */\n          enum dso_binary_type       symtab_type:8;        /*   412: 0  4 */\n          enum dso_binary_type       binary_type:8;        /*   412: 8  4 */\n          enum dso_space_type        kernel:2;             /*   412:16  4 */\n          enum dso_swap_type         needs_swap:2;         /*   412:18  4 */\n\n          /* Bitfield combined with next fields */\n\n          _Bool                      is_kmod:1;            /*   414: 4  1 */\n          u8                         adjust_symbols:1;     /*   414: 5  1 */\n          u8                         has_build_id:1;       /*   414: 6  1 */\n          u8                         header_build_id:1;    /*   414: 7  1 */\n          u8                         has_srcline:1;        /*   415: 0  1 */\n          u8                         hit:1;                /*   415: 1  1 */\n          u8                         annotate_warned:1;    /*   415: 2  1 */\n          u8                         auxtrace_warned:1;    /*   415: 3  1 */\n          u8                         short_name_allocated:1; /*   415: 4  1 */\n          u8                         long_name_allocated:1; /*   415: 5  1 */\n          u8                         is_64_bit:1;          /*   415: 6  1 */\n\n          /* XXX 1 bit hole', ' try to pack */\n\n          _Bool                      sorted_by_name;       /*   416     1 */\n          _Bool                      loaded;               /*   417     1 */\n          u8                         rel;                  /*   418     1 */\n          char                       name[];               /*   419     0 */\n\n          /* size: 424', ' cachelines: 7', ' members: 48 */\n          /* sum members: 415 */\n          /* sum bitfield members: 31 bits', ' bit holes: 1', ' sum bit holes: 1 bits */\n          /* padding: 5 */\n          /* paddings: 1', ' sum paddings: 4 */\n          /* forced alignments: 1 */\n          /* last cacheline: 40 bytes */\n  } __attribute__((__aligned__(8)));\n\nSigned-off-by: Ian Rogers <irogers@google.com>\nCc: Adrian Hunter <adrian.hunter@intel.com>\nCc: Ahelenia Ziemiańska <nabijaczleweli@nabijaczleweli.xyz>\nCc: Alexander Shishkin <alexander.shishkin@linux.intel.com>\nCc: Andi Kleen <ak@linux.intel.com>\nCc: Athira Rajeev <atrajeev@linux.vnet.ibm.com>\nCc: Ben Gainey <ben.gainey@arm.com>\nCc: Changbin Du <changbin.du@huawei.com>\nCc: Chengen Du <chengen.du@canonical.com>\nCc: Colin Ian King <colin.i.king@gmail.com>\nCc: Ilkka Koskinen <ilkka@os.amperecomputing.com>\nCc: Ingo Molnar <mingo@redhat.com>\nCc: James Clark <james.clark@arm.com>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: K Prateek Nayak <kprateek.nayak@amd.com>\nCc: Kan Liang <kan.liang@linux.intel.com>\nCc: Leo Yan <leo.yan@linux.dev>\nCc: Li Dong <lidong@vivo.com>\nCc: Liam Howlett <liam.howlett@oracle.com>\nCc: Mark Rutland <mark.rutland@arm.com>\nCc: Markus Elfring <Markus.Elfring@web.de>\nCc: Masami Hiramatsu <mhiramat@kernel.org>\nCc: Miguel Ojeda <ojeda@kernel.org>\nCc: Namhyung Kim <namhyung@kernel.org>\nCc: Paran Lee <p4ranlee@gmail.com>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Ravi Bangoria <ravi.bangoria@amd.com>\nCc: Song Liu <song@kernel.org>\nCc: Sun Haiyong <sunhaiyong@loongson.cn>\nCc: Yanteng Si <siyanteng@loongson.cn>\nCc: zhaimingbing <zhaimingbing@cmss.chinamobile.com>\nLink: https://lore.kernel.org/r/20240321160300.1635121-2-irogers@google.com\nSigned-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>\n', '']",Optimize 'struct dso' in perf tool by reordering members to reduce cache lines and save space.,"optimize, reorder, struct",It's a performance optimization.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['other']
cba9ffdb9913dfe6be29f049ce920ce451ce7cc4,cba9ffdb9913dfe6be29f049ce920ce451ce7cc4,Linus Torvalds,torvalds@linux-foundation.org,1711057839,Linus Torvalds,torvalds@linux-foundation.org,1711057839,7b4a85ce028c0911bd7d2a69a8801af537dca41f,1d35aae78ffe739bf46c2bf9dea7b51a4eebfbe0 f99c5f563c174a49ea1cbf4754539b05cfde40c4,"Merge tag 'net-6.9-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Jakub Kicinski:
 ""Including fixes from CAN", netfilter,"["" wireguard and IPsec.\n\n  I'd like to highlight [ lowlight? - Linus ] Florian W stepping down as\n  a netfilter maintainer due to constant stream of bug reports. Not sure\n  what we can do but IIUC this is not the first such case.\n\n  Current release - regressions:\n\n   - rxrpc: fix use of page_frag_alloc_align()"", ' it changed semantics and\n     we added a new caller in a different subtree\n\n   - xfrm: allow UDP encapsulation only in offload modes\n\n  Current release - new code bugs:\n\n   - tcp: fix refcnt handling in __inet_hash_connect()\n\n   - Revert ""net: Re-use and set mono_delivery_time bit for userspace\n     tstamp packets""', ' conflicted with some expectations in BPF uAPI\n\n  Previous releases - regressions:\n\n   - ipv4: raw: fix sending packets from raw sockets via IPsec tunnels\n\n   - devlink: fix devlink\'s parallel command processing\n\n   - veth: do not manipulate GRO when using XDP\n\n   - esp: fix bad handling of pages from page_pool\n\n  Previous releases - always broken:\n\n   - report RCU QS for busy network kthreads (with Paul McK\'s blessing)\n\n   - tcp/rds: fix use-after-free on netns with kernel TCP reqsk\n\n   - virt: vmxnet3: fix missing reserved tailroom with XDP\n\n  Misc:\n\n   - couple of build fixes for Documentation""\n\n* tag \'net-6.9-rc1\' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (59 commits)\n  selftests: forwarding: Fix ping failure due to short timeout\n  MAINTAINERS: step down as netfilter maintainer\n  netfilter: nf_tables: Fix a memory leak in nf_tables_updchain\n  net: dsa: mt7530: fix handling of all link-local frames\n  net: dsa: mt7530: fix link-local frames that ingress vlan filtering ports\n  bpf: report RCU QS in cpumap kthread\n  net: report RCU QS on threaded NAPI repolling\n  rcu: add a helper to report consolidated flavor QS\n  ionic: update documentation for XDP support\n  lib/bitmap: Fix bitmap_scatter() and bitmap_gather() kernel doc\n  netfilter: nf_tables: do not compare internal table flags on updates\n  netfilter: nft_set_pipapo: release elements in clone only from destroy path\n  octeontx2-af: Use separate handlers for interrupts\n  octeontx2-pf: Send UP messages to VF only when VF is up.\n  octeontx2-pf: Use default max_active works instead of one\n  octeontx2-pf: Wait till detach_resources msg is complete\n  octeontx2: Detect the mbox up or down message via register\n  devlink: fix port new reply cmd type\n  tcp: Clear req->syncookie in reqsk_alloc().\n  net/bnx2x: Prevent access to a freed page in page_pool\n  ...\n', '']","Merge network fixes from net-6.9-rc1 tag, includes CAN related corrections.","merge, networking, fixes",It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
4c2a26fc80bcb851dc630590f2eec157991eccbf,4c2a26fc80bcb851dc630590f2eec157991eccbf,Harishankar Vishwanathan,harishankar.vishwanathan@gmail.com,1710980994,Andrii Nakryiko,andrii@kernel.org,1711047386,7285a497ce184df14a8c17f2d33b44ba09c6e1d0,cc9b22dfa735800980e7362f02aff6f1c2280996,"bpf-next: Avoid goto in regs_refine_cond_op()

In case of GE/GT/SGE/JST instructions"," regs_refine_cond_op()
reuses the logic that does analysis of LE/LT/SLE/SLT instructions.
This commit avoids the use of a goto to perform the reuse.

Signed-off-by: Harishankar Vishwanathan <harishankar.vishwanathan@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240321002955.808604-1-harishankar.vishwanathan@gmail.com
",[''],The commit refactors the logic in regs_refine_cond_op to eliminate the use of a goto statement.,"regs_refine_cond_op, refactor, goto",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ddb2ffdc474a3000887dc776b971d04bde29decc,ddb2ffdc474a3000887dc776b971d04bde29decc,Arnaldo Carvalho de Melo,acme@kernel.org,1711036918,Andrii Nakryiko,andrii@kernel.org,1711045637,b19420fdd37dc8a46668e115ed24ee50310c000d,a51cd6bf8e10793103c5870ff9e4db295a843604,"libbpf: Define MFD_CLOEXEC if not available

Since its going directly to the syscall to avoid not having
memfd_create() available in some systems"," do the same for its
MFD_CLOEXEC flags","[' defining it if not available.\n\nThis fixes the build in those systems', ' noticed while building perf on a\nset of build containers.\n\nFixes: 9fa5e1a180aa639f (""libbpf: Call memfd_create() syscall directly"")\nSigned-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/ZfxZ9nCyKvwmpKkE@x1\n', '']",Defines MFD_CLOEXEC flag in libbpf for systems missing memfd_create support.,"libbpf, MFD_CLOEXEC, memfd_create",It's a build system or CI/CD change.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
88ce0106a1f603bf360cb397e8fe293f8298fabb,88ce0106a1f603bf360cb397e8fe293f8298fabb,Ian Rogers,irogers@google.com,1709279196,Arnaldo Carvalho de Melo,acme@redhat.com,1711040079,0fb9cd8f38d482c33a1f2ca78029ad052b2ecb30,67ee8e71daabb8632931b7559e5c8a4b69a427f8,"perf record: Delete session after stopping sideband thread

The session has a header in it which contains a perf env with
bpf_progs. The bpf_progs are accessed by the sideband thread and so
the sideband thread must be stopped before the session is deleted"," to
avoid a use after free.  This error was detected by AddressSanitizer
in the following:

  ==2054673==ERROR: AddressSanitizer: heap-use-after-free on address 0x61d000161e00 at pc 0x55769289de54 bp 0x7f9df36d4ab0 sp 0x7f9df36d4aa8
  READ of size 8 at 0x61d000161e00 thread T1
      #0 0x55769289de53 in __perf_env__insert_bpf_prog_info util/env.c:42
      #1 0x55769289dbb1 in perf_env__insert_bpf_prog_info util/env.c:29
      #2 0x557692bbae29 in perf_env__add_bpf_info util/bpf-event.c:483
      #3 0x557692bbb01a in bpf_event__sb_cb util/bpf-event.c:512
      #4 0x5576928b75f4 in perf_evlist__poll_thread util/sideband_evlist.c:68
      #5 0x7f9df96a63eb in start_thread nptl/pthread_create.c:444
      #6 0x7f9df9726a4b in clone3 ../sysdeps/unix/sysv/linux/x86_64/clone3.S:81

  0x61d000161e00 is located 384 bytes inside of 2136-byte region [0x61d000161c80","['0x61d0001624d8)\n  freed by thread T0 here:\n      #0 0x7f9dfa6d7288 in __interceptor_free libsanitizer/asan/asan_malloc_linux.cpp:52\n      #1 0x557692978d50 in perf_session__delete util/session.c:319\n      #2 0x557692673959 in __cmd_record tools/perf/builtin-record.c:2884\n      #3 0x55769267a9f0 in cmd_record tools/perf/builtin-record.c:4259\n      #4 0x55769286710c in run_builtin tools/perf/perf.c:349\n      #5 0x557692867678 in handle_internal_command tools/perf/perf.c:402\n      #6 0x557692867a40 in run_argv tools/perf/perf.c:446\n      #7 0x557692867fae in main tools/perf/perf.c:562\n      #8 0x7f9df96456c9 in __libc_start_call_main ../sysdeps/nptl/libc_start_call_main.h:58\n\nFixes: 657ee5531903339b (""perf evlist: Introduce side band thread"")\nSigned-off-by: Ian Rogers <irogers@google.com>\nCc: Adrian Hunter <adrian.hunter@intel.com>\nCc: Alexander Shishkin <alexander.shishkin@linux.intel.com>\nCc: Athira Rajeev <atrajeev@linux.vnet.ibm.com>\nCc: Christian Brauner <brauner@kernel.org>\nCc: Disha Goel <disgoel@linux.ibm.com>\nCc: Ingo Molnar <mingo@redhat.com>\nCc: James Clark <james.clark@arm.com>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: Kajol Jain <kjain@linux.ibm.com>\nCc: Kan Liang <kan.liang@linux.intel.com>\nCc: K Prateek Nayak <kprateek.nayak@amd.com>\nCc: Mark Rutland <mark.rutland@arm.com>\nCc: Namhyung Kim <namhyung@kernel.org>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Song Liu <songliubraving@fb.com>\nCc: Tim Chen <tim.c.chen@linux.intel.com>\nCc: Yicong Yang <yangyicong@hisilicon.com>\nLink: https://lore.kernel.org/r/20240301074639.2260708-1-irogers@google.com\nSigned-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>\n', '']",Fixes a use-after-free error by ensuring the sideband thread stops before deleting the session in perf record.,"use-after-free, sideband thread, perf record",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
a51cd6bf8e10793103c5870ff9e4db295a843604,a51cd6bf8e10793103c5870ff9e4db295a843604,Artem Savkov,asavkov@redhat.com,1711009089,Alexei Starovoitov,ast@kernel.org,1711018745,b43ed013baaf135044a4b751e52cfca9749c872a,114b5b3b4bde7358624437be2f12cde1b265224e,"arm64: bpf: fix 32bit unconditional bswap

In case when is64 == 1 in emit(A64_REV32(is64", dst,"[' dst)', ' ctx) the\ngenerated insn reverses byte order for both high and low 32-bit words', '\nresuling in an incorrect swap as indicated by the jit test:\n\n[ 9757.262607] test_bpf: #312 BSWAP 16: 0x0123456789abcdef -> 0xefcd jited:1 8 PASS\n[ 9757.264435] test_bpf: #313 BSWAP 32: 0x0123456789abcdef -> 0xefcdab89 jited:1 ret 1460850314 != -271733879 (0x5712ce8a != 0xefcdab89)FAIL (1 times)\n[ 9757.266260] test_bpf: #314 BSWAP 64: 0x0123456789abcdef -> 0x67452301 jited:1 8 PASS\n[ 9757.268000] test_bpf: #315 BSWAP 64: 0x0123456789abcdef >> 32 -> 0xefcdab89 jited:1 8 PASS\n[ 9757.269686] test_bpf: #316 BSWAP 16: 0xfedcba9876543210 -> 0x1032 jited:1 8 PASS\n[ 9757.271380] test_bpf: #317 BSWAP 32: 0xfedcba9876543210 -> 0x10325476 jited:1 ret -1460850316 != 271733878 (0xa8ed3174 != 0x10325476)FAIL (1 times)\n[ 9757.273022] test_bpf: #318 BSWAP 64: 0xfedcba9876543210 -> 0x98badcfe jited:1 7 PASS\n[ 9757.274721] test_bpf: #319 BSWAP 64: 0xfedcba9876543210 >> 32 -> 0x10325476 jited:1 9 PASS\n\nFix this by forcing 32bit variant of rev32.\n\nFixes: 1104247f3f979 (""bpf', ' arm64: Support unconditional bswap"")\nSigned-off-by: Artem Savkov <asavkov@redhat.com>\nTested-by: Puranjay Mohan <puranjay12@gmail.com>\nAcked-by: Puranjay Mohan <puranjay12@gmail.com>\nAcked-by: Xu Kuohai <xukuohai@huawei.com>\nMessage-ID: <20240321081809.158803-1-asavkov@redhat.com>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes an issue with 32-bit unconditional byte swap in ARM64 BPF code.,"ARM64, BPF, fix",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
cc9b22dfa735800980e7362f02aff6f1c2280996,cc9b22dfa735800980e7362f02aff6f1c2280996,Quentin Monnet,qmo@kernel.org,1710898863,Alexei Starovoitov,ast@kernel.org,1711002829,3203601a079fc7f6bfa75424390e5c8c908315fe,520fad2e3206b2476f201a283ecf096cfb671902,bpftool: Clean up HOST_CFLAGS," HOST_LDFLAGS for bootstrap bpftool

Bpftool's Makefile uses $(HOST_CFLAGS) to build the bootstrap version of
bpftool","[' in order to pick the flags for the host (where we run the\nbootstrap version) and not for the target system (where we plan to run\nthe full bpftool binary). But we pass too much information through this\nvariable.\n\nIn particular', ' we set HOST_CFLAGS by copying most of the $(CFLAGS); but\nwe do this after the feature detection for bpftool', ' which means that\n$(CFLAGS)', ' hence $(HOST_CFLAGS)', ' contain all macro definitions for using\nthe different optional features. For example', ' -DHAVE_LLVM_SUPPORT may be\npassed to the $(HOST_CFLAGS)', ' even though the LLVM disassembler is not\nused in the bootstrap version', ' and the related library may even be\nmissing for the host architecture.\n\nA similar thing happens with the $(LDFLAGS)', ' that we use unchanged for\nlinking the bootstrap version even though they may contains flags to\nlink against additional libraries.\n\nTo address the $(HOST_CFLAGS) issue', ' we move the definition of\n$(HOST_CFLAGS) earlier in the Makefile', ' before the $(CFLAGS) update\nresulting from the feature probing - none of which being relevant to the\nbootstrap version. To clean up the $(LDFLAGS) for the bootstrap version', '\nwe introduce a dedicated $(HOST_LDFLAGS) variable that we base on\n$(LDFLAGS)', ' before the feature probing as well.\n\nOn my setup', ' the following macro and libraries are removed from the\ncompiler invocation to build bpftool after this patch:\n\n  -DUSE_LIBCAP\n  -DHAVE_LLVM_SUPPORT\n  -I/usr/lib/llvm-17/include\n  -D_GNU_SOURCE\n  -D__STDC_CONSTANT_MACROS\n  -D__STDC_FORMAT_MACROS\n  -D__STDC_LIMIT_MACROS\n  -lLLVM-17\n  -L/usr/lib/llvm-17/lib\n\nAnother advantage of cleaning up these flags is that displaying\navailable features with ""bpftool version"" becomes more accurate for the\nbootstrap bpftool', ' and no longer reflects the features detected (and\navailable only) for the final binary.\n\nCc: Jean-Philippe Brucker <jean-philippe@linaro.org>\nSigned-off-by: Quentin Monnet <qmo@kernel.org>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nMessage-ID: <20240320014103.45641-1-qmo@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Clean up HOST_CFLAGS usage in bpftool's Makefile for bootstrap build.,"bpftool, Makefile, HOST_CFLAGS",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,['other']
3201de46a2013293abe28caa46aa0387864d7cf7,3201de46a2013293abe28caa46aa0387864d7cf7,Jakub Kicinski,kuba@kernel.org,1710993944,Jakub Kicinski,kuba@kernel.org,1710993945,bb54c5de6214b985d103ec0d400e6b8d9527e10f,f7bf0ec1e73d43a347489e958b42841b111d63d6 00bf63122459e87193ee7f1bc6161c83a525569f,"Merge branch 'report-rcu-qs-for-busy-network-kthreads'

Yan Zhai says:

====================
Report RCU QS for busy network kthreads

This changeset fixes a common problem for busy networking kthreads.
These threads", e.g. NAPI threads,"[' typically will do:\n\n* polling a batch of packets\n* if there are more work', ' call cond_resched() to allow scheduling\n* continue to poll more packets when rx queue is not empty\n\nWe observed this being a problem in production', ' since it can block RCU\ntasks from making progress under heavy load. Investigation indicates\nthat just calling cond_resched() is insufficient for RCU tasks to reach\nquiescent states. This also has the side effect of frequently clearing\nthe TIF_NEED_RESCHED flag on voluntary preempt kernels. As a result', '\nschedule() will not be called in these circumstances', ' despite schedule()\nin fact provides required quiescent states. This at least affects NAPI\nthreads', ' napi_busy_loop', ' and also cpumap kthread.\n\nBy reporting RCU QSes in these kthreads periodically before cond_resched', ' the\nblocked RCU waiters can correctly progress. Instead of just reporting QS for\nRCU tasks', ' these code share the same concern as noted in the commit\nd28139c4e967 (""rcu: Apply RCU-bh QSes to RCU-sched and RCU-preempt when safe"").\nSo report a consolidated QS for safety.\n\nIt is worth noting that', ' although this problem is reproducible in\nnapi_busy_loop', ' it only shows up when setting the polling interval to as high\nas 2ms', ' which is far larger than recommended 50us-100us in the documentation.\nSo napi_busy_loop is left untouched.\n\nLastly', ' this does not affect RT kernels', ' which does not enter the scheduler\nthrough cond_resched(). Without the mentioned side effect', ' schedule() will\nbe called time by time', ' and clear the RCU task holdouts.\n\nV4: https://lore.kernel.org/bpf/cover.1710525524.git.yan@cloudflare.com/\nV3: https://lore.kernel.org/lkml/20240314145459.7b3aedf1@kernel.org/t/\nV2: https://lore.kernel.org/bpf/ZeFPz4D121TgvCje@debian.debian/\nV1: https://lore.kernel.org/lkml/Zd4DXTyCf17lcTfq@debian.debian/#t\n====================\n\nLink: https://lore.kernel.org/r/cover.1710877680.git.yan@cloudflare.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Fixes RCU quiescent state reporting for busy network kernel threads.,"RCU,kthreads,networking",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
00bf63122459e87193ee7f1bc6161c83a525569f,00bf63122459e87193ee7f1bc6161c83a525569f,Yan Zhai,yan@cloudflare.com,1710881080,Jakub Kicinski,kuba@kernel.org,1710993943,bb54c5de6214b985d103ec0d400e6b8d9527e10f,d6dbbb11247c71203785a2c9da474c36f4b19eae,"bpf: report RCU QS in cpumap kthread

When there are heavy load"," cpumap kernel threads can be busy polling
packets from redirect queues and block out RCU tasks from reaching
quiescent states. It is insufficient to just call cond_resched() in such
context. Periodically raise a consolidated RCU QS before cond_resched
fixes the problem.

Fixes: 6710e1126934 (""bpf: introduce new bpf cpu map type BPF_MAP_TYPE_CPUMAP"")
Reviewed-by: Jesper Dangaard Brouer <hawk@kernel.org>
Signed-off-by: Yan Zhai <yan@cloudflare.com>
Acked-by: Paul E. McKenney <paulmck@kernel.org>
Acked-by: Jesper Dangaard Brouer <hawk@kernel.org>
Link: https://lore.kernel.org/r/c17b9f1517e19d813da3ede5ed33ee18496bb5d8.1710877680.git.yan@cloudflare.com
Signed-off-by: Jakub Kicinski <kuba@kernel.org>
",[''],The commit adds periodic RCU quiescent state reporting in cpumap kthreads to prevent blocking RCU tasks.,"RCU, cpumap, kthread",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d6dbbb11247c71203785a2c9da474c36f4b19eae,d6dbbb11247c71203785a2c9da474c36f4b19eae,Yan Zhai,yan@cloudflare.com,1710881077,Jakub Kicinski,kuba@kernel.org,1710993942,01b60754e953d9a3c3d5109a37a25112fd374362,1a77557d48cff187a169c2aec01c0dd78a5e7e50,"net: report RCU QS on threaded NAPI repolling

NAPI threads can keep polling packets under load. Currently it is only
calling cond_resched() before repolling"," but it is not sufficient to
clear out the holdout of RCU tasks","[' which prevent BPF tracing programs\nfrom detaching for long period. This can be reproduced easily with\nfollowing set up:\n\nip netns add test1\nip netns add test2\n\nip -n test1 link add veth1 type veth peer name veth2 netns test2\n\nip -n test1 link set veth1 up\nip -n test1 link set lo up\nip -n test2 link set veth2 up\nip -n test2 link set lo up\n\nip -n test1 addr add 192.168.1.2/31 dev veth1\nip -n test1 addr add 1.1.1.1/32 dev lo\nip -n test2 addr add 192.168.1.3/31 dev veth2\nip -n test2 addr add 2.2.2.2/31 dev lo\n\nip -n test1 route add default via 192.168.1.3\nip -n test2 route add default via 192.168.1.2\n\nfor i in `seq 10 210`; do\n for j in `seq 10 210`; do\n    ip netns exec test2 iptables -I INPUT -s 3.3.$i.$j -p udp --dport 5201\n done\ndone\n\nip netns exec test2 ethtool -K veth2 gro on\nip netns exec test2 bash -c \'echo 1 > /sys/class/net/veth2/threaded\'\nip netns exec test1 ethtool -K veth1 tso off\n\nThen run an iperf3 client/server and a bpftrace script can trigger it:\n\nip netns exec test2 iperf3 -s -B 2.2.2.2 >/dev/null&\nip netns exec test1 iperf3 -c 2.2.2.2 -B 1.1.1.1 -u -l 1500 -b 3g -t 100 >/dev/null&\nbpftrace -e \'kfunc:__napi_poll{@=count();} interval:s:1{exit();}\'\n\nReport RCU quiescent states periodically will resolve the issue.\n\nFixes: 29863d41bb6e (""net: implement threaded-able napi poll loop support"")\nReviewed-by: Jesper Dangaard Brouer <hawk@kernel.org>\nSigned-off-by: Yan Zhai <yan@cloudflare.com>\nAcked-by: Paul E. McKenney <paulmck@kernel.org>\nAcked-by: Jesper Dangaard Brouer <hawk@kernel.org>\nLink: https://lore.kernel.org/r/4c3b0d3f32d3b18949d75b18e5e1d9f13a24f025.1710877680.git.yan@cloudflare.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Improve RCU task handling during threaded NAPI repolling to optimize network packet processing.,"RCU, NAPI, repolling",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
520fad2e3206b2476f201a283ecf096cfb671902,520fad2e3206b2476f201a283ecf096cfb671902,Andrii Nakryiko,andrii@kernel.org,1710538409,Alexei Starovoitov,ast@kernel.org,1710916895,e4fee37094eff46816887a0f211fe37972ce71f5,e9a826dd145bf2c19888aee1b974214cefc74a2e,"selftests/bpf: scale benchmark counting by using per-CPU counters

When benchmarking with multiple threads (-pN", where N>1),"[' we start\ncontending on single atomic counter that both BPF trigger benchmarks are\nusing', ' as well as ""baseline"" tests in user space (trig-base and\ntrig-uprobe-base benchmarks). As such', ' we start bottlenecking on\nsomething completely irrelevant to benchmark at hand.\n\nScale counting up by using per-CPU counters on BPF side. On use space\nside we do the next best thing: hash thread ID to approximate per-CPU\nbehavior. It seems to work quite well in practice.\n\nTo demonstrate the difference', ' I ran three benchmarks with 1', ' 2', ' 4', ' 8', '\n16', ' and 32 threads:\n  - trig-uprobe-base (no syscalls', ' pure tight counting loop in user-space);\n  - trig-base (get_pgid() syscall', ' atomic counter in user-space);\n  - trig-fentry (syscall to trigger fentry program', ' atomic uncontended per-CPU\n    counter on BPF side).\n\nCommand used:\n\n  for b in uprobe-base base fentry; do \\\n    for p in 1 2 4 8 16 32; do \\\n      printf ""%-11s %2d: %s\\n"" $b $p \\\n        ""$(sudo ./bench -w2 -d5 -a -p$p trig-$b | tail -n1 | cut -d\'(\' -f1 | cut -d\' \' -f3-)""; \\\n    done; \\\n  done\n\nBefore these changes', "" aggregate throughput across all threads doesn't\nscale well with number of threads"", ' it actually even falls sharply for\nuprobe-base due to a very high contention:\n\n  uprobe-base  1:  138.998 ± 0.650M/s\n  uprobe-base  2:   70.526 ± 1.147M/s\n  uprobe-base  4:   63.114 ± 0.302M/s\n  uprobe-base  8:   54.177 ± 0.138M/s\n  uprobe-base 16:   45.439 ± 0.057M/s\n  uprobe-base 32:   37.163 ± 0.242M/s\n  base         1:   16.940 ± 0.182M/s\n  base         2:   19.231 ± 0.105M/s\n  base         4:   21.479 ± 0.038M/s\n  base         8:   23.030 ± 0.037M/s\n  base        16:   22.034 ± 0.004M/s\n  base        32:   18.152 ± 0.013M/s\n  fentry       1:   14.794 ± 0.054M/s\n  fentry       2:   17.341 ± 0.055M/s\n  fentry       4:   23.792 ± 0.024M/s\n  fentry       8:   21.557 ± 0.047M/s\n  fentry      16:   21.121 ± 0.004M/s\n  fentry      32:   17.067 ± 0.023M/s\n\nAfter these changes', ' we see almost perfect linear scaling', ' as expected.\nThe sub-linear scaling when going from 8 to 16 threads is interesting\nand consistent on my test machine', "" but I haven't investigated what is\ncausing it this peculiar slowdown (across all benchmarks"", ' could be due\nto hyperthreading effects', ' not sure).\n\n  uprobe-base  1:  139.980 ± 0.648M/s\n  uprobe-base  2:  270.244 ± 0.379M/s\n  uprobe-base  4:  532.044 ± 1.519M/s\n  uprobe-base  8: 1004.571 ± 3.174M/s\n  uprobe-base 16: 1720.098 ± 0.744M/s\n  uprobe-base 32: 3506.659 ± 8.549M/s\n  base         1:   16.869 ± 0.071M/s\n  base         2:   33.007 ± 0.092M/s\n  base         4:   64.670 ± 0.203M/s\n  base         8:  121.969 ± 0.210M/s\n  base        16:  207.832 ± 0.112M/s\n  base        32:  424.227 ± 1.477M/s\n  fentry       1:   14.777 ± 0.087M/s\n  fentry       2:   28.575 ± 0.146M/s\n  fentry       4:   56.234 ± 0.176M/s\n  fentry       8:  106.095 ± 0.385M/s\n  fentry      16:  181.440 ± 0.032M/s\n  fentry      32:  369.131 ± 0.693M/s\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nMessage-ID: <20240315213329.1161589-1-andrii@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Enhance benchmark accuracy by implementing per-CPU counters in selftests for multi-threaded environments.,"benchmark, per-CPU, selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"[""It's not related to any of the above.""]"
e9a826dd145bf2c19888aee1b974214cefc74a2e,e9a826dd145bf2c19888aee1b974214cefc74a2e,Quentin Monnet,qmo@kernel.org,1710898497,Alexei Starovoitov,ast@kernel.org,1710915475,0fa8f3b9dfbc7abc770a626991f7405497945790,be24a895149b6df4c474848e3928c237ad10fdc4,"bpftool: Remove unnecessary source files from bootstrap version

Commit d510296d331a (""bpftool: Use syscall/loader program in ""prog load""
and ""gen skeleton"" command."") added new files to the list of objects to
compile in order to build the bootstrap version of bpftool. As far as I
can tell"," these objects are unnecessary and were added by mistake; maybe
a draft version intended to add support for loading loader programs from
the bootstrap version. Anyway","[' we can remove these object files from the\nlist to make the bootstrap bpftool binary a tad smaller and faster to\nbuild.\n\nFixes: d510296d331a (""bpftool: Use syscall/loader program in ""prog load"" and ""gen skeleton"" command."")\nSigned-off-by: Quentin Monnet <qmo@kernel.org>\nMessage-ID: <20240320013457.44808-1-qmo@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Remove unnecessary source files from bpftool's bootstrap version due to mistaken inclusion.,"bpftool, bootstrap, unnecessary",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"[""It's not related to any of the above.""]"
be24a895149b6df4c474848e3928c237ad10fdc4,be24a895149b6df4c474848e3928c237ad10fdc4,Quentin Monnet,qmo@kernel.org,1710897761,Alexei Starovoitov,ast@kernel.org,1710915142,43ff9022833899117df1e0abacc2f6a807abfdba,2e244a72cd489e9b8d4c779c0674c80cf92b6aab,"bpftool: Enable libbpf logs when loading pid_iter in debug mode

When trying to load the pid_iter BPF program used to iterate over the
PIDs of the processes holding file descriptors to BPF links"," we would
unconditionally silence libbpf in order to keep the output clean if the
kernel does not support iterators and loading fails.

Although this is the desirable behaviour in most cases","[' this may hide\nbugs in the pid_iter program that prevent it from loading', ' and it makes\nit hard to debug such load failures', ' even in ""debug"" mode. Instead', "" it\nmakes more sense to print libbpf's logs when we pass the -d|--debug flag\nto bpftool"", "" so that users get the logs to investigate failures without\nhaving to edit bpftool's source code.\n\nSigned-off-by: Quentin Monnet <qmo@kernel.org>\nMessage-ID: <20240320012241.42991-1-qmo@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Enable libbpf logs for pid_iter BPF program in debug mode in bpftool.,"libbpf, pid_iter, debug",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The bpftool utility,['tracepoints like programs']
2e244a72cd489e9b8d4c779c0674c80cf92b6aab,2e244a72cd489e9b8d4c779c0674c80cf92b6aab,Alexei Starovoitov,ast@kernel.org,1710914734,Alexei Starovoitov,ast@kernel.org,1710914734,53411f9aa32fbcae919dc97e705a7598893d5156,f803bcf9208a2540acb4c32bdc3616673169f490 51146ff0fae309a558bc8ab6cbf6cfda17356993,"Merge branch 'bpf-raw-tracepoint-support-for-bpf-cookie'

Andrii Nakryiko says:

====================
BPF raw tracepoint support for BPF cookie

Add ability to specify and retrieve BPF cookie for raw tracepoint programs.
Both BTF-aware (SEC(""tp_btf"")) and non-BTF-aware (SEC(""raw_tp"")) are
supported"," as they are exactly the same at runtime.

This issue recently came up in production use cases","[' where custom tried to\nswitch from slower classic tracepoints to raw tracepoints and ran into this\nlimitation. Luckily', "" it's not that hard to support this for raw_tp programs.\n\nv2->v3:\n  - s/bpf_raw_tp_open/bpf_raw_tracepoint_open_opts/ (Alexei"", ' Eduard);\nv1->v2:\n  - fixed type definition for stubs of bpf_probe_{register', ""unregister};\n  - added __u32 :u32 and aligned raw_tp fields (Jiri);\n  - added Stanislav's ack.\n====================\n\nLink: https://lore.kernel.org/r/20240319233852.1977493-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']","Add support for specifying and retrieving BPF cookies in raw tracepoint programs, including BTF-aware and non-BTF-aware implementations.","BPF cookie,raw tracepoint,support",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
51146ff0fae309a558bc8ab6cbf6cfda17356993,51146ff0fae309a558bc8ab6cbf6cfda17356993,Andrii Nakryiko,andrii@kernel.org,1710891532,Alexei Starovoitov,ast@kernel.org,1710914734,53411f9aa32fbcae919dc97e705a7598893d5156,36ffb2023e3703a64266ca5fed30f710b1263c70,"selftests/bpf: add raw_tp/tp_btf BPF cookie subtests

Add test validating BPF cookie can be passed during raw_tp/tp_btf
attachment and can be retried at runtime with bpf_get_attach_cookie()
helper.

Acked-by: Stanislav Fomichev <sdf@google.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Message-ID: <20240319233852.1977493-6-andrii@kernel.org>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add subtests for validating BPF cookie during raw_tp/tp_btf attachment using bpf_get_attach_cookie() helper.,"BPF cookie,raw_tp,tp_btf",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tracepoints like programs']
36ffb2023e3703a64266ca5fed30f710b1263c70,36ffb2023e3703a64266ca5fed30f710b1263c70,Andrii Nakryiko,andrii@kernel.org,1710891531,Alexei Starovoitov,ast@kernel.org,1710914734,fb05c40a43afcd3f237b38c253256379c0a23a09,68ca5d4eebb8c4de246ee5f634eee26bc689562d,"libbpf: add support for BPF cookie for raw_tp/tp_btf programs

Wire up BPF cookie passing or raw_tp and tp_btf programs"," both in
low-level and high-level APIs.

Acked-by: Stanislav Fomichev <sdf@google.com>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Message-ID: <20240319233852.1977493-5-andrii@kernel.org>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Added support for BPF cookie in libbpf for raw_tp and tp_btf programs.,"BPF cookie, raw_tp, tp_btf",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
68ca5d4eebb8c4de246ee5f634eee26bc689562d,68ca5d4eebb8c4de246ee5f634eee26bc689562d,Andrii Nakryiko,andrii@kernel.org,1710891530,Alexei Starovoitov,ast@kernel.org,1710914734,bca6f6bf993364106eab3d99e79796e4ca01685e,d4dfc5700e867b22ab94f960f9a9972696a637d5,bpf: support BPF cookie in raw tracepoint (raw_tp," tp_btf) programs

Wire up BPF cookie for raw tracepoint programs (both BTF and non-BTF
aware variants). This brings them up to part w.r.t. BPF cookie usage
with classic tracepoint and fentry/fexit programs.

Acked-by: Stanislav Fomichev <sdf@google.com>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Message-ID: <20240319233852.1977493-4-andrii@kernel.org>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Wire up BPF cookie support for raw tracepoint programs in both BTF and non-BTF variants.,"BPF cookie, raw tracepoint, BTF",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
d4dfc5700e867b22ab94f960f9a9972696a637d5,d4dfc5700e867b22ab94f960f9a9972696a637d5,Andrii Nakryiko,andrii@kernel.org,1710891529,Alexei Starovoitov,ast@kernel.org,1710914733,fa2c0c39612987fdcab3cd17e8f34b5908fe7d31,6b9c2950c912780ce113079c9c52041b1e2a611a,"bpf: pass whole link instead of prog when triggering raw tracepoint

Instead of passing prog as an argument to bpf_trace_runX() helpers"," that
are called from tracepoint triggering calls","[' store BPF link itself\n(struct bpf_raw_tp_link for raw tracepoints). This will allow to pass\nextra information like BPF cookie into raw tracepoint registration.\n\nInstead of replacing `struct bpf_prog *prog = __data;` with\ncorresponding `struct bpf_raw_tp_link *link = __data;` assignment in\n`__bpf_trace_##call` I just passed `__data` through into underlying\nbpf_trace_runX() call. This works well because we implicitly cast `void *`', '\nand it also avoids naming clashes with arguments coming from\ntracepoint\'s ""proto"" list. We could have run into the same problem with\n""prog""', ' we just happened to not have a tracepoint that has ""prog"" input\nargument. We are less lucky with ""link""', ' as there are tracepoints using\n""link"" argument name already. So instead of trying to avoid naming\nconflicts', "" let's just remove intermediate local variable. It doesn't\nhurt readibility"", "" it's either way a bit of a maze of calls and macros"", '\nthat requires careful reading.\n\nAcked-by: Stanislav Fomichev <sdf@google.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nMessage-ID: <20240319233852.1977493-3-andrii@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit changes the argument to bpf_trace_runX() helpers from prog to the whole link for triggering raw tracepoints.,"bpf, tracepoints, link",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
6b9c2950c912780ce113079c9c52041b1e2a611a,6b9c2950c912780ce113079c9c52041b1e2a611a,Andrii Nakryiko,andrii@kernel.org,1710891528,Alexei Starovoitov,ast@kernel.org,1710914733,bb5b88cda791dce09c4065b1ee1c20a985d2f623,f803bcf9208a2540acb4c32bdc3616673169f490,"bpf: flatten bpf_probe_register call chain

bpf_probe_register() and __bpf_probe_register() have identical
signatures and bpf_probe_register() just redirect to
__bpf_probe_register(). So get rid of this extra function call step to
simplify following the source code.

It has no difference at runtime due to inlining"," of course.

Acked-by: Stanislav Fomichev <sdf@google.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Message-ID: <20240319233852.1977493-2-andrii@kernel.org>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The commit simplifies the source code by removing an unnecessary function call step in bpf_probe_register.,"simplify,function,call",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
114b5b3b4bde7358624437be2f12cde1b265224e,114b5b3b4bde7358624437be2f12cde1b265224e,Puranjay Mohan,puranjay12@gmail.com,1710287957,Alexei Starovoitov,ast@kernel.org,1710914119,939f3098ea73a57a4752cced16f8e3e97f2c7c28,5ab8cb89dbb6f3e111c8b0a9a86496da23c94439,bpf," arm64: fix bug in BPF_LDX_MEMSX

A64_LDRSW() takes three registers: Xt","[' Xn', ' Xm as arguments and it loads\nand sign extends the value at address Xn + Xm into register Xt.\n\nCurrently', ' the offset is being directly used in place of the tmp\nregister which has the offset already loaded by the last emitted\ninstruction.\n\nThis will cause JIT failures. The easiest way to reproduce this is to\ntest the following code through test_bpf module:\n\n{\n\t""BPF_LDX_MEMSX | BPF_W""', '\n\t.u.insns_int = {\n\t\tBPF_LD_IMM64(R1', ' 0x00000000deadbeefULL)', '\n\t\tBPF_LD_IMM64(R2', ' 0xffffffffdeadbeefULL)', '\n\t\tBPF_STX_MEM(BPF_DW', ' R10', ' R1', ' -7)', '\n\t\tBPF_LDX_MEMSX(BPF_W', ' R0', ' R10', ' -7)', '\n\t\tBPF_JMP_REG(BPF_JNE', ' R0', ' R2', ' 1)', '\n\t\tBPF_ALU64_IMM(BPF_MOV', ' R0', ' 0)', '\n\t\tBPF_EXIT_INSN()', '\n\t}', '\n\tINTERNAL', '\n\t{ }', '\n\t{ { 0', ' 0 } }', '\n\t.stack_depth = 7', '\n}', '\n\nWe need to use the offset as -7 to trigger this code path', ' there could\nbe other valid ways to trigger this from proper BPF programs as well.\n\nThis code is rejected by the JIT because -7 is passed to A64_LDRSW() but\nit expects a valid register (0 - 31).\n\n roott@pjy:~# modprobe test_bpf test_name=""BPF_LDX_MEMSX | BPF_W""\n [11300.490371] test_bpf: test_bpf: set \'test_bpf\' as the default test_suite.\n [11300.491750] test_bpf: #345 BPF_LDX_MEMSX | BPF_W\n [11300.493179] aarch64_insn_encode_register: unknown register encoding -7\n [11300.494133] aarch64_insn_encode_register: unknown register encoding -7\n [11300.495292] FAIL to select_runtime err=-524\n [11300.496804] test_bpf: Summary: 0 PASSED', ' 1 FAILED', ' [0/0 JIT\'ed]\n modprobe: ERROR: could not insert \'test_bpf\': Invalid argument\n\nApplying this patch fixes the issue.\n\n root@pjy:~# modprobe test_bpf test_name=""BPF_LDX_MEMSX | BPF_W""\n [  292.837436] test_bpf: test_bpf: set \'test_bpf\' as the default test_suite.\n [  292.839416] test_bpf: #345 BPF_LDX_MEMSX | BPF_W jited:1 156 PASS\n [  292.844794] test_bpf: Summary: 1 PASSED', ' 0 FAILED', ' [1/1 JIT\'ed]\n\nFixes: cc88f540da52 (""bpf', ' arm64: Support sign-extension load instructions"")\nSigned-off-by: Puranjay Mohan <puranjay12@gmail.com>\nMessage-ID: <20240312235917.103626-1-puranjay12@gmail.com>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix a bug related to the BPF_LDX_MEMSX instruction on arm64.,"bug, BPF_LDX_MEMSX, arm64",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5ab8cb89dbb6f3e111c8b0a9a86496da23c94439,5ab8cb89dbb6f3e111c8b0a9a86496da23c94439,Andrii Nakryiko,andrii@kernel.org,1710885103,Alexei Starovoitov,ast@kernel.org,1710914044,e39824b931c665dba7872599e8d7a3982292e036,7ded842b356d151ece8ac4985940438e6d3998bb,"libbpf: fix u64-to-pointer cast on 32-bit arches

It's been reported that (void *)map->map_extra is causing compilation
warnings on 32-bit architectures. It's easy enough to fix this by
casting to long first.

Fixes: 79ff13e99169 (""libbpf: Add support for bpf_arena."")
Reported-by: Ryan Eatmon <reatmon@ti.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Message-ID: <20240319215143.1279312-1-andrii@kernel.org>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Fix compilation warning on 32-bit architectures by adjusting u64-to-pointer casting in libbpf.,"libbpf,cast,32-bit",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"[""It's not related to any of the above.""]"
7ded842b356d151ece8ac4985940438e6d3998bb,7ded842b356d151ece8ac4985940438e6d3998bb,Ilya Leoshkevich,iii@linux.ibm.com,1710899652,Alexei Starovoitov,ast@kernel.org,1710913963,f3232760a376c683a629c6c47e9ac4a9500967d1,f6e922365faf4cd576bd1cf3e64b58c8a32e1856,"s390/bpf: Fix bpf_plt pointer arithmetic

Kui-Feng Lee reported a crash on s390x triggered by the
dummy_st_ops/dummy_init_ptr_arg test [1]:

  [<0000000000000002>] 0x2
  [<00000000009d5cde>] bpf_struct_ops_test_run+0x156/0x250
  [<000000000033145a>] __sys_bpf+0xa1a/0xd00
  [<00000000003319dc>] __s390x_sys_bpf+0x44/0x50
  [<0000000000c4382c>] __do_syscall+0x244/0x300
  [<0000000000c59a40>] system_call+0x70/0x98

This is caused by GCC moving memcpy() after assignments in
bpf_jit_plt()"," resulting in NULL pointers being written instead of
the return and the target addresses.

Looking at the GCC internals","["" the reordering is allowed because the\nalias analysis thinks that the memcpy() destination and the assignments'\nleft-hand-sides are based on different objects: new_plt and\nbpf_plt_ret/bpf_plt_target respectively"", ' and therefore they cannot\nalias.\n\nThis is in turn due to a violation of the C standard:\n\n  When two pointers are subtracted', ' both shall point to elements of the\n  same array object', "" or one past the last element of the array object\n  ...\n\nFrom the C's perspective"", ' bpf_plt_ret and bpf_plt are distinct objects\nand cannot be subtracted. In the practical terms', "" doing so confuses the\nGCC's alias analysis.\n\nThe code was written this way in order to let the C side know a few\noffsets defined in the assembly. While nice"", ' this is by no means\nnecessary. Fix the noncompliance by hardcoding these offsets.\n\n[1] https://lore.kernel.org/bpf/c9923c1d-971d-4022-8dc8-1364e929d34c@gmail.com/\n\nFixes: f1d5df84cd8c (""s390/bpf: Implement bpf_arch_text_poke()"")\nSigned-off-by: Ilya Leoshkevich <iii@linux.ibm.com>\nMessage-ID: <20240320015515.11883-1-iii@linux.ibm.com>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes pointer arithmetic bug in s390 BPF leading to crashes during tests.,"pointer, bug, arithmetic",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
956c0d6191075f0592367512bf07aede458f0151,956c0d6191075f0592367512bf07aede458f0151,Kuniyuki Iwashima,kuniyu@amazon.com,1710542830,Jakub Kicinski,kuba@kernel.org,1710902159,3c27f57f732e6d4ce846b1f802098350a2a0441c,d27e2da94a42655861ca4baea30c8cd65546f25d,"tcp: Clear req->syncookie in reqsk_alloc().

syzkaller reported a read of uninit req->syncookie. [0]

Originally"," req->syncookie was used only in tcp_conn_request()
to indicate if we need to encode SYN cookie in SYN+ACK","[' so the\nfield remains uninitialised in other places.\n\nThe commit 695751e31a63 (""bpf: tcp: Handle BPF SYN Cookie in\ncookie_v[46]_check()."") added another meaning in ACK path;\nreq->syncookie is set true if SYN cookie is validated by BPF\nkfunc.\n\nAfter the change', ' cookie_v[46]_check() always read req->syncookie', ""\nbut it is not initialised in the normal SYN cookie case as reported\nby KMSAN.\n\nLet's make sure we always initialise req->syncookie in reqsk_alloc().\n\n[0]:\nBUG: KMSAN: uninit-value in cookie_v4_check+0x22b7/0x29e0\n net/ipv4/syncookies.c:477\n cookie_v4_check+0x22b7/0x29e0 net/ipv4/syncookies.c:477\n tcp_v4_cookie_check net/ipv4/tcp_ipv4.c:1855 [inline]\n tcp_v4_do_rcv+0xb17/0x10b0 net/ipv4/tcp_ipv4.c:1914\n tcp_v4_rcv+0x4ce4/0x5420 net/ipv4/tcp_ipv4.c:2322\n ip_protocol_deliver_rcu+0x2a3/0x13d0 net/ipv4/ip_input.c:205\n ip_local_deliver_finish+0x332/0x500 net/ipv4/ip_input.c:233\n NF_HOOK include/linux/netfilter.h:314 [inline]\n ip_local_deliver+0x21f/0x490 net/ipv4/ip_input.c:254\n dst_input include/net/dst.h:460 [inline]\n ip_rcv_finish+0x4a2/0x520 net/ipv4/ip_input.c:449\n NF_HOOK include/linux/netfilter.h:314 [inline]\n ip_rcv+0xcd/0x380 net/ipv4/ip_input.c:569\n __netif_receive_skb_one_core net/core/dev.c:5538 [inline]\n __netif_receive_skb+0x319/0x9e0 net/core/dev.c:5652\n process_backlog+0x480/0x8b0 net/core/dev.c:5981\n __napi_poll+0xe7/0x980 net/core/dev.c:6632\n napi_poll net/core/dev.c:6701 [inline]\n net_rx_action+0x89d/0x1820 net/core/dev.c:6813\n __do_softirq+0x1c0/0x7d7 kernel/softirq.c:554\n do_softirq+0x9a/0x100 kernel/softirq.c:455\n __local_bh_enable_ip+0x9f/0xb0 kernel/softirq.c:382\n local_bh_enable include/linux/bottom_half.h:33 [inline]\n rcu_read_unlock_bh include/linux/rcupdate.h:820 [inline]\n __dev_queue_xmit+0x2776/0x52c0 net/core/dev.c:4362\n dev_queue_xmit include/linux/netdevice.h:3091 [inline]\n neigh_hh_output include/net/neighbour.h:526 [inline]\n neigh_output include/net/neighbour.h:540 [inline]\n ip_finish_output2+0x187a/0x1b70 net/ipv4/ip_output.c:235\n __ip_finish_output+0x287/0x810\n ip_finish_output+0x4b/0x550 net/ipv4/ip_output.c:323\n NF_HOOK_COND include/linux/netfilter.h:303 [inline]\n ip_output+0x15f/0x3f0 net/ipv4/ip_output.c:433\n dst_output include/net/dst.h:450 [inline]\n ip_local_out net/ipv4/ip_output.c:129 [inline]\n __ip_queue_xmit+0x1e93/0x2030 net/ipv4/ip_output.c:535\n ip_queue_xmit+0x60/0x80 net/ipv4/ip_output.c:549\n __tcp_transmit_skb+0x3c70/0x4890 net/ipv4/tcp_output.c:1462\n tcp_transmit_skb net/ipv4/tcp_output.c:1480 [inline]\n tcp_write_xmit+0x3ee1/0x8900 net/ipv4/tcp_output.c:2792\n __tcp_push_pending_frames net/ipv4/tcp_output.c:2977 [inline]\n tcp_send_fin+0xa90/0x12e0 net/ipv4/tcp_output.c:3578\n tcp_shutdown+0x198/0x1f0 net/ipv4/tcp.c:2716\n inet_shutdown+0x33f/0x5b0 net/ipv4/af_inet.c:923\n __sys_shutdown_sock net/socket.c:2425 [inline]\n __sys_shutdown net/socket.c:2437 [inline]\n __do_sys_shutdown net/socket.c:2445 [inline]\n __se_sys_shutdown+0x2a4/0x440 net/socket.c:2443\n __x64_sys_shutdown+0x6c/0xa0 net/socket.c:2443\n do_syscall_64+0xd5/0x1f0\n entry_SYSCALL_64_after_hwframe+0x6d/0x75\n\nUninit was stored to memory at:\n reqsk_alloc include/net/request_sock.h:148 [inline]\n inet_reqsk_alloc+0x651/0x7a0 net/ipv4/tcp_input.c:6978\n cookie_tcp_reqsk_alloc+0xd4/0x900 net/ipv4/syncookies.c:328\n cookie_tcp_check net/ipv4/syncookies.c:388 [inline]\n cookie_v4_check+0x289f/0x29e0 net/ipv4/syncookies.c:420\n tcp_v4_cookie_check net/ipv4/tcp_ipv4.c:1855 [inline]\n tcp_v4_do_rcv+0xb17/0x10b0 net/ipv4/tcp_ipv4.c:1914\n tcp_v4_rcv+0x4ce4/0x5420 net/ipv4/tcp_ipv4.c:2322\n ip_protocol_deliver_rcu+0x2a3/0x13d0 net/ipv4/ip_input.c:205\n ip_local_deliver_finish+0x332/0x500 net/ipv4/ip_input.c:233\n NF_HOOK include/linux/netfilter.h:314 [inline]\n ip_local_deliver+0x21f/0x490 net/ipv4/ip_input.c:254\n dst_input include/net/dst.h:460 [inline]\n ip_rcv_finish+0x4a2/0x520 net/ipv4/ip_input.c:449\n NF_HOOK include/linux/netfilter.h:314 [inline]\n ip_rcv+0xcd/0x380 net/ipv4/ip_input.c:569\n __netif_receive_skb_one_core net/core/dev.c:5538 [inline]\n __netif_receive_skb+0x319/0x9e0 net/core/dev.c:5652\n process_backlog+0x480/0x8b0 net/core/dev.c:5981\n __napi_poll+0xe7/0x980 net/core/dev.c:6632\n napi_poll net/core/dev.c:6701 [inline]\n net_rx_action+0x89d/0x1820 net/core/dev.c:6813\n __do_softirq+0x1c0/0x7d7 kernel/softirq.c:554\n\nUninit was created at:\n __alloc_pages+0x9a7/0xe00 mm/page_alloc.c:4592\n __alloc_pages_node include/linux/gfp.h:238 [inline]\n alloc_pages_node include/linux/gfp.h:261 [inline]\n alloc_slab_page mm/slub.c:2175 [inline]\n allocate_slab mm/slub.c:2338 [inline]\n new_slab+0x2de/0x1400 mm/slub.c:2391\n ___slab_alloc+0x1184/0x33d0 mm/slub.c:3525\n __slab_alloc mm/slub.c:3610 [inline]\n __slab_alloc_node mm/slub.c:3663 [inline]\n slab_alloc_node mm/slub.c:3835 [inline]\n kmem_cache_alloc+0x6d3/0xbe0 mm/slub.c:3852\n reqsk_alloc include/net/request_sock.h:131 [inline]\n inet_reqsk_alloc+0x66/0x7a0 net/ipv4/tcp_input.c:6978\n tcp_conn_request+0x484/0x44e0 net/ipv4/tcp_input.c:7135\n tcp_v4_conn_request+0x16f/0x1d0 net/ipv4/tcp_ipv4.c:1716\n tcp_rcv_state_process+0x2e5/0x4bb0 net/ipv4/tcp_input.c:6655\n tcp_v4_do_rcv+0xbfd/0x10b0 net/ipv4/tcp_ipv4.c:1929\n tcp_v4_rcv+0x4ce4/0x5420 net/ipv4/tcp_ipv4.c:2322\n ip_protocol_deliver_rcu+0x2a3/0x13d0 net/ipv4/ip_input.c:205\n ip_local_deliver_finish+0x332/0x500 net/ipv4/ip_input.c:233\n NF_HOOK include/linux/netfilter.h:314 [inline]\n ip_local_deliver+0x21f/0x490 net/ipv4/ip_input.c:254\n dst_input include/net/dst.h:460 [inline]\n ip_sublist_rcv_finish net/ipv4/ip_input.c:580 [inline]\n ip_list_rcv_finish net/ipv4/ip_input.c:631 [inline]\n ip_sublist_rcv+0x15f3/0x17f0 net/ipv4/ip_input.c:639\n ip_list_rcv+0x9ef/0xa40 net/ipv4/ip_input.c:674\n __netif_receive_skb_list_ptype net/core/dev.c:5581 [inline]\n __netif_receive_skb_list_core+0x15c5/0x1670 net/core/dev.c:5629\n __netif_receive_skb_list net/core/dev.c:5681 [inline]\n netif_receive_skb_list_internal+0x106c/0x16f0 net/core/dev.c:5773\n gro_normal_list include/net/gro.h:438 [inline]\n napi_complete_done+0x425/0x880 net/core/dev.c:6113\n virtqueue_napi_complete drivers/net/virtio_net.c:465 [inline]\n virtnet_poll+0x149d/0x2240 drivers/net/virtio_net.c:2211\n __napi_poll+0xe7/0x980 net/core/dev.c:6632\n napi_poll net/core/dev.c:6701 [inline]\n net_rx_action+0x89d/0x1820 net/core/dev.c:6813\n __do_softirq+0x1c0/0x7d7 kernel/softirq.c:554\n\nCPU: 0 PID: 16792 Comm: syz-executor.2 Not tainted 6.8.0-syzkaller-05562-g61387b8dcf1d #0\nHardware name: Google Google Compute Engine/Google Compute Engine"", ' BIOS Google 02/29/2024\n\nFixes: 695751e31a63 (""bpf: tcp: Handle BPF SYN Cookie in cookie_v[46]_check()."")\nReported-by: syzkaller <syzkaller@googlegroups.com>\nReported-by: Eric Dumazet <edumazet@google.com>\nCloses: https://lore.kernel.org/bpf/CANn89iKdN9c+C_2JAUbc+VY3DDQjAQukMtiBbormAmAk9CdvQA@mail.gmail.com/\nSigned-off-by: Kuniyuki Iwashima <kuniyu@amazon.com>\nReviewed-by: Eric Dumazet <edumazet@google.com>\nAcked-by: Martin KaFai Lau <martin.lau@kernel.org>\nLink: https://lore.kernel.org/r/20240315224710.55209-1-kuniyu@amazon.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Fix uninitialized req->syncookie issue in reqsk_alloc() in TCP connection handling.,"tcp, syncookie, syzkaller",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
f803bcf9208a2540acb4c32bdc3616673169f490,f803bcf9208a2540acb4c32bdc3616673169f490,Alessandro Carminati (Red Hat),alessandro.carminati@gmail.com,1710413951,Andrii Nakryiko,andrii@kernel.org,1710890169,a90cb445d6fa8d01e4d2e739c5d7d48a78a33a29,437ffcb0bf97361e5c4062043309832f4724d1a8,"selftests/bpf: Prevent client connect before server bind in test_tc_tunnel.sh

In some systems"," the netcat server can incur in delay to start listening.
When this happens","[' the test can randomly fail in various points.\nThis is an example error message:\n\n   # ip gre none gso\n   # encap 192.168.1.1 to 192.168.1.2', ' type gre', ' mac none len 2000\n   # test basic connectivity\n   # Ncat: Connection refused.\n\nThe issue stems from a race condition between the netcat client and server.\nThe test author had addressed this problem by implementing a sleep', ' which\nI have removed in this patch.\nThis patch introduces a function capable of sleeping for up to two seconds.\nHowever', ' it can terminate the waiting period early if the port is reported\nto be listening.\n\nSigned-off-by: Alessandro Carminati (Red Hat) <alessandro.carminati@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240314105911.213411-1-alessandro.carminati@gmail.com\n', '']",Fix race condition by ensuring server is ready before the client connects in test_tc_tunnel.sh.,"selftests,bpf,connect",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tc/netfilter like programs']
437ffcb0bf97361e5c4062043309832f4724d1a8,437ffcb0bf97361e5c4062043309832f4724d1a8,Andrii Nakryiko,andrii@kernel.org,1710883315,Andrii Nakryiko,andrii@kernel.org,1710883621,334907acabeb9fe6a105708b078f8b54f68f9e6e,1a4a0cb7985f921548f1a7ac17686afbefe67f87 4c195ee4865d57786b3a63018d489b8a07877354,"Merge branch 'current_pid_tgid-for-all-prog-types'

Yonghong Song says:

====================
current_pid_tgid() for all prog types

Currently bpf_get_current_pid_tgid() is allowed in tracing"," cgroup
and sk_msg progs while bpf_get_ns_current_pid_tgid() is only allowed
in tracing progs.

We have an internal use case where for an application running
in a container (with pid namespace)","[' user wants to get\nthe pid associated with the pid namespace in a cgroup bpf\nprogram. Besides cgroup', ' the only prog type', ' supporting\nbpf_get_current_pid_tgid() but not bpf_get_ns_current_pid_tgid()', '\nis sk_msg.\n\nBut actually both bpf_get_current_pid_tgid() and\nbpf_get_ns_current_pid_tgid() helpers do not reveal kernel internal\ndata and there is no reason that they cannot be used in other\nprogram types. This patch just did this and enabled these\ntwo helpers for all program types.\n\nPatch 1 added the kernel support and patches 2-5 added\nthe test for cgroup and sk_msg.\n\nChange logs:\n  v1 -> v2:\n    - allow bpf_get_[ns_]current_pid_tgid() for all prog types.\n    - for network related selftests', ' using netns.\n====================\n\nLink: https://lore.kernel.org/r/20240315184849.2974556-1-yonghong.song@linux.dev\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n', '']","Extend support for bpf_get_current_pid_tgid() to all eBPF program types, improving container namespace compatibility.","bpf_get_current_pid_tgid,prog types,container",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4c195ee4865d57786b3a63018d489b8a07877354,4c195ee4865d57786b3a63018d489b8a07877354,Yonghong Song,yonghong.song@linux.dev,1710528555,Andrii Nakryiko,andrii@kernel.org,1710883620,334907acabeb9fe6a105708b078f8b54f68f9e6e,87ade6cd859ea9dbde6e80b3fcf717ed9a73b4a9,"selftests/bpf: Add a sk_msg prog bpf_get_ns_current_pid_tgid() test

Add a sk_msg bpf program test where the program is running in a pid
namespace. The test is successful:
  #165/4   ns_current_pid_tgid/new_ns_sk_msg:OK

Signed-off-by: Yonghong Song <yonghong.song@linux.dev>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240315184915.2976718-1-yonghong.song@linux.dev
",,Add a selftest for sk_msg program using bpf_get_ns_current_pid_tgid().,"selftest, sk_msg, bpf_get_ns_current_pid_tgid",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
87ade6cd859ea9dbde6e80b3fcf717ed9a73b4a9,87ade6cd859ea9dbde6e80b3fcf717ed9a73b4a9,Yonghong Song,yonghong.song@linux.dev,1710528550,Andrii Nakryiko,andrii@kernel.org,1710883619,97a9efc82b398905fbf299a093d751180ef9f358,4d4bd29e363c467752536f874a2cba10a5923c59,"selftests/bpf: Add a cgroup prog bpf_get_ns_current_pid_tgid() test

Add a cgroup bpf program test where the bpf program is running
in a pid namespace. The test is successfully:
  #165/3   ns_current_pid_tgid/new_ns_cgrp:OK

Signed-off-by: Yonghong Song <yonghong.song@linux.dev>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240315184910.2976522-1-yonghong.song@linux.dev
",,Add a test for cgroup BPF programs using bpf_get_ns_current_pid_tgid in a PID namespace.,"cgroup, test, pid namespace",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['cgroup like programs']
4d4bd29e363c467752536f874a2cba10a5923c59,4d4bd29e363c467752536f874a2cba10a5923c59,Yonghong Song,yonghong.song@linux.dev,1710528544,Andrii Nakryiko,andrii@kernel.org,1710883618,bd42079c998c577d894c1bd3fcdf27e6396dd2c5,84239a24d10174fcfc7d6760cb120435a6ff69af,"selftests/bpf: Refactor out some functions in ns_current_pid_tgid test

Refactor some functions in both user space code and bpf program
as these functions are used by later cgroup/sk_msg tests.
Another change is to mark tp program optional loading as later
patches will use optional loading as well since they have quite
different attachment and testing logic.

There is no functionality change.

Signed-off-by: Yonghong Song <yonghong.song@linux.dev>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240315184904.2976123-1-yonghong.song@linux.dev
",,Refactor functions in the ns_current_pid_tgid test for future use in cgroup/sk_msg selftests without changing functionality.,"refactor, selftests, optional loading",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['cgroup like programs', 'tracepoints like programs']"
84239a24d10174fcfc7d6760cb120435a6ff69af,84239a24d10174fcfc7d6760cb120435a6ff69af,Yonghong Song,yonghong.song@linux.dev,1710528539,Andrii Nakryiko,andrii@kernel.org,1710883477,9590038ef860dc7d5a538b15bbd15d30144dcd16,eb166e522c77699fc19bfa705652327a1e51a117,"selftests/bpf: Replace CHECK with ASSERT_* in ns_current_pid_tgid test

Replace CHECK in selftest ns_current_pid_tgid with recommended ASSERT_* style.
I also shortened subtest name as the prefix of subtest name is covered
by the test name already.

This patch does fix a testing issue. Currently even if bss->user_{pid","tgid}
is not correct","[' the test still passed since the clone func returns 0.\nI fixed it to return a non-zero value if bss->user_{pid', 'tgid} is incorrect.\n\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/bpf/20240315184859.2975543-1-yonghong.song@linux.dev\n', '']",Replaced CHECK with ASSERT_* in the ns_current_pid_tgid selftest for better clarity and error handling.,"CHECK, ASSERT, selftest",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
eb166e522c77699fc19bfa705652327a1e51a117,eb166e522c77699fc19bfa705652327a1e51a117,Yonghong Song,yonghong.song@linux.dev,1710528534,Andrii Nakryiko,andrii@kernel.org,1710883447,868016438479325a893aa55572834edc674f267d,1a4a0cb7985f921548f1a7ac17686afbefe67f87,"bpf: Allow helper bpf_get_[ns_]current_pid_tgid() for all prog types

Currently bpf_get_current_pid_tgid() is allowed in tracing"," cgroup
and sk_msg progs while bpf_get_ns_current_pid_tgid() is only allowed
in tracing progs.

We have an internal use case where for an application running
in a container (with pid namespace)","[' user wants to get\nthe pid associated with the pid namespace in a cgroup bpf\nprogram. Currently', ' cgroup bpf progs already allow\nbpf_get_current_pid_tgid(). Let us allow bpf_get_ns_current_pid_tgid()\nas well.\n\nWith auditing the code', ' bpf_get_current_pid_tgid() is also used\nby sk_msg prog. But there are no side effect to expose these two\nhelpers to all prog types since they do not reveal any kernel specific\ndata. The detailed discussion is in [1].\n\nSo with this patch', ' both bpf_get_current_pid_tgid() and bpf_get_ns_current_pid_tgid()\nare put in bpf_base_func_proto()', ' making them available to all\nprogram types.\n\n  [1] https://lore.kernel.org/bpf/20240307232659.1115872-1-yonghong.song@linux.dev/\n\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/bpf/20240315184854.2975190-1-yonghong.song@linux.dev\n', '']",The commit allows bpf_get_[ns_]current_pid_tgid() helper function for all eBPF program types.,"helper, prog types, pid tgid",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f6e922365faf4cd576bd1cf3e64b58c8a32e1856,f6e922365faf4cd576bd1cf3e64b58c8a32e1856,Stanislav Fomichev,sdf@google.com,1710780867,Daniel Borkmann,daniel@iogearbox.net,1710852449,c372a3f31a8e6f41af1bcd51c6187805f8da8503,0740b6427e90ef03177888c50dc1c78ca6e0f7f0,"xsk: Don't assume metadata is always requested in TX completion

`compl->tx_timestam != NULL` means that the user has explicitly
requested the metadata via XDP_TX_METADATA+XDP_TX_METADATA_TIMESTAMP.

Fixes: 48eb03dd2630 (""xsk: Add TX timestamp and TX checksum offload support"")
Reported-by: Daniele Salvatore Albano <d.albano@gmail.com>
Signed-off-by: Stanislav Fomichev <sdf@google.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Tested-by: Daniele Salvatore Albano <d.albano@gmail.com>
Link: https://lore.kernel.org/bpf/20240318165427.1403313-1-sdf@google.com
",,Fixes assumption about metadata request in TX completion for xsk.,"xsk,metadata,TX completion",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['xdp like programs', 'socket like programs']"
1a4a0cb7985f921548f1a7ac17686afbefe67f87,1a4a0cb7985f921548f1a7ac17686afbefe67f87,Jesper Dangaard Brouer,hawk@kernel.org,1710768326,Daniel Borkmann,daniel@iogearbox.net,1710852363,c42fe60b18d5a8d0c9432082ab2a121d2cf192fb,c733239f8f530872a1f80d8c45dcafbaff368737,"bpf/lpm_trie: Inline longest_prefix_match for fastpath

The BPF map type LPM (Longest Prefix Match) is used heavily
in production by multiple products that have BPF components.
Perf data shows trie_lookup_elem() and longest_prefix_match()
being part of kernels perf top.

For every level in the LPM tree trie_lookup_elem() calls out
to longest_prefix_match().  The compiler is free to inline this
call", but chooses not to inline,"[' because other slowpath callers\n(that can be invoked via syscall) exists like trie_update_elem()', ""\ntrie_delete_elem() or trie_get_next_key().\n\n bcc/tools/funccount -Ti 1 'trie_lookup_elem|longest_prefix_match.isra.0'\n FUNC                                    COUNT\n trie_lookup_elem                       664945\n longest_prefix_match.isra.0           8101507\n\nObservation on a single random machine shows a factor 12 between\nthe two functions. Given an average of 12 levels in the trie being\nsearched.\n\nThis patch force inlining longest_prefix_match()"", ' but only for\nthe lookup fastpath to balance object instruction size.\n\nIn production with AMD CPUs', "" measuring the function latency of\n'trie_lookup_elem' (bcc/tools/funclatency) we are seeing an improvement\nfunction latency reduction 7-8% with this patch applied (to production\nkernels 6.6 and 6.1). Analyzing perf data"", ' we can explain this rather\nlarge improvement due to reducing the overhead for AMD side-channel\nmitigation SRSO (Speculative Return Stack Overflow).\n\nFixes: fb3bd914b3ec (""x86/srso: Add a Speculative RAS Overflow mitigation"")\nSigned-off-by: Jesper Dangaard Brouer <hawk@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/bpf/171076828575.2141737.18370644069389889027.stgit@firesoul\n', '']",The commit inlines the longest_prefix_match function for performance improvements in the LPM trie BPF map.,"inline, LPM trie, performance",It's a performance optimization.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF maps,['tc/netfilter like programs']
c733239f8f530872a1f80d8c45dcafbaff368737,c733239f8f530872a1f80d8c45dcafbaff368737,Christophe Leroy,christophe.leroy@csgroup.eu,1710574541,Martin KaFai Lau,martin.lau@kernel.org,1710796727,bd2fb53ca8a95c663a415f5b8a5479b338cfa7fd,e3362acd796789dc0562eb1a3937007b0beb0c5b,"bpf: Check return from set_memory_rox()

arch_protect_bpf_trampoline() and alloc_new_pack() call
set_memory_rox() which can fail"," leading to unprotected memory.

Take into account return from set_memory_rox() function and add
__must_check flag to arch_protect_bpf_trampoline().

Signed-off-by: Christophe Leroy <christophe.leroy@csgroup.eu>
Reviewed-by: Kees Cook <keescook@chromium.org>
Link: https://lore.kernel.org/r/fe1c163c83767fde5cab31d209a4a6be3ddb3a73.1710574353.git.christophe.leroy@csgroup.eu
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],The commit ensures proper handling of set_memory_rox() return by using __must_check in arch_protect_bpf_trampoline().,"set_memory_rox, arch_protect_bpf_trampoline, __must_check",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
e3362acd796789dc0562eb1a3937007b0beb0c5b,e3362acd796789dc0562eb1a3937007b0beb0c5b,Christophe Leroy,christophe.leroy@csgroup.eu,1710574540,Martin KaFai Lau,martin.lau@kernel.org,1710796727,60fdaf720eaf3b7e5b6367504c99d880b92e953e,7b30c296af6525571fc967f6a8661f6e1127369e,"bpf: Remove arch_unprotect_bpf_trampoline()

Last user of arch_unprotect_bpf_trampoline() was removed by
commit 187e2af05abe (""bpf: struct_ops supports more than one page for
trampolines."")

Remove arch_unprotect_bpf_trampoline()

Reported-by: Daniel Borkmann <daniel@iogearbox.net>
Fixes: 187e2af05abe (""bpf: struct_ops supports more than one page for trampolines."")
Signed-off-by: Christophe Leroy <christophe.leroy@csgroup.eu>
Link: https://lore.kernel.org/r/42c635bb54d3af91db0f9b85d724c7c290069f67.1710574353.git.christophe.leroy@csgroup.eu
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,The commit removes the unused arch_unprotect_bpf_trampoline function after its last user was removed.,"remove,arch_unprotect_bpf_trampoline,trampolines",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7b30c296af6525571fc967f6a8661f6e1127369e,7b30c296af6525571fc967f6a8661f6e1127369e,Mykyta Yatsenko,yatsenko@meta.com,1710767888,Andrii Nakryiko,andrii@kernel.org,1710794711,ac27064d83f809fbec1e63ec44e67167d2622d5b,7f3edd0c72c3f7214f8f28495f2e6466348eb128,"libbpbpf: Check bpf_map/bpf_program fd validity

libbpf creates bpf_program/bpf_map structs for each program/map that
user defines"," but it allows to disable creating/loading those objects in
kernel","["" in that case they won't have associated file descriptor\n(fd < 0). Such functionality is used for backward compatibility\nwith some older kernels.\n\nNothing prevents users from passing these maps or programs with no\nkernel counterpart to libbpf APIs. This change introduces explicit\nchecks for kernel objects existence"", ' aiming to improve visibility of\nthose edge cases and provide meaningful warnings to users.\n\nSigned-off-by: Mykyta Yatsenko <yatsenko@meta.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240318131808.95959-1-yatsenko@meta.com\n', '']",This commit adds a check for the validity of bpf_map and bpf_program file descriptors in libbpf.,"libbpf, validity check, bpf_program",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7f3edd0c72c3f7214f8f28495f2e6466348eb128,7f3edd0c72c3f7214f8f28495f2e6466348eb128,Martin KaFai Lau,martin.lau@kernel.org,1710530472,Andrii Nakryiko,andrii@kernel.org,1710791290,a53d58eb46894feba698e54bbb36eb1a5371512f,4c8644f86c854c214aaabbcc24a27fa4c7e6a951,"bpf: Remove unnecessary err < 0 check in bpf_struct_ops_map_update_elem

There is a ""if (err)"" check earlier"," so the ""if (err < 0)""
check that this patch removing is unnecessary. It was my overlook
when making adjustments to the bpf_struct_ops_prepare_trampoline()
such that the caller does not have to worry about the new page when
the function returns error.

Fixes: 187e2af05abe (""bpf: struct_ops supports more than one page for trampolines."")
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Stanislav Fomichev <sdf@google.com>
Link: https://lore.kernel.org/bpf/20240315192112.2825039-1-martin.lau@linux.dev
",[''],Remove redundant error check in bpf_struct_ops_map_update_elem function.,"error check, redundant, bpf_struct_ops",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
35c3e27917568192927c785fc380f139255468b4,35c3e27917568192927c785fc380f139255468b4,Abhishek Chauhan,quic_abchauha@quicinc.com,1710444244,David S. Miller,davem@davemloft.net,1710764993,cea90dc6e4c3226ed8f9a5c6c11bdf9971cba4f7,f490c492e946d8ffbe65ad4efc66de3c5ede30a4,"Revert ""net: Re-use and set mono_delivery_time bit for userspace tstamp packets""

This reverts commit 885c36e59f46375c138de18ff1692f18eff67b7f.

The patch currently broke the bpf selftest test_tc_dtime because
uapi field __sk_buff->tstamp_type depends on skb->mono_delivery_time which
does not necessarily mean mono with the original fix as the bit was re-used
for userspace timestamp as well to avoid tstamp reset in the forwarding
path. To solve this we need to keep mono_delivery_time as is and
introduce another bit called user_delivery_time and fall back to the
initial proposal of setting the user_delivery_time bit based on
sk_clockid set from userspace.

Fixes: 885c36e59f46 (""net: Re-use and set mono_delivery_time bit for userspace tstamp packets"")
Link: https://lore.kernel.org/netdev/bc037db4-58bb-4861-ac31-a361a93841d3@linux.dev/
Signed-off-by: Abhishek Chauhan <quic_abchauha@quicinc.com>
Acked-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Martin KaFai Lau <martin.lau@kernel.org>
Signed-off-by: David S. Miller <davem@davemloft.net>
",,This commit reverts a patch due to a selftest failure related to reuse of mono_delivery_time bit.,"reverts, mono_delivery_time, selftest",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0740b6427e90ef03177888c50dc1c78ca6e0f7f0,0740b6427e90ef03177888c50dc1c78ca6e0f7f0,Andrii Nakryiko,andrii@kernel.org,1710536945,Andrii Nakryiko,andrii@kernel.org,1710537850,b97a172c0443649cceb63e430623d10f69b1a105,aae08491b9438347e9656c44021824ad236052b4 a90c5845db958701ddc7659bc4f6db6fa647e449,"Merge branch 'bpf-arena-followups'

Alexei Starovoitov says:

====================
bpf: arena followups.

From: Alexei Starovoitov <ast@kernel.org>

A set of follow ups to clean up bpf_arena and adjust to the latest LLVM.
====================

Link: https://lore.kernel.org/r/20240315021834.62988-1-alexei.starovoitov@gmail.com
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
",,Clean up bpf_arena and adapt to latest LLVM updates.,"bpf_arena, followups, LLVM",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['other']
a90c5845db958701ddc7659bc4f6db6fa647e449,a90c5845db958701ddc7659bc4f6db6fa647e449,Alexei Starovoitov,ast@kernel.org,1710469114,Andrii Nakryiko,andrii@kernel.org,1710537846,b97a172c0443649cceb63e430623d10f69b1a105,9a2d5a966b47e5657b22dfa257365b7ef2abc3c0,"selftests/bpf: Add arena test case for 4Gbyte corner case

Check that 4Gbyte arena can be allocated and overflow/underflow access in
the first and the last page behaves as expected.

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Stanislav Fomichev <sdf@google.com>
Link: https://lore.kernel.org/bpf/20240315021834.62988-5-alexei.starovoitov@gmail.com
",,Add a selftest for 4Gbyte allocation and access behavior in bpf arena.,"4Gbyte,arena,test",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9a2d5a966b47e5657b22dfa257365b7ef2abc3c0,9a2d5a966b47e5657b22dfa257365b7ef2abc3c0,Alexei Starovoitov,ast@kernel.org,1710469113,Andrii Nakryiko,andrii@kernel.org,1710537843,091be020ed052c2d6ab1a421391e4af201406b89,10ebe835c937a11870690aa44c7c970fe906ff54,"selftests/bpf: Remove hard coded PAGE_SIZE macro.

Remove hard coded PAGE_SIZE.
Add #include <sys/user.h> instead (that works on x86-64 and s390)
and fallback to slow getpagesize() for aarch64.

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Stanislav Fomichev <sdf@google.com>
Link: https://lore.kernel.org/bpf/20240315021834.62988-4-alexei.starovoitov@gmail.com
",,The commit removes hard coded PAGE_SIZE and introduces new includes for compatibility.,"PAGE_SIZE, compatibility, selftests",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
10ebe835c937a11870690aa44c7c970fe906ff54,10ebe835c937a11870690aa44c7c970fe906ff54,Alexei Starovoitov,ast@kernel.org,1710469112,Andrii Nakryiko,andrii@kernel.org,1710537840,f790b75713a6d9845bf8e2cb9c6d4e489a794264,ee498a38f3177d9ee0213839d3a05b94272aa48c,libbpf, selftests/bpf: Adjust libbpf,"[' bpftool', ' selftests to match LLVM\n\nThe selftests use\nto tell LLVM about special pointers. For LLVM there is nothing ""arena""\nabout them. They are simply pointers in a different address space.\nHence LLVM diff https://github.com/llvm/llvm-project/pull/85161 renamed:\n. macro __BPF_FEATURE_ARENA_CAST -> __BPF_FEATURE_ADDR_SPACE_CAST\n. global variables in __attribute__((address_space(N))) are now\n  placed in section named "".addr_space.N"" instead of "".arena.N"".\n\nAdjust libbpf', ' bpftool', ' and selftests to match LLVM.\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nLink: https://lore.kernel.org/bpf/20240315021834.62988-3-alexei.starovoitov@gmail.com\n', '']",Adjustments made to libbpf in the selftests for bpf.,"libbpf, selftests, bpf",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ee498a38f3177d9ee0213839d3a05b94272aa48c,ee498a38f3177d9ee0213839d3a05b94272aa48c,Alexei Starovoitov,ast@kernel.org,1710469111,Andrii Nakryiko,andrii@kernel.org,1710537825,458a921bce8d3a8e3719f05fbb8d1abe5b7a4462,aae08491b9438347e9656c44021824ad236052b4,"bpf: Clarify bpf_arena comments.

Clarify two bpf_arena comments", use existing SZ_4G #define,"['\nimprove page_cnt check.\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nLink: https://lore.kernel.org/bpf/20240315021834.62988-2-alexei.starovoitov@gmail.com\n', '']",This commit clarifies comments in the bpf_arena code section.,"bpf, arena, comments",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
4c8644f86c854c214aaabbcc24a27fa4c7e6a951,4c8644f86c854c214aaabbcc24a27fa4c7e6a951,Colin Ian King,colin.i.king@gmail.com,1710494814,Daniel Borkmann,daniel@iogearbox.net,1710510836,d812af3794ce521c8ae6e8094b01411f7d6f23c8,e60adf513275c3a38e5cb67f7fd12387e43a3ff5,"selftests/bpf: Remove second semicolon

There are statements with two semicolons. Remove the second one"," it
is redundant.

Signed-off-by: Colin Ian King <colin.i.king@gmail.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240315092654.2431062-1-colin.i.king@gmail.com
",[''],Remove redundant second semicolon in selftests for BPF.,"selftests,semicolon,BPF",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5384cc0d1a88c27448a6a4e65b8abe6486de8012,5384cc0d1a88c27448a6a4e65b8abe6486de8012,Hangbin Liu,liuhangbin@gmail.com,1710470083,Daniel Borkmann,daniel@iogearbox.net,1710510391,dfdacc7b2a061c0559f54c538ee6b8ce23e3811f,44d79142ede8162fd67bf8ca4ddbda1fbcfa94f1,"scripts/bpf_doc: Use silent mode when exec make cmd

When getting kernel version via make"," the result may be polluted by other
output","[' like directory change info. e.g.\n\n  $ export MAKEFLAGS=""-w""\n  $ make kernelversion\n  make: Entering directory \'/home/net\'\n  6.8.0\n  make: Leaving directory \'/home/net\'\n\nThis will distort the reStructuredText output and make latter rst2man\nfailed like:\n\n  [...]\n  bpf-helpers.rst:20: (WARNING/2) Field list ends without a blank line; unexpected unindent.\n  [...]\n\nUsing silent mode would help. e.g.\n\n  $ make -s --no-print-directory kernelversion\n  6.8.0\n\nFixes: fd0a38f9c37d (""scripts/bpf: Set version attribute for bpf-helpers(7) man page"")\nSigned-off-by: Michael Hofmann <mhofmann@redhat.com>\nSigned-off-by: Hangbin Liu <liuhangbin@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Quentin Monnet <qmo@kernel.org>\nAcked-by: Alejandro Colomar <alx@kernel.org>\nLink: https://lore.kernel.org/bpf/20240315023443.2364442-1-liuhangbin@gmail.com\n', '']",The commit changes the bpf_doc script to use silent mode for make commands to avoid output pollution.,"bpf_doc,silent mode,make",It's a build system or CI/CD change.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['other']
e60adf513275c3a38e5cb67f7fd12387e43a3ff5,e60adf513275c3a38e5cb67f7fd12387e43a3ff5,Christophe Leroy,christophe.leroy@csgroup.eu,1709876288,Alexei Starovoitov,ast@kernel.org,1710469732,f154a2a436cb986c45b30f5090aca12218d43a2c,7d2cc63eca0c993c99d18893214abf8f85d566d8,"bpf: Take return from set_memory_rox() into account with bpf_jit_binary_lock_ro()

set_memory_rox() can fail"," leaving memory unprotected.

Check return and bail out when bpf_jit_binary_lock_ro() returns
an error.

Link: https://github.com/KSPP/linux/issues/7
Signed-off-by: Christophe Leroy <christophe.leroy@csgroup.eu>
Cc: linux-hardening@vger.kernel.org <linux-hardening@vger.kernel.org>
Reviewed-by: Kees Cook <keescook@chromium.org>
Reviewed-by: Puranjay Mohan <puranjay12@gmail.com>
Reviewed-by: Ilya Leoshkevich <iii@linux.ibm.com>  # s390x
Acked-by: Tiezhu Yang <yangtiezhu@loongson.cn>  # LoongArch
Reviewed-by: Johan Almbladh <johan.almbladh@anyfinetworks.com> # MIPS Part
Message-ID: <036b6393f23a2032ce75a1c92220b2afcb798d5d.1709850515.git.christophe.leroy@csgroup.eu>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Fix check return handling in bpf_jit_binary_lock_ro() for set_memory_rox() failures.,"bpf, jit, memory",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7d2cc63eca0c993c99d18893214abf8f85d566d8,7d2cc63eca0c993c99d18893214abf8f85d566d8,Christophe Leroy,christophe.leroy@csgroup.eu,1709876287,Alexei Starovoitov,ast@kernel.org,1710469732,f76363657d57f38f950856a1c399dad1ad31780b,4d8926a0407cff0c864b759b59104f4fb6f8efab,"bpf: Take return from set_memory_ro() into account with bpf_prog_lock_ro()

set_memory_ro() can fail"," leaving memory unprotected.

Check its return and take it into account as an error.

Link: https://github.com/KSPP/linux/issues/7
Signed-off-by: Christophe Leroy <christophe.leroy@csgroup.eu>
Cc: linux-hardening@vger.kernel.org <linux-hardening@vger.kernel.org>
Reviewed-by: Kees Cook <keescook@chromium.org>
Message-ID: <286def78955e04382b227cb3e4b6ba272a7442e3.1709850515.git.christophe.leroy@csgroup.eu>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The commit handles failures from the set_memory_ro() function within bpf_prog_lock_ro().,"bpf, set_memory_ro, error-handling",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4d8926a0407cff0c864b759b59104f4fb6f8efab,4d8926a0407cff0c864b759b59104f4fb6f8efab,Andrii Nakryiko,andrii@kernel.org,1710374487,Alexei Starovoitov,ast@kernel.org,1710469696,de80ba0b517f082bf17cd397cdedfb63b606b1cf,6cda7e17392e0eca9fcafcb9b1d269c31fd737b7,"bpf: preserve sleepable bit in subprog info

Copy over main program's sleepable bit into subprog's info. This might
be important for", e.g.,"[' freplace cases.\n\nSuggested-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nMessage-ID: <20240314000127.3881569-1-andrii@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Preserve the sleepable bit in subprograms' info for eBPF programs.,"sleepable, subprog, info",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6cda7e17392e0eca9fcafcb9b1d269c31fd737b7,6cda7e17392e0eca9fcafcb9b1d269c31fd737b7,Andrii Nakryiko,andrii@kernel.org,1710449225,Andrii Nakryiko,andrii@kernel.org,1710449683,23b3d167b14c63d771404758606aebfb8aaaa812,9bf48fa19a4b1d186e08b20bf7e5de26a15644fb 26a7cf2bbea656837583f9a1a0f9390db63d6cc3,"Merge branch 'ignore-additional-fields-in-the-struct_ops-maps-in-an-updated-version'

Kui-Feng Lee says:

====================
Ignore additional fields in the struct_ops maps in an updated version.

According to an offline discussion"," it would be beneficial to
implement a backward-compatible method for struct_ops types with
additional fields that are not present in older kernels.

This patchset accepts additional fields of a struct_ops map with all
zero values even if these fields are not in the corresponding type in
the kernel. This provides a way to be backward compatible. User space
programs can use the same map on a machine running an old kernel by
clearing fields that do not exist in the kernel.

For example","[' in a test case', ' it adds an additional field ""zeroed"" that\ndoesn\'t exist in struct bpf_testmod_ops of the kernel.\n\n    struct bpf_testmod_ops___zeroed {\n    \tint (*test_1)(void);\n    \tvoid (*test_2)(int a', ' int b);\n    \tint (*test_maybe_null)(int dummy', ' struct task_struct *task);\n    \tint zeroed;\n    };\n\n    SEC("".struct_ops.link"")\n    struct bpf_testmod_ops___zeroed testmod_zeroed = {\n    \t.test_1 = (void *)test_1', '\n    \t.test_2 = (void *)test_2_v2', '\n    };\n\nHere', ' it doesn\'t assign a value to ""zeroed"" of testmod_zeroed', ' and by\ndefault the value of this field will be zero. So', ' the map will be\naccepted by libbpf', ' but libbpf will skip the ""zeroed"" field. However', '\nif the ""zeroed"" field is assigned to any value other than ""0""', ' libbpf\nwill reject to load this map.\n---\nChanges from v1:\n\n - Fix the issue about function pointer fields.\n\n - Change a warning message', ' and add an info message for skipping\n   fields.\n\n - Add a small demo of additional arguments that are not in the\n   function pointer prototype in the kernel.\n\nv1: https://lore.kernel.org/all/20240312183245.341141-1-thinker.li@gmail.com/\n\nKui-Feng Lee (3):\n  libbpf: Skip zeroed or null fields if not found in the kernel type.\n  selftests/bpf: Ensure libbpf skip all-zeros fields of struct_ops maps.\n  selftests/bpf: Accept extra arguments if they are not used.\n\n tools/lib/bpf/libbpf.c                        |  24 +++-\n .../bpf/prog_tests/test_struct_ops_module.c   | 103 ++++++++++++++++++\n .../bpf/progs/struct_ops_extra_arg.c          |  49 +++++++++\n .../selftests/bpf/progs/struct_ops_module.c   |  16 ++-\n 4 files changed', ' 186 insertions(+)', ' 6 deletions(-)\n create mode 100644 tools/testing/selftests/bpf/progs/struct_ops_extra_arg.c\n====================\n\nLink: https://lore.kernel.org/r/20240313214139.685112-1-thinker.li@gmail.com\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n', '']",Implemented backward-compatible handling for additional fields in struct_ops maps for older kernels.,"backward-compatible, struct_ops, maps",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
26a7cf2bbea656837583f9a1a0f9390db63d6cc3,26a7cf2bbea656837583f9a1a0f9390db63d6cc3,Kui-Feng Lee,thinker.li@gmail.com,1710366098,Andrii Nakryiko,andrii@kernel.org,1710449225,23b3d167b14c63d771404758606aebfb8aaaa812,c911fc61a7ce367f9ea48e457f31bb171e80ca4d,"selftests/bpf: Ensure libbpf skip all-zeros fields of struct_ops maps.

A new version of a type may have additional fields that do not exist in
older versions. Previously"," libbpf would reject struct_ops maps with a new
version containing extra fields when running on a machine with an old
kernel. However","[' we have updated libbpf to ignore these fields if their\nvalues are all zeros or null in order to provide backward compatibility.\n\nSigned-off-by: Kui-Feng Lee <thinker.li@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240313214139.685112-3-thinker.li@gmail.com\n', '']",Ensure libbpf skips all-zero fields in struct_ops maps for compatibility with older kernels.,"libbpf, struct_ops, compatibility",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c911fc61a7ce367f9ea48e457f31bb171e80ca4d,c911fc61a7ce367f9ea48e457f31bb171e80ca4d,Kui-Feng Lee,thinker.li@gmail.com,1710366097,Andrii Nakryiko,andrii@kernel.org,1710449225,80958ee01093375725f14731119423303eee93b0,9bf48fa19a4b1d186e08b20bf7e5de26a15644fb,"libbpf: Skip zeroed or null fields if not found in the kernel type.

Accept additional fields of a struct_ops type with all zero values even if
these fields are not in the corresponding type in the kernel. This provides
a way to be backward compatible. User space programs can use the same map
on a machine running an old kernel by clearing fields that do not exist in
the kernel.

Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240313214139.685112-2-thinker.li@gmail.com
",,libbpf update to skip zeroed fields for backward compatibility with older kernels.,"libbpf,backward compatibility,zeroed fields",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9bf48fa19a4b1d186e08b20bf7e5de26a15644fb,9bf48fa19a4b1d186e08b20bf7e5de26a15644fb,Quentin Monnet,qmo@kernel.org,1710428678,Andrii Nakryiko,andrii@kernel.org,1710448877,1fcbb6ba740bcc479893149a2ad3f1dc2f83db8d,fe879bb42f8a6513ed18e9d22efb99cb35590201,"libbpf: Prevent null-pointer dereference when prog to load has no BTF

In bpf_objec_load_prog()"," there's no guarantee that obj->btf is non-NULL
when passing it to btf__fd()","[' and this function does not perform any\ncheck before dereferencing its argument (as bpf_object__btf_fd() used to\ndo). As a consequence', ' we get segmentation fault errors in bpftool (for\nexample) when trying to load programs that come without BTF information.\n\nv2: Keep btf__fd() in the fix instead of reverting to bpf_object__btf_fd().\n\nFixes: df7c3f7d3a3d (""libbpf: make uniform use of btf__fd() accessor inside libbpf"")\nSuggested-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Quentin Monnet <qmo@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240314150438.232462-1-qmo@kernel.org\n', '']",Fix a null-pointer dereference in libbpf when the program to load has no BTF.,"null-pointer,libbpf,BTF",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fe879bb42f8a6513ed18e9d22efb99cb35590201,fe879bb42f8a6513ed18e9d22efb99cb35590201,Yonghong Song,yonghong.song@linux.dev,1710210769,Andrii Nakryiko,andrii@kernel.org,1710448663,949cc3dd9c47df524cefd04ba20aeb104b0902e4,c2a0257c1edf16c6acd2afac7572d7e9043b6577,"bpftool: Fix missing pids during link show

Current 'bpftool link' command does not show pids", e.g.,"['\n  $ tools/build/bpftool/bpftool link\n  ...\n  4: tracing  prog 23\n        prog_type lsm  attach_type lsm_mac\n        target_obj_id 1  target_btf_id 31320\n\nHack the following change to enable normal libbpf debug output', '\n  --- a/tools/bpf/bpftool/pids.c\n  +++ b/tools/bpf/bpftool/pids.c\n  @@ -121', '9 +121', '9 @@ int build_obj_refs_table(struct hashmap **map', "" enum bpf_obj_type type)\n          /* we don't want output polluted with libbpf errors if bpf_iter is not\n           * supported\n           */\n  -       default_print = libbpf_set_print(libbpf_print_none);\n  +       /* default_print = libbpf_set_print(libbpf_print_none); */\n          err = pid_iter_bpf__load(skel);\n  -       libbpf_set_print(default_print);\n  +       /* libbpf_set_print(default_print); */\n\nRerun the above bpftool command:\n  $ tools/build/bpftool/bpftool link\n  libbpf: prog 'iter': BPF program load failed: Permission denied\n  libbpf: prog 'iter': -- BEGIN PROG LOAD LOG --\n  0: R1=ctx() R10=fp0\n  ; struct task_struct *task = ctx->task; @ pid_iter.bpf.c:69\n  0: (79) r6 = *(u64 *)(r1 +8)          ; R1=ctx() R6_w=ptr_or_null_task_struct(id=1)\n  ; struct file *file = ctx->file; @ pid_iter.bpf.c:68\n  ...\n  ; struct bpf_link *link = (struct bpf_link *) file->private_data; @ pid_iter.bpf.c:103\n  80: (79) r3 = *(u64 *)(r8 +432)       ; R3_w=scalar() R8=ptr_file()\n  ; if (link->type == bpf_core_enum_value(enum bpf_link_type___local"", "" @ pid_iter.bpf.c:105\n  81: (61) r1 = *(u32 *)(r3 +12)\n  R3 invalid mem access 'scalar'\n  processed 39 insns (limit 1000000) max_states_per_insn 0 total_states 3 peak_states 3 mark_read 2\n  -- END PROG LOAD LOG --\n  libbpf: prog 'iter': failed to load: -13\n  ...\n\nThe 'file->private_data' returns a 'void' type and this caused subsequent 'link->type'\n(insn #81) failed in verification.\n\nTo fix the issue"", ' restore the previous BPF_CORE_READ so old kernels can also work.\nWith this patch', ' the \'bpftool link\' runs successfully with \'pids\'.\n  $ tools/build/bpftool/bpftool link\n  ...\n  4: tracing  prog 23\n        prog_type lsm  attach_type lsm_mac\n        target_obj_id 1  target_btf_id 31320\n        pids systemd(1)\n\nFixes: 44ba7b30e84f (""bpftool: Use a local copy of BPF_LINK_TYPE_PERF_EVENT in pid_iter.bpf.c"")\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nTested-by: Quentin Monnet <quentin@isovalent.com>\nReviewed-by: Quentin Monnet <quentin@isovalent.com>\nLink: https://lore.kernel.org/bpf/20240312023249.3776718-1-yonghong.song@linux.dev\n', '']",Fixes missing process IDs in link information shown by bpftool command.,"bpftool, pids, link",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c2a0257c1edf16c6acd2afac7572d7e9043b6577,c2a0257c1edf16c6acd2afac7572d7e9043b6577,Kui-Feng Lee,thinker.li@gmail.com,1710207446,Andrii Nakryiko,andrii@kernel.org,1710448461,d68b6bd0f77702745446b0b6e15ce5558efb5d7a,9187210eee7d87eea37b45ea93454a88681894a4,"bpftool: Cast pointers for shadow types explicitly.

According to a report"," skeletons fail to assign shadow pointers when being
compiled with C++ programs. Unlike C doing implicit casting for void
pointers","[' C++ requires an explicit casting.\n\nTo support C++', ' we do explicit casting for each shadow pointer.\n\nAlso add struct_ops_module.skel.h to test_cpp to validate C++\ncompilation as part of BPF selftests.\n\nSigned-off-by: Kui-Feng Lee <thinker.li@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nAcked-by: Quentin Monnet <quentin@isovalent.com>\nLink: https://lore.kernel.org/bpf/20240312013726.1780720-1-thinker.li@gmail.com\n', '']",The commit explicitly casts pointers for shadow types in bpftool to address compilation issues with C++.,"bpftool, pointers, shadow",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The bpftool utility,"[""It's not related to any of the above.""]"
44d79142ede8162fd67bf8ca4ddbda1fbcfa94f1,44d79142ede8162fd67bf8ca4ddbda1fbcfa94f1,Puranjay Mohan,puranjay12@gmail.com,1710438571,Alexei Starovoitov,ast@kernel.org,1710443085,ea5ef659bcaa1dc72bb8258baa47b3a9e59fd2db,e30cef001da259e8df354b813015d0e5acc08740,"bpf: Temporarily disable atomic operations in BPF arena

Currently"," the x86 JIT handling PROBE_MEM32 tagged accesses is not
equipped to handle atomic accesses into PTR_TO_ARENA","[' as no PROBE_MEM32\ntagging is performed and no handling is enabled for them.\n\nThis will lead to unsafety as the offset into arena will dereferenced\ndirectly without turning it into a base + offset access into the arena\nregion.\n\nSince the changes to the x86 JIT will be fairly involved', ' for now', '\ntemporarily disallow use of PTR_TO_ARENA as the destination operand for\natomics until support is added to the JIT backend.\n\nFixes: 2fe99eb0ccf2 (""bpf: Add x86-64 JIT support for PROBE_MEM32 pseudo instructions."")\nReported-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nSigned-off-by: Puranjay Mohan <puranjay12@gmail.com>\nAcked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nMessage-ID: <20240314174931.98702-1-puranjay12@gmail.com>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit temporarily disables atomic operations in the BPF arena due to limitations in x86 JIT handling.,"atomic, JIT, PTR_TO_ARENA",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3e78a6c0d3e02e4cf881dc84c5127e9990f939d6,3e78a6c0d3e02e4cf881dc84c5127e9990f939d6,Linus Torvalds,torvalds@linux-foundation.org,1710435375,Linus Torvalds,torvalds@linux-foundation.org,1710435375,a23819b38950e840438a2bda77485d6361706966,b345ff698ec7ed52d90bd5603ec8fc1802f40110 0db18cd824f781584a880653e65a0cfd38f060ee,"Merge tag 'hid-for-linus-2024031301' of git://git.kernel.org/pub/scm/linux/kernel/git/hid/hid

Pull HID updates from Jiri Kosina:

 - support for the following Bluetooth devices from Samsung: Samsung
   wireless {Keyboard", GamePad,"[' Action Mouse', ' Book Cover', ' Universal\n   Keyboard', ' HOGP Keyboard} (Sandeep C S)\n\n - second version of code for applying proper quirk depending on\n   firmware version for lenovo/cptkbd (Mikhail Khvainitski)\n\n - lenovo/cptkbd firmware-dependent quirk (Mikhail Khvainitski)\n\n - assorted fixes and optimizations for amd-sfh (Basavaraj Natikar)\n\n - dead code and dead data structures removal (Jiri Slaby', "" Jiapeng\n   Chong)\n\n* tag 'hid-for-linus-2024031301' of git://git.kernel.org/pub/scm/linux/kernel/git/hid/hid: (25 commits)\n  HID: amd_sfh: Set the AMD SFH driver to depend on x86\n  HID: input: avoid polling stylus battery on Chromebook Pompom\n  HID: amd_sfh: Extend MP2 register access to SFH\n  HID: amd_sfh: Improve boot time when SFH is available\n  HID: amd_sfh: Avoid disabling the interrupt\n  HID: amd_sfh: Update HPD sensor structure elements\n  HID: amd_sfh: Increase sensor command timeout\n  HID: intel-ish-hid: ipc: Add Arrow Lake PCI device ID\n  HID: nintendo: Remove some unused functions\n  HID: hid-prodikeys: remove struct pk_device\n  HID: hid-prodikeys: remove unused struct pcmidi_snd members\n  HID: hid-multitouch: remove unused mt_application::dev_time\n  HID: hid-lg3ff: remove unused struct lg3ff_device\n  HID: protect hid_device::bpf by CONFIG_HID_BPF\n  HID: wacom: remove unused hid_data::pressure\n  HID: apple: remove unused members from struct apple_sc_backlight\n  HID: wacom: Clean up use of struct->wacom_wac\n  HID: samsung: Add Samsung wireless bookcover and universal keyboard support\n  HID: samsung: Add Samsung wireless action mouse support\n  HID: samsung: Add Samsung wireless gamepad support\n  ...\n"", '']",Merge HID subsystem updates for support of Samsung Bluetooth devices.,"Merge,HID,Samsung",It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['HID driver like programs']
9187210eee7d87eea37b45ea93454a88681894a4,9187210eee7d87eea37b45ea93454a88681894a4,Linus Torvalds,torvalds@linux-foundation.org,1710290648,Linus Torvalds,torvalds@linux-foundation.org,1710290648,31b4610e62cdd5e1dfb700014aa619e41145d7d3,1f440397665f4241346e4cc6d93f8b73880815d1 ed1f164038b50c5864aa85389f3ffd456f050cca,"Merge tag 'net-next-6.9' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net-next

Pull networking updates from Jakub Kicinski:
 ""Core & protocols:

   - Large effort by Eric to lower rtnl_lock pressure and remove locks:

      - Make commonly used parts of rtnetlink (address"," route dumps
        etc) lockless","[' protected by RCU instead of rtnl_lock.\n\n      - Add a netns exit callback which already holds rtnl_lock', '\n        allowing netns exit to take rtnl_lock once in the core instead\n        of once for each driver / callback.\n\n      - Remove locks / serialization in the socket diag interface.\n\n      - Remove 6 calls to synchronize_rcu() while holding rtnl_lock.\n\n      - Remove the dev_base_lock', ' depend on RCU where necessary.\n\n   - Support busy polling on a per-epoll context basis. Poll length and\n     budget parameters can be set independently of system defaults.\n\n   - Introduce struct net_hotdata', "" to make sure read-mostly global\n     config variables fit in as few cache lines as possible.\n\n   - Add optional per-nexthop statistics to ease monitoring / debug of\n     ECMP imbalance problems.\n\n   - Support TCP_NOTSENT_LOWAT in MPTCP.\n\n   - Ensure that IPv6 temporary addresses' preferred lifetimes are long\n     enough"", ' compared to other configured lifetimes', ' and at least 2 sec.\n\n   - Support forwarding of ICMP Error messages in IPSec', ' per RFC 4301.\n\n   - Add support for the independent control state machine for bonding\n     per IEEE 802.1AX-2008 5.4.15 in addition to the existing coupled\n     control state machine.\n\n   - Add ""network ID"" to MCTP socket APIs to support hosts with multiple\n     disjoint MCTP networks.\n\n   - Re-use the mono_delivery_time skbuff bit for packets which user\n     space wants to be sent at a specified time. Maintain the timing\n     information while traversing veth links', ' bridge etc.\n\n   - Take advantage of MSG_SPLICE_PAGES for RxRPC DATA and ACK packets.\n\n   - Simplify many places iterating over netdevs by using an xarray\n     instead of a hash table walk (hash table remains in place', ' for use\n     on fastpaths).\n\n   - Speed up scanning for expired routes by keeping a dedicated list.\n\n   - Speed up ""generic"" XDP by trying harder to avoid large allocations.\n\n   - Support attaching arbitrary metadata to netconsole messages.\n\n  Things we sprinkled into general kernel code:\n\n   - Enforce VM_IOREMAP flag and range in ioremap_page_range and\n     introduce VM_SPARSE kind and vm_area_[un]map_pages (used by\n     bpf_arena).\n\n   - Rework selftest harness to enable the use of the full range of ksft\n     exit code (pass', ' fail', ' skip', ' xfail', "" xpass).\n\n  Netfilter:\n\n   - Allow userspace to define a table that is exclusively owned by a\n     daemon (via netlink socket aliveness) without auto-removing this\n     table when the userspace program exits. Such table gets marked as\n     orphaned and a restarting management daemon can re-attach/regain\n     ownership.\n\n   - Speed up element insertions to nftables' concatenated-ranges set\n     type. Compact a few related data structures.\n\n  BPF:\n\n   - Add BPF token support for delegating a subset of BPF subsystem\n     functionality from privileged system-wide daemons such as systemd\n     through special mount options for userns-bound BPF fs to a trusted\n     & unprivileged application.\n\n   - Introduce bpf_arena which is sparse shared memory region between\n     BPF program and user space where structures inside the arena can\n     have pointers to other areas of the arena"", "" and pointers work\n     seamlessly for both user-space programs and BPF programs.\n\n   - Introduce may_goto instruction that is a contract between the\n     verifier and the program. The verifier allows the program to loop\n     assuming it's behaving well"", ' but reserves the right to terminate\n     it.\n\n   - Extend the BPF verifier to enable static subprog calls in spin lock\n     critical sections.\n\n   - Support registration of struct_ops types from modules which helps\n     projects like fuse-bpf that seeks to implement a new struct_ops\n     type.\n\n   - Add support for retrieval of cookies for perf/kprobe multi links.\n\n   - Support arbitrary TCP SYN cookie generation / validation in the TC\n     layer with BPF to allow creating SYN flood handling in BPF\n     firewalls.\n\n   - Add code generation to inline the bpf_kptr_xchg() helper which\n     improves performance when stashing/popping the allocated BPF\n     objects.\n\n  Wireless:\n\n   - Add SPP (signaling and payload protected) AMSDU support.\n\n   - Support wider bandwidth OFDMA', ' as required for EHT operation.\n\n  Driver API:\n\n   - Major overhaul of the Energy Efficient Ethernet internals to\n     support new link modes (2.5GE', ' 5GE)', ' share more code between\n     drivers (especially those using phylib)', ' and encourage more\n     uniform behavior. Convert and clean up drivers.\n\n   - Define an API for querying per netdev queue statistics from\n     drivers.\n\n   - IPSec: account in global stats for fully offloaded sessions.\n\n   - Create a concept of Ethernet PHY Packages at the Device Tree level', '\n     to allow parameterizing the existing PHY package code.\n\n   - Enable Rx hashing (RSS) on GTP protocol fields.\n\n  Misc:\n\n   - Improvements and refactoring all over networking selftests.\n\n   - Create uniform module aliases for TC classifiers', ' actions', ' and\n     packet schedulers to simplify creating modprobe policies.\n\n   - Address all missing MODULE_DESCRIPTION() warnings in networking.\n\n   - Extend the Netlink descriptions in YAML to cover message\n     encapsulation or ""Netlink polymorphism""', ' where interpretation of\n     nested attributes depends on link type', ' classifier type or some\n     other ""class type"".\n\n  Drivers:\n\n   - Ethernet high-speed NICs:\n      - Add a new driver for Marvell\'s Octeon PCI Endpoint NIC VF.\n      - Intel (100G', ' ice', "" idpf):\n         - support E825-C devices\n      - nVidia/Mellanox:\n         - support devices with one port and multiple PCIe links\n      - Broadcom (bnxt):\n         - support n-tuple filters\n         - support configuring the RSS key\n      - Wangxun (ngbe/txgbe):\n         - implement irq_domain for TXGBE's sub-interrupts\n      - Pensando/AMD:\n         - support XDP\n         - optimize queue submission and wakeup handling (+17% bps)\n         - optimize struct layout"", ' saving 28% of memory on queues\n\n   - Ethernet NICs embedded and virtual:\n      - Google cloud vNIC:\n         - refactor driver to perform memory allocations for new queue\n           config before stopping and freeing the old queue memory\n      - Synopsys (stmmac):\n         - obey queueMaxSDU and implement counters required by 802.1Qbv\n      - Renesas (ravb):\n         - support packet checksum offload\n         - suspend to RAM and runtime PM support\n\n   - Ethernet switches:\n      - nVidia/Mellanox:\n         - support for nexthop group statistics\n      - Microchip:\n         - ksz8: implement PHY loopback\n         - add support for KSZ8567', ' a 7-port 10/100Mbps switch\n\n   - PTP:\n      - New driver for RENESAS FemtoClock3 Wireless clock generator.\n      - Support OCP PTP cards designed and built by Adva.\n\n   - CAN:\n      - Support recvmsg() flags for own', ' local and remote traffic on CAN\n        BCM sockets.\n      - Support for esd GmbH PCIe/402 CAN device family.\n      - m_can:\n         - Rx/Tx submission coalescing\n         - wake on frame Rx\n\n   - WiFi:\n      - Intel (iwlwifi):\n         - enable signaling and payload protected A-MSDUs\n         - support wider-bandwidth OFDMA\n         - support for new devices\n         - bump FW API to 89 for AX devices; 90 for BZ/SC devices\n      - MediaTek (mt76):\n         - mt7915: newer ADIE version support\n         - mt7925: radio temperature sensor support\n      - Qualcomm (ath11k):\n         - support 6 GHz station power modes: Low Power Indoor (LPI)', '\n           Standard Power) SP and Very Low Power (VLP)\n         - QCA6390 & WCN6855: support 2 concurrent station interfaces\n         - QCA2066 support\n      - Qualcomm (ath12k):\n         - refactoring in preparation for Multi-Link Operation (MLO)\n           support\n         - 1024 Block Ack window size support\n         - firmware-2.bin support\n         - support having multiple identical PCI devices (firmware needs\n           to have ATH12K_FW_FEATURE_MULTI_QRTR_ID)\n         - QCN9274: support split-PHY devices\n         - WCN7850: enable Power Save Mode in station mode\n         - WCN7850: P2P support\n      - RealTek:\n         - rtw88: support for more rtw8811cu and rtw8821cu devices\n         - rtw89: support SCAN_RANDOM_SN and SET_SCAN_DWELL\n         - rtlwifi: speed up USB firmware initialization\n         - rtwl8xxxu:\n             - RTL8188F: concurrent interface support\n             - Channel Switch Announcement (CSA) support in AP mode\n      - Broadcom (brcmfmac):\n         - per-vendor feature support\n         - per-vendor SAE password setup\n         - DMI nvram filename quirk for ACEPC W5 Pro""\n\n* tag \'net-next-6.9\' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net-next: (2255 commits)\n  nexthop: Fix splat with CONFIG_DEBUG_PREEMPT=y\n  nexthop: Fix out-of-bounds access during attribute validation\n  nexthop: Only parse NHA_OP_FLAGS for dump messages that require it\n  nexthop: Only parse NHA_OP_FLAGS for get messages that require it\n  bpf: move sleepable flag from bpf_prog_aux to bpf_prog\n  bpf: hardcode BPF_PROG_PACK_SIZE to 2MB * num_possible_nodes()\n  selftests/bpf: Add kprobe multi triggering benchmarks\n  ptp: Move from simple ida to xarray\n  vxlan: Remove generic .ndo_get_stats64\n  vxlan: Do not alloc tstats manually\n  devlink: Add comments to use netlink gen tool\n  nfp: flower: handle acti_netdevs allocation failure\n  net/packet: Add getsockopt support for PACKET_COPY_THRESH\n  net/netlink: Add getsockopt support for NETLINK_LISTEN_ALL_NSID\n  selftests/bpf: Add bpf_arena_htab test.\n  selftests/bpf: Add bpf_arena_list test.\n  selftests/bpf: Add unit tests for bpf_arena_alloc/free_pages\n  bpf: Add helper macro bpf_addr_space_cast()\n  libbpf: Recognize __arena global variables.\n  bpftool: Recognize arena map type\n  ...\n', '']","Merging networking updates, focusing on reducing rtnl_lock pressure and achieving lockless operations in rtnetlink.","networking,rtnl_lock,rtnetlink",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5f20e6ab1f65aaaaae248e6946d5cb6d039e7de8,5f20e6ab1f65aaaaae248e6946d5cb6d039e7de8,Jakub Kicinski,kuba@kernel.org,1710205564,Jakub Kicinski,kuba@kernel.org,1710205564,826f8a879f1d954b00e4b07a8afe271aed02992e,f095fefacdd35b4ea97dc6d88d054f2749a73d07 66c8473135c62f478301a0e5b3012f203562dfa6,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next

Alexei Starovoitov says:

====================
pull-request: bpf-next 2024-03-11

We've added 59 non-merge commits during the last 9 day(s) which contain
a total of 88 files changed", 4181 insertions(+),"[' 590 deletions(-).\n\nThe main changes are:\n\n1) Enforce VM_IOREMAP flag and range in ioremap_page_range and introduce\n   VM_SPARSE kind and vm_area_[un]map_pages to be used in bpf_arena', '\n   from Alexei.\n\n2) Introduce bpf_arena which is sparse shared memory region between bpf\n   program and user space where structures inside the arena can have\n   pointers to other areas of the arena', ' and pointers work seamlessly for\n   both user-space programs and bpf programs', "" from Alexei and Andrii.\n\n3) Introduce may_goto instruction that is a contract between the verifier\n   and the program. The verifier allows the program to loop assuming it's\n   behaving well"", ' but reserves the right to terminate it', ' from Alexei.\n\n4) Use IETF format for field definitions in the BPF standard\n   document', ' from Dave.\n\n5) Extend struct_ops libbpf APIs to allow specify version suffixes for\n   stuct_ops map types', ' share the same BPF program between several map\n   definitions', ' and other improvements', ' from Eduard.\n\n6) Enable struct_ops support for more than one page in trampolines', '\n   from Kui-Feng.\n\n7) Support kCFI + BPF on riscv64', ' from Puranjay.\n\n8) Use bpf_prog_pack for arm64 bpf trampoline', ' from Puranjay.\n\n9) Fix roundup_pow_of_two undefined behavior on 32-bit archs', ' from Toke.\n====================\n\nLink: https://lore.kernel.org/r/20240312003646.8692-1-alexei.starovoitov@gmail.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Merged changes from 'bpf-next' branch into the main network development branch.,"merge,bpf-next,network",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
66c8473135c62f478301a0e5b3012f203562dfa6,66c8473135c62f478301a0e5b3012f203562dfa6,Andrii Nakryiko,andrii@kernel.org,1709945259,Alexei Starovoitov,ast@kernel.org,1710200485,38552c4bba5b6de12904aa40539c2d14950c17a8,d6170e4aaf86424c24ce06e355b4573daa891b17,"bpf: move sleepable flag from bpf_prog_aux to bpf_prog

prog->aux->sleepable is checked very frequently as part of (some) BPF
program run hot paths. So this extra aux indirection seems wasteful and
on busy systems might cause unnecessary memory cache misses.

Let's move sleepable flag into prog itself to eliminate unnecessary
pointer dereference.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Message-ID: <20240309004739.2961431-1-andrii@kernel.org>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Moved sleepable flag from bpf_prog_aux to bpf_prog for performance optimization.,"sleepable,performance,flag",It's a performance optimization.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d6170e4aaf86424c24ce06e355b4573daa891b17,d6170e4aaf86424c24ce06e355b4573daa891b17,Puranjay Mohan,puranjay12@gmail.com,1710160042,Alexei Starovoitov,ast@kernel.org,1710200010,3ea4c2d6d52315f79d58cbd825edbabffb4f2999,379b97bbf02feecae5ce870bc0c67e3d723e30f5,"bpf: hardcode BPF_PROG_PACK_SIZE to 2MB * num_possible_nodes()

On some architectures like ARM64"," PMD_SIZE can be really large in some
configurations. Like with CONFIG_ARM64_64K_PAGES=y the PMD_SIZE is
512MB.

Use 2MB * num_possible_nodes() as the size for allocations done through
the prog pack allocator. On most architectures","[' PMD_SIZE will be equal\nto 2MB in case of 4KB pages and will be greater than 2MB for bigger page\nsizes.\n\nFixes: ea2babac63d4 (""bpf: Simplify bpf_prog_pack_[size|mask]"")\nReported-by: ""kernelci.org bot"" <bot@kernelci.org>\nCloses: https://lore.kernel.org/all/7e216c88-77ee-47b8-becc-a0f780868d3c@sirena.org.uk/\nReported-by: kernel test robot <lkp@intel.com>\nCloses: https://lore.kernel.org/oe-kbuild-all/202403092219.dhgcuz2G-lkp@intel.com/\nSuggested-by: Song Liu <song@kernel.org>\nSigned-off-by: Puranjay Mohan <puranjay12@gmail.com>\nMessage-ID: <20240311122722.86232-1-puranjay12@gmail.com>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Hardcode BPF_PROG_PACK_SIZE to 2MB times num_possible_nodes across various architectures.,"BPF, allocation, ARM64",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
379b97bbf02feecae5ce870bc0c67e3d723e30f5,379b97bbf02feecae5ce870bc0c67e3d723e30f5,Jiri Olsa,jolsa@kernel.org,1710191423,Andrii Nakryiko,andrii@kernel.org,1710198408,8f109e164d4cfa7ab1c1f451603de1730830d133,08701e306e480c56b68c1fa35f2c5b27204083e2,"selftests/bpf: Add kprobe multi triggering benchmarks

Adding kprobe multi triggering benchmarks. It's useful now to bench
new fprobe implementation and might be useful later as well.

Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240311211023.590321-1-jolsa@kernel.org
",,The commit adds kprobe multi-triggering benchmarks for evaluating the new fprobe implementation.,"kprobe, benchmarks, fprobe",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
08701e306e480c56b68c1fa35f2c5b27204083e2,08701e306e480c56b68c1fa35f2c5b27204083e2,Andrii Nakryiko,andrii@kernel.org,1710196646,Andrii Nakryiko,andrii@kernel.org,1710197023,0adc349c9b30acf84420c5e52584264a0b048f4f,365c2b32792e692bad6e3761ad19ac3f8f52c0fe 8df839ae23b8c581bdac4b6970d029d65a415852,"Merge branch 'bpf-introduce-bpf-arena'

Alexei Starovoitov says:

====================
bpf: Introduce BPF arena.

From: Alexei Starovoitov <ast@kernel.org>

v2->v3:
- contains bpf bits only"," but cc-ing past audience for continuity
- since prerequisite patches landed","["" this series focus on the main\n  functionality of bpf_arena.\n- adopted Andrii's approach to support arena in libbpf.\n- simplified LLVM support. Instead of two instructions it's now only one.\n- switched to cond_break (instead of open coded iters) in selftests\n- implemented several follow-ups that will be sent after this set\n  . remember first IP and bpf insn that faulted in arena.\n    report to user space via bpftool\n  . copy paste and tweak glob_match() aka mini-regex as a selftests/bpf\n- see patch 1 for detailed description of bpf_arena\n\nv1->v2:\n- Improved commit log with reasons for using vmap_pages_range() in arena.\n  Thanks to Johannes\n- Added support for __arena global variables in bpf programs\n- Fixed race conditions spotted by Barret\n- Fixed wrap32 issue spotted by Barret\n- Fixed bpf_map_mmap_sz() the way Andrii suggested\n\nThe work on bpf_arena was inspired by Barret's work:\nhttps://github.com/google/ghost-userspace/blob/main/lib/queue.bpf.h\nthat implements queues"", ' lists and AVL trees completely as bpf programs\nusing giant bpf array map and integer indices instead of pointers.\nbpf_arena is a sparse array that allows to use normal C pointers to\nbuild such data structures. Last few patches implement page_frag\nallocator', ' link list and hash table as bpf programs.\n\nv1:\nbpf programs have multiple options to communicate with user space:\n- Various ring buffers (perf', ' ftrace', ' bpf): The data is streamed\n  unidirectionally from bpf to user space.\n- Hash map: The bpf program populates elements', "" and user space consumes\n  them via bpf syscall.\n- mmap()-ed array map: Libbpf creates an array map that is directly\n  accessed by the bpf program and mmap-ed to user space. It's the fastest\n  way. Its disadvantage is that memory for the whole array is reserved at\n  the start.\n====================\n\nLink: https://lore.kernel.org/r/20240308010812.89848-1-alexei.starovoitov@gmail.com\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n"", '']",Introduces BPF arena to improve eBPF memory management.,"BPF, arena, memory",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8df839ae23b8c581bdac4b6970d029d65a415852,8df839ae23b8c581bdac4b6970d029d65a415852,Alexei Starovoitov,ast@kernel.org,1709860092,Andrii Nakryiko,andrii@kernel.org,1710197023,0adc349c9b30acf84420c5e52584264a0b048f4f,9f2c156f90a422b4897a8c2831076a96a31413d1,"selftests/bpf: Add bpf_arena_htab test.

bpf_arena_htab.h - hash table implemented as bpf program

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240308010812.89848-15-alexei.starovoitov@gmail.com
",,Add a test for bpf_arena_htab implemented as a BPF program.,"test,bpf,hastable",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9f2c156f90a422b4897a8c2831076a96a31413d1,9f2c156f90a422b4897a8c2831076a96a31413d1,Alexei Starovoitov,ast@kernel.org,1709860091,Andrii Nakryiko,andrii@kernel.org,1710197023,5d4844a16170e216e023889c56d88b22e87cf67a,80a4129fcf20da3c6941411155a9b3b45caa5b8d,"selftests/bpf: Add bpf_arena_list test.

bpf_arena_alloc.h - implements page_frag allocator as a bpf program.
bpf_arena_list.h - doubly linked link list as a bpf program.

Compiled as a bpf program and as native C code.

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240308010812.89848-14-alexei.starovoitov@gmail.com
",,Add selftests for bpf_arena_list and page_frag allocator as bpf programs.,"selftests,bpf_arena_list,page_frag",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
80a4129fcf20da3c6941411155a9b3b45caa5b8d,80a4129fcf20da3c6941411155a9b3b45caa5b8d,Alexei Starovoitov,ast@kernel.org,1709860090,Andrii Nakryiko,andrii@kernel.org,1710197023,e044153bc798df2cec3cce5030f788c6c4023e15,204c628730c62de5a0b593008549a9b95aa96b01,"selftests/bpf: Add unit tests for bpf_arena_alloc/free_pages

Add unit tests for bpf_arena_alloc/free_pages() functionality
and bpf_arena_common.h with a set of common helpers and macros that
is used in this test and the following patches.

Also modify test_loader that didn't support running bpf_prog_type_syscall
programs.

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240308010812.89848-13-alexei.starovoitov@gmail.com
",,Add unit tests for bpf_arena_alloc/free_pages and update test_loader for syscall programs.,"unit tests,bpf_arena_alloc,syscall",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
204c628730c62de5a0b593008549a9b95aa96b01,204c628730c62de5a0b593008549a9b95aa96b01,Alexei Starovoitov,ast@kernel.org,1709860089,Andrii Nakryiko,andrii@kernel.org,1710197022,0b9cd27de01c10719f2b7c49b07660652df3d9d9,2e7ba4f8fd1fa879b37db0b738c23ba2af8292ee,"bpf: Add helper macro bpf_addr_space_cast()

Introduce helper macro bpf_addr_space_cast() that emits:
rX = rX
instruction with off = BPF_ADDR_SPACE_CAST
and encodes dest and src address_space-s into imm32.

It's useful with older LLVM that doesn't emit this insn automatically.

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>
Link: https://lore.kernel.org/bpf/20240308010812.89848-12-alexei.starovoitov@gmail.com
",,Add helper macro bpf_addr_space_cast for older LLVM compatibility in eBPF.,"helper macro, bpf_addr_space_cast, LLVM",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2e7ba4f8fd1fa879b37db0b738c23ba2af8292ee,2e7ba4f8fd1fa879b37db0b738c23ba2af8292ee,Andrii Nakryiko,andrii@kernel.org,1709860088,Andrii Nakryiko,andrii@kernel.org,1710197015,1bfe5765d6f39dbdf850102d379085140cf65e1f,eed512e8ac64339cfc69da1a6a4b60982cb502ca,"libbpf: Recognize __arena global variables.

LLVM automatically places __arena variables into "".arena.1"" ELF section.
In order to use such global variables bpf program must include definition
of arena map in "".maps"" section"," like:
struct {
       __uint(type","[' BPF_MAP_TYPE_ARENA);\n       __uint(map_flags', ' BPF_F_MMAPABLE);\n       __uint(max_entries', ' 1000);         /* number of pages */\n       __ulong(map_extra', ' 2ull << 44);    /* start of mmap() region */\n} arena SEC("".maps"");\n\nlibbpf recognizes both uses of arena and creates single `struct bpf_map *`\ninstance in libbpf APIs.\n"".arena.1"" ELF section data is used as initial data image', ' which is exposed\nthrough skeleton and bpf_map__initial_value() to the user', ' if they need to tune\nit before the load phase. During load phase', "" this initial image is copied over\ninto mmap()'ed region corresponding to arena"", ' and discarded.\n\nFew small checks here and there had to be added to make sure this\napproach works with bpf_map__initial_value()', "" mostly due to hard-coded\nassumption that map->mmaped is set up with mmap() syscall and should be\nmunmap()'ed. For arena"", ' .arena.1 can be (much) smaller than maximum\narena size', ' so this smaller data size has to be tracked separately.\nGiven it is enforced that there is only one arena for entire bpf_object\ninstance', ' we just keep it in a separate field. This can be generalized\nif necessary later.\n\nAll global variables from "".arena.1"" section are accessible from user space\nvia skel->arena->name_of_var.\n\nFor bss/data/rodata the skeleton/libbpf perform the following sequence:\n1. addr = mmap(MAP_ANONYMOUS)\n2. user space optionally modifies global vars\n3. map_fd = bpf_create_map()\n4. bpf_update_map_elem(map_fd', ' addr) // to store values into the kernel\n5. mmap(addr', ' MAP_FIXED', ' map_fd)\nafter step 5 user spaces see the values it wrote at step 2 at the same addresses\n\narena doesn\'t support update_map_elem. Hence skeleton/libbpf do:\n1. addr = malloc(sizeof SEC "".arena.1"")\n2. user space optionally modifies global vars\n3. map_fd = bpf_create_map(MAP_TYPE_ARENA)\n4. real_addr = mmap(map->map_extra', ' MAP_SHARED | MAP_FIXED', ' map_fd)\n5. memcpy(real_addr', ' addr) // this will fault-in and allocate pages\n\nAt the end look and feel of global data vs __arena global data is the same from\nbpf prog pov.\n\nAnother complication is:\nstruct {\n  __uint(type', ' BPF_MAP_TYPE_ARENA);\n} arena SEC("".maps"");\n\nint __arena foo;\nint bar;\n\n  ptr1 = &foo;   // relocation against "".arena.1"" section\n  ptr2 = &arena; // relocation against "".maps"" section\n  ptr3 = &bar;   // relocation against "".bss"" section\n\nFo the kernel ptr1 and ptr2 has point to the same arena\'s map_fd\nwhile ptr3 points to a different global array\'s map_fd.\nFor the verifier:\nptr1->type == unknown_scalar\nptr2->type == const_ptr_to_map\nptr3->type == ptr_to_map_value\n\nAfter verification', ' from JIT pov all 3 ptr-s are normal ld_imm64 insns.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Quentin Monnet <quentin@isovalent.com>\nLink: https://lore.kernel.org/bpf/20240308010812.89848-11-alexei.starovoitov@gmail.com\n', '']",This commit updates libbpf to support __arena global variables in bpf programs.,"libbpf,global variables,__arena",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
eed512e8ac64339cfc69da1a6a4b60982cb502ca,eed512e8ac64339cfc69da1a6a4b60982cb502ca,Alexei Starovoitov,ast@kernel.org,1709860087,Andrii Nakryiko,andrii@kernel.org,1710196644,98a2347bd01b204c478c3d9215b0c94822cc6a74,79ff13e99169ddb0e2277e046dbfb112f77dfac5,"bpftool: Recognize arena map type

Teach bpftool to recognize arena map type.

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Quentin Monnet <quentin@isovalent.com>
Link: https://lore.kernel.org/bpf/20240308010812.89848-10-alexei.starovoitov@gmail.com
",,The commit adds support for recognizing arena map type in bpftool.,"bpftool, arena, map type",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"[""It's not related to any of the above.""]"
79ff13e99169ddb0e2277e046dbfb112f77dfac5,79ff13e99169ddb0e2277e046dbfb112f77dfac5,Alexei Starovoitov,ast@kernel.org,1709860086,Andrii Nakryiko,andrii@kernel.org,1710196644,4ebc8420dd502d99d541e538ec00c80e6e4b2b15,4d2b56081c32cb33364745da434b88eeaa9d8d8d,"libbpf: Add support for bpf_arena.

mmap() bpf_arena right after creation"," since the kernel needs to
remember the address returned from mmap. This is user_vm_start.
LLVM will generate bpf_arena_cast_user() instructions where
necessary and JIT will add upper 32-bit of user_vm_start
to such pointers.

Fix up bpf_map_mmap_sz() to compute mmap size as
map->value_size * map->max_entries for arrays and
PAGE_SIZE * map->max_entries for arena.

Don't set BTF at arena creation time","["" since it doesn't support it.\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240308010812.89848-9-alexei.starovoitov@gmail.com\n"", '']","The commit adds support for bpf_arena in libbpf, enhancing mmap handling and pointer management.","libbpf,bpf_arena,mmap",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4d2b56081c32cb33364745da434b88eeaa9d8d8d,4d2b56081c32cb33364745da434b88eeaa9d8d8d,Alexei Starovoitov,ast@kernel.org,1709860085,Andrii Nakryiko,andrii@kernel.org,1710196644,9c134f6f121825010e07adba5b56109c95779606,2edc3de6fb650924a87fffebebc3b7572cbf6e38,"libbpf: Add __arg_arena to bpf_helpers.h

Add __arg_arena to bpf_helpers.h

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240308010812.89848-8-alexei.starovoitov@gmail.com
",,Add __arg_arena to enhance functionality in bpf_helpers.h for libbpf.,"libbpf,arg_arena,bpf_helpers",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2edc3de6fb650924a87fffebebc3b7572cbf6e38,2edc3de6fb650924a87fffebebc3b7572cbf6e38,Alexei Starovoitov,ast@kernel.org,1709860084,Andrii Nakryiko,andrii@kernel.org,1710196644,507c3f99582f9326e792ab0a5078e424f1902520,6082b6c328b5486da2b356eae94b8b83c98b5565,"bpf: Recognize btf_decl_tag(""arg: Arena"") as PTR_TO_ARENA.

In global bpf functions recognize btf_decl_tag(""arg:arena"") as PTR_TO_ARENA.

Note"," when the verifier sees:

__weak void foo(struct bar *p)

it recognizes 'p' as PTR_TO_MEM and 'struct bar' has to be a struct with scalars.
Hence the only way to use arena pointers in global functions is to tag them with ""arg:arena"".

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>
Link: https://lore.kernel.org/bpf/20240308010812.89848-7-alexei.starovoitov@gmail.com
",[''],"This commit enables BPF functions to recognize arena pointers tagged with ""arg:arena"" as PTR_TO_ARENA in global functions.","btf_decl_tag,PTR_TO_ARENA,arena",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6082b6c328b5486da2b356eae94b8b83c98b5565,6082b6c328b5486da2b356eae94b8b83c98b5565,Alexei Starovoitov,ast@kernel.org,1709860083,Andrii Nakryiko,andrii@kernel.org,1710196644,c61b1d28d56273bc3b459f87167423a55b989675,142fd4d2dcf58b1720a6af644f31de1a5551f219,"bpf: Recognize addr_space_cast instruction in the verifier.

rY = addr_space_cast(rX", 0,"[' 1) tells the verifier that rY->type = PTR_TO_ARENA.\nAny further operations on PTR_TO_ARENA register have to be in 32-bit domain.\n\nThe verifier will mark load/store through PTR_TO_ARENA with PROBE_MEM32.\nJIT will generate them as kern_vm_start + 32bit_addr memory accesses.\n\nrY = addr_space_cast(rX', ' 1', ' 0) tells the verifier that rY->type = unknown scalar.\nIf arena->map_flags has BPF_F_NO_USER_CONV set then convert cast_user to mov32 as well.\nOtherwise JIT will convert it to:\n  rY = (u32)rX;\n  if (rY)\n     rY |= arena->user_vm_start & ~(u64)~0U;\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240308010812.89848-6-alexei.starovoitov@gmail.com\n', '']",The commit adds recognition of addr_space_cast instruction to the eBPF verifier.,"addr_space_cast, verifier, bpf",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
142fd4d2dcf58b1720a6af644f31de1a5551f219,142fd4d2dcf58b1720a6af644f31de1a5551f219,Alexei Starovoitov,ast@kernel.org,1709860082,Andrii Nakryiko,andrii@kernel.org,1710196644,aefa22cd078872844283df5ae8aa9f64e1614fa9,2fe99eb0ccf2bb73df65ebcbbf2f2ff70e63547b,"bpf: Add x86-64 JIT support for bpf_addr_space_cast instruction.

LLVM generates bpf_addr_space_cast instruction while translating
pointers between native (zero) address space and
__attribute__((address_space(N))).
The addr_space=1 is reserved as bpf_arena address space.

rY = addr_space_cast(rX", 0,"[' 1) is processed by the verifier and\nconverted to normal 32-bit move: wX = wY\n\nrY = addr_space_cast(rX', ' 1', ' 0) has to be converted by JIT:\n\naux_reg = upper_32_bits of arena->user_vm_start\naux_reg <<= 32\nwX = wY // clear upper 32 bits of dst register\nif (wX) // if not zero add upper bits of user_vm_start\n  wX |= aux_reg\n\nJIT can do it more efficiently:\n\nmov dst_reg32', ' src_reg32  // 32-bit move\nshl dst_reg', ' 32\nor dst_reg', ' user_vm_start\nrol dst_reg', ' 32\nxor r11', ' r11\ntest dst_reg32', ' dst_reg32 // check if lower 32-bit are zero\ncmove r11', ' dst_reg\t  // if so', ' set dst_reg to zero\n\t\t\t  // Intel swapped src/dst register encoding in CMOVcc\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/bpf/20240308010812.89848-5-alexei.starovoitov@gmail.com\n', '']",Add x86-64 JIT support for bpf_addr_space_cast instruction to enhance pointer address space conversion.,"x86-64 JIT, bpf_addr_space_cast, pointer conversion",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2fe99eb0ccf2bb73df65ebcbbf2f2ff70e63547b,2fe99eb0ccf2bb73df65ebcbbf2f2ff70e63547b,Alexei Starovoitov,ast@kernel.org,1709860081,Andrii Nakryiko,andrii@kernel.org,1710196644,9bc8df3820cfa576dfbff871acff07e3145e1e1d,667a86ad9b71d934c444eec193cf3508016f35c5,"bpf: Add x86-64 JIT support for PROBE_MEM32 pseudo instructions.

Add support for [LDX | STX | ST]", PROBE_MEM32,"["" [B | H | W | DW] instructions.\nThey are similar to PROBE_MEM instructions with the following differences:\n- PROBE_MEM has to check that the address is in the kernel range with\n  src_reg + insn->off >= TASK_SIZE_MAX + PAGE_SIZE check\n- PROBE_MEM doesn't support store\n- PROBE_MEM32 relies on the verifier to clear upper 32-bit in the register\n- PROBE_MEM32 adds 64-bit kern_vm_start address (which is stored in %r12 in the prologue)\n  Due to bpf_arena constructions such %r12 + %reg + off16 access is guaranteed\n  to be within arena virtual range"", ' so no address check at run-time.\n- PROBE_MEM32 allows STX and ST. If they fault the store is a nop.\n  When LDX faults the destination register is zeroed.\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nLink: https://lore.kernel.org/bpf/20240308010812.89848-4-alexei.starovoitov@gmail.com\n', '']",Support added for x86-64 JIT handling of PROBE_MEM32 pseudo instructions in eBPF.,"x86-64, JIT, PROBE_MEM32",It's a new feature.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
667a86ad9b71d934c444eec193cf3508016f35c5,667a86ad9b71d934c444eec193cf3508016f35c5,Alexei Starovoitov,ast@kernel.org,1709860080,Andrii Nakryiko,andrii@kernel.org,1710196644,1517fb859cd443cd74b02dbf3d3684cb29a40f40,317460317a02a1af512697e6e964298dedd8a163,"bpf: Disasm support for addr_space_cast instruction.

LLVM generates rX = addr_space_cast(rY", dst_addr_space,"[' src_addr_space)\ninstruction when pointers in non-zero address space are used by the bpf\nprogram. Recognize this insn in uapi and in bpf disassembler.\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nLink: https://lore.kernel.org/bpf/20240308010812.89848-3-alexei.starovoitov@gmail.com\n', '']",Added disassembly support for addr_space_cast instruction in bpf.,"disassembly, addr_space_cast, instruction",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
317460317a02a1af512697e6e964298dedd8a163,317460317a02a1af512697e6e964298dedd8a163,Alexei Starovoitov,ast@kernel.org,1709860079,Andrii Nakryiko,andrii@kernel.org,1710196643,4c3766d365686326053292a860fde3f8ced2c087,365c2b32792e692bad6e3761ad19ac3f8f52c0fe,"bpf: Introduce bpf_arena.

Introduce bpf_arena"," which is a sparse shared memory region between the bpf
program and user space.

Use cases:
1. User space mmap-s bpf_arena and uses it as a traditional mmap-ed
   anonymous region","[' like memcached or any key/value storage. The bpf\n   program implements an in-kernel accelerator. XDP prog can search for\n   a key in bpf_arena and return a value without going to user space.\n2. The bpf program builds arbitrary data structures in bpf_arena (hash\n   tables', ' rb-trees', ' sparse arrays)', ' while user space consumes it.\n3. bpf_arena is a ""heap"" of memory from the bpf program\'s point of view.\n   The user space may mmap it', ' but bpf program will not convert pointers\n   to user base at run-time to improve bpf program speed.\n\nInitially', ' the kernel vm_area and user vma are not populated. User space\ncan fault in pages within the range. While servicing a page fault', '\nbpf_arena logic will insert a new page into the kernel and user vmas. The\nbpf program can allocate pages from that region via\nbpf_arena_alloc_pages(). This kernel function will insert pages into the\nkernel vm_area. The subsequent fault-in from user space will populate that\npage into the user vma. The BPF_F_SEGV_ON_FAULT flag at arena creation time\ncan be used to prevent fault-in from user space. In such a case', ' if a page\nis not allocated by the bpf program and not present in the kernel vm_area', '\nthe user process will segfault. This is useful for use cases 2 and 3 above.\n\nbpf_arena_alloc_pages() is similar to user space mmap(). It allocates pages\neither at a specific address within the arena or allocates a range with the\nmaple tree. bpf_arena_free_pages() is analogous to munmap()', ' which frees\npages and removes the range from the kernel vm_area and from user process\nvmas.\n\nbpf_arena can be used as a bpf program ""heap"" of up to 4GB. The speed of\nbpf program is more important than ease of sharing with user space. This is\nuse case 3. In such a case', ' the BPF_F_NO_USER_CONV flag is recommended.\nIt will tell the verifier to treat the rX = bpf_arena_cast_user(rY)\ninstruction as a 32-bit move wX = wY', ' which will improve bpf prog\nperformance. Otherwise', ' bpf_arena_cast_user is translated by JIT to\nconditionally add the upper 32 bits of user vm_start (if the pointer is not\nNULL) to arena pointers before they are stored into memory. This way', ' user\nspace sees them as valid 64-bit pointers.\n\nDiff https://github.com/llvm/llvm-project/pull/84410 enables LLVM BPF\nbackend generate the bpf_addr_space_cast() instruction to cast pointers\nbetween address_space(1) which is reserved for bpf_arena pointers and\ndefault address space zero. All arena pointers in a bpf program written in\nC language are tagged as __attribute__((address_space(1))). Hence', ' clang\nprovides helpful diagnostics when pointers cross address space. Libbpf and\nthe kernel support only address_space == 1. All other address space\nidentifiers are reserved.\n\nrX = bpf_addr_space_cast(rY', ' /* dst_as */ 1', ' /* src_as */ 0) tells the\nverifier that rX->type = PTR_TO_ARENA. Any further operations on\nPTR_TO_ARENA register have to be in the 32-bit domain. The verifier will\nmark load/store through PTR_TO_ARENA with PROBE_MEM32. JIT will generate\nthem as kern_vm_start + 32bit_addr memory accesses. The behavior is similar\nto copy_from_kernel_nofault() except that no address checks are necessary.\nThe address is guaranteed to be in the 4GB range. If the page is not\npresent', ' the destination register is zeroed on read', ' and the operation is\nignored on write.\n\nrX = bpf_addr_space_cast(rY', ' 0', ' 1) tells the verifier that rX->type =\nunknown scalar. If arena->map_flags has BPF_F_NO_USER_CONV set', ' then the\nverifier converts such cast instructions to mov32. Otherwise', ' JIT will emit\nnative code equivalent to:\nrX = (u32)rY;\nif (rY)\n  rX |= clear_lo32_bits(arena->user_vm_start); /* replace hi32 bits in rX */\n\nAfter such conversion', ' the pointer becomes a valid user pointer within\nbpf_arena range. The user process can access data structures created in\nbpf_arena without any additional computations. For example', ' a linked list\nbuilt by a bpf program can be walked natively by user space.\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nReviewed-by: Barret Rhoden <brho@google.com>\nLink: https://lore.kernel.org/bpf/20240308010812.89848-2-alexei.starovoitov@gmail.com\n', '']",Introduce bpf_arena for sparse shared memory usage between eBPF program and user space.,"bpf_arena,sparse,memory",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
365c2b32792e692bad6e3761ad19ac3f8f52c0fe,365c2b32792e692bad6e3761ad19ac3f8f52c0fe,Andrii Nakryiko,andrii@kernel.org,1709945484,Daniel Borkmann,daniel@iogearbox.net,1710172800,6de4e5a10f581e5c26cdf855c6e8602ed6a5fe32,d7bca9199a27b8690ae1c71dc11f825154af7234,"selftests/bpf: Add fexit and kretprobe triggering benchmarks

We already have kprobe and fentry benchmarks. Let's add kretprobe and
fexit ones for completeness.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Link: https://lore.kernel.org/bpf/20240309005124.3004446-1-andrii@kernel.org
",,Added benchmarks for fexit and kretprobe in selftests/bpf.,"fexit,kretprobe,benchmarks",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
d7bca9199a27b8690ae1c71dc11f825154af7234,d7bca9199a27b8690ae1c71dc11f825154af7234,Alexei Starovoitov,ast@kernel.org,1709917974,Daniel Borkmann,daniel@iogearbox.net,1710172690,bab755c8891d6e8c5868a571a3270cc98c00b99f,96b0f5addc7a0d9ed1f4969ca85ed7513cb1ed25,"mm: Introduce vmap_page_range() to map pages in PCI address space

ioremap_page_range() should be used for ranges within vmalloc range only.
The vmalloc ranges are allocated by get_vm_area(). PCI has ""resource""
allocator that manages PCI_IOBASE", IO_SPACE_LIMIT address range,"[' hence\nintroduce vmap_page_range() to be used exclusively to map pages\nin PCI address space.\n\nFixes: 3e49a866c9dc (""mm: Enforce VM_IOREMAP flag and range in ioremap_page_range."")\nReported-by: Miguel Ojeda <ojeda@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Christoph Hellwig <hch@lst.de>\nTested-by: Miguel Ojeda <ojeda@kernel.org>\nLink: https://lore.kernel.org/bpf/CANiq72ka4rir+RTN2FQoT=Vvprp_Ao-CvoYEkSNqtSY+RZj+AA@mail.gmail.com\n', '']","Introduce vmap_page_range() for mapping pages in PCI address space, distinct from ioremap_page_range().","vmap_page_range, PCI, ioremap",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
08842c43d0165b0ed78907fd8cc92ce17d857913,08842c43d0165b0ed78907fd8cc92ce17d857913,Eric Dumazet,edumazet@google.com,1709848816,David S. Miller,davem@davemloft.net,1710150963,160989a2a4c9aac50ed9694d32d0dea8912ca5a0,e996401e06a5232f61b4906e2eea643fffa88396,"udp: no longer touch sk->sk_refcnt in early demux

After commits ca065d0cf80f (""udp: no longer use SLAB_DESTROY_BY_RCU"")
and 7ae215d23c12 (""bpf: Don't refcount LISTEN sockets in sk_assign()"")
UDP early demux no longer need to grab a refcount on the UDP socket.

This save two atomic operations per incoming packet for connected
sockets.

Signed-off-by: Eric Dumazet <edumazet@google.com>
Cc: Martin KaFai Lau <kafai@fb.com>
Cc: Joe Stringer <joe@wand.net.nz>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Willem de Bruijn <willemdebruijn.kernel@gmail.com>
Cc: Kuniyuki Iwashima <kuniyu@amazon.com>
Acked-by: Paolo Abeni <pabeni@redhat.com>
Signed-off-by: David S. Miller <davem@davemloft.net>
",,The commit removes the need to modify sk_refcnt in UDP early demux for improved performance.,"UDP, refcount, demux",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['socket like programs']
96d9cbe2f2ff7abde021bac75eafaceabe9a51fa,96d9cbe2f2ff7abde021bac75eafaceabe9a51fa,Manjunath Patil,manjunath.b.patil@oracle.com,1709966003,Leon Romanovsky,leon@kernel.org,1710069474,06f5ce1c681da5d07cdbd2f0e22dbdb8b5c4067d,2d5c00815778ec4f4e0a84e405e3e157b7815db1,"RDMA/cm: add timeout to cm_destroy_id wait

Add timeout to cm_destroy_id"," so that userspace can trigger any data
collection that would help in analyzing the cause of delay in destroying
the cm_id.

New noinline function helps dtrace/ebpf programs to hook on to it.
Existing functionality isn't changed except triggering a probe-able new
function at every timeout interval.

We have seen cases where CM messages stuck with MAD layer (either due to
software bug or faulty HCA)","[' leading to cm_id getting stuck in the\nfollowing call stack. This patch helps in resolving such issues faster.\n\nkernel: ... INFO: task XXXX:56778 blocked for more than 120 seconds.\n...\n\tCall Trace:\n\t__schedule+0x2bc/0x895\n\tschedule+0x36/0x7c\n\tschedule_timeout+0x1f6/0x31f\n \t? __slab_free+0x19c/0x2ba\n\twait_for_completion+0x12b/0x18a\n\t? wake_up_q+0x80/0x73\n\tcm_destroy_id+0x345/0x610 [ib_cm]\n\tib_destroy_cm_id+0x10/0x20 [ib_cm]\n\trdma_destroy_id+0xa8/0x300 [rdma_cm]\n\tucma_destroy_id+0x13e/0x190 [rdma_ucm]\n\tucma_write+0xe0/0x160 [rdma_ucm]\n\t__vfs_write+0x3a/0x16d\n\tvfs_write+0xb2/0x1a1\n\t? syscall_trace_enter+0x1ce/0x2b8\n\tSyS_write+0x5c/0xd3\n\tdo_syscall_64+0x79/0x1b9\n\tentry_SYSCALL_64_after_hwframe+0x16d/0x0\n\nSigned-off-by: Manjunath Patil <manjunath.b.patil@oracle.com>\nLink: https://lore.kernel.org/r/20240309063323.458102-1-manjunath.b.patil@oracle.com\nSigned-off-by: Leon Romanovsky <leon@kernel.org>\n', '']",The commit adds a timeout to the cm_destroy_id wait for improved data collection during delays.,"timeout,cm_destroy_id,dtrace",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
96b0f5addc7a0d9ed1f4969ca85ed7513cb1ed25,96b0f5addc7a0d9ed1f4969ca85ed7513cb1ed25,Puranjay Mohan,puranjay12@gmail.com,1709584083,Alexei Starovoitov,ast@kernel.org,1710002395,0f7bb0775e388cb9a2ae69a818d5c938c0ca2d33,a27e89673abf1623c298ea84eaa03f4c57aeca1b,arm64," bpf: Use bpf_prog_pack for arm64 bpf trampoline

We used bpf_prog_pack to aggregate bpf programs into huge page to
relieve the iTLB pressure on the system. This was merged for ARM64[1]
We can apply it to bpf trampoline as well. This would increase the
preformance of fentry and struct_ops programs.

[1] https://lore.kernel.org/bpf/20240228141824.119877-1-puranjay12@gmail.com/

Signed-off-by: Puranjay Mohan <puranjay12@gmail.com>
Reviewed-by: Pu Lehui <pulehui@huawei.com>
Message-ID: <20240304202803.31400-1-puranjay12@gmail.com>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],"The commit uses bpf_prog_pack to optimize bpf trampoline performance on ARM64, reducing iTLB pressure and enhancing fentry and struct_ops programs.","bpf_prog_pack,ARM64,iTLB",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['tracepoints like programs', 'kprobe/uprobe/ftrace like programs']"
caabd859c41b50a571cfdf7747de9f245c5d531b,caabd859c41b50a571cfdf7747de9f245c5d531b,fuyuanli,fuyuanli@didiglobal.com,1709607857,David S. Miller,davem@davemloft.net,1709893547,29348feae2058257acf7bafa281bb5b6a3741fec,6025b9135f7a8b46826a5fcf947259da43bac281,"tcp: Add skb addr and sock addr to arguments of tracepoint tcp_probe.

It is useful to expose skb addr and sock addr to user in tracepoint
tcp_probe"," so that we can get more information while monitoring
receiving of tcp data","[' by ebpf or other ways.\n\nFor example', ' we need to identify a packet by seq and end_seq when\ncalculate transmit latency between layer 2 and layer 4 by ebpf', ' but which is\nnot available in tcp_probe', ' so we can only use kprobe hooking\ntcp_rcv_established to get them. But we can use tcp_probe directly if skb\naddr and sock addr are available', ' which is more efficient.\n\nSigned-off-by: fuyuanli <fuyuanli@didiglobal.com>\nReviewed-by: Jason Xing <kerneljasonxing@gmail.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>\n', '']",The commit adds skb and sock addresses as arguments to the tcp_probe tracepoint for enhanced monitoring of TCP data reception.,"tcp_probe, skb addr, sock addr",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
a27e89673abf1623c298ea84eaa03f4c57aeca1b,a27e89673abf1623c298ea84eaa03f4c57aeca1b,Alexei Starovoitov,ast@kernel.org,1709870559,Alexei Starovoitov,ast@kernel.org,1709870792,055be779382b86723c540e8c180876dd163b4826,c7d4274e90a1e7aa43d11d2a16066cbbe610070e 7a4b21250bf79eef26543d35bd390448646c536b,"Merge branch 'fix-hash-bucket-overflow-checks-for-32-bit-arches'

Toke Høiland-Jørgensen says:

====================
Fix hash bucket overflow checks for 32-bit arches

Syzbot managed to trigger a crash by creating a DEVMAP_HASH map with a
large number of buckets because the overflow check relies on
well-defined behaviour that is only correct on 64-bit arches.

Fix the overflow checks to happen before values are rounded up in all
the affected map types.

v3:
- Keep the htab->n_buckets > U32_MAX / sizeof(struct bucket) check
- Use 1UL << 31 instead of U32_MAX / 2 + 1 as the constant to check
  against
- Add patch to fix stackmap.c
v2:
- Fix off-by-one error in overflow check
- Apply the same fix to hashtab"," where the devmap_hash code was copied
  from (John)

Toke Høiland-Jørgensen (3):
  bpf: Fix DEVMAP_HASH overflow check on 32-bit arches
  bpf: Fix hashtab overflow check on 32-bit arches
  bpf: Fix stackmap overflow check on 32-bit arches

 kernel/bpf/devmap.c   | 11 ++++++-----
 kernel/bpf/hashtab.c  | 14 +++++++++-----
 kernel/bpf/stackmap.c |  9 ++++++---
 3 files changed","[' 21 insertions(+)', ' 13 deletions(-)\n====================\n\nLink: https://lore.kernel.org/r/20240307120340.99577-1-toke@redhat.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix overflow checks in hash buckets for 32-bit architectures in eBPF.,"overflow, 32-bit, hash",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7a4b21250bf79eef26543d35bd390448646c536b,7a4b21250bf79eef26543d35bd390448646c536b,Toke Høiland-Jørgensen,toke@redhat.com,1709813017,Alexei Starovoitov,ast@kernel.org,1709870785,055be779382b86723c540e8c180876dd163b4826,6787d916c2cf9850c97a0a3f73e08c43e7d973b1,"bpf: Fix stackmap overflow check on 32-bit arches

The stackmap code relies on roundup_pow_of_two() to compute the number
of hash buckets"," and contains an overflow check by checking if the
resulting value is 0. However","[' on 32-bit arches', ' the roundup code itself\ncan overflow by doing a 32-bit left-shift of an unsigned long value', '\nwhich is undefined behaviour', ' so it is not guaranteed to truncate\nneatly. This was triggered by syzbot on the DEVMAP_HASH type', ' which\ncontains the same check', ' copied from the hashtab code.\n\nThe commit in the fixes tag actually attempted to fix this', ' but the fix\ndid not account for the UB', ' so the fix only works on CPUs where an\noverflow does result in a neat truncation to zero', ' which is not\nguaranteed. Checking the value before rounding does not have this\nproblem.\n\nFixes: 6183f4d3a0a2 (""bpf: Check for integer overflow when using roundup_pow_of_two()"")\nSigned-off-by: Toke Høiland-Jørgensen <toke@redhat.com>\nReviewed-by: Bui Quang Minh <minhquangbui99@gmail.com>\nMessage-ID: <20240307120340.99577-4-toke@redhat.com>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes stackmap overflow check issue on 32-bit architectures in BPF.,"stackmap, overflow, 32-bit",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6787d916c2cf9850c97a0a3f73e08c43e7d973b1,6787d916c2cf9850c97a0a3f73e08c43e7d973b1,Toke Høiland-Jørgensen,toke@redhat.com,1709813016,Alexei Starovoitov,ast@kernel.org,1709870756,4507c251124f0b366db3aeaa34baa51fac562d67,281d464a34f540de166cee74b723e97ac2515ec3,"bpf: Fix hashtab overflow check on 32-bit arches

The hashtab code relies on roundup_pow_of_two() to compute the number of
hash buckets"," and contains an overflow check by checking if the
resulting value is 0. However","[' on 32-bit arches', ' the roundup code itself\ncan overflow by doing a 32-bit left-shift of an unsigned long value', '\nwhich is undefined behaviour', ' so it is not guaranteed to truncate\nneatly. This was triggered by syzbot on the DEVMAP_HASH type', ' which\ncontains the same check', ' copied from the hashtab code. So apply the same\nfix to hashtab', ' by moving the overflow check to before the roundup.\n\nFixes: daaf427c6ab3 (""bpf: fix arraymap NULL deref and missing overflow and zero size checks"")\nSigned-off-by: Toke Høiland-Jørgensen <toke@redhat.com>\nMessage-ID: <20240307120340.99577-3-toke@redhat.com>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes overflow issue in hashtab code for 32-bit architectures.,"hashtab,overflow,32-bit",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
281d464a34f540de166cee74b723e97ac2515ec3,281d464a34f540de166cee74b723e97ac2515ec3,Toke Høiland-Jørgensen,toke@redhat.com,1709813015,Alexei Starovoitov,ast@kernel.org,1709870558,507887987fc4b8cd45838464e2ceda8cfd5951d6,c7d4274e90a1e7aa43d11d2a16066cbbe610070e,"bpf: Fix DEVMAP_HASH overflow check on 32-bit arches

The devmap code allocates a number hash buckets equal to the next power
of two of the max_entries value provided when creating the map. When
rounding up to the next power of two"," the 32-bit variable storing the
number of buckets can overflow","[' and the code checks for overflow by\nchecking if the truncated 32-bit value is equal to 0. However', ' on 32-bit\narches the rounding up itself can overflow mid-way through', ' because it\nends up doing a left-shift of 32 bits on an unsigned long value. If the\nsize of an unsigned long is four bytes', ' this is undefined behaviour', ' so\nthere is no guarantee that we\'ll end up with a nice and tidy 0-value at\nthe end.\n\nSyzbot managed to turn this into a crash on arm32 by creating a\nDEVMAP_HASH with max_entries > 0x80000000 and then trying to update it.\nFix this by moving the overflow check to before the rounding up\noperation.\n\nFixes: 6f9d451ab1a3 (""xdp: Add devmap_hash map type for looking up devices by hashed index"")\nLink: https://lore.kernel.org/r/000000000000ed666a0611af6818@google.com\nReported-and-tested-by: syzbot+8cd36f6b65f3cafd400a@syzkaller.appspotmail.com\nSigned-off-by: Toke Høiland-Jørgensen <toke@redhat.com>\nMessage-ID: <20240307120340.99577-2-toke@redhat.com>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes DEVMAP_HASH overflow issue on 32-bit architectures in the eBPF subsystem.,"DEVMAP_HASH, overflow, 32-bit",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c7d4274e90a1e7aa43d11d2a16066cbbe610070e,c7d4274e90a1e7aa43d11d2a16066cbbe610070e,Martin KaFai Lau,martin.lau@kernel.org,1709852329,Martin KaFai Lau,martin.lau@kernel.org,1709852517,afd0ca6870d3abf41b811e706c3f788057183e9b,e63985ecd22681c7f5975f2e8637187a326b6791 fe5064158c561b807af5708c868f6c7cb5144e01,"Merge branch 'bpf: arena prerequisites'

Alexei Starovoitov says:

====================
These are bpf_arena prerequisite patches.
Useful on its own.

Alexei Starovoitov (5):
  bpf: Allow kfuncs return 'void *'
  bpf: Recognize '__map' suffix in kfunc arguments
  bpf: Plumb get_unmapped_area() callback into bpf_map_ops
  libbpf: Allow specifying 64-bit integers in map BTF.
  bpf: Tell bpf programs kernel's PAGE_SIZE
====================

Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,This commit merges prerequisites for bpf_arena to enhance BPF functionalities including kfunc improvements and map operations.,"bpf_arena, kfuncs, map_ops",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fe5064158c561b807af5708c868f6c7cb5144e01,fe5064158c561b807af5708c868f6c7cb5144e01,Alexei Starovoitov,ast@kernel.org,1709781148,Martin KaFai Lau,martin.lau@kernel.org,1709852328,afd0ca6870d3abf41b811e706c3f788057183e9b,1576b07961971d4eeb0e269c7133e9a6d430daf8,"bpf: Tell bpf programs kernel's PAGE_SIZE

vmlinux BTF includes all kernel enums.
Add __PAGE_SIZE = PAGE_SIZE enum"," so that bpf programs
that include vmlinux.h can easily access it.

Acked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/r/20240307031228.42896-7-alexei.starovoitov@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],The commit introduces a kernel enum for PAGE_SIZE to make it accessible to bpf programs using vmlinux.h.,"PAGE_SIZE, bpf, vmlinux",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1576b07961971d4eeb0e269c7133e9a6d430daf8,1576b07961971d4eeb0e269c7133e9a6d430daf8,Andrii Nakryiko,andrii@kernel.org,1709781147,Martin KaFai Lau,martin.lau@kernel.org,1709852328,17697edda374b0ce33105ea003e5201d602890a7,d147357e2e5977c5fe9218457a1e359fd1d36609,"bpftool: rename is_internal_mmapable_map into is_mmapable_map

It's not restricted to working with ""internal"" maps"," it cares about any
map that can be mmap'ed. Reflect that in more succinct and generic name.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Acked-by: Quentin Monnet <quentin@isovalent.com>
Link: https://lore.kernel.org/r/20240307031228.42896-6-alexei.starovoitov@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],"Renamed function to reflect usage with any mmap'able map, not just internal ones.","rename, mmapable, bpftool",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d147357e2e5977c5fe9218457a1e359fd1d36609,d147357e2e5977c5fe9218457a1e359fd1d36609,Alexei Starovoitov,ast@kernel.org,1709781146,Martin KaFai Lau,martin.lau@kernel.org,1709852328,3460c738a1dd66aeab815a4e10efee871376909a,cf2c2e4a3d910270903d50462aaa75140cdb2c96,"libbpf: Allow specifying 64-bit integers in map BTF.

__uint() macro that is used to specify map attributes like:
  __uint(type"," BPF_MAP_TYPE_ARRAY);
  __uint(map_flags","[' BPF_F_MMAPABLE);\nIt is limited to 32-bit', ' since BTF_KIND_ARRAY has u32 ""number of elements""\nfield in ""struct btf_array"".\n\nIntroduce __ulong() macro that allows specifying values bigger than 32-bit.\nIn map definition ""map_extra"" is the only u64 field', ' so far.\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nLink: https://lore.kernel.org/r/20240307031228.42896-5-alexei.starovoitov@gmail.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",This commit enables specifying 64-bit integers in map BTF using libbpf.,"libbpf, 64-bit integers, map BTF",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
cf2c2e4a3d910270903d50462aaa75140cdb2c96,cf2c2e4a3d910270903d50462aaa75140cdb2c96,Alexei Starovoitov,ast@kernel.org,1709781145,Martin KaFai Lau,martin.lau@kernel.org,1709852328,af6f493a310ee8317f38abc0ec963a5fc33637af,8d94f1357c00d7706c1f3d0bb568e054cef6aea1,"bpf: Plumb get_unmapped_area() callback into bpf_map_ops

Subsequent patches introduce bpf_arena that imposes special alignment
requirements on address selection.

Acked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/r/20240307031228.42896-4-alexei.starovoitov@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Plumbs get_unmapped_area() callback into bpf_map_ops to support special alignment requirements.,"get_unmapped_area, bpf_map_ops, alignment",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8d94f1357c00d7706c1f3d0bb568e054cef6aea1,8d94f1357c00d7706c1f3d0bb568e054cef6aea1,Alexei Starovoitov,ast@kernel.org,1709781144,Martin KaFai Lau,martin.lau@kernel.org,1709852328,862e04056270e16af686d28debe629be4daeba1b,88d1d4a7eebea2836859246d91fe9d141789dfc3,"bpf: Recognize '__map' suffix in kfunc arguments

Recognize 'void *p__map' kfunc argument as 'struct bpf_map *p__map'.
It allows kfunc to have 'void *' argument for maps"," since bpf progs
will call them as:
struct {
        __uint(type","[' BPF_MAP_TYPE_ARENA);\n\t...\n} arena SEC("".maps"");\n\nbpf_kfunc_with_map(... &arena ...);\n\nUnderneath libbpf will load CONST_PTR_TO_MAP into the register via ld_imm64\ninsn. If kfunc was defined with \'struct bpf_map *\' it would pass the\nverifier as well', ' but bpf prog would need to type cast the argument\n(void *)&arena', ' which is not clean.\n\nAcked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nLink: https://lore.kernel.org/r/20240307031228.42896-3-alexei.starovoitov@gmail.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",The commit allows kfunc arguments with a '__map' suffix to be recognized as 'struct bpf_map'.,"kfunc, argument, map",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
88d1d4a7eebea2836859246d91fe9d141789dfc3,88d1d4a7eebea2836859246d91fe9d141789dfc3,Alexei Starovoitov,ast@kernel.org,1709781143,Martin KaFai Lau,martin.lau@kernel.org,1709852328,265870b328e4ba8fd92373cca74fb1f12b849c84,e63985ecd22681c7f5975f2e8637187a326b6791,"bpf: Allow kfuncs return 'void *'

Recognize return of 'void *' from kfunc as returning unknown scalar.

Acked-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/r/20240307031228.42896-2-alexei.starovoitov@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,"The commit allows kfuncs to return 'void *', treating it as unknown scalar.","kfuncs, void, scalar",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
df4793505abd5df399bc6d9a4d8fe81761f557cd,df4793505abd5df399bc6d9a4d8fe81761f557cd,Linus Torvalds,torvalds@linux-foundation.org,1709832213,Linus Torvalds,torvalds@linux-foundation.org,1709832213,71bcf8836d374b96b163ae50d7dbd7976189acc1,67be068d31d423b857ffd8c34dbcc093f8dfff76 ba18deddd6d502da71fd6b6143c53042271b82bd,"Merge tag 'net-6.8-rc8' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Paolo Abeni:
 ""Including fixes from bpf"," ipsec and netfilter.

  No solution yet for the stmmac issue mentioned in the last PR","[' but it\n  proved to be a lockdep false positive', ' not a blocker.\n\n  Current release - regressions:\n\n   - dpll: move all dpll<>netdev helpers to dpll code', ' fix build\n     regression with old compilers\n\n  Current release - new code bugs:\n\n   - page_pool: fix netlink dump stop/resume\n\n  Previous releases - regressions:\n\n   - bpf: fix verifier to check bpf_func_state->callback_depth when\n     pruning states as otherwise unsafe programs could get accepted\n\n   - ipv6: avoid possible UAF in ip6_route_mpath_notify()\n\n   - ice: reconfig host after changing MSI-X on VF\n\n   - mlx5:\n       - e-switch', ' change flow rule destination checking\n       - add a memory barrier to prevent a possible null-ptr-deref\n       - switch to using _bh variant of of spinlock where needed\n\n  Previous releases - always broken:\n\n   - netfilter: nf_conntrack_h323: add protection for bmp length out of\n     range\n\n   - bpf: fix to zero-initialise xdp_rxq_info struct before running XDP\n     program in CPU map which led to random xdp_md fields\n\n   - xfrm: fix UDP encapsulation in TX packet offload\n\n   - netrom: fix data-races around sysctls\n\n   - ice:\n       - fix potential NULL pointer dereference in ice_bridge_setlink()\n       - fix uninitialized dplls mutex usage\n\n   - igc: avoid returning frame twice in XDP_REDIRECT\n\n   - i40e: disable NAPI right after disabling irqs when handling\n     xsk_pool\n\n   - geneve: make sure to pull inner header in geneve_rx()\n\n   - sparx5: fix use after free inside sparx5_del_mact_entry\n\n   - dsa: microchip: fix register write order in ksz8_ind_write8()\n\n  Misc:\n\n   - selftests: mptcp: fixes for diag.sh""\n\n* tag \'net-6.8-rc8\' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (63 commits)\n  net: pds_core: Fix possible double free in error handling path\n  netrom: Fix data-races around sysctl_net_busy_read\n  netrom: Fix a data-race around sysctl_netrom_link_fails_count\n  netrom: Fix a data-race around sysctl_netrom_routing_control\n  netrom: Fix a data-race around sysctl_netrom_transport_no_activity_timeout\n  netrom: Fix a data-race around sysctl_netrom_transport_requested_window_size\n  netrom: Fix a data-race around sysctl_netrom_transport_busy_delay\n  netrom: Fix a data-race around sysctl_netrom_transport_acknowledge_delay\n  netrom: Fix a data-race around sysctl_netrom_transport_maximum_tries\n  netrom: Fix a data-race around sysctl_netrom_transport_timeout\n  netrom: Fix data-races around sysctl_netrom_network_ttl_initialiser\n  netrom: Fix a data-race around sysctl_netrom_obsolescence_count_initialiser\n  netrom: Fix a data-race around sysctl_netrom_default_path_quality\n  netfilter: nf_conntrack_h323: Add protection for bmp length out of range\n  netfilter: nf_tables: mark set as dead when unbinding anonymous set with timeout\n  netfilter: nft_ct: fix l3num expectations with inet pseudo family\n  netfilter: nf_tables: reject constant set with timeout\n  netfilter: nf_tables: disallow anonymous set with timeout flag\n  net/rds: fix WARNING in rds_conn_connect_if_down\n  net: dsa: microchip: fix register write order in ksz8_ind_write8()\n  ...\n', '']",Merge networking fixes including bpf from net-6.8-rc8 by Paolo Abeni.,"networking,bpf,fixes",It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF maps,"['tracepoints like programs', ""It's not related to any of the above."", 'other']"
d3eee81fd6111eb404318ddbaded3f86c7f21d70,d3eee81fd6111eb404318ddbaded3f86c7f21d70,Jakub Kicinski,kuba@kernel.org,1709785261,Jakub Kicinski,kuba@kernel.org,1709785261,d4af1ea22ca7522e93c41a18e9b30ce5cd4c2c4e,c055fc00c07be1f0df7375ab0036cebd1106ed38 2487007aa3b9fafbd2cb14068f49791ce1d7ede5,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Daniel Borkmann says:

====================
pull-request: bpf 2024-03-06

We've added 5 non-merge commits during the last 1 day(s) which contain
a total of 5 files changed", 77 insertions(+),"[' 4 deletions(-).\n\nThe main changes are:\n\n1) Fix BPF verifier to check bpf_func_state->callback_depth when pruning\n   states as otherwise unsafe programs could get accepted', '\n   from Eduard Zingerman.\n\n2) Fix to zero-initialise xdp_rxq_info struct before running XDP program in\n   CPU map which led to random xdp_md fields', ' from Toke Høiland-Jørgensen.\n\n3) Fix bonding XDP feature flags calculation when bonding device has no\n   slave devices anymore', "" from Daniel Borkmann.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  cpumap: Zero-initialise xdp_rxq_info struct before running XDP program\n  selftests/bpf: Fix up xdp bonding test wrt feature flags\n  xdp"", ' bonding: Fix feature flags when there are no slave devs anymore\n  selftests/bpf: test case for callback_depth states pruning logic\n  bpf: check bpf_func_state->callback_depth when pruning states\n====================\n\nLink: https://lore.kernel.org/r/20240306220309.13534-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']","Merge tag 'for-netdev' with 5 non-merge commits affecting 5 files, totaling 77 insertions.","merge,netdev,commits",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e63985ecd22681c7f5975f2e8637187a326b6791,e63985ecd22681c7f5975f2e8637187a326b6791,Puranjay Mohan,puranjay12@gmail.com,1709485327,Andrii Nakryiko,andrii@kernel.org,1709767096,acb127a58be4cbad6faf591ede9e9aa00573d4bf,516fca5a7516cde7a9968f84179ed20ffb438885,bpf," riscv64/cfi: Support kCFI + BPF on riscv64

The riscv BPF JIT doesn't emit proper kCFI prologues for BPF programs
and struct_ops trampolines when CONFIG_CFI_CLANG is enabled.

This causes CFI failures when calling BPF programs and can even crash
the kernel due to invalid memory accesses.

Example crash:

root@rv-selftester:~/bpf# ./test_progs -a dummy_st_ops

 Unable to handle kernel paging request at virtual address ffffffff78204ffc
 Oops [#1]
 Modules linked in: bpf_testmod(OE) [....]
 CPU: 3 PID: 356 Comm: test_progs Tainted: P           OE      6.8.0-rc1 #1
 Hardware name: riscv-virtio","['qemu (DT)\n epc : bpf_struct_ops_test_run+0x28c/0x5fc\n  ra : bpf_struct_ops_test_run+0x26c/0x5fc\n epc : ffffffff82958010 ra : ffffffff82957ff0 sp : ff200000007abc80\n  gp : ffffffff868d6218 tp : ff6000008d87b840 t0 : 000000000000000f\n  t1 : 0000000000000000 t2 : 000000002005793e s0 : ff200000007abcf0\n  s1 : ff6000008a90fee0 a0 : 0000000000000000 a1 : 0000000000000000\n  a2 : 0000000000000000 a3 : 0000000000000000 a4 : 0000000000000000\n  a5 : ffffffff868dba26 a6 : 0000000000000001 a7 : 0000000052464e43\n  s2 : 00007ffffc0a95f0 s3 : ff6000008a90fe80 s4 : ff60000084c24c00\n  s5 : ffffffff78205000 s6 : ff60000088750648 s7 : ff20000000035008\n  s8 : fffffffffffffff4 s9 : ffffffff86200610 s10: 0000000000000000\n  s11: 0000000000000000 t3 : ffffffff8483dc30 t4 : ffffffff8483dc10\n  t5 : ffffffff8483dbf0 t6 : ffffffff8483dbd0\n status: 0000000200000120 badaddr: ffffffff78204ffc cause: 000000000000000d\n [<ffffffff82958010>] bpf_struct_ops_test_run+0x28c/0x5fc\n [<ffffffff805083ee>] bpf_prog_test_run+0x170/0x548\n [<ffffffff805029c8>] __sys_bpf+0x2d2/0x378\n [<ffffffff804ff570>] __riscv_sys_bpf+0x5c/0x120\n [<ffffffff8000e8fe>] syscall_handler+0x62/0xe4\n [<ffffffff83362df6>] do_trap_ecall_u+0xc6/0x27c\n [<ffffffff833822c4>] ret_from_exception+0x0/0x64\n Code: b603 0109 b683 0189 b703 0209 8493 0609 157d 8d65 (a303) ffca\n ---[ end trace 0000000000000000 ]---\n Kernel panic - not syncing: Fatal exception\n SMP: stopping secondary CPUs\n\nImplement proper kCFI prologues for the BPF programs and callbacks and\ndrop __nocfi for riscv64. Fix the trampoline generation code to emit kCFI\nprologue when a struct_ops trampoline is being prepared.\n\nSigned-off-by: Puranjay Mohan <puranjay12@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Björn Töpel <bjorn@kernel.org>\nLink: https://lore.kernel.org/bpf/20240303170207.82201-2-puranjay12@gmail.com\n', '']",Fix riscv BPF JIT to emit correct kCFI prologues for BPF programs with CONFIG_CFI_CLANG enabled.,"riscv, JIT, kCFI",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
516fca5a7516cde7a9968f84179ed20ffb438885,516fca5a7516cde7a9968f84179ed20ffb438885,Andrii Nakryiko,andrii@kernel.org,1709752802,Andrii Nakryiko,andrii@kernel.org,1709767096,06fb0432340f8ae5ca35102e7250a394274051c4,0f79bb8987a5c483362dc12d58b221a1a1c45578 5208930a909ad618363471e2872d79abef103626,"Merge branch 'libbpf-type-suffixes-and-autocreate-flag-for-struct_ops-maps'

Eduard Zingerman says:

====================
libbpf: type suffixes and autocreate flag for struct_ops maps

Tweak struct_ops related APIs to allow the following features:
- specify version suffixes for stuct_ops map types;
- share same BPF program between several map definitions with
  different local BTF types"," assuming only maps with same
  kernel BTF type would be selected for load;
- toggle autocreate flag for struct_ops maps;
- automatically toggle autoload for struct_ops programs referenced
  from struct_ops maps","[' depending on autocreate status of the\n  corresponding map;\n- use SEC(""?.struct_ops"") and SEC(""?.struct_ops.link"")\n  to define struct_ops maps with autocreate == false after object open.\n\nThis would allow loading programs like below:\n\n    SEC(""struct_ops/foo"") int BPF_PROG(foo) { ... }\n    SEC(""struct_ops/bar"") int BPF_PROG(bar) { ... }\n\n    struct bpf_testmod_ops___v1 {\n        int (*foo)(void);\n    };\n\n    struct bpf_testmod_ops___v2 {\n        int (*foo)(void);\n        int (*bar)(void);\n    };\n\n    /* Assume kernel type name to be \'test_ops\' */\n    SEC("".struct_ops.link"")\n    struct test_ops___v1 map_v1 = {\n        /* Program \'foo\' shared by maps with\n         * different local BTF type\n         */\n        .foo = (void *)foo\n    };\n\n    SEC("".struct_ops.link"")\n    struct test_ops___v2 map_v2 = {\n        .foo = (void *)foo', '\n        .bar = (void *)bar\n    };\n\nAssuming the following tweaks are done before loading:\n\n    /* to load v1 */\n    bpf_map__set_autocreate(skel->maps.map_v1', ' true);\n    bpf_map__set_autocreate(skel->maps.map_v2', ' false);\n\n    /* to load v2 */\n    bpf_map__set_autocreate(skel->maps.map_v1', ' false);\n    bpf_map__set_autocreate(skel->maps.map_v2', ' true);\n\nPatch #8 ties autocreate and autoload flags for struct_ops maps and\nprograms.\n\nChangelog:\n- v3 [3] -> v4:\n  - changes for multiple styling suggestions from Andrii;\n  - patch #5: libbpf log capture now happens for LIBBPF_INFO and\n    LIBBPF_WARN messages and does not depend on verbosity flags\n    (Andrii);\n  - patch #6: fixed runtime crash caused by conflict with newly added\n    test case struct_ops_multi_pages;\n  - patch #7: fixed free of possibly uninitialized pointer (Daniel)\n  - patch #8: simpler algorithm to detect which programs to autoload\n    (Andrii);\n  - patch #9: added assertions for autoload flag after object load\n    (Andrii);\n  - patch #12: DATASEC name rewrite in libbpf is now done inplace', ' no\n    new strings added to BTF (Andrii);\n  - patch #14: allow any printable characters in DATASEC names when\n    kernel validates BTF (Andrii)\n- v2 [2] -> v3:\n  - moved patch #8 logic to be fully done on load\n    (requested by Andrii in offlist discussion);\n  - in patch #9 added test case for shadow vars and\n    autocreate/autoload interaction.\n- v1 [1] -> v2:\n  - fixed memory leak in patch #1 (Kui-Feng);\n  - improved error messages in patch #2 (Martin', ' Andrii);\n  - in bad_struct_ops selftest from patch #6 added .test_2\n    map member setup (David);\n  - added utility functions to capture libbpf log from selftests (David)\n  - in selftests replaced usage of ...__open_and_load by separate\n    calls to ..._open() and ..._load() (Andrii);\n  - removed serial_... in selftest definitions (Andrii);\n  - improved comments in selftest struct_ops_autocreate\n    from patch #7 (David);\n  - removed autoload toggling logic incompatible with shadow variables\n    from bpf_map__set_autocreate()', ' instead struct_ops programs\n    autoload property is computed at struct_ops maps load phase', '\n    see patch #8 (Kui-Feng', ' Martin', ' Andrii);\n  - added support for SEC(""?.struct_ops"") and SEC(""?.struct_ops.link"")\n    (Andrii).\n\n[1] https://lore.kernel.org/bpf/20240227204556.17524-1-eddyz87@gmail.com/\n[2] https://lore.kernel.org/bpf/20240302011920.15302-1-eddyz87@gmail.com/\n[3] https://lore.kernel.org/bpf/20240304225156.24765-1-eddyz87@gmail.com/\n====================\n\nLink: https://lore.kernel.org/r/20240306104529.6453-1-eddyz87@gmail.com\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n', '']","Enhance struct_ops maps in libbpf with type suffixes, autocreate flag, and autoload toggle features.","struct_ops, type suffixes, autocreate",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5208930a909ad618363471e2872d79abef103626,5208930a909ad618363471e2872d79abef103626,Eduard Zingerman,eddyz87@gmail.com,1709721929,Andrii Nakryiko,andrii@kernel.org,1709767096,06fb0432340f8ae5ca35102e7250a394274051c4,bd70a8fb7ca4fcb078086f4d96b048aaf1aa4786,"selftests/bpf: Test cases for '?' in BTF names

Two test cases to verify that '?' and other printable characters are
allowed in BTF DATASEC names:
- DATASEC with name ""?.foo bar:buz"" should be accepted;
- type with name ""?foo"" should be rejected.

Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240306104529.6453-16-eddyz87@gmail.com
",,Add test cases to verify BTF names with '?' and other characters in eBPF.,"test cases,BTF names,selftests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
bd70a8fb7ca4fcb078086f4d96b048aaf1aa4786,bd70a8fb7ca4fcb078086f4d96b048aaf1aa4786,Eduard Zingerman,eddyz87@gmail.com,1709721928,Andrii Nakryiko,andrii@kernel.org,1709767096,5e508f79182e882a923a5f2986a0e9fcaa53334f,733e5e875444fc5afc9b72714f0ecaca629ccf8a,"bpf: Allow all printable characters in BTF DATASEC names

The intent is to allow libbpf to use SEC(""?.struct_ops"") to identify
struct_ops maps that are optional"," e.g. like in the following BPF code:

    SEC(""?.struct_ops"")
    struct test_ops optional_map = { ... };

Which yields the following BTF:

    ...
    [13] DATASEC '?.struct_ops' size=0 vlen=...
    ...

To load such BTF libbpf rewrites DATASEC name before load.
After this patch the rewrite won't be necessary.

Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240306104529.6453-15-eddyz87@gmail.com
",[''],The commit allows all printable characters in BTF DATASEC names for struct_ops maps.,"BTF, struct_ops, libbpf",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"[""It's not related to any of the above.""]"
733e5e875444fc5afc9b72714f0ecaca629ccf8a,733e5e875444fc5afc9b72714f0ecaca629ccf8a,Eduard Zingerman,eddyz87@gmail.com,1709721927,Andrii Nakryiko,andrii@kernel.org,1709767096,2024cbc2e714c16921db1db347d02f151bcd2ca4,6ebaa3fb88bbe4c33a0e01ce27007e1dd4fd133c,"selftests/bpf: Test case for SEC(""?.struct_ops"")

Check that ""?.struct_ops"" and ""?.struct_ops.link"" section names define
struct_ops maps with autocreate == false after open.

Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240306104529.6453-14-eddyz87@gmail.com
",,Add test case for struct_ops map sections with autocreate set to false.,selftests struct_ops autocreate,It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6ebaa3fb88bbe4c33a0e01ce27007e1dd4fd133c,6ebaa3fb88bbe4c33a0e01ce27007e1dd4fd133c,Eduard Zingerman,eddyz87@gmail.com,1709721926,Andrii Nakryiko,andrii@kernel.org,1709767096,a57dae4f7884140f99d6b78f9a461b2b16f9f30d,5ad0ecbe056a4ea5ffaa73e58503a2f87b119a59,"libbpf: Rewrite btf datasec names starting from '?'

Optional struct_ops maps are defined using question mark at the start
of the section name"," e.g.:

    SEC(""?.struct_ops"")
    struct test_ops optional_map = { ... };

This commit teaches libbpf to detect if kernel allows '?' prefix
in datasec names","["" and if it doesn't then to rewrite such names\nby replacing '?' with '_'"", ' e.g.:\n\n    DATASEC ?.struct_ops -> DATASEC _.struct_ops\n\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240306104529.6453-13-eddyz87@gmail.com\n', '']",This commit updates libbpf to support datasec names starting with '?' for optional struct_ops maps.,"libbpf, datasec, struct_ops",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,['other']
5ad0ecbe056a4ea5ffaa73e58503a2f87b119a59,5ad0ecbe056a4ea5ffaa73e58503a2f87b119a59,Eduard Zingerman,eddyz87@gmail.com,1709721925,Andrii Nakryiko,andrii@kernel.org,1709767096,0ec07c636e02a90443c866021c0ebfa1e457c9ef,240bf8a5162e8c43cf368909582a01082d494d79,"libbpf: Struct_ops in SEC(""?.struct_ops"") / SEC(""?.struct_ops.link"")

Allow using two new section names for struct_ops maps:
- SEC(""?.struct_ops"")
- SEC(""?.struct_ops.link"")

To specify maps that have bpf_map->autocreate == false after open.

Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240306104529.6453-12-eddyz87@gmail.com
",,This commit introduces new section names for struct_ops maps in libbpf to specify autocreate flag as false.,"struct_ops,section names,libbpf",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
240bf8a5162e8c43cf368909582a01082d494d79,240bf8a5162e8c43cf368909582a01082d494d79,Eduard Zingerman,eddyz87@gmail.com,1709721924,Andrii Nakryiko,andrii@kernel.org,1709767095,cdaac97bf8b0e3bc431f47562503e871a1c88500,651d49f15b2a84b3bcfe950fa99c3672b9619dbd,"libbpf: Replace elf_state->st_ops_* fields with SEC_ST_OPS sec_type

The next patch would add two new section names for struct_ops maps.
To make working with multiple struct_ops sections more convenient:
- remove fields like elf_state->st_ops_{shndx","link_shndx};
- mark section descriptions hosting struct_ops as
  elf_sec_desc->sec_type == SEC_ST_OPS;

After these changes struct_ops sections could be processed uniformly
by iterating bpf_object->efile.secs entries.

Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240306104529.6453-11-eddyz87@gmail.com
",[''],This commit refactors libbpf to enhance handling of struct_ops sections by consolidating section descriptors.,"libbpf, struct_ops, elf_state",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
651d49f15b2a84b3bcfe950fa99c3672b9619dbd,651d49f15b2a84b3bcfe950fa99c3672b9619dbd,Eduard Zingerman,eddyz87@gmail.com,1709721923,Andrii Nakryiko,andrii@kernel.org,1709767095,eea5bdf4b6fe6d7b31445339fba8e799bf8ad623,fe9d049c3da06373a1a35914b7f695509e4cb1fe,"selftests/bpf: Verify struct_ops autoload/autocreate sync

Check that autocreate flags of struct_ops map cause autoload of
struct_ops corresponding programs:
- when struct_ops program is referenced only from a map for which
  autocreate is set to false"," that program should not be loaded;
- when struct_ops program with autoload == false is set to be used
  from a map with autocreate == true using shadow var","['\n  that program should be loaded;\n- when struct_ops program is not referenced from any map object load\n  should fail.\n\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240306104529.6453-10-eddyz87@gmail.com\n', '']",Enhances selftests to verify struct_ops map autocreate and autoload synchronization behavior.,"selftests,bpf,struct_ops",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fe9d049c3da06373a1a35914b7f695509e4cb1fe,fe9d049c3da06373a1a35914b7f695509e4cb1fe,Eduard Zingerman,eddyz87@gmail.com,1709721922,Andrii Nakryiko,andrii@kernel.org,1709767095,6c12581c804da865f4d0f7bf2b224e1d0543f90a,1863acccdf936c6917398165ca97e252d02fa6dd,"libbpf: Sync progs autoload with maps autocreate for struct_ops maps

Automatically select which struct_ops programs to load depending on
which struct_ops maps are selected for automatic creation.
E.g. for the BPF code below:

    SEC(""struct_ops/test_1"") int BPF_PROG(foo) { ... }
    SEC(""struct_ops/test_2"") int BPF_PROG(bar) { ... }

    SEC("".struct_ops.link"")
    struct test_ops___v1 A = {
        .foo = (void *)foo
    };

    SEC("".struct_ops.link"")
    struct test_ops___v2 B = {
        .foo = (void *)foo","
        .bar = (void *)bar","['\n    };\n\nAnd the following libbpf API calls:\n\n    bpf_map__set_autocreate(skel->maps.A', ' true);\n    bpf_map__set_autocreate(skel->maps.B', "" false);\n\nThe autoload would be enabled for program 'foo' and disabled for\nprogram 'bar'.\n\nDuring load"", ' for each struct_ops program P', "" referenced from some\nstruct_ops map M:\n- set P.autoload = true if M.autocreate is true for some M;\n- set P.autoload = false if M.autocreate is false for all M;\n- don't change P.autoload"", ' if P is not referenced from any map.\n\nDo this after bpf_object__init_kern_struct_ops_maps()\nto make sure that shadow vars assignment is done.\n\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240306104529.6453-9-eddyz87@gmail.com\n', '']",Sync program autoload with automatic map creation for struct_ops maps in libbpf.,"libbpf, struct_ops, autoload",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1863acccdf936c6917398165ca97e252d02fa6dd,1863acccdf936c6917398165ca97e252d02fa6dd,Eduard Zingerman,eddyz87@gmail.com,1709721921,Andrii Nakryiko,andrii@kernel.org,1709767095,38f5eee7c613edbace508dea7f294c3357faf3d2,c1b93c07b3ac3204c6a42a7f7b6217e36f44df4f,"selftests/bpf: Test autocreate behavior for struct_ops maps

Check that bpf_map__set_autocreate() can be used to disable automatic
creation for struct_ops maps.

Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240306104529.6453-8-eddyz87@gmail.com
",,Test added for autocreate behavior of struct_ops maps in selftests/bpf.,"selftests,bpf,struct_ops",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c1b93c07b3ac3204c6a42a7f7b6217e36f44df4f,c1b93c07b3ac3204c6a42a7f7b6217e36f44df4f,Eduard Zingerman,eddyz87@gmail.com,1709721920,Andrii Nakryiko,andrii@kernel.org,1709767095,bc5013bfc1d6b5f26f1a7cf9796c0f11b7639022,c8617e8bcf8d1ef357fadf5c96bd86b9952fb93f,"selftests/bpf: Bad_struct_ops test

When loading struct_ops programs kernel requires BTF id of the
struct_ops type and member index for attachment point inside that
type. This makes impossible to use same BPF program in several
struct_ops maps that have different struct_ops type.
Check if libbpf rejects such BPF objects files.

Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240306104529.6453-7-eddyz87@gmail.com
",,Adds a selftest in BPF to verify libbpf rejection of BPF objects with mismatched struct_ops types and indices.,"selftests, struct_ops, libbpf",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c8617e8bcf8d1ef357fadf5c96bd86b9952fb93f,c8617e8bcf8d1ef357fadf5c96bd86b9952fb93f,Eduard Zingerman,eddyz87@gmail.com,1709721919,Andrii Nakryiko,andrii@kernel.org,1709767095,98d73393511d70d2f7712f98ae0ace043330d0bc,5bab7a277ca8d4ef377a50a6678577b5bd7f74d8,"selftests/bpf: Utility functions to capture libbpf log in test_progs

Several test_progs tests already capture libbpf log in order to check
for some expected output", e.g bpf_tcp_ca.c,"[' kfunc_dynptr_param.c', '\nlog_buf.c and a few others.\n\nThis commit provides a', ' hopefully', ' simple API to capture libbpf log\nw/o necessity to define new print callback in each test:\n\n    /* Creates a global memstream capturing INFO and WARN level output\n     * passed to libbpf_print_fn.\n     * Returns 0 on success', ' negative value on failure.\n     * On failure the description is printed using PRINT_FAIL and\n     * current test case is marked as fail.\n     */\n    int start_libbpf_log_capture(void)\n\n    /* Destroys global memstream created by start_libbpf_log_capture().\n     * Returns a pointer to captured data which has to be freed.\n     * Returned buffer is null terminated.\n     */\n    char *stop_libbpf_log_capture(void)\n\nThe intended usage is as follows:\n\n    if (start_libbpf_log_capture())\n            return;\n    use_libbpf();\n    char *log = stop_libbpf_log_capture();\n    ASSERT_HAS_SUBSTR(log', ' ""... expected ...""', ' ""expected some message"");\n    free(log);\n\nAs a safety measure', ' free(start_libbpf_log_capture()) is invoked in the\nepilogue of the test_progs.c:run_one_test().\n\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240306104529.6453-6-eddyz87@gmail.com\n', '']",Add utility functions for capturing libbpf log in test_progs selftests.,"utility functions, libbpf log, test_progs",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5bab7a277ca8d4ef377a50a6678577b5bd7f74d8,5bab7a277ca8d4ef377a50a6678577b5bd7f74d8,Eduard Zingerman,eddyz87@gmail.com,1709721918,Andrii Nakryiko,andrii@kernel.org,1709767095,1548d99624590adc3fb77a35942e00b65577a1c1,8db052615a9780b45e26d6afabc7abefe1ba20ac,"selftests/bpf: Test struct_ops map definition with type suffix

Extend struct_ops_module test case to check if it is possible to use
'___' suffixes for struct_ops type specification.

Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: David Vernet <void@manifault.com>
Link: https://lore.kernel.org/bpf/20240306104529.6453-5-eddyz87@gmail.com
",,Extend struct_ops_module test case to verify struct_ops type specification with '___' suffixes.,"selftests,bpf,struct_ops",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8db052615a9780b45e26d6afabc7abefe1ba20ac,8db052615a9780b45e26d6afabc7abefe1ba20ac,Eduard Zingerman,eddyz87@gmail.com,1709721917,Andrii Nakryiko,andrii@kernel.org,1709767095,0be700562e5dd26252c1f41e1d3dbc45445dec06,d9ab2f76ef5abb76190ffb42d83bdc6caede807e,"libbpf: Honor autocreate flag for struct_ops maps

Skip load steps for struct_ops maps not marked for automatic creation.
This should allow to load bpf object in situations like below:

    SEC(""struct_ops/foo"") int BPF_PROG(foo) { ... }
    SEC(""struct_ops/bar"") int BPF_PROG(bar) { ... }

    struct test_ops___v1 {
    	int (*foo)(void);
    };

    struct test_ops___v2 {
    	int (*foo)(void);
    	int (*does_not_exist)(void);
    };

    SEC("".struct_ops.link"")
    struct test_ops___v1 map_for_old = {
    	.test_1 = (void *)foo
    };

    SEC("".struct_ops.link"")
    struct test_ops___v2 map_for_new = {
    	.test_1 = (void *)foo","
    	.does_not_exist = (void *)bar
    };

Suppose program is loaded on old kernel that does not have definition
for 'does_not_exist' struct_ops member. After this commit it would be
possible to load such object file after the following tweaks:

    bpf_program__set_autoload(skel->progs.bar","[' false);\n    bpf_map__set_autocreate(skel->maps.map_for_new', ' false);\n\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: David Vernet <void@manifault.com>\nLink: https://lore.kernel.org/bpf/20240306104529.6453-4-eddyz87@gmail.com\n', '']",Skip loading steps for struct_ops maps not marked for automatic creation in libbpf.,"libbpf,struct_ops,autocreate",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d9ab2f76ef5abb76190ffb42d83bdc6caede807e,d9ab2f76ef5abb76190ffb42d83bdc6caede807e,Eduard Zingerman,eddyz87@gmail.com,1709721916,Andrii Nakryiko,andrii@kernel.org,1709767095,ea29a8f148822b4c4874a56cd456bd2435f81980,a2a5172cf1eb39472bd2038079f65c6f676906a5,libbpf: Tie struct_ops programs to kernel BTF ids," not to local ids

Enforce the following existing limitation on struct_ops programs based
on kernel BTF id instead of program-local BTF id:

    struct_ops BPF prog can be re-used between multiple .struct_ops &
    .struct_ops.link as long as it's the same struct_ops struct
    definition and the same function pointer field

This allows reusing same BPF program for versioned struct_ops map
definitions","[' e.g.:\n\n    SEC(""struct_ops/test"")\n    int BPF_PROG(foo) { ... }\n\n    struct some_ops___v1 { int (*test)(void); };\n    struct some_ops___v2 { int (*test)(void); };\n\n    SEC("".struct_ops.link"") struct some_ops___v1 a = { .test = foo }\n    SEC("".struct_ops.link"") struct some_ops___v2 b = { .test = foo }\n\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240306104529.6453-3-eddyz87@gmail.com\n', '']",The commit ties struct_ops programs to kernel BTF ids for reuse across multiple struct_ops definitions.,"struct_ops,kernel BTF,reuse",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a2a5172cf1eb39472bd2038079f65c6f676906a5,a2a5172cf1eb39472bd2038079f65c6f676906a5,Eduard Zingerman,eddyz87@gmail.com,1709721915,Andrii Nakryiko,andrii@kernel.org,1709767095,8fa10eaa502c527a8572b6c89958e9e06d1fd0e9,0f79bb8987a5c483362dc12d58b221a1a1c45578,"libbpf: Allow version suffixes (___smth) for struct_ops types

E.g. allow the following struct_ops definitions:

    struct bpf_testmod_ops___v1 { int (*test)(void); };
    struct bpf_testmod_ops___v2 { int (*test)(void); };

    SEC("".struct_ops.link"")
    struct bpf_testmod_ops___v1 a = { .test = ... }
    SEC("".struct_ops.link"")
    struct bpf_testmod_ops___v2 b = { .test = ... }

Where both bpf_testmod_ops__v1 and bpf_testmod_ops__v2 would be
resolved as 'struct bpf_testmod_ops' from kernel BTF.

Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: David Vernet <void@manifault.com>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240306104529.6453-2-eddyz87@gmail.com
",,Enable version suffixes for struct_ops types in the libbpf library to support multiple versions.,"libbpf,struct_ops,BTF",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0f79bb8987a5c483362dc12d58b221a1a1c45578,0f79bb8987a5c483362dc12d58b221a1a1c45578,Andrii Nakryiko,andrii@kernel.org,1709750478,Andrii Nakryiko,andrii@kernel.org,1709767094,cd7ae2ef290324dcc66110f84aec4ad01fd94a85,9a9d1d36050e486822dc54990c896761b04e7446 0c8bbf990bddef1a4f32889b18a4a016d9bd2cfd,"Merge branch 'bpf-introduce-may_goto-and-cond_break'

Alexei Starovoitov says:

====================
bpf: Introduce may_goto and cond_break

From: Alexei Starovoitov <ast@kernel.org>

v5 -> v6:
- Rename BPF_JMA to BPF_JCOND
- Addressed Andrii's review comments

v4 -> v5:
- rewrote patch 1 to avoid fake may_goto_reg and use 'u32 may_goto_cnt' instead.
  This way may_goto handling is similar to bpf_loop() processing.
- fixed bug in patch 2 that RANGE_WITHIN should not use
  rold->type == NOT_INIT as a safe signal.
- patch 3 fixed negative offset computation in cond_break macro
- using bpf_arena and cond_break recompiled lib/glob.c as bpf prog
  and it works! It will be added as a selftest to arena series.

v3 -> v4:
- fix drained issue reported by John.
  may_goto insn could be implemented with sticky state (once
  reaches 0 it stays 0)"," but the verifier shouldn't assume that.
  It has to explore both branches.
  Arguably drained iterator state shouldn't be there at all.
  bpf_iter_css_next() is not sticky. Can be fixed","["" but auditing all\n  iterators for stickiness. That's an orthogonal discussion.\n- explained JMA name reasons in patch 1\n- fixed test_progs-no_alu32 issue and added another test\n\nv2 -> v3: Major change\n- drop bpf_can_loop() kfunc and introduce may_goto instruction instead\n  kfunc is a function call while may_goto doesn't consume any registers\n  and LLVM can produce much better code due to less register pressure.\n- instead of counting from zero to BPF_MAX_LOOPS start from it instead\n  and break out of the loop when count reaches zero\n- use may_goto instruction in cond_break macro\n- recognize that 'exact' state comparison doesn't need to be truly exact.\n  regsafe() should ignore precision and liveness marks"", ' but range_within\n  logic is safe to use while evaluating open coded iterators.\n====================\n\nLink: https://lore.kernel.org/r/20240306031929.42666-1-alexei.starovoitov@gmail.com\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n', '']",The commit introduces may_goto and cond_break constructs in the eBPF verifier.,"may_goto, cond_break, eBPF",It's a new feature.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0c8bbf990bddef1a4f32889b18a4a016d9bd2cfd,0c8bbf990bddef1a4f32889b18a4a016d9bd2cfd,Alexei Starovoitov,ast@kernel.org,1709695169,Andrii Nakryiko,andrii@kernel.org,1709767090,cd7ae2ef290324dcc66110f84aec4ad01fd94a85,06375801525717173aee790310b7d959bb77879b,"selftests/bpf: Test may_goto

Add tests for may_goto instruction via cond_break macro.

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Tested-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/bpf/20240306031929.42666-5-alexei.starovoitov@gmail.com
",,Add selftests for the may_goto instruction using the cond_break macro in BPF.,"selftests,BPF,may_goto",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
06375801525717173aee790310b7d959bb77879b,06375801525717173aee790310b7d959bb77879b,Alexei Starovoitov,ast@kernel.org,1709695168,Andrii Nakryiko,andrii@kernel.org,1709767084,56f571c37744c55fbab9eb4952875c1725e968e7,4f81c16f50baf6d5d8bfa6eef3250dcfa22cbc08,"bpf: Add cond_break macro

Use may_goto instruction to implement cond_break macro.
Ideally the macro should be written as:
  asm volatile goto("".byte 0xe5;
                     .byte 0;
                     .short %l[l_break] ...
                     .long 0;
but LLVM doesn't recognize fixup of 2 byte PC relative yet.
Hence use
  asm volatile goto("".byte 0xe5;
                     .byte 0;
                     .long %l[l_break] ...
                     .short 0;
that produces correct asm on little endian.

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Tested-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/bpf/20240306031929.42666-4-alexei.starovoitov@gmail.com
",,Add cond_break macro using may_goto instruction for better assembly compatibility with little endian systems.,"cond_break, macro, may_goto",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4f81c16f50baf6d5d8bfa6eef3250dcfa22cbc08,4f81c16f50baf6d5d8bfa6eef3250dcfa22cbc08,Alexei Starovoitov,ast@kernel.org,1709695167,Andrii Nakryiko,andrii@kernel.org,1709767080,9d0f0fd22a3c61db123c1e02ca4874ec34ad8f96,011832b97b311bb9e3c27945bc0d1089a14209c9,"bpf: Recognize that two registers are safe when their ranges match

When open code iterators"," bpf_loop or may_goto are used the following two
states are equivalent and safe to prune the search:

cur state: fp-8_w=scalar(id=3","['smin=umin=smin32=umin32=2', 'smax=umax=smax32=umax32=11', 'var_off=(0x0; 0xf))\nold state: fp-8_rw=scalar(id=2', 'smin=umin=smin32=umin32=1', 'smax=umax=smax32=umax32=11', 'var_off=(0x0; 0xf))\n\nIn other words ""exact"" state match should ignore liveness and precision\nmarks', "" since open coded iterator logic didn't complete their propagation"", '\nreg_old->type == NOT_INIT && reg_cur->type != NOT_INIT is also not safe to\nprune while looping', ' but range_within logic that applies to scalars', '\nptr_to_mem', ' map_value', ' pkt_ptr is safe to rely on.\n\nAvoid doing such comparison when regular infinite loop detection logic is\nused', ' otherwise bounded loop logic will declare such ""infinite loop"" as\nfalse positive. Such example is in progs/verifier_loops1.c\nnot_an_inifinite_loop().\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nTested-by: John Fastabend <john.fastabend@gmail.com>\nLink: https://lore.kernel.org/bpf/20240306031929.42666-3-alexei.starovoitov@gmail.com\n', '']",The commit optimizes register safety recognition by matching their ranges for bpf open code iterators.,"registers,safe,ranges",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
011832b97b311bb9e3c27945bc0d1089a14209c9,011832b97b311bb9e3c27945bc0d1089a14209c9,Alexei Starovoitov,ast@kernel.org,1709695166,Andrii Nakryiko,andrii@kernel.org,1709767051,895a1b974a1b6edcd101286dcf3436fffad046b2,9a9d1d36050e486822dc54990c896761b04e7446,"bpf: Introduce may_goto instruction

Introduce may_goto instruction that from the verifier pov is similar to
open coded iterators bpf_for()/bpf_repeat() and bpf_loop() helper"," but it
doesn't iterate any objects.
In assembly 'may_goto' is a nop most of the time until bpf runtime has to
terminate the program for whatever reason. In the current implementation
may_goto has a hidden counter","[' but other mechanisms can be used.\nFor programs written in C the later patch introduces \'cond_break\' macro\nthat combines \'may_goto\' with \'break\' statement and has similar semantics:\ncond_break is a nop until bpf runtime has to break out of this loop.\nIt can be used in any normal ""for"" or ""while"" loop', ' like\n\n  for (i = zero; i < cnt; cond_break', ' i++) {\n\nThe verifier recognizes that may_goto is used in the program', ' reserves\nadditional 8 bytes of stack', ' initializes them in subprog prologue', ' and\nreplaces may_goto instruction with:\naux_reg = *(u64 *)(fp - 40)\nif aux_reg == 0 goto pc+off\naux_reg -= 1\n*(u64 *)(fp - 40) = aux_reg\n\nmay_goto instruction can be used by LLVM to implement __builtin_memcpy', ""\n__builtin_strcmp.\n\nmay_goto is not a full substitute for bpf_for() macro.\nbpf_for() doesn't have induction variable that verifiers sees"", ""\nso 'i' in bpf_for(i"", ' 0', ' 100) is seen as imprecise and bounded.\n\nBut when the code is written as:\nfor (i = 0; i < 100; cond_break', "" i++)\nthe verifier see 'i' as precise constant zero"", ""\nhence cond_break (aka may_goto) doesn't help to converge the loop.\nA static or global variable can be used as a workaround:\nstatic int zero = 0;\nfor (i = zero; i < 100; cond_break"", "" i++) // works!\n\nmay_goto works well with arena pointers that don't need to be bounds\nchecked on access. Load/store from arena returns imprecise unbounded\nscalar and loops with may_goto pass the verifier.\n\nReserve new opcode BPF_JMP | BPF_JCOND for may_goto insn.\nJCOND stands for conditional pseudo jump.\nSince goto_or_nop insn was proposed"", ' it may use the same opcode.\nmay_goto vs goto_or_nop can be distinguished by src_reg:\ncode = BPF_JMP | BPF_JCOND\nsrc_reg = 0 - may_goto\nsrc_reg = 1 - goto_or_nop\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nTested-by: John Fastabend <john.fastabend@gmail.com>\nLink: https://lore.kernel.org/bpf/20240306031929.42666-2-alexei.starovoitov@gmail.com\n', '']",Introduce may_goto instruction that acts as a conditional program termination point in BPF verifier.,"may_goto,instruction,verifier",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e6f798225a31485e47a6e4f6aa07ee9fdf80c2cb,e6f798225a31485e47a6e4f6aa07ee9fdf80c2cb,Alexei Starovoitov,ast@kernel.org,1709607916,Andrii Nakryiko,andrii@kernel.org,1709767042,97b3ec52194dd1296d16edda6288460a32cd2ef8,3e49a866c9dcbd8173e4f3e491293619a9e81fa4,"mm: Introduce VM_SPARSE kind and vm_area_[un]map_pages().

vmap/vmalloc APIs are used to map a set of pages into contiguous kernel
virtual space.

get_vm_area() with appropriate flag is used to request an area of kernel
address range. It's used for vmalloc", vmap,"[' ioremap', ' xen use cases.\n- vmalloc use case dominates the usage. Such vm areas have VM_ALLOC flag.\n- the areas created by vmap() function should be tagged with VM_MAP.\n- ioremap areas are tagged with VM_IOREMAP.\n\nBPF would like to extend the vmap API to implement a lazily-populated\nsparse', ' yet contiguous kernel virtual space. Introduce VM_SPARSE flag\nand vm_area_map_pages(area', ' start_addr', ' count', ' pages) API to map a set\nof pages within a given area.\nIt has the same sanity checks as vmap() does.\nIt also checks that get_vm_area() was created with VM_SPARSE flag\nwhich identifies such areas in /proc/vmallocinfo\nand returns zero pages on read through /proc/kcore.\n\nThe next commits will introduce bpf_arena which is a sparsely populated\nshared memory region between bpf program and user space process. It will\nmap privately-managed pages into a sparse vm area with the following steps:\n\n  // request virtual memory region during bpf prog verification\n  area = get_vm_area(area_size', ' VM_SPARSE);\n\n  // on demand\n  vm_area_map_pages(area', ' kaddr', ' kend', ' pages);\n  vm_area_unmap_pages(area', ' kaddr', ' kend);\n\n  // after bpf program is detached and unloaded\n  free_vm_area(area);\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nReviewed-by: Christoph Hellwig <hch@lst.de>\nReviewed-by: Pasha Tatashin <pasha.tatashin@soleen.com>\nLink: https://lore.kernel.org/bpf/20240305030516.41519-3-alexei.starovoitov@gmail.com\n', '']",Introduces VM_SPARSE kind and vm_area_[un]map_pages() functionality to handle kernel virtual space mapping.,"VM_SPARSE, vmap, vmalloc",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
3e49a866c9dcbd8173e4f3e491293619a9e81fa4,3e49a866c9dcbd8173e4f3e491293619a9e81fa4,Alexei Starovoitov,ast@kernel.org,1709607915,Andrii Nakryiko,andrii@kernel.org,1709749144,5ed90ad44657e757261e3c827c3a87dd67df8b3e,8f50d5c423551bfa259af792647a2f4799780ac5,"mm: Enforce VM_IOREMAP flag and range in ioremap_page_range.

There are various users of get_vm_area() + ioremap_page_range() APIs.
Enforce that get_vm_area() was requested as VM_IOREMAP type and range
passed to ioremap_page_range() matches created vm_area to avoid
accidentally ioremap-ing into wrong address range.

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Reviewed-by: Christoph Hellwig <hch@lst.de>
Link: https://lore.kernel.org/bpf/20240305030516.41519-2-alexei.starovoitov@gmail.com
",,Enforce VM_IOREMAP flag and range in ioremap_page_range to prevent incorrect ioremap usage.,"VM_IOREMAP,enforce,ioremap",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['other']
2487007aa3b9fafbd2cb14068f49791ce1d7ede5,2487007aa3b9fafbd2cb14068f49791ce1d7ede5,Toke Høiland-Jørgensen,toke@redhat.com,1709674292,Martin KaFai Lau,martin.lau@kernel.org,1709686133,b3ecf09e17cc47833c8e8a196655e3924bbd911c,0bfc0336e1348883fdab4689f0c8c56458f36dd8,"cpumap: Zero-initialise xdp_rxq_info struct before running XDP program

When running an XDP program that is attached to a cpumap entry"," we don't
initialise the xdp_rxq_info data structure being used in the xdp_buff
that backs the XDP program invocation. Tobias noticed that this leads to
random values being returned as the xdp_md->rx_queue_index value for XDP
programs running in a cpumap.

This means we're basically returning the contents of the uninitialised
memory","[' which is bad. Fix this by zero-initialising the rxq data\nstructure before running the XDP program.\n\nFixes: 9216477449f3 (""bpf: cpumap: Add the possibility to attach an eBPF program to cpumap"")\nReported-by: Tobias Böhm <tobias@aibor.de>\nSigned-off-by: Toke Høiland-Jørgensen <toke@redhat.com>\nLink: https://lore.kernel.org/r/20240305213132.11955-1-toke@redhat.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",This commit zero-initializes the xdp_rxq_info structure to prevent random values in xdp_md->rx_queue_index for cpumap entries.,"zero-initialize,xdp_rxq_info,cpumap",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['xdp like programs']
0bfc0336e1348883fdab4689f0c8c56458f36dd8,0bfc0336e1348883fdab4689f0c8c56458f36dd8,Daniel Borkmann,daniel@iogearbox.net,1709629709,Alexei Starovoitov,ast@kernel.org,1709684382,5f00303a03b043fcd0cb03d674c27cbca91660ab,f267f262815033452195f46c43b572159262f533,"selftests/bpf: Fix up xdp bonding test wrt feature flags

Adjust the XDP feature flags for the bond device when no bond slave
devices are attached. After 9b0ed890ac2a (""bonding: do not report
NETDEV_XDP_ACT_XSK_ZEROCOPY"")"," the empty bond device must report 0
as flags instead of NETDEV_XDP_ACT_MASK.

  # ./vmtest.sh -- ./test_progs -t xdp_bond
  [...]
  [    3.983311] bond1 (unregistering): (slave veth1_1): Releasing backup interface
  [    3.995434] bond1 (unregistering): Released all slaves
  [    4.022311] bond2: (slave veth2_1): Releasing backup interface
  #507/1   xdp_bonding/xdp_bonding_attach:OK
  #507/2   xdp_bonding/xdp_bonding_nested:OK
  #507/3   xdp_bonding/xdp_bonding_features:OK
  #507/4   xdp_bonding/xdp_bonding_roundrobin:OK
  #507/5   xdp_bonding/xdp_bonding_activebackup:OK
  #507/6   xdp_bonding/xdp_bonding_xor_layer2:OK
  #507/7   xdp_bonding/xdp_bonding_xor_layer23:OK
  #507/8   xdp_bonding/xdp_bonding_xor_layer34:OK
  #507/9   xdp_bonding/xdp_bonding_redirect_multi:OK
  #507     xdp_bonding:OK
  Summary: 1/9 PASSED","[' 0 SKIPPED', ' 0 FAILED\n  [    4.185255] bond2 (unregistering): Released all slaves\n  [...]\n\nFixes: 9b0ed890ac2a (""bonding: do not report NETDEV_XDP_ACT_XSK_ZEROCOPY"")\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Toke Høiland-Jørgensen <toke@redhat.com>\nMessage-ID: <20240305090829.17131-2-daniel@iogearbox.net>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes XDP feature flags for bond devices when no slave devices are attached in selftests.,"XDP,bonding,feature",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['xdp like programs']
399eca1bd4fc14645dcdf19ee10adf5cde85aecf,399eca1bd4fc14645dcdf19ee10adf5cde85aecf,Alexei Starovoitov,ast@kernel.org,1708620887,Alexei Starovoitov,ast@kernel.org,1709684157,9679deaf78e877789d754ee7f82f9d1b874e64fa,685f7d531264599b3f167f1e94bbd22f120e5fab 5c2bc5e2f81d3344095ae241032dde20a4ea2b48,"Merge branch 'check-bpf_func_state-callback_depth-when-pruning-states'

Eduard Zingerman says:

====================
check bpf_func_state->callback_depth when pruning states

This patch-set fixes bug in states pruning logic hit in mailing list
discussion [0]. The details of the fix are in patch #1.

The main idea for the fix belongs to Yonghong Song","
mine contribution is merely in review and test cases.

There are some changes in verification performance:

File                       Program        Insns    (DIFF)  States  (DIFF)
-------------------------  -------------  ---------------  --------------
pyperf600_bpf_loop.bpf.o   on_event          +15 (+0.42%)     +0 (+0.00%)
strobemeta_bpf_loop.bpf.o  on_event        +857 (+37.95%)   +60 (+38.96%)
xdp_synproxy_kern.bpf.o    syncookie_tc   +2892 (+30.39%)  +109 (+36.33%)
xdp_synproxy_kern.bpf.o    syncookie_xdp  +2892 (+30.01%)  +109 (+36.09%)

(when tested on a subset of selftests identified by
 selftests/bpf/veristat.cfg and Cilium bpf object files from [4])

Changelog:
v2 [2] -> v3:
- fixes for verifier.c commit message as suggested by Yonghong;
- patch-set re-rerouted to 'bpf' tree as suggested in [2];
- patch for test_tcp_custom_syncookie is sent separately to 'bpf-next' [3].
- veristat results updated using 'bpf' tree as baseline and clang 16.

v1 [1] -> v2:
- patch #2 commit message updated to better reflect verifier behavior
  with regards to checkpoints tree (suggested by Yonghong);
- veristat results added (suggested by Andrii).

[0] https://lore.kernel.org/bpf/9b251840-7cb8-4d17-bd23-1fc8071d8eef@linux.dev/
[1] https://lore.kernel.org/bpf/20240212143832.28838-1-eddyz87@gmail.com/
[2] https://lore.kernel.org/bpf/20240216150334.31937-1-eddyz87@gmail.com/
[3] https://lore.kernel.org/bpf/20240222150300.14909-1-eddyz87@gmail.com/
[4] https://github.com/anakryiko/cilium
====================

Link: https://lore.kernel.org/r/20240222154121.6991-1-eddyz87@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Fixes a bug in eBPF verifier state pruning logic related to callback depth.,"bugfix, pruning, verifier",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5c2bc5e2f81d3344095ae241032dde20a4ea2b48,5c2bc5e2f81d3344095ae241032dde20a4ea2b48,Eduard Zingerman,eddyz87@gmail.com,1708616481,Alexei Starovoitov,ast@kernel.org,1709684156,9679deaf78e877789d754ee7f82f9d1b874e64fa,e9a8e5a587ca55fec6c58e4881742705d45bee54,"selftests/bpf: test case for callback_depth states pruning logic

The test case was minimized from mailing list discussion [0].
It is equivalent to the following C program:

    struct iter_limit_bug_ctx { __u64 a; __u64 b; __u64 c; };

    static __naked void iter_limit_bug_cb(void)
    {
    	switch (bpf_get_prandom_u32()) {
    	case 1:  ctx->a = 42; break;
    	case 2:  ctx->b = 42; break;
    	default: ctx->c = 42; break;
    	}
    }

    int iter_limit_bug(struct __sk_buff *skb)
    {
    	struct iter_limit_bug_ctx ctx = { 7", 7,"[' 7 };\n\n    \tbpf_loop(2', ' iter_limit_bug_cb', ' &ctx', ' 0);\n    \tif (ctx.a == 42 && ctx.b == 42 && ctx.c == 7)\n    \t  asm volatile(""r1 /= 0;"":::""r1"");\n    \treturn 0;\n    }\n\nThe main idea is that each loop iteration changes one of the state\nvariables in a non-deterministic manner. Hence it is premature to\nprune the states that have two iterations left comparing them to\nstates with one iteration left.\nE.g. {{7', '7', '7}', ' callback_depth=0} can reach state {42', '42', '7}', '\nwhile {{7', '7', '7}', "" callback_depth=1} can't.\n\n[0] https://lore.kernel.org/bpf/9b251840-7cb8-4d17-bd23-1fc8071d8eef@linux.dev/\n\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20240222154121.6991-3-eddyz87@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Add test case for callback_depth states pruning logic in BPF selftests.,"test case,callback_depth,pruning",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e9a8e5a587ca55fec6c58e4881742705d45bee54,e9a8e5a587ca55fec6c58e4881742705d45bee54,Eduard Zingerman,eddyz87@gmail.com,1708616480,Alexei Starovoitov,ast@kernel.org,1709684156,98218bc1166ae5b153e46acb518eafe1d8d15c9d,685f7d531264599b3f167f1e94bbd22f120e5fab,"bpf: check bpf_func_state->callback_depth when pruning states

When comparing current and cached states verifier should consider
bpf_func_state->callback_depth. Current state cannot be pruned against
cached state"," when current states has more iterations left compared to
cached state. Current state has more iterations left when it's
callback_depth is smaller.

Below is an example illustrating this bug","[' minimized from mailing list\ndiscussion [0] (assume that BPF_F_TEST_STATE_FREQ is set).\nThe example is not a safe program: if loop_cb point (1) is followed by\nloop_cb point (2)', ' then division by zero is possible at point (4).\n\n    struct ctx {\n    \t__u64 a;\n    \t__u64 b;\n    \t__u64 c;\n    };\n\n    static void loop_cb(int i', ' struct ctx *ctx)\n    {\n    \t/* assume that generated code is ""fallthrough-first"":\n    \t * if ... == 1 goto\n    \t * if ... == 2 goto\n    \t * <default>\n    \t */\n    \tswitch (bpf_get_prandom_u32()) {\n    \tcase 1:  /* 1 */ ctx->a = 42; return 0; break;\n    \tcase 2:  /* 2 */ ctx->b = 42; return 0; break;\n    \tdefault: /* 3 */ ctx->c = 42; return 0; break;\n    \t}\n    }\n\n    SEC(""tc"")\n    __failure\n    __flag(BPF_F_TEST_STATE_FREQ)\n    int test(struct __sk_buff *skb)\n    {\n    \tstruct ctx ctx = { 7', ' 7', ' 7 };\n\n    \tbpf_loop(2', ' loop_cb', ' &ctx', ' 0);              /* 0 */\n    \t/* assume generated checks are in-order: .a first */\n    \tif (ctx.a == 42 && ctx.b == 42 && ctx.c == 7)\n    \t\tasm volatile(""r0 /= 0;"":::""r0"");    /* 4 */\n    \treturn 0;\n    }\n\nPrior to this commit verifier built the following checkpoint tree for\nthis example:\n\n .------------------------------------- Checkpoint / State name\n |    .-------------------------------- Code point number\n |    |   .---------------------------- Stack state {ctx.a', 'ctx.b', 'ctx.c}\n |    |   |        .------------------- Callback depth in frame #0\n v    v   v        v\n   - (0) {7P', '7P', '7}', 'depth=0\n     - (3) {7P', '7P', '7}', 'depth=1\n       - (0) {7P', '7P', '42}', 'depth=1\n         - (3) {7P', '7', '42}', 'depth=2\n           - (0) {7P', '7', '42}', 'depth=2      loop terminates because of depth limit\n             - (4) {7P', '7', '42}', 'depth=0    predicted false', ' ctx.a marked precise\n             - (6) exit\n(a)      - (2) {7P', '7', '42}', 'depth=2\n           - (0) {7P', '42', '42}', 'depth=2     loop terminates because of depth limit\n             - (4) {7P', '42', '42}', 'depth=0   predicted false', ' ctx.a marked precise\n             - (6) exit\n(b)      - (1) {7P', '7P', '42}', 'depth=2\n           - (0) {42P', '7P', '42}', 'depth=2    loop terminates because of depth limit\n             - (4) {42P', '7P', '42}', 'depth=0  predicted false', ' ctx.{a', 'b} marked precise\n             - (6) exit\n     - (2) {7P', '7', '7}', 'depth=1             considered safe', ' pruned using checkpoint (a)\n(c)  - (1) {7P', '7P', '7}', 'depth=1            considered safe', ' pruned using checkpoint (b)\n\nHere checkpoint (b) has callback_depth of 2', ' meaning that it would\nnever reach state {42', '42', '7}.\nWhile checkpoint (c) has callback_depth of 1', ' and thus\ncould yet explore the state {42', '42', '7} if not pruned prematurely.\nThis commit makes forbids such premature pruning', '\nallowing verifier to explore states sub-tree starting at (c):\n\n(c)  - (1) {7', '7', '7P}', 'depth=1\n       - (0) {42P', '7', '7P}', 'depth=1\n         ...\n         - (2) {42', '7', '7}', 'depth=2\n           - (0) {42', '42', '7}', 'depth=2      loop terminates because of depth limit\n             - (4) {42', '42', '7}', 'depth=0    predicted true', ' ctx.{a', 'b', 'c} marked precise\n               - (5) division by zero\n\n[0] https://lore.kernel.org/bpf/9b251840-7cb8-4d17-bd23-1fc8071d8eef@linux.dev/\n\nFixes: bb124da69c47 (""bpf: keep track of max number of bpf_loop callback iterations"")\nSuggested-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240222154121.6991-2-eddyz87@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix the pruning logic in the eBPF verifier by considering callback_depth in function states.,"bpf,func_state,callback_depth",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ef27f655b438bed4c83680e4f01e1cde2739854b,ef27f655b438bed4c83680e4f01e1cde2739854b,Florian Kauer,florian.kauer@linutronix.de,1708333723,Tony Nguyen,anthony.l.nguyen@intel.com,1709661033,b4cfcb66fc2d5f1e8b495ab50e1bcb6ce22dbd79,36c824ca3e4fa8d1224c2dcdeaca39d2ca86a42f,"igc: avoid returning frame twice in XDP_REDIRECT

When a frame can not be transmitted in XDP_REDIRECT
(e.g. due to a full queue)"," it is necessary to free
it by calling xdp_return_frame_rx_napi.

However","[' this is the responsibility of the caller of\nthe ndo_xdp_xmit (see for example bq_xmit_all in\nkernel/bpf/devmap.c) and thus calling it inside\nigc_xdp_xmit (which is the ndo_xdp_xmit of the igc\ndriver) as well will lead to memory corruption.\n\nIn fact', ' bq_xmit_all expects that it can return all\nframes after the last successfully transmitted one.\nTherefore', ' break for the first not transmitted frame', '\nbut do not call xdp_return_frame_rx_napi in igc_xdp_xmit.\nThis is equally implemented in other Intel drivers\nsuch as the igb.\n\nThere are two alternatives to this that were rejected:\n1. Return num_frames as all the frames would have been\n   transmitted and release them inside igc_xdp_xmit.\n   While it might work technically', ' it is not what\n   the return value is meant to represent (i.e. the\n   number of SUCCESSFULLY transmitted packets).\n2. Rework kernel/bpf/devmap.c and all drivers to\n   support non-consecutively dropped packets.\n   Besides being complex', ' it likely has a negative\n   performance impact without a significant gain\n   since it is anyway unlikely that the next frame\n   can be transmitted if the previous one was dropped.\n\nThe memory corruption can be reproduced with\nthe following script which leads to a kernel panic\nafter a few seconds.  It basically generates more\ntraffic than a i225 NIC can transmit and pushes it\nvia XDP_REDIRECT from a virtual interface to the\nphysical interface where frames get dropped.\n\n   #!/bin/bash\n   INTERFACE=enp4s0\n   INTERFACE_IDX=`cat /sys/class/net/$INTERFACE/ifindex`\n\n   sudo ip link add dev veth1 type veth peer name veth2\n   sudo ip link set up $INTERFACE\n   sudo ip link set up veth1\n   sudo ip link set up veth2\n\n   cat << EOF > redirect.bpf.c\n\n   SEC(""prog"")\n   int redirect(struct xdp_md *ctx)\n   {\n       return bpf_redirect($INTERFACE_IDX', ' 0);\n   }\n\n   char _license[] SEC(""license"") = ""GPL"";\n   EOF\n   clang -O2 -g -Wall -target bpf -c redirect.bpf.c -o redirect.bpf.o\n   sudo ip link set veth2 xdp obj redirect.bpf.o\n\n   cat << EOF > pass.bpf.c\n\n   SEC(""prog"")\n   int pass(struct xdp_md *ctx)\n   {\n       return XDP_PASS;\n   }\n\n   char _license[] SEC(""license"") = ""GPL"";\n   EOF\n   clang -O2 -g -Wall -target bpf -c pass.bpf.c -o pass.bpf.o\n   sudo ip link set $INTERFACE xdp obj pass.bpf.o\n\n   cat << EOF > trafgen.cfg\n\n   {\n     /* Ethernet Header */\n     0xe8', ' 0x6a', ' 0x64', ' 0x41', ' 0xbf', ' 0x46', '\n     0xFF', ' 0xFF', ' 0xFF', ' 0xFF', ' 0xFF', ' 0xFF', '\n     const16(ETH_P_IP)', '\n\n     /* IPv4 Header */\n     0b01000101', ' 0', '   # IPv4 version', ' IHL', ' TOS\n     const16(1028)', '   # IPv4 total length (UDP length + 20 bytes (IP header))\n     const16(2)', '      # IPv4 ident\n     0b01000000', ' 0', '   # IPv4 flags', ' fragmentation off\n     64', '              # IPv4 TTL\n     17', '              # Protocol UDP\n     csumip(14', ' 33)', '  # IPv4 checksum\n\n     /* UDP Header */\n     10', '  0', ' 1', ' 1', '    # IP Src - adapt as needed\n     10', '  0', ' 1', ' 2', '    # IP Dest - adapt as needed\n     const16(6666)', '   # UDP Src Port\n     const16(6666)', '   # UDP Dest Port\n     const16(1008)', '   # UDP length (UDP header 8 bytes + payload length)\n     csumudp(14', ' 34)', "" # UDP checksum\n\n     /* Payload */\n     fill('W'"", ' 1000)', '\n   }\n   EOF\n\n   sudo trafgen -i trafgen.cfg -b3000MB -o veth1 --cpp\n\nFixes: 4ff320361092 (""igc: Add support for XDP_REDIRECT action"")\nSigned-off-by: Florian Kauer <florian.kauer@linutronix.de>\nReviewed-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>\nTested-by: Naama Meir <naamax.meir@linux.intel.com>\nSigned-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>\n', '']",Fix to prevent returning frame twice in XDP_REDIRECT when the transmission queue is full.,"XDP_REDIRECT,frame,transmit",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['xdp like programs']
8f50d5c423551bfa259af792647a2f4799780ac5,8f50d5c423551bfa259af792647a2f4799780ac5,Martin KaFai Lau,martin.lau@kernel.org,1709248992,Martin KaFai Lau,martin.lau@kernel.org,1709590164,c3e977ac6a70cf40b315f9d84c42ad51b5d35799,01031fd473059bf69bb6edc6d51d4bd58ad92e50 93bc28d859e57f1a654d3b63600d14c85c5630a4,"Merge branch 'Allow struct_ops maps with a large number of programs'

Kui-Feng Lee says:

====================
The BPF struct_ops previously only allowed for one page to be used for
the trampolines of all links in a map. However"," we have recently run
out of space due to the large number of BPF program links. By
allocating additional pages when we exhaust an existing page","[' we can\naccommodate more links in a single map.\n\nThe variable st_map->image has been changed to st_map->image_pages', '\nand its type has been changed to an array of pointers to buffers of\nPAGE_SIZE. Additional pages are allocated when all existing pages are\nexhausted.\n\nThe test case loads a struct_ops maps having 40 programs. Their\ntrampolines takes about 6.6k+ bytes over 1.5 pages on x86.\n---\nMajor differences from v3:\n\n - Refactor buffer allocations to bpf_struct_ops_tramp_buf_alloc() and\n   bpf_struct_ops_tramp_buf_free().\n\nMajor differences from v2:\n\n - Move image buffer allocation to bpf_struct_ops_prepare_trampoline().\n\nMajor differences from v1:\n\n - Always free pages if failing to update.\n\n - Allocate 8 pages at most.\n\nv3: https://lore.kernel.org/all/20240224030302.1500343-1-thinker.li@gmail.com/\nv2: https://lore.kernel.org/all/20240221225911.757861-1-thinker.li@gmail.com/\nv1: https://lore.kernel.org/all/20240216182828.201727-1-thinker.li@gmail.com/\n====================\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",The commit allows struct_ops maps to support a larger number of BPF program links by allocating additional pages for trampolines.,"struct_ops maps, trampolines, BPF programs",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
93bc28d859e57f1a654d3b63600d14c85c5630a4,93bc28d859e57f1a654d3b63600d14c85c5630a4,Kui-Feng Lee,thinker.li@gmail.com,1708814058,Martin KaFai Lau,martin.lau@kernel.org,1709590164,c3e977ac6a70cf40b315f9d84c42ad51b5d35799,187e2af05abe6bf80581490239c449456627d17a,"selftests/bpf: Test struct_ops maps with a large number of struct_ops program.

Create and load a struct_ops map with a large number of struct_ops
programs to generate trampolines taking a size over multiple pages. The
map includes 40 programs. Their trampolines takes 6.6k+"," more than 1.5
pages","[' on x86.\n\nSigned-off-by: Kui-Feng Lee <thinker.li@gmail.com>\nLink: https://lore.kernel.org/r/20240224223418.526631-4-thinker.li@gmail.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",The commit tests struct_ops maps with many struct_ops programs generating large trampolines spanning multiple pages in selftests.,"struct_ops, trampolines, selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
187e2af05abe6bf80581490239c449456627d17a,187e2af05abe6bf80581490239c449456627d17a,Kui-Feng Lee,thinker.li@gmail.com,1708814057,Martin KaFai Lau,martin.lau@kernel.org,1709590160,573c922b888bd957230d958b50a0756ce457262b,73e4f9e615d7b99f39663d4722dc73e8fa5db5f9,"bpf: struct_ops supports more than one page for trampolines.

The BPF struct_ops previously only allowed one page of trampolines.
Each function pointer of a struct_ops is implemented by a struct_ops
bpf program. Each struct_ops bpf program requires a trampoline.
The following selftest patch shows each page can hold a little more
than 20 trampolines.

While one page is more than enough for the tcp-cc usecase","
the sched_ext use case shows that one page is not always enough and hits
the one page limit. This patch overcomes the one page limit by allocating
another page when needed and it is limited to a total of
MAX_IMAGE_PAGES (8) pages which is more than enough for
reasonable usages.

The variable st_map->image has been changed to st_map->image_pages","[' and\nits type has been changed to an array of pointers to pages.\n\nSigned-off-by: Kui-Feng Lee <thinker.li@gmail.com>\nLink: https://lore.kernel.org/r/20240224223418.526631-3-thinker.li@gmail.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Increase the support for multiple pages in struct_ops trampolines to accommodate higher requirements.,"struct_ops,trampolines,pages",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
73e4f9e615d7b99f39663d4722dc73e8fa5db5f9,73e4f9e615d7b99f39663d4722dc73e8fa5db5f9,Kui-Feng Lee,thinker.li@gmail.com,1708814056,Martin KaFai Lau,martin.lau@kernel.org,1709575437,af6063b8367fde8327b948b44be205ca7817c50d,01031fd473059bf69bb6edc6d51d4bd58ad92e50,bpf," net: validate struct_ops when updating value.

Perform all validations when updating values of struct_ops maps. Doing
validation in st_ops->reg() and st_ops->update() is not necessary anymore.
However","[' tcp_register_congestion_control() has been called in various\nplaces. It still needs to do validations.\n\nCc: netdev@vger.kernel.org\nSigned-off-by: Kui-Feng Lee <thinker.li@gmail.com>\nLink: https://lore.kernel.org/r/20240224223418.526631-2-thinker.li@gmail.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Perform validation of struct_ops maps on value updates instead of in reg and update functions.,"validate, struct_ops, update",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
01031fd473059bf69bb6edc6d51d4bd58ad92e50,01031fd473059bf69bb6edc6d51d4bd58ad92e50,Song Yoong Siang,yoong.siang.song@intel.com,1709454744,Daniel Borkmann,daniel@iogearbox.net,1709560919,05d146fce3abfe4cbf39785303e10518b4fd12e5,8f79870ec8a9409983ad5981e1b7d599cbf047bd,"selftests/bpf: xdp_hw_metadata reduce sleep interval

In current ping-pong design"," xdp_hw_metadata will wait until the packet
transmission completely done","[' then only start to receive the next packet.\n\nThe current sleep interval is 10ms', ' which is unnecessary large. Typically', '\na NIC does not need such a long time to transmit a packet. Furthermore', '\nduring this 10ms sleep time', ' the app is unable to receive incoming packets.\n\nTherefore', ' this commit reduce sleep interval to 10us', ' so that\nxdp_hw_metadata is able to support periodic packets with shorter interval.\n10us * 500 = 5ms should be enough for packet transmission and status\nretrieval.\n\nSigned-off-by: Song Yoong Siang <yoong.siang.song@intel.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nLink: https://lore.kernel.org/bpf/20240303083225.1184165-2-yoong.siang.song@intel.com\n', '']",Reduce sleep interval in xdp_hw_metadata test to improve efficiency.,"xdp_hw_metadata,sleep,interval",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['xdp like programs']
8f79870ec8a9409983ad5981e1b7d599cbf047bd,8f79870ec8a9409983ad5981e1b7d599cbf047bd,Andrii Nakryiko,andrii@kernel.org,1709329551,Daniel Borkmann,daniel@iogearbox.net,1709559624,70171da4dbc7892c20cf522a471ae8fe8baa156f,25703adf45f8430ec59effa20920c80139d13cdc,"selftests/bpf: Extend uprobe/uretprobe triggering benchmarks

Settle on three ""flavors"" of uprobe/uretprobe"," installed on different
kinds of instruction: nop","[' push', ' and ret. All three are testing\ndifferent internal code paths emulating or single-stepping instructions', ""\nso are interesting to compare and benchmark separately.\n\nTo ensure `push rbp` instruction we ensure that uprobe_target_push() is\nnot a leaf function by calling (global __weak) noop function and\nreturning something afterwards (if we don't do that"", ' compiler will just\ndo a tail call optimization).\n\nAlso', "" we need to make sure that compiler isn't skipping frame pointer\ngeneration"", "" so let's add `-fno-omit-frame-pointers` to Makefile.\n\nJust to give an idea of where we currently stand in terms of relative\nperformance of different uprobe/uretprobe cases vs a cheap syscall\n(getpgid()) baseline"", ' here are results from my local machine:\n\n$ benchs/run_bench_uprobes.sh\nbase           :    1.561 ± 0.020M/s\nuprobe-nop     :    0.947 ± 0.007M/s\nuprobe-push    :    0.951 ± 0.004M/s\nuprobe-ret     :    0.443 ± 0.007M/s\nuretprobe-nop  :    0.471 ± 0.013M/s\nuretprobe-push :    0.483 ± 0.004M/s\nuretprobe-ret  :    0.306 ± 0.007M/s\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240301214551.1686095-1-andrii@kernel.org\n', '']",Extend uprobe/uretprobe benchmarks with different instruction types in selftests for BPF.,"uprobe, uretprobe, benchmarks",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
25703adf45f8430ec59effa20920c80139d13cdc,25703adf45f8430ec59effa20920c80139d13cdc,Chen Shen,peterchenshen@gmail.com,1709360538,Daniel Borkmann,daniel@iogearbox.net,1709559231,8f10e46244d15818ccb3a8159c91d7a9528419ee,0ef05e258b5e15c254534d9dd382ad4c3173dce0,"libbpf: Correct debug message in btf__load_vmlinux_btf

In the function btf__load_vmlinux_btf"," the debug message incorrectly
refers to 'path' instead of 'sysfs_btf_path'.

Signed-off-by: Chen Shen <peterchenshen@gmail.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/bpf/20240302062218.3587-1-peterchenshen@gmail.com
",[''],Corrected debug message in btf__load_vmlinux_btf function to use correct path reference.,"libbpf,debug path,correction",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0ef05e258b5e15c254534d9dd382ad4c3173dce0,0ef05e258b5e15c254534d9dd382ad4c3173dce0,Dave Thaler,dthaler1968@googlemail.com,1709342549,Daniel Borkmann,daniel@iogearbox.net,1709559066,9684a0bf6aa2df7ff3a0d5fbe4607781282c9349,4e73e1bc1abf3181d57d6b8f1ab2a9f62a6a1a52,bpf," docs: Rename legacy conformance group to packet

There could be other legacy conformance groups in the future","['\nso use a more descriptive name.  The status of the conformance\ngroup in the IANA registry is what designates it as legacy', '\nnot the name of the group.\n\nSigned-off-by: Dave Thaler <dthaler1968@gmail.com>\nLink: https://lore.kernel.org/r/20240302012229.16452-1-dthaler1968@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\n', '']",Renames legacy conformance group to packet in documentation.,"rename, conformance, packet",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
4e73e1bc1abf3181d57d6b8f1ab2a9f62a6a1a52,4e73e1bc1abf3181d57d6b8f1ab2a9f62a6a1a52,Dave Thaler,dthaler1968@googlemail.com,1709331817,Alexei Starovoitov,ast@kernel.org,1709444414,1cd1b5245f658de089a618834103c3340ab7e247,4b2765ae410abf01154cf97876384d8a58c43953,bpf," docs: Use IETF format for field definitions in instruction-set.rst

In preparation for publication as an IETF RFC","[' the WG chairs asked me\nto convert the document to use IETF packet format for field layout', ' so\nthis patch attempts to make it consistent with other IETF documents.\n\nSome fields that are not byte aligned were previously inconsistent\nin how values were defined.  Some were defined as the value of the\nbyte containing the field (like 0x20 for a field holding the high\nfour bits of the byte)', ' and others were defined as the value of the\nfield itself (like 0x2).  This PR makes them be consistent in using\njust the values of the field itself', ' which is IETF convention.\n\nAs a result', ' some of the defines that used BPF_* would no longer\nmatch the value in the spec', ' and so this patch also drops the BPF_*\nprefix to avoid confusion with the defines that are the full-byte\nequivalent values.  For consistency', ' BPF_* is then dropped from\nother fields too.  BPF_<foo> is thus the Linux implementation-specific\ndefine for <foo> as it appears in the BPF ISA specification.\n\nThe syntax BPF_ADD | BPF_X | BPF_ALU only worked for full-byte\nvalues so the convention {ADD', ' X', ' ALU} is proposed for referring\nto field values instead.\n\nAlso replace the redundant ""LSB bits"" with ""least significant bits"".\n\nA preview of what the resulting Internet Draft would look like can\nbe seen at:\nhttps://htmlpreview.github.io/?https://raw.githubusercontent.com/dthaler/ebp\nf-docs-1/format/draft-ietf-bpf-isa.html\n\nv1->v2: Fix sphinx issue as recommended by David Vernet\n\nSigned-off-by: Dave Thaler <dthaler1968@gmail.com>\nAcked-by: David Vernet <void@manifault.com>\nLink: https://lore.kernel.org/r/20240301222337.15931-1-dthaler1968@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Updated instruction-set documentation to use IETF format for field definitions.,"documentation,IETF,RFC",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
4b2765ae410abf01154cf97876384d8a58c43953,4b2765ae410abf01154cf97876384d8a58c43953,Jakub Kicinski,kuba@kernel.org,1709441459,Jakub Kicinski,kuba@kernel.org,1709441459,6f5cdb7a5085b67c90244b2cbaeaa96bf401e17c,e960825709330cb199d209740326cec37e8c419d 0270d69121ba7fbc449a386f989b9b7b5eaebde3,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next

Daniel Borkmann says:

====================
pull-request: bpf-next 2024-02-29

We've added 119 non-merge commits during the last 32 day(s) which contain
a total of 150 files changed", 3589 insertions(+),"[' 995 deletions(-).\n\nThe main changes are:\n\n1) Extend the BPF verifier to enable static subprog calls in spin lock\n   critical sections', ' from Kumar Kartikeya Dwivedi.\n\n2) Fix confusing and incorrect inference of PTR_TO_CTX argument type\n   in BPF global subprogs', ' from Andrii Nakryiko.\n\n3) Larger batch of riscv BPF JIT improvements and enabling inlining\n   of the bpf_kptr_xchg() for RV64', ' from Pu Lehui.\n\n4) Allow skeleton users to change the values of the fields in struct_ops\n   maps at runtime', "" from Kui-Feng Lee.\n\n5) Extend the verifier's capabilities of tracking scalars when they\n   are spilled to stack"", ' especially when the spill or fill is narrowing', '\n   from Maxim Mikityanskiy & Eduard Zingerman.\n\n6) Various BPF selftest improvements to fix errors under gcc BPF backend', '\n   from Jose E. Marchesi.\n\n7) Avoid module loading failure when the module trying to register\n   a struct_ops has its BTF section stripped', ' from Geliang Tang.\n\n8) Annotate all kfuncs in .BTF_ids section which eventually allows\n   for automatic kfunc prototype generation from bpftool', ' from Daniel Xu.\n\n9) Several updates to the instruction-set.rst IETF standardization\n   document', ' from Dave Thaler.\n\n10) Shrink the size of struct bpf_map resp. bpf_array', '\n    from Alexei Starovoitov.\n\n11) Initial small subset of BPF verifier prepwork for sleepable bpf_timer', ""\n    from Benjamin Tissoires.\n\n12) Fix bpftool to be more portable to musl libc by using POSIX's\n    basename()"", ' from Arnaldo Carvalho de Melo.\n\n13) Add libbpf support to gcc in CORE macro definitions', '\n    from Cupertino Miranda.\n\n14) Remove a duplicate type check in perf_event_bpf_event', '\n    from Florian Lehner.\n\n15) Fix bpf_spin_{un', '}lock BPF helpers to actually annotate them\n    with notrace correctly', ' from Yonghong Song.\n\n16) Replace the deprecated bpf_lpm_trie_key 0-length array with flexible\n    array to fix build warnings', ' from Kees Cook.\n\n17) Fix resolve_btfids cross-compilation to non host-native endianness', ""\n    from Viktor Malik.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next: (119 commits)\n  selftests/bpf: Test if shadow types work correctly.\n  bpftool: Add an example for struct_ops map and shadow type.\n  bpftool: Generated shadow variables for struct_ops maps.\n  libbpf: Convert st_ops->data to shadow type.\n  libbpf: Set btf_value_type_id of struct bpf_map for struct_ops.\n  bpf: Replace bpf_lpm_trie_key 0-length array with flexible array\n  bpf"", ' arm64: use bpf_prog_pack for memory management\n  arm64: patching: implement text_poke API\n  bpf', ' arm64: support exceptions\n  arm64: stacktrace: Implement arch_bpf_stack_walk() for the BPF JIT\n  bpf: add is_async_callback_calling_insn() helper\n  bpf: introduce in_sleepable() helper\n  bpf: allow more maps in sleepable bpf programs\n  selftests/bpf: Test case for lacking CFI stub functions.\n  bpf: Check cfi_stubs before registering a struct_ops type.\n  bpf: Clarify batch lookup/lookup_and_delete semantics\n  bpf', ' docs: specify which BPF_ABS and BPF_IND fields were zero\n  bpf', ' docs: Fix typos in instruction-set.rst\n  selftests/bpf: update tcp_custom_syncookie to use scalar packet offset\n  bpf: Shrink size of struct bpf_map/bpf_array.\n  ...\n====================\n\nLink: https://lore.kernel.org/r/20240301001625.8800-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Merge various updates from the bpf-next branch affecting multiple files in the Linux kernel repository.,"merge, bpf-next, updates",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
dd267d056fed323f1684fa52d2a864fc93ca3be0,dd267d056fed323f1684fa52d2a864fc93ca3be0,Ian Rogers,irogers@google.com,1709139929,Namhyung Kim,namhyung@kernel.org,1709258893,6e8213cf5cc7a7b670ed242b515c692ea9931c39,ec42d3d56819688537ec7ee37ce97f695fb8e6d7,"perf vendor events intel: Add umasks/occ_sel to PCU events.

UMasks were being dropped leading to all PCU
UNC_P_POWER_STATE_OCCUPANCY events having the same encoding. Don't
drop the umask trying to be consistent with other sources of events
like libpfm4 [1]. Older models need to use occ_sel rather than umask","
correct these values too. This applies the change from [2].

[1] https://sourceforge.net/p/perfmon2/libpfm4/ci/master/tree/lib/events/intel_skx_unc_pcu_events.h#l30
[2] https://github.com/captain5050/perfmon/commit/cbd4aee81023e5bfa09677b1ce170ff69e9c423d

Signed-off-by: Ian Rogers <irogers@google.com>
Reviewed-by: Kan Liang <kan.liang@linux.intel.com>
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
Link: https://lore.kernel.org/r/20240228170529.4035675-1-irogers@google.com
",[''],Fix PCU event encoding by adding umasks/occ_sel for better consistency in perf vendor events on Intel.,"PCU,umasks,events",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
0270d69121ba7fbc449a386f989b9b7b5eaebde3,0270d69121ba7fbc449a386f989b9b7b5eaebde3,Andrii Nakryiko,andrii@kernel.org,1709243646,Andrii Nakryiko,andrii@kernel.org,1709245447,524cfad5f7755ea83210ec355b43fa650219b237,896880ff30866f386ebed14ab81ce1ad3710cfc4 0623e73317940d052216fb6eef4efd55a0a7f602,"Merge branch 'create-shadow-types-for-struct_ops-maps-in-skeletons'

Kui-Feng Lee says:

====================
Create shadow types for struct_ops maps in skeletons

This patchset allows skeleton users to change the values of the fields
in struct_ops maps at runtime. It will create a shadow type pointer in
a skeleton for each struct_ops map"," allowing users to access the
values of fields through these pointers. For instance","[' if there is an\ninteger field named ""FOO"" in a struct_ops map called ""testmap""', ' you\ncan access the value of ""FOO"" in this way.\n\n    skel->struct_ops.testmap->FOO = 13;\n\nWith this feature', ' the users can pass flags or other data along with\nthe map from the user space to the kernel without creating separate\nstruct_ops map for different values in BPF.\n\n== Shadow Type ==\n\nThe shadow type of a struct_ops map is a variant of the original\nstruct type of the map. The code generator translates each field in\nthe original struct type to a field in the shadow type. The type of a\nfield in the shadow type may not be the same as the corresponding\nfield in the original struct type. For example', ' modifiers like\nvolatile', ' const', ' etc.', ' are removed from the fields in a shadow\ntype. Function pointers are translated to pointers of struct\nbpf_program.\n\nCurrently', ' only scalar types and function pointers are\nsupported. Fields belonging to structs', ' unions', ' non-function pointers', '\narrays', ' or other types are not supported. For those unsupported\nfields', ' they are converted to arrays of characters to preserve their\nspace within the original struct type.\n\nThe padding between consecutive fields is handled by padding fields\n(__padding_*). This helps to maintain the memory layout consistent\nwith the original struct_type.\n\nHere is an example of shadow types.\nThe origin struct type of a struct_ops map is\n\n    struct bpf_testmod_ops {\n    \tint (*test_1)(void);\n    \tvoid (*test_2)(int a', ' int b);\n    \t/* Used to test nullable arguments. */\n    \tint (*test_maybe_null)(int dummy', ' struct task_struct *task);\n\n    \t/* The following fields are used to test shadow copies. */\n    \tchar onebyte;\n    \tstruct {\n    \t\tint a;\n    \t\tint b;\n    \t} unsupported;\n    \tint data;\n    };\n\nThe struct_ops map', ' named testmod_1', ' of this type will be translated\nto a pointer in the shadow type.\n\n    struct {\n    \tstruct my_skel__testmod_1__bpf_testmod_ops {\n    \t\tconst struct bpf_program *test_1;\n    \t\tconst struct bpf_program *test_2;\n    \t\tconst struct bpf_program *test_maybe_null;\n    \t\tchar onebyte;\n    \t\tchar __padding_4[3];\n    \t\tchar __unsupported_4[8];\n    \t\tint data;\n    \t} *testmod_1;\n    } struct_ops;\n\n== Convert st_ops->data to Shadow Type ==\n\nlibbpf converts st_ops->data to the format of the shadow type for each\nstruct_ops map. This means that the bytes where function pointers are\nlocated are converted to the values of the pointers of struct\nbpf_program. The fields of other types are kept as they were.\n\nLibbpf will synchronize the pointers of struct bpf_program with\nst_ops->progs[] so that users can change function pointers\n(bpf_program) before loading the map.\n---\nChanges from v5:\n\n - Generate names for shadow types.\n\n - Check btf and the number of struct_ops maps in gen_st_ops_shadow()\n   and gen_st_ops_shadow_init() instead of do_skeleton() and\n   do_subskeleton().\n\n - Name unsupported fields in the pattern __unsupported_*.\n\n - Have a padding field for a unsupported fields as well if necessary.\n\n - Implement resolve_func_ptr() in gen.c instead of reusing the one in\n   libbpf. (Remove the part 1 in v4.)\n\n - Fix stylistic issues.\n\nChanges from v4:\n\n - Convert function pointers to the pointers to struct bpf_program in\n   bpf_object__collect_st_ops_relos().\n\nChanges from v3:\n\n - Add comment to avoid people from removing resolve_func_ptr() from\n   libbpf_internal.h\n\n - Fix commit logs and comments.\n\n - Add an example about using the pointers of shadow types\n   for struct_ops maps to bpftool-gen.8.\n\nv5: https://lore.kernel.org/all/20240227010432.714127-1-thinker.li@gmail.com/\nv4: https://lore.kernel.org/all/20240222222624.1163754-1-thinker.li@gmail.com/\nv3: https://lore.kernel.org/all/20240221012329.1387275-1-thinker.li@gmail.com/\nv2: https://lore.kernel.org/all/20240214020836.1845354-1-thinker.li@gmail.com/\nv1: https://lore.kernel.org/all/20240124224130.859921-1-thinker.li@gmail.com/\n\nKui-Feng Lee (5):\n  libbpf: set btf_value_type_id of struct bpf_map for struct_ops.\n  libbpf: Convert st_ops->data to shadow type.\n  bpftool: generated shadow variables for struct_ops maps.\n  bpftool: Add an example for struct_ops map and shadow type.\n  selftests/bpf: Test if shadow types work correctly.\n\n .../bpf/bpftool/Documentation/bpftool-gen.rst |  58 ++++-\n tools/bpf/bpftool/gen.c                       | 237 +++++++++++++++++-\n tools/lib/bpf/libbpf.c                        |  50 +++-\n .../selftests/bpf/bpf_testmod/bpf_testmod.c   |  11 +-\n .../selftests/bpf/bpf_testmod/bpf_testmod.h   |   8 +\n .../bpf/prog_tests/test_struct_ops_module.c   |  19 +-\n .../selftests/bpf/progs/struct_ops_module.c   |   8 +\n 7 files changed', ' 377 insertions(+)', ' 14 deletions(-)\n====================\n\nLink: https://lore.kernel.org/r/20240229064523.2091270-1-thinker.li@gmail.com\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n', '']",The commit introduces shadow types for struct_ops maps to allow runtime modifications in skeletons.,"shadow types, struct_ops, skeletons",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0623e73317940d052216fb6eef4efd55a0a7f602,0623e73317940d052216fb6eef4efd55a0a7f602,Kui-Feng Lee,thinker.li@gmail.com,1709189123,Andrii Nakryiko,andrii@kernel.org,1709245433,524cfad5f7755ea83210ec355b43fa650219b237,f2e81192e07e87897ff1296c96775eceea8f582a,"selftests/bpf: Test if shadow types work correctly.

Change the values of fields", including scalar types and function pointers,"['\nand check if the struct_ops map works as expected.\n\nThe test changes the field ""test_2"" of ""testmod_1"" from the pointer to\ntest_2() to pointer to test_3() and the field ""data"" to 13. The function\ntest_2() and test_3() both compute a new value for ""test_2_result""', ' but in\ndifferent way. By checking the value of ""test_2_result""', ' it ensures the\nstruct_ops map works as expected with changes through shadow types.\n\nSigned-off-by: Kui-Feng Lee <thinker.li@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240229064523.2091270-6-thinker.li@gmail.com\n', '']",The commit adds selftests for verifying the correct functionality of shadow types in BPF programs.,"selftests, shadow types, BPF",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f2e81192e07e87897ff1296c96775eceea8f582a,f2e81192e07e87897ff1296c96775eceea8f582a,Kui-Feng Lee,thinker.li@gmail.com,1709189122,Andrii Nakryiko,andrii@kernel.org,1709245433,39d67b886bcd562accc2b99f99d9c9c5f85e5855,a7b0fa352eafef95bd0d736ca94965d3f884ad18,"bpftool: Add an example for struct_ops map and shadow type.

The example in bpftool-gen.8 explains how to use the pointer of the shadow
type to change the value of a field of a struct_ops map.

Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Reviewed-by: Quentin Monnet <quentin@isovalent.com>
Link: https://lore.kernel.org/bpf/20240229064523.2091270-5-thinker.li@gmail.com
",,The commit adds an example in bpftool-gen for using the shadow type in struct_ops maps.,"bpftool, struct_ops, shadow type",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a7b0fa352eafef95bd0d736ca94965d3f884ad18,a7b0fa352eafef95bd0d736ca94965d3f884ad18,Kui-Feng Lee,thinker.li@gmail.com,1709189121,Andrii Nakryiko,andrii@kernel.org,1709245433,ed6217fb23ed793a284adf35e6b749505e0acdea,69e4a9d2b3f5adf5af4feeab0a9f505da971265a,"bpftool: Generated shadow variables for struct_ops maps.

Declares and defines a pointer of the shadow type for each struct_ops map.

The code generator will create an anonymous struct type as the shadow type
for each struct_ops map. The shadow type is translated from the original
struct type of the map. The user of the skeleton use pointers of them to
access the values of struct_ops maps.

However", shadow types only supports certain types of fields,"[' including\nscalar types and function pointers. Any fields of unsupported types are\ntranslated into an array of characters to occupy the space of the original\nfield. Function pointers are translated into pointers of the struct\nbpf_program. Additionally', ' padding fields are generated to occupy the space\nbetween two consecutive fields.\n\nThe pointers of shadow types of struct_osp maps are initialized when\n*__open_opts() in skeletons are called. For a map called FOO', ' the user can\naccess it through the pointer at skel->struct_ops.FOO.\n\nSigned-off-by: Kui-Feng Lee <thinker.li@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nReviewed-by: Quentin Monnet <quentin@isovalent.com>\nLink: https://lore.kernel.org/bpf/20240229064523.2091270-4-thinker.li@gmail.com\n', '']",Introduced shadow variable generation for struct_ops maps in bpftool.,"shadow, struct_ops, bpftool",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
69e4a9d2b3f5adf5af4feeab0a9f505da971265a,69e4a9d2b3f5adf5af4feeab0a9f505da971265a,Kui-Feng Lee,thinker.li@gmail.com,1709189120,Andrii Nakryiko,andrii@kernel.org,1709245432,0b044a41286a8648b98c65ca50b1ccb20b9dadb9,3644d285462a60c80ac225d508fcfe705640d2b4,"libbpf: Convert st_ops->data to shadow type.

Convert st_ops->data to the shadow type of the struct_ops map. The shadow
type of a struct_ops type is a variant of the original struct type
providing a way to access/change the values in the maps of the struct_ops
type.

bpf_map__initial_value() will return st_ops->data for struct_ops types. The
skeleton is going to use it as the pointer to the shadow type of the
original struct type.

One of the main differences between the original struct type and the shadow
type is that all function pointers of the shadow type are converted to
pointers of struct bpf_program. Users can replace these bpf_program
pointers with other BPF programs. The st_ops->progs[] will be updated
before updating the value of a map to reflect the changes made by users.

Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240229064523.2091270-3-thinker.li@gmail.com
",,Convert struct_ops data to a shadow type allowing modified program pointers in libbpf.,"libbpf,shadow,struct_ops",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3644d285462a60c80ac225d508fcfe705640d2b4,3644d285462a60c80ac225d508fcfe705640d2b4,Kui-Feng Lee,thinker.li@gmail.com,1709189119,Andrii Nakryiko,andrii@kernel.org,1709245432,1c08efa523718f023f462628a0aeb61797e007e4,896880ff30866f386ebed14ab81ce1ad3710cfc4,"libbpf: Set btf_value_type_id of struct bpf_map for struct_ops.

For a struct_ops map"," btf_value_type_id is the type ID of it's struct
type. This value is required by bpftool to generate skeleton including
pointers of shadow types. The code generator gets the type ID from
bpf_map__btf_value_type_id() in order to get the type information of the
struct type of a map.

Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240229064523.2091270-2-thinker.li@gmail.com
",[''],Set btf_value_type_id for struct_ops in bpf_map to enable bpftool skeleton generation.,"libbpf,bpf_map,btf_value_type_id",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"[""It's not related to any of the above.""]"
b44d66536859393772c67cb1da65345127f692e0,b44d66536859393772c67cb1da65345127f692e0,Namhyung Kim,namhyung@kernel.org,1709098415,Namhyung Kim,namhyung@kernel.org,1709243636,4b0a7da48fdc47ae727eeef00f83bf2a7509dd18,97b6b4ac1c5dd42a473a4f8e775d97476c5da038,"perf lock contention: Account contending locks too

Currently it accounts the contention using delta between timestamps in
lock:contention_begin and lock:contention_end tracepoints.  But it means
the lock should see the both events during the monitoring period.

Actually there are 4 cases that happen with the monitoring:

                monitoring period
            /                       \
            |                       |
 1:  B------+-----------------------+--------E
 2:    B----+-------------E         |
 3:         |           B-----------+----E
 4:         |     B-------------E   |
            |                       |
            t0                      t1

where B and E mean contention BEGIN and END"," respectively.  So it only
accounts the case 4 for now.  It seems there's no way to handle the case
1.  The case 2 might be handled if it saved the timestamp (t0)","[' but it\nlacks the information from the B notably the flags which shows the lock\ntypes.  Also it could be a nested lock which it currently ignores.  So\nI think we should ignore the case 2.\n\nHowever we can handle the case 3 if we save the timestamp (t1) at the\nend of the period.  And then it can iterate the map entries in the\nuserspace and update the lock stat accordinly.\n\nSigned-off-by: Namhyung Kim <namhyung@kernel.org>\nReviewed-by: Ian Rogers <irogers@google.com>\nReviwed-by: Arnaldo Carvalho de Melo <acme@redhat.com>\nCc: Song Liu <song@kernel.org>\nCc: bpf@vger.kernel.org\nLink: https://lore.kernel.org/r/20240228053335.312776-1-namhyung@kernel.org\n', '']",Enhance lock contention accounting by handling additional cases in the monitoring period.,"lock,contention,accounting",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
896880ff30866f386ebed14ab81ce1ad3710cfc4,896880ff30866f386ebed14ab81ce1ad3710cfc4,Kees Cook,keescook@chromium.org,1708617375,Daniel Borkmann,daniel@iogearbox.net,1709243563,376f9437aae34eb8c1216a1d22c576cda2eabbec,b9a62998482fa1488123f690bcacc26fd2351a18,"bpf: Replace bpf_lpm_trie_key 0-length array with flexible array

Replace deprecated 0-length array in struct bpf_lpm_trie_key with
flexible array. Found with GCC 13:

../kernel/bpf/lpm_trie.c:207:51: warning: array subscript i is outside array bounds of 'const __u8[0]' {aka 'const unsigned char[]'} [-Warray-bounds=]
  207 |                                        *(__be16 *)&key->data[i]);
      |                                                   ^~~~~~~~~~~~~
../include/uapi/linux/swab.h:102:54: note: in definition of macro '__swab16'
  102 | #define __swab16(x) (__u16)__builtin_bswap16((__u16)(x))
      |                                                      ^
../include/linux/byteorder/generic.h:97:21: note: in expansion of macro '__be16_to_cpu'
   97 | #define be16_to_cpu __be16_to_cpu
      |                     ^~~~~~~~~~~~~
../kernel/bpf/lpm_trie.c:206:28: note: in expansion of macro 'be16_to_cpu'
  206 |                 u16 diff = be16_to_cpu(*(__be16 *)&node->data[i]
^
      |                            ^~~~~~~~~~~
In file included from ../include/linux/bpf.h:7:
../include/uapi/linux/bpf.h:82:17: note: while referencing 'data'
   82 |         __u8    data[0];        /* Arbitrary size */
      |                 ^~~~

And found at run-time under CONFIG_FORTIFY_SOURCE:

  UBSAN: array-index-out-of-bounds in kernel/bpf/lpm_trie.c:218:49
  index 0 is out of range for type '__u8 [*]'

Changing struct bpf_lpm_trie_key is difficult since has been used by
userspace. For example"," in Cilium:

	struct egress_gw_policy_key {
	        struct bpf_lpm_trie_key lpm_key;
	        __u32 saddr;
	        __u32 daddr;
	};

While direct references to the ""data"" member haven't been found","[' there\nare static initializers what include the final member. For example', '\nthe ""{}"" here:\n\n        struct egress_gw_policy_key in_key = {\n                .lpm_key = { 32 + 24', ' {} }', '\n                .saddr   = CLIENT_IP', '\n                .daddr   = EXTERNAL_SVC_IP & 0Xffffff', '\n        };\n\nTo avoid the build time and run time warnings seen with a 0-sized\ntrailing array for struct bpf_lpm_trie_key', ' introduce a new struct\nthat correctly uses a flexible array for the trailing bytes', '\nstruct bpf_lpm_trie_key_u8. As part of this', ' include the ""header""\nportion (which is just the ""prefixlen"" member)', "" so it can be used\nby anything building a bpf_lpr_trie_key that has trailing members that\naren't a u8 flexible array (like the self-test[1])"", ' which is named\nstruct bpf_lpm_trie_key_hdr.\n\nUnfortunately', ' C++ refuses to parse the __struct_group() helper', ' so\nit is not possible to define struct bpf_lpm_trie_key_hdr directly in\nstruct bpf_lpm_trie_key_u8', ' so we must open-code the union directly.\n\nAdjust the kernel code to use struct bpf_lpm_trie_key_u8 through-out', '\nand for the selftest to use struct bpf_lpm_trie_key_hdr. Add a comment\nto the UAPI header directing folks to the two new options.\n\nReported-by: Mark Rutland <mark.rutland@arm.com>\nSigned-off-by: Kees Cook <keescook@chromium.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Gustavo A. R. Silva <gustavoars@kernel.org>\nCloses: https://paste.debian.net/hidden/ca500597/\nLink: https://lore.kernel.org/all/202206281009.4332AA33@keescook/ [1]\nLink: https://lore.kernel.org/bpf/20240222155612.it.533-kees@kernel.org\n', '']",Replaced deprecated 0-length array with a flexible array in bpf_lpm_trie_key to address GCC warnings and runtime issues.,"flexible array, 0-length array, bpf_lpm_trie_key",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8f5afe41148ce6a719864e23c2bf776c88e9212f,8f5afe41148ce6a719864e23c2bf776c88e9212f,Jakub Kicinski,kuba@kernel.org,1709226438,Jakub Kicinski,kuba@kernel.org,1709226439,edca5dcec127fc1268a474167cafa13303931f9e,616d82c3cfa2a2146dd7e3ae47bda7e877ee549e 13114dc5543069f7b97991e3b79937b6da05f5b0,"Merge branch 'tls-a-few-more-fixes-for-async-decrypt'

Sabrina Dubroca says:

====================
tls: a few more fixes for async decrypt

The previous patchset [1] took care of ""full async"". This adds a few
fixes for cases where only part of the crypto operations go the async
route"," found by extending my previous debug patch [2] to do N
synchronous operations followed by M asynchronous ops (with N and M
configurable).

[1] https://patchwork.kernel.org/project/netdevbpf/list/?series=823784&state=*
[2] https://lore.kernel.org/all/9d664093b1bf7f47497b2c40b3a085b45f3274a2.1694021240.git.sd@queasysnail.net/
====================

Link: https://lore.kernel.org/r/cover.1709132643.git.sd@queasysnail.net
Signed-off-by: Jakub Kicinski <kuba@kernel.org>
",[''],This commit merges several bug fixes for TLS asynchronous decryption pathways.,"TLS, async, decrypt",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
616d82c3cfa2a2146dd7e3ae47bda7e877ee549e,616d82c3cfa2a2146dd7e3ae47bda7e877ee549e,Alexander Ofitserov,oficerovas@altlinux.org,1709120823,Paolo Abeni,pabeni@redhat.com,1709212458,e4bbcfe533367900aeee0d8677d88362a2e4e2c6,b611b776a9c89a86e57ea6dbf8adfc99c6e8a62e,"gtp: fix use-after-free and null-ptr-deref in gtp_newlink()

The gtp_link_ops operations structure for the subsystem must be
registered after registering the gtp_net_ops pernet operations structure.

Syzkaller hit 'general protection fault in gtp_genl_dump_pdp' bug:

[ 1010.702740] gtp: GTP module unloaded
[ 1010.715877] general protection fault"," probably for non-canonical address 0xdffffc0000000001: 0000 [#1] SMP KASAN NOPTI
[ 1010.715888] KASAN: null-ptr-deref in range [0x0000000000000008-0x000000000000000f]
[ 1010.715895] CPU: 1 PID: 128616 Comm: a.out Not tainted 6.8.0-rc6-std-def-alt1 #1
[ 1010.715899] Hardware name: QEMU Standard PC (Q35 + ICH9","[' 2009)', ' BIOS 1.16.0-alt1 04/01/2014\n[ 1010.715908] RIP: 0010:gtp_newlink+0x4d7/0x9c0 [gtp]\n[ 1010.715915] Code: 80 3c 02 00 0f 85 41 04 00 00 48 8b bb d8 05 00 00 e8 ed f6 ff ff 48 89 c2 48 89 c5 48 b8 00 00 00 00 00 fc ff df 48 c1 ea 03 <80> 3c 02 00 0f 85 4f 04 00 00 4c 89 e2 4c 8b 6d 00 48 b8 00 00 00\n[ 1010.715920] RSP: 0018:ffff888020fbf180 EFLAGS: 00010203\n[ 1010.715929] RAX: dffffc0000000000 RBX: ffff88800399c000 RCX: 0000000000000000\n[ 1010.715933] RDX: 0000000000000001 RSI: ffffffff84805280 RDI: 0000000000000282\n[ 1010.715938] RBP: 000000000000000d R08: 0000000000000001 R09: 0000000000000000\n[ 1010.715942] R10: 0000000000000001 R11: 0000000000000001 R12: ffff88800399cc80\n[ 1010.715947] R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000400\n[ 1010.715953] FS:  00007fd1509ab5c0(0000) GS:ffff88805b300000(0000) knlGS:0000000000000000\n[ 1010.715958] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[ 1010.715962] CR2: 0000000000000000 CR3: 000000001c07a000 CR4: 0000000000750ee0\n[ 1010.715968] PKRU: 55555554\n[ 1010.715972] Call Trace:\n[ 1010.715985]  ? __die_body.cold+0x1a/0x1f\n[ 1010.715995]  ? die_addr+0x43/0x70\n[ 1010.716002]  ? exc_general_protection+0x199/0x2f0\n[ 1010.716016]  ? asm_exc_general_protection+0x1e/0x30\n[ 1010.716026]  ? gtp_newlink+0x4d7/0x9c0 [gtp]\n[ 1010.716034]  ? gtp_net_exit+0x150/0x150 [gtp]\n[ 1010.716042]  __rtnl_newlink+0x1063/0x1700\n[ 1010.716051]  ? rtnl_setlink+0x3c0/0x3c0\n[ 1010.716063]  ? is_bpf_text_address+0xc0/0x1f0\n[ 1010.716070]  ? kernel_text_address.part.0+0xbb/0xd0\n[ 1010.716076]  ? __kernel_text_address+0x56/0xa0\n[ 1010.716084]  ? unwind_get_return_address+0x5a/0xa0\n[ 1010.716091]  ? create_prof_cpu_mask+0x30/0x30\n[ 1010.716098]  ? arch_stack_walk+0x9e/0xf0\n[ 1010.716106]  ? stack_trace_save+0x91/0xd0\n[ 1010.716113]  ? stack_trace_consume_entry+0x170/0x170\n[ 1010.716121]  ? __lock_acquire+0x15c5/0x5380\n[ 1010.716139]  ? mark_held_locks+0x9e/0xe0\n[ 1010.716148]  ? kmem_cache_alloc_trace+0x35f/0x3c0\n[ 1010.716155]  ? __rtnl_newlink+0x1700/0x1700\n[ 1010.716160]  rtnl_newlink+0x69/0xa0\n[ 1010.716166]  rtnetlink_rcv_msg+0x43b/0xc50\n[ 1010.716172]  ? rtnl_fdb_dump+0x9f0/0x9f0\n[ 1010.716179]  ? lock_acquire+0x1fe/0x560\n[ 1010.716188]  ? netlink_deliver_tap+0x12f/0xd50\n[ 1010.716196]  netlink_rcv_skb+0x14d/0x440\n[ 1010.716202]  ? rtnl_fdb_dump+0x9f0/0x9f0\n[ 1010.716208]  ? netlink_ack+0xab0/0xab0\n[ 1010.716213]  ? netlink_deliver_tap+0x202/0xd50\n[ 1010.716220]  ? netlink_deliver_tap+0x218/0xd50\n[ 1010.716226]  ? __virt_addr_valid+0x30b/0x590\n[ 1010.716233]  netlink_unicast+0x54b/0x800\n[ 1010.716240]  ? netlink_attachskb+0x870/0x870\n[ 1010.716248]  ? __check_object_size+0x2de/0x3b0\n[ 1010.716254]  netlink_sendmsg+0x938/0xe40\n[ 1010.716261]  ? netlink_unicast+0x800/0x800\n[ 1010.716269]  ? __import_iovec+0x292/0x510\n[ 1010.716276]  ? netlink_unicast+0x800/0x800\n[ 1010.716284]  __sock_sendmsg+0x159/0x190\n[ 1010.716290]  ____sys_sendmsg+0x712/0x880\n[ 1010.716297]  ? sock_write_iter+0x3d0/0x3d0\n[ 1010.716304]  ? __ia32_sys_recvmmsg+0x270/0x270\n[ 1010.716309]  ? lock_acquire+0x1fe/0x560\n[ 1010.716315]  ? drain_array_locked+0x90/0x90\n[ 1010.716324]  ___sys_sendmsg+0xf8/0x170\n[ 1010.716331]  ? sendmsg_copy_msghdr+0x170/0x170\n[ 1010.716337]  ? lockdep_init_map_type+0x2c7/0x860\n[ 1010.716343]  ? lockdep_hardirqs_on_prepare+0x430/0x430\n[ 1010.716350]  ? debug_mutex_init+0x33/0x70\n[ 1010.716360]  ? percpu_counter_add_batch+0x8b/0x140\n[ 1010.716367]  ? lock_acquire+0x1fe/0x560\n[ 1010.716373]  ? find_held_lock+0x2c/0x110\n[ 1010.716384]  ? __fd_install+0x1b6/0x6f0\n[ 1010.716389]  ? lock_downgrade+0x810/0x810\n[ 1010.716396]  ? __fget_light+0x222/0x290\n[ 1010.716403]  __sys_sendmsg+0xea/0x1b0\n[ 1010.716409]  ? __sys_sendmsg_sock+0x40/0x40\n[ 1010.716419]  ? lockdep_hardirqs_on_prepare+0x2b3/0x430\n[ 1010.716425]  ? syscall_enter_from_user_mode+0x1d/0x60\n[ 1010.716432]  do_syscall_64+0x30/0x40\n[ 1010.716438]  entry_SYSCALL_64_after_hwframe+0x62/0xc7\n[ 1010.716444] RIP: 0033:0x7fd1508cbd49\n[ 1010.716452] Code: 00 c3 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 44 00 00 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 73 01 c3 48 8b 0d ef 70 0d 00 f7 d8 64 89 01 48\n[ 1010.716456] RSP: 002b:00007fff18872348 EFLAGS: 00000202 ORIG_RAX: 000000000000002e\n[ 1010.716463] RAX: ffffffffffffffda RBX: 000055f72bf0eac0 RCX: 00007fd1508cbd49\n[ 1010.716468] RDX: 0000000000000000 RSI: 0000000020000280 RDI: 0000000000000006\n[ 1010.716473] RBP: 00007fff18872360 R08: 00007fff18872360 R09: 00007fff18872360\n[ 1010.716478] R10: 00007fff18872360 R11: 0000000000000202 R12: 000055f72bf0e1b0\n[ 1010.716482] R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000\n[ 1010.716491] Modules linked in: gtp(+) udp_tunnel ib_core uinput af_packet rfkill qrtr joydev hid_generic usbhid hid kvm_intel iTCO_wdt intel_pmc_bxt iTCO_vendor_support kvm snd_hda_codec_generic ledtrig_audio irqbypass crct10dif_pclmul crc32_pclmul crc32c_intel ghash_clmulni_intel snd_hda_intel nls_utf8 snd_intel_dspcfg nls_cp866 psmouse aesni_intel vfat crypto_simd fat cryptd glue_helper snd_hda_codec pcspkr snd_hda_core i2c_i801 snd_hwdep i2c_smbus xhci_pci snd_pcm lpc_ich xhci_pci_renesas xhci_hcd qemu_fw_cfg tiny_power_button button sch_fq_codel vboxvideo drm_vram_helper drm_ttm_helper ttm vboxsf vboxguest snd_seq_midi snd_seq_midi_event snd_seq snd_rawmidi snd_seq_device snd_timer snd soundcore msr fuse efi_pstore dm_mod ip_tables x_tables autofs4 virtio_gpu virtio_dma_buf drm_kms_helper cec rc_core drm virtio_rng virtio_scsi rng_core virtio_balloon virtio_blk virtio_net virtio_console net_failover failover ahci libahci libata evdev scsi_mod input_leds serio_raw virtio_pci intel_agp\n[ 1010.716674]  virtio_ring intel_gtt virtio [last unloaded: gtp]\n[ 1010.716693] ---[ end trace 04990a4ce61e174b ]---\n\nCc: stable@vger.kernel.org\nSigned-off-by: Alexander Ofitserov <oficerovas@altlinux.org>\nFixes: 459aa660eb1d (""gtp: add initial driver for datapath of GPRS Tunneling Protocol (GTP-U)"")\nReviewed-by: Jiri Pirko <jiri@nvidia.com>\nLink: https://lore.kernel.org/r/20240228114703.465107-1-oficerovas@altlinux.org\nSigned-off-by: Paolo Abeni <pabeni@redhat.com>\n', '']",Fix use-after-free and null-pointer dereference in gtp_newlink function registration sequence.,"gtp, use-after-free, null-ptr-deref",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
7e0f122c65912740327e4c54472acaa5f85868cb,7e0f122c65912740327e4c54472acaa5f85868cb,Ignat Korchagin,ignat@cloudflare.com,1708597988,Pablo Neira Ayuso,pablo@netfilter.org,1709160775,140f28e24c7fc3a0fc090e356c0bb6054d3288de,359e54a93ab43d32ee1bff3c2f9f10cb9f6b6e79,"netfilter: nf_tables: allow NFPROTO_INET in nft_(match/target)_validate()

Commit d0009effa886 (""netfilter: nf_tables: validate NFPROTO_* family"") added
some validation of NFPROTO_* families in the nft_compat module"," but it broke
the ability to use legacy iptables modules in dual-stack nftables.

While with legacy iptables one had to independently manage IPv4 and IPv6
tables","[' with nftables it is possible to have dual-stack tables sharing the\nrules. Moreover', ' it was possible to use rules based on legacy iptables\nmatch/target modules in dual-stack nftables.\n\nAs an example', ' the program from [2] creates an INET dual-stack family table\nusing an xt_bpf based rule', ' which looks like the following (the actual output\nwas generated with a patched nft tool as the current nft tool does not parse\ndual stack tables with legacy match rules', ' so consider it for illustrative\npurposes only):\n\ntable inet testfw {\n  chain input {\n    type filter hook prerouting priority filter; policy accept;\n    bytecode counter packets 0 bytes 0 accept\n  }\n}\n\nAfter d0009effa886 (""netfilter: nf_tables: validate NFPROTO_* family"") we get\nEOPNOTSUPP for the above program.\n\nFix this by allowing NFPROTO_INET for nft_(match/target)_validate()', ' but also\nrestrict the functions to classic iptables hooks.\n\nChanges in v3:\n  * clarify that upstream nft will not display such configuration properly and\n    that the output was generated with a patched nft tool\n  * remove example program from commit description and link to it instead\n  * no code changes otherwise\n\nChanges in v2:\n  * restrict nft_(match/target)_validate() to classic iptables hooks\n  * rewrite example program to use unmodified libnftnl\n\nFixes: d0009effa886 (""netfilter: nf_tables: validate NFPROTO_* family"")\nLink: https://lore.kernel.org/all/Zc1PfoWN38UuFJRI@calendula/T/#mc947262582c90fec044c7a3398cc92fac7afea72 [1]\nLink: https://lore.kernel.org/all/20240220145509.53357-1-ignat@cloudflare.com/ [2]\nReported-by: Jordan Griege <jgriege@cloudflare.com>\nSigned-off-by: Ignat Korchagin <ignat@cloudflare.com>\nSigned-off-by: Pablo Neira Ayuso <pablo@netfilter.org>\n', '']",Fix allows NFPROTO_INET use in nft_(match/target)_validate to support dual-stack nftables.,"NFPROTO_INET, dual-stack, nftables",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['tc/netfilter like programs']
b9a62998482fa1488123f690bcacc26fd2351a18,b9a62998482fa1488123f690bcacc26fd2351a18,Alexei Starovoitov,ast@kernel.org,1709156688,Alexei Starovoitov,ast@kernel.org,1709156688,5811a3a6deb3825618a7d1a0577df5170871de2a,e59997d9052599feb17419289f2a57ed300e1dfa 1dad391daef129e01e28206b8d586608ff026548,"Merge branch 'bpf-arm64-use-bpf-prog-pack-allocator-in-bpf-jit'

Puranjay Mohan says:

====================
bpf"," arm64: use BPF prog pack allocator in BPF JIT

Changes in V8 => V9:
V8: https://lore.kernel.org/bpf/20240221145106.105995-1-puranjay12@gmail.com/
1. Rebased on bpf-next/master
2. Added Acked-by: Catalin Marinas <catalin.marinas@arm.com>

Changes in V7 => V8:
V7: https://lore.kernel.org/bpf/20240125133159.85086-1-puranjay12@gmail.com/
1. Rebase on bpf-next/master
2. Fix __text_poke() by removing usage of 'ret' that was never set.

Changes in V6 => V7:
V6: https://lore.kernel.org/all/20240124164917.119997-1-puranjay12@gmail.com/
1. Rebase on bpf-next/master.

Changes in V5 => V6:
V5: https://lore.kernel.org/all/20230908144320.2474-1-puranjay12@gmail.com/
1. Implement a text poke api to reduce code repeatition.
2. Use flush_icache_range() in place of caches_clean_inval_pou() in the
   functions that modify code.
3. Optimize the bpf_jit_free() by not copying the all instructions on
   the rw image to the ro_image

Changes in V4 => v5:
1. Remove the patch for making prog pack allocator portable as it will come
   through the RISCV tree[1].

2. Add a new function aarch64_insn_set() to be used in
   bpf_arch_text_invalidate() for putting illegal instructions after a
   program is removed. The earlier implementation of bpf_arch_text_invalidate()
   was calling aarch64_insn_patch_text_nosync() in a loop and making it slow
   because each call invalidated the cache.

   Here is test_tag now:
   [root@ip-172-31-6-176 bpf]# time ./test_tag
   test_tag: OK (40945 tests)

   real    0m19.695s
   user    0m1.514s
   sys     0m17.841s

   test_tag without these patches:
   [root@ip-172-31-6-176 bpf]# time ./test_tag
   test_tag: OK (40945 tests)

   real    0m21.487s
   user    0m1.647s
   sys     0m19.106s

   test_tag in the previous version was really slow > 2 minutes. see [2]

3. Add cache invalidation in aarch64_insn_copy() so other users can call the
   function without worrying about the cache. Currently only bpf_arch_text_copy()
   is using it","[' but there might be more users in the future.\n\nChanes in V3 => V4: Changes only in 3rd patch\n1. Fix the I-cache maintenance: Clean the data cache and invalidate the i-Cache\n   only *after* the instructions have been copied to the ROX region.\n\nChanes in V2 => V3: Changes only in 3rd patch\n1. Set prog = orig_prog; in the failure path of bpf_jit_binary_pack_finalize()\ncall.\n2. Add comments explaining the usage of the offsets in the exception table.\n\nChanges in v1 => v2:\n1. Make the naming consistent in the 3rd patch:\n   ro_image and image\n   ro_header and header\n   ro_image_ptr and image_ptr\n2. Use names dst/src in place of addr/opcode in second patch.\n3. Add Acked-by: Song Liu <song@kernel.org> in 1st and 2nd patch.\n\nBPF programs currently consume a page each on ARM64. For systems with many BPF\nprograms', ' this adds significant pressure to instruction TLB. High iTLB pressure\nusually causes slow down for the whole system.\n\nSong Liu introduced the BPF prog pack allocator[3] to mitigate the above issue.\nIt packs multiple BPF programs into a single huge page. It is currently only\nenabled for the x86_64 BPF JIT.\n\nThis patch series enables the BPF prog pack allocator for the ARM64 BPF JIT.\n\n====================================================\nPerformance Analysis of prog pack allocator on ARM64\n====================================================\n\nTo test the performance of the BPF prog pack allocator on ARM64', ' a stresser\ntool[4] was built. This tool loads 8 BPF programs on the system and triggers\n5 of them in an infinite loop by doing system calls.\n\nThe runner script starts 20 instances of the above which loads 8*20=160 BPF\nprograms on the system', ' 5*20=100 of which are being constantly triggered.\n\nIn the above environment we try to build Python-3.8.4 and try to find different\niTLB metrics for the compilation done by gcc-12.2.0.\n\nThe source code[5] is  configured with the following command:\n./configure --enable-optimizations --with-ensurepip=install\n\nThen the runner script is executed with the following command:\n./run.sh ""perf stat -e ITLB_WALK', 'L1I_TLB', 'INST_RETIRED', 'iTLB-load-misses -a make -j32""\n\nThis builds Python while 160 BPF programs are loaded and 100 are being constantly\ntriggered and measures iTLB related metrics.\n\nThe output of the above command is discussed below before and after enabling the\nBPF prog pack allocator.\n\nThe tests were run on qemu-system-aarch64 with 32 cpus', ' 4G memory', ' -machine virt', '\n-cpu host', "" and -enable-kvm.\n\nResults\n-------\n\nBefore enabling prog pack allocator:\n------------------------------------\n\nPerformance counter stats for 'system wide':\n\n         333278635      ITLB_WALK\n     6762692976558      L1I_TLB\n    25359571423901      INST_RETIRED\n       15824054789      iTLB-load-misses\n\n     189.029769053 seconds time elapsed\n\nAfter enabling prog pack allocator:\n-----------------------------------\n\nPerformance counter stats for 'system wide':\n\n         190333544      ITLB_WALK\n     6712712386528      L1I_TLB\n    25278233304411      INST_RETIRED\n        5716757866      iTLB-load-misses\n\n     185.392650561 seconds time elapsed\n\nImprovements in metrics\n-----------------------\n\nCompilation time                             ---> 1.92% faster\niTLB-load-misses/Sec (Less is better)        ---> 63.16% decrease\nITLB_WALK/1000 INST_RETIRED (Less is better) ---> 42.71% decrease\nITLB_Walk/L1I_TLB (Less is better)           ---> 42.47% decrease\n\n[1] https://git.kernel.org/pub/scm/linux/kernel/git/riscv/linux.git/commit/?h=for-next&id=20e490adea279d49d57b800475938f5b67926d98\n[2] https://lore.kernel.org/all/CANk7y0gcP3dF2mESLp5JN1+9iDfgtiWRFGqLkCgZD6wby1kQOw@mail.gmail.com/\n[3] https://lore.kernel.org/bpf/20220204185742.271030-1-song@kernel.org/\n[4] https://github.com/puranjaymohan/BPF-Allocator-Bench\n[5] https://www.python.org/ftp/python/3.8.4/Python-3.8.4.tgz\n====================\n\nLink: https://lore.kernel.org/r/20240228141824.119877-1-puranjay12@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",The commit integrates BPF prog pack allocator into BPF JIT for arm64 to improve performance.,"BPF JIT, allocator, arm64",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['tracepoints like programs', 'kprobe/uprobe/ftrace like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1dad391daef129e01e28206b8d586608ff026548,1dad391daef129e01e28206b8d586608ff026548,Puranjay Mohan,puranjay12@gmail.com,1709129904,Alexei Starovoitov,ast@kernel.org,1709156687,5811a3a6deb3825618a7d1a0577df5170871de2a,451c3cab9a65e656c3b3d106831fc02d56b8c34a,bpf," arm64: use bpf_prog_pack for memory management

Use bpf_jit_binary_pack_alloc for memory management of JIT binaries in
ARM64 BPF JIT. The bpf_jit_binary_pack_alloc creates a pair of RW and RX
buffers. The JIT writes the program into the RW buffer. When the JIT is
done","[' the program is copied to the final RX buffer\nwith bpf_jit_binary_pack_finalize.\n\nImplement bpf_arch_text_copy() and bpf_arch_text_invalidate() for ARM64\nJIT as these functions are required by bpf_jit_binary_pack allocator.\n\nSigned-off-by: Puranjay Mohan <puranjay12@gmail.com>\nAcked-by: Song Liu <song@kernel.org>\nAcked-by: Catalin Marinas <catalin.marinas@arm.com>\nLink: https://lore.kernel.org/r/20240228141824.119877-3-puranjay12@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Introduces bpf_prog_pack for efficient memory management of JIT binaries in ARM64 BPF JIT.,"bpf_prog_pack,JIT,ARM64",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e59997d9052599feb17419289f2a57ed300e1dfa,e59997d9052599feb17419289f2a57ed300e1dfa,Alexei Starovoitov,ast@kernel.org,1709070858,Alexei Starovoitov,ast@kernel.org,1709070858,4a75076e5895a08e735de95e9e5c0ba31d21f4c9,2ab256e93249f5ac1da665861aa0f03fb4208d9c 22fc0e80aeb5c0c1377e6c02d7248f8fbf5df7fc,"Merge branch 'bpf-arm64-support-exceptions'

Puranjay Mohan says:

====================
bpf"," arm64: Support Exceptions

Changes in V2->V3:
V2: https://lore.kernel.org/all/20230917000045.56377-1-puranjay12@gmail.com/
- Use unwinder from stacktrace.c rather than open coding the unwind logic.
- Fix a bug in the prologue related to BPF_FP (Xu Kuohai)

Changes in V1->V2:
V1: https://lore.kernel.org/all/20230912233942.6734-1-puranjay12@gmail.com/
- Remove exceptions from DENYLIST.aarch64 as they are supported now.

The base support for exceptions was merged with [1] and it was enabled for
x86-64.

This patch set enables the support on ARM64","[' all sefltests are passing:\n\n# ./test_progs -a exceptions\n#74/1    exceptions/exception_throw_always_1:OK\n#74/2    exceptions/exception_throw_always_2:OK\n#74/3    exceptions/exception_throw_unwind_1:OK\n#74/4    exceptions/exception_throw_unwind_2:OK\n#74/5    exceptions/exception_throw_default:OK\n#74/6    exceptions/exception_throw_default_value:OK\n#74/7    exceptions/exception_tail_call:OK\n#74/8    exceptions/exception_ext:OK\n#74/9    exceptions/exception_ext_mod_cb_runtime:OK\n#74/10   exceptions/exception_throw_subprog:OK\n#74/11   exceptions/exception_assert_nz_gfunc:OK\n#74/12   exceptions/exception_assert_zero_gfunc:OK\n#74/13   exceptions/exception_assert_neg_gfunc:OK\n#74/14   exceptions/exception_assert_pos_gfunc:OK\n#74/15   exceptions/exception_assert_negeq_gfunc:OK\n#74/16   exceptions/exception_assert_poseq_gfunc:OK\n#74/17   exceptions/exception_assert_nz_gfunc_with:OK\n#74/18   exceptions/exception_assert_zero_gfunc_with:OK\n#74/19   exceptions/exception_assert_neg_gfunc_with:OK\n#74/20   exceptions/exception_assert_pos_gfunc_with:OK\n#74/21   exceptions/exception_assert_negeq_gfunc_with:OK\n#74/22   exceptions/exception_assert_poseq_gfunc_with:OK\n#74/23   exceptions/exception_bad_assert_nz_gfunc:OK\n#74/24   exceptions/exception_bad_assert_zero_gfunc:OK\n#74/25   exceptions/exception_bad_assert_neg_gfunc:OK\n#74/26   exceptions/exception_bad_assert_pos_gfunc:OK\n#74/27   exceptions/exception_bad_assert_negeq_gfunc:OK\n#74/28   exceptions/exception_bad_assert_poseq_gfunc:OK\n#74/29   exceptions/exception_bad_assert_nz_gfunc_with:OK\n#74/30   exceptions/exception_bad_assert_zero_gfunc_with:OK\n#74/31   exceptions/exception_bad_assert_neg_gfunc_with:OK\n#74/32   exceptions/exception_bad_assert_pos_gfunc_with:OK\n#74/33   exceptions/exception_bad_assert_negeq_gfunc_with:OK\n#74/34   exceptions/exception_bad_assert_poseq_gfunc_with:OK\n#74/35   exceptions/exception_assert_range:OK\n#74/36   exceptions/exception_assert_range_with:OK\n#74/37   exceptions/exception_bad_assert_range:OK\n#74/38   exceptions/exception_bad_assert_range_with:OK\n#74/39   exceptions/non-throwing fentry -> exception_cb:OK\n#74/40   exceptions/throwing fentry -> exception_cb:OK\n#74/41   exceptions/non-throwing fexit -> exception_cb:OK\n#74/42   exceptions/throwing fexit -> exception_cb:OK\n#74/43   exceptions/throwing extension (with custom cb) -> exception_cb:OK\n#74/44   exceptions/throwing extension -> global func in exception_cb:OK\n#74/45   exceptions/exception_ext_mod_cb_runtime:OK\n#74/46   exceptions/throwing extension (with custom cb) -> global func in exception_cb:OK\n#74/47   exceptions/exception_ext:OK\n#74/48   exceptions/non-throwing fentry -> non-throwing subprog:OK\n#74/49   exceptions/throwing fentry -> non-throwing subprog:OK\n#74/50   exceptions/non-throwing fentry -> throwing subprog:OK\n#74/51   exceptions/throwing fentry -> throwing subprog:OK\n#74/52   exceptions/non-throwing fexit -> non-throwing subprog:OK\n#74/53   exceptions/throwing fexit -> non-throwing subprog:OK\n#74/54   exceptions/non-throwing fexit -> throwing subprog:OK\n#74/55   exceptions/throwing fexit -> throwing subprog:OK\n#74/56   exceptions/non-throwing fmod_ret -> non-throwing subprog:OK\n#74/57   exceptions/non-throwing fmod_ret -> non-throwing global subprog:OK\n#74/58   exceptions/non-throwing extension -> non-throwing subprog:OK\n#74/59   exceptions/non-throwing extension -> throwing subprog:OK\n#74/60   exceptions/non-throwing extension -> non-throwing subprog:OK\n#74/61   exceptions/non-throwing extension -> throwing global subprog:OK\n#74/62   exceptions/throwing extension -> throwing global subprog:OK\n#74/63   exceptions/throwing extension -> non-throwing global subprog:OK\n#74/64   exceptions/non-throwing extension -> main subprog:OK\n#74/65   exceptions/throwing extension -> main subprog:OK\n#74/66   exceptions/reject_exception_cb_type_1:OK\n#74/67   exceptions/reject_exception_cb_type_2:OK\n#74/68   exceptions/reject_exception_cb_type_3:OK\n#74/69   exceptions/reject_exception_cb_type_4:OK\n#74/70   exceptions/reject_async_callback_throw:OK\n#74/71   exceptions/reject_with_lock:OK\n#74/72   exceptions/reject_subprog_with_lock:OK\n#74/73   exceptions/reject_with_rcu_read_lock:OK\n#74/74   exceptions/reject_subprog_with_rcu_read_lock:OK\n#74/75   exceptions/reject_with_rbtree_add_throw:OK\n#74/76   exceptions/reject_with_reference:OK\n#74/77   exceptions/reject_with_cb_reference:OK\n#74/78   exceptions/reject_with_cb:OK\n#74/79   exceptions/reject_with_subprog_reference:OK\n#74/80   exceptions/reject_throwing_exception_cb:OK\n#74/81   exceptions/reject_exception_cb_call_global_func:OK\n#74/82   exceptions/reject_exception_cb_call_static_func:OK\n#74/83   exceptions/reject_multiple_exception_cb:OK\n#74/84   exceptions/reject_exception_throw_cb:OK\n#74/85   exceptions/reject_exception_throw_cb_diff:OK\n#74/86   exceptions/reject_set_exception_cb_bad_ret1:OK\n#74/87   exceptions/reject_set_exception_cb_bad_ret2:OK\n#74/88   exceptions/check_assert_eq_int_min:OK\n#74/89   exceptions/check_assert_eq_int_max:OK\n#74/90   exceptions/check_assert_eq_zero:OK\n#74/91   exceptions/check_assert_eq_llong_min:OK\n#74/92   exceptions/check_assert_eq_llong_max:OK\n#74/93   exceptions/check_assert_lt_pos:OK\n#74/94   exceptions/check_assert_lt_zero:OK\n#74/95   exceptions/check_assert_lt_neg:OK\n#74/96   exceptions/check_assert_le_pos:OK\n#74/97   exceptions/check_assert_le_zero:OK\n#74/98   exceptions/check_assert_le_neg:OK\n#74/99   exceptions/check_assert_gt_pos:OK\n#74/100  exceptions/check_assert_gt_zero:OK\n#74/101  exceptions/check_assert_gt_neg:OK\n#74/102  exceptions/check_assert_ge_pos:OK\n#74/103  exceptions/check_assert_ge_zero:OK\n#74/104  exceptions/check_assert_ge_neg:OK\n#74/105  exceptions/check_assert_range_s64:OK\n#74/106  exceptions/check_assert_range_u64:OK\n#74/107  exceptions/check_assert_single_range_s64:OK\n#74/108  exceptions/check_assert_single_range_u64:OK\n#74/109  exceptions/check_assert_generic:OK\n#74/110  exceptions/check_assert_with_return:OK\n#74      exceptions:OK\nSummary: 1/110 PASSED', ' 0 SKIPPED', ' 0 FAILED\n\n[1] https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next.git/commit/?h=for-next&id=ec6f1b4db95b7eedb3fe85f4f14e08fa0e9281c3\n====================\n\nLink: https://lore.kernel.org/r/20240201125225.72796-1-puranjay12@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Enable exception support for eBPF on ARM64 architecture.,"ARM64, exceptions, support",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
22fc0e80aeb5c0c1377e6c02d7248f8fbf5df7fc,22fc0e80aeb5c0c1377e6c02d7248f8fbf5df7fc,Puranjay Mohan,puranjay12@gmail.com,1706791945,Alexei Starovoitov,ast@kernel.org,1709070857,4a75076e5895a08e735de95e9e5c0ba31d21f4c9,e74cb1b422131615a0fe3bedd4ab2e38b7442d10,bpf," arm64: support exceptions

The prologue generation code has been modified to make the callback
program use the stack of the program marked as exception boundary where
callee-saved registers are already pushed.

As the bpf_throw function never returns","[' if it clobbers any callee-saved\nregisters', ' they would remain clobbered. So', ' the prologue of the\nexception-boundary program is modified to push R23 and R24 as well', '\nwhich the callback will then recover in its epilogue.\n\nThe Procedure Call Standard for the Arm 64-bit Architecture[1] states\nthat registers r19 to r28 should be saved by the callee. BPF programs on\nARM64 already save all callee-saved registers except r23 and r24. This\npatch adds an instruction in prologue of the  program to save these\ntwo registers and another instruction in the epilogue to recover them.\n\nThese extra instructions are only added if bpf_throw() is used. Otherwise\nthe emitted prologue/epilogue remains unchanged.\n\n[1] https://github.com/ARM-software/abi-aa/blob/main/aapcs64/aapcs64.rst\n\nSigned-off-by: Puranjay Mohan <puranjay12@gmail.com>\nLink: https://lore.kernel.org/r/20240201125225.72796-3-puranjay12@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Modified prologue generation code to use stack of exception boundary programs for callbacks.,"prologue,stack,exception",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e74cb1b422131615a0fe3bedd4ab2e38b7442d10,e74cb1b422131615a0fe3bedd4ab2e38b7442d10,Puranjay Mohan,puranjay12@gmail.com,1706791944,Alexei Starovoitov,ast@kernel.org,1709070857,1ff1bbf0dfae6441b61ff0cdae9f70f2cb1de7fa,2ab256e93249f5ac1da665861aa0f03fb4208d9c,"arm64: stacktrace: Implement arch_bpf_stack_walk() for the BPF JIT

This will be used by bpf_throw() to unwind till the program marked as
exception boundary and run the callback with the stack of the main
program.

This is required for supporting BPF exceptions on ARM64.

Signed-off-by: Puranjay Mohan <puranjay12@gmail.com>
Acked-by: Catalin Marinas <catalin.marinas@arm.com>
Link: https://lore.kernel.org/r/20240201125225.72796-2-puranjay12@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Implement arch_bpf_stack_walk for ARM64 BPF JIT to support BPF exceptions.,"ARM64,BPF JIT,stacktrace",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
529d5818a3bb0272ced031e022e4b41d6410a4da,529d5818a3bb0272ced031e022e4b41d6410a4da,Arnaldo Carvalho de Melo,acme@kernel.org,1708789677,Namhyung Kim,namhyung@kernel.org,1708964168,2e2e0dc4452314f1e01524139e58907db983573a,c2bd08ba20a57e0ed55777a9d1724647a0f53e88,"perf bpf: Check that the minimal vmlinux.h installed is the latest one

When building BPF skels perf will", by default,"[' install a minimalistic\nvmlinux.h file with the types needed by the BPF skels in\ntools/perf/util/bpf_skel/ in its build directory.\n\nWhen 29d16de26df17e94 (""perf augmented_raw_syscalls.bpf: Move \'struct\ntimespec64\' to vmlinux.h"") was added', ' a type used in the augmented_raw_syscalls\nBPF skel', "" 'struct timespec64' was not found when building from a pre-existing\nbuild directory"", "" because the vmlinux.h there didn't contain that type"", '\nending up with this error', "" spotted in linux-next:\n\n    CLANG   /tmp/build/perf-tools-next/util/bpf_skel/.tmp/augmented_raw_syscalls.bpf.o\n  util/bpf_skel/augmented_raw_syscalls.bpf.c:329:15: error: invalid application of 'sizeof' to an incomplete type 'struct timespec64'\n    329 |         __u32 size = sizeof(struct timespec64);\n        |                      ^     ~~~~~~~~~~~~~~~~~~~\n  util/bpf_skel/augmented_raw_syscalls.bpf.c:329:29: note: forward declaration of 'struct timespec64'\n    329 |         __u32 size = sizeof(struct timespec64);\n        |                                    ^\n  util/bpf_skel/augmented_raw_syscalls.bpf.c:350:15: error: invalid application of 'sizeof' to an incomplete type 'struct timespec64'\n    350 |         __u32 size = sizeof(struct timespec64);\n        |                      ^     ~~~~~~~~~~~~~~~~~~~\n  util/bpf_skel/augmented_raw_syscalls.bpf.c:350:29: note: forward declaration of 'struct timespec64'\n    350 |         __u32 size = sizeof(struct timespec64);\n        |                                    ^\n  2 errors generated.\n  make[2]: *** [Makefile.perf:1158: /tmp/build/perf-tools-next/util/bpf_skel/.tmp/augmented_raw_syscalls.bpf.o] Error 1\n  make[2]: *** Waiting for unfinished jobs....\n  make[1]: *** [Makefile.perf:261: sub-make] Error 2\n  make: *** [Makefile:113: install-bin] Error 2\n  make: Leaving directory '/home/acme/git/perf-tools-next/tools/perf'\n\nSo add a Makefile dependency (Namhyung's suggestion) to make sure that\nthe new tools/perf/util/bpf_skel/vmlinux/vmlinux.h minimal vmlinux is\nupdated in the build directory"", ' providing the moved \'struct timespec64\'\ntype.\n\nFixes: 29d16de26df17e94 (""perf augmented_raw_syscalls.bpf: Move \'struct timespec64\' to vmlinux.h"")\nReported-by: Stephen Rothwell <sfr@canb.auug.org.au>\nReviewed-by: Ian Rogers <irogers@google.com>\nSuggested-by: Namhyung Kim <namhyung@kernel.org>\nSigned-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>\nSigned-off-by: Namhyung Kim <namhyung@kernel.org>\nLink: https://lore.kernel.org/r/ZdoPrWg-qYFpBJbz@x1\n', '']",Ensure the latest minimal vmlinux.h is checked when building BPF skeletons in perf.,"perf,vmlinux,BPF",It's a build system or CI/CD change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The bpftool utility,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2ab256e93249f5ac1da665861aa0f03fb4208d9c,2ab256e93249f5ac1da665861aa0f03fb4208d9c,Benjamin Tissoires,bentiss@kernel.org,1708532719,Alexei Starovoitov,ast@kernel.org,1708652933,8eabe7f48f894fd2af17dadebbe9eacad98ebfa5,dfe6625df48ec54c6dc9b86d361f26962d09de88,"bpf: add is_async_callback_calling_insn() helper

Currently we have a special case for BPF_FUNC_timer_set_callback","
let's introduce a helper we can extend for the kfunc that will come in
a later patch

Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
Link: https://lore.kernel.org/r/20240221-hid-bpf-sleepable-v3-3-1fb378ca6301@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Add is_async_callback_calling_insn() helper to extend functionality for future kfuncs.,"helper, kfunc, async",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
dfe6625df48ec54c6dc9b86d361f26962d09de88,dfe6625df48ec54c6dc9b86d361f26962d09de88,Benjamin Tissoires,bentiss@kernel.org,1708532718,Alexei Starovoitov,ast@kernel.org,1708652835,999be8e21d533dc7a8dc5d7c39a142a4ff392d3e,55bad79e33aeb670317290158a4b2ff71cdc8380,"bpf: introduce in_sleepable() helper

No code change"," but it'll allow to have only one place to change
everything when we add in_sleepable in cur_state.

Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
Link: https://lore.kernel.org/r/20240221-hid-bpf-sleepable-v3-2-1fb378ca6301@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Introduces the in_sleepable() helper function for eBPF.,"in_sleepable, helper, eBPF",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
55bad79e33aeb670317290158a4b2ff71cdc8380,55bad79e33aeb670317290158a4b2ff71cdc8380,Benjamin Tissoires,bentiss@kernel.org,1708532717,Alexei Starovoitov,ast@kernel.org,1708652543,57e5032537f1bcceb4e98608df9ac6dee06f19a6,63c7049ef9d642ab60bb1eccf75b29dc40277664,"bpf: allow more maps in sleepable bpf programs

These 2 maps types are required for HID-BPF when a user wants to do
IO with a device from a sleepable tracing point.

Allowing BPF_MAP_TYPE_QUEUE (and therefore BPF_MAP_TYPE_STACK) allows
for a BPF program to prepare from an IRQ the list of HID commands to send
back to the device and then these commands can be retrieved from the
sleepable trace point.

Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
Link: https://lore.kernel.org/r/20240221-hid-bpf-sleepable-v3-1-1fb378ca6301@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Enable additional map types in sleepable BPF programs for HID interaction.,"sleepable,HID,MAP_TYPE_QUEUE",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['tracepoints like programs', 'HID driver like programs']"
63c7049ef9d642ab60bb1eccf75b29dc40277664,63c7049ef9d642ab60bb1eccf75b29dc40277664,Martin KaFai Lau,martin.lau@kernel.org,1708629580,Martin KaFai Lau,martin.lau@kernel.org,1708633602,5c5951094ff327b9e52343e25707d5cc944f2fdb,58fd62e0aa50fdd20bc41a01e787001f3af8a925 e9bbda13a7b876451285ab15fb600b809e5e2290,"Merge branch 'Check cfi_stubs before registering a struct_ops type.'

Kui-Feng Lee says:

====================
Recently", st_ops->cfi_stubs was introduced. However,"[' the upcoming new\nstruct_ops support (e.g. sched_ext) is not aware of this and does not\nprovide its own cfi_stubs. The kernel ends up NULL dereferencing the\nst_ops->cfi_stubs.\n\nConsidering struct_ops supports kernel module now', ' this NULL check\nis necessary. This patch set is to reject struct_ops registration\nthat does not provide a cfi_stubs.\n\nChanges from v4:\n\n - Remove changes of check_member.\n\n - Remove checks of the pointers in cfi_stubs[].\n\nChanges from v3:\n\n - Remove CFI stub function for get_info.\n\n - Allow passing NULL prog arg to check_member of struct\n   bpf_struct_ops type.\n\n - Call check_member to determines if a CFI stub function should be\n   defined for an operator.\n\nChanges from v2:\n\n - Add a stub function for get_info of struct tcp_congestion_ops.\n\nChanges from v1:\n\n - Check *(void **)(cfi_stubs + moff) to make sure stub functions are\n   provided for every operator.\n\n - Add a test case to ensure that struct_ops rejects incomplete\n   cfi_stub.\n\nv4: https://lore.kernel.org/all/20240221075213.2071454-1-thinker.li@gmail.com/\nv3: https://lore.kernel.org/all/20240216193434.735874-1-thinker.li@gmail.com/\nv2: https://lore.kernel.org/all/20240216020350.2061373-1-thinker.li@gmail.com/\nv1: https://lore.kernel.org/all/20240215022401.1882010-1-thinker.li@gmail.com/\n====================\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",This commit merges changes to check cfi_stubs before registering a struct_ops type.,"cfi_stubs, struct_ops, merge",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
e9bbda13a7b876451285ab15fb600b809e5e2290,e9bbda13a7b876451285ab15fb600b809e5e2290,Kui-Feng Lee,thinker.li@gmail.com,1708567865,Martin KaFai Lau,martin.lau@kernel.org,1708633601,5c5951094ff327b9e52343e25707d5cc944f2fdb,3e0008336ae3153fb89b1a15bb877ddd38680fe6,"selftests/bpf: Test case for lacking CFI stub functions.

Ensure struct_ops rejects the registration of struct_ops types without
proper CFI stub functions.

bpf_test_no_cfi.ko is a module that attempts to register a struct_ops type
called ""bpf_test_no_cfi_ops"" with cfi_stubs of NULL and non-NULL value.
The NULL one should fail"," and the non-NULL one should succeed. The module
can only be loaded successfully if these registrations yield the expected
results.

Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240222021105.1180475-3-thinker.li@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Add a test case for struct_ops registration with CFI stub function validation in selftests/bpf.,"test case, struct_ops, CFI",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3e0008336ae3153fb89b1a15bb877ddd38680fe6,3e0008336ae3153fb89b1a15bb877ddd38680fe6,Kui-Feng Lee,thinker.li@gmail.com,1708567864,Martin KaFai Lau,martin.lau@kernel.org,1708633600,8c45e2221acca5756299cd79561305fa71569755,58fd62e0aa50fdd20bc41a01e787001f3af8a925,"bpf: Check cfi_stubs before registering a struct_ops type.

Recently", st_ops->cfi_stubs was introduced. However,"[' the upcoming new\nstruct_ops support (e.g. sched_ext) is not aware of this and does not\nprovide its own cfi_stubs. The kernel ends up NULL dereferencing the\nst_ops->cfi_stubs.\n\nConsidering struct_ops supports kernel module now', ' this NULL check\nis necessary. This patch is to reject struct_ops registration\nthat does not provide a cfi_stubs.\n\nSigned-off-by: Kui-Feng Lee <thinker.li@gmail.com>\nLink: https://lore.kernel.org/r/20240222021105.1180475-2-thinker.li@gmail.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",The commit ensures cfi_stubs are checked before registering a struct_ops type in the BPF subsystem.,"cfi_stubs, struct_ops, register",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0827a1fb143fae588cb6f5b9a97c405d6c2ddec9,0827a1fb143fae588cb6f5b9a97c405d6c2ddec9,Chengming Zhou,zhouchengming@bytedance.com,1707015960,Andrew Morton,akpm@linux-foundation.org,1708626294,76de3ff51d3ad34fbc26d8743134ce1b383d4fd9,f9c0f1c32cb568e16ef0676d8e7827a3ad443742,"mm/zswap: invalidate zswap entry when swap entry free

During testing I found there are some times the zswap_writeback_entry()
return -ENOMEM"," which is not we expected:

bpftrace -e 'kr:zswap_writeback_entry {@[(int32)retval]=count()}'
@[-12]: 1563
@[0]: 277221

The reason is that __read_swap_cache_async() return NULL because
swapcache_prepare() failed.  The reason is that we won't invalidate zswap
entry when swap entry freed to the per-cpu pool","[' these zswap entries are\nstill on the zswap tree and lru list.\n\nThis patch moves the invalidation ahead to when swap entry freed to the\nper-cpu pool', "" since there is no any benefit to leave trashy zswap entry on\nthe tree and lru list.\n\nWith this patch:\nbpftrace -e 'kr:zswap_writeback_entry {@[(int32)retval]=count()}'\n@[0]: 259744\n\nNote: large folio can't have zswap entry for now"", "" so don't bother\nto add zswap entry invalidation in the large folio swap free path.\n\nLink: https://lkml.kernel.org/r/20240201-b4-zswap-invalidate-entry-v2-2-99d4084260a0@bytedance.com\nSigned-off-by: Chengming Zhou <zhouchengming@bytedance.com>\nReviewed-by: Nhat Pham <nphamcs@gmail.com>\nAcked-by: Johannes Weiner <hannes@cmpxchg.org>\nAcked-by: Yosry Ahmed <yosryahmed@google.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\n"", '']",The commit fixes an issue where zswap entries are not invalidated when swap entries are freed.,"zswap, invalidate, swap",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['other']
f9c0f1c32cb568e16ef0676d8e7827a3ad443742,f9c0f1c32cb568e16ef0676d8e7827a3ad443742,Chengming Zhou,zhouchengming@bytedance.com,1707015959,Andrew Morton,akpm@linux-foundation.org,1708626294,885052a9087ad575d314c256f8c262d2bdf8cca5,e374ae2be2f7cb4aad46e17e3fa5da7bbb0d2a09,"mm/zswap: add more comments in shrink_memcg_cb()

Patch series ""mm/zswap: optimize zswap lru list"""," v2.

This series is motivated when observe the zswap lru list shrinking","["" noted\nthere are some unexpected cases in zswap_writeback_entry().\n\nbpftrace -e 'kr:zswap_writeback_entry {@[(int32)retval]=count()}'\n\nThere are some -ENOMEM because when the swap entry is freed to per-cpu\nswap pool"", "" it doesn't invalidate/drop zswap entry.  Then the shrinker\nencounter these trashy zswap entries"", "" it can't be reclaimed and return\n-ENOMEM.\n\nSo move the invalidation ahead to when swap entry freed to the per-cpu\nswap pool"", ' since there is no any benefit to leave trashy zswap entries on\nthe zswap tree and lru list.\n\nAnother case is -EEXIST', ' which is seen more in the case of\n!zswap_exclusive_loads_enabled', "" in which case the swapin folio will leave\ncompressed copy on the tree and lru list.  And it can't be reclaimed until\nthe folio is removed from swapcache.\n\nChanging to zswap_exclusive_loads_enabled mode will invalidate when folio\nswapin"", ' which has its own drawback if that folio is still clean in\nswapcache and swapout again', ' we need to compress it again.  Please see the\ncommit for details on why we choose exclusive load as the default for\nzswap.\n\nAnother optimization for -EEXIST is that we add LRU_STOP to support\nterminating the shrinking process to avoid evicting warmer region.\n\nTesting using kernel build in tmpfs', ' one 50GB swapfile and\nzswap shrinker_enabled', ' with memory.max set to 2GB.\n\n                mm-unstable   zswap-optimize\nreal               63.90s       63.25s\nuser             1064.05s     1063.40s\nsys               292.32s      270.94s\n\nThe main optimization is in sys cpu', ' about 7% improvement.\n\n\nThis patch (of 6):\n\nAdd more comments in shrink_memcg_cb() to describe the deref dance which\nis implemented to fix race problem between lru writeback and swapoff', ' and\nthe reason why we rotate the entry at the beginning.\n\nAlso fix the stale comments in zswap_writeback_entry()', ' and add more\ncomments to state that we only deref the tree after we get the swapcache\nreference.\n\nLink: https://lkml.kernel.org/r/20240201-b4-zswap-invalidate-entry-v2-0-99d4084260a0@bytedance.com\nLink: https://lkml.kernel.org/r/20240201-b4-zswap-invalidate-entry-v2-1-99d4084260a0@bytedance.com\nSigned-off-by: Johannes Weiner <hannes@cmpxchg.org>\nSigned-off-by: Chengming Zhou <zhouchengming@bytedance.com>\nSuggested-by: Yosry Ahmed <yosryahmed@google.com>\nSuggested-by: Johannes Weiner <hannes@cmpxchg.org>\nAcked-by: Yosry Ahmed <yosryahmed@google.com>\nReviewed-by: Nhat Pham <nphamcs@gmail.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\n', '']",Added comments in shrink_memcg_cb() function related to zswap lru list.,"comments, zswap, lru",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
58fd62e0aa50fdd20bc41a01e787001f3af8a925,58fd62e0aa50fdd20bc41a01e787001f3af8a925,Martin Kelly,martin.kelly@crowdstrike.com,1708550318,Martin KaFai Lau,martin.lau@kernel.org,1708626278,1fb68a2bc562186287c461a7c1382697e8e19b69,89ee838130f470afcd02b30ca868f236a3f3b1d2,"bpf: Clarify batch lookup/lookup_and_delete semantics

The batch lookup and lookup_and_delete APIs have two parameters","
in_batch and out_batch","[' to facilitate iterative\nlookup/lookup_and_deletion operations for supported maps. Except NULL\nfor in_batch at the start of these two batch operations', ' both parameters\nneed to point to memory equal or larger than the respective map key\nsize', ' except for various hashmaps (hash', ' percpu_hash', ' lru_hash', '\nlru_percpu_hash) where the in_batch/out_batch memory size should be\nat least 4 bytes.\n\nDocument these semantics to clarify the API.\n\nSigned-off-by: Martin Kelly <martin.kelly@crowdstrike.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240221211838.1241578-1-martin.kelly@crowdstrike.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",The commit clarifies the semantics of batch lookup and lookup_and_delete APIs in eBPF.,"batch,lookup,APIs",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6714ebb922ab15a209dfc3c1ed29d4bb0abc9f02,6714ebb922ab15a209dfc3c1ed29d4bb0abc9f02,Linus Torvalds,torvalds@linux-foundation.org,1708624678,Linus Torvalds,torvalds@linux-foundation.org,1708624678,4c8c92b7a4ded99e9ad8f66c2d369032825d81ee,efa80dcbb7a3ecc4a1b2f54624c49b5a612f92b3 359e54a93ab43d32ee1bff3c2f9f10cb9f6b6e79,"Merge tag 'net-6.8.0-rc6' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Paolo Abeni:
 ""Including fixes from bpf and netfilter.

  Current release - regressions:

   - af_unix: fix another unix GC hangup

  Previous releases - regressions:

   - core: fix a possible AF_UNIX deadlock

   - bpf: fix NULL pointer dereference in sk_psock_verdict_data_ready()

   - netfilter: nft_flow_offload: release dst in case direct xmit path
     is used

   - bridge: switchdev: ensure MDB events are delivered exactly once

   - l2tp: pass correct message length to ip6_append_data

   - dccp/tcp: unhash sk from ehash for tb2 alloc failure after
     check_estalblished()

   - tls: fixes for record type handling with PEEK

   - devlink: fix possible use-after-free and memory leaks in
     devlink_init()

  Previous releases - always broken:

   - bpf: fix an oops when attempting to read the vsyscall page through
     bpf_probe_read_kernel

   - sched: act_mirred: use the backlog for mirred ingress

   - netfilter: nft_flow_offload: fix dst refcount underflow

   - ipv6: sr: fix possible use-after-free and null-ptr-deref

   - mptcp: fix several data races

   - phonet: take correct lock to peek at the RX queue

  Misc:

   - handful of fixes and reliability improvements for selftests""

* tag 'net-6.8.0-rc6' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (72 commits)
  l2tp: pass correct message length to ip6_append_data
  net: phy: realtek: Fix rtl8211f_config_init() for RTL8211F(D)(I)-VD-CG PHY
  selftests: ioam: refactoring to align with the fix
  Fix write to cloned skb in ipv6_hop_ioam()
  phonet/pep: fix racy skb_queue_empty() use
  phonet: take correct lock to peek at the RX queue
  net: sparx5: Add spinlock for frame transmission from CPU
  net/sched: flower: Add lock protection when remove filter handle
  devlink: fix port dump cmd type
  net: stmmac: Fix EST offset for dwmac 5.10
  tools: ynl: don't leak mcast_groups on init error
  tools: ynl: make sure we always pass yarg to mnl_cb_run
  net: mctp: put sock on tag allocation failure
  netfilter: nf_tables: use kzalloc for hook allocation
  netfilter: nf_tables: register hooks last when adding new chain/flowtable
  netfilter: nft_flow_offload: release dst in case direct xmit path is used
  netfilter: nft_flow_offload: reset dst in route object after setting up flow
  netfilter: nf_tables: set dormant flag on hook register failure
  selftests: tls: add test for peeking past a record of a different type
  selftests: tls: add test for merging of same-type control messages
  ...
",,Merge various networking and BPF-related fixes for current and previous Linux kernel releases.,"networking,fixed,regressions",It's a bug fix.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
89ee838130f470afcd02b30ca868f236a3f3b1d2,89ee838130f470afcd02b30ca868f236a3f3b1d2,Dave Thaler,dthaler1968@googlemail.com,1708538059,Alexei Starovoitov,ast@kernel.org,1708621909,601d5b8af76dcb769c9a5331cf35231d458422d3,c1bb68f6b2f6be5297c5fbad5caebf67d0dd3034,bpf," docs: specify which BPF_ABS and BPF_IND fields were zero

Specifying which fields were unused allows IANA to only list as deprecated
instructions that were actually used","[' leaving the rest as unassigned and\npossibly available for future use for something else.\n\nSigned-off-by: Dave Thaler <dthaler1968@gmail.com>\nAcked-by: David Vernet <void@manifault.com>\nLink: https://lore.kernel.org/r/20240221175419.16843-1-dthaler1968@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit specifies unused BPF_ABS and BPF_IND fields allowing IANA to list deprecated instructions accurately.,"BPF_ABS,BPF_IND,deprecated",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),"[""It's not related to any of the above.""]"
c1bb68f6b2f6be5297c5fbad5caebf67d0dd3034,c1bb68f6b2f6be5297c5fbad5caebf67d0dd3034,Dave Thaler,dthaler1968@googlemail.com,1708536935,Alexei Starovoitov,ast@kernel.org,1708621657,35984a7f955038cff0e43701f069beb5a5adeb19,8425b6eb51460ef429920b2ee7e2b0881d4e23c5,bpf," docs: Fix typos in instruction-set.rst

* ""BPF ADD"" should be ""BPF_ADD"".
* ""src"" should be ""src_reg"" in several places.  The latter is the field name
  in the instruction.  The former refers to the value of the register","["" or the\n  immediate.\n* Add '' around field names in one sentence"", ' for consistency with the rest\n  of the document.\n\nSigned-off-by: Dave Thaler <dthaler1968@gmail.com>\nAcked-by: David Vernet <void@manifault.com>\nLink: https://lore.kernel.org/r/20240221173535.16601-1-dthaler1968@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix typos in the eBPF instruction-set documentation regarding field names.,"BPF_ADD,src_reg,typos",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8425b6eb51460ef429920b2ee7e2b0881d4e23c5,8425b6eb51460ef429920b2ee7e2b0881d4e23c5,Alexei Starovoitov,ast@kernel.org,1708620375,Alexei Starovoitov,ast@kernel.org,1708620375,d550154aa14ebbfe7ad0b361f808c2366fbdd9a3,a3c70a3cf11eb4b6409afc2cce1a3747e1dfe96f b546b57526953be2981113171ed586c4c50b1b0a,"Merge branch 'selftests-bpf-reduce-tcp_custom_syncookie-verification-complexity'

Eduard Zingerman says:

====================
selftests/bpf: reduce tcp_custom_syncookie verification complexity

Thread [0] discusses a fix for bpf_loop() handling bug.
That change makes tcp_custom_syncookie test too complex to verify.
The fix discussed in [0] would be sent via 'bpf' tree","
tcp_custom_syncookie test is not in 'bpf' tree yet.
As agreed in [0] I'm sending syncookie test update separately.

[0] https://lore.kernel.org/bpf/20240216150334.31937-1-eddyz87@gmail.com/
====================

Link: https://lore.kernel.org/r/20240222150300.14909-1-eddyz87@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Optimize the tcp_custom_syncookie test in selftests/bpf by reducing its verification complexity.,"tcp_custom_syncookie, selftests, complexity",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
b546b57526953be2981113171ed586c4c50b1b0a,b546b57526953be2981113171ed586c4c50b1b0a,Eduard Zingerman,eddyz87@gmail.com,1708614180,Alexei Starovoitov,ast@kernel.org,1708620375,d550154aa14ebbfe7ad0b361f808c2366fbdd9a3,a3c70a3cf11eb4b6409afc2cce1a3747e1dfe96f,"selftests/bpf: update tcp_custom_syncookie to use scalar packet offset

This commit updates tcp_custom_syncookie.c:tcp_parse_option() to use
explicit packet offset (ctx->off) for packet access instead of ever
moving pointer (ctx->ptr)"," this reduces verification complexity:
- the tcp_parse_option() is passed as a callback to bpf_loop();
- suppose a checkpoint is created each time at function entry;
- the ctx->ptr is tracked by verifier as PTR_TO_PACKET;
- the ctx->ptr is incremented in tcp_parse_option()","[""\n  thus umax_value field tracked for it is incremented as well;\n- on each next iteration of tcp_parse_option()\n  checkpoint from a previous iteration can't be reused\n  for state pruning"", ' because PTR_TO_PACKET registers are\n  considered equivalent only if old->umax_value >= cur->umax_value;\n- on the other hand', ' the ctx->off is a SCALAR', '\n  subject to widen_imprecise_scalars();\n- it\'s exact bounds are eventually forgotten and it is tracked as\n  unknown scalar at entry to tcp_parse_option();\n- hence checkpoints created at the start of the function eventually\n  converge.\n\nThe change is similar to one applied in [0] to xdp_synproxy_kern.c.\n\nComparing before and after with veristat yields following results:\n\nFile                             Insns (A)  Insns (B)  Insns      (DIFF)\n-------------------------------  ---------  ---------  -----------------\ntest_tcp_custom_syncookie.bpf.o     466657      12423  -454234 (-97.34%)\n\n[0] commit 977bc146d4eb (""selftests/bpf: track tcp payload offset as scalar in xdp_synproxy"")\n\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20240222150300.14909-2-eddyz87@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit updates tcp_custom_syncookie to use scalar packet offset in tcp_parse_option for better verification.,"selftests,bpf,offset",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tc/netfilter like programs']
fdcd4467ba154465402432888f9ba9ad2122a37a,fdcd4467ba154465402432888f9ba9ad2122a37a,Paolo Abeni,pabeni@redhat.com,1708592686,Paolo Abeni,pabeni@redhat.com,1708592687,0298a166b0c60212e58c72a5351a6fd1e58d1474,3489182b11d35f1944c1245fc9c4867cf622c50f 4cd12c6065dfcdeba10f49949bffcf383b3952d8,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Daniel Borkmann says:

====================
pull-request: bpf 2024-02-22

The following pull-request contains BPF updates for your *net* tree.

We've added 11 non-merge commits during the last 24 day(s) which contain
a total of 15 files changed", 217 insertions(+),"[' 17 deletions(-).\n\nThe main changes are:\n\n1) Fix a syzkaller-triggered oops when attempting to read the vsyscall\n   page through bpf_probe_read_kernel and friends', ' from Hou Tao.\n\n2) Fix a kernel panic due to uninitialized iter position pointer in\n   bpf_iter_task', ' from Yafang Shao.\n\n3) Fix a race between bpf_timer_cancel_and_free and bpf_timer_cancel', '\n   from Martin KaFai Lau.\n\n4) Fix a xsk warning in skb_add_rx_frag() (under CONFIG_DEBUG_NET)\n   due to incorrect truesize accounting', ' from Sebastian Andrzej Siewior.\n\n5) Fix a NULL pointer dereference in sk_psock_verdict_data_ready', '\n   from Shigeru Yoshida.\n\n6) Fix a resolve_btfids warning when bpf_cpumask symbol cannot be\n   resolved', "" from Hari Bathini.\n\nbpf-for-netdev\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  bpf"", ' sockmap: Fix NULL pointer dereference in sk_psock_verdict_data_ready()\n  selftests/bpf: Add negtive test cases for task iter\n  bpf: Fix an issue due to uninitialized bpf_iter_task\n  selftests/bpf: Test racing between bpf_timer_cancel_and_free and bpf_timer_cancel\n  bpf: Fix racing between bpf_timer_cancel_and_free and bpf_timer_cancel\n  selftest/bpf: Test the read of vsyscall page under x86-64\n  x86/mm: Disallow vsyscall page read for copy_from_kernel_nofault()\n  x86/mm: Move is_vsyscall_vaddr() into asm/vsyscall.h\n  bpf', ' scripts: Correct GPL license name\n  xsk: Add truesize to skb_add_rx_frag().\n  bpf: Fix warning for bpf_cpumask in verifier\n====================\n\nLink: https://lore.kernel.org/r/20240221231826.1404-1-daniel@iogearbox.net\nSigned-off-by: Paolo Abeni <pabeni@redhat.com>\n', '']",Merge of BPF updates into the net tree with changes across 15 files and 217 insertions.,"BPF, netdev, updates",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a3c70a3cf11eb4b6409afc2cce1a3747e1dfe96f,a3c70a3cf11eb4b6409afc2cce1a3747e1dfe96f,Alexei Starovoitov,ast@kernel.org,1708473001,Alexei Starovoitov,ast@kernel.org,1708552154,5fe7b4c3fc67c958714897ade529227918b1282c,01dbd7d8720a0cc97dad5e70ec674dacdc66cf3c,"bpf: Shrink size of struct bpf_map/bpf_array.

Back in 2018 the commit be95a845cc44 (""bpf: avoid false sharing of map refcount
with max_entries"") added ____cacheline_aligned to ""struct bpf_map"" to make sure
that fields like refcnt don't share a cache line with max_entries that is used
to bounds check map access. That was done to make spectre style attacks harder.
The main mitigation is done via code similar to array_index_nospec()"," of course.
This was an additional precaution.

It increased the size of ""struct bpf_map"" a little","["" but it's affect on all\nother maps (like array) is significant"", ' since ""struct bpf_map"" is typically\nthe first member in other map types.\n\nUndo this ____cacheline_aligned tag. Instead move freeze_mutex field around', ' so\nthat refcnt and max_entries are still in different cache lines.\n\nThe main effect is seen in sizeof(struct bpf_array) that reduces from 320\nto 248 bytes.\n\nBEFORE:\n\nstruct bpf_map {\n\tconst struct bpf_map_ops  * ops;                 /*     0     8 */\n\t...\n\tchar                       name[16];             /*    96    16 */\n\n\t/* XXX 16 bytes hole', ' try to pack */\n\n\t/* --- cacheline 2 boundary (128 bytes) --- */\n\tatomic64_t refcnt __attribute__((__aligned__(64))); /*   128     8 */\n\t...\n\t/* size: 256', ' cachelines: 4', ' members: 30 */\n\t/* sum members: 232', ' holes: 1', ' sum holes: 16 */\n\t/* padding: 8 */\n\t/* paddings: 1', ' sum paddings: 2 */\n} __attribute__((__aligned__(64)));\n\nstruct bpf_array {\n\tstruct bpf_map             map;                  /*     0   256 */\n\t...\n\t/* size: 320', ' cachelines: 5', ' members: 5 */\n\t/* padding: 48 */\n\t/* paddings: 1', ' sum paddings: 8 */\n} __attribute__((__aligned__(64)));\n\nAFTER:\n\nstruct bpf_map {\n\t/* size: 232', ' cachelines: 4', ' members: 30 */\n\t/* paddings: 1', ' sum paddings: 2 */\n\t/* last cacheline: 40 bytes */\n};\nstruct bpf_array {\n\t/* size: 248', ' cachelines: 4', ' members: 5 */\n\t/* last cacheline: 56 bytes */\n};\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/bpf/20240220235001.57411-1-alexei.starovoitov@gmail.com\n', '']",The commit reduces the size of struct bpf_map and struct bpf_array to improve efficiency.,"bpf_map,bpf_array,shrinking",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
01dbd7d8720a0cc97dad5e70ec674dacdc66cf3c,01dbd7d8720a0cc97dad5e70ec674dacdc66cf3c,Alexei Starovoitov,ast@kernel.org,1708470662,Alexei Starovoitov,ast@kernel.org,1708552154,81b0943a028be74b939afd8fb83dacdd6c3ee738,7648f0c91eaa3598add9e91991a5483b29da32ee,"selftests/bpf: Remove intermediate test files.

The test of linking process creates several intermediate files.
Remove them once the build is over.

This reduces the number of files in selftests/bpf/ directory
from ~4400 to ~2600.

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240220231102.49090-1-alexei.starovoitov@gmail.com
",,The commit removes intermediate test files in selftests/bpf to reduce directory clutter.,"selftests, intermediate, files",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
4cd12c6065dfcdeba10f49949bffcf383b3952d8,4cd12c6065dfcdeba10f49949bffcf383b3952d8,Shigeru Yoshida,syoshida@redhat.com,1708268973,Daniel Borkmann,daniel@iogearbox.net,1708532123,5636131fbde49ba080526f386b244e72cbcbace1,5c138a8a4abe152fcbef1ed40a6a4b5727b2991b,bpf," sockmap: Fix NULL pointer dereference in sk_psock_verdict_data_ready()

syzbot reported the following NULL pointer dereference issue [1]:

  BUG: kernel NULL pointer dereference","[' address: 0000000000000000\n  [...]\n  RIP: 0010:0x0\n  [...]\n  Call Trace:\n   <TASK>\n   sk_psock_verdict_data_ready+0x232/0x340 net/core/skmsg.c:1230\n   unix_stream_sendmsg+0x9b4/0x1230 net/unix/af_unix.c:2293\n   sock_sendmsg_nosec net/socket.c:730 [inline]\n   __sock_sendmsg+0x221/0x270 net/socket.c:745\n   ____sys_sendmsg+0x525/0x7d0 net/socket.c:2584\n   ___sys_sendmsg net/socket.c:2638 [inline]\n   __sys_sendmsg+0x2b0/0x3a0 net/socket.c:2667\n   do_syscall_64+0xf9/0x240\n   entry_SYSCALL_64_after_hwframe+0x6f/0x77\n\nIf sk_psock_verdict_data_ready() and sk_psock_stop_verdict() are called\nconcurrently', ' psock->saved_data_ready can be NULL', ' causing the above issue.\n\nThis patch fixes this issue by calling the appropriate data ready function\nusing the sk_psock_data_ready() helper and protecting it from concurrency\nwith sk->sk_callback_lock.\n\nFixes: 6df7f764cd3c (""bpf', ' sockmap: Wake up polling after data copy"")\nReported-by: syzbot+fd7b34375c1c8ce29c93@syzkaller.appspotmail.com\nSigned-off-by: Shigeru Yoshida <syoshida@redhat.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: syzbot+fd7b34375c1c8ce29c93@syzkaller.appspotmail.com\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nCloses: https://syzkaller.appspot.com/bug?extid=fd7b34375c1c8ce29c93 [1]\nLink: https://lore.kernel.org/bpf/20240218150933.6004-1-syoshida@redhat.com\n', '']",Fixes a NULL pointer dereference issue in sk_psock_verdict_data_ready().,"NULL, pointer, dereference",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The syscall interface,['socket like programs']
56667da7399eb19af857e30f41bea89aa6fa812c,56667da7399eb19af857e30f41bea89aa6fa812c,Eric Dumazet,edumazet@google.com,1708351940,David S. Miller,davem@davemloft.net,1708514660,f3d61fc0ba42af287720204d892fbc0e1268669f,3b1ae9b71c2a97f848b00fb085a2bd29bddbe8d9,"net: implement lockless setsockopt(SO_PEEK_OFF)

syzbot reported a lockdep violation [1] involving af_unix
support of SO_PEEK_OFF.

Since SO_PEEK_OFF is inherently not thread safe (it uses a per-socket
sk_peek_off field)"," there is really no point to enforce a pointless
thread safety in the kernel.

After this patch :

- setsockopt(SO_PEEK_OFF) no longer acquires the socket lock.

- skb_consume_udp() no longer has to acquire the socket lock.

- af_unix no longer needs a special version of sk_set_peek_off()","['\n  because it does not lock u->iolock anymore.\n\nAs a followup', ' we could replace prot->set_peek_off to be a boolean\nand avoid an indirect call', ' since we always use sk_set_peek_off().\n\n[1]\n\nWARNING: possible circular locking dependency detected\n6.8.0-rc4-syzkaller-00267-g0f1dd5e91e2b #0 Not tainted\n\nsyz-executor.2/30025 is trying to acquire lock:\n ffff8880765e7d80 (&u->iolock){+.+.}-{3:3}', ' at: unix_set_peek_off+0x26/0xa0 net/unix/af_unix.c:789\n\nbut task is already holding lock:\n ffff8880765e7930 (sk_lock-AF_UNIX){+.+.}-{0:0}', ' at: lock_sock include/net/sock.h:1691 [inline]\n ffff8880765e7930 (sk_lock-AF_UNIX){+.+.}-{0:0}', ' at: sockopt_lock_sock net/core/sock.c:1060 [inline]\n ffff8880765e7930 (sk_lock-AF_UNIX){+.+.}-{0:0}', ' at: sk_setsockopt+0xe52/0x3360 net/core/sock.c:1193\n\nwhich lock already depends on the new lock.\n\nthe existing dependency chain (in reverse order) is:\n\n-> #1 (sk_lock-AF_UNIX){+.+.}-{0:0}:\n        lock_acquire+0x1e3/0x530 kernel/locking/lockdep.c:5754\n        lock_sock_nested+0x48/0x100 net/core/sock.c:3524\n        lock_sock include/net/sock.h:1691 [inline]\n        __unix_dgram_recvmsg+0x1275/0x12c0 net/unix/af_unix.c:2415\n        sock_recvmsg_nosec+0x18e/0x1d0 net/socket.c:1046\n        ____sys_recvmsg+0x3c0/0x470 net/socket.c:2801\n        ___sys_recvmsg net/socket.c:2845 [inline]\n        do_recvmmsg+0x474/0xae0 net/socket.c:2939\n        __sys_recvmmsg net/socket.c:3018 [inline]\n        __do_sys_recvmmsg net/socket.c:3041 [inline]\n        __se_sys_recvmmsg net/socket.c:3034 [inline]\n        __x64_sys_recvmmsg+0x199/0x250 net/socket.c:3034\n       do_syscall_64+0xf9/0x240\n       entry_SYSCALL_64_after_hwframe+0x6f/0x77\n\n-> #0 (&u->iolock){+.+.}-{3:3}:\n        check_prev_add kernel/locking/lockdep.c:3134 [inline]\n        check_prevs_add kernel/locking/lockdep.c:3253 [inline]\n        validate_chain+0x18ca/0x58e0 kernel/locking/lockdep.c:3869\n        __lock_acquire+0x1345/0x1fd0 kernel/locking/lockdep.c:5137\n        lock_acquire+0x1e3/0x530 kernel/locking/lockdep.c:5754\n        __mutex_lock_common kernel/locking/mutex.c:608 [inline]\n        __mutex_lock+0x136/0xd70 kernel/locking/mutex.c:752\n        unix_set_peek_off+0x26/0xa0 net/unix/af_unix.c:789\n       sk_setsockopt+0x207e/0x3360\n        do_sock_setsockopt+0x2fb/0x720 net/socket.c:2307\n        __sys_setsockopt+0x1ad/0x250 net/socket.c:2334\n        __do_sys_setsockopt net/socket.c:2343 [inline]\n        __se_sys_setsockopt net/socket.c:2340 [inline]\n        __x64_sys_setsockopt+0xb5/0xd0 net/socket.c:2340\n       do_syscall_64+0xf9/0x240\n       entry_SYSCALL_64_after_hwframe+0x6f/0x77\n\nother info that might help us debug this:\n\n Possible unsafe locking scenario:\n\n       CPU0                    CPU1\n       ----                    ----\n  lock(sk_lock-AF_UNIX);\n                               lock(&u->iolock);\n                               lock(sk_lock-AF_UNIX);\n  lock(&u->iolock);\n\n *** DEADLOCK ***\n\n1 lock held by syz-executor.2/30025:\n  #0: ffff8880765e7930 (sk_lock-AF_UNIX){+.+.}-{0:0}', ' at: lock_sock include/net/sock.h:1691 [inline]\n  #0: ffff8880765e7930 (sk_lock-AF_UNIX){+.+.}-{0:0}', ' at: sockopt_lock_sock net/core/sock.c:1060 [inline]\n  #0: ffff8880765e7930 (sk_lock-AF_UNIX){+.+.}-{0:0}', ' at: sk_setsockopt+0xe52/0x3360 net/core/sock.c:1193\n\nstack backtrace:\nCPU: 0 PID: 30025 Comm: syz-executor.2 Not tainted 6.8.0-rc4-syzkaller-00267-g0f1dd5e91e2b #0\nHardware name: Google Google Compute Engine/Google Compute Engine', ' BIOS Google 01/25/2024\nCall Trace:\n <TASK>\n  __dump_stack lib/dump_stack.c:88 [inline]\n  dump_stack_lvl+0x1e7/0x2e0 lib/dump_stack.c:106\n  check_noncircular+0x36a/0x4a0 kernel/locking/lockdep.c:2187\n  check_prev_add kernel/locking/lockdep.c:3134 [inline]\n  check_prevs_add kernel/locking/lockdep.c:3253 [inline]\n  validate_chain+0x18ca/0x58e0 kernel/locking/lockdep.c:3869\n  __lock_acquire+0x1345/0x1fd0 kernel/locking/lockdep.c:5137\n  lock_acquire+0x1e3/0x530 kernel/locking/lockdep.c:5754\n  __mutex_lock_common kernel/locking/mutex.c:608 [inline]\n  __mutex_lock+0x136/0xd70 kernel/locking/mutex.c:752\n  unix_set_peek_off+0x26/0xa0 net/unix/af_unix.c:789\n sk_setsockopt+0x207e/0x3360\n  do_sock_setsockopt+0x2fb/0x720 net/socket.c:2307\n  __sys_setsockopt+0x1ad/0x250 net/socket.c:2334\n  __do_sys_setsockopt net/socket.c:2343 [inline]\n  __se_sys_setsockopt net/socket.c:2340 [inline]\n  __x64_sys_setsockopt+0xb5/0xd0 net/socket.c:2340\n do_syscall_64+0xf9/0x240\n entry_SYSCALL_64_after_hwframe+0x6f/0x77\nRIP: 0033:0x7f78a1c7dda9\nCode: 28 00 00 00 75 05 48 83 c4 28 c3 e8 e1 20 00 00 90 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 73 01 c3 48 c7 c1 b0 ff ff ff f7 d8 64 89 01 48\nRSP: 002b:00007f78a0fde0c8 EFLAGS: 00000246 ORIG_RAX: 0000000000000036\nRAX: ffffffffffffffda RBX: 00007f78a1dac050 RCX: 00007f78a1c7dda9\nRDX: 000000000000002a RSI: 0000000000000001 RDI: 0000000000000006\nRBP: 00007f78a1cca47a R08: 0000000000000004 R09: 0000000000000000\nR10: 0000000020000180 R11: 0000000000000246 R12: 0000000000000000\nR13: 000000000000006e R14: 00007f78a1dac050 R15: 00007ffe5cd81ae8\n\nFixes: 859051dd165e (""bpf: Implement cgroup sockaddr hooks for unix sockets"")\nSigned-off-by: Eric Dumazet <edumazet@google.com>\nCc: Willem de Bruijn <willemdebruijn.kernel@gmail.com>\nCc: Daan De Meyer <daan.j.demeyer@gmail.com>\nCc: Kuniyuki Iwashima <kuniyu@amazon.com>\nCc: Martin KaFai Lau <martin.lau@kernel.org>\nCc: David Ahern <dsahern@kernel.org>\nReviewed-by: Willem de Bruijn <willemb@google.com>\nReviewed-by: Kuniyuki Iwashima <kuniyu@amazon.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>\n', '']",Implemented a lockless version of setsockopt for SO_PEEK_OFF to prevent a lockdep violation in af_unix.,"lockless,setsockopt,SO_PEEK_OFF",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The syscall interface,"['socket like programs', 'other']"
5d4cc87414c5d11345c4b11d61377d351b5c28a2,5d4cc87414c5d11345c4b11d61377d351b5c28a2,Eric Dumazet,edumazet@google.com,1708100406,Paolo Abeni,pabeni@redhat.com,1708426905,1ae0e74ca86ec95d5e670634a404043f4212a20a,465c1abcb64426f0ff39e80e508e2432672c2dae,"net: reorganize ""struct sock"" fields

Last major reorg happened in commit 9115e8cd2a0c (""net: reorganize
struct sock for better data locality"")

Since then"," many changes have been done.

Before SO_PEEK_OFF support is added to TCP","[' we need\nto move sk_peek_off to a better location.\n\nIt is time to make another pass', ' and add six groups', '\nwithout explicit alignment.\n\n- sock_write_rx (following sk_refcnt) read-write fields in rx path.\n- sock_read_rx read-mostly fields in rx path.\n- sock_read_rxtx read-mostly fields in both rx and tx paths.\n- sock_write_rxtx read-write fields in both rx and tx paths.\n- sock_write_tx read-write fields in tx paths.\n- sock_read_tx read-mostly fields in tx paths.\n\nResults on TCP_RR benchmarks seem to show a gain (4 to 5 %).\n\nIt is possible UDP needs a change', ' because sk_peek_off\nshares a cache line with sk_receive_queue.\nIf this the case', ' we can exchange roles of sk->sk_receive\nand up->reader_queue queues.\n\nAfter this change', ' we have the following layout:\n\nstruct sock {\n\tstruct sock_common         __sk_common;          /*     0  0x88 */\n\t/* --- cacheline 2 boundary (128 bytes) was 8 bytes ago --- */\n\t__u8                       __cacheline_group_begin__sock_write_rx[0]; /*  0x88     0 */\n\tatomic_t                   sk_drops;             /*  0x88   0x4 */\n\t__s32                      sk_peek_off;          /*  0x8c   0x4 */\n\tstruct sk_buff_head        sk_error_queue;       /*  0x90  0x18 */\n\tstruct sk_buff_head        sk_receive_queue;     /*  0xa8  0x18 */\n\t/* --- cacheline 3 boundary (192 bytes) --- */\n\tstruct {\n\t\tatomic_t           rmem_alloc;           /*  0xc0   0x4 */\n\t\tint                len;                  /*  0xc4   0x4 */\n\t\tstruct sk_buff *   head;                 /*  0xc8   0x8 */\n\t\tstruct sk_buff *   tail;                 /*  0xd0   0x8 */\n\t} sk_backlog;                                    /*  0xc0  0x18 */\n\tstruct {\n\t\tatomic_t                   rmem_alloc;           /*     0   0x4 */\n\t\tint                        len;                  /*   0x4   0x4 */\n\t\tstruct sk_buff *           head;                 /*   0x8   0x8 */\n\t\tstruct sk_buff *           tail;                 /*  0x10   0x8 */\n\n\t\t/* size: 24', ' cachelines: 1', ' members: 4 */\n\t\t/* last cacheline: 24 bytes */\n\t};\n\n\t__u8                       __cacheline_group_end__sock_write_rx[0]; /*  0xd8     0 */\n\t__u8                       __cacheline_group_begin__sock_read_rx[0]; /*  0xd8     0 */\n\trcu *                      sk_rx_dst;            /*  0xd8   0x8 */\n\tint                        sk_rx_dst_ifindex;    /*  0xe0   0x4 */\n\tu32                        sk_rx_dst_cookie;     /*  0xe4   0x4 */\n\tunsigned int               sk_ll_usec;           /*  0xe8   0x4 */\n\tunsigned int               sk_napi_id;           /*  0xec   0x4 */\n\tu16                        sk_busy_poll_budget;  /*  0xf0   0x2 */\n\tu8                         sk_prefer_busy_poll;  /*  0xf2   0x1 */\n\tu8                         sk_userlocks;         /*  0xf3   0x1 */\n\tint                        sk_rcvbuf;            /*  0xf4   0x4 */\n\trcu *                      sk_filter;            /*  0xf8   0x8 */\n\t/* --- cacheline 4 boundary (256 bytes) --- */\n\tunion {\n\t\trcu *              sk_wq;                /* 0x100   0x8 */\n\t\tstruct socket_wq * sk_wq_raw;            /* 0x100   0x8 */\n\t};                                               /* 0x100   0x8 */\n\tunion {\n\t\trcu *                      sk_wq;                /*     0   0x8 */\n\t\tstruct socket_wq *         sk_wq_raw;            /*     0   0x8 */\n\t};\n\n\tvoid                       (*sk_data_ready)(struct sock *); /* 0x108   0x8 */\n\tlong                       sk_rcvtimeo;          /* 0x110   0x8 */\n\tint                        sk_rcvlowat;          /* 0x118   0x4 */\n\t__u8                       __cacheline_group_end__sock_read_rx[0]; /* 0x11c     0 */\n\t__u8                       __cacheline_group_begin__sock_read_rxtx[0]; /* 0x11c     0 */\n\tint                        sk_err;               /* 0x11c   0x4 */\n\tstruct socket *            sk_socket;            /* 0x120   0x8 */\n\tstruct mem_cgroup *        sk_memcg;             /* 0x128   0x8 */\n\trcu *                      sk_policy[2];         /* 0x130  0x10 */\n\t/* --- cacheline 5 boundary (320 bytes) --- */\n\t__u8                       __cacheline_group_end__sock_read_rxtx[0]; /* 0x140     0 */\n\t__u8                       __cacheline_group_begin__sock_write_rxtx[0]; /* 0x140     0 */\n\tsocket_lock_t              sk_lock;              /* 0x140  0x20 */\n\tu32                        sk_reserved_mem;      /* 0x160   0x4 */\n\tint                        sk_forward_alloc;     /* 0x164   0x4 */\n\tu32                        sk_tsflags;           /* 0x168   0x4 */\n\t__u8                       __cacheline_group_end__sock_write_rxtx[0]; /* 0x16c     0 */\n\t__u8                       __cacheline_group_begin__sock_write_tx[0]; /* 0x16c     0 */\n\tint                        sk_write_pending;     /* 0x16c   0x4 */\n\tatomic_t                   sk_omem_alloc;        /* 0x170   0x4 */\n\tint                        sk_sndbuf;            /* 0x174   0x4 */\n\tint                        sk_wmem_queued;       /* 0x178   0x4 */\n\trefcount_t                 sk_wmem_alloc;        /* 0x17c   0x4 */\n\t/* --- cacheline 6 boundary (384 bytes) --- */\n\tunsigned long              sk_tsq_flags;         /* 0x180   0x8 */\n\tunion {\n\t\tstruct sk_buff *   sk_send_head;         /* 0x188   0x8 */\n\t\tstruct rb_root     tcp_rtx_queue;        /* 0x188   0x8 */\n\t};                                               /* 0x188   0x8 */\n\tunion {\n\t\tstruct sk_buff *           sk_send_head;         /*     0   0x8 */\n\t\tstruct rb_root             tcp_rtx_queue;        /*     0   0x8 */\n\t};\n\n\tstruct sk_buff_head        sk_write_queue;       /* 0x190  0x18 */\n\tu32                        sk_dst_pending_confirm; /* 0x1a8   0x4 */\n\tu32                        sk_pacing_status;     /* 0x1ac   0x4 */\n\tstruct page_frag           sk_frag;              /* 0x1b0  0x10 */\n\t/* --- cacheline 7 boundary (448 bytes) --- */\n\tstruct timer_list          sk_timer;             /* 0x1c0  0x28 */\n\n\t/* XXX last struct has 4 bytes of padding */\n\n\tunsigned long              sk_pacing_rate;       /* 0x1e8   0x8 */\n\tatomic_t                   sk_zckey;             /* 0x1f0   0x4 */\n\tatomic_t                   sk_tskey;             /* 0x1f4   0x4 */\n\t__u8                       __cacheline_group_end__sock_write_tx[0]; /* 0x1f8     0 */\n\t__u8                       __cacheline_group_begin__sock_read_tx[0]; /* 0x1f8     0 */\n\tunsigned long              sk_max_pacing_rate;   /* 0x1f8   0x8 */\n\t/* --- cacheline 8 boundary (512 bytes) --- */\n\tlong                       sk_sndtimeo;          /* 0x200   0x8 */\n\tu32                        sk_priority;          /* 0x208   0x4 */\n\tu32                        sk_mark;              /* 0x20c   0x4 */\n\trcu *                      sk_dst_cache;         /* 0x210   0x8 */\n\tnetdev_features_t          sk_route_caps;        /* 0x218   0x8 */\n\tu16                        sk_gso_type;          /* 0x220   0x2 */\n\tu16                        sk_gso_max_segs;      /* 0x222   0x2 */\n\tunsigned int               sk_gso_max_size;      /* 0x224   0x4 */\n\tgfp_t                      sk_allocation;        /* 0x228   0x4 */\n\tu32                        sk_txhash;            /* 0x22c   0x4 */\n\tu8                         sk_pacing_shift;      /* 0x230   0x1 */\n\tbool                       sk_use_task_frag;     /* 0x231   0x1 */\n\t__u8                       __cacheline_group_end__sock_read_tx[0]; /* 0x232     0 */\n\tu8                         sk_gso_disabled:1;    /* 0x232: 0 0x1 */\n\tu8                         sk_kern_sock:1;       /* 0x232:0x1 0x1 */\n\tu8                         sk_no_check_tx:1;     /* 0x232:0x2 0x1 */\n\tu8                         sk_no_check_rx:1;     /* 0x232:0x3 0x1 */\n\n\t/* XXX 4 bits hole', ' try to pack */\n\n\tu8                         sk_shutdown;          /* 0x233   0x1 */\n\tu16                        sk_type;              /* 0x234   0x2 */\n\tu16                        sk_protocol;          /* 0x236   0x2 */\n\tunsigned long              sk_lingertime;        /* 0x238   0x8 */\n\t/* --- cacheline 9 boundary (576 bytes) --- */\n\tstruct proto *             sk_prot_creator;      /* 0x240   0x8 */\n\trwlock_t                   sk_callback_lock;     /* 0x248   0x8 */\n\tint                        sk_err_soft;          /* 0x250   0x4 */\n\tu32                        sk_ack_backlog;       /* 0x254   0x4 */\n\tu32                        sk_max_ack_backlog;   /* 0x258   0x4 */\n\tkuid_t                     sk_uid;               /* 0x25c   0x4 */\n\tspinlock_t                 sk_peer_lock;         /* 0x260   0x4 */\n\tint                        sk_bind_phc;          /* 0x264   0x4 */\n\tstruct pid *               sk_peer_pid;          /* 0x268   0x8 */\n\tconst struct cred  *       sk_peer_cred;         /* 0x270   0x8 */\n\tktime_t                    sk_stamp;             /* 0x278   0x8 */\n\t/* --- cacheline 10 boundary (640 bytes) --- */\n\tint                        sk_disconnects;       /* 0x280   0x4 */\n\tu8                         sk_txrehash;          /* 0x284   0x1 */\n\tu8                         sk_clockid;           /* 0x285   0x1 */\n\tu8                         sk_txtime_deadline_mode:1; /* 0x286: 0 0x1 */\n\tu8                         sk_txtime_report_errors:1; /* 0x286:0x1 0x1 */\n\tu8                         sk_txtime_unused:6;   /* 0x286:0x2 0x1 */\n\n\t/* XXX 1 byte hole', ' try to pack */\n\n\tvoid *                     sk_user_data;         /* 0x288   0x8 */\n\tvoid *                     sk_security;          /* 0x290   0x8 */\n\tstruct sock_cgroup_data    sk_cgrp_data;         /* 0x298   0x8 */\n\tvoid                       (*sk_state_change)(struct sock *); /* 0x2a0   0x8 */\n\tvoid                       (*sk_write_space)(struct sock *); /* 0x2a8   0x8 */\n\tvoid                       (*sk_error_report)(struct sock *); /* 0x2b0   0x8 */\n\tint                        (*sk_backlog_rcv)(struct sock *', ' struct sk_buff *); /* 0x2b8   0x8 */\n\t/* --- cacheline 11 boundary (704 bytes) --- */\n\tvoid                       (*sk_destruct)(struct sock *); /* 0x2c0   0x8 */\n\trcu *                      sk_reuseport_cb;      /* 0x2c8   0x8 */\n\trcu *                      sk_bpf_storage;       /* 0x2d0   0x8 */\n\tstruct callback_head       sk_rcu __attribute__((__aligned__(8))); /* 0x2d8  0x10 */\n\tnetns_tracker              ns_tracker;           /* 0x2e8   0x8 */\n\n\t/* size: 752', ' cachelines: 12', ' members: 105 */\n\t/* sum members: 749', ' holes: 1', ' sum holes: 1 */\n\t/* sum bitfield members: 12 bits', ' bit holes: 1', ' sum bit holes: 4 bits */\n\t/* paddings: 1', ' sum paddings: 4 */\n\t/* forced alignments: 1 */\n\t/* last cacheline: 48 bytes */\n};\n\nSigned-off-by: Eric Dumazet <edumazet@google.com>\nAcked-by: Paolo Abeni <pabeni@redhat.com>\nLink: https://lore.kernel.org/r/20240216162006.2342759-1-edumazet@google.com\nSigned-off-by: Paolo Abeni <pabeni@redhat.com>\n', '']",Reorganize struct sock fields for better data locality.,"reorganize, struct sock, data locality",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
5c138a8a4abe152fcbef1ed40a6a4b5727b2991b,5c138a8a4abe152fcbef1ed40a6a4b5727b2991b,Yafang Shao,laoar.shao@gmail.com,1708170112,Daniel Borkmann,daniel@iogearbox.net,1708342095,c9aee41673c07d98b333e9ab9e87d7b0535bb9bd,5f2ae606cb5a90839a9be9d22388c4200f820e75,"selftests/bpf: Add negtive test cases for task iter

Incorporate a test case to assess the handling of invalid flags or
task__nullable parameters passed to bpf_iter_task_new(). Prior to the
preceding commit"," this scenario could potentially trigger a kernel panic.
However","[' with the previous commit', ' this test case is expected to function\ncorrectly.\n\nSigned-off-by: Yafang Shao <laoar.shao@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240217114152.1623-3-laoar.shao@gmail.com\n', '']",Add negative test cases to bpf_iter_task_new to prevent kernel panics with invalid inputs.,"negtive,test cases,task iter",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5f2ae606cb5a90839a9be9d22388c4200f820e75,5f2ae606cb5a90839a9be9d22388c4200f820e75,Yafang Shao,laoar.shao@gmail.com,1708170111,Daniel Borkmann,daniel@iogearbox.net,1708342095,95d2c6a9b5d7acb4ea4d1581f15b7e5dc3aa480d,3f00e4a9c96f4488a924aff4e35b77c8eced897e,"bpf: Fix an issue due to uninitialized bpf_iter_task

Failure to initialize it->pos"," coupled with the presence of an invalid
value in the flags variable","[' can lead to it->pos referencing an invalid\ntask', ' potentially resulting in a kernel panic. To mitigate this risk', ' it\'s\ncrucial to ensure proper initialization of it->pos to NULL.\n\nFixes: ac8148d957f5 (""bpf: bpf_iter_task_next: use next_task(kit->task) rather than next_task(kit->pos)"")\nSigned-off-by: Yafang Shao <laoar.shao@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nAcked-by: Oleg Nesterov <oleg@redhat.com>\nLink: https://lore.kernel.org/bpf/20240217114152.1623-2-laoar.shao@gmail.com\n', '']",Fixes an issue with uninitialized bpf_iter_task causing invalid values in flags.,"bpf_iter_task,uninitialized,fix",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3f00e4a9c96f4488a924aff4e35b77c8eced897e,3f00e4a9c96f4488a924aff4e35b77c8eced897e,Martin KaFai Lau,martin.lau@kernel.org,1708031538,Daniel Borkmann,daniel@iogearbox.net,1708342006,f715138a7e72079c5e8608da6113196f1ac19f5d,0281b919e175bb9c3128bd3872ac2903e9436e3f,"selftests/bpf: Test racing between bpf_timer_cancel_and_free and bpf_timer_cancel

This selftest is based on a Alexei's test adopted from an internal
user to troubleshoot another bug. During this exercise"," a separate
racing bug was discovered between bpf_timer_cancel_and_free
and bpf_timer_cancel. The details can be found in the previous
patch.

This patch is to add a selftest that can trigger the bug.
I can trigger the UAF everytime in my qemu setup with KASAN. The idea
is to have multiple user space threads running in a tight loop to exercise
both bpf_map_update_elem (which calls into bpf_timer_cancel_and_free)
and bpf_timer_cancel.

Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Hou Tao <houtao1@huawei.com>
Link: https://lore.kernel.org/bpf/20240215211218.990808-2-martin.lau@linux.dev
",[''],Add a selftest to detect race conditions between bpf_timer_cancel_and_free and bpf_timer_cancel.,"selftest,race,bug",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0281b919e175bb9c3128bd3872ac2903e9436e3f,0281b919e175bb9c3128bd3872ac2903e9436e3f,Martin KaFai Lau,martin.lau@kernel.org,1708031537,Daniel Borkmann,daniel@iogearbox.net,1708342006,015d5f0db53ce3761fab03b8173edb45ee9126cf,54d46c9f581d16ac6adad3c3e61766e02bbfcb60,"bpf: Fix racing between bpf_timer_cancel_and_free and bpf_timer_cancel

The following race is possible between bpf_timer_cancel_and_free
and bpf_timer_cancel. It will lead a UAF on the timer->timer.

bpf_timer_cancel();
	spin_lock();
	t = timer->time;
	spin_unlock();

					bpf_timer_cancel_and_free();
						spin_lock();
						t = timer->timer;
						timer->timer = NULL;
						spin_unlock();
						hrtimer_cancel(&t->timer);
						kfree(t);

	/* UAF on t */
	hrtimer_cancel(&t->timer);

In bpf_timer_cancel_and_free"," this patch frees the timer->timer
after a rcu grace period. This requires a rcu_head addition
to the ""struct bpf_hrtimer"". Another kfree(t) happens in bpf_timer_init","['\nthis does not need a kfree_rcu because it is still under the\nspin_lock and timer->timer has not been visible by others yet.\n\nIn bpf_timer_cancel', ' rcu_read_lock() is added because this helper\ncan be used in a non rcu critical section context (e.g. from\na sleepable bpf prog). Other timer->timer usages in helpers.c\nhave been audited', ' bpf_timer_cancel() is the only place where\ntimer->timer is used outside of the spin_lock.\n\nAnother solution considered is to mark a t->flag in bpf_timer_cancel\nand clear it after hrtimer_cancel() is done.  In bpf_timer_cancel_and_free', '\nit busy waits for the flag to be cleared before kfree(t). This patch\ngoes with a straight forward solution and frees timer->timer after\na rcu grace period.\n\nFixes: b00628b1c7d5 (""bpf: Introduce bpf timers."")\nSuggested-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/bpf/20240215211218.990808-1-martin.lau@linux.dev\n', '']",Fix race condition in bpf_timer_cancel_and_free leading to use-after-free on timers.,"bpf_timer,race condition,use-after-free",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.",['kprobe/uprobe/ftrace like programs']
ac00b6546d390bc12d1d2824c2b5d95046097eb2,ac00b6546d390bc12d1d2824c2b5d95046097eb2,Linus Torvalds,torvalds@linux-foundation.org,1708186412,Linus Torvalds,torvalds@linux-foundation.org,1708186412,1e71beb5f40035be915687abb55db633583bc03f,4a7571485c467b76cc19fae304452fd56921c789 346c84e281a963437b9fe9dfcd92c531630289de,"Merge tag 'media/v6.8-4' of git://git.kernel.org/pub/scm/linux/kernel/git/mchehab/linux-media

Pull media fixes from Mauro Carvalho Chehab:

 - regression fix for rkisp1 shared IRQ logic

 - fix atomisp breakage due to a kAPI change

 - permission fix for remote controller BPF support

 - memleak fix in ir_toy driver

 - Kconfig dependency fix for pwm-ir-rx

* tag 'media/v6.8-4' of git://git.kernel.org/pub/scm/linux/kernel/git/mchehab/linux-media:
  media: pwm-ir-tx: Depend on CONFIG_HIGH_RES_TIMERS
  media: ir_toy: fix a memleak in irtoy_tx
  media: rc: bpf attach/detach requires write permission
  media: atomisp: Adjust for v4l2_subdev_state handling changes in 6.8
  media: rkisp1: Fix IRQ handling due to shared interrupts
  media: Revert ""media: rkisp1: Drop IRQF_SHARED""
",,"Merge media fixes including IRQ logic, kAPI changes, and memory leak corrections.","media, fixes, IRQ",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
bacefe0c7b77b7527a613e053b6d378412a8a779,bacefe0c7b77b7527a613e053b6d378412a8a779,Namhyung Kim,namhyung@kernel.org,1707780802,Namhyung Kim,namhyung@kernel.org,1708128448,db162f3ec5e37f61b6acc4708ff902d9e811d539,6f146b249b3ada0082209b34abf01c90c702a96b,"perf tools: Fixup module symbol end address properly

I got a strange error on ARM to fail on processing FINISHED_ROUND
record.  It turned out that it was failing in symbol__alloc_hist()
because the symbol size is too big.

When a sample is captured on a specific BPF program"," it failed.  I've
added a debug code and found the end address of the symbol is from
the next module which is placed far way.

  ffff800008795778-ffff80000879d6d8: bpf_prog_1bac53b8aac4bc58_netcg_sock    [bpf]
  ffff80000879d6d8-ffff80000ad656b4: bpf_prog_76867454b5944e15_netcg_getsockopt      [bpf]
  ffff80000ad656b4-ffffd69b7af74048: bpf_prog_1d50286d2eb1be85_hn_egress     [bpf]   <---------- here
  ffffd69b7af74048-ffffd69b7af74048: $x.5    [sha3_generic]
  ffffd69b7af74048-ffffd69b7af740b8: crypto_sha3_init        [sha3_generic]
  ffffd69b7af740b8-ffffd69b7af741e0: crypto_sha3_update      [sha3_generic]

The logic in symbols__fixup_end() just uses curr->start to update the
prev->end.  But in this case","["" it won't work as it's too different.\n\nI think ARM has a different kernel memory layout for modules and BPF\nthan on x86.  Actually there's a logic to handle kernel and module\nboundary.  Let's do the same for symbols between different modules.\n\nSigned-off-by: Namhyung Kim <namhyung@kernel.org>\nReviewed-by: Leo Yan <leo.yan@linux.dev>\nCc: Will Deacon <will@kernel.org>\nCc: Mike Leach <mike.leach@linaro.org>\nCc: John Garry <john.g.garry@oracle.com>\nLink: https://lore.kernel.org/r/20240212233322.1855161-1-namhyung@kernel.org\n"", '']",Fixes end address calculation for module symbols in perf tools on ARM.,"perf tools, symbol, ARM",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
29d16de26df17e94dd0310dc83c37f82b48a59cf,29d16de26df17e94dd0310dc83c37f82b48a59cf,Arnaldo Carvalho de Melo,acme@kernel.org,1708122023,Namhyung Kim,namhyung@kernel.org,1708125597,a343299a1911d83be2f4eeab8ea8822c1127d4ae,f512e08fd0940fcd811d24e2cfd95683fe8042c3,"perf augmented_raw_syscalls.bpf: Move 'struct timespec64' to vmlinux.h

If we instead decide to generate vmlinux.h from BTF info"," it will be
there:

  $ pahole timespec64
  struct timespec64 {
  	time64_t                   tv_sec;               /*     0     8 */
  	long int                   tv_nsec;              /*     8     8 */

  	/* size: 16","[' cachelines: 1', ' members: 2 */\n  \t/* last cacheline: 16 bytes */\n  };\n\n  $\n\npahole manages to find it from /sys/kernel/btf/vmlinux', "" that is\ngenerated from the kernel types.\n\nWith this linux/bpf.h doesn't need to be included"", ' as its already in the\nminimalistic tools/perf/util/bpf_skel/vmlinux/vmlinux.h file or what we\nneed comes when generating a vmlinux.h file from BTF info', ' i.e. when\nusing GEN_VMLINUX_H=1', ' as noticed by Namyung in a build break before\nremoving linux/bpf.h.\n\nSigned-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>\nSigned-off-by: Namhyung Kim <namhyung@kernel.org>\nLink: https://lore.kernel.org/r/Zc_fp6CgDClPhS_O@x1\n', '']",Moved 'struct timespec64' definition to vmlinux.h in perf augmented_raw_syscalls.bpf.,"timespec64,vmlinux.h,perf",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),['tracepoints like programs']
7648f0c91eaa3598add9e91991a5483b29da32ee,7648f0c91eaa3598add9e91991a5483b29da32ee,Marcos Paulo de Souza,mpdesouza@suse.com,1708087365,Daniel Borkmann,daniel@iogearbox.net,1708103306,6b92bed7c484661dd0b66c422490693bdb835ae2,682158ab532a5bd24399fec25b65fec561f0f6e9,"selftests/bpf: Remove empty TEST_CUSTOM_PROGS

Commit f04a32b2c5b5 (""selftests/bpf: Do not use sign-file as testcase"")
removed the TEST_CUSTOM_PROGS assignment"," and removed it from being used
on TEST_GEN_FILES. Remove two leftovers from that cleanup. Found by
inspection.

Signed-off-by: Marcos Paulo de Souza <mpdesouza@suse.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Cc: Alexey Gladkov <legion@kernel.org>
Link: https://lore.kernel.org/bpf/20240216-bpf-selftests-custom-progs-v1-1-f7cf281a1fda@suse.com
",[''],The commit removes leftover entries relating to TEST_CUSTOM_PROGS in selftests for BPF.,"selftests,bpf,cleanup",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
54d46c9f581d16ac6adad3c3e61766e02bbfcb60,54d46c9f581d16ac6adad3c3e61766e02bbfcb60,Alexei Starovoitov,ast@kernel.org,1708053699,Alexei Starovoitov,ast@kernel.org,1708053699,28462df0448f891d561b5d843fea7360145e8aa5,e37243b65d528a8a9f8b9a57a43885f8e8dfc15c be66d79189ec8a1006ec6ec302bb27b160b3e6ce,"Merge branch 'fix-the-read-of-vsyscall-page-through-bpf'

Hou Tao says:

====================
Fix the read of vsyscall page through bpf

From: Hou Tao <houtao1@huawei.com>

Hi","

As reported by syzboot [1] and [2]","[' when trying to read vsyscall page\nby using bpf_probe_read_kernel() or bpf_probe_read()', ' oops may happen.\n\nThomas Gleixner had proposed a test patch [3]', ' but it seems that no\nformal patch is posted after about one month [4]', ' so I post it instead\nand add an Originally-by tag in patch #2.\n\nPatch #1 makes is_vsyscall_vaddr() being a common helper. Patch #2 fixes\nthe problem by disallowing vsyscall page read for\ncopy_from_kernel_nofault(). Patch #3 adds one test case to ensure the\nread of vsyscall page through bpf is rejected. Please see individual\npatches for more details.\n\nComments are always welcome.\n\n[1]: https://lore.kernel.org/bpf/CAG48ez06TZft=ATH1qh2c5mpS5BT8UakwNkzi6nvK5_djC-4Nw@mail.gmail.com/\n[2]: https://lore.kernel.org/bpf/CABOYnLynjBoFZOf3Z4BhaZkc5hx_kHfsjiW+UWLoB=w33LvScw@mail.gmail.com/\n[3]: https://lore.kernel.org/bpf/87r0jwquhv.ffs@tglx/\n[4]: https://lore.kernel.org/bpf/e24b125c-8ff4-9031-6c53-67ff2e01f316@huaweicloud.com/\n\nChange Log:\nv3:\n * rephrase commit message for patch #1 & #2 (Sohil)\n * reword comments in copy_from_kernel_nofault_allowed() (Sohil)\n * add Rvb tag for patch #1 and Acked-by tag for patch #3 (Sohil', ' Yonghong)\n\nv2: https://lore.kernel.org/bpf/20240126115423.3943360-1-houtao@huaweicloud.com/\n  * move is_vsyscall_vaddr to asm/vsyscall.h instead (Sohil)\n  * elaborate on the reason for disallowing of vsyscall page read in\n    copy_from_kernel_nofault_allowed() (Sohil)\n  * update the commit message of patch #2 to more clearly explain how\n    the oops occurs. (Sohil)\n  * update the commit message of patch #3 to explain the expected return\n    values of various bpf helpers (Yonghong)\n\nv1: https://lore.kernel.org/bpf/20240119073019.1528573-1-houtao@huaweicloud.com/\n====================\n\nLink: https://lore.kernel.org/r/20240202103935.3154011-1-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes issue with reading the vsyscall page through BPF.,"vsyscall, BPF, fix",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
be66d79189ec8a1006ec6ec302bb27b160b3e6ce,be66d79189ec8a1006ec6ec302bb27b160b3e6ce,Hou Tao,houtao1@huawei.com,1706870375,Alexei Starovoitov,ast@kernel.org,1708053699,28462df0448f891d561b5d843fea7360145e8aa5,32019c659ecfe1d92e3bf9fcdfbb11a7c70acd58,"selftest/bpf: Test the read of vsyscall page under x86-64

Under x86-64"," when using bpf_probe_read_kernel{_str}() or
bpf_probe_read{_str}() to read vsyscall page","[' the read may trigger oops', '\nso add one test case to ensure that the problem is fixed. Beside those\nfour bpf helpers mentioned above', ' testing the read of vsyscall page by\nusing bpf_probe_read_user{_str} and bpf_copy_from_user{_task}() as well.\n\nThe test case passes the address of vsyscall page to these six helpers\nand checks whether the returned values are expected:\n\n1) For bpf_probe_read_kernel{_str}()/bpf_probe_read{_str}()', ' the\n   expected return value is -ERANGE as shown below:\n\nbpf_probe_read_kernel_common\n  copy_from_kernel_nofault\n    // false', ' return -ERANGE\n    copy_from_kernel_nofault_allowed\n\n2) For bpf_probe_read_user{_str}()', ' the expected return value is -EFAULT\n   as show below:\n\nbpf_probe_read_user_common\n  copy_from_user_nofault\n    // false', ' return -EFAULT\n    __access_ok\n\n3) For bpf_copy_from_user()', ' the expected return value is -EFAULT:\n\n// return -EFAULT\nbpf_copy_from_user\n  copy_from_user\n    _copy_from_user\n      // return false\n      access_ok\n\n4) For bpf_copy_from_user_task()', ' the expected return value is -EFAULT:\n\n// return -EFAULT\nbpf_copy_from_user_task\n  access_process_vm\n    // return 0\n    vma_lookup()\n    // return 0\n    expand_stack()\n\nThe occurrence of oops depends on the availability of CPU SMAP [1]\nfeature and there are three possible configurations of vsyscall page in\nthe boot cmd-line: vsyscall={xonly|none|emulate}', ' so there are a total\nof six possible combinations. Under all these combinations', ' the test\ncase runs successfully.\n\n[1]: https://en.wikipedia.org/wiki/Supervisor_Mode_Access_Prevention\n\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20240202103935.3154011-4-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add selftest for reading vsyscall page using bpf_probe_read functions under x86-64 architecture.,"selftest, vsyscall, bpf_probe_read",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
32019c659ecfe1d92e3bf9fcdfbb11a7c70acd58,32019c659ecfe1d92e3bf9fcdfbb11a7c70acd58,Hou Tao,houtao1@huawei.com,1706870374,Alexei Starovoitov,ast@kernel.org,1708053699,7651eed33fc33fba0bbfe0bf408b89a02be420f8,ee0e39a63b78849f8abbef268b13e4838569f646,"x86/mm: Disallow vsyscall page read for copy_from_kernel_nofault()

When trying to use copy_from_kernel_nofault() to read vsyscall page
through a bpf program"," the following oops was reported:

  BUG: unable to handle page fault for address: ffffffffff600000
  #PF: supervisor read access in kernel mode
  #PF: error_code(0x0000) - not-present page
  PGD 3231067 P4D 3231067 PUD 3233067 PMD 3235067 PTE 0
  Oops: 0000 [#1] PREEMPT SMP PTI
  CPU: 1 PID: 20390 Comm: test_progs ...... 6.7.0+ #58
  Hardware name: QEMU Standard PC (i440FX + PIIX","[' 1996) ......\n  RIP: 0010:copy_from_kernel_nofault+0x6f/0x110\n  ......\n  Call Trace:\n   <TASK>\n   ? copy_from_kernel_nofault+0x6f/0x110\n   bpf_probe_read_kernel+0x1d/0x50\n   bpf_prog_2061065e56845f08_do_probe_read+0x51/0x8d\n   trace_call_bpf+0xc5/0x1c0\n   perf_call_bpf_enter.isra.0+0x69/0xb0\n   perf_syscall_enter+0x13e/0x200\n   syscall_trace_enter+0x188/0x1c0\n   do_syscall_64+0xb5/0xe0\n   entry_SYSCALL_64_after_hwframe+0x6e/0x76\n   </TASK>\n  ......\n  ---[ end trace 0000000000000000 ]---\n\nThe oops is triggered when:\n\n1) A bpf program uses bpf_probe_read_kernel() to read from the vsyscall\npage and invokes copy_from_kernel_nofault() which in turn calls\n__get_user_asm().\n\n2) Because the vsyscall page address is not readable from kernel space', '\na page fault exception is triggered accordingly.\n\n3) handle_page_fault() considers the vsyscall page address as a user\nspace address instead of a kernel space address. This results in the\nfix-up setup by bpf not being applied and a page_fault_oops() is invoked\ndue to SMAP.\n\nConsidering handle_page_fault() has already considered the vsyscall page\naddress as a userspace address', ' fix the problem by disallowing vsyscall\npage read for copy_from_kernel_nofault().\n\nOriginally-by: Thomas Gleixner <tglx@linutronix.de>\nReported-by: syzbot+72aa0161922eba61b50e@syzkaller.appspotmail.com\nCloses: https://lore.kernel.org/bpf/CAG48ez06TZft=ATH1qh2c5mpS5BT8UakwNkzi6nvK5_djC-4Nw@mail.gmail.com\nReported-by: xingwei lee <xrivendell7@gmail.com>\nCloses: https://lore.kernel.org/bpf/CABOYnLynjBoFZOf3Z4BhaZkc5hx_kHfsjiW+UWLoB=w33LvScw@mail.gmail.com\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nReviewed-by: Sohil Mehta <sohil.mehta@intel.com>\nAcked-by: Thomas Gleixner <tglx@linutronix.de>\nLink: https://lore.kernel.org/r/20240202103935.3154011-3-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit disallows reading the vsyscall page through copy_from_kernel_nofault() in x86/mm for bpf programs.,"vsyscall,copy_from_kernel_nofault,page fault",It's a security fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['other']
682158ab532a5bd24399fec25b65fec561f0f6e9,682158ab532a5bd24399fec25b65fec561f0f6e9,Yonghong Song,yonghong.song@linux.dev,1707953391,Alexei Starovoitov,ast@kernel.org,1708033527,b181de0ece77b7575285af9c77080738c22eee7a,57354f5fdee8017783b5cc2e53b263641b6862e9,"bpf: Fix test verif_scale_strobemeta_subprogs failure due to llvm19

With latest llvm19"," I hit the following selftest failures with

  $ ./test_progs -j
  libbpf: prog 'on_event': BPF program load failed: Permission denied
  libbpf: prog 'on_event': -- BEGIN PROG LOAD LOG --
  combined stack size of 4 calls is 544. Too large
  verification time 1344153 usec
  stack depth 24+440+0+32
  processed 51008 insns (limit 1000000) max_states_per_insn 19 total_states 1467 peak_states 303 mark_read 146
  -- END PROG LOAD LOG --
  libbpf: prog 'on_event': failed to load: -13
  libbpf: failed to load object 'strobemeta_subprogs.bpf.o'
  scale_test:FAIL:expect_success unexpected error: -13 (errno 13)
  #498     verif_scale_strobemeta_subprogs:FAIL

The verifier complains too big of the combined stack size (544 bytes) which
exceeds the maximum stack limit 512. This is a regression from llvm19 ([1]).

In the above error log","["" the original stack depth is 24+440+0+32.\nTo satisfy interpreter's need"", ' in verifier the stack depth is adjusted to\n32+448+32+32=544 which exceeds 512', ' hence the error. The same adjusted\nstack size is also used for jit case.\n\nBut the jitted codes could use smaller stack size.\n\n  $ egrep -r stack_depth | grep round_up\n  arm64/net/bpf_jit_comp.c:       ctx->stack_size = round_up(prog->aux->stack_depth', ' 16);\n  loongarch/net/bpf_jit.c:        bpf_stack_adjust = round_up(ctx->prog->aux->stack_depth', ' 16);\n  powerpc/net/bpf_jit_comp.c:     cgctx.stack_size = round_up(fp->aux->stack_depth', ' 16);\n  riscv/net/bpf_jit_comp32.c:             round_up(ctx->prog->aux->stack_depth', ' STACK_ALIGN);\n  riscv/net/bpf_jit_comp64.c:     bpf_stack_adjust = round_up(ctx->prog->aux->stack_depth', ' 16);\n  s390/net/bpf_jit_comp.c:        u32 stack_depth = round_up(fp->aux->stack_depth', ' 8);\n  sparc/net/bpf_jit_comp_64.c:            stack_needed += round_up(stack_depth', ' 16);\n  x86/net/bpf_jit_comp.c:         EMIT3_off32(0x48', ' 0x81', ' 0xEC', ' round_up(stack_depth', ' 8));\n  x86/net/bpf_jit_comp.c: int tcc_off = -4 - round_up(stack_depth', ' 8);\n  x86/net/bpf_jit_comp.c:                     round_up(stack_depth', ' 8));\n  x86/net/bpf_jit_comp.c: int tcc_off = -4 - round_up(stack_depth', ' 8);\n  x86/net/bpf_jit_comp.c:         EMIT3_off32(0x48', ' 0x81', ' 0xC4', ' round_up(stack_depth', ' 8));\n\nIn the above', ' STACK_ALIGN in riscv/net/bpf_jit_comp32.c is defined as 16.\nSo stack is aligned in either 8 or 16', ' x86/s390 having 8-byte stack alignment and\nthe rest having 16-byte alignment.\n\nThis patch calculates total stack depth based on 16-byte alignment if jit is requested.\nFor the above failing case', ' the new stack size will be 32+448+0+32=512 and no verification\nfailure. llvm19 regression will be discussed separately in llvm upstream.\n\nThe verifier change caused three test failures as these tests compared messages\nwith stack size. More specifically', '\n  - test_global_funcs/global_func1: fail with interpreter mode and success with jit mode.\n    Adjusted stack sizes so both jit and interpreter modes will fail.\n  - async_stack_depth/{pseudo_call_check', ' async_call_root_check}: since jit and interpreter\n    will calculate different stack sizes', ' the failure msg is adjusted to omit those\n    specific stack size numbers.\n\n  [1] https://lore.kernel.org/bpf/32bde0f0-1881-46c9-931a-673be566c61d@linux.dev/\n\nSuggested-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240214232951.4113094-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit fixes a test failure caused by exceeding stack size limit due to llvm19 regression.,"fix, verifier, llvm19",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
57354f5fdee8017783b5cc2e53b263641b6862e9,57354f5fdee8017783b5cc2e53b263641b6862e9,Andrii Nakryiko,andrii@kernel.org,1707932460,Alexei Starovoitov,ast@kernel.org,1708030848,a02fe1abc888edac813b20bc648e475333d8c989,a4561f5afef8a8ff25a2cfd46d587f65869494f2,"bpf: improve duplicate source code line detection

Verifier log avoids printing the same source code line multiple times
when a consecutive block of BPF assembly instructions are covered by the
same original (C) source code line. This greatly improves verifier log
legibility.

Unfortunately"," this check is imperfect and in production applications it
quite often happens that verifier log will have multiple duplicated
source lines emitted","[' for no apparently good reason. E.g.', ' this is\nexcerpt from a real-world BPF application (with register states omitted\nfor clarity):\n\nBEFORE\n======\n; for (int i = 0; i < STROBE_MAX_MAP_ENTRIES; ++i) { @ strobemeta_probe.bpf.c:394\n5369: (07) r8 += 2                    ;\n5370: (07) r7 += 16                   ;\n; for (int i = 0; i < STROBE_MAX_MAP_ENTRIES; ++i) { @ strobemeta_probe.bpf.c:394\n5371: (07) r9 += 1                    ;\n5372: (79) r4 = *(u64 *)(r10 -32)     ;\n; for (int i = 0; i < STROBE_MAX_MAP_ENTRIES; ++i) { @ strobemeta_probe.bpf.c:394\n5373: (55) if r9 != 0xf goto pc+2\n; if (i >= map->cnt) @ strobemeta_probe.bpf.c:396\n5376: (79) r1 = *(u64 *)(r10 -40)     ;\n5377: (79) r1 = *(u64 *)(r1 +8)       ;\n; if (i >= map->cnt) @ strobemeta_probe.bpf.c:396\n5378: (dd) if r1 s<= r9 goto pc-5     ;\n; descr->key_lens[i] = 0; @ strobemeta_probe.bpf.c:398\n5379: (b4) w1 = 0                     ;\n5380: (6b) *(u16 *)(r8 -30) = r1      ;\n; task', ' data', ' off', ' STROBE_MAX_STR_LEN', ' map->entries[i].key); @ strobemeta_probe.bpf.c:400\n5381: (79) r3 = *(u64 *)(r7 -8)       ;\n5382: (7b) *(u64 *)(r10 -24) = r6     ;\n; task', ' data', ' off', ' STROBE_MAX_STR_LEN', ' map->entries[i].key); @ strobemeta_probe.bpf.c:400\n5383: (bc) w6 = w6                    ;\n; barrier_var(payload_off); @ strobemeta_probe.bpf.c:280\n5384: (bf) r2 = r6                    ;\n5385: (bf) r1 = r4                    ;\n\nAs can be seen', ' line 394 is emitted thrice', ' 396 is emitted twice', ' and\nline 400 is duplicated as well. Note that there are no intermingling\nother lines of source code in between these duplicates', "" so the issue is\nnot compiler reordering assembly instruction such that multiple original\nsource code lines are in effect.\n\nIt becomes more obvious what's going on if we look at *full* original line info\ninformation (using btfdump for this"", ' [0]):\n\n  #2764: line: insn #5363 --> 394:3 @ ./././strobemeta_probe.bpf.c\n            for (int i = 0; i < STROBE_MAX_MAP_ENTRIES; ++i) {\n  #2765: line: insn #5373 --> 394:21 @ ./././strobemeta_probe.bpf.c\n            for (int i = 0; i < STROBE_MAX_MAP_ENTRIES; ++i) {\n  #2766: line: insn #5375 --> 394:47 @ ./././strobemeta_probe.bpf.c\n            for (int i = 0; i < STROBE_MAX_MAP_ENTRIES; ++i) {\n  #2767: line: insn #5377 --> 394:3 @ ./././strobemeta_probe.bpf.c\n            for (int i = 0; i < STROBE_MAX_MAP_ENTRIES; ++i) {\n  #2768: line: insn #5378 --> 414:10 @ ./././strobemeta_probe.bpf.c\n            return off;\n\nWe can see that there are four line info records covering\ninstructions #5363 through #5377 (instruction indices are shifted due to\nsubprog instruction being appended to main program)', ' all of them are\npointing to the same C source code line #394. But each of them points to\na different part of that line', ' which is denoted by differing column\nnumbers (3', ' 21', ' 47', "" 3).\n\nBut verifier log doesn't distinguish between parts of the same source code line\nand doesn't emit this column number information"", "" so for end user it's just a\nrepetitive visual noise. So let's improve the detection of repeated source code\nline and avoid this.\n\nWith the changes in this patch"", ' we get this output for the same piece of BPF\nprogram log:\n\nAFTER\n=====\n; for (int i = 0; i < STROBE_MAX_MAP_ENTRIES; ++i) { @ strobemeta_probe.bpf.c:394\n5369: (07) r8 += 2                    ;\n5370: (07) r7 += 16                   ;\n5371: (07) r9 += 1                    ;\n5372: (79) r4 = *(u64 *)(r10 -32)     ;\n5373: (55) if r9 != 0xf goto pc+2\n; if (i >= map->cnt) @ strobemeta_probe.bpf.c:396\n5376: (79) r1 = *(u64 *)(r10 -40)     ;\n5377: (79) r1 = *(u64 *)(r1 +8)       ;\n5378: (dd) if r1 s<= r9 goto pc-5     ;\n; descr->key_lens[i] = 0; @ strobemeta_probe.bpf.c:398\n5379: (b4) w1 = 0                     ;\n5380: (6b) *(u16 *)(r8 -30) = r1      ;\n; task', ' data', ' off', ' STROBE_MAX_STR_LEN', ' map->entries[i].key); @ strobemeta_probe.bpf.c:400\n5381: (79) r3 = *(u64 *)(r7 -8)       ;\n5382: (7b) *(u64 *)(r10 -24) = r6     ;\n5383: (bc) w6 = w6                    ;\n; barrier_var(payload_off); @ strobemeta_probe.bpf.c:280\n5384: (bf) r2 = r6                    ;\n5385: (bf) r1 = r4                    ;\n\nAll the duplication is gone and the log is cleaner and less distracting.\n\n  [0] https://github.com/anakryiko/btfdump\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240214174100.2847419-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Improves detection of duplicate source code lines in eBPF verifier logs for better legibility.,duplicate detection logs,It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a4561f5afef8a8ff25a2cfd46d587f65869494f2,a4561f5afef8a8ff25a2cfd46d587f65869494f2,Andrii Nakryiko,andrii@kernel.org,1707870191,Daniel Borkmann,daniel@iogearbox.net,1707951222,d0fae642023a578a86c291fb3f1282aed287b4cc,1159d27852207e8efb8d6ef2dae5aaa87ec4e225,"bpf: Use O(log(N)) binary search to find line info record

Real-world BPF applications keep growing in size. Medium-sized production
application can easily have 50K+ verified instructions"," and its line
info section in .BTF.ext has more than 3K entries.

When verifier emits log with log_level>=1","[' it annotates assembly code\nwith matched original C source code. Currently it uses linear search\nover line info records to find a match. As complexity of BPF\napplications grows', ' this O(K * N) approach scales poorly.\n\nSo', "" let's instead of linear O(N) search for line info record use faster\nequivalent O(log(N)) binary search algorithm. It's not a plain binary\nsearch"", "" as we don't look for exact match. It's an upper bound search\nvariant"", ' looking for rightmost line info record that starts at or before\ngiven insn_off.\n\nSome unscientific measurements were done before and after this change.\nThey were done in VM and fluctuate a bit', "" but overall the speed up is\nundeniable.\n\nBASELINE\n========\nFile                              Program           Duration (us)   Insns\n--------------------------------  ----------------  -------------  ------\nkatran.bpf.o                      balancer_ingress        2497130  343552\npyperf600.bpf.linked3.o           on_event               12389611  627288\nstrobelight_pyperf_libbpf.o       on_py_event              387399   52445\n--------------------------------  ----------------  -------------  ------\n\nBINARY SEARCH\n=============\n\nFile                              Program           Duration (us)   Insns\n--------------------------------  ----------------  -------------  ------\nkatran.bpf.o                      balancer_ingress        2339312  343552\npyperf600.bpf.linked3.o           on_event                5602203  627288\nstrobelight_pyperf_libbpf.o       on_py_event              294761   52445\n--------------------------------  ----------------  -------------  ------\n\nWhile Katran's speed up is pretty modest (about 105ms"", ' or 6%)', "" for\nproduction pyperf BPF program (on_py_event) it's much greater already"", ""\ngoing from 387ms down to 295ms (23% improvement).\n\nLooking at BPF selftests's biggest pyperf example"", ' we can see even more\ndramatic improvement', ' shaving more than 50% of time', ' going from 12.3s\ndown to 5.6s.\n\nDifferent amount of improvement is the function of overall amount of BPF\nassembly instructions in .bpf.o files (which contributes to how much\nline info records there will be and thus', ' on average', ' how much time linear\nsearch will take)', ' among other things:\n\n$ llvm-objdump -d katran.bpf.o | wc -l\n3863\n$ llvm-objdump -d strobelight_pyperf_libbpf.o | wc -l\n6997\n$ llvm-objdump -d pyperf600.bpf.linked3.o | wc -l\n87854\n\nGranted', ' this only applies to debugging cases (e.g.', ' using veristat', ' or\nfailing verification in production)', ' but seems worth doing to improve\noverall developer experience anyways.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/bpf/20240214002311.2197116-1-andrii@kernel.org\n', '']",The commit optimizes line info record lookup in bpf by implementing a binary search to improve performance.,"binary search, line info, performance",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e3a9ee963ad8ba677ca925149812c5932b49af69,e3a9ee963ad8ba677ca925149812c5932b49af69,Nathan Chancellor,nathan@kernel.org,1707789910,Masahiro Yamada,masahiroy@kernel.org,1707947800,135acef85d1618fde9c263fb295e633637baad58,6388cfd0e69b56ca640610f1bf29334619d18142,"kbuild: Fix changing ELF file type for output of gen_btf for big endian

Commit 90ceddcb4950 (""bpf: Support llvm-objcopy for vmlinux BTF"")
changed the ELF type of .btf.vmlinux.bin.o to ET_REL via dd"," which works
fine for little endian platforms:

   00000000  7f 45 4c 46 02 01 01 00  00 00 00 00 00 00 00 00  |.ELF............|
  -00000010  03 00 b7 00 01 00 00 00  00 00 00 80 00 80 ff ff  |................|
  +00000010  01 00 b7 00 01 00 00 00  00 00 00 80 00 80 ff ff  |................|

However","[' for big endian platforms', ' it changes the wrong byte', ' resulting\nin an invalid ELF file type', ' which ld.lld rejects:\n\n   00000000  7f 45 4c 46 02 02 01 00  00 00 00 00 00 00 00 00  |.ELF............|\n  -00000010  00 03 00 16 00 00 00 01  00 00 00 00 00 10 00 00  |................|\n  +00000010  01 03 00 16 00 00 00 01  00 00 00 00 00 10 00 00  |................|\n\n  Type:                              <unknown>: 103\n\n  ld.lld: error: .btf.vmlinux.bin.o: unknown file type\n\nFix this by updating the entire 16-bit e_type field rather than just a\nsingle byte', ' so that everything works correctly for all platforms and\nlinkers.\n\n   00000000  7f 45 4c 46 02 02 01 00  00 00 00 00 00 00 00 00  |.ELF............|\n  -00000010  00 03 00 16 00 00 00 01  00 00 00 00 00 10 00 00  |................|\n  +00000010  00 01 00 16 00 00 00 01  00 00 00 00 00 10 00 00  |................|\n\n  Type:                              REL (Relocatable file)\n\nWhile in the area', "" update the comment to mention that binutils 2.35+\nmatches LLD's behavior of rejecting an ET_EXEC input"", ' which occurred\nafter the comment was added.\n\nCc: stable@vger.kernel.org\nFixes: 90ceddcb4950 (""bpf: Support llvm-objcopy for vmlinux BTF"")\nLink: https://github.com/llvm/llvm-project/pull/75643\nSuggested-by: Masahiro Yamada <masahiroy@kernel.org>\nSigned-off-by: Nathan Chancellor <nathan@kernel.org>\nReviewed-by: Fangrui Song <maskray@google.com>\nReviewed-by: Nicolas Schier <nicolas@fjasle.eu>\nReviewed-by: Kees Cook <keescook@chromium.org>\nReviewed-by: Justin Stitt <justinstitt@google.com>\nSigned-off-by: Masahiro Yamada <masahiroy@kernel.org>\n', '']",Fixes an ELF file type change issue for big endian platforms in gen_btf output.,"big endian, ELF file, gen_btf",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1159d27852207e8efb8d6ef2dae5aaa87ec4e225,1159d27852207e8efb8d6ef2dae5aaa87ec4e225,Matt Bobrowski,mattbobrowski@google.com,1707902063,Andrii Nakryiko,andrii@kernel.org,1707932926,b95004b53f9c6ea8b5bd0c9570668b1807933317,7cc13adbd057f1905564ec2a254883d7fd407deb,"libbpf: Make remark about zero-initializing bpf_*_info structs

In some situations"," if you fail to zero-initialize the
bpf_{prog","['map', 'btf', 'link}_info structs supplied to the set of LIBBPF\nhelpers bpf_{prog', 'map', 'btf', 'link}_get_info_by_fd()', "" you can expect the\nhelper to return an error. This can possibly leave people in a\nsituation where they're scratching their heads for an unnnecessary\namount of time. Make an explicit remark about the requirement of\nzero-initializing the supplied bpf_{prog"", 'map', 'btf', 'link}_info structs\nfor the respective LIBBPF helpers.\n\nInternally', ' LIBBPF helpers bpf_{prog', 'map', 'btf', 'link}_get_info_by_fd()\ncall into bpf_obj_get_info_by_fd() where the bpf(2)\nBPF_OBJ_GET_INFO_BY_FD command is used. This specific command is\neffectively backed by restrictions enforced by the\nbpf_check_uarg_tail_zero() helper. This function ensures that if the\nsize of the supplied bpf_{prog', 'map', 'btf', 'link}_info structs are larger\nthan what the kernel can handle', "" trailing bits are zeroed. This can be\na problem when compiling against UAPI headers that don't necessarily\nmatch the sizes of the same underlying types known to the kernel.\n\nSigned-off-by: Matt Bobrowski <mattbobrowski@google.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/bpf/ZcyEb8x4VbhieWsL@google.com\n"", '']",The commit addresses the necessity of zero-initializing bpf_info structs in the libbpf library.,"zero-initializing,bpf_info,libbpf",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e37243b65d528a8a9f8b9a57a43885f8e8dfc15c,e37243b65d528a8a9f8b9a57a43885f8e8dfc15c,Gianmarco Lusvardi,glusvardi@posteo.net,1707865546,Daniel Borkmann,daniel@iogearbox.net,1707927048,8adfff45546c2e37126ea53c33157429df6edb6c,2127c604383666675789fd4a5fc2aead46c73aad,bpf," scripts: Correct GPL license name

The bpf_doc script refers to the GPL as the ""GNU Privacy License"".
I strongly suspect that the author wanted to refer to the GNU General
Public License","[' under which the Linux kernel is released', ' as', ' to the\nbest of my knowledge', ' there is no license named ""GNU Privacy License"".\nThis patch corrects the license name in the script accordingly.\n\nFixes: 56a092c89505 (""bpf: add script and prepare bpf.h for new helpers documentation"")\nSigned-off-by: Gianmarco Lusvardi <glusvardi@posteo.net>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Quentin Monnet <quentin@isovalent.com>\nLink: https://lore.kernel.org/bpf/20240213230544.930018-3-glusvardi@posteo.net\n', '']",Fix typo in bpf_doc script by correcting 'GNU Privacy License' to 'GNU General Public License'.,"typo, GPL, correction",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
7cc13adbd057f1905564ec2a254883d7fd407deb,7cc13adbd057f1905564ec2a254883d7fd407deb,Andrii Nakryiko,andrii@kernel.org,1707782384,Alexei Starovoitov,ast@kernel.org,1707879092,8bca01f6d20b084b75c77f1a00bb1694fb50e29b,96adbf7125e49687e5c1dbd8a241c68e2441da98,"bpf: emit source code file name and line number in verifier log

As BPF applications grow in size and complexity and are separated into
multiple .bpf.c files that are statically linked together"," it becomes
harder and harder to match verifier's BPF assembly level output to
original C code. While often annotated C source code is unique enough to
be able to identify the file it belongs to","[' quite often this is actually\nproblematic as parts of source code can be quite generic.\n\nLong story short', ' it is very useful to see source code file name and\nline number information along with the original C code. Verifier already\nknows this information', ' we just need to output it.\n\nThis patch extends verifier log with file name and line number\ninformation', ' emitted next to original (presumably C) source code', '\nannotating BPF assembly output', ' like so:\n\n  ; <original C code> @ <filename>.bpf.c:<line>\n\nIf file name has directory names in it', ' they are stripped away. This\nshould be fine in practice as file names tend to be pretty unique with\nC code anyways', ' and keeping log size smaller is always good.\n\nIn practice this might look something like below', ' where some code is\ncoming from application files', "" while others are from libbpf's usdt.bpf.h\nheader file:\n\n  ; if (STROBEMETA_READ( @ strobemeta_probe.bpf.c:534\n  5592: (79) r1 = *(u64 *)(r10 -56)     ; R1_w=mem_or_null(id=1589"", 'sz=7680) R10=fp0\n  5593: (7b) *(u64 *)(r10 -56) = r1     ; R1_w=mem_or_null(id=1589', 'sz=7680) R10=fp0\n  5594: (79) r3 = *(u64 *)(r10 -8)      ; R3_w=scalar() R10=fp0 fp-8=mmmmmmmm\n\n  ...\n\n  170: (71) r1 = *(u8 *)(r8 +15)        ; frame1: R1_w=scalar(...) R8_w=map_value(map=__bpf_usdt_spec', 'ks=4', 'vs=208)\n  171: (67) r1 <<= 56                   ; frame1: R1_w=scalar(...)\n  172: (c7) r1 s>>= 56                  ; frame1: R1_w=scalar(smin=smin32=-128', 'smax=smax32=127)\n  ; val <<= arg_spec->arg_bitshift; @ usdt.bpf.h:183\n  173: (67) r1 <<= 32                   ; frame1: R1_w=scalar(...)\n  174: (77) r1 >>= 32                   ; frame1: R1_w=scalar(smin=0', 'smax=umax=0xffffffff', 'var_off=(0x0; 0xffffffff))\n  175: (79) r2 = *(u64 *)(r10 -8)       ; frame1: R2_w=scalar() R10=fp0 fp-8=mmmmmmmm\n  176: (6f) r2 <<= r1                   ; frame1: R1_w=scalar(smin=0', 'smax=umax=0xffffffff', 'var_off=(0x0; 0xffffffff)) R2_w=scalar()\n  177: (7b) *(u64 *)(r10 -8) = r2       ; frame1: R2_w=scalar(id=61) R10=fp0 fp-8_w=scalar(id=61)\n  ; if (arg_spec->arg_signed) @ usdt.bpf.h:184\n  178: (bf) r3 = r2                     ; frame1: R2_w=scalar(id=61) R3_w=scalar(id=61)\n  179: (7f) r3 >>= r1                   ; frame1: R1_w=scalar(smin=0', 'smax=umax=0xffffffff', 'var_off=(0x0; 0xffffffff)) R3_w=scalar()\n  ; if (arg_spec->arg_signed) @ usdt.bpf.h:184\n  180: (71) r4 = *(u8 *)(r8 +14)\n  181: safe\n\nlog_fixup tests needed a minor adjustment as verifier log output\nincreased a bit and that test is quite sensitive to such changes.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240212235944.2816107-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Enhance verifier log with source file and line number for better code traceability in BPF applications.,"verifier, source code, log",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
96adbf7125e49687e5c1dbd8a241c68e2441da98,96adbf7125e49687e5c1dbd8a241c68e2441da98,Alexei Starovoitov,ast@kernel.org,1707878807,Alexei Starovoitov,ast@kernel.org,1707878807,26d39c1ca7d67401245a928139012ad7624faad1,32e18e7688c6847b0c9db073aafb00639ecf576c 63d5a33fb4ec2a4ed6907c8ac144b6f10f6dba47,"Merge branch 'fix-global-subprog-ptr_to_ctx-arg-handling'

Andrii Nakryiko says:

====================
Fix global subprog PTR_TO_CTX arg handling

Fix confusing and incorrect inference of PTR_TO_CTX argument type in BPF
global subprogs. For some program types (iters", tracepoint,"[' any program type\nthat doesn\'t have fixed named ""canonical"" context type) when user uses (in\na correct and valid way) a pointer argument to user-defined anonymous struct\ntype', ' verifier will incorrectly assume that it has to be PTR_TO_CTX argument.\nWhile it should be just a PTR_TO_MEM argument with allowed size calculated\nfrom user-provided (even if anonymous) struct.\n\nThis did come up in practice and was very confusing to users', "" so let's prevent\nthis going forward. We had to do a slight refactoring of\nbtf_get_prog_ctx_type() to make it easy to support a special s390x KPROBE use\ncases. See details in respective patches.\n\nv1->v2:\n  - special-case typedef bpf_user_pt_regs_t handling for KPROBE programs"", '\n    fixing s390x after changes in patch #2.\n====================\n\nLink: https://lore.kernel.org/r/20240212233221.2575350-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes incorrect inference of PTR_TO_CTX argument type in BPF global subprograms.,"PTR_TO_CTX,global subprog,fix",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,['tracepoints like programs']
63d5a33fb4ec2a4ed6907c8ac144b6f10f6dba47,63d5a33fb4ec2a4ed6907c8ac144b6f10f6dba47,Andrii Nakryiko,andrii@kernel.org,1707780741,Alexei Starovoitov,ast@kernel.org,1707878807,26d39c1ca7d67401245a928139012ad7624faad1,879bbe7aa4afa80acf72a1cad7f52416ea78c52d,"selftests/bpf: add anonymous user struct as global subprog arg test

Add tests validating that kernel handles pointer to anonymous struct
argument as PTR_TO_MEM case"," not as PTR_TO_CTX case.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240212233221.2575350-5-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Add a test case for handling anonymous struct pointers as PTR_TO_MEM in eBPF selftests.,"anonymous, struct, test",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
879bbe7aa4afa80acf72a1cad7f52416ea78c52d,879bbe7aa4afa80acf72a1cad7f52416ea78c52d,Andrii Nakryiko,andrii@kernel.org,1707780740,Alexei Starovoitov,ast@kernel.org,1707878807,7167d3b75c871d1ba5001c27c13a751e2f0b77a8,824c58fb1090ae5e502284400682e30841280a87,"bpf: don't infer PTR_TO_CTX for programs with unnamed context type

For program types that don't have named context type name (e.g."," BPF
iterator programs or tracepoint programs)","["" ctx_tname will be a non-NULL\nempty string. For such programs it shouldn't be possible to have\nPTR_TO_CTX argument for global subprogs based on type name alone.\narg:ctx tag is the only way to have PTR_TO_CTX passed into global\nsubprog for such program types.\n\nFix this loophole"", ' which currently would assume PTR_TO_CTX whenever\nuser uses a pointer to anonymous struct as an argument to their global\nsubprogs. This happens in practice with the following (quite common', "" in\npractice) approach:\n\ntypedef struct { /* anonymous */\n    int x;\n} my_type_t;\n\nint my_subprog(my_type_t *arg) { ... }\n\nUser's intent is to have PTR_TO_MEM argument for `arg`"", ' but verifier\nwill complain about expecting PTR_TO_CTX.\n\nThis fix also closes unintended s390x-specific KPROBE handling of\nPTR_TO_CTX case. Selftest change is necessary to accommodate this.\n\nFixes: 91cc1a99740e (""bpf: Annotate context types"")\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240212233221.2575350-4-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Prevent automatic inference of PTR_TO_CTX for eBPF programs with unnamed context types.,"PTR_TO_CTX, unnamed context, programs",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['tracepoints like programs', ""It's not related to any of the above.""]"
824c58fb1090ae5e502284400682e30841280a87,824c58fb1090ae5e502284400682e30841280a87,Andrii Nakryiko,andrii@kernel.org,1707780739,Alexei Starovoitov,ast@kernel.org,1707878807,268b666e38890c286cc91c2cc2780a1304706902,fb5b86cfd4ef21ea18966718f6bf6c8f1b9df12e,"bpf: handle bpf_user_pt_regs_t typedef explicitly for PTR_TO_CTX global arg

Expected canonical argument type for global function arguments
representing PTR_TO_CTX is `bpf_user_pt_regs_t *ctx`. This currently
works on s390x by accident because kernel resolves such typedef to
underlying struct (which is anonymous on s390x)"," and erroneously
accepting it as expected context type. We are fixing this problem next","['\nwhich would break s390x arch', ' so we need to handle `bpf_user_pt_regs_t`\ncase explicitly for KPROBE programs.\n\nFixes: 91cc1a99740e (""bpf: Annotate context types"")\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240212233221.2575350-3-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixed handling of bpf_user_pt_regs_t typedef for PTR_TO_CTX global argument to ensure proper context type recognition across architectures.,bpf typedef PTR_TO_CTX,It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fb5b86cfd4ef21ea18966718f6bf6c8f1b9df12e,fb5b86cfd4ef21ea18966718f6bf6c8f1b9df12e,Andrii Nakryiko,andrii@kernel.org,1707780738,Alexei Starovoitov,ast@kernel.org,1707878806,eb856ee133bdfa5517d4e25a7331ce560ba56b22,32e18e7688c6847b0c9db073aafb00639ecf576c,"bpf: simplify btf_get_prog_ctx_type() into btf_is_prog_ctx_type()

Return result of btf_get_prog_ctx_type() is never used and callers only
check NULL vs non-NULL case to determine if given type matches expected
PTR_TO_CTX type. So rename function to `btf_is_prog_ctx_type()` and
return a simple true/false. We'll use this simpler interface to handle
kprobe program type's special typedef case in the next patch.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240212233221.2575350-2-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Refactored btf_get_prog_ctx_type() to btf_is_prog_ctx_type() simplifying its interface for detecting PTR_TO_CTX types.,"BTF,simplify,kprobe",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),['kprobe/uprobe/ftrace like programs']
32e18e7688c6847b0c9db073aafb00639ecf576c,32e18e7688c6847b0c9db073aafb00639ecf576c,Oliver Crumrine,ozlinuxc@gmail.com,1707507682,Martin KaFai Lau,martin.lau@kernel.org,1707867677,dd578e3b4d1a6678286ee3b1f1fcbc70b60c411d,2c21a0f67c8ce334b8a58332e8c2d71694bef0ab,"bpf: remove check in __cgroup_bpf_run_filter_skb

Originally"," this patch removed a redundant check in
BPF_CGROUP_RUN_PROG_INET_EGRESS","[' as the check was already being done in\nthe function it called', ' __cgroup_bpf_run_filter_skb. For v2', ' it was\nreccomended that I remove the check from __cgroup_bpf_run_filter_skb', '\nand add the checks to the other macro that calls that function', '\nBPF_CGROUP_RUN_PROG_INET_INGRESS.\n\nTo sum it up', ' checking that the socket exists and that it is a full\nsocket is now part of both macros BPF_CGROUP_RUN_PROG_INET_EGRESS and\nBPF_CGROUP_RUN_PROG_INET_INGRESS', ' and it is no longer part of the\nfunction they call', ' __cgroup_bpf_run_filter_skb.\n\nv3->v4: Fixed weird merge conflict.\nv2->v3: Sent to bpf-next instead of generic patch\nv1->v2: Addressed feedback about where check should be removed.\n\nSigned-off-by: Oliver Crumrine <ozlinuxc@gmail.com>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nLink: https://lore.kernel.org/r/7lv62yiyvmj5a7eozv2iznglpkydkdfancgmbhiptrgvgan5sy@3fl3onchgdz3\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Removed a redundant check in BPF_CGROUP_RUN_PROG_INET_EGRESS function.,"remove, redundant, cgroup",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,['cgroup like programs']
2c21a0f67c8ce334b8a58332e8c2d71694bef0ab,2c21a0f67c8ce334b8a58332e8c2d71694bef0ab,Martin KaFai Lau,martin.lau@kernel.org,1707859692,Martin KaFai Lau,martin.lau@kernel.org,1707866204,2f57131d002ff067db53ab4a62ccd8d5f735ef54,dc8543b597c282643a433e9a8af0459ed3046908 00f239eccf461a6403b3c16e767d04f3954cae98,"Merge branch 'Support PTR_MAYBE_NULL for struct_ops arguments.'

Kui-Feng Lee says:

====================
Allow passing null pointers to the operators provided by a struct_ops
object. This is an RFC to collect feedbacks/opinions.

The function pointers that are passed to struct_ops operators (the function
pointers) are always considered reliable until now. They cannot be
null. However", in certain scenarios,"[' it should be possible to pass null\npointers to these operators. For instance', ' sched_ext may pass a null\npointer in the struct task type to an operator that is provided by its\nstruct_ops objects.\n\nThe proposed solution here is to add PTR_MAYBE_NULL annotations to\narguments and create instances of struct bpf_ctx_arg_aux (arg_info) for\nthese arguments. These arg_infos will be installed at\nprog->aux->ctx_arg_info and will be checked by the BPF verifier when\nloading the programs. When a struct_ops program accesses arguments in the\nctx', ' the verifier will call btf_ctx_access() (through\nbpf_verifier_ops->is_valid_access) to verify the access. btf_ctx_access()\nwill check arg_info and use the information of the matched arg_info to\nproperly set reg_type.\n\nFor nullable arguments', ' this patch sets an arg_info to label them with\nPTR_TO_BTF_ID | PTR_TRUSTED | PTR_MAYBE_NULL. This enforces the verifier to\ncheck programs and ensure that they properly check the pointer. The\nprograms should check if the pointer is null before reading/writing the\npointed memory.\n\nThe implementer of a struct_ops should annotate the arguments that can\nbe null. The implementer should define a stub function (empty) as a\nplaceholder for each defined operator. The name of a stub function\nshould be in the pattern ""<st_op_type>__<operator name>"". For example', '\nfor test_maybe_null of struct bpf_testmod_ops', ' it\'s stub function name\nshould be ""bpf_testmod_ops__test_maybe_null"". You mark an argument\nnullable by suffixing the argument name with ""__nullable"" at the stub\nfunction.  Here is the example in bpf_testmod.c.\n\n  static int bpf_testmod_ops__test_maybe_null(int dummy', '\n                                              struct task_struct *task__nullable)\n  {\n          return 0;\n  }\n\nThis means that the argument 1 (2nd) of bpf_testmod_ops->test_maybe_null', '\nwhich is a function pointer that can be null. With this annotation', ' the\nverifier will understand how to check programs using this arguments.  A BPF\nprogram that implement test_maybe_null should check the pointer to make\nsure it is not null before using it. For example', '\n\n  if (task__nullable)\n      save_tgid = task__nullable->tgid\n\nWithout the check', ' the verifier will reject the program.\n\nSince we already has stub functions for kCFI', ' we just reuse these stub\nfunctions with the naming convention mentioned earlier. These stub\nfunctions with the naming convention is only required if there are nullable\narguments to annotate. For functions without nullable arguments', ' stub\nfunctions are not necessary for the purpose of this patch.\n---\nMajor changes from v7:\n\n - Update a comment that is out of date.\n\nMajor changes from v6:\n\n - Remove ""len"" from bpf_struct_ops_desc_release().\n\n - Rename arg_info(s) to info', ' and rename all_arg_info to arg_info in\n   prepare_arg_info().\n\n - Rename arg_info to info in struct bpf_struct_ops_arg_info.\n\nMajor changes from v5:\n\n - Rename all member_arg_info variables.\n\n - Refactor to bpf_struct_ops_desc_release() to share code\n   between btf_free_struct_ops_tab() and bpf_struct_ops_desc_init().\n\n - Refactor to btf_param_match_suffix(). (Add a new patch as the part 2.)\n\n - Clean up the commit log and remaining code in the patch of test cases.\n\n - Update a comment in struct_ops_maybe_null.c.\n\nMajor changes from v4:\n\n - Remove the support of pointers to types other than struct\n   types. That would be a separate patchset.\n\n   - Remove the patch about extending PTR_TO_BTF_ID.\n\n   - Remove the test against various pointer types from selftests.\n\n - Remove the patch ""bpf: Remove an unnecessary check"" and send that\n   patch separately.\n\n - Remove member_arg_info_cnt from struct bpf_struct_ops_desc.\n\n - Use btf_id from FUNC_PROTO of a function pointer instead of a stub\n   function.\n\nMajor changes from v3:\n\n - Move the code collecting argument information to prepare_arg_info()\n   called in the loop in bpf_struct_ops_desc_init().\n\n - Simplify the memory allocation by having separated arg_info for\n   each member of a struct_ops type.\n\n - Extend PTR_TO_BTF_ID to pointers to scalar types and array types', '\n   not only to struct types.\n\nMajor changes from v2:\n\n - Remove dead code.\n\n - Add comments to explain the code itself.\n\nMajor changes from v1:\n\n - Annotate arguments by suffixing argument names with ""__nullable"" at\n   stub functions.\n\nv7: https://lore.kernel.org/all/20240209020053.1132710-1-thinker.li@gmail.com/\nv6: https://lore.kernel.org/all/20240208065103.2154768-1-thinker.li@gmail.com/\nv5: https://lore.kernel.org/all/20240206063833.2520479-1-thinker.li@gmail.com/\nv4: https://lore.kernel.org/all/20240202220516.1165466-1-thinker.li@gmail.com/\nv3: https://lore.kernel.org/all/20240122212217.1391878-1-thinker.li@gmail.com/\nv2: https://lore.kernel.org/all/20240118224922.336006-1-thinker.li@gmail.com/\n====================\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",The commit allows null pointers for struct_ops function arguments in certain scenarios.,"null,pointers,struct_ops",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
00f239eccf461a6403b3c16e767d04f3954cae98,00f239eccf461a6403b3c16e767d04f3954cae98,Kui-Feng Lee,thinker.li@gmail.com,1707446270,Martin KaFai Lau,martin.lau@kernel.org,1707866204,2f57131d002ff067db53ab4a62ccd8d5f735ef54,1611603537a4b88cec7993f32b70c03113801a46,"selftests/bpf: Test PTR_MAYBE_NULL arguments of struct_ops operators.

Test if the verifier verifies nullable pointer arguments correctly for BPF
struct_ops programs.

""test_maybe_null"" in struct bpf_testmod_ops is the operator defined for the
test cases here.

A BPF program should check a pointer for NULL beforehand to access the
value pointed by the nullable pointer arguments"," or the verifier should
reject the programs. The test here includes two parts; the programs
checking pointers properly and the programs not checking pointers
beforehand. The test checks if the verifier accepts the programs checking
properly and rejects the programs not checking at all.

Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240209023750.1153905-5-thinker.li@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Add tests for nullable pointer verification in BPF struct_ops programs.,"selftests,bpf,nullable",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1611603537a4b88cec7993f32b70c03113801a46,1611603537a4b88cec7993f32b70c03113801a46,Kui-Feng Lee,thinker.li@gmail.com,1707446269,Martin KaFai Lau,martin.lau@kernel.org,1707866204,7ab0b168954609b13b81b777444c8e574ac4fb3b,6115a0aeef01aef152ad7738393aad11422bfb82,"bpf: Create argument information for nullable arguments.

Collect argument information from the type information of stub functions to
mark arguments of BPF struct_ops programs with PTR_MAYBE_NULL if they are
nullable.  A nullable argument is annotated by suffixing ""__nullable"" at
the argument name of stub function.

For nullable arguments"," this patch sets a struct bpf_ctx_arg_aux to label
their reg_type with PTR_TO_BTF_ID | PTR_TRUSTED | PTR_MAYBE_NULL. This
makes the verifier to check programs and ensure that they properly check
the pointer. The programs should check if the pointer is null before
accessing the pointed memory.

The implementer of a struct_ops type should annotate the arguments that can
be null. The implementer should define a stub function (empty) as a
placeholder for each defined operator. The name of a stub function should
be in the pattern ""<st_op_type>__<operator name>"". For example","[' for\ntest_maybe_null of struct bpf_testmod_ops', ' it\'s stub function name should\nbe ""bpf_testmod_ops__test_maybe_null"". You mark an argument nullable by\nsuffixing the argument name with ""__nullable"" at the stub function.\n\nSince we already has stub functions for kCFI', ' we just reuse these stub\nfunctions with the naming convention mentioned earlier. These stub\nfunctions with the naming convention is only required if there are nullable\narguments to annotate. For functions having not nullable arguments', ' stub\nfunctions are not necessary for the purpose of this patch.\n\nThis patch will prepare a list of struct bpf_ctx_arg_aux', ' aka arg_info', ' for\neach member field of a struct_ops type.  ""arg_info"" will be assigned to\n""prog->aux->ctx_arg_info"" of BPF struct_ops programs in\ncheck_struct_ops_btf_id() so that it can be used by btf_ctx_access() later\nto set reg_type properly for the verifier.\n\nSigned-off-by: Kui-Feng Lee <thinker.li@gmail.com>\nLink: https://lore.kernel.org/r/20240209023750.1153905-4-thinker.li@gmail.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Adds handling for nullable arguments in BPF struct_ops by marking them with PTR_MAYBE_NULL.,"nullable, arguments, struct_ops",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6115a0aeef01aef152ad7738393aad11422bfb82,6115a0aeef01aef152ad7738393aad11422bfb82,Kui-Feng Lee,thinker.li@gmail.com,1707446268,Martin KaFai Lau,martin.lau@kernel.org,1707866204,347d202fac2f91df9dcdc3c772c970860390fc86,77c0208e199ccb0986fb3612f2409c8cdcb036ad,"bpf: Move __kfunc_param_match_suffix() to btf.c.

Move __kfunc_param_match_suffix() to btf.c and rename it as
btf_param_match_suffix(). It can be reused by bpf_struct_ops later.

Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240209023750.1153905-3-thinker.li@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,The function __kfunc_param_match_suffix() is moved and renamed to btf_param_match_suffix() for reuse soon.,"bpf,moved,reuse",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
77c0208e199ccb0986fb3612f2409c8cdcb036ad,77c0208e199ccb0986fb3612f2409c8cdcb036ad,Kui-Feng Lee,thinker.li@gmail.com,1707446267,Martin KaFai Lau,martin.lau@kernel.org,1707866204,f8b3520a1efab15f6e766f7f559887c2964606f5,dc8543b597c282643a433e9a8af0459ed3046908,"bpf: add btf pointer to struct bpf_ctx_arg_aux.

Enable the providers to use types defined in a module instead of in the
kernel (btf_vmlinux).

Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240209023750.1153905-2-thinker.li@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Add BTF pointer in struct bpf_ctx_arg_aux to enable use of module-defined types.,"BTF, bpf_ctx_arg_aux, module",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
dc8543b597c282643a433e9a8af0459ed3046908,dc8543b597c282643a433e9a8af0459ed3046908,Dave Thaler,dthaler1968@googlemail.com,1707430489,Daniel Borkmann,daniel@iogearbox.net,1707862455,482bd672866f482580e325473d1296224ec472d6,12bbcf8e840f40b82b02981e96e0a5fbb0703ea9,bpf," docs: Update ISA document title

* Use ""Instruction Set Architecture (ISA)"" instead of ""Instruction Set
  Specification""
* Remove version number

As previously discussed on the mailing list at
https://mailarchive.ietf.org/arch/msg/bpf/SEpn3OL9TabNRn-4rDX9A6XVbjM/

Signed-off-by: Dave Thaler <dthaler1968@gmail.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: David Vernet <void@manifault.com>
Link: https://lore.kernel.org/bpf/20240208221449.12274-1-dthaler1968@gmail.com
",[''],Updated the BPF ISA document by changing the title and removing the version number.,"ISA, document, update",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
2127c604383666675789fd4a5fc2aead46c73aad,2127c604383666675789fd4a5fc2aead46c73aad,Sebastian Andrzej Siewior,bigeasy@linutronix.de,1706891540,Daniel Borkmann,daniel@iogearbox.net,1707862229,02052833aea3ecc5810989ab53e4eeaa550c4a5f,11f522256e9043b0fcd2f994278645d3e201d20c,"xsk: Add truesize to skb_add_rx_frag().

xsk_build_skb() allocates a page and adds it to the skb via
skb_add_rx_frag() and specifies 0 for truesize. This leads to a warning
in skb_add_rx_frag() with CONFIG_DEBUG_NET enabled because size is
larger than truesize.

Increasing truesize requires to add the same amount to socket's
sk_wmem_alloc counter in order not to underflow the counter during
release in the destructor (sock_wfree()).

Pass the size of the allocated page as truesize to skb_add_rx_frag().
Add this mount to socket's sk_wmem_alloc counter.

Fixes: cf24f5a5feea (""xsk: add support for AF_XDP multi-buffer on Tx path"")
Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>
Link: https://lore.kernel.org/bpf/20240202163221.2488589-1-bigeasy@linutronix.de
",,The commit addresses a warning by adding truesize to skb_add_rx_frag and updating sk_wmem_alloc accordingly.,"truesize, xsk, skb_add_rx_frag",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['socket like programs']
12bbcf8e840f40b82b02981e96e0a5fbb0703ea9,12bbcf8e840f40b82b02981e96e0a5fbb0703ea9,Cupertino Miranda,cupertino.miranda@oracle.com,1707845743,Andrii Nakryiko,andrii@kernel.org,1707852492,9238bb36e780acb761de92836f81c420f941aeb8,52dbd67dff5d050e99301100e2cac578eef9b2e9,"libbpf: Add support to GCC in CORE macro definitions

Due to internal differences between LLVM and GCC the current
implementation for the CO-RE macros does not fit GCC parser"," as it will
optimize those expressions even before those would be accessible by the
BPF backend.

As examples","[' the following would be optimized out with the original\ndefinitions:\n  - As enums are converted to their integer representation during\n  parsing', ' the IR would not know how to distinguish an integer\n  constant from an actual enum value.\n  - Types need to be kept as temporary variables', ' as the existing type\n  casts of the 0 address (as expanded for LLVM)', ' are optimized away by\n  the GCC C parser', ' never really reaching GCCs IR.\n\nAlthough', ' the macros appear to add extra complexity', ' the expanded code\nis removed from the compilation flow very early in the compilation\nprocess', ' not really affecting the quality of the generated assembly.\n\nSigned-off-by: Cupertino Miranda <cupertino.miranda@oracle.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240213173543.1397708-1-cupertino.miranda@oracle.com\n', '']",Add support for GCC in CO-RE macro definitions in libbpf.,"GCC, CORE, libbpf",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
52dbd67dff5d050e99301100e2cac578eef9b2e9,52dbd67dff5d050e99301100e2cac578eef9b2e9,Jose E. Marchesi,jose.marchesi@oracle.com,1707424572,Andrii Nakryiko,andrii@kernel.org,1707851850,221cc0a5b0dac1f0336a9da2c59112269c77a0b2,fc1c9e40da37905f87c73711a1ecc57f52c1fe1c,"bpf: Abstract loop unrolling pragmas in BPF selftests

[Changes from V1:
- Avoid conflict by rebasing with latest master.]

Some BPF tests use loop unrolling compiler pragmas that are clang
specific and not supported by GCC.  These pragmas"," along with their
GCC equivalences are:

  #pragma clang loop unroll_count(N)
  #pragma GCC unroll N

  #pragma clang loop unroll(full)
  #pragma GCC unroll 65534

  #pragma clang loop unroll(disable)
  #pragma GCC unroll 1

  #pragma unroll [aka #pragma clang loop unroll(enable)]
  There is no GCC equivalence to this pragma.  It enables unrolling on
  loops that the compiler would not ordinarily unroll even with
  -O2|-funroll-loops","[' but it is not equivalent to full unrolling\n  either.\n\nThis patch adds a new header progs/bpf_compiler.h that defines the\nfollowing macros', ' which correspond to each pair of compiler-specific\npragmas above:\n\n  __pragma_loop_unroll_count(N)\n  __pragma_loop_unroll_full\n  __pragma_loop_no_unroll\n  __pragma_loop_unroll\n\nThe selftests using loop unrolling pragmas are then changed to include\nthe header and use these macros in place of the explicit pragmas.\n\nTested in bpf-next master.\nNo regressions.\n\nSigned-off-by: Jose E. Marchesi <jose.marchesi@oracle.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/bpf/20240208203612.29611-1-jose.marchesi@oracle.com\n', '']",Abstracts loop unrolling pragmas for BPF selftests to support both Clang and GCC compilers.,"loop unrolling, BPF selftests, compilers",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
11f522256e9043b0fcd2f994278645d3e201d20c,11f522256e9043b0fcd2f994278645d3e201d20c,Hari Bathini,hbathini@linux.ibm.com,1707386475,Andrii Nakryiko,andrii@kernel.org,1707851619,f6cdb169c58301dcc9d1419af3a9eb0d0e885776,577e4432f3ac810049cb7e6b71f4d96ec7c6e894,"bpf: Fix warning for bpf_cpumask in verifier

Compiling with CONFIG_BPF_SYSCALL & !CONFIG_BPF_JIT throws the below
warning:

  ""WARN: resolve_btfids: unresolved symbol bpf_cpumask""

Fix it by adding the appropriate #ifdef.

Signed-off-by: Hari Bathini <hbathini@linux.ibm.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Acked-by: Stanislav Fomichev <sdf@google.com>
Acked-by: David Vernet <void@manifault.com>
Link: https://lore.kernel.org/bpf/20240208100115.602172-1-hbathini@linux.ibm.com
",,Fix warning for unresolved symbol bpf_cpumask in the eBPF verifier using an appropriate #ifdef.,"warning,bpf_cpumask,verifier",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fc1c9e40da37905f87c73711a1ecc57f52c1fe1c,fc1c9e40da37905f87c73711a1ecc57f52c1fe1c,Yonghong Song,yonghong.song@linux.dev,1707289267,Andrii Nakryiko,andrii@kernel.org,1707851485,b952abe8f9f1f32783a44801d5e99973ee43b0a6,178c54666f9c4d2f49f2ea661d0c11b52f0ed190,selftests/bpf: Ensure fentry prog cannot attach to bpf_spin_{lock,"unlcok}()

Add two tests to ensure fentry programs cannot attach to
bpf_spin_{lock","['unlock}() helpers. The tracing_failure.c files\ncan be used in the future for other tracing failure cases.\n\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240207070107.335341-1-yonghong.song@linux.dev\n', '']",The commit adds tests to ensure fentry programs cannot attach to bpf_spin_lock functions.,"fentry, bpf_spin_lock, tests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
178c54666f9c4d2f49f2ea661d0c11b52f0ed190,178c54666f9c4d2f49f2ea661d0c11b52f0ed190,Yonghong Song,yonghong.song@linux.dev,1707289262,Andrii Nakryiko,andrii@kernel.org,1707851485,5ea3e36d839819b4ec8deb0a4fec766d12fdf13f,5b268d1ebcdceacf992dfda8f9031d56005a274e,bpf: Mark bpf_spin_{lock,"unlock}() helpers with notrace correctly

Currently tracing is supposed not to allow for bpf_spin_{lock","['unlock}()\nhelper calls. This is to prevent deadlock for the following cases:\n  - there is a prog (prog-A) calling bpf_spin_{lock', 'unlock}().\n  - there is a tracing program (prog-B)', ' e.g.', ' fentry', ' attached\n    to bpf_spin_lock() and/or bpf_spin_unlock().\n  - prog-B calls bpf_spin_{lock', 'unlock}().\nFor such a case', ' when prog-A calls bpf_spin_{lock', 'unlock}()', '\na deadlock will happen.\n\nThe related source codes are below in kernel/bpf/helpers.c:\n  notrace BPF_CALL_1(bpf_spin_lock', ' struct bpf_spin_lock *', ' lock)\n  notrace BPF_CALL_1(bpf_spin_unlock', ' struct bpf_spin_lock *', ' lock)\nnotrace is supposed to prevent fentry prog from attaching to\nbpf_spin_{lock', 'unlock}().\n\nBut actually this is not the case and fentry prog can successfully\nattached to bpf_spin_lock(). Siddharth Chintamaneni reported\nthe issue in [1]. The following is the macro definition for\nabove BPF_CALL_1:\n  #define BPF_CALL_x(x', ' name', ' ...)                                               \\\n        static __always_inline                                                 \\\n        u64 ____##name(__BPF_MAP(x', ' __BPF_DECL_ARGS', ' __BPF_V', ' __VA_ARGS__));   \\\n        typedef u64 (*btf_##name)(__BPF_MAP(x', ' __BPF_DECL_ARGS', ' __BPF_V', ' __VA_ARGS__)); \\\n        u64 name(__BPF_REG(x', ' __BPF_DECL_REGS', ' __BPF_N', ' __VA_ARGS__));         \\\n        u64 name(__BPF_REG(x', ' __BPF_DECL_REGS', ' __BPF_N', ' __VA_ARGS__))          \\\n        {                                                                      \\\n                return ((btf_##name)____##name)(__BPF_MAP(x', '__BPF_CAST', '__BPF_N', '__VA_ARGS__));\\\n        }                                                                      \\\n        static __always_inline                                                 \\\n        u64 ____##name(__BPF_MAP(x', ' __BPF_DECL_ARGS', ' __BPF_V', ' __VA_ARGS__))\n\n  #define BPF_CALL_1(name', ' ...)   BPF_CALL_x(1', ' name', ' __VA_ARGS__)\n\nThe notrace attribute is actually applied to the static always_inline function\n____bpf_spin_{lock', 'unlock}(). The actual callback function\nbpf_spin_{lock', 'unlock}() is not marked with notrace', ' hence\nallowing fentry prog to attach to two helpers', ' and this\nmay cause the above mentioned deadlock. Siddharth Chintamaneni\nactually has a reproducer in [2].\n\nTo fix the issue', ' a new macro NOTRACE_BPF_CALL_1 is introduced which\nwill add notrace attribute to the original function instead of\nthe hidden always_inline function and this fixed the problem.\n\n  [1] https://lore.kernel.org/bpf/CAE5sdEigPnoGrzN8WU7Tx-h-iFuMZgW06qp0KHWtpvoXxf1OAQ@mail.gmail.com/\n  [2] https://lore.kernel.org/bpf/CAE5sdEg6yUc_Jz50AnUXEEUh6O73yQ1Z6NV2srJnef0ZrQkZew@mail.gmail.com/\n\nFixes: d83525ca62cf (""bpf: introduce bpf_spin_lock"")\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/bpf/20240207070102.335167-1-yonghong.song@linux.dev\n', '']","This commit correctly marks bpf_spin_{lock,unlock} helpers with notrace attribute.","bpf_spin_lock,helpers,notrace",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5b268d1ebcdceacf992dfda8f9031d56005a274e,5b268d1ebcdceacf992dfda8f9031d56005a274e,Daniel Xu,dxu@dxuuu.xyz,1707080794,Andrii Nakryiko,andrii@kernel.org,1707851126,aaadf3248447dd3757ec764eaec06de4025b1afc,68bc61c26cacf152baf905786b5949769700f40d,"bpf: Have bpf_rdonly_cast() take a const pointer

Since 20d59ee55172 (""libbpf: add bpf_core_cast() macro"")"," libbpf is now
exporting a const arg version of bpf_rdonly_cast(). This causes the
following conflicting type error when generating kfunc prototypes from
BTF:

In file included from skeleton/pid_iter.bpf.c:5:
/home/dxu/dev/linux/tools/bpf/bpftool/bootstrap/libbpf/include/bpf/bpf_core_read.h:297:14: error: conflicting types for 'bpf_rdonly_cast'
extern void *bpf_rdonly_cast(const void *obj__ign","[' __u32 btf_id__k) __ksym __weak;\n             ^\n./vmlinux.h:135625:14: note: previous declaration is here\nextern void *bpf_rdonly_cast(void *obj__ign', ' u32 btf_id__k) __weak __ksym;\n\nThis is b/c the kernel defines bpf_rdonly_cast() with non-const arg.\nSince const arg is more permissive and thus backwards compatible', ' we\nchange the kernel definition as well to avoid conflicting type errors.\n\nSigned-off-by: Daniel Xu <dxu@dxuuu.xyz>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/bpf/dfd3823f11ffd2d4c838e961d61ec9ae8a646773.1707080349.git.dxu@dxuuu.xyz\n', '']",The commit modifies bpf_rdonly_cast function to accept a constant pointer for compatibility with libbpf changes.,"bpf,rdonly_cast,const",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ed94a8f8ca75ea0f607c919edf2ed5a5e707ef44,ed94a8f8ca75ea0f607c919edf2ed5a5e707ef44,Jiri Slaby (SUSE),jirislaby@kernel.org,1706788396,Jiri Kosina,jkosina@suse.com,1707821035,f02180c3f5fb8557ff350cde1f2ee866115c9502,dcd5231f093b6cd8ea2015e7fe1f372cef5c643d,"HID: protect hid_device::bpf by CONFIG_HID_BPF

And not by CONFIG_BPF. BPF can be selected while HID_BPF does not have
to. It actually cannot be on some platforms due to Kconfig dependences.

This saves quite some bytes on those setups.

Found by https://github.com/jirislaby/clang-struct.

Signed-off-by: Jiri Slaby (SUSE) <jirislaby@kernel.org>
Cc: Jiri Kosina <jikos@kernel.org>
Cc: Benjamin Tissoires <benjamin.tissoires@redhat.com>
Signed-off-by: Jiri Kosina <jkosina@suse.com>
",,The commit modifies HID device configuration dependency to use CONFIG_HID_BPF instead of CONFIG_BPF.,"HID, CONFIG_HID_BPF, configuration",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['HID driver like programs']
923e4616ec15b7feabdc353b229762069eb73c43,923e4616ec15b7feabdc353b229762069eb73c43,Ian Rogers,irogers@google.com,1707535066,Namhyung Kim,namhyung@kernel.org,1707770141,6f9d5e861d27560f0ba58a98cd191924abc6546f,ff0bd79980fffa00c36eb2b9044dbe9cfdf4bb79,"perf maps: Locking tidy up of nr_maps

After this change maps__nr_maps is only used by tests"," existing users
are migrated to maps__empty. Compute maps__empty under the read lock.

Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: K Prateek Nayak <kprateek.nayak@amd.com>
Cc: James Clark <james.clark@arm.com>
Cc: Vincent Whitchurch <vincent.whitchurch@axis.com>
Cc: Alexey Dobriyan <adobriyan@gmail.com>
Cc: Colin Ian King <colin.i.king@gmail.com>
Cc: Changbin Du <changbin.du@huawei.com>
Cc: Masami Hiramatsu <mhiramat@kernel.org>
Cc: Song Liu <song@kernel.org>
Cc: Leo Yan <leo.yan@linux.dev>
Cc: Athira Rajeev <atrajeev@linux.vnet.ibm.com>
Cc: Liam Howlett <liam.howlett@oracle.com>
Cc: Artem Savkov <asavkov@redhat.com>
Cc: bpf@vger.kernel.org
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
Link: https://lore.kernel.org/r/20240210031746.4057262-7-irogers@google.com
",[''],"The commit tidies up locking of nr_maps, migrating users to maps__empty under a read lock, used only by tests.","locking, maps, read-lock",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"[""It's not related to any of the above.""]"
ff0bd79980fffa00c36eb2b9044dbe9cfdf4bb79,ff0bd79980fffa00c36eb2b9044dbe9cfdf4bb79,Ian Rogers,irogers@google.com,1707535065,Namhyung Kim,namhyung@kernel.org,1707770141,530469d90e3fce274309acbff0df69ea8f7d9704,39a27325e6099e9f9a10d8b5f3b2470a3c10efa5,"perf maps: Hide maps internals

Move the struct into the C file. Add maps__equal to work around
exposing the struct for reference count checking. Add accessors for
the unwind_libunwind_ops. Move maps_list_node to its only use in
symbol.c.

Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: K Prateek Nayak <kprateek.nayak@amd.com>
Cc: James Clark <james.clark@arm.com>
Cc: Vincent Whitchurch <vincent.whitchurch@axis.com>
Cc: Alexey Dobriyan <adobriyan@gmail.com>
Cc: Colin Ian King <colin.i.king@gmail.com>
Cc: Changbin Du <changbin.du@huawei.com>
Cc: Masami Hiramatsu <mhiramat@kernel.org>
Cc: Song Liu <song@kernel.org>
Cc: Leo Yan <leo.yan@linux.dev>
Cc: Athira Rajeev <atrajeev@linux.vnet.ibm.com>
Cc: Liam Howlett <liam.howlett@oracle.com>
Cc: Artem Savkov <asavkov@redhat.com>
Cc: bpf@vger.kernel.org
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
Link: https://lore.kernel.org/r/20240210031746.4057262-6-irogers@google.com
",,"Refactor the perf map internals by moving structs, adding workarounds and accessors, and relocating specific elements to improve encapsulation.","perf maps, structures, encapsulation",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['other']
39a27325e6099e9f9a10d8b5f3b2470a3c10efa5,39a27325e6099e9f9a10d8b5f3b2470a3c10efa5,Ian Rogers,irogers@google.com,1707535064,Namhyung Kim,namhyung@kernel.org,1707770141,408c5e465935ca0fa8da2244f6e65ba1c3b42e4b,107ef66cb054f8d54e336236a31631a8cc167c1f,"perf maps: Get map before returning in maps__find_next_entry

Finding a map is done under a lock"," returning the map without a
reference count means it can be removed without notice and causing
uses after free. Grab a reference count to the map within the lock
region and return this. Fix up locations that need a map__put
following this.

Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: K Prateek Nayak <kprateek.nayak@amd.com>
Cc: James Clark <james.clark@arm.com>
Cc: Vincent Whitchurch <vincent.whitchurch@axis.com>
Cc: Alexey Dobriyan <adobriyan@gmail.com>
Cc: Colin Ian King <colin.i.king@gmail.com>
Cc: Changbin Du <changbin.du@huawei.com>
Cc: Masami Hiramatsu <mhiramat@kernel.org>
Cc: Song Liu <song@kernel.org>
Cc: Leo Yan <leo.yan@linux.dev>
Cc: Athira Rajeev <atrajeev@linux.vnet.ibm.com>
Cc: Liam Howlett <liam.howlett@oracle.com>
Cc: Artem Savkov <asavkov@redhat.com>
Cc: bpf@vger.kernel.org
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
Link: https://lore.kernel.org/r/20240210031746.4057262-5-irogers@google.com
",[''],Acquire map reference count within lock to prevent use-after-free in maps__find_next_entry.,map lock reference,It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
107ef66cb054f8d54e336236a31631a8cc167c1f,107ef66cb054f8d54e336236a31631a8cc167c1f,Ian Rogers,irogers@google.com,1707535063,Namhyung Kim,namhyung@kernel.org,1707770133,d3b67ab8a3a16e344c3b05d1023bd80a2fa144d0,42fd623b58dbcc48310705bbf3e3d4d7c1deec29,"perf maps: Get map before returning in maps__find_by_name

Finding a map is done under a lock"," returning the map without a
reference count means it can be removed without notice and causing
uses after free. Grab a reference count to the map within the lock
region and return this. Fix up locations that need a map__put
following this. Also fix some reference counted pointer comparisons.

Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: K Prateek Nayak <kprateek.nayak@amd.com>
Cc: James Clark <james.clark@arm.com>
Cc: Vincent Whitchurch <vincent.whitchurch@axis.com>
Cc: Alexey Dobriyan <adobriyan@gmail.com>
Cc: Colin Ian King <colin.i.king@gmail.com>
Cc: Changbin Du <changbin.du@huawei.com>
Cc: Masami Hiramatsu <mhiramat@kernel.org>
Cc: Song Liu <song@kernel.org>
Cc: Leo Yan <leo.yan@linux.dev>
Cc: Athira Rajeev <atrajeev@linux.vnet.ibm.com>
Cc: Liam Howlett <liam.howlett@oracle.com>
Cc: Artem Savkov <asavkov@redhat.com>
Cc: bpf@vger.kernel.org
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
Link: https://lore.kernel.org/r/20240210031746.4057262-4-irogers@google.com
",[''],Fix potential use after free in perf maps by ensuring reference count manipulation within lock.,"perf maps,reference count,lock",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
42fd623b58dbcc48310705bbf3e3d4d7c1deec29,42fd623b58dbcc48310705bbf3e3d4d7c1deec29,Ian Rogers,irogers@google.com,1707535062,Namhyung Kim,namhyung@kernel.org,1707770126,c83e8fd2ea1911d949137e0d51979a3d4675195d,659ad3492b913c9033d47cb406ac5754780875b6,"perf maps: Get map before returning in maps__find

Finding a map is done under a lock"," returning the map without a
reference count means it can be removed without notice and causing
uses after free. Grab a reference count to the map within the lock
region and return this. Fix up locations that need a map__put
following this.

Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: K Prateek Nayak <kprateek.nayak@amd.com>
Cc: James Clark <james.clark@arm.com>
Cc: Vincent Whitchurch <vincent.whitchurch@axis.com>
Cc: Alexey Dobriyan <adobriyan@gmail.com>
Cc: Colin Ian King <colin.i.king@gmail.com>
Cc: Changbin Du <changbin.du@huawei.com>
Cc: Masami Hiramatsu <mhiramat@kernel.org>
Cc: Song Liu <song@kernel.org>
Cc: Leo Yan <leo.yan@linux.dev>
Cc: Athira Rajeev <atrajeev@linux.vnet.ibm.com>
Cc: Liam Howlett <liam.howlett@oracle.com>
Cc: Artem Savkov <asavkov@redhat.com>
Cc: bpf@vger.kernel.org
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
Link: https://lore.kernel.org/r/20240210031746.4057262-3-irogers@google.com
",[''],This commit fixes use-after-free by managing reference counts for maps in perf maps.,"perf maps, reference count, use-after-free",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,['other']
659ad3492b913c9033d47cb406ac5754780875b6,659ad3492b913c9033d47cb406ac5754780875b6,Ian Rogers,irogers@google.com,1707535061,Namhyung Kim,namhyung@kernel.org,1707770114,0f0076d25aace83d0503a56b2d6ba59a279665c2,39d14c0dd650f3de62242c2f92fb4d7a0ec3386a,"perf maps: Switch from rbtree to lazily sorted array for addresses

Maps is a collection of maps primarily sorted by the starting address
of the map. Prior to this change the maps were held in an rbtree
requiring 4 pointers per node. Prior to reference count checking"," the
rbnode was embedded in the map so 3 pointers per node were
necessary. This change switches the rbtree to an array lazily sorted
by address","[' much as the array sorting nodes by name. 1 pointer is\nneeded per node', ' but to avoid excessive resizing the backing array may\nbe twice the number of used elements. Meaning the memory overhead is\nroughly half that of the rbtree. For a perf record with\n""--no-bpf-event -g -a"" of true', ' the memory overhead of perf inject is\nreduce fom 3.3MB to 3MB', ' so 10% or 300KB is saved.\n\nMap inserts always happen at the end of the array. The code tracks\nwhether the insertion violates the sorting property. O(log n) rb-tree\ncomplexity is switched to O(1).\n\nRemove slides the array', ' so O(log n) rb-tree complexity is degraded to\nO(n).\n\nA find may need to sort the array using qsort which is O(n*log n)', ' but\nin general the maps should be sorted and so average performance should\nbe O(log n) as with the rbtree.\n\nAn rbtree node consumes a cache line', ' but with the array 4 nodes fit\non a cache line. Iteration is simplified to scanning an array rather\nthan pointer chasing.\n\nOverall it is expected the performance after the change should be\ncomparable to before', ' but with half of the memory consumed.\n\nTo avoid a list and repeated logic around splitting maps', '\nmaps__merge_in is rewritten in terms of\nmaps__fixup_overlap_and_insert. maps_merge_in splits the given mapping\ninserting remaining gaps. maps__fixup_overlap_and_insert splits the\nexisting mappings', ' then adds the incoming mapping. By adding the new\nmapping first', ' then re-inserting the existing mappings the splitting\nbehavior matches.\n\nSigned-off-by: Ian Rogers <irogers@google.com>\nAcked-by: Namhyung Kim <namhyung@kernel.org>\nCc: K Prateek Nayak <kprateek.nayak@amd.com>\nCc: James Clark <james.clark@arm.com>\nCc: Vincent Whitchurch <vincent.whitchurch@axis.com>\nCc: Alexey Dobriyan <adobriyan@gmail.com>\nCc: Colin Ian King <colin.i.king@gmail.com>\nCc: Changbin Du <changbin.du@huawei.com>\nCc: Masami Hiramatsu <mhiramat@kernel.org>\nCc: Song Liu <song@kernel.org>\nCc: Leo Yan <leo.yan@linux.dev>\nCc: Athira Rajeev <atrajeev@linux.vnet.ibm.com>\nCc: Liam Howlett <liam.howlett@oracle.com>\nCc: Artem Savkov <asavkov@redhat.com>\nCc: bpf@vger.kernel.org\nSigned-off-by: Namhyung Kim <namhyung@kernel.org>\nLink: https://lore.kernel.org/r/20240210031746.4057262-2-irogers@google.com\n', '']",The commit switches perf maps from using an rbtree to a lazily sorted array for better memory efficiency.,"perf maps,rbtree,lazily sorted array",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
68bc61c26cacf152baf905786b5949769700f40d,68bc61c26cacf152baf905786b5949769700f40d,Marco Elver,elver@google.com,1707308777,Martin KaFai Lau,martin.lau@kernel.org,1707689184,f49b1e314e72c5ce745c3ecd05cdfb4e624792bf,a7170d81e0002345576b5f87a5890d91bc06c106,"bpf: Allow compiler to inline most of bpf_local_storage_lookup()

In various performance profiles of kernels with BPF programs attached","
bpf_local_storage_lookup() appears as a significant portion of CPU
cycles spent. To enable the compiler generate more optimal code","[' turn\nbpf_local_storage_lookup() into a static inline function', ' where only the\ncache insertion code path is outlined\n\nNotably', ' outlining cache insertion helps avoid bloating callers by\nduplicating setting up calls to raw_spin_{lock', 'unlock}_irqsave() (on\narchitectures which do not inline spin_lock/unlock', ' such as x86)', ' which\nwould cause the compiler produce worse code by deciding to outline\notherwise inlinable functions. The call overhead is neutral', ' because we\nmake 2 calls either way: either calling raw_spin_lock_irqsave() and\nraw_spin_unlock_irqsave(); or call __bpf_local_storage_insert_cache()', '\nwhich calls raw_spin_lock_irqsave()', "" followed by a tail-call to\nraw_spin_unlock_irqsave() where the compiler can perform TCO and (in\noptimized uninstrumented builds) turns it into a plain jump. The call to\n__bpf_local_storage_insert_cache() can be elided entirely if\ncacheit_lockit is a false constant expression.\n\nBased on results from './benchs/run_bench_local_storage.sh' (21 trials"", '\nreboot between each trial; x86 defconfig + BPF', ' clang 16) this produces\nimprovements in throughput and latency in the majority of cases', ' with an\naverage (geomean) improvement of 8%:\n\n+---- Hashmap Control --------------------\n|\n| + num keys: 10\n| :                                         <before>             | <after>\n| +-+ hashmap (control) sequential get    +----------------------+----------------------\n|   +- hits throughput                    | 14.789 M ops/s       | 14.745 M ops/s (  ~  )\n|   +- hits latency                       | 67.679 ns/op         | 67.879 ns/op   (  ~  )\n|   +- important_hits throughput          | 14.789 M ops/s       | 14.745 M ops/s (  ~  )\n|\n| + num keys: 1000\n| :                                         <before>             | <after>\n| +-+ hashmap (control) sequential get    +----------------------+----------------------\n|   +- hits throughput                    | 12.233 M ops/s       | 12.170 M ops/s (  ~  )\n|   +- hits latency                       | 81.754 ns/op         | 82.185 ns/op   (  ~  )\n|   +- important_hits throughput          | 12.233 M ops/s       | 12.170 M ops/s (  ~  )\n|\n| + num keys: 10000\n| :                                         <before>             | <after>\n| +-+ hashmap (control) sequential get    +----------------------+----------------------\n|   +- hits throughput                    | 7.220 M ops/s        | 7.204 M ops/s  (  ~  )\n|   +- hits latency                       | 138.522 ns/op        | 138.842 ns/op  (  ~  )\n|   +- important_hits throughput          | 7.220 M ops/s        | 7.204 M ops/s  (  ~  )\n|\n| + num keys: 100000\n| :                                         <before>             | <after>\n| +-+ hashmap (control) sequential get    +----------------------+----------------------\n|   +- hits throughput                    | 5.061 M ops/s        | 5.165 M ops/s  (+2.1%)\n|   +- hits latency                       | 198.483 ns/op        | 194.270 ns/op  (-2.1%)\n|   +- important_hits throughput          | 5.061 M ops/s        | 5.165 M ops/s  (+2.1%)\n|\n| + num keys: 4194304\n| :                                         <before>             | <after>\n| +-+ hashmap (control) sequential get    +----------------------+----------------------\n|   +- hits throughput                    | 2.864 M ops/s        | 2.882 M ops/s  (  ~  )\n|   +- hits latency                       | 365.220 ns/op        | 361.418 ns/op  (-1.0%)\n|   +- important_hits throughput          | 2.864 M ops/s        | 2.882 M ops/s  (  ~  )\n|\n+---- Local Storage ----------------------\n|\n| + num_maps: 1\n| :                                         <before>             | <after>\n| +-+ local_storage cache sequential get  +----------------------+----------------------\n|   +- hits throughput                    | 33.005 M ops/s       | 39.068 M ops/s (+18.4%)\n|   +- hits latency                       | 30.300 ns/op         | 25.598 ns/op   (-15.5%)\n|   +- important_hits throughput          | 33.005 M ops/s       | 39.068 M ops/s (+18.4%)\n| :\n| :                                         <before>             | <after>\n| +-+ local_storage cache interleaved get +----------------------+----------------------\n|   +- hits throughput                    | 37.151 M ops/s       | 44.926 M ops/s (+20.9%)\n|   +- hits latency                       | 26.919 ns/op         | 22.259 ns/op   (-17.3%)\n|   +- important_hits throughput          | 37.151 M ops/s       | 44.926 M ops/s (+20.9%)\n|\n| + num_maps: 10\n| :                                         <before>             | <after>\n| +-+ local_storage cache sequential get  +----------------------+----------------------\n|   +- hits throughput                    | 32.288 M ops/s       | 38.099 M ops/s (+18.0%)\n|   +- hits latency                       | 30.972 ns/op         | 26.248 ns/op   (-15.3%)\n|   +- important_hits throughput          | 3.229 M ops/s        | 3.810 M ops/s  (+18.0%)\n| :\n| :                                         <before>             | <after>\n| +-+ local_storage cache interleaved get +----------------------+----------------------\n|   +- hits throughput                    | 34.473 M ops/s       | 41.145 M ops/s (+19.4%)\n|   +- hits latency                       | 29.010 ns/op         | 24.307 ns/op   (-16.2%)\n|   +- important_hits throughput          | 12.312 M ops/s       | 14.695 M ops/s (+19.4%)\n|\n| + num_maps: 16\n| :                                         <before>             | <after>\n| +-+ local_storage cache sequential get  +----------------------+----------------------\n|   +- hits throughput                    | 32.524 M ops/s       | 38.341 M ops/s (+17.9%)\n|   +- hits latency                       | 30.748 ns/op         | 26.083 ns/op   (-15.2%)\n|   +- important_hits throughput          | 2.033 M ops/s        | 2.396 M ops/s  (+17.9%)\n| :\n| :                                         <before>             | <after>\n| +-+ local_storage cache interleaved get +----------------------+----------------------\n|   +- hits throughput                    | 34.575 M ops/s       | 41.338 M ops/s (+19.6%)\n|   +- hits latency                       | 28.925 ns/op         | 24.193 ns/op   (-16.4%)\n|   +- important_hits throughput          | 11.001 M ops/s       | 13.153 M ops/s (+19.6%)\n|\n| + num_maps: 17\n| :                                         <before>             | <after>\n| +-+ local_storage cache sequential get  +----------------------+----------------------\n|   +- hits throughput                    | 28.861 M ops/s       | 32.756 M ops/s (+13.5%)\n|   +- hits latency                       | 34.649 ns/op         | 30.530 ns/op   (-11.9%)\n|   +- important_hits throughput          | 1.700 M ops/s        | 1.929 M ops/s  (+13.5%)\n| :\n| :                                         <before>             | <after>\n| +-+ local_storage cache interleaved get +----------------------+----------------------\n|   +- hits throughput                    | 31.529 M ops/s       | 36.110 M ops/s (+14.5%)\n|   +- hits latency                       | 31.719 ns/op         | 27.697 ns/op   (-12.7%)\n|   +- important_hits throughput          | 9.598 M ops/s        | 10.993 M ops/s (+14.5%)\n|\n| + num_maps: 24\n| :                                         <before>             | <after>\n| +-+ local_storage cache sequential get  +----------------------+----------------------\n|   +- hits throughput                    | 18.602 M ops/s       | 19.937 M ops/s (+7.2%)\n|   +- hits latency                       | 53.767 ns/op         | 50.166 ns/op   (-6.7%)\n|   +- important_hits throughput          | 0.776 M ops/s        | 0.831 M ops/s  (+7.2%)\n| :\n| :                                         <before>             | <after>\n| +-+ local_storage cache interleaved get +----------------------+----------------------\n|   +- hits throughput                    | 21.718 M ops/s       | 23.332 M ops/s (+7.4%)\n|   +- hits latency                       | 46.047 ns/op         | 42.865 ns/op   (-6.9%)\n|   +- important_hits throughput          | 6.110 M ops/s        | 6.564 M ops/s  (+7.4%)\n|\n| + num_maps: 32\n| :                                         <before>             | <after>\n| +-+ local_storage cache sequential get  +----------------------+----------------------\n|   +- hits throughput                    | 14.118 M ops/s       | 14.626 M ops/s (+3.6%)\n|   +- hits latency                       | 70.856 ns/op         | 68.381 ns/op   (-3.5%)\n|   +- important_hits throughput          | 0.442 M ops/s        | 0.458 M ops/s  (+3.6%)\n| :\n| :                                         <before>             | <after>\n| +-+ local_storage cache interleaved get +----------------------+----------------------\n|   +- hits throughput                    | 17.111 M ops/s       | 17.906 M ops/s (+4.6%)\n|   +- hits latency                       | 58.451 ns/op         | 55.865 ns/op   (-4.4%)\n|   +- important_hits throughput          | 4.776 M ops/s        | 4.998 M ops/s  (+4.6%)\n|\n| + num_maps: 100\n| :                                         <before>             | <after>\n| +-+ local_storage cache sequential get  +----------------------+----------------------\n|   +- hits throughput                    | 5.281 M ops/s        | 5.528 M ops/s  (+4.7%)\n|   +- hits latency                       | 192.398 ns/op        | 183.059 ns/op  (-4.9%)\n|   +- important_hits throughput          | 0.053 M ops/s        | 0.055 M ops/s  (+4.9%)\n| :\n| :                                         <before>             | <after>\n| +-+ local_storage cache interleaved get +----------------------+----------------------\n|   +- hits throughput                    | 6.265 M ops/s        | 6.498 M ops/s  (+3.7%)\n|   +- hits latency                       | 161.436 ns/op        | 152.877 ns/op  (-5.3%)\n|   +- important_hits throughput          | 1.636 M ops/s        | 1.697 M ops/s  (+3.7%)\n|\n| + num_maps: 1000\n| :                                         <before>             | <after>\n| +-+ local_storage cache sequential get  +----------------------+----------------------\n|   +- hits throughput                    | 0.355 M ops/s        | 0.354 M ops/s  (  ~  )\n|   +- hits latency                       | 2826.538 ns/op       | 2827.139 ns/op (  ~  )\n|   +- important_hits throughput          | 0.000 M ops/s        | 0.000 M ops/s  (  ~  )\n| :\n| :                                         <before>             | <after>\n| +-+ local_storage cache interleaved get +----------------------+----------------------\n|   +- hits throughput                    | 0.404 M ops/s        | 0.403 M ops/s  (  ~  )\n|   +- hits latency                       | 2481.190 ns/op       | 2487.555 ns/op (  ~  )\n|   +- important_hits throughput          | 0.102 M ops/s        | 0.101 M ops/s  (  ~  )\n\nThe on_lookup test in {cgrp', 'task}_ls_recursion.c is removed\nbecause the bpf_local_storage_lookup is no longer traceable\nand adding tracepoint will make the compiler generate worse\ncode: https://lore.kernel.org/bpf/ZcJmok64Xqv6l4ZS@elver.google.com/\n\nSigned-off-by: Marco Elver <elver@google.com>\nCc: Martin KaFai Lau <martin.lau@linux.dev>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240207122626.3508658-1-elver@google.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Enable compiler to inline bpf_local_storage_lookup() for improved performance in BPF programs.,"compiler,inlining,performance",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d27553c14f06f4db61cb9ddaf88e8d4df91d740c,d27553c14f06f4db61cb9ddaf88e8d4df91d740c,Jinjian Song,jinjian.song@fibocom.com,1707128549,David S. Miller,davem@davemloft.net,1707480468,e583d2ef036c42727f1227315eca3aa5a38dfecb,409c38d4f156740bf3165fd6ceae4fa6425eebf4,"net: wwan: t7xx: Infrastructure for early port configuration

To support cases such as FW update or Core dump"," the t7xx
device is capable of signaling the host that a special port
needs to be created before the handshake phase.

Adds the infrastructure required to create the early ports
which also requires a different configuration of CLDMA queues.

Base on the v5 patch version of follow series:
'net: wwan: t7xx: fw flashing & coredump support'
(https://patchwork.kernel.org/project/netdevbpf/patch/3777bb382f4b0395cb594a602c5c79dbab86c9e0.1674307425.git.m.chetan.kumar@linux.intel.com/)

Signed-off-by: Jinjian Song <jinjian.song@fibocom.com>
Signed-off-by: David S. Miller <davem@davemloft.net>
",[''],"This commit adds early port infrastructure for t7xx device in network subsystem, supporting firmware updates and core dumps.","early port infrastructure, firmware update, core dump",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
a7170d81e0002345576b5f87a5890d91bc06c106,a7170d81e0002345576b5f87a5890d91bc06c106,Martin KaFai Lau,martin.lau@kernel.org,1707419109,Martin KaFai Lau,martin.lau@kernel.org,1707421218,d86d4ccbb81089e586156921f3bc70d759d02936,e55dad12abe42383b68ba88212eb3d0fba0e9820 947e56f82fd783a1ec1c9359b20b5699d09cae14,Merge branch 'bpf," btf: Add DEBUG_INFO_BTF checks for __register_bpf_struct_ops'

Geliang Tang says:

====================
bpf: Add DEBUG_INFO_BTF checks for __register_bpf_struct_ops

This patch set avoids module loading failure when the module
trying to register a struct_ops and the module has its btf section
stripped. This will then work similarly as module kfunc registration in
commit 3de4d22cc9ac (""bpf","[' btf: Warn but return no error for NULL btf from __register_btf_kfunc_id_set()"")\n\nv5:\n - drop CONFIG_MODULE_ALLOW_BTF_MISMATCH check as Martin suggested.\n\nv4:\n - add a new patch to fix error checks for btf_get_module_btf.\n - rename the helper to check_btf_kconfigs.\n\nv3:\n - fix this build error:\nkernel/bpf/btf.c:7750:11: error: incomplete definition of type \'struct module\'\n\nReported-by: kernel test robot <lkp@intel.com>\nCloses: https://lore.kernel.org/oe-kbuild-all/202402040934.Fph0XeEo-lkp@intel.com/\n\nv2:\n - add register_check_missing_btf helper as Jiri suggested.\n====================\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Fix module loading issues by adding DEBUG_INFO_BTF checks for struct_ops registration in eBPF.,"DEBUG_INFO_BTF, struct_ops, module",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
947e56f82fd783a1ec1c9359b20b5699d09cae14,947e56f82fd783a1ec1c9359b20b5699d09cae14,Geliang Tang,tanggeliang@kylinos.cn,1707373463,Martin KaFai Lau,martin.lau@kernel.org,1707421069,d86d4ccbb81089e586156921f3bc70d759d02936,9e60b0e02550aaf5f2301e49353641a5e3701674,bpf," btf: Check btf for register_bpf_struct_ops

Similar to the handling in the functions __register_btf_kfunc_id_set()
and register_btf_id_dtor_kfuncs()","[' this patch uses the newly added\nhelper check_btf_kconfigs() to handle module with its btf section\nstripped.\n\nWhile at it', ' the patch also adds the missed IS_ERR() check to fix the\ncommit f6be98d19985 (""bpf', ' net: switch to dynamic registration"")\n\nFixes: f6be98d19985 (""bpf', ' net: switch to dynamic registration"")\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nLink: https://lore.kernel.org/r/69082b9835463fe36f9e354bddf2d0a97df39c2b.1707373307.git.tanggeliang@kylinos.cn\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Add btf check for register_bpf_struct_ops aligning with similar btf use in registration functions.,"btf, register, struct_ops",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9e60b0e02550aaf5f2301e49353641a5e3701674,9e60b0e02550aaf5f2301e49353641a5e3701674,Geliang Tang,tanggeliang@kylinos.cn,1707373462,Martin KaFai Lau,martin.lau@kernel.org,1707420176,eb3073aaab7aa1ca63533f8e396fb487df354172,b9a395f0f7af66fe8224450481b99d4f83b57207,bpf," btf: Add check_btf_kconfigs helper

This patch extracts duplicate code on error path when btf_get_module_btf()
returns NULL from the functions __register_btf_kfunc_id_set() and
register_btf_id_dtor_kfuncs() into a new helper named check_btf_kconfigs()
to check CONFIG_DEBUG_INFO_BTF and CONFIG_DEBUG_INFO_BTF_MODULES in it.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Link: https://lore.kernel.org/r/fa5537fc55f1e4d0bfd686598c81b7ab9dbd82b7.1707373307.git.tanggeliang@kylinos.cn
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Refactor error handling with check_btf_kconfigs helper for BTF module support.,"duplicated, error, helper",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b9a395f0f7af66fe8224450481b99d4f83b57207,b9a395f0f7af66fe8224450481b99d4f83b57207,Geliang Tang,tanggeliang@kylinos.cn,1707373461,Martin KaFai Lau,martin.lau@kernel.org,1707419107,1d92c1af25cd8725f9d870209de02717462b69bb,e55dad12abe42383b68ba88212eb3d0fba0e9820,bpf," btf: Fix return value of register_btf_id_dtor_kfuncs

The same as __register_btf_kfunc_id_set()","[' to let the modules with\nstripped btf section loaded', ' this patch changes the return value of\nregister_btf_id_dtor_kfuncs() too from -ENOENT to 0 when btf is NULL.\n\nSigned-off-by: Geliang Tang <tanggeliang@kylinos.cn>\nLink: https://lore.kernel.org/r/eab65586d7fb0e72f2707d3747c7d4a5d60c823f.1707373307.git.tanggeliang@kylinos.cn\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Fixes the return value handling for BTF ID destructor kfuncs registration in BPF.,"BTF, return value, kfuncs",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
03fa49a386b298d357b90c9c5599f8d00dfc425c,03fa49a386b298d357b90c9c5599f8d00dfc425c,Paolo Abeni,pabeni@redhat.com,1707388402,Paolo Abeni,pabeni@redhat.com,1707388402,71db0a1c6f0d74e21e6ccb5b7a35a000e2f7ea5e,335bac1daae3fd9070d0f9f34d7d7ba708729256 bc4ce46b1e3d1da4309405cd4afc7c0fcddd0b90,"Merge branch 'cpsw-enable-mac_managed_pm-to-fix-mdio'

Sinthu Raja says:

====================
CPSW: enable mac_managed_pm to fix mdio

This patch fix the resume/suspend issue on CPSW interface.

Reference from the foloowing patchwork:
https://lore.kernel.org/netdev/20221014144729.1159257-2-shenwei.wang@nxp.com/T/

V1: https://patchwork.kernel.org/project/netdevbpf/patch/20240122083414.6246-1-sinthu.raja@ti.com/
V2: https://patchwork.kernel.org/project/netdevbpf/patch/20240122093326.7618-1-sinthu.raja@ti.com/
====================

Link: https://lore.kernel.org/r/20240206005928.15703-1-sinthu.raja@ti.com
Signed-off-by: Paolo Abeni <pabeni@redhat.com>
",,Fix resume/suspend issue on CPSW interface by enabling mac_managed_pm.,"CPSW,mac_managed_pm,MDIO",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
79d72c68c58784a3e1cd2378669d51bfd0cb7498,79d72c68c58784a3e1cd2378669d51bfd0cb7498,Oscar Salvador,osalvador@suse.de,1706648658,Andrew Morton,akpm@linux-foundation.org,1707369636,5b501e855a003844b161205e566581253afb08e3,f2076032096775d1bb1af16b6eddbc6534575328,fs,"hugetlb: fix NULL pointer dereference in hugetlbs_fill_super

When configuring a hugetlb filesystem via the fsconfig() syscall","[' there is\na possible NULL dereference in hugetlbfs_fill_super() caused by assigning\nNULL to ctx->hstate in hugetlbfs_parse_param() when the requested pagesize\nis non valid.\n\nE.g: Taking the following steps:\n\n     fd = fsopen(""hugetlbfs""', ' FSOPEN_CLOEXEC);\n     fsconfig(fd', ' FSCONFIG_SET_STRING', ' ""pagesize""', ' ""1024""', ' 0);\n     fsconfig(fd', ' FSCONFIG_CMD_CREATE', ' NULL', ' NULL', ' 0);\n\nGiven that the requested ""pagesize"" is invalid', ' ctxt->hstate will be replaced\nwith NULL', ' losing its previous value', ' and we will print an error:\n\n ...\n ...\n case Opt_pagesize:\n ps = memparse(param->string', ' &rest);\n ctx->hstate = h;\n if (!ctx->hstate) {\n         pr_err(""Unsupported page size %lu MB\\n""', ' ps / SZ_1M);\n         return -EINVAL;\n }\n return 0;\n ...\n ...\n\nThis is a problem because later on', ' we will dereference ctxt->hstate in\nhugetlbfs_fill_super()\n\n ...\n ...\n sb->s_blocksize = huge_page_size(ctx->hstate);\n ...\n ...\n\nCausing below Oops.\n\nFix this by replacing cxt->hstate value only when then pagesize is known\nto be valid.\n\n kernel: hugetlbfs: Unsupported page size 0 MB\n kernel: BUG: kernel NULL pointer dereference', ' address: 0000000000000028\n kernel: #PF: supervisor read access in kernel mode\n kernel: #PF: error_code(0x0000) - not-present page\n kernel: PGD 800000010f66c067 P4D 800000010f66c067 PUD 1b22f8067 PMD 0\n kernel: Oops: 0000 [#1] PREEMPT SMP PTI\n kernel: CPU: 4 PID: 5659 Comm: syscall Tainted: G            E      6.8.0-rc2-default+ #22 5a47c3fef76212addcc6eb71344aabc35190ae8f\n kernel: Hardware name: Intel Corp. GROVEPORT/GROVEPORT', ' BIOS GVPRCRB1.86B.0016.D04.1705030402 05/03/2017\n kernel: RIP: 0010:hugetlbfs_fill_super+0xb4/0x1a0\n kernel: Code: 48 8b 3b e8 3e c6 ed ff 48 85 c0 48 89 45 20 0f 84 d6 00 00 00 48 b8 ff ff ff ff ff ff ff 7f 4c 89 e7 49 89 44 24 20 48 8b 03 <8b> 48 28 b8 00 10 00 00 48 d3 e0 49 89 44 24 18 48 8b 03 8b 40 28\n kernel: RSP: 0018:ffffbe9960fcbd48 EFLAGS: 00010246\n kernel: RAX: 0000000000000000 RBX: ffff9af5272ae780 RCX: 0000000000372004\n kernel: RDX: ffffffffffffffff RSI: ffffffffffffffff RDI: ffff9af555e9b000\n kernel: RBP: ffff9af52ee66b00 R08: 0000000000000040 R09: 0000000000370004\n kernel: R10: ffffbe9960fcbd48 R11: 0000000000000040 R12: ffff9af555e9b000\n kernel: R13: ffffffffa66b86c0 R14: ffff9af507d2f400 R15: ffff9af507d2f400\n kernel: FS:  00007ffbc0ba4740(0000) GS:ffff9b0bd7000000(0000) knlGS:0000000000000000\n kernel: CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n kernel: CR2: 0000000000000028 CR3: 00000001b1ee0000 CR4: 00000000001506f0\n kernel: Call Trace:\n kernel:  <TASK>\n kernel:  ? __die_body+0x1a/0x60\n kernel:  ? page_fault_oops+0x16f/0x4a0\n kernel:  ? search_bpf_extables+0x65/0x70\n kernel:  ? fixup_exception+0x22/0x310\n kernel:  ? exc_page_fault+0x69/0x150\n kernel:  ? asm_exc_page_fault+0x22/0x30\n kernel:  ? __pfx_hugetlbfs_fill_super+0x10/0x10\n kernel:  ? hugetlbfs_fill_super+0xb4/0x1a0\n kernel:  ? hugetlbfs_fill_super+0x28/0x1a0\n kernel:  ? __pfx_hugetlbfs_fill_super+0x10/0x10\n kernel:  vfs_get_super+0x40/0xa0\n kernel:  ? __pfx_bpf_lsm_capable+0x10/0x10\n kernel:  vfs_get_tree+0x25/0xd0\n kernel:  vfs_cmd_create+0x64/0xe0\n kernel:  __x64_sys_fsconfig+0x395/0x410\n kernel:  do_syscall_64+0x80/0x160\n kernel:  ? syscall_exit_to_user_mode+0x82/0x240\n kernel:  ? do_syscall_64+0x8d/0x160\n kernel:  ? syscall_exit_to_user_mode+0x82/0x240\n kernel:  ? do_syscall_64+0x8d/0x160\n kernel:  ? exc_page_fault+0x69/0x150\n kernel:  entry_SYSCALL_64_after_hwframe+0x6e/0x76\n kernel: RIP: 0033:0x7ffbc0cb87c9\n kernel: Code: 00 90 90 90 90 90 90 90 90 90 90 90 90 90 90 66 90 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 73 01 c3 48 8b 0d 97 96 0d 00 f7 d8 64 89 01 48\n kernel: RSP: 002b:00007ffc29d2f388 EFLAGS: 00000206 ORIG_RAX: 00000000000001af\n kernel: RAX: ffffffffffffffda RBX: 0000000000000000 RCX: 00007ffbc0cb87c9\n kernel: RDX: 0000000000000000 RSI: 0000000000000006 RDI: 0000000000000003\n kernel: RBP: 00007ffc29d2f3b0 R08: 0000000000000000 R09: 0000000000000000\n kernel: R10: 0000000000000000 R11: 0000000000000206 R12: 0000000000000000\n kernel: R13: 00007ffc29d2f4c0 R14: 0000000000000000 R15: 0000000000000000\n kernel:  </TASK>\n kernel: Modules linked in: rpcsec_gss_krb5(E) auth_rpcgss(E) nfsv4(E) dns_resolver(E) nfs(E) lockd(E) grace(E) sunrpc(E) netfs(E) af_packet(E) bridge(E) stp(E) llc(E) iscsi_ibft(E) iscsi_boot_sysfs(E) intel_rapl_msr(E) intel_rapl_common(E) iTCO_wdt(E) intel_pmc_bxt(E) sb_edac(E) iTCO_vendor_support(E) x86_pkg_temp_thermal(E) intel_powerclamp(E) coretemp(E) kvm_intel(E) rfkill(E) ipmi_ssif(E) kvm(E) acpi_ipmi(E) irqbypass(E) pcspkr(E) igb(E) ipmi_si(E) mei_me(E) i2c_i801(E) joydev(E) intel_pch_thermal(E) i2c_smbus(E) dca(E) lpc_ich(E) mei(E) ipmi_devintf(E) ipmi_msghandler(E) acpi_pad(E) tiny_power_button(E) button(E) fuse(E) efi_pstore(E) configfs(E) ip_tables(E) x_tables(E) ext4(E) mbcache(E) jbd2(E) hid_generic(E) usbhid(E) sd_mod(E) t10_pi(E) crct10dif_pclmul(E) crc32_pclmul(E) crc32c_intel(E) polyval_clmulni(E) ahci(E) xhci_pci(E) polyval_generic(E) gf128mul(E) ghash_clmulni_intel(E) sha512_ssse3(E) sha256_ssse3(E) xhci_pci_renesas(E) libahci(E) ehci_pci(E) sha1_ssse3(E) xhci_hcd(E) ehci_hcd(E) libata(E)\n kernel:  mgag200(E) i2c_algo_bit(E) usbcore(E) wmi(E) sg(E) dm_multipath(E) dm_mod(E) scsi_dh_rdac(E) scsi_dh_emc(E) scsi_dh_alua(E) scsi_mod(E) scsi_common(E) aesni_intel(E) crypto_simd(E) cryptd(E)\n kernel: Unloaded tainted modules: acpi_cpufreq(E):1 fjes(E):1\n kernel: CR2: 0000000000000028\n kernel: ---[ end trace 0000000000000000 ]---\n kernel: RIP: 0010:hugetlbfs_fill_super+0xb4/0x1a0\n kernel: Code: 48 8b 3b e8 3e c6 ed ff 48 85 c0 48 89 45 20 0f 84 d6 00 00 00 48 b8 ff ff ff ff ff ff ff 7f 4c 89 e7 49 89 44 24 20 48 8b 03 <8b> 48 28 b8 00 10 00 00 48 d3 e0 49 89 44 24 18 48 8b 03 8b 40 28\n kernel: RSP: 0018:ffffbe9960fcbd48 EFLAGS: 00010246\n kernel: RAX: 0000000000000000 RBX: ffff9af5272ae780 RCX: 0000000000372004\n kernel: RDX: ffffffffffffffff RSI: ffffffffffffffff RDI: ffff9af555e9b000\n kernel: RBP: ffff9af52ee66b00 R08: 0000000000000040 R09: 0000000000370004\n kernel: R10: ffffbe9960fcbd48 R11: 0000000000000040 R12: ffff9af555e9b000\n kernel: R13: ffffffffa66b86c0 R14: ffff9af507d2f400 R15: ffff9af507d2f400\n kernel: FS:  00007ffbc0ba4740(0000) GS:ffff9b0bd7000000(0000) knlGS:0000000000000000\n kernel: CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n kernel: CR2: 0000000000000028 CR3: 00000001b1ee0000 CR4: 00000000001506f0\n\nLink: https://lkml.kernel.org/r/20240130210418.3771-1-osalvador@suse.de\nFixes: 32021982a324 (""hugetlbfs: Convert to fs_context"")\nSigned-off-by: Michal Hocko <mhocko@suse.com>\nSigned-off-by: Oscar Salvador <osalvador@suse.de>\nAcked-by: Muchun Song <muchun.song@linux.dev>\nCc: <stable@vger.kernel.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\n', '']",Fix a NULL pointer dereference in hugetlb filesystem configuration using fsconfig() syscall.,"NULL pointer, hugetlb, fsconfig",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
e55dad12abe42383b68ba88212eb3d0fba0e9820,e55dad12abe42383b68ba88212eb3d0fba0e9820,Masahiro Yamada,masahiroy@kernel.org,1707033394,Andrii Nakryiko,andrii@kernel.org,1707352700,95060d8656e08791594f03f7a6f9897238a7dc0f,ba6a6abb3bfa8377bcf386a11077c0533909f9e8,"bpf: Merge two CONFIG_BPF entries

'config BPF' exists in both init/Kconfig and kernel/bpf/Kconfig.

Commit b24abcff918a (""bpf"," kconfig: Add consolidated menu entry for bpf
with core options"") added the second one to kernel/bpf/Kconfig instead
of moving the existing one.

Merge them together.

Signed-off-by: Masahiro Yamada <masahiroy@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/bpf/20240204075634.32969-1-masahiroy@kernel.org
",[''],Merge two CONFIG_BPF entries from init/Kconfig and kernel/bpf/Kconfig into one.,"CONFIG_BPF,Kconfig,merge",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['other']
ba6a6abb3bfa8377bcf386a11077c0533909f9e8,ba6a6abb3bfa8377bcf386a11077c0533909f9e8,Yafang Shao,laoar.shao@gmail.com,1707207255,Andrii Nakryiko,andrii@kernel.org,1707351259,2a279297c137645aa92eedc2632d6f675ab179ea,a2bff65cfca93f0fe4c5996f55ce8f413e85e4fe,"selftests/bpf: Mark cpumask kfunc declarations as __weak

After the series ""Annotate kfuncs in .BTF_ids section""[0]"," kfuncs can be
generated from bpftool. Let's mark the existing cpumask kfunc declarations
__weak so they don't conflict with definitions that will eventually come
from vmlinux.h.

[0]. https://lore.kernel.org/all/cover.1706491398.git.dxu@dxuuu.xyz

Suggested-by: Andrii Nakryiko <andrii.nakryiko@gmail.com>
Signed-off-by: Yafang Shao <laoar.shao@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Daniel Xu <dxu@dxuuu.xyz>
Link: https://lore.kernel.org/bpf/20240206081416.26242-5-laoar.shao@gmail.com
",[''],Mark cpumask kfunc declarations as __weak to avoid conflicts with future vmlinux.h definitions.,"cpumask,kfunc,weak",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a2bff65cfca93f0fe4c5996f55ce8f413e85e4fe,a2bff65cfca93f0fe4c5996f55ce8f413e85e4fe,Yafang Shao,laoar.shao@gmail.com,1707207254,Andrii Nakryiko,andrii@kernel.org,1707351259,08f77121b850c0a41aebedae163280cf12231b49,abae1ac5231e56ecc3932f83f2de13701070803a,"selftests/bpf: Fix error checking for cpumask_success__load()

We should verify the return value of cpumask_success__load().

Signed-off-by: Yafang Shao <laoar.shao@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240206081416.26242-4-laoar.shao@gmail.com
",,Added error checking for cpumask_success__load() in the selftests/bpf tests.,"error checking,selftests,bpf",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
abae1ac5231e56ecc3932f83f2de13701070803a,abae1ac5231e56ecc3932f83f2de13701070803a,Andrii Nakryiko,andrii@kernel.org,1707350178,Andrii Nakryiko,andrii@kernel.org,1707350178,78646bb8e255f22fb742237706ed2d49bbeee529,92a871ab9fa59a74d013bc04f321026a057618e7 903fad4394666bc23975c93fb58f137ce64b5192,"Merge branch 'tools-resolve_btfids-fix-cross-compilation-to-non-host-endianness'

Viktor Malik says:

====================
tools/resolve_btfids: fix cross-compilation to non-host endianness

The .BTF_ids section is pre-filled with zeroed BTF ID entries during the
build and afterwards patched by resolve_btfids with correct values.
Since resolve_btfids always writes in host-native endianness"," it relies
on libelf to do the translation when the target ELF is cross-compiled to
a different endianness (this was introduced in commit 61e8aeda9398
(""bpf: Fix libelf endian handling in resolv_btfids"")).

Unfortunately","["" the translation will corrupt the flags fields of SET8\nentries because these were written during vmlinux compilation and are in\nthe correct endianness already. This will lead to numerous selftests\nfailures such as:\n\n    $ sudo ./test_verifier 502 502\n    #502/p sleepable fentry accept FAIL\n    Failed to load prog 'Invalid argument'!\n    bpf_fentry_test1 is not sleepable\n    verification time 34 usec\n    stack depth 0\n    processed 0 insns (limit 1000000) max_states_per_insn 0 total_states 0 peak_states 0 mark_read 0\n    Summary: 0 PASSED"", ' 0 SKIPPED', "" 1 FAILED\n\nSince it's not possible to instruct libelf to translate just certain\nvalues"", "" let's manually bswap the flags (both global and entry flags) in\nresolve_btfids when needed"", "" so that libelf then translates everything\ncorrectly.\n\nThe first patch of the series refactors resolve_btfids by using types\nfrom btf_ids.h instead of accessing the BTF ID data using magic offsets.\nAcked-by: Jiri Olsa <jolsa@kernel.org>\n---\nChanges in v4:\n- remove unnecessary vars and pointer casts (suggested by Daniel Xu)\n\nChanges in v3:\n- add byte swap of global 'flags' field in btf_id_set8 (suggested by\n  Jiri Olsa)\n- cleaner refactoring of sets_patch (suggested by Jiri Olsa)\n- add compile-time assertion that IDs are at the beginning of pairs\n  struct in btf_id_set8 (suggested by Daniel Borkmann)\n\nChanges in v2:\n- use type defs from btf_ids.h (suggested by Andrii Nakryiko)\n====================\n\nLink: https://lore.kernel.org/r/cover.1707223196.git.vmalik@redhat.com\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n"", '']",The commit fixes cross-compilation of BTF ID entries in non-host endianness.,"cross-compilation,BTF,endianness",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
903fad4394666bc23975c93fb58f137ce64b5192,903fad4394666bc23975c93fb58f137ce64b5192,Viktor Malik,vmalik@redhat.com,1707223570,Andrii Nakryiko,andrii@kernel.org,1707350178,78646bb8e255f22fb742237706ed2d49bbeee529,9707ac4fe2f5bac6406d2403f8b8a64d7b3d8e43,"tools/resolve_btfids: Fix cross-compilation to non-host endianness

The .BTF_ids section is pre-filled with zeroed BTF ID entries during the
build and afterwards patched by resolve_btfids with correct values.
Since resolve_btfids always writes in host-native endianness"," it relies
on libelf to do the translation when the target ELF is cross-compiled to
a different endianness (this was introduced in commit 61e8aeda9398
(""bpf: Fix libelf endian handling in resolv_btfids"")).

Unfortunately","["" the translation will corrupt the flags fields of SET8\nentries because these were written during vmlinux compilation and are in\nthe correct endianness already. This will lead to numerous selftests\nfailures such as:\n\n    $ sudo ./test_verifier 502 502\n    #502/p sleepable fentry accept FAIL\n    Failed to load prog 'Invalid argument'!\n    bpf_fentry_test1 is not sleepable\n    verification time 34 usec\n    stack depth 0\n    processed 0 insns (limit 1000000) max_states_per_insn 0 total_states 0 peak_states 0 mark_read 0\n    Summary: 0 PASSED"", ' 0 SKIPPED', "" 1 FAILED\n\nSince it's not possible to instruct libelf to translate just certain\nvalues"", "" let's manually bswap the flags (both global and entry flags) in\nresolve_btfids when needed"", ' so that libelf then translates everything\ncorrectly.\n\nFixes: ef2c6f370a63 (""tools/resolve_btfids: Add support for 8-byte BTF sets"")\nSigned-off-by: Viktor Malik <vmalik@redhat.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/7b6bff690919555574ce0f13d2a5996cacf7bf69.1707223196.git.vmalik@redhat.com\n', '']",Fixes cross-compilation issue in resolve_btfids for non-host endianness by correcting BTF ID entry handling.,"cross-compilation,endian,BTF",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9707ac4fe2f5bac6406d2403f8b8a64d7b3d8e43,9707ac4fe2f5bac6406d2403f8b8a64d7b3d8e43,Viktor Malik,vmalik@redhat.com,1707223569,Andrii Nakryiko,andrii@kernel.org,1707350178,0d58e1e1bff4f1d5e73cb9f11b7fa9157ec58a14,92a871ab9fa59a74d013bc04f321026a057618e7,"tools/resolve_btfids: Refactor set sorting with types from btf_ids.h

Instead of using magic offsets to access BTF ID set data"," leverage types
from btf_ids.h (btf_id_set and btf_id_set8) which define the actual
layout of the data. Thanks to this change","["" set sorting should also\ncontinue working if the layout changes.\n\nThis requires to sync the definition of 'struct btf_id_set8' from\ninclude/linux/btf_ids.h to tools/include/linux/btf_ids.h. We don't sync\nthe rest of the file at the moment"", "" b/c that would require to also sync\nmultiple dependent headers and we don't need any other defs from\nbtf_ids.h.\n\nSigned-off-by: Viktor Malik <vmalik@redhat.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Daniel Xu <dxu@dxuuu.xyz>\nLink: https://lore.kernel.org/bpf/ff7f062ddf6a00815fda3087957c4ce667f50532.1707223196.git.vmalik@redhat.com\n"", '']",Refactor tools/resolve_btfids to use type definitions from btf_ids.h for set sorting.,"refactor,BTF ID,tools",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
92a871ab9fa59a74d013bc04f321026a057618e7,92a871ab9fa59a74d013bc04f321026a057618e7,Toke Høiland-Jørgensen,toke@redhat.com,1707224362,Andrii Nakryiko,andrii@kernel.org,1707241886,8e13b5d7d65df829f352e669512badd7f97fb2b5,c27aa462aa78ff157fdda222af242e4571803d4a,"libbpf: Use OPTS_SET() macro in bpf_xdp_query()

When the feature_flags and xdp_zc_max_segs fields were added to the libbpf
bpf_xdp_query_opts"," the code writing them did not use the OPTS_SET() macro.
This causes libbpf to write to those fields unconditionally","[' which means\nthat programs compiled against an older version of libbpf (with a smaller\nsize of the bpf_xdp_query_opts struct) will have its stack corrupted by\nlibbpf writing out of bounds.\n\nThe patch adding the feature_flags field has an early bail out if the\nfeature_flags field is not part of the opts struct (via the OPTS_HAS)\nmacro', ' but the patch adding xdp_zc_max_segs does not. For consistency', ' this\nfix just changes the assignments to both fields to use the OPTS_SET()\nmacro.\n\nFixes: 13ce2daa259a (""xsk: add new netlink attribute dedicated for ZC max frags"")\nSigned-off-by: Toke Høiland-Jørgensen <toke@redhat.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240206125922.1992815-1-toke@redhat.com\n', '']",The commit updates libbpf's bpf_xdp_query function to use the OPTS_SET() macro for feature_flags and xdp_zc_max_segs fields.,"libbpf, OPTS_SET, bpf_xdp_query",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,['xdp like programs']
c27aa462aa78ff157fdda222af242e4571803d4a,c27aa462aa78ff157fdda222af242e4571803d4a,Jose E. Marchesi,jose.marchesi@oracle.com,1707215010,Andrii Nakryiko,andrii@kernel.org,1707241225,9fa7f115dee42bc9786a742bd5c661970cfc71d1,563918a0e3afd97bcfb680b72c52ec080c82aea6,"bpf: Use -Wno-address-of-packed-member in some selftests

[Differences from V2:
- Remove conditionals in the source files pragmas"," as the
  pragma is supported by both GCC and clang.]

Both GCC and clang implement the -Wno-address-of-packed-member
warning","[' which is enabled by -Wall', ' that warns about taking the\naddress of a packed struct field when it can lead to an ""unaligned""\naddress.\n\nThis triggers the following errors (-Werror) when building three\nparticular BPF selftests with GCC:\n\n  progs/test_cls_redirect.c\n  986 |         if (ipv4_is_fragment((void *)&encap->ip)) {\n  progs/test_cls_redirect_dynptr.c\n  410 |         pkt_ipv4_checksum((void *)&encap_gre->ip);\n  progs/test_cls_redirect.c\n  521 |         pkt_ipv4_checksum((void *)&encap_gre->ip);\n  progs/test_tc_tunnel.c\n   232 |         set_ipv4_csum((void *)&h_outer.ip);\n\nThese warnings do not signal any real problem in the tests as far as I\ncan see.\n\nThis patch adds pragmas to these test files that inhibit the\n-Waddress-of-packed-member warning.\n\nTested in bpf-next master.\nNo regressions.\n\nSigned-off-by: Jose E. Marchesi <jose.marchesi@oracle.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/bpf/20240206102330.7113-1-jose.marchesi@oracle.com\n', '']",Suppress the address-of-packed-member warning in certain BPF selftests using specific compiler flags.,"compiler, selftests, warning",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
563918a0e3afd97bcfb680b72c52ec080c82aea6,563918a0e3afd97bcfb680b72c52ec080c82aea6,Dave Thaler,dthaler1968@googlemail.com,1707195106,Alexei Starovoitov,ast@kernel.org,1707234299,e3a42c09c1b3d1e748b044ca7fca5e831e9a4139,c7dcb6c9aa85fa310251dad7e233eb955a5235ed,bpf," docs: Fix typos in instructions-set.rst

* ""imm32"" should just be ""imm""
* Add blank line to fix formatting error reported by Stephen Rothwell [0]

[0]: https://lore.kernel.org/bpf/20240206153301.4ead0bad@canb.auug.org.au/T/#u

Signed-off-by: Dave Thaler <dthaler1968@gmail.com>
Acked-by: David Vernet <void@manifault.com>
Link: https://lore.kernel.org/r/20240206045146.4965-1-dthaler1968@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Fix typos and formatting errors in BPF documentation files.,"typos, formatting, documentation",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
c7dcb6c9aa85fa310251dad7e233eb955a5235ed,c7dcb6c9aa85fa310251dad7e233eb955a5235ed,Andrii Nakryiko,andrii@kernel.org,1707180008,Alexei Starovoitov,ast@kernel.org,1707192158,1b1f362cb3489569fd473d0fda11c678c016df7c,d7bc416aa5cc183691287e8f0b1d5b182a7ce9c3,"selftests/bpf: mark dynptr kfuncs __weak to make them optional on old kernels

Mark dynptr kfuncs as __weak to allow
verifier_global_subprogs/arg_ctx_{perf",kprobe,"['raw_tp} subtests to be\nloadable on old kernels. Because bpf_dynptr_from_xdp() kfunc is used\nfrom arg_tag_dynptr BPF program in progs/verifier_global_subprogs.c\n*and* is not marked as __weak', "" loading any subtest from\nverifier_global_subprogs fails on old kernels that don't have\nbpf_dynptr_from_xdp() kfunc defined. Even if arg_tag_dynptr program\nitself is not loaded"", "" libbpf bails out on non-weak reference to\nbpf_dynptr_from_xdp (that can't be resolved)"", ' which shared across all\nprograms in progs/verifier_global_subprogs.c.\n\nSo mark all dynptr-related kfuncs as __weak to unblock libbpf CI ([0]).\nIn the upcoming ""kfunc in vmlinux.h"" work we should make sure that\nkfuncs are always declared __weak as well.\n\n  [0] https://github.com/libbpf/libbpf/actions/runs/7792673215/job/21251250831?pr=776#step:4:7961\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240206004008.1541513-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Mark dynamic pointer kfuncs as __weak to ensure compatibility with older kernels in BPF selftests.,"dynptr, optional, kfuncs",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
d7bc416aa5cc183691287e8f0b1d5b182a7ce9c3,d7bc416aa5cc183691287e8f0b1d5b182a7ce9c3,Andrii Nakryiko,andrii@kernel.org,1707178963,Alexei Starovoitov,ast@kernel.org,1707192106,1e054fec46141850da461e64e9a72c06039dbcff,6146fae67bc2b92100bff8b2d6a6d5bca07edcf8,"libbpf: fix return value for PERF_EVENT __arg_ctx type fix up check

If PERF_EVENT program has __arg_ctx argument with matching
architecture-specific pt_regs/user_pt_regs/user_regs_struct pointer
type", libbpf should still perform type rewrite for old kernels,"[' but not\nemit the warning. Fix copy/paste from kernel code where 0 is meant to\nsignify ""no error"" condition. For libbpf we need to return ""true"" to\nproceed with type rewrite (which for PERF_EVENT program will be\na canonical `struct bpf_perf_event_data *` type).\n\nFixes: 9eea8fafe33e (""libbpf: fix __arg_ctx type enforcement for perf_event programs"")\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240206002243.1439450-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes return value handling for type fix-up check in libbpf for PERF_EVENT programs.,"libbpf,return value,PERF_EVENT",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,['tracepoints like programs']
20a286c1a35ba4dc2fca5d4c1fb2e7ced101e576,20a286c1a35ba4dc2fca5d4c1fb2e7ced101e576,Alexei Starovoitov,ast@kernel.org,1707192014,Alexei Starovoitov,ast@kernel.org,1707192014,5633630512456d6639125786010e2125253f83eb,8244ab509f89d63941d5ee207967c5a3e00bb493 8be6a0147af314fd60db9da2158cd737dc6394a7,"Merge branch 'transfer-rcu-lock-state-across-subprog-calls'

Kumar Kartikeya Dwivedi says:

====================
Transfer RCU lock state across subprog calls

David suggested during the discussion in [0] that we should handle RCU
locks in a similar fashion to spin locks where the verifier understands
when a lock held in a caller is released in callee"," or lock taken in
callee is released in a caller","[' or the callee is called within a lock\ncritical section. This set extends the same semantics to RCU read locks\nand adds a few selftests to verify correct behavior. This issue has also\ncome up for sched-ext programs.\n\nThis would now allow static subprog calls to be made without errors\nwithin RCU read sections', ' for subprogs to release RCU locks of callers\nand return to them', ' or for subprogs to take RCU lock which is later\nreleased in the caller.\n\n  [0]: https://lore.kernel.org/bpf/20240204120206.796412-1-memxor@gmail.com\n\nChangelog:\n----------\nv1 -> v2:\nv1: https://lore.kernel.org/bpf/20240204230231.1013964-1-memxor@gmail.com\n\n * Add tests for global subprog behaviour (Yafang)\n * Add Acks', ' Tested-by (Yonghong', ' Yafang)\n====================\n\nLink: https://lore.kernel.org/r/20240205055646.1112186-1-memxor@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Implements transfer of RCU lock state across subprogram calls in eBPF verifier.,"RCU,verifier,locks",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8be6a0147af314fd60db9da2158cd737dc6394a7,8be6a0147af314fd60db9da2158cd737dc6394a7,Kumar Kartikeya Dwivedi,memxor@gmail.com,1707112606,Alexei Starovoitov,ast@kernel.org,1707192014,5633630512456d6639125786010e2125253f83eb,6fceea0fa59f6786a2847a4cae409117624e8b58,"selftests/bpf: Add tests for RCU lock transfer between subprogs

Add selftests covering the following cases:
- A static or global subprog called from within a RCU read section works
- A static subprog taking an RCU read lock which is released in caller works
- A static subprog releasing the caller's RCU read lock works

Global subprogs that leave the lock in an imbalanced state will not
work", as they are verified separately,"[' so ensure those cases fail as\nwell.\n\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nAcked-by: David Vernet <void@manifault.com>\nLink: https://lore.kernel.org/r/20240205055646.1112186-3-memxor@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add selftests for RCU lock handling in static or global subprograms within BPF programs.,"selftests, RCU lock, subprograms",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['tracepoints like programs', 'kprobe/uprobe/ftrace like programs', 'cgroup like programs']"
6fceea0fa59f6786a2847a4cae409117624e8b58,6fceea0fa59f6786a2847a4cae409117624e8b58,Kumar Kartikeya Dwivedi,memxor@gmail.com,1707112605,Alexei Starovoitov,ast@kernel.org,1707192014,0756fa0cce159ca3d2eb887f3b4c53fab2e823c5,8244ab509f89d63941d5ee207967c5a3e00bb493,"bpf: Transfer RCU lock state between subprog calls

Allow transferring an imbalanced RCU lock state between subprog calls
during verification. This allows patterns where a subprog call returns
with an RCU lock held"," or a subprog call releases an RCU lock held by
the caller. Currently","[' the verifier would end up complaining if the RCU\nlock is not released when processing an exit from a subprog', ' which is\nnon-ideal if its execution is supposed to be enclosed in an RCU read\nsection of the caller.\n\nInstead', ' simply only check whether we are processing exit for frame#0\nand do not complain on an active RCU lock otherwise. We only need to\nupdate the check when processing BPF_EXIT insn', ' as copy_verifier_state\nis already set up to do the right thing.\n\nSuggested-by: David Vernet <void@manifault.com>\nTested-by: Yafang Shao <laoar.shao@gmail.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nAcked-by: David Vernet <void@manifault.com>\nLink: https://lore.kernel.org/r/20240205055646.1112186-2-memxor@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Enable transferring imbalanced RCU lock state between subprogram calls during eBPF verification.,"RCU lock,state transfer,subprog calls",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8244ab509f89d63941d5ee207967c5a3e00bb493,8244ab509f89d63941d5ee207967c5a3e00bb493,Alexei Starovoitov,ast@kernel.org,1707191927,Alexei Starovoitov,ast@kernel.org,1707191927,b0dda80da2bdd867ad47d5d108bbea0e1e5f822c,2d9a925d0fbf0dae99af148adaf4f5cadf1be5e0 e8699c4ff85baedcf40f33db816cc487cee39397,"Merge branch 'enable-static-subprog-calls-in-spin-lock-critical-sections'

Kumar Kartikeya Dwivedi says:

====================
Enable static subprog calls in spin lock critical sections

This set allows a BPF program to make a call to a static subprog within
a bpf_spin_lock critical section. This problem has been hit in sched-ext
and ghOSt [0] as well"," and is mostly an annoyance which is worked around
by inling the static subprog into the critical section.

In case of sched-ext","[' there are a lot of other helper/kfunc calls that\nneed to be allow listed for the support to be complete', ' but a separate\nfollow up will deal with that.\n\nUnlike static subprogs', ' global subprogs cannot be allowed yet as the\nverifier will not explore their body when encountering a call\ninstruction for them. Therefore', ' we would need an alternative approach\n(some sort of function summarization to ensure a lock is never taken\nfrom a global subprog and all its callees).\n\n [0]: https://lore.kernel.org/bpf/bd173bf2-dea6-3e0e-4176-4a9256a9a056@google.com\n\nChangelog:\n----------\nv1 -> v2\nv1: https://lore.kernel.org/bpf/20240204120206.796412-1-memxor@gmail.com\n\n * Indicate global function call in verifier error string (Yonghong', ' David)\n * Add Acks from Yonghong', ' David\n====================\n\nLink: https://lore.kernel.org/r/20240204222349.938118-1-memxor@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Enable static subprog calls within bpf_spin_lock critical sections in eBPF programs.,"static subprog, spin lock, eBPF",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['scheduler like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e8699c4ff85baedcf40f33db816cc487cee39397,e8699c4ff85baedcf40f33db816cc487cee39397,Kumar Kartikeya Dwivedi,memxor@gmail.com,1707085429,Alexei Starovoitov,ast@kernel.org,1707191927,b0dda80da2bdd867ad47d5d108bbea0e1e5f822c,a44b1334aadd82203f661adb9adb41e53ad0e8d1,"selftests/bpf: Add test for static subprog call in lock cs

Add selftests for static subprog calls within bpf_spin_lock critical
section"," and ensure we still reject global subprog calls. Also test the
case where a subprog call will unlock the caller's held lock","[' or the\ncaller will unlock a lock taken by a subprog call', ' ensuring correct\ntransfer of lock state across frames on exit.\n\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nAcked-by: David Vernet <void@manifault.com>\nSigned-off-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nLink: https://lore.kernel.org/r/20240204222349.938118-3-memxor@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit adds selftests for static subprogram calls within bpf_spin_lock critical section.,"selftests, subprog, bpf_spin_lock",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a44b1334aadd82203f661adb9adb41e53ad0e8d1,a44b1334aadd82203f661adb9adb41e53ad0e8d1,Kumar Kartikeya Dwivedi,memxor@gmail.com,1707085428,Alexei Starovoitov,ast@kernel.org,1707191927,05b11f422c3dc5bc08aec65c23cda9a0a3b7d885,2d9a925d0fbf0dae99af148adaf4f5cadf1be5e0,"bpf: Allow calling static subprogs while holding a bpf_spin_lock

Currently", calling any helpers,"[' kfuncs', ' or subprogs except the graph\ndata structure (lists', "" rbtrees) API kfuncs while holding a bpf_spin_lock\nis not allowed. One of the original motivations of this decision was to\nforce the BPF programmer's hand into keeping the bpf_spin_lock critical\nsection small"", ' and to ensure the execution time of the program does not\nincrease due to lock waiting times. In addition to this', ' some of the\nhelpers and kfuncs may be unsafe to call while holding a bpf_spin_lock.\n\nHowever', ' when it comes to subprog calls', ' atleast for static subprogs', '\nthe verifier is able to explore their instructions during verification.\nTherefore', ' it is similar in effect to having the same code inlined into\nthe critical section. Hence', ' not allowing static subprog calls in the\nbpf_spin_lock critical section is mostly an annoyance that needs to be\nworked around', ' without providing any tangible benefit.\n\nUnlike static subprog calls', ' global subprog calls are not safe to permit\nwithin the critical section', ' as the verifier does not explore them\nduring verification', ' therefore whether the same lock will be taken\nagain', ' or unlocked', ' cannot be ascertained.\n\nTherefore', ' allow calling static subprogs within a bpf_spin_lock critical\nsection', ' and only reject it in case the subprog linkage is global.\n\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nAcked-by: David Vernet <void@manifault.com>\nSigned-off-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nLink: https://lore.kernel.org/r/20240204222349.938118-2-memxor@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit allows calling static subprograms while holding a bpf_spin_lock in eBPF programs.,"bpf_spin_lock,static subprograms,eBPF",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['xdp like programs', 'tc/netfilter like programs', 'tracepoints like programs']"
2d9a925d0fbf0dae99af148adaf4f5cadf1be5e0,2d9a925d0fbf0dae99af148adaf4f5cadf1be5e0,Dave Thaler,dthaler1968@googlemail.com,1706911870,Alexei Starovoitov,ast@kernel.org,1707173085,d9dea1846484578b31d59625e04b3821f590a24c,e7f31873176a345d72ca77c7b4da48493ccd9efd,bpf," docs: Expand set of initial conformance groups

This patch attempts to update the ISA specification according
to the latest mailing list discussion about conformance groups","['\nin a way that is intended to be consistent with IANA registry\nprocesses and IETF 118 WG meeting discussion.\n\nIt does the following:\n* Split basic into base32 and base64 for 32-bit vs 64-bit base\n  instructions\n* Split division/multiplication/modulo instructions out of base groups\n* Split atomic instructions out of base groups\n\nThere may be additional changes as discussion continues', '\nbut there seems to be consensus on the principles above.\n\nv1->v2: fixed typo pointed out by David Vernet\n\nv2->v3: Moved multiplication to same groups as division/modulo\n\nSigned-off-by: Dave Thaler <dthaler1968@gmail.com>\nAcked-by: David Vernet <void@manifault.com>\nLink: https://lore.kernel.org/r/20240202221110.3872-1-dthaler1968@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Update the ISA specification with changes from latest mailing list discussion on conformance groups.,"ISA,specification,conformance",It's a documentation change or typo fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e7f31873176a345d72ca77c7b4da48493ccd9efd,e7f31873176a345d72ca77c7b4da48493ccd9efd,Yonghong Song,yonghong.song@linux.dev,1707110954,Andrii Nakryiko,andrii@kernel.org,1707160416,ef486ceb0fff08250fc11800b2987299daf71041,169e650069647325496e5a65408ff301874c8e01,"selftests/bpf: Fix flaky selftest lwt_redirect/lwt_reroute

Recently", when running './test_progs -j',"[' I occasionally hit the\nfollowing errors:\n\n  test_lwt_redirect:PASS:pthread_create 0 nsec\n  test_lwt_redirect_run:FAIL:netns_create unexpected error: 256 (errno 0)\n  #142/2   lwt_redirect/lwt_redirect_normal_nomac:FAIL\n  #142     lwt_redirect:FAIL\n  test_lwt_reroute:PASS:pthread_create 0 nsec\n  test_lwt_reroute_run:FAIL:netns_create unexpected error: 256 (errno 0)\n  test_lwt_reroute:PASS:pthread_join 0 nsec\n  #143/2   lwt_reroute/lwt_reroute_qdisc_dropped:FAIL\n  #143     lwt_reroute:FAIL\n\nThe netns_create() definition looks like below:\n\n  #define NETNS ""ns_lwt""\n  static inline int netns_create(void)\n  {\n        return system(""ip netns add "" NETNS);\n  }\n\nOne possibility is that both lwt_redirect and lwt_reroute create\nnetns with the same name ""ns_lwt"" which may cause conflict. I tried\nthe following example:\n  $ sudo ip netns add abc\n  $ echo $?\n  0\n  $ sudo ip netns add abc\n  Cannot create namespace file ""/var/run/netns/abc"": File exists\n  $ echo $?\n  1\n  $\n\nThe return code for above netns_create() is 256. The internet search\nsuggests that the return value for \'ip netns add ns_lwt\' is 1', "" which\nmatches the above 'sudo ip netns add abc' example.\n\nThis patch tried to use different netns names for two tests to avoid\n'ip netns add <name>' failure.\n\nI ran './test_progs -j' 10 times and all succeeded with\nlwt_redirect/lwt_reroute tests.\n\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nTested-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/bpf/20240205052914.1742687-1-yonghong.song@linux.dev\n"", '']",Fixes a flaky selftest for lwt_redirect and lwt_reroute in the BPF testing suite.,"flaky,selftest,lwt_redirect",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['socket like programs', 'tc/netfilter like programs']"
169e650069647325496e5a65408ff301874c8e01,169e650069647325496e5a65408ff301874c8e01,Kui-Feng Lee,thinker.li@gmail.com,1707027124,Martin KaFai Lau,martin.lau@kernel.org,1707159158,1ccdd32f79d639cd3cdf9b86c50debd1a864df24,7e428638bd784fd9e8944bfbf11513520e141b91,"selftests/bpf: Suppress warning message of an unused variable.

""r"" is used to receive the return value of test_2 in bpf_testmod.c"," but it
is not actually used. So","[' we remove ""r"" and change the return type to\n""void"".\n\nReported-by: kernel test robot <lkp@intel.com>\nCloses: https://lore.kernel.org/oe-kbuild-all/202401300557.z5vzn8FM-lkp@intel.com/\nSigned-off-by: Kui-Feng Lee <thinker.li@gmail.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240204061204.1864529-1-thinker.li@gmail.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Suppress unused variable warning in bpf_testmod.c selftest.,"selftests,bpf,unused variable",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7e428638bd784fd9e8944bfbf11513520e141b91,7e428638bd784fd9e8944bfbf11513520e141b91,Yonghong Song,yonghong.song@linux.dev,1707075892,Andrii Nakryiko,andrii@kernel.org,1707158921,bab39b99b5cc9453ae43dbc5a06df7c60072b2a4,df9705eaa0bad034dad0f73386ff82f5c4dd7e24,"selftests/bpf: Fix flaky test ptr_untrusted

Somehow recently I frequently hit the following test failure
with either ./test_progs or ./test_progs-cpuv4:
  serial_test_ptr_untrusted:PASS:skel_open 0 nsec
  serial_test_ptr_untrusted:PASS:lsm_attach 0 nsec
  serial_test_ptr_untrusted:PASS:raw_tp_attach 0 nsec
  serial_test_ptr_untrusted:FAIL:cmp_tp_name unexpected cmp_tp_name: actual -115 != expected 0
  #182     ptr_untrusted:FAIL

Further investigation found the failure is due to
  bpf_probe_read_user_str()
where reading user-level string attr->raw_tracepoint.name
is not successfully"," most likely due to the
string itself still in disk and not populated into memory yet.

One solution is do a printf() call of the string before doing bpf
syscall which will force the raw_tracepoint.name into memory.
But I think a more robust solution is to use bpf_copy_from_user()
which is used in sleepable program and can tolerate page fault","['\nand the fix here used the latter approach.\n\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240204194452.2785936-1-yonghong.song@linux.dev\n', '']",Fixes a flaky test caused by bpf_probe_read_user_str() failure in ptr_untrusted.,"flaky,test,bpf_probe_read_user_str",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tracepoints like programs']
df9705eaa0bad034dad0f73386ff82f5c4dd7e24,df9705eaa0bad034dad0f73386ff82f5c4dd7e24,Kui-Feng Lee,thinker.li@gmail.com,1706939479,Martin KaFai Lau,martin.lau@kernel.org,1707157508,524621a4914a63253486e260a7d1ed7932108f7b,2a79690eae953daaac232f93e6c5ac47ac539f2d,"bpf: Remove an unnecessary check.

The ""i"" here is always equal to ""btf_type_vlen(t)"" since
the ""for_each_member()"" loop never breaks.

Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20240203055119.2235598-1-thinker.li@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Removed an unnecessary check in bpf code related to loop iteration.,"unnecessary, check, loop",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a8882313c5640103f93a07cf352f6ccf8e7defc3,a8882313c5640103f93a07cf352f6ccf8e7defc3,David S. Miller,davem@davemloft.net,1707136767,David S. Miller,davem@davemloft.net,1707136767,c9cb385d4255e5d83b7955a628fdc71a54578344,0cd216d769fbd161c06f5a702bf7a951f276f558 709776ea85625fb668ced6b97b005cf53612996e,"Merge branch 'qca8k-cleanup-fixes'

Vladimir Oltean says:

====================
Fixups for qca8k ds->user_mii_bus cleanup

The series ""ds->user_mii_bus cleanup (part 1)"" from the last development
cycle:
https://patchwork.kernel.org/project/netdevbpf/cover/20240104140037.374166-1-vladimir.oltean@nxp.com/

had some review comments I didn't have the time to address at the time.
One from Alvin and one from Luiz. They can reasonably be treated as
improvements for v6.9.
====================

Signed-off-by: David S. Miller <davem@davemloft.net>
",,The commit merges cleanup and fix improvements for qca8k driver user MII bus implementation.,"qca8k,cleanup,fixes",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
aad98efd0b121f63a2e1c221dcb4d4850128c697,aad98efd0b121f63a2e1c221dcb4d4850128c697,Naveen N Rao,naveen@kernel.org,1706888596,Michael Ellerman,mpe@ellerman.id.au,1707133399,731c97a15b910942119143471d340ec0ae0d441a,ed8b94f6e0acd652ce69bd69d678a0c769172df8,"powerpc/64: Set task pt_regs->link to the LR value on scv entry

Nysal reported that userspace backtraces are missing in offcputime bcc
tool. As an example:
    $ sudo ./bcc/tools/offcputime.py -uU
    Tracing off-CPU time (us) of user threads by user stack... Hit Ctrl-C to end.

    ^C
	write
	-                python (9107)
	    8

	write
	-                sudo (9105)
	    9

	mmap
	-                python (9107)
	    16

	clock_nanosleep
	-                multipathd (697)
	    3001604

The offcputime bcc tool attaches a bpf program to a kprobe on
finish_task_switch()"," which is usually hit on a syscall from userspace.
With the switch to system call vectored","[' we started setting\npt_regs->link to zero. This is because system call vectored behaves like\na function call with LR pointing to the system call return address', ' and\nwith no modification to SRR0/SRR1. The LR value does indicate our next\ninstruction', ' so it is being saved as pt_regs->nip', ' and pt_regs->link is\nbeing set to zero. This is not a problem by itself', ' but BPF uses perf\ncallchain infrastructure for capturing stack traces', ' and that stores LR\nas the second entry in the stack trace. perf has code to cope with the\nsecond entry being zero', ' and skips over it. However', ' generic userspace\nunwinders assume that a zero entry indicates end of the stack trace', '\nresulting in a truncated userspace stack trace.\n\nRather than fixing all userspace unwinders to ignore/skip past the\nsecond entry', ' store the real LR value in pt_regs->link so that there\ncontinues to be a valid', ' though duplicate entry in the stack trace.\n\nWith this change:\n    $ sudo ./bcc/tools/offcputime.py -uU\n    Tracing off-CPU time (us) of user threads by user stack... Hit Ctrl-C to end.\n\n    ^C\n\twrite\n\twrite\n\t[unknown]\n\t[unknown]\n\t[unknown]\n\t[unknown]\n\t[unknown]\n\tPyObject_VectorcallMethod\n\t[unknown]\n\t[unknown]\n\tPyObject_CallOneArg\n\tPyFile_WriteObject\n\tPyFile_WriteString\n\t[unknown]\n\t[unknown]\n\tPyObject_Vectorcall\n\t_PyEval_EvalFrameDefault\n\tPyEval_EvalCode\n\t[unknown]\n\t[unknown]\n\t[unknown]\n\t_PyRun_SimpleFileObject\n\t_PyRun_AnyFileObject\n\tPy_RunMain\n\t[unknown]\n\tPy_BytesMain\n\t[unknown]\n\t__libc_start_main\n\t-                python (1293)\n\t    7\n\n\twrite\n\twrite\n\t[unknown]\n\tsudo_ev_loop_v1\n\tsudo_ev_dispatch_v1\n\t[unknown]\n\t[unknown]\n\t[unknown]\n\t[unknown]\n\t__libc_start_main\n\t-                sudo (1291)\n\t    7\n\n\tsyscall\n\tsyscall\n\tbpf_open_perf_buffer_opts\n\t[unknown]\n\t[unknown]\n\t[unknown]\n\t[unknown]\n\t_PyObject_MakeTpCall\n\tPyObject_Vectorcall\n\t_PyEval_EvalFrameDefault\n\tPyEval_EvalCode\n\t[unknown]\n\t[unknown]\n\t[unknown]\n\t_PyRun_SimpleFileObject\n\t_PyRun_AnyFileObject\n\tPy_RunMain\n\t[unknown]\n\tPy_BytesMain\n\t[unknown]\n\t__libc_start_main\n\t-                python (1293)\n\t    11\n\n\tclock_nanosleep\n\tclock_nanosleep\n\tnanosleep\n\tsleep\n\t[unknown]\n\t[unknown]\n\t__clone\n\t-                multipathd (698)\n\t    3001661\n\nFixes: 7fa95f9adaee (""powerpc/64s: system call support for scv/rfscv instructions"")\nCc: stable@vger.kernel.org\nReported-by: ""Nysal Jan K.A"" <nysal@linux.ibm.com>\nSigned-off-by: Naveen N Rao <naveen@kernel.org>\nSigned-off-by: Michael Ellerman <mpe@ellerman.id.au>\nLink: https://msgid.link/20240202154316.395276-1-naveen@kernel.org\n\n', '']",This commit fixes the missing userspace backtraces in offcputime bcc tool by setting task pt_regs->link to the LR value on scv entry for powerpc.,"offcputime, backtraces, powerpc",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
1eb986746a67952df86eb2c50a36450ef103d01b,1eb986746a67952df86eb2c50a36450ef103d01b,Andrii Nakryiko,andrii@kernel.org,1706900729,Alexei Starovoitov,ast@kernel.org,1706926139,0e4d601040f137b0bc160f6757cff8577ae15fe4,e2e70535dd76c6f17bdc9009ffca3d26cfd35ea4,"bpf: don't emit warnings intended for global subprogs for static subprogs

When btf_prepare_func_args() was generalized to handle both static and
global subprogs"," a few warnings/errors that are meant only for global
subprog cases started to be emitted for static subprogs","[' where they are\nsort of expected and irrelavant.\n\nStop polutting verifier logs with irrelevant scary-looking messages.\n\nFixes: e26080d0da87 (""bpf: prepare btf_prepare_func_args() for handling static subprogs"")\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240202190529.2374377-4-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit stops warnings for global subprograms from being emitted for static subprograms in bpf.,"warnings, global, subprograms",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e2e70535dd76c6f17bdc9009ffca3d26cfd35ea4,e2e70535dd76c6f17bdc9009ffca3d26cfd35ea4,Andrii Nakryiko,andrii@kernel.org,1706900728,Alexei Starovoitov,ast@kernel.org,1706926138,c62f08e9d64c498ef6d87b9d47430f4438fd9c83,8f13c34087d3eb64329529b8517e5a6251653176,"selftests/bpf: add more cases for __arg_trusted __arg_nullable args

Add extra layer of global functions to ensure that passing around
(trusted) PTR_TO_BTF_ID_OR_NULL registers works as expected. We also
extend trusted_task_arg_nullable subtest to check three possible valid
argumements: known NULL", known non-NULL,"[' and maybe NULL cases.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240202190529.2374377-3-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Added tests for handling __arg_trusted and __arg_nullable argument cases in BPF selftests.,"tests,selftests,arguments",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8f13c34087d3eb64329529b8517e5a6251653176,8f13c34087d3eb64329529b8517e5a6251653176,Andrii Nakryiko,andrii@kernel.org,1706900727,Alexei Starovoitov,ast@kernel.org,1706926138,a3fb464c0e39b7aeab5aa2ee9c514bda0e0af6b7,a68b50f47bec8bd6a33b07b7e1562db2553981a7,"bpf: handle trusted PTR_TO_BTF_ID_OR_NULL in argument check logic

Add PTR_TRUSTED | PTR_MAYBE_NULL modifiers for PTR_TO_BTF_ID to
check_reg_type() to support passing trusted nullable PTR_TO_BTF_ID
registers into global functions accepting `__arg_trusted __arg_nullable`
arguments. This hasn't been caught earlier because tests were either
passing known non-NULL PTR_TO_BTF_ID registers or known NULL (SCALAR)
registers.

When utilizing this functionality in complicated real-world BPF
application that passes around PTR_TO_BTF_ID_OR_NULL"," it became apparent
that verifier rejects valid case because check_reg_type() doesn't handle
this case explicitly. Existing check_reg_type() logic is already
anticipating this combination","[' so we just need to explicitly list this\ncombo in the switch statement.\n\nFixes: e2b3c4ff5d18 (""bpf: add __arg_trusted global func arg tag"")\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240202190529.2374377-2-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit enhances argument check logic in eBPF verifier to support trusted nullable PTR_TO_BTF_ID registers.,"PTR_TO_BTF_ID, trusted, nullable",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['kprobe/uprobe/ftrace like programs', 'tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ffd856537b95dd65facb4e0c78ca1cb92c2048ff,ffd856537b95dd65facb4e0c78ca1cb92c2048ff,Arnaldo Carvalho de Melo,acme@kernel.org,1706884340,Namhyung Kim,namhyung@kernel.org,1706925837,0df147ce149485520701e8620567753cd234b902,b8db070f389c902f48e83ee7a94952e9557199e8,"perf bpf: Clean up the generated/copied vmlinux.h

When building perf with BPF skels we either copy the minimalistic
tools/perf/util/bpf_skel/vmlinux/vmlinux.h or use bpftool to generate a
vmlinux from BTF"," storing the result in $(SKEL_OUT)/vmlinux.h.

We need to remove that when doing a 'make -C tools/perf clean'","[' fix it.\n\nFixes: b7a2d774c9c5a9a3 (""perf build: Add ability to build with a generated vmlinux.h"")\nReviewed-by: Ian Rogers <irogers@google.com>\nCc: Andrii Nakryiko <andrii@kernel.org>\nCc: James Clark <james.clark@arm.com>\nCc: Tiezhu Yang <yangtiezhu@loongson.cn>\nCc: Yang Jihong <yangjihong1@huawei.com>\nCc: bpf@vger.kernel.org\nSigned-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>\nSigned-off-by: Namhyung Kim <namhyung@kernel.org>\nLink: https://lore.kernel.org/r/Zbz89KK5wHfZ82jv@x1\n', '']",This commit cleans up the generated/copied vmlinux.h file when cleaning the perf build directory.,"perf,BPF,vmlinux.h",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a68b50f47bec8bd6a33b07b7e1562db2553981a7,a68b50f47bec8bd6a33b07b7e1562db2553981a7,Shung-Hsi Yu,shung-hsi.yu@suse.com,1706867758,Martin KaFai Lau,martin.lau@kernel.org,1706912043,319c590302cf34ab5eae788a6b59f698fe848f09,6fb3f72702fba97323a89e53f484de58bc59d13c,"selftests/bpf: trace_helpers.c: do not use poisoned type

After commit c698eaebdf47 (""selftests/bpf: trace_helpers.c: Optimize
kallsyms cache"") trace_helpers.c now includes libbpf_internal.h"," and
thus can no longer use the u32 type (among others) since they are poison
in libbpf_internal.h. Replace u32 with __u32 to fix the following error
when building trace_helpers.c on powerpc:

  error: attempt to use poisoned ""u32""

Fixes: c698eaebdf47 (""selftests/bpf: trace_helpers.c: Optimize kallsyms cache"")
Signed-off-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Link: https://lore.kernel.org/r/20240202095559.12900-1-shung-hsi.yu@suse.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Replace poisoned u32 type with __u32 in trace_helpers.c to fix build error.,"poisoned,u32,trace_helpers",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6fb3f72702fba97323a89e53f484de58bc59d13c,6fb3f72702fba97323a89e53f484de58bc59d13c,Andrii Nakryiko,andrii@kernel.org,1706908935,Andrii Nakryiko,andrii@kernel.org,1706908935,3fc8bcaba15ec02e57e63eb576acba505394dd84,943b043aeecce9accb6d367af47791c633e95e4d 73a28d9d000e8d20b4b3c516b74ee92afe3ae4be,"Merge branch 'improvements-for-tracking-scalars-in-the-bpf-verifier'

Maxim Mikityanskiy says:

====================
Improvements for tracking scalars in the BPF verifier

From: Maxim Mikityanskiy <maxim@isovalent.com>

The goal of this series is to extend the verifier's capabilities of
tracking scalars when they are spilled to stack"," especially when the
spill or fill is narrowing. It also contains a fix by Eduard for
infinite loop detection and a state pruning optimization by Eduard that
compensates for a verification complexity regression introduced by
tracking unbounded scalars. These improvements reduce the surface of
false rejections that I saw while working on Cilium codebase.

Patches 1-9 of the original series were previously applied in v2.

Patches 1-2 (Maxim): Support the case when boundary checks are first
performed after the register was spilled to the stack.

Patches 3-4 (Maxim): Support narrowing fills.

Patches 5-6 (Eduard): Optimization for state pruning in stacksafe() to
mitigate the verification complexity regression.

veristat -e file","['prog', ""states -f '!states_diff<50' -f '!states_pct<10' -f '!states_a<10' -f '!states_b<10' -C ...\n\n * Without patch 5:\n\nFile                  Program   States (A)  States (B)  States    (DIFF)\n--------------------  --------  ----------  ----------  ----------------\npyperf100.bpf.o       on_event        4878        6528   +1650 (+33.83%)\npyperf180.bpf.o       on_event        6936       11032   +4096 (+59.05%)\npyperf600.bpf.o       on_event       22271       39455  +17184 (+77.16%)\npyperf600_iter.bpf.o  on_event         400         490     +90 (+22.50%)\nstrobemeta.bpf.o      on_event        4895       14028  +9133 (+186.58%)\n\n * With patch 5:\n\nFile                     Program        States (A)  States (B)  States   (DIFF)\n-----------------------  -------------  ----------  ----------  ---------------\nbpf_xdp.o                tail_lb_ipv4         2770        2224   -546 (-19.71%)\npyperf100.bpf.o          on_event             4878        5848   +970 (+19.89%)\npyperf180.bpf.o          on_event             6936        8868  +1932 (+27.85%)\npyperf600.bpf.o          on_event            22271       29656  +7385 (+33.16%)\npyperf600_iter.bpf.o     on_event              400         450    +50 (+12.50%)\nxdp_synproxy_kern.bpf.o  syncookie_tc          280         226    -54 (-19.29%)\nxdp_synproxy_kern.bpf.o  syncookie_xdp         302         228    -74 (-24.50%)\n\nv2 changes:\n\nFixed comments in patch 1"", ' moved endianness checks to header files in\npatch 12 where possible', "" added Eduard's ACKs.\n\nv3 changes:\n\nMaxim: Removed __is_scalar_unbounded altogether"", "" addressed Andrii's\ncomments.\n\nEduard: Patch #5 (#14 in v2) changed significantly:\n- Logical changes:\n  - Handling of STACK_{MISC"", 'ZERO} mix turned out to be incorrect:\n    a mix of MISC and ZERO in old state is not equivalent to e.g.\n    just MISC is current state', ' because verifier could have deduced\n    zero scalars from ZERO slots in old state for some loads.\n  - There is no reason to limit the change only to cases when\n    old or current stack is a spill of unbounded scalar', '\n    it is valid to compare any 64-bit scalar spill with fake\n    register impersonating MISC.\n  - STACK_ZERO vs spilled zero case was dropped', '\n    after recent changes for zero handling by Andrii and Yonghong\n    it is hard (impossible?) to conjure all ZERO slots for an spi.\n    => the case does not make any difference in veristat results.\n- Use global static variable for unbound_reg (Andrii)\n- Code shuffling to remove duplication in stacksafe() (Andrii)\n====================\n\nLink: https://lore.kernel.org/r/20240127175237.526726-1-maxtram95@gmail.com\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n', '']","The commit improves scalar tracking in the BPF verifier, including state pruning optimization for verification complexity regression.","scalar tracking, BPF verifier, optimization",It's a cleanup or refactoring in the code.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
73a28d9d000e8d20b4b3c516b74ee92afe3ae4be,73a28d9d000e8d20b4b3c516b74ee92afe3ae4be,Eduard Zingerman,eddyz87@gmail.com,1706377957,Andrii Nakryiko,andrii@kernel.org,1706908934,3fc8bcaba15ec02e57e63eb576acba505394dd84,6efbde200bf3cf2dbf6e7181893fed13a79c789b,"selftests/bpf: States pruning checks for scalar vs STACK_MISC

Check that stacksafe() compares spilled scalars with STACK_MISC.
The following combinations are explored:
- old spill of imprecise scalar is equivalent to cur STACK_{MISC","INVALID}
  (plus error in unpriv mode);
- old spill of precise scalar is not equivalent to cur STACK_MISC;
- old STACK_MISC is equivalent to cur scalar;
- old STACK_MISC is not equivalent to cur non-scalar.

Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240127175237.526726-7-maxtram95@gmail.com
",[''],Add selftests for checking stack safety with scalar and STACK_MISC comparisons in eBPF.,"selftests,stack,scalar",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6efbde200bf3cf2dbf6e7181893fed13a79c789b,6efbde200bf3cf2dbf6e7181893fed13a79c789b,Eduard Zingerman,eddyz87@gmail.com,1706377956,Andrii Nakryiko,andrii@kernel.org,1706908934,0b91ca2602847f5df1035b1b80bf01ab8872bb3c,067313a85c6f213932518f12f628810f0092492b,"bpf: Handle scalar spill vs all MISC in stacksafe()

When check_stack_read_fixed_off() reads value from an spi
all stack slots of which are set to STACK_{MISC",INVALID},"[""\nthe destination register is set to unbound SCALAR_VALUE.\n\nExploit this fact by allowing stacksafe() to use a fake\nunbound scalar register to compare 'mmmm mmmm' stack value\nin old state vs spilled 64-bit scalar in current state\nand vice versa.\n\nVeristat results after this patch show some gains:\n\n./veristat -C -e file"", 'prog', ""states -f 'states_pct>10'  not-opt after\nFile                     Program                States   (DIFF)\n-----------------------  ---------------------  ---------------\nbpf_overlay.o            tail_rev_nodeport_lb4    -45 (-15.85%)\nbpf_xdp.o                tail_lb_ipv4            -541 (-19.57%)\npyperf100.bpf.o          on_event                -680 (-10.42%)\npyperf180.bpf.o          on_event               -2164 (-19.62%)\npyperf600.bpf.o          on_event               -9799 (-24.84%)\nstrobemeta.bpf.o         on_event               -9157 (-65.28%)\nxdp_synproxy_kern.bpf.o  syncookie_tc             -54 (-19.29%)\nxdp_synproxy_kern.bpf.o  syncookie_xdp            -74 (-24.50%)\n\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240127175237.526726-6-maxtram95@gmail.com\n"", '']",Fixes handling of scalar spills vs all MISC states in stacksafe checks in eBPF.,"scalar,spill,stacksafe",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
067313a85c6f213932518f12f628810f0092492b,067313a85c6f213932518f12f628810f0092492b,Maxim Mikityanskiy,maxim@isovalent.com,1706377955,Andrii Nakryiko,andrii@kernel.org,1706908934,fb3a4026aa0f46104a8a929e1711f6ef262df857,c1e6148cb4f83cec841db1f066e8db4a86c1f118,"selftests/bpf: Add test cases for narrowing fill

The previous commit allowed to preserve boundaries and track IDs of
scalars on narrowing fills. Add test cases for that pattern.

Signed-off-by: Maxim Mikityanskiy <maxim@isovalent.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/bpf/20240127175237.526726-5-maxtram95@gmail.com
",,Add test cases for handling narrowing fill patterns in eBPF selftests.,"test cases,narrowing fill,selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c1e6148cb4f83cec841db1f066e8db4a86c1f118,c1e6148cb4f83cec841db1f066e8db4a86c1f118,Maxim Mikityanskiy,maxim@isovalent.com,1706377954,Andrii Nakryiko,andrii@kernel.org,1706908934,d27fac029e258f1f529907e0c05ab9ce458ee021,6be503cec6c9bccd64f72c03697011d2e2b96fc3,"bpf: Preserve boundaries and track scalars on narrowing fill

When the width of a fill is smaller than the width of the preceding
spill", the information about scalar boundaries can still be preserved,"[""\nas long as it's coerced to the right width (done by coerce_reg_to_size).\nEven further"", ' if the actual value fits into the fill width', ' the ID can\nbe preserved as well for further tracking of equal scalars.\n\nImplement the above improvements', "" which makes narrowing fills behave the\nsame as narrowing spills and MOVs between registers.\n\nTwo tests are adjusted to accommodate for endianness differences and to\ntake into account that it's now allowed to do a narrowing fill from the\nleast significant bits.\n\nreg_bounds_sync is added to coerce_reg_to_size to correctly adjust\numin/umax boundaries after the var_off truncation"", ' for example', ' a 64-bit\nvalue 0xXXXXXXXX00000000', ' when read as a 32-bit', ' gets umin = 0', ' umax =\n0xFFFFFFFF', ' var_off = (0x0; 0xffffffff00000000)', ' which needs to be\nsynced down to umax = 0', "" otherwise reg_bounds_sanity_check doesn't pass.\n\nSigned-off-by: Maxim Mikityanskiy <maxim@isovalent.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240127175237.526726-4-maxtram95@gmail.com\n"", '']",This commit preserves boundaries and tracks scalars when narrowing fills in eBPF programs.,"preserve, boundaries, scalars",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6be503cec6c9bccd64f72c03697011d2e2b96fc3,6be503cec6c9bccd64f72c03697011d2e2b96fc3,Maxim Mikityanskiy,maxim@isovalent.com,1706377953,Andrii Nakryiko,andrii@kernel.org,1706908934,26368b72f39c3d9bc5236197f86cad5feb243f61,e67ddd9b1cff7872d43ead73a1403c4e532003d9,"selftests/bpf: Test tracking spilled unbounded scalars

The previous commit added tracking for unbounded scalars on spill. Add
the test case to check the new functionality.

Signed-off-by: Maxim Mikityanskiy <maxim@isovalent.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/bpf/20240127175237.526726-3-maxtram95@gmail.com
",,Add a test case to validate the functionality of tracking spilled unbounded scalars in selftests for BPF.,"test, unbounded scalars, selftests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e67ddd9b1cff7872d43ead73a1403c4e532003d9,e67ddd9b1cff7872d43ead73a1403c4e532003d9,Maxim Mikityanskiy,maxim@isovalent.com,1706377952,Andrii Nakryiko,andrii@kernel.org,1706908934,41bab4348d2c9d1a9a07548d2bbb3e44c6dcd444,943b043aeecce9accb6d367af47791c633e95e4d,"bpf: Track spilled unbounded scalars

Support the pattern where an unbounded scalar is spilled to the stack","
then boundary checks are performed on the src register","[' after which the\nstack frame slot is refilled into a register.\n\nBefore this commit', "" the verifier didn't treat the src register and the\nstack slot as related if the src register was an unbounded scalar. The\nregister state wasn't copied"", "" the id wasn't preserved"", "" and the stack\nslot was marked as STACK_MISC. Subsequent boundary checks on the src\nregister wouldn't result in updating the boundaries of the spilled\nvariable on the stack.\n\nAfter this commit"", ' the verifier will preserve the bond between src and\ndst even if src is unbounded', ' which permits to do boundary checks on src\nand refill dst later', ' still remembering its boundaries. Such a pattern\nis sometimes generated by clang when compiling complex long functions.\n\nOne test is adjusted to reflect that now unbounded scalars are tracked.\n\nSigned-off-by: Maxim Mikityanskiy <maxim@isovalent.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/bpf/20240127175237.526726-2-maxtram95@gmail.com\n', '']",The commit tracks spilled unbounded scalars to improve boundary checks for src registers in BPF programs.,"spilled, scalars, unbounded",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
943b043aeecce9accb6d367af47791c633e95e4d,943b043aeecce9accb6d367af47791c633e95e4d,Andrii Nakryiko,andrii@kernel.org,1706808027,Daniel Borkmann,daniel@iogearbox.net,1706822172,97a7fbc05a135c421de0685dceeb38ee74693da4,b9551da8cf3ade01a50316df8a618fd945723ee0,"selftests/bpf: Fix bench runner SIGSEGV

Some benchmarks don't have either ""consumer"" or ""producer"" sides. For
example"," trig-tp and other BPF triggering benchmarks don't have
consumers","[' as they only do ""producing"" by calling into syscall or\npredefined uproes. As such it\'s valid for some benchmarks to have zero\nconsumers or producers. So allows to specify `-c0` explicitly.\n\nThis triggers another problem. If benchmark doesn\'t support either\nconsumer or producer side', ' consumer_thread/producer_thread callback will\nbe NULL', ' but benchmark runner will attempt to use those NULL callback to\ncreate threads anyways. So instead of crashing with SIGSEGV in case of\nmisconfigured benchmark', ' detect the condition and report error.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/bpf/20240201172027.604869-6-andrii@kernel.org\n', '']",Fixes a segmentation fault in the selftests benchmark runner due to missing consumer or producer sides.,"selftests, benchmark, SIGSEGV",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tracepoints like programs']
b9551da8cf3ade01a50316df8a618fd945723ee0,b9551da8cf3ade01a50316df8a618fd945723ee0,Andrii Nakryiko,andrii@kernel.org,1706808026,Daniel Borkmann,daniel@iogearbox.net,1706822172,697abd705136a3f892e83bbe4f4d9041c774150c,c81a8ab196b5083d5109a51585fcc24fa2055a77,"libbpf: Add missed btf_ext__raw_data() API

Another API that was declared in libbpf.map but actual implementation
was missing. btf_ext__get_raw_data() was intended as a discouraged alias
to consistently-named btf_ext__raw_data()"," so make this an actuality.

Fixes: 20eccf29e297 (""libbpf: hide and discourage inconsistently named getters"")
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/bpf/20240201172027.604869-5-andrii@kernel.org
",[''],Add implementation of missing btf_ext__raw_data() API in libbpf.,"libbpf, API, implementation",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c81a8ab196b5083d5109a51585fcc24fa2055a77,c81a8ab196b5083d5109a51585fcc24fa2055a77,Andrii Nakryiko,andrii@kernel.org,1706808025,Daniel Borkmann,daniel@iogearbox.net,1706822172,79b7a7266067dcdca3d01e7d949050951533d069,93ee1eb85e28d1e35bb059c1f5965d65d5fc83c2,"libbpf: Add btf__new_split() API that was declared but not implemented

Seems like original commit adding split BTF support intended to add
btf__new_split() API", and even declared it in libbpf.map,"[' but never\nadded (trivial) implementation. Fix this.\n\nFixes: ba451366bf44 (""libbpf: Implement basic split BTF support"")\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/bpf/20240201172027.604869-4-andrii@kernel.org\n', '']",The commit implements the previously declared but unimplemented btf__new_split() API in libbpf.,libbpf BTF API,It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
93ee1eb85e28d1e35bb059c1f5965d65d5fc83c2,93ee1eb85e28d1e35bb059c1f5965d65d5fc83c2,Andrii Nakryiko,andrii@kernel.org,1706808024,Daniel Borkmann,daniel@iogearbox.net,1706822171,42db78e843ce7af0251e565fd25d91004d7b49e3,9fa5e1a180aa639fb156a16e453ab820b7e7860b,"libbpf: Add missing LIBBPF_API annotation to libbpf_set_memlock_rlim API

LIBBPF_API annotation seems missing on libbpf_set_memlock_rlim API"," so
add it to make this API callable from libbpf's shared library version.

Fixes: e542f2c4cd16 (""libbpf: Auto-bump RLIMIT_MEMLOCK if kernel needs it for BPF"")
Fixes: ab9a5a05dc48 (""libbpf: fix up few libbpf.map problems"")
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/bpf/20240201172027.604869-3-andrii@kernel.org
",[''],Add missing LIBBPF_API annotation to libbpf_set_memlock_rlim for shared library usage.,"LIBBPF_API, libbpf, memlock",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9fa5e1a180aa639fb156a16e453ab820b7e7860b,9fa5e1a180aa639fb156a16e453ab820b7e7860b,Andrii Nakryiko,andrii@kernel.org,1706808023,Daniel Borkmann,daniel@iogearbox.net,1706822171,31cb7e6da88097ca1880c6a8776ee4e56b4e469b,1581e5118e485e82cfb5d04d636a79aaefb6f266,"libbpf: Call memfd_create() syscall directly

Some versions of Android do not implement memfd_create() wrapper in
their libc implementation"," leading to build failures ([0]). On the other
hand","[' memfd_create() is available as a syscall on quite old kernels\n(3.17+', ' while bpf() syscall itself is available since 3.18+)', "" so it is\nok to assume that syscall availability and call into it with syscall()\nhelper to avoid Android-specific workarounds.\n\nValidated in libbpf-bootstrap's CI ([1]).\n\n  [0] https://github.com/libbpf/libbpf-bootstrap/actions/runs/7701003207/job/20986080319#step:5:83\n  [1] https://github.com/libbpf/libbpf-bootstrap/actions/runs/7715988887/job/21031767212?pr=253\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/bpf/20240201172027.604869-2-andrii@kernel.org\n"", '']",This commit modifies libbpf to call the memfd_create syscall directly to avoid build issues on some Android platforms.,"libbpf, memfd_create, Android",It's a build system or CI/CD change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"[""It's not related to any of the above.""]"
5c24e4e9e70822cf49955fc8174bc5efaa93d17f,5c24e4e9e70822cf49955fc8174bc5efaa93d17f,Linus Torvalds,torvalds@linux-foundation.org,1706811574,Linus Torvalds,torvalds@linux-foundation.org,1706811574,a793614a9f5bde6302d84c932d36887d530ad14b,f6cdd897cc7030a573f56ab1e9ebaece26c7c10c 764ad6b02777d77dca3659ca490f0898aa593670,"Merge tag 'hid-for-linus-2024020101' of git://git.kernel.org/pub/scm/linux/kernel/git/hid/hid

Pull HID fixes from Benjamin Tissoires:

 - cleanups in the error path in hid-steam (Dan Carpenter)

 - fixes for Wacom tablets selftests that sneaked in while the CI was
   taking a break during the year end holidays (Benjamin Tissoires)

 - null pointer check in nvidia-shield (Kunwu Chan)

 - memory leak fix in hidraw (Su Hui)

 - another null pointer fix in i2c-hid-of (Johan Hovold)

 - another memory leak fix in HID-BPF this time"," as well as a double
   fdget() fix reported by Dan Carpenter (Benjamin Tissoires)

 - fix for Cirque touchpad when they go on suspend (Kai-Heng Feng)

 - new device ID in hid-logitech-hidpp: ""Logitech G Pro X SuperLight 2""
   (Jiri Kosina)

* tag 'hid-for-linus-2024020101' of git://git.kernel.org/pub/scm/linux/kernel/git/hid/hid:
  HID: bpf: use __bpf_kfunc instead of noinline
  HID: bpf: actually free hdev memory after attaching a HID-BPF program
  HID: bpf: remove double fdget()
  HID: i2c-hid-of: fix NULL-deref on failed power up
  HID: hidraw: fix a problem of memory leak in hidraw_release()
  HID: i2c-hid: Skip SET_POWER SLEEP for Cirque touchpad on system suspend
  HID: nvidia-shield: Add missing null pointer checks to LED initialization
  HID: logitech-hidpp: add support for Logitech G Pro X Superlight 2
  selftests/hid: wacom: fix confidence tests
  HID: hid-steam: Fix cleanup in probe()
  HID: hid-steam: remove pointless error message
",[''],This commit merges HID fixes including memory leak and null pointer checks for various devices.,"HID, fixes, memory",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['HID driver like programs']
1581e5118e485e82cfb5d04d636a79aaefb6f266,1581e5118e485e82cfb5d04d636a79aaefb6f266,Matt Bobrowski,mattbobrowski@google.com,1706784220,Daniel Borkmann,daniel@iogearbox.net,1706809065,977ae9fe3c50e0a68463195acf4b0835c7a15419,994ff2f7973982af286608da10c295383650fc28,"bpf: Minor clean-up to sleepable_lsm_hooks BTF set

There's already one main CONFIG_SECURITY_NETWORK ifdef block within
the sleepable_lsm_hooks BTF set. Consolidate this duplicated ifdef
block as there's no need for it and all things guarded by it should
remain in one place in this specific context.

Signed-off-by: Matt Bobrowski <mattbobrowski@google.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/Zbt1smz43GDMbVU3@google.com
",,Consolidate duplicated ifdef blocks in sleepable_lsm_hooks BTF set for cleaner code structure.,"clean-up, ifdef, BTF",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),['LSM like programs']
e0526ec5360a48ad3ab2e26e802b0532302a7e11,e0526ec5360a48ad3ab2e26e802b0532302a7e11,Souradeep Chakrabarti,schakrabarti@linux.microsoft.com,1706686551,Jakub Kicinski,kuba@kernel.org,1706805223,0e9d7ebabe6893cdaad90907275584cbf84cc83c,7b55984c96ffe9e236eb9c82a2196e0b1f84990d,"hv_netvsc: Fix race condition between netvsc_probe and netvsc_remove

In commit ac5047671758 (""hv_netvsc: Disable NAPI before closing the
VMBus channel"")", napi_disable was getting called for all channels,"['\nincluding all subchannels without confirming if they are enabled or not.\n\nThis caused hv_netvsc getting hung at napi_disable', ' when netvsc_probe()\nhas finished running but nvdev->subchan_work has not started yet.\nnetvsc_subchan_work() -> rndis_set_subchannel() has not created the\nsub-channels and because of that netvsc_sc_open() is not running.\nnetvsc_remove() calls cancel_work_sync(&nvdev->subchan_work)', ' for which\nnetvsc_subchan_work did not run.\n\nnetif_napi_add() sets the bit NAPI_STATE_SCHED because it ensures NAPI\ncannot be scheduled. Then netvsc_sc_open() -> napi_enable will clear the\nNAPIF_STATE_SCHED bit', ' so it can be scheduled. napi_disable() does the\nopposite.\n\nNow during netvsc_device_remove()', ' when napi_disable is called for those\nsubchannels', ' napi_disable gets stuck on infinite msleep.\n\nThis fix addresses this problem by ensuring that napi_disable() is not\ngetting called for non-enabled NAPI struct.\nBut netif_napi_del() is still necessary for these non-enabled NAPI struct\nfor cleanup purpose.\n\nCall trace:\n[  654.559417] task:modprobe        state:D stack:    0 pid: 2321 ppid:  1091 flags:0x00004002\n[  654.568030] Call Trace:\n[  654.571221]  <TASK>\n[  654.573790]  __schedule+0x2d6/0x960\n[  654.577733]  schedule+0x69/0xf0\n[  654.581214]  schedule_timeout+0x87/0x140\n[  654.585463]  ? __bpf_trace_tick_stop+0x20/0x20\n[  654.590291]  msleep+0x2d/0x40\n[  654.593625]  napi_disable+0x2b/0x80\n[  654.597437]  netvsc_device_remove+0x8a/0x1f0 [hv_netvsc]\n[  654.603935]  rndis_filter_device_remove+0x194/0x1c0 [hv_netvsc]\n[  654.611101]  ? do_wait_intr+0xb0/0xb0\n[  654.615753]  netvsc_remove+0x7c/0x120 [hv_netvsc]\n[  654.621675]  vmbus_remove+0x27/0x40 [hv_vmbus]\n\nCc: stable@vger.kernel.org\nFixes: ac5047671758 (""hv_netvsc: Disable NAPI before closing the VMBus channel"")\nSigned-off-by: Souradeep Chakrabarti <schakrabarti@linux.microsoft.com>\nReviewed-by: Dexuan Cui <decui@microsoft.com>\nReviewed-by: Haiyang Zhang <haiyangz@microsoft.com>\nReviewed-by: Simon Horman <horms@kernel.org>\nLink: https://lore.kernel.org/r/1706686551-28510-1-git-send-email-schakrabarti@linux.microsoft.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Fixes a race condition between netvsc_probe and netvsc_remove in hv_netvsc driver.,"hv_netvsc,race condition,probe",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
6a9d552483d50953320b9d3b57abdee8d436f23f,6a9d552483d50953320b9d3b57abdee8d436f23f,Sean Young,sean@mess.org,1681375832,Mauro Carvalho Chehab,mchehab@kernel.org,1706791737,fae8ab584d5b37806ceccaef3b6205dd53fcfb9b,f66556c1333b3bd4806fc98ee07c419ab545e6ee,"media: rc: bpf attach/detach requires write permission

Note that bpf attach/detach also requires CAP_NET_ADMIN.

Cc: stable@vger.kernel.org
Signed-off-by: Sean Young <sean@mess.org>
Signed-off-by: Mauro Carvalho Chehab <mchehab@kernel.org>
",,The commit requires write permission for bpf attach/detach operations in media rc subsystem.,"bpf,attach,permission",It's a security fix.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['other']
994ff2f7973982af286608da10c295383650fc28,994ff2f7973982af286608da10c295383650fc28,Pu Lehui,pulehui@huawei.com,1706618819,Daniel Borkmann,daniel@iogearbox.net,1706783748,71e4c406e87719866e5e9e1163654267fd28feaa,69065aa11ca680d76a6c6bc088aa0f0abe24afdb,"selftests/bpf: Enable inline bpf_kptr_xchg() test for RV64

Enable inline bpf_kptr_xchg() test for RV64"," and the test have passed as
show below:

Summary: 1/0 PASSED","[' 0 SKIPPED', ' 0 FAILED\n\nSigned-off-by: Pu Lehui <pulehui@huawei.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Björn Töpel <bjorn@kernel.org>\nLink: https://lore.kernel.org/bpf/20240130124659.670321-3-pulehui@huaweicloud.com\n', '']",Enable inline bpf_kptr_xchg() test for RV64 architecture in selftests.,bpf_kptr_xchg RV64 selftests,It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
69065aa11ca680d76a6c6bc088aa0f0abe24afdb,69065aa11ca680d76a6c6bc088aa0f0abe24afdb,Pu Lehui,pulehui@huawei.com,1706618818,Daniel Borkmann,daniel@iogearbox.net,1706783748,0228b8ec5043cee4077500406119b3c0aa777d7a,088a464ed53feeab9632c6748b9f25354639e2bd,riscv," bpf: Enable inline bpf_kptr_xchg() for RV64

RV64 JIT supports 64-bit BPF_XCHG atomic instructions. At the same time","[""\nthe underlying implementation of xchg() and atomic64_xchg() in RV64 both\nare raw_xchg() that supported 64-bit. Therefore inline bpf_kptr_xchg()\nwill have equivalent semantics. Let's inline it for better performance.\n\nSigned-off-by: Pu Lehui <pulehui@huawei.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Björn Töpel <bjorn@kernel.org>\nLink: https://lore.kernel.org/bpf/20240130124659.670321-2-pulehui@huaweicloud.com\n"", '']",Enable inline bpf_kptr_xchg() support for RV64 JIT with 64-bit atomic instructions.,"RV64,JIT,BPF_XCHG",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
088a464ed53feeab9632c6748b9f25354639e2bd,088a464ed53feeab9632c6748b9f25354639e2bd,Dave Thaler,dthaler1968@googlemail.com,1706672279,Daniel Borkmann,daniel@iogearbox.net,1706783533,a2956e5c82064fc3d1a2c0f1be58490c27d0c0db,8263b3382d8c1af0fffa27095a9f1db6f2dad899,bpf," docs: Clarify which legacy packet instructions existed

As discussed on the BPF IETF mailing list (see link)","[' this patch updates\nthe ""Legacy BPF Packet access instructions"" section to clarify which\ninstructions are deprecated (vs which were never defined and so are not\ndeprecated).\n\nSigned-off-by: Dave Thaler <dthaler1968@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nAcked-by: David Vernet <void@manifault.com>\nLink: https://mailarchive.ietf.org/arch/msg/bpf/5LnnKm093cGpOmDI9TnLQLBXyys\nLink: https://lore.kernel.org/bpf/20240131033759.3634-1-dthaler1968@gmail.com\n', '']",The commit clarifies documentation regarding legacy packet instructions discussed on the BPF IETF mailing list.,"docs, packet, instructions",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),"[""It's not related to any of the above.""]"
8263b3382d8c1af0fffa27095a9f1db6f2dad899,8263b3382d8c1af0fffa27095a9f1db6f2dad899,Eduard Zingerman,eddyz87@gmail.com,1706736375,Daniel Borkmann,daniel@iogearbox.net,1706782425,aaf52c8edacd92fe52eea3edc723ebc760ecc6ee,b3d3e29376a3f898bc90063a1e8c36c76cea1901,"libbpf: Remove unnecessary null check in kernel_supports()

After recent changes"," Coverity complained about inconsistent null checks
in kernel_supports() function:

    kernel_supports(const struct bpf_object *obj","[' ...)\n    [...]\n    // var_compare_op: Comparing obj to null implies that obj might be null\n    if (obj && obj->gen_loader)\n        return true;\n\n    // var_deref_op: Dereferencing null pointer obj\n    if (obj->token_fd)\n        return feat_supported(obj->feat_cache', ' feat_id);\n    [...]\n\n- The original null check was introduced by commit [0]', ' which introduced\n  a call `kernel_supports(NULL', ' ...)` in function bump_rlimit_memlock();\n- This call was refactored to use `feat_supported(NULL', ' ...)` in commit [1].\n\nLooking at all places where kernel_supports() is called:\n\n- There is either `obj->...` access before the call;\n- Or `obj` comes from `prog->obj` expression', ' where `prog` comes from\n  enumeration of programs in `obj`;\n- Or `obj` comes from `prog->obj`', ' where `prog` is a parameter to one\n  of the API functions:\n  - bpf_program__attach_kprobe_opts;\n  - bpf_program__attach_kprobe;\n  - bpf_program__attach_ksyscall.\n\nAssuming correct API usage', ' it appears that `obj` can never be null when\npassed to kernel_supports(). Silence the Coverity warning by removing\nredundant null check.\n\n  [0] e542f2c4cd16 (""libbpf: Auto-bump RLIMIT_MEMLOCK if kernel needs it for BPF"")\n  [1] d6dd1d49367a (""libbpf: Further decouple feature checking logic from bpf_object"")\n\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240131212615.20112-1-eddyz87@gmail.com\n', '']",This commit removes an unnecessary null check in the kernel_supports() function in libbpf.,"null check, libbpf, kernel_supports",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b3d3e29376a3f898bc90063a1e8c36c76cea1901,b3d3e29376a3f898bc90063a1e8c36c76cea1901,Alexei Starovoitov,ast@kernel.org,1706731524,Alexei Starovoitov,ast@kernel.org,1706762456,fd932c0339367596adb67fd652849506971fda3f,2ef61296d2844c6a4211e07ab70ef2fb412b2c30 6f3189f38a3e995232e028a4c341164c4aca1b20,"Merge branch 'annotate-kfuncs-in-btf_ids-section'

Daniel Xu says:

====================
Annotate kfuncs in .BTF_ids section

=== Description ===

This is a bpf-treewide change that annotates all kfuncs as such inside
.BTF_ids. This annotation eventually allows us to automatically generate
kfunc prototypes from bpftool.

We store this metadata inside a yet-unused flags field inside struct
btf_id_set8 (thanks Kumar!). pahole will be taught where to look.

More details about the full chain of events are available in commit 3's
description.

The accompanying pahole and bpftool changes can be viewed
here on these ""frozen"" branches [0][1].

[0]: https://github.com/danobi/pahole/tree/kfunc_btf-v3-mailed
[1]: https://github.com/danobi/linux/tree/kfunc_bpftool-mailed

=== Changelog ===

Changes from v3:
* Rebase to bpf-next and add missing annotation on new kfunc

Changes from v2:
* Only WARN() for vmlinux kfuncs

Changes from v1:
* Move WARN_ON() up a call level
* Also return error when kfunc set is not properly tagged
* Use BTF_KFUNCS_START/END instead of flags
* Rename BTF_SET8_KFUNC to BTF_SET8_KFUNCS
====================

Acked-by: Jiri Olsa <jolsa@kernel.org>
Link: https://lore.kernel.org/r/cover.1706491398.git.dxu@dxuuu.xyz
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,This commit annotates kfuncs in the .BTF_ids section for automatic kfunc prototype generation with bpftool.,"kfuncs,BTF_ids,bpftool",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6f3189f38a3e995232e028a4c341164c4aca1b20,6f3189f38a3e995232e028a4c341164c4aca1b20,Daniel Xu,dxu@dxuuu.xyz,1706491448,Alexei Starovoitov,ast@kernel.org,1706762456,fd932c0339367596adb67fd652849506971fda3f,a05e90427ef6706f59188b379ad6366b9d298bc5,"bpf: treewide: Annotate BPF kfuncs in BTF

This commit marks kfuncs as such inside the .BTF_ids section. The upshot
of these annotations is that we'll be able to automatically generate
kfunc prototypes for downstream users. The process is as follows:

1. In source"," use BTF_KFUNCS_START/END macro pair to mark kfuncs
2. During build","[' pahole injects into BTF a ""bpf_kfunc"" BTF_DECL_TAG for\n   each function inside BTF_KFUNCS sets\n3. At runtime', ' vmlinux or module BTF is made available in sysfs\n4. At runtime', ' bpftool (or similar) can look at provided BTF and\n   generate appropriate prototypes for functions with ""bpf_kfunc"" tag\n\nTo ensure future kfunc are similarly tagged', ' we now also return error\ninside kfunc registration for untagged kfuncs. For vmlinux kfuncs', '\nwe also WARN()', ' as initcall machinery does not handle errors.\n\nSigned-off-by: Daniel Xu <dxu@dxuuu.xyz>\nAcked-by: Benjamin Tissoires <bentiss@kernel.org>\nLink: https://lore.kernel.org/r/e55150ceecbf0a5d961e608941165c0bee7bc943.1706491398.git.dxu@dxuuu.xyz\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Annotate BPF kfuncs in BTF to enable automatic kfunc prototype generation for downstream users.,"kfuncs,BTF,annotations",It's a documentation change or typo fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a05e90427ef6706f59188b379ad6366b9d298bc5,a05e90427ef6706f59188b379ad6366b9d298bc5,Daniel Xu,dxu@dxuuu.xyz,1706491447,Alexei Starovoitov,ast@kernel.org,1706762452,5bafea12fa3f4e5bdf0d08a0db79cf73fc0c9de5,79b47344bbc5a693a92ed6b2b09dac59254bfac8,"bpf: btf: Add BTF_KFUNCS_START/END macro pair

This macro pair is functionally equivalent to BTF_SET8_START/END"," except
with BTF_SET8_KFUNCS flag set in the btf_id_set8 flags field. The next
commit will codemod all kfunc set8s to this new variant such that all
kfuncs are tagged as such in .BTF_ids section.

Signed-off-by: Daniel Xu <dxu@dxuuu.xyz>
Link: https://lore.kernel.org/r/d536c57c7c2af428686853cc7396b7a44faa53b7.1706491398.git.dxu@dxuuu.xyz
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Add BTF_KFUNCS_START/END macro pair for improved kfunc tagging in BTF_ids section.,"BTF,KFUNCS,macro",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
79b47344bbc5a693a92ed6b2b09dac59254bfac8,79b47344bbc5a693a92ed6b2b09dac59254bfac8,Daniel Xu,dxu@dxuuu.xyz,1706491446,Alexei Starovoitov,ast@kernel.org,1706731524,e4c178e4c0ba6bed66b699a815c7289301b21b37,2ef61296d2844c6a4211e07ab70ef2fb412b2c30,"bpf: btf: Support flags for BTF_SET8 sets

This commit adds support for flags on BTF_SET8s. struct btf_id_set8
already supported 32 bits worth of flags"," but was only used for
alignment purposes before.

We now use these bits to encode flags. The first use case is tagging
kfunc sets with a flag so that pahole can recognize which
BTF_ID_FLAGS(func","[' ..) are actual kfuncs.\n\nSigned-off-by: Daniel Xu <dxu@dxuuu.xyz>\nLink: https://lore.kernel.org/r/7bb152ec76d6c2c930daec88e995bf18484a5ebb.1706491398.git.dxu@dxuuu.xyz\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']","Adds support for flags in BTF_SET8 structures, enabling flag tagging for kfunc sets.","BTF_SET8, flags, kfunc",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2ef61296d2844c6a4211e07ab70ef2fb412b2c30,2ef61296d2844c6a4211e07ab70ef2fb412b2c30,Manu Bretelle,chantr4@gmail.com,1706679132,Andrii Nakryiko,andrii@kernel.org,1706721243,2f93f0305f24453b2d94f48f3e6100207723818a,e4009250574c69d2a3dd838af81cc3d4d72058e4,"selftests/bpf: Disable IPv6 for lwt_redirect test

After a recent change in the vmtest runner"," this test started failing
sporadically.

Investigation showed that this test was subject to race condition which
got exacerbated after the vm runner change. The symptoms being that the
logic that waited for an ICMPv4 packet is naive and will break if 5 or
more non-ICMPv4 packets make it to tap0.
When ICMPv6 is enabled","[' the kernel will generate traffic such as ICMPv6\nrouter solicitation...\nOn a system with good performance', ' the expected ICMPv4 packet would very\nlikely make it to the network interface promptly', ' but on a system with\npoor performance', ' those ""guarantees"" do not hold true anymore.\n\nGiven that the test is IPv4 only', ' this change disable IPv6 in the test\nnetns by setting `net.ipv6.conf.all.disable_ipv6` to 1.\nThis essentially leaves ""ping"" as the sole generator of traffic in the\nnetwork namespace.\nIf this test was to be made IPv6 compatible', ' the logic in\n`wait_for_packet` would need to be modified.\n\nIn more details...\n\nAt a high level', ' the test does:\n- create a new namespace\n- in `setup_redirect_target` set up lo', ' tap0', ' and link_err interfaces as\n  well as add 2 routes that attaches ingress/egress sections of\n  `test_lwt_redirect.bpf.o` to the xmit path.\n- in `send_and_capture_test_packets` send an ICMP packet and read off\n  the tap interface (using `wait_for_packet`) to check that a ICMP packet\n  with the right size is read.\n\n`wait_for_packet` will try to read `max_retry` (5) times from the tap0\nfd looking for an ICMPv4 packet matching some criteria.\n\nThe problem is that when we set up the `tap0` interface', ' because IPv6 is\nenabled by default', ' traffic such as Router solicitation is sent through\ntap0', ' as in:\n\n  # tcpdump -r /tmp/lwt_redirect.pc\n  reading from file /tmp/lwt_redirect.pcap', ' link-type EN10MB (Ethernet)\n  04:46:23.578352 IP6 :: > ff02::1:ffc0:4427: ICMP6', ' neighbor solicitation', ' who has fe80::fcba:dff:fec0:4427', ' length 32\n  04:46:23.659522 IP6 :: > ff02::16: HBH ICMP6', ' multicast listener report v2', ' 1 group record(s)', ' length 28\n  04:46:24.389169 IP 10.0.0.1 > 20.0.0.9: ICMP echo request', ' id 122', ' seq 1', ' length 108\n  04:46:24.618599 IP6 fe80::fcba:dff:fec0:4427 > ff02::16: HBH ICMP6', ' multicast listener report v2', ' 1 group record(s)', ' length 28\n  04:46:24.619985 IP6 fe80::fcba:dff:fec0:4427 > ff02::2: ICMP6', ' router solicitation', ' length 16\n  04:46:24.767326 IP6 fe80::fcba:dff:fec0:4427 > ff02::16: HBH ICMP6', ' multicast listener report v2', ' 1 group record(s)', ' length 28\n  04:46:28.936402 IP6 fe80::fcba:dff:fec0:4427 > ff02::2: ICMP6', ' router solicitation', ' length 16\n\nIf `wait_for_packet` sees 5 non-ICMPv4 packets', ' it will return 0', ' which is what we see in:\n\n  2024-01-31T03:51:25.0336992Z test_lwt_redirect_run:PASS:netns_create 0 nsec\n  2024-01-31T03:51:25.0341309Z open_netns:PASS:malloc token 0 nsec\n  2024-01-31T03:51:25.0344844Z open_netns:PASS:open /proc/self/ns/net 0 nsec\n  2024-01-31T03:51:25.0350071Z open_netns:PASS:open netns fd 0 nsec\n  2024-01-31T03:51:25.0353516Z open_netns:PASS:setns 0 nsec\n  2024-01-31T03:51:25.0356560Z test_lwt_redirect_run:PASS:setns 0 nsec\n  2024-01-31T03:51:25.0360140Z open_tuntap:PASS:open(/dev/net/tun) 0 nsec\n  2024-01-31T03:51:25.0363822Z open_tuntap:PASS:ioctl(TUNSETIFF) 0 nsec\n  2024-01-31T03:51:25.0367402Z open_tuntap:PASS:fcntl(O_NONBLOCK) 0 nsec\n  2024-01-31T03:51:25.0371167Z setup_redirect_target:PASS:open_tuntap 0 nsec\n  2024-01-31T03:51:25.0375180Z setup_redirect_target:PASS:if_nametoindex 0 nsec\n  2024-01-31T03:51:25.0379929Z setup_redirect_target:PASS:ip link add link_err type dummy 0 nsec\n  2024-01-31T03:51:25.0384874Z setup_redirect_target:PASS:ip link set lo up 0 nsec\n  2024-01-31T03:51:25.0389678Z setup_redirect_target:PASS:ip addr add dev lo 10.0.0.1/32 0 nsec\n  2024-01-31T03:51:25.0394814Z setup_redirect_target:PASS:ip link set link_err up 0 nsec\n  2024-01-31T03:51:25.0399874Z setup_redirect_target:PASS:ip link set tap0 up 0 nsec\n  2024-01-31T03:51:25.0407731Z setup_redirect_target:PASS:ip route add 10.0.0.0/24 dev link_err encap bpf xmit obj test_lwt_redirect.bpf.o sec redir_ingress 0 nsec\n  2024-01-31T03:51:25.0419105Z setup_redirect_target:PASS:ip route add 20.0.0.0/24 dev link_err encap bpf xmit obj test_lwt_redirect.bpf.o sec redir_egress 0 nsec\n  2024-01-31T03:51:25.0427209Z test_lwt_redirect_normal:PASS:setup_redirect_target 0 nsec\n  2024-01-31T03:51:25.0431424Z ping_dev:PASS:if_nametoindex 0 nsec\n  2024-01-31T03:51:25.0437222Z send_and_capture_test_packets:FAIL:wait_for_epacket unexpected wait_for_epacket: actual 0 != expected 1\n  2024-01-31T03:51:25.0448298Z (/tmp/work/bpf/bpf/tools/testing/selftests/bpf/prog_tests/lwt_redirect.c:175: errno: Success) test_lwt_redirect_normal egress test fails\n  2024-01-31T03:51:25.0457124Z close_netns:PASS:setns 0 nsec\n\nWhen running in a VM which potential resource contrains', ' the odds that calling\n`ping` is not scheduled very soon after bringing `tap0` up increases', '\nand with this the chances to get our ICMP packet pushed to position 6+\nin the network trace.\n\nTo confirm this indeed solves the issue', ' I ran the test 100 times in a\nrow with:\n\n  errors=0\n  successes=0\n  for i in `seq 1 100`\n  do\n    ./test_progs -t lwt_redirect/lwt_redirect_normal\n    if [ $? -eq 0 ]; then\n      successes=$((successes+1))\n    else\n      errors=$((errors+1))\n    fi\n  done\n  echo ""successes: $successes/errors: $errors""\n\nWhile this test would at least fail a couple of time every 10 runs', ' here\nit ran 100 times with no error.\n\nFixes: 43a7c3ef8a15 (""selftests/bpf: Add lwt_xmit tests for BPF_REDIRECT"")\nSigned-off-by: Manu Bretelle <chantr4@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240131053212.2247527-1-chantr4@gmail.com\n', '']",Disable IPv6 in lwt_redirect test due to race conditions causing sporadic failures.,"selftests, IPv6, race condition",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
764ad6b02777d77dca3659ca490f0898aa593670,764ad6b02777d77dca3659ca490f0898aa593670,Benjamin Tissoires,bentiss@kernel.org,1706095619,Benjamin Tissoires,bentiss@kernel.org,1706693228,0e42f1b4a2b6c57fec946137e316371f90a3e69d,89be8aa5b0ecb3b729c7bcff64bb2af7921fec63,"HID: bpf: use __bpf_kfunc instead of noinline

Follow the docs at Documentation/bpf/kfuncs.rst:
- declare the function with `__bpf_kfunc`
- disables missing prototype warnings"," which allows to remove them from
  include/linux/hid-bpf.h

Removing the prototypes is not an issue because we currently have to
redeclare them when writing the BPF program. They will eventually be
generated by bpftool directly AFAIU.

Link: https://lore.kernel.org/r/20240124-b4-hid-bpf-fixes-v2-3-052520b1e5e6@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],The commit replaces noinline with __bpf_kfunc for HID related BPF functions to align with documentation and streamline prototype handling.,"HID, __bpf_kfunc, prototype",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,['HID driver like programs']
89be8aa5b0ecb3b729c7bcff64bb2af7921fec63,89be8aa5b0ecb3b729c7bcff64bb2af7921fec63,Benjamin Tissoires,bentiss@kernel.org,1706095618,Benjamin Tissoires,bentiss@kernel.org,1706693225,b1a6d7ede14188df09992669cbfda5f6eaea0c5b,7cdd2108903a4e369eb37579830afc12a6877ec2,"HID: bpf: actually free hdev memory after attaching a HID-BPF program

Turns out that I got my reference counts wrong and each successful
bus_find_device() actually calls get_device()"," and we need to manually
call put_device().

Ensure each bus_find_device() gets a matching put_device() when releasing
the bpf programs and fix all the error paths.

Cc: <stable@vger.kernel.org>
Fixes: f5c27da4e3c8 (""HID: initial BPF implementation"")
Link: https://lore.kernel.org/r/20240124-b4-hid-bpf-fixes-v2-2-052520b1e5e6@kernel.org
Signed-off-by: Benjamin Tissoires <bentiss@kernel.org>
",[''],Fixes memory leak by ensuring each bus_find_device() call is matched with a put_device() call in HID-BPF implementation.,"memory, HID-BPF, bus_find_device",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['HID driver like programs']
7cdd2108903a4e369eb37579830afc12a6877ec2,7cdd2108903a4e369eb37579830afc12a6877ec2,Benjamin Tissoires,bentiss@kernel.org,1706095617,Benjamin Tissoires,bentiss@kernel.org,1706693220,53d7b58e90273e85e237500a2b887a18497d6c5d,00aab7dcb2267f2aef59447602f34501efe1a07f,"HID: bpf: remove double fdget()

When the kfunc hid_bpf_attach_prog() is called"," we called twice fdget():
one for fetching the type of the bpf program","[' and one for actually\nattaching the program to the device.\n\nThe problem is that between those two calls', ' we have no guarantees that\nthe prog_fd is still the same file descriptor for the given program.\n\nSolve this by calling bpf_prog_get() earlier', ' and use this to fetch the\nprogram type.\n\nReported-by: Dan Carpenter <dan.carpenter@linaro.org>\nLink: https://lore.kernel.org/bpf/CAO-hwJJ8vh8JD3-P43L-_CLNmPx0hWj44aom0O838vfP4=_1CA@mail.gmail.com/T/#t\nCc: <stable@vger.kernel.org>\nFixes: f5c27da4e3c8 (""HID: initial BPF implementation"")\nLink: https://lore.kernel.org/r/20240124-b4-hid-bpf-fixes-v2-1-052520b1e5e6@kernel.org\nSigned-off-by: Benjamin Tissoires <bentiss@kernel.org>\n', '']",Removed redundant fdget() call in hid_bpf_attach_prog() function.,"HID,bpf,fdget",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,['HID driver like programs']
e4009250574c69d2a3dd838af81cc3d4d72058e4,e4009250574c69d2a3dd838af81cc3d4d72058e4,Martin KaFai Lau,martin.lau@kernel.org,1706658950,Martin KaFai Lau,martin.lau@kernel.org,1706658959,a894b1c60e0bfa06e3acb82179271039dbedd3e3,4d8ebe1304e99cf6e08e432c23041638d6d1de56 ea9d561686fbd0e1ddf05d861d8f2c1ae8291870,"Merge branch 'libbpf: add bpf_core_cast() helper'

Andrii Nakryiko says:

====================
Add bpf_core_cast(<ptr>"," <type>) macro wrapper around bpf_rdonly_cast() kfunc
to make it easier to use this functionality in BPF code. See patch #2 for
BPF selftests conversions demonstrating improvements in code succinctness.
====================

Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Add bpf_core_cast() macro in libbpf to simplify usage of bpf_rdonly_cast() in BPF code.,"bpf_core_cast,libbpf,bpf_rdonly_cast",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ea9d561686fbd0e1ddf05d861d8f2c1ae8291870,ea9d561686fbd0e1ddf05d861d8f2c1ae8291870,Andrii Nakryiko,andrii@kernel.org,1706649623,Martin KaFai Lau,martin.lau@kernel.org,1706658950,a894b1c60e0bfa06e3acb82179271039dbedd3e3,20d59ee55172fdf6072abf871fa62b2070d6383f,"selftests/bpf: convert bpf_rdonly_cast() uses to bpf_core_cast() macro

Use more ergonomic bpf_core_cast() macro instead of bpf_rdonly_cast() in
selftests code.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240130212023.183765-3-andrii@kernel.org
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,The commit updates selftests to use bpf_core_cast() instead of bpf_rdonly_cast() for better ergonomics.,"bpf_core_cast,selftests,ergonomic",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
20d59ee55172fdf6072abf871fa62b2070d6383f,20d59ee55172fdf6072abf871fa62b2070d6383f,Andrii Nakryiko,andrii@kernel.org,1706649622,Martin KaFai Lau,martin.lau@kernel.org,1706658950,943d0e21220a3f83781da27546c470cbd56f71cf,4d8ebe1304e99cf6e08e432c23041638d6d1de56,"libbpf: add bpf_core_cast() macro

Add bpf_core_cast() macro that wraps bpf_rdonly_cast() kfunc. It's more
ergonomic than kfunc"," as it automatically extracts btf_id with
bpf_core_type_id_kernel()","[' and works with type names. It also casts result\nto (T *) pointer. See the definition of the macro', "" it's self-explanatory.\n\nlibbpf declares bpf_rdonly_cast() extern as __weak __ksym and should be\nsafe to not conflict with other possible declarations in user code.\n\nBut we do have a conflict with current BPF selftests that declare their\nexterns with first argument as `void *obj`"", ' while libbpf opts into more\npermissive `const void *obj`. This causes conflict', ' so we fix up BPF\nselftests uses in the same patch.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240130212023.183765-2-andrii@kernel.org\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Introduces bpf_core_cast() macro to enhance usability by wrapping bpf_rdonly_cast() kfunc in libbpf.,"bpf_core_cast, ergonomic, libbpf",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4207b556e62f0a8915afc5da4c5d5ad915a253a5,4207b556e62f0a8915afc5da4c5d5ad915a253a5,Tejun Heo,tj@kernel.org,1704836884,Greg Kroah-Hartman,gregkh@linuxfoundation.org,1706658865,ee2acfd9720b3ed444d539954ba55447e6808aa4,1c9f2c7606afe149800986182638f636646dd824,"kernfs: RCU protect kernfs_nodes and avoid kernfs_idr_lock in kernfs_find_and_get_node_by_id()

The BPF helper bpf_cgroup_from_id() calls kernfs_find_and_get_node_by_id()
which acquires kernfs_idr_lock"," which is an non-raw non-IRQ-safe lock. This
can lead to deadlocks as bpf_cgroup_from_id() can be called from any BPF
programs including e.g. the ones that attach to functions which are holding
the scheduler rq lock.

Consider the following BPF program:

  SEC(""fentry/__set_cpus_allowed_ptr_locked"")
  int BPF_PROG(__set_cpus_allowed_ptr_locked","[' struct task_struct *p', '\n\t       struct affinity_context *affn_ctx', ' struct rq *rq', ' struct rq_flags *rf)\n  {\n\t  struct cgroup *cgrp = bpf_cgroup_from_id(p->cgroups->dfl_cgrp->kn->id);\n\n\t  if (cgrp) {\n\t\t  bpf_printk(""%d[%s] in %s""', ' p->pid', ' p->comm', ' cgrp->kn->name);\n\t\t  bpf_cgroup_release(cgrp);\n\t  }\n\t  return 0;\n  }\n\n__set_cpus_allowed_ptr_locked() is called with rq lock held and the above\nBPF program calls bpf_cgroup_from_id() within leading to the following\nlockdep warning:\n\n  =====================================================\n  WARNING: HARDIRQ-safe -> HARDIRQ-unsafe lock order detected\n  6.7.0-rc3-work-00053-g07124366a1d7-dirty #147 Not tainted\n  -----------------------------------------------------\n  repro/1620 [HC0[0]:SC0[0]:HE0:SE1] is trying to acquire:\n  ffffffff833b3688 (kernfs_idr_lock){+.+.}-{2:2}', ' at: kernfs_find_and_get_node_by_id+0x1e/0x70\n\n\t\tand this task is already holding:\n  ffff888237ced698 (&rq->__lock){-.-.}-{2:2}', "" at: task_rq_lock+0x4e/0xf0\n  which would create a new lock dependency:\n   (&rq->__lock){-.-.}-{2:2} -> (kernfs_idr_lock){+.+.}-{2:2}\n  ...\n   Possible interrupt unsafe locking scenario:\n\n\t CPU0                    CPU1\n\t ----                    ----\n    lock(kernfs_idr_lock);\n\t\t\t\t local_irq_disable();\n\t\t\t\t lock(&rq->__lock);\n\t\t\t\t lock(kernfs_idr_lock);\n    <Interrupt>\n      lock(&rq->__lock);\n\n\t\t *** DEADLOCK ***\n  ...\n  Call Trace:\n   dump_stack_lvl+0x55/0x70\n   dump_stack+0x10/0x20\n   __lock_acquire+0x781/0x2a40\n   lock_acquire+0xbf/0x1f0\n   _raw_spin_lock+0x2f/0x40\n   kernfs_find_and_get_node_by_id+0x1e/0x70\n   cgroup_get_from_id+0x21/0x240\n   bpf_cgroup_from_id+0xe/0x20\n   bpf_prog_98652316e9337a5a___set_cpus_allowed_ptr_locked+0x96/0x11a\n   bpf_trampoline_6442545632+0x4f/0x1000\n   __set_cpus_allowed_ptr_locked+0x5/0x5a0\n   sched_setaffinity+0x1b3/0x290\n   __x64_sys_sched_setaffinity+0x4f/0x60\n   do_syscall_64+0x40/0xe0\n   entry_SYSCALL_64_after_hwframe+0x46/0x4e\n\nLet's fix it by protecting kernfs_node and kernfs_root with RCU and making\nkernfs_find_and_get_node_by_id() acquire rcu_read_lock() instead of\nkernfs_idr_lock.\n\nThis adds an rcu_head to kernfs_node making it larger by 16 bytes on 64bit.\nCombined with the preceding rearrange patch"", ' the net increase is 8 bytes.\n\nSigned-off-by: Tejun Heo <tj@kernel.org>\nCc: Andrea Righi <andrea.righi@canonical.com>\nCc: Geert Uytterhoeven <geert@linux-m68k.org>\nLink: https://lore.kernel.org/r/20240109214828.252092-4-tj@kernel.org\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>\n', '']",This commit improves RCU protection for kernfs_nodes to avoid deadlocks in bpf_cgroup_from_id().,"kernfs,RUC protection,deadlocks",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4d8ebe1304e99cf6e08e432c23041638d6d1de56,4d8ebe1304e99cf6e08e432c23041638d6d1de56,Alexei Starovoitov,ast@kernel.org,1706636511,Alexei Starovoitov,ast@kernel.org,1706636511,4d444f41e3e3e2410dc6faac1ce817127a40b4e2,24219056805f3988bf93e494499b2329453fc706 c381203eadb76d5601fc04b814317e7608af5f5c,"Merge branch 'trusted-ptr_to_btf_id-arg-support-in-global-subprogs'

Andrii Nakryiko says:

====================
Trusted PTR_TO_BTF_ID arg support in global subprogs

This patch set follows recent changes that added btf_decl_tag-based argument
annotation support for global subprogs. This time we add ability to pass
PTR_TO_BTF_ID (BTF-aware kernel pointers) arguments into global subprograms.
We support explicitly trusted arguments only"," for now.

Patch #1 adds logic for arg:trusted tag support on the verifier side. Default
semantic of such arguments is non-NULL","[' enforced on caller side. But patch #2\nadds arg:nullable tag that can be combined with arg:trusted to make callee\nexplicitly do the NULL check', ' which helps implement ""optional"" PTR_TO_BTF_ID\narguments.\n\nPatch #3 adds libbpf-side __arg_trusted and __arg_nullable macros.\n\nPatch #4 adds a bunch of tests validating __arg_trusted in combination with\n__arg_nullable.\n\nv2->v3:\n  - went back to arg:nullable and __arg_nullable naming;\n  - rebased on latest bpf-next after prepartory patches landed;\nv1->v2:\n  - added fix up to type enforcement changes', ' landed earlier;\n  - dropped bpf_core_cast() changes', ' will post them separately', ' as they now\n    are not used in added tests;\n  - dropped arg:untrusted support (Alexei);\n  - renamed arg:nullable to arg:maybe_null (Alexei);\n  - and also added task_struct___local flavor tests (Alexei).\n====================\n\nLink: https://lore.kernel.org/r/20240130000648.2144827-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit supports trusted PTR_TO_BTF_ID argument handling in global subprograms.,"trusted arguments, PTR_TO_BTF_ID, global subprograms",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c381203eadb76d5601fc04b814317e7608af5f5c,c381203eadb76d5601fc04b814317e7608af5f5c,Andrii Nakryiko,andrii@kernel.org,1706573208,Alexei Starovoitov,ast@kernel.org,1706636510,4d444f41e3e3e2410dc6faac1ce817127a40b4e2,d28bb1a86e68a3d523e0acee8281bb904dd7f451,"selftests/bpf: add trusted global subprog arg tests

Add a bunch of test cases validating behavior of __arg_trusted and its
combination with __arg_nullable tag. We also validate CO-RE flavor
support by kernel for __arg_trusted args.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240130000648.2144827-5-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add selftests for trusted global subprogram arguments in eBPF.,"selftests,arg_trusted,CO-RE",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d28bb1a86e68a3d523e0acee8281bb904dd7f451,d28bb1a86e68a3d523e0acee8281bb904dd7f451,Andrii Nakryiko,andrii@kernel.org,1706573207,Alexei Starovoitov,ast@kernel.org,1706636510,68c3f0fffa3d5b2c2394a9f3e7dca317d20c2546,8f2b44cd9d69ec36c9ce9623993978babb575ee8,"libbpf: add __arg_trusted and __arg_nullable tag macros

Add __arg_trusted to annotate global func args that accept trusted
PTR_TO_BTF_ID arguments.

Also add __arg_nullable to combine with __arg_trusted (and maybe other
tags in the future) to force global subprog itself (i.e."," callee) to do
NULL checks","["" as opposed to default non-NULL semantics (and thus caller's\nresponsibility to ensure non-NULL values).\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240130000648.2144827-4-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",This commit introduces __arg_trusted and __arg_nullable tag macros for annotating global function arguments in libbpf.,"libbpf, trusted, nullable",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8f2b44cd9d69ec36c9ce9623993978babb575ee8,8f2b44cd9d69ec36c9ce9623993978babb575ee8,Andrii Nakryiko,andrii@kernel.org,1706573206,Alexei Starovoitov,ast@kernel.org,1706636510,45c7502fc70ead45db93a3891838d7f2c364d6ac,e2b3c4ff5d183da6d1863c2321413406a2752e7a,"bpf: add arg:nullable tag to be combined with trusted pointers

Add ability to mark arg:trusted arguments with optional arg:nullable
tag to mark it as PTR_TO_BTF_ID_OR_NULL variant"," which will allow
callers to pass NULL","[' and subsequently will force global subprog\'s code\nto do NULL check. This allows to have ""optional"" PTR_TO_BTF_ID values\npassed into global subprogs.\n\nFor now arg:nullable cannot be combined with anything else.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240130000648.2144827-3-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Added support for marking trusted pointer arguments as nullable in eBPF.,"nullable, trusted, pointers",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e2b3c4ff5d183da6d1863c2321413406a2752e7a,e2b3c4ff5d183da6d1863c2321413406a2752e7a,Andrii Nakryiko,andrii@kernel.org,1706573205,Alexei Starovoitov,ast@kernel.org,1706636510,f72b7b9a230cda038b505d3a98732b658440bd3f,24219056805f3988bf93e494499b2329453fc706,"bpf: add __arg_trusted global func arg tag

Add support for passing PTR_TO_BTF_ID registers to global subprogs.
Currently only PTR_TRUSTED flavor of PTR_TO_BTF_ID is supported.
Non-NULL semantics is assumed"," so caller will be forced to prove
PTR_TO_BTF_ID can't be NULL.

Note","[' we disallow global subprogs to destroy passed in PTR_TO_BTF_ID\narguments', ' even the trusted one. We achieve that by not setting\nref_obj_id when validating subprog code. This basically enforces (in\nRust terms) borrowing semantics vs move semantics. Borrowing semantics\nseems to be a better fit for isolated global subprog validation\napproach.\n\nImplementation-wise', ' we utilize existing logic for matching\nuser-provided BTF type to kernel-side BTF type', ' used by BPF CO-RE logic\nand following same matching rules. We enforce a unique match for types.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240130000648.2144827-2-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Support is added for passing PTR_TO_BTF_ID registers with PTR_TRUSTED flavor to global subprogs in bpf.,"PTR_TO_BTF_ID,PTR_TRUSTED,global subprogs",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
24219056805f3988bf93e494499b2329453fc706,24219056805f3988bf93e494499b2329453fc706,Jose E. Marchesi,jose.marchesi@oracle.com,1706614584,Daniel Borkmann,daniel@iogearbox.net,1706627620,24f307e11435646d679987cebd4c7c9fbe198f06,27a90b14b93d3b2e1efd10764e456af7e2a42991,"bpf: Move -Wno-compare-distinct-pointer-types to BPF_CFLAGS

Clang supports enabling/disabling certain conversion diagnostics via
the -W[no-]compare-distinct-pointer-types command line options.
Disabling this warning is required by some BPF selftests due to
-Werror.  Until very recently GCC would emit these warnings
unconditionally", which was a problem for gcc-bpf,"[' but we added support\nfor the command-line options to GCC upstream [1].\n\nThis patch moves the -Wno-cmopare-distinct-pointer-types from\nCLANG_CFLAGS to BPF_CFLAGS in selftests/bpf/Makefile so the option\nis also used in gcc-bpf builds', ' not just in clang builds.\n\nTested in bpf-next master.\nNo regressions.\n\n  [1] https://gcc.gnu.org/pipermail/gcc-patches/2023-August/627769.html\n\nSigned-off-by: Jose E. Marchesi <jose.marchesi@oracle.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240130113624.24940-1-jose.marchesi@oracle.com\n', '']",Move Clang diagnostic flag -Wno-compare-distinct-pointer-types to BPF_CFLAGS for BPF selftests compatibility.,"Clang, BPF_CFLAGS, selftests",It's a build system or CI/CD change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
27a90b14b93d3b2e1efd10764e456af7e2a42991,27a90b14b93d3b2e1efd10764e456af7e2a42991,Jose E. Marchesi,jose.marchesi@oracle.com,1706612623,Daniel Borkmann,daniel@iogearbox.net,1706627298,d830754421a89bf6005406d6e13f276796662a78,6668e818f960b0f32110a9efa7c97351a5771b35,"bpf: Build type-punning BPF selftests with -fno-strict-aliasing

A few BPF selftests perform type punning and they may break strict
aliasing rules"," which are exploited by both GCC and clang by default
while optimizing.  This can lead to broken compiled programs.

This patch disables strict aliasing for these particular tests","[' by\nmean of the -fno-strict-aliasing command line option.  This will make\nsure these tests are optimized properly even if some strict aliasing\nrule gets violated.\n\nAfter this patch', ' GCC is able to build all the selftests without\nwarning about potential strict aliasing issue.\n\nbpf@vger discussion on strict aliasing and BPF selftests:\nhttps://lore.kernel.org/bpf/bae1205a-b6e5-4e46-8e20-520d7c327f7a@linux.dev/T/#t\n\nTested in bpf-next master.\nNo regressions.\n\nSigned-off-by: Jose E. Marchesi <jose.marchesi@oracle.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/bae1205a-b6e5-4e46-8e20-520d7c327f7a@linux.dev\nLink: https://lore.kernel.org/bpf/20240130110343.11217-1-jose.marchesi@oracle.com\n', '']",Disable strict aliasing in certain BPF selftests to prevent optimization-related issues by compilers.,"type-punning,BPF selftests,strict-aliasing",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6668e818f960b0f32110a9efa7c97351a5771b35,6668e818f960b0f32110a9efa7c97351a5771b35,Haiyue Wang,haiyue.wang@intel.com,1706363336,Andrii Nakryiko,andrii@kernel.org,1706587495,e0d8c6487fd080914d48eababd5bfb1f38a9f049,ff2071a7b7fd77908417603c4a785822939b3841,bpf,"token: Use BIT_ULL() to convert the bit mask

Replace the '(1ULL << *)' with the macro BIT_ULL(nr).

Signed-off-by: Haiyue Wang <haiyue.wang@intel.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240127134901.3698613-1-haiyue.wang@intel.com
",[''],Replace bit mask calculation with BIT_ULL macro for improved readability.,"BIT_ULL,macro,bit",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ff2071a7b7fd77908417603c4a785822939b3841,ff2071a7b7fd77908417603c4a785822939b3841,Jose E. Marchesi,jose.marchesi@oracle.com,1706381431,Andrii Nakryiko,andrii@kernel.org,1706575572,e98a8449e31b80a0d7c0288571ca0a0aa426a09f,f2e4040c82d3fddd11fa7c64e8f810e6f9cb7460,"bpf: Generate const static pointers for kernel helpers

The generated bpf_helper_defs.h file currently contains definitions
like this for the kernel helpers"," which are static objects:

  static void *(*bpf_map_lookup_elem)(void *map","[' const void *key) = (void *) 1;\n\nThese work well in both clang and GCC because both compilers do\nconstant propagation with -O1 and higher optimization', "" resulting in\n`call 1' BPF instructions being generated"", ' which are calls to kernel\nhelpers.\n\nHowever', ' there is a discrepancy on how the -Wunused-variable\nwarning (activated by -Wall) is handled in these compilers:\n\n- clang will not emit -Wunused-variable warnings for static variables\n  defined in C header files', ' be them constant or not constant.\n\n- GCC will not emit -Wunused-variable warnings for _constant_ static\n  variables defined in header files', ' but it will emit warnings for\n  non-constant static variables defined in header files.\n\nThere is no reason for these bpf_helpers_def.h pointers to not be\ndeclared constant', ' and it is actually desirable to do so', ' since their\nvalues are not to be changed.  So this patch modifies bpf_doc.py to\ngenerate prototypes like:\n\n  static void *(* const bpf_map_lookup_elem)(void *map', "" const void *key) = (void *) 1;\n\nThis allows GCC to not error while compiling BPF programs with `-Wall\n-Werror'"", "" while still being able to detect and error on legitimate\nunused variables in the program themselves.\n\nThis change doesn't impact the desired constant propagation in neither\nClang nor GCC with -O1 and higher.  On the contrary"", ' being declared as\nconstant may increase the odds they get constant folded when\nused/referred to in certain circumstances.\n\nTested in bpf-next master.\nNo regressions.\n\nSigned-off-by: Jose E. Marchesi <jose.marchesi@oracle.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/bpf/20240127185031.29854-1-jose.marchesi@oracle.com\n', '']",The commit generates const static pointers for kernel helper functions in bpf_helper_defs.h file.,"bpf, kernel helpers, pointers",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f2e4040c82d3fddd11fa7c64e8f810e6f9cb7460,f2e4040c82d3fddd11fa7c64e8f810e6f9cb7460,Ian Rogers,irogers@google.com,1706224720,Andrii Nakryiko,andrii@kernel.org,1706575362,f413ae5bdb8800f9612a875e827cc811bd3639b9,aecaa3ed48c3ae74c06f5e8ef0746b69c62397f1,"libbpf: Add some details for BTF parsing failures

As CONFIG_DEBUG_INFO_BTF is default off the existing ""failed to find
valid kernel BTF"" message makes diagnosing the kernel build issue somewhat
cryptic. Add a little more detail with the hope of helping users.

Before:
```
libbpf: failed to find valid kernel BTF
libbpf: Error loading vmlinux BTF: -3
```

After not accessible:
```
libbpf: kernel BTF is missing at '/sys/kernel/btf/vmlinux'"," was CONFIG_DEBUG_INFO_BTF enabled?
libbpf: failed to find valid kernel BTF
libbpf: Error loading vmlinux BTF: -3
```

After not readable:
```
libbpf: failed to read kernel BTF from (/sys/kernel/btf/vmlinux): -1
```

Closes: https://lore.kernel.org/bpf/CAP-5=fU+DN_+Y=Y4gtELUsJxKNDDCOvJzPHvjUVaUoeFAzNnig@mail.gmail.com/

Signed-off-by: Ian Rogers <irogers@google.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20240125231840.1647951-1-irogers@google.com
",[''],The commit enhances error messages for BTF parsing failures to aid in diagnosing kernel build issues.,"BTF,libbpf,error messages",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
aecaa3ed48c3ae74c06f5e8ef0746b69c62397f1,aecaa3ed48c3ae74c06f5e8ef0746b69c62397f1,Florian Lehner,dev@der-flo.net,1705763360,Daniel Borkmann,daniel@iogearbox.net,1706564437,595fcd3705bd6c5641be5b3c794cbfe53f47e71d,646751d523587cfd7ebcf1733298ecd470879eda,"perf/bpf: Fix duplicate type check

Remove the duplicate check on type and unify result.

Signed-off-by: Florian Lehner <dev@der-flo.net>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Song Liu <song@kernel.org>
Link: https://lore.kernel.org/bpf/20240120150920.3370-1-dev@der-flo.net
",,Remove duplicate type check in perf/bpf for consistency.,"perf,bpf,duplicate",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
646751d523587cfd7ebcf1733298ecd470879eda,646751d523587cfd7ebcf1733298ecd470879eda,Jose E. Marchesi,jose.marchesi@oracle.com,1706350022,Daniel Borkmann,daniel@iogearbox.net,1706564328,2cbf6d8e7a106064183bceb0c8c49581ac0c550e,fbaf59a9f513416c05f4b4e87d26898d3dccd1cc,"bpf: Use -Wno-error in certain tests when building with GCC

Certain BPF selftests contain code that", albeit being legal C,"[' trigger\nwarnings in GCC that cannot be disabled.  This is the case for example\nfor the tests\n\n  progs/btf_dump_test_case_bitfields.c\n  progs/btf_dump_test_case_namespacing.c\n  progs/btf_dump_test_case_packing.c\n  progs/btf_dump_test_case_padding.c\n  progs/btf_dump_test_case_syntax.c\n\nwhich contain struct type declarations inside function parameter\nlists.  This is problematic', ' because:\n\n- The BPF selftests are built with -Werror.\n\n- The Clang and GCC compilers sometimes differ when it comes to handle\n  warnings.  in the handling of warnings.  One compiler may emit\n  warnings for code that the other compiles compiles silently', ' and one\n  compiler may offer the possibility to disable certain warnings', "" while\n  the other doesn't.\n\nIn order to overcome this problem"", ' this patch modifies the\ntools/testing/selftests/bpf/Makefile in order to:\n\n1. Enable the possibility of specifing per-source-file extra CFLAGS.\n   This is done by defining a make variable like:\n\n   <source-filename>-CFLAGS := <whateverflags>\n\n   And then modifying the proper Make rule in order to use these flags\n   when compiling <source-filename>.\n\n2. Use the mechanism above to add -Wno-error to CFLAGS for the\n   following selftests:\n\n   progs/btf_dump_test_case_bitfields.c\n   progs/btf_dump_test_case_namespacing.c\n   progs/btf_dump_test_case_packing.c\n   progs/btf_dump_test_case_padding.c\n   progs/btf_dump_test_case_syntax.c\n\n   Note the corresponding -CFLAGS variables for these files are\n   defined only if the selftests are being built with GCC.\n\nNote that', ' while compiler pragmas can generally be used to disable\nparticular warnings per file', ' this 1) is only possible for warning\nthat actually can be disabled in the command line', ' i.e. that have\n-Wno-FOO options', "" and 2) doesn't apply to -Wno-error.\n\nTested in bpf-next master branch.\nNo regressions.\n\nSigned-off-by: Jose E. Marchesi <jose.marchesi@oracle.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20240127100702.21549-1-jose.marchesi@oracle.com\n"", '']",Add -Wno-error flag to certain BPF selftests when using GCC.,"BPF selftests,GCC,-Wno-error",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fbaf59a9f513416c05f4b4e87d26898d3dccd1cc,fbaf59a9f513416c05f4b4e87d26898d3dccd1cc,Martin KaFai Lau,martin.lau@kernel.org,1706323817,Alexei Starovoitov,ast@kernel.org,1706561312,515085461029a2092aebd20f5a3b5187453d4a15,add9c58cd44e88a15f285945e26bf0d9d81c5890,"selftests/bpf: Remove ""&>"" usage in the selftests

In s390"," CI reported that the sock_iter_batch selftest
hits this error very often:

2024-01-26T16:56:49.3091804Z Bind /proc/self/ns/net -> /run/netns/sock_iter_batch_netns failed: No such file or directory
2024-01-26T16:56:49.3149524Z Cannot remove namespace file ""/run/netns/sock_iter_batch_netns"": No such file or directory
2024-01-26T16:56:49.3772213Z test_sock_iter_batch:FAIL:ip netns add sock_iter_batch_netns unexpected error: 256 (errno 0)

It happens very often in s390 but Manu also noticed it happens very
sparsely in other arch also.

It turns out the default dash shell does not recognize ""&>""
as a redirection operator","[' so the command went to the background.\nIn the sock_iter_batch selftest', ' the ""ip netns delete"" went\ninto background and then race with the following ""ip netns add""\ncommand.\n\nThis patch replaces the ""&> /dev/null"" usage with "">/dev/null 2>&1""\nand does this redirection in the SYS_NOFAIL macro instead of doing\nit individually by its caller. The SYS_NOFAIL callers do not care\nabout failure', ' so it is no harm to do this redirection even if\nsome of the existing callers do not redirect to /dev/null now.\n\nIt touches different test files', ' so I skipped the Fixes tags\nin this patch. Some of the changed tests do not use ""&>""\nbut they use the SYS_NOFAIL', ' so these tests are also\nchanged to avoid doing its own redirection because\nSYS_NOFAIL does it internally now.\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nLink: https://lore.kernel.org/r/20240127025017.950825-1-martin.lau@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']","Remove ""&>"" redirection usage in bpf selftests to address shell compatibility issues.","selftests, redirection, s390",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
add9c58cd44e88a15f285945e26bf0d9d81c5890,add9c58cd44e88a15f285945e26bf0d9d81c5890,Andrii Nakryiko,andrii@kernel.org,1706216106,Alexei Starovoitov,ast@kernel.org,1706560453,c1d2907a12d225121b23ffc703031d33f9f48cc4,9eea8fafe33eb70868f6ace2fc1e17c4ff5539c3,"bpf: move arg:ctx type enforcement check inside the main logic loop

Now that bpf and bpf-next trees converged and we don't run the risk of
merge conflicts"," move btf_validate_prog_ctx_type() into its most logical
place inside the main logic loop.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240125205510.3642094-4-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Refactor the position of context type enforcement check inside the bpf main logic loop.,"type enforcement, context, logic loop",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9eea8fafe33eb70868f6ace2fc1e17c4ff5539c3,9eea8fafe33eb70868f6ace2fc1e17c4ff5539c3,Andrii Nakryiko,andrii@kernel.org,1706216105,Alexei Starovoitov,ast@kernel.org,1706560453,504fe883aa1bf4cbb27a7cbf85152d3cd2d93c65,0e6d0a9d2348b64df74239e859fa9d6e86cdcdef,"libbpf: fix __arg_ctx type enforcement for perf_event programs

Adjust PERF_EVENT type enforcement around __arg_ctx to match exactly
what kernel is doing.

Fixes: 76ec90a996e3 (""libbpf: warn on unexpected __arg_ctx type when rewriting BTF"")
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240125205510.3642094-3-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Fixes type enforcement for __arg_ctx in PERF_EVENT programs to match kernel behavior in libbpf.,"libbpf, perf_event, __arg_ctx",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,['tracepoints like programs']
0e6d0a9d2348b64df74239e859fa9d6e86cdcdef,0e6d0a9d2348b64df74239e859fa9d6e86cdcdef,Andrii Nakryiko,andrii@kernel.org,1706216104,Alexei Starovoitov,ast@kernel.org,1706560453,02f3789507760c1311101d6c8203d84addec2955,ced33f2cfa21a14a292a00e31dc9f85c1bfbda1c,"libbpf: integrate __arg_ctx feature detector into kernel_supports()

Now that feature detection code is in bpf-next tree"," integrate __arg_ctx
kernel-side support into kernel_supports() framework.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240125205510.3642094-2-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Integrates the __arg_ctx feature detection into the libbpf's kernel_supports framework.,"libbpf,__arg_ctx,feature",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ced33f2cfa21a14a292a00e31dc9f85c1bfbda1c,ced33f2cfa21a14a292a00e31dc9f85c1bfbda1c,Yonghong Song,yonghong.song@linux.dev,1706384789,Daniel Borkmann,daniel@iogearbox.net,1706543673,c1ff1a7054587716b2ad4cd071023314b4cca538,efaa47db92451608499ab7edf108bf30141c33db,"docs/bpf: Improve documentation of 64-bit immediate instructions

For 64-bit immediate instruction"," 'BPF_IMM | BPF_DW | BPF_LD' and
src_reg=[0-6]","[' the current documentation describes the 64-bit\nimmediate is constructed by:\n\n  imm64 = (next_imm << 32) | imm\n\nBut actually imm64 is only used when src_reg=0. For all other\nvariants (src_reg != 0)', "" 'imm' and 'next_imm' have separate special\nencoding requirement and imm64 cannot be easily used to describe\ninstruction semantics.\n\nThis patch clarifies that 64-bit immediate instructions use\ntwo 32-bit immediate values instead of a 64-bit immediate value"", '\nso later describing individual 64-bit immediate instructions\nbecomes less confusing.\n\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Dave Thaler <dthaler1968@gmail.com>\nLink: https://lore.kernel.org/bpf/20240127194629.737589-1-yonghong.song@linux.dev\n', '']",Improve the documentation for 64-bit immediate instructions in eBPF.,"documentation, 64-bit, instructions",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
efaa47db92451608499ab7edf108bf30141c33db,efaa47db92451608499ab7edf108bf30141c33db,Menglong Dong,dongmenglong.8@bytedance.com,1706421283,Daniel Borkmann,daniel@iogearbox.net,1706543093,d8c2405cd3568bca72a9c7472cc0d1418646d207,f149d03f450b4afab11f5e1ebd8fdfaf7eb24a28,"bpf: Remove unused field ""mod"" in struct bpf_trampoline

It seems that the field ""mod"" in struct bpf_trampoline is not used
anywhere after the commit 31bf1dbccfb0 (""bpf: Fix attaching
fentry/fexit/fmod_ret/lsm to modules""). So we can just remove it now.

Fixes: 31bf1dbccfb0 (""bpf: Fix attaching fentry/fexit/fmod_ret/lsm to modules"")
Signed-off-by: Menglong Dong <dongmenglong.8@bytedance.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Link: https://lore.kernel.org/bpf/20240128055443.413291-1-dongmenglong.8@bytedance.com
",,"Remove unused ""mod"" field from bpf_trampoline structure for simplification.","unused field,bpf_trampoline,mod removal",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f149d03f450b4afab11f5e1ebd8fdfaf7eb24a28,f149d03f450b4afab11f5e1ebd8fdfaf7eb24a28,Geliang Tang,tanggeliang@kylinos.cn,1706442237,Daniel Borkmann,daniel@iogearbox.net,1706542889,4ad7347ebcf54143db3162389cff406a0c89ff50,06a33d024838414432b6c0f51f994e7f1695b74f,"selftests/bpf: Drop return in bpf_testmod_exit

bpf_testmod_exit() does not need to have a return value (given the void)","
so this patch drops this useless 'return' in it.

Signed-off-by: Geliang Tang <tanggeliang@kylinos.cn>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Link: https://lore.kernel.org/bpf/5765b287ea088f0c820f2a834faf9b20fb2f8215.1706442113.git.tanggeliang@kylinos.cn
",[''],Removed unnecessary return statement in bpf_testmod_exit() due to void return type.,"selftests,bpf,bpf_testmod_exit",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
06a33d024838414432b6c0f51f994e7f1695b74f,06a33d024838414432b6c0f51f994e7f1695b74f,Pu Lehui,pulehui@huawei.com,1705324355,Daniel Borkmann,daniel@iogearbox.net,1706541933,ce2470d5a3291c05e9a48eb2fd0f20334c769379,519fb722bea09ae2664ad21f8ef4360fb799eb2f,riscv," bpf: Optimize bswap insns with Zbb support

Optimize bswap instructions by rev8 Zbb instruction conbined with srli
instruction. And Optimize 16-bit zero-extension with Zbb support.

Signed-off-by: Pu Lehui <pulehui@huawei.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Tested-by: Björn Töpel <bjorn@rivosinc.com>
Acked-by: Björn Töpel <bjorn@kernel.org>
Link: https://lore.kernel.org/bpf/20240115131235.2914289-7-pulehui@huaweicloud.com
",[''],Optimize bswap instructions with Zbb support on RISC-V architecture.,"Optimize,RISC-V,Zbb",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
519fb722bea09ae2664ad21f8ef4360fb799eb2f,519fb722bea09ae2664ad21f8ef4360fb799eb2f,Pu Lehui,pulehui@huawei.com,1705324354,Daniel Borkmann,daniel@iogearbox.net,1706541933,e20f5b0751cd2551f703834bd9be65633771a59c,647b93f65daa128d9a0e4aac744a5fcf5f58b2d2,riscv," bpf: Optimize sign-extention mov insns with Zbb support

Add 8-bit and 16-bit sign-extention wraper with Zbb support to optimize
sign-extension mov instructions.

Signed-off-by: Pu Lehui <pulehui@huawei.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Tested-by: Björn Töpel <bjorn@rivosinc.com>
Acked-by: Björn Töpel <bjorn@kernel.org>
Link: https://lore.kernel.org/bpf/20240115131235.2914289-6-pulehui@huaweicloud.com
",[''],Optimize sign-extension mov instructions on RISC-V with support for 8-bit and 16-bit Zbb extensions.,"sign-extension,RISC-V,Zbb",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
647b93f65daa128d9a0e4aac744a5fcf5f58b2d2,647b93f65daa128d9a0e4aac744a5fcf5f58b2d2,Pu Lehui,pulehui@huawei.com,1705324353,Daniel Borkmann,daniel@iogearbox.net,1706541933,1dbbebfef86d0568d6de577164baac167ef10f27,361db44c3c59cde05e9926647f16255e274a37f4,riscv," bpf: Add necessary Zbb instructions

Add necessary Zbb instructions introduced by [0] to reduce code size and
improve performance of RV64 JIT. Meanwhile","[' a runtime deteted helper is\nadded to check whether the CPU supports Zbb instructions.\n\nSigned-off-by: Pu Lehui <pulehui@huawei.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Björn Töpel <bjorn@rivosinc.com>\nAcked-by: Björn Töpel <bjorn@kernel.org>\nLink: https://github.com/riscv/riscv-bitmanip/releases/download/1.0.0/bitmanip-1.0.0-38-g865e7a7.pdf [0]\nLink: https://lore.kernel.org/bpf/20240115131235.2914289-5-pulehui@huaweicloud.com\n', '']",Add Zbb instructions to enhance performance and reduce code size for RV64 JIT in RISC-V architecture.,"Zbb, RV64, JIT",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
361db44c3c59cde05e9926647f16255e274a37f4,361db44c3c59cde05e9926647f16255e274a37f4,Pu Lehui,pulehui@huawei.com,1705324352,Daniel Borkmann,daniel@iogearbox.net,1706541933,5a95a54d3a7fbc93b9d4dbf3205b4f854f562ace,914c7a5ff18a225f7df254ae3433574f3d47b711,riscv," bpf: Simplify sext and zext logics in branch instructions

There are many extension helpers in the current branch instructions","[' and\nthe implementation is a bit complicated. We simplify this logic through\ntwo simple extension helpers with alternate register.\n\nSigned-off-by: Pu Lehui <pulehui@huawei.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Björn Töpel <bjorn@rivosinc.com>\nAcked-by: Björn Töpel <bjorn@kernel.org>\nLink: https://lore.kernel.org/bpf/20240115131235.2914289-4-pulehui@huaweicloud.com\n', '']",Simplify the extension logic in RISC-V branch instructions for the BPF subsystem.,"riscv, simplify, branch",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
914c7a5ff18a225f7df254ae3433574f3d47b711,914c7a5ff18a225f7df254ae3433574f3d47b711,Pu Lehui,pulehui@huawei.com,1705324351,Daniel Borkmann,daniel@iogearbox.net,1706541933,e4dc7d61f7d90f4121042426892ee4f7a3ab1c0c,e33758f7493c9ad8cf6960bcf7c70f5761f3acfb,riscv," bpf: Unify 32-bit zero-extension to emit_zextw

For code unification","[' add emit_zextw wrapper to unify all the 32-bit\nzero-extension operations.\n\nSigned-off-by: Pu Lehui <pulehui@huawei.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Björn Töpel <bjorn@rivosinc.com>\nAcked-by: Björn Töpel <bjorn@kernel.org>\nLink: https://lore.kernel.org/bpf/20240115131235.2914289-3-pulehui@huaweicloud.com\n', '']",Unify 32-bit zero-extension code in riscv architecture.,"riscv, code unification, emit_zextw",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e33758f7493c9ad8cf6960bcf7c70f5761f3acfb,e33758f7493c9ad8cf6960bcf7c70f5761f3acfb,Pu Lehui,pulehui@huawei.com,1705324350,Daniel Borkmann,daniel@iogearbox.net,1706541932,dcc00029047295dfcb3f8be9454ac90b444c1a30,ad57654053805bf9a62602aaec74cc78edb6f235,riscv," bpf: Unify 32-bit sign-extension to emit_sextw

For code unification","[' add emit_sextw wrapper to unify all the 32-bit\nsign-extension operations.\n\nSigned-off-by: Pu Lehui <pulehui@huawei.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Björn Töpel <bjorn@rivosinc.com>\nAcked-by: Björn Töpel <bjorn@kernel.org>\nLink: https://lore.kernel.org/bpf/20240115131235.2914289-2-pulehui@huaweicloud.com\n', '']",Unifies 32-bit sign-extension for the RISC-V architecture in BPF.,"unify, sign-extension, riscv",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ad57654053805bf9a62602aaec74cc78edb6f235,ad57654053805bf9a62602aaec74cc78edb6f235,Andrii Nakryiko,andrii@kernel.org,1706306984,Daniel Borkmann,daniel@iogearbox.net,1706541464,d6f66e87082111583b271b5dff78a22745acb1c4,29788f39a4171dd48a6d19eb78cf2ab168c4349a,"libbpf: Fix faccessat() usage on Android

Android implementation of libc errors out with -EINVAL in faccessat() if
passed AT_EACCESS ([0])"," this leads to ridiculous issue with libbpf
refusing to load /sys/kernel/btf/vmlinux on Androids ([1]). Fix by
detecting Android and redefining AT_EACCESS to 0","[' it\'s equivalent on\nAndroid.\n\n  [0] https://android.googlesource.com/platform/bionic/+/refs/heads/android13-release/libc/bionic/faccessat.cpp#50\n  [1] https://github.com/libbpf/libbpf-bootstrap/issues/250#issuecomment-1911324250\n\nFixes: 6a4ab8869d0b (""libbpf: Fix the case of running as non-root with capabilities"")\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/bpf/20240126220944.2497665-1-andrii@kernel.org\n', '']",The commit fixes faccessat() usage in libbpf on Android by handling AT_EACCESS error.,"libbpf, Android, faccessat",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
29788f39a4171dd48a6d19eb78cf2ab168c4349a,29788f39a4171dd48a6d19eb78cf2ab168c4349a,Arnaldo Carvalho de Melo,acme@kernel.org,1706538806,Daniel Borkmann,daniel@iogearbox.net,1706540926,d072aec607a6d5fa0825e542e00f11a9e9fdef95,723de3ebef03bc14bd72531f00f9094337654009,"bpftool: Be more portable by using POSIX's basename()

musl libc had the basename() prototype in string.h"," but this is a
glibc-ism","[' now they removed the _GNU_SOURCE bits in their devel distro', '\nAlpine Linux edge:\n\n  https://git.musl-libc.org/cgit/musl/commit/?id=725e17ed6dff4d0cd22487bb64470881e86a92e7\n\nSo lets use the POSIX version', ' the whole rationale is spelled out at:\n\n  https://gitlab.alpinelinux.org/alpine/aports/-/issues/15643\n\nSigned-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Jiri Olsa <olsajiri@gmail.com>\nAcked-by: Quentin Monnet <quentin@isovalent.com>\nLink: https://lore.kernel.org/lkml/ZZhsPs00TI75RdAr@kernel.org\nLink: https://lore.kernel.org/bpf/Zbe3NuOgaupvUcpF@kernel.org\n', '']",Improve bpftool portability by using POSIX basename() function.,"bpftool, portability, POSIX",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"[""It's not related to any of the above.""]"
92046e83c07b064ca65ac4ae7660a540016bdfc1,92046e83c07b064ca65ac4ae7660a540016bdfc1,Jakub Kicinski,kuba@kernel.org,1706332101,Jakub Kicinski,kuba@kernel.org,1706332102,7f8a5dd9522e2b744a48d93ca5a7ec418ea192f5,c09f32a859458002b40ba44fc736329a4c0fe4e5 fa7178b0f12e55a4f2d4906df3f25d6d4f88d962,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next

Daniel Borkmann says:

====================
pull-request: bpf-next 2024-01-26

We've added 107 non-merge commits during the last 4 day(s) which contain
a total of 101 files changed", 6009 insertions(+),"["" 1260 deletions(-).\n\nThe main changes are:\n\n1) Add BPF token support to delegate a subset of BPF subsystem\n   functionality from privileged system-wide daemons such as systemd\n   through special mount options for userns-bound BPF fs to a trusted\n   & unprivileged application. With addressed changes from Christian\n   and Linus' reviews"", ' from Andrii Nakryiko.\n\n2) Support registration of struct_ops types from modules which helps\n   projects like fuse-bpf that seeks to implement a new struct_ops type', '\n   from Kui-Feng Lee.\n\n3) Add support for retrieval of cookies for perf/kprobe multi links', '\n   from Jiri Olsa.\n\n4) Bigger batch of prep-work for the BPF verifier to eventually support\n   preserving boundaries and tracking scalars on narrowing fills', '\n   from Maxim Mikityanskiy.\n\n5) Extend the tc BPF flavor to support arbitrary TCP SYN cookies to help\n   with the scenario of SYN floods', ' from Kuniyuki Iwashima.\n\n6) Add code generation to inline the bpf_kptr_xchg() helper which\n   improves performance when stashing/popping the allocated BPF objects', '\n   from Hou Tao.\n\n7) Extend BPF verifier to track aligned ST stores as imprecise spilled\n   registers', ' from Yonghong Song.\n\n8) Several fixes to BPF selftests around inline asm constraints and\n   unsupported VLA code generation', ' from Jose E. Marchesi.\n\n9) Various updates to the BPF IETF instruction set draft document such\n   as the introduction of conformance groups for instructions', '\n   from Dave Thaler.\n\n10) Fix BPF verifier to make infinite loop detection in is_state_visited()\n    exact to catch some too lax spill/fill corner cases', '\n    from Eduard Zingerman.\n\n11) Refactor the BPF verifier pointer ALU check to allow ALU explicitly\n    instead of implicitly for various register types', ' from Hao Sun.\n\n12) Fix the flaky tc_redirect_dtime BPF selftest due to slowness\n    in neighbor advertisement at setup time', ' from Martin KaFai Lau.\n\n13) Change BPF selftests to skip callback tests for the case when the\n    JIT is disabled', "" from Tiezhu Yang.\n\n14) Add a small extension to libbpf which allows to auto create\n    a map-in-map's inner map"", "" from Andrey Grafin.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next: (107 commits)\n  selftests/bpf: Add missing line break in test_verifier\n  bpf"", ' docs: Clarify definitions of various instructions\n  bpf: Fix error checks against bpf_get_btf_vmlinux().\n  bpf: One more maintainer for libbpf and BPF selftests\n  selftests/bpf: Incorporate LSM policy to token-based tests\n  selftests/bpf: Add tests for LIBBPF_BPF_TOKEN_PATH envvar\n  libbpf: Support BPF token path setting through LIBBPF_BPF_TOKEN_PATH envvar\n  selftests/bpf: Add tests for BPF object load with implicit token\n  selftests/bpf: Add BPF object loading tests with explicit token passing\n  libbpf: Wire up BPF token support at BPF object level\n  libbpf: Wire up token_fd into feature probing logic\n  libbpf: Move feature detection code into its own file\n  libbpf: Further decouple feature checking logic from bpf_object\n  libbpf: Split feature detectors definitions from cached results\n  selftests/bpf: Utilize string values for delegate_xxx mount options\n  bpf: Support symbolic BPF FS delegation mount options\n  bpf: Fail BPF_TOKEN_CREATE if no delegation option was set on BPF FS\n  bpf', 'selinux: Allocate bpf_security_struct per BPF token\n  selftests/bpf: Add BPF token-enabled tests\n  libbpf: Add BPF token support to bpf_prog_load() API\n  ...\n====================\n\nLink: https://lore.kernel.org/r/20240126215710.19855-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Merged branch 'for-netdev' from bpf-next with 107 new commits.,"bpf-next, merge, netdev",It's a new feature.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
d3cb3b0088ca92082e2bebc40cc6894a632173e2,d3cb3b0088ca92082e2bebc40cc6894a632173e2,Paolo Abeni,pabeni@redhat.com,1706170970,Jakub Kicinski,kuba@kernel.org,1706306970,b0dd97fb4c484d1c9cbab15cbc302989a9b0f5dd,281cb9d65a95c00bb844f332cd187491d2d55496,"selftests: net: add missing required classifier

the udpgro_fraglist self-test uses the BPF classifiers"," but the
current net self-test configuration does not include it","[' causing\nCI failures:\n\n # selftests: net: udpgro_frglist.sh\n # ipv6\n # tcp - over veth touching data\n # -l 4 -6 -D 2001:db8::1 -t rx -4 -t\n # Error: TC classifier not found.\n # We have an error talking to the kernel\n # Error: TC classifier not found.\n # We have an error talking to the kernel\n\nAdd the missing knob.\n\nFixes: edae34a3ed92 (""selftests net: add UDP GRO fraglist + bpf self-tests"")\nSigned-off-by: Paolo Abeni <pabeni@redhat.com>\nReviewed-by: Maciej Żenczykowski <maze@google.com>\nReviewed-by: Eric Dumazet <edumazet@google.com>\nLink: https://lore.kernel.org/r/7c3643763b331e9a400e1874fe089193c99a1c3f.1706170897.git.pabeni@redhat.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",The commit adds a missing required BPF classifier for the udpgro_fraglist self-test in net self-tests.,"self-test, BPF classifiers, net",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fa7178b0f12e55a4f2d4906df3f25d6d4f88d962,fa7178b0f12e55a4f2d4906df3f25d6d4f88d962,Tiezhu Yang,yangtiezhu@loongson.cn,1706234256,Andrii Nakryiko,andrii@kernel.org,1706296172,6817be7ae5fd0cbb8587ea8d4e8ee6acec766f39,e48f0f4a9bfed8947e4d1123e8b6a15c18ee1708,"selftests/bpf: Add missing line break in test_verifier

There are no break lines in the test log for test_verifier #106 ~ #111
if jit is disabled"," add the missing line break at the end of printf()
to fix it.

Without this patch:

  [root@linux bpf]# echo 0 > /proc/sys/net/core/bpf_jit_enable
  [root@linux bpf]# ./test_verifier 106
  #106/p inline simple bpf_loop call SKIP (requires BPF JIT)Summary: 0 PASSED","[' 1 SKIPPED', ' 0 FAILED\n\nWith this patch:\n\n  [root@linux bpf]# echo 0 > /proc/sys/net/core/bpf_jit_enable\n  [root@linux bpf]# ./test_verifier 106\n  #106/p inline simple bpf_loop call SKIP (requires BPF JIT)\n  Summary: 0 PASSED', ' 1 SKIPPED', ' 0 FAILED\n\nFixes: 0b50478fd877 (""selftests/bpf: Skip callback tests if jit is disabled in test_verifier"")\nSigned-off-by: Tiezhu Yang <yangtiezhu@loongson.cn>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240126015736.655-1-yangtiezhu@loongson.cn\n', '']",Added missing line break in test_verifier selftest to improve readability for non-JIT logs.,"line break,selftests,test_verifier",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e48f0f4a9bfed8947e4d1123e8b6a15c18ee1708,e48f0f4a9bfed8947e4d1123e8b6a15c18ee1708,Dave Thaler,dthaler1968@googlemail.com,1706241650,Daniel Borkmann,daniel@iogearbox.net,1706292338,c0d661ff0303c6bf02ae0aad1d355e72cbd8ea23,e6be8cd5d3cf54ccd0ae66027d6f4697b15f4c3e,bpf," docs: Clarify definitions of various instructions

Clarify definitions of several instructions:

* BPF_NEG does not support BPF_X
* BPF_CALL does not support BPF_JMP32 or BPF_X
* BPF_EXIT does not support BPF_X
* BPF_JA does not support BPF_X (was implied but not explicitly stated)

Also fix a typo in the wide instruction figure where the field is
actually named ""opcode"" not ""code"".

Signed-off-by: Dave Thaler <dthaler1968@gmail.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/bpf/20240126040050.8464-1-dthaler1968@gmail.com
",[''],Clarified instruction definitions in documentation and fixed typo in BPF opcode description.,"documentation, instruction, typo",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
e6be8cd5d3cf54ccd0ae66027d6f4697b15f4c3e,e6be8cd5d3cf54ccd0ae66027d6f4697b15f4c3e,Kui-Feng Lee,thinker.li@gmail.com,1706236273,Martin KaFai Lau,martin.lau@kernel.org,1706244599,ea60dfda94c8a06e4c14f90a4900b7167121d847,be4840b33eb2ea7d80830530aab5fcbeaa90e857,"bpf: Fix error checks against bpf_get_btf_vmlinux().

In bpf_struct_ops_map_alloc"," it needs to check for NULL in the returned
pointer of bpf_get_btf_vmlinux() when CONFIG_DEBUG_INFO_BTF is not set.
ENOTSUPP is used to preserve the same behavior before the
struct_ops kmod support.

In the function check_struct_ops_btf_id()","[' instead of redoing the\nbpf_get_btf_vmlinux() that has already been done in syscall.c', ' the fix\nhere is to check for prog->aux->attach_btf_id.\nBPF_PROG_TYPE_STRUCT_OPS must require attach_btf_id and syscall.c\nguarantees a valid attach_btf as long as attach_btf_id is set.\nWhen attach_btf_id is not set', ' this patch returns -ENOTSUPP\nbecause it is what the selftest in test_libbpf_probe_prog_types()\nand libbpf_probes.c are expecting for feature probing purpose.\n\nChanges from v1:\n\n - Remove an unnecessary NULL check in check_struct_ops_btf_id()\n\nReported-by: syzbot+88f0aafe5f950d7489d7@syzkaller.appspotmail.com\nCloses: https://lore.kernel.org/bpf/00000000000040d68a060fc8db8c@google.com/\nReported-by: syzbot+1336f3d4b10bcda75b89@syzkaller.appspotmail.com\nCloses: https://lore.kernel.org/bpf/00000000000026353b060fc21c07@google.com/\nFixes: fcc2c1fb0651 (""bpf: pass attached BTF to the bpf_struct_ops subsystem"")\nSigned-off-by: Kui-Feng Lee <thinker.li@gmail.com>\nLink: https://lore.kernel.org/r/20240126023113.1379504-1-thinker.li@gmail.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Fix NULL pointer checks for bpf_get_btf_vmlinux() in bpf_struct_ops_map_alloc.,"NULL, ENOTSUPP, struct_ops",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
be4840b33eb2ea7d80830530aab5fcbeaa90e857,be4840b33eb2ea7d80830530aab5fcbeaa90e857,Eduard Zingerman,eddyz87@gmail.com,1706239554,Alexei Starovoitov,ast@kernel.org,1706241452,84f56e6cb2fdbe64638b989d2cf7a1f94df5b809,c8632acf193beac64bbdaebef013368c480bf74f,"bpf: One more maintainer for libbpf and BPF selftests

I've been working on BPF verifier", BPF selftests and,"[' to some extent', '\nlibbpf', ' for some time. As suggested by Andrii and Alexei', '\nI humbly ask to add me to maintainers list:\n- As reviewer   for BPF [GENERAL]\n- As maintainer for BPF [LIBRARY]\n- As maintainer for BPF [SELFTESTS]\n\nThis patch adds dedicated entries to MAINTAINERS.\n\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20240126032554.9697-1-eddyz87@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Added an additional maintainer for libbpf and BPF selftests.,"maintainer, libbpf, selftests",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ce36ea754051cfae39eabd841f907de0e8d8a6b7,ce36ea754051cfae39eabd841f907de0e8d8a6b7,Jakub Kicinski,kuba@kernel.org,1706227164,Jakub Kicinski,kuba@kernel.org,1706227165,965e547493fc98430faa22c5c62678935754dfee,b64787840080bdbd048bb9c68222ad17236cbd7e 4acffb66630a0e4800880baa61a54ef18047ccd3,"Merge branch 'selftests-net-a-few-fixes'

Paolo Abeni says:

====================
selftests: net: a few fixes

This series address self-tests failures for udp gro-related tests.

The first patch addresses the main problem I observe locally - the XDP
program required by such tests", xdp_dummy,"[' is currently build in the\nebpf self-tests directory', ' not available if/when the user targets net\nonly. Arguably is more a refactor than a fix', ' but still targeting net\nto hopefully\n\nThe second patch fixes the integration of such tests with the build\nsystem.\n\nPatch 3/3 fixes sporadic failures due to races.\n\nTested with:\n\nmake -C tools/testing/selftests/ TARGETS=net install\n./tools/testing/selftests/kselftest_install/run_kselftest.sh \\\n\t-t ""net:udpgro_bench.sh net:udpgro.sh net:udpgro_fwd.sh \\\n\t    net:udpgro_frglist.sh net:veth.sh""\n\nno failures.\n====================\n\nLink: https://lore.kernel.org/r/cover.1706131762.git.pabeni@redhat.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",This commit integrates a series of fixes for self-tests related to udp gro and XDP programs.,"self-tests, udp, XDP",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['xdp like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
98cb12eb52a780e682bea8372fdb2912c08132dd,98cb12eb52a780e682bea8372fdb2912c08132dd,Paolo Abeni,pabeni@redhat.com,1706132000,Jakub Kicinski,kuba@kernel.org,1706227162,b02b00f3fe5c800af62c6560bd47f96d4aec1a41,b64787840080bdbd048bb9c68222ad17236cbd7e,"selftests: net: remove dependency on ebpf tests

Several net tests requires an XDP program build under the ebpf
directory"," and error out if such program is not available.

That makes running successful net test hard","["" let's duplicate into the\nnet dir the [very small] program"", ' re-using the existing rules to build\nit', ' and finally dropping the bogus dependency.\n\nSigned-off-by: Paolo Abeni <pabeni@redhat.com>\nReviewed-by: Willem de Bruijn <willemb@google.com>\nLink: https://lore.kernel.org/r/28e7af7c031557f691dc8045ee41dd549dd5e74c.1706131762.git.pabeni@redhat.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",The commit removes the dependency of net tests on building XDP programs in the ebpf directory.,"selftests, net, dependency",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['xdp like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ecb1b8288dc7ccbdcb3b9df005fa1c0e0c0388a7,ecb1b8288dc7ccbdcb3b9df005fa1c0e0c0388a7,Linus Torvalds,torvalds@linux-foundation.org,1706209115,Linus Torvalds,torvalds@linux-foundation.org,1706209115,0079bb506b44bd5add46812c38ec0addf34078a7,bdc010200eb5e2cddf1c76c83386bdde8aad0899 0a5bd0ffe790511d802e7f40898429a89e2487df,"Merge tag 'net-6.8-rc2' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Paolo Abeni:
 ""Including fixes from bpf"," netfilter and WiFi.

  Jakub is doing a lot of work to include the self-tests in our CI","[' as a\n  result a significant amount of self-tests related fixes is flowing in\n  (and will likely continue in the next few weeks).\n\n  Current release - regressions:\n\n   - bpf: fix a kernel crash for the riscv 64 JIT\n\n   - bnxt_en: fix memory leak in bnxt_hwrm_get_rings()\n\n   - revert ""net: macsec: use skb_ensure_writable_head_tail to expand\n     the skb""\n\n  Previous releases - regressions:\n\n   - core: fix removing a namespace with conflicting altnames\n\n   - tc/flower: fix chain template offload memory leak\n\n   - tcp:\n      - make sure init the accept_queue\'s spinlocks once\n      - fix autocork on CPUs with weak memory model\n\n   - udp: fix busy polling\n\n   - mlx5e:\n      - fix out-of-bound read in port timestamping\n      - fix peer flow lists corruption\n\n   - iwlwifi: fix a memory corruption\n\n  Previous releases - always broken:\n\n   - netfilter:\n      - nft_chain_filter: handle NETDEV_UNREGISTER for inet/ingress\n        basechain\n      - nft_limit: reject configurations that cause integer overflow\n\n   - bpf: fix bpf_xdp_adjust_tail() with XSK zero-copy mbuf', ' avoiding a\n     NULL pointer dereference upon shrinking\n\n   - llc: make llc_ui_sendmsg() more robust against bonding changes\n\n   - smc: fix illegal rmb_desc access in SMC-D connection dump\n\n   - dpll: fix pin dump crash for rebound module\n\n   - bnxt_en: fix possible crash after creating sw mqprio TCs\n\n   - hv_netvsc: calculate correct ring size when PAGE_SIZE is not 4kB\n\n  Misc:\n\n   - several self-tests fixes for better integration with the netdev CI\n\n   - added several missing modules descriptions""\n\n* tag \'net-6.8-rc2\' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (88 commits)\n  tsnep: Fix XDP_RING_NEED_WAKEUP for empty fill ring\n  tsnep: Remove FCS for XDP data path\n  net: fec: fix the unhandled context fault from smmu\n  selftests: bonding: do not test arp/ns target with mode balance-alb/tlb\n  fjes: fix memleaks in fjes_hw_setup\n  i40e: update xdp_rxq_info::frag_size for ZC enabled Rx queue\n  i40e: set xdp_rxq_info::frag_size\n  xdp: reflect tail increase for MEM_TYPE_XSK_BUFF_POOL\n  ice: update xdp_rxq_info::frag_size for ZC enabled Rx queue\n  intel: xsk: initialize skb_frag_t::bv_offset in ZC drivers\n  ice: remove redundant xdp_rxq_info registration\n  i40e: handle multi-buffer packets that are shrunk by xdp prog\n  ice: work on pre-XDP prog frag count\n  xsk: fix usage of multi-buffer BPF helpers for ZC XDP\n  xsk: make xsk_buff_pool responsible for clearing xdp_buff::flags\n  xsk: recycle buffer in case Rx queue was full\n  net: fill in MODULE_DESCRIPTION()s for rvu_mbox\n  net: fill in MODULE_DESCRIPTION()s for litex\n  net: fill in MODULE_DESCRIPTION()s for fsl_pq_mdio\n  net: fill in MODULE_DESCRIPTION()s for fec\n  ...\n', '']",Merge networking fixes including BPF improvements in net-6.8-rc2.,"Merge, networking, BPF",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).', 'tc/netfilter like programs', 'other']"
fdf8e6d18c6dcc0421d65aa6382f5a4fa0050149,fdf8e6d18c6dcc0421d65aa6382f5a4fa0050149,Paolo Abeni,pabeni@redhat.com,1706178631,Paolo Abeni,pabeni@redhat.com,1706178631,9c1a9a11efd243b907652499fb22b8d5125b947c,5e344807735023cd3a67c37a1852b849caa42620 9d71bc833f57a6549c753e37ce47136d35b67fc4,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Daniel Borkmann says:

====================
pull-request: bpf 2024-01-25

The following pull-request contains BPF updates for your *net* tree.

We've added 12 non-merge commits during the last 2 day(s) which contain
a total of 13 files changed", 190 insertions(+),"[' 91 deletions(-).\n\nThe main changes are:\n\n1) Fix bpf_xdp_adjust_tail() in context of XSK zero-copy drivers which\n   support XDP multi-buffer. The former triggered a NULL pointer\n   dereference upon shrinking', ' from Maciej Fijalkowski & Tirthendu Sarkar.\n\n2) Fix a bug in riscv64 BPF JIT which emitted a wrong prologue and\n   epilogue for struct_ops programs', "" from Pu Lehui.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  i40e: update xdp_rxq_info::frag_size for ZC enabled Rx queue\n  i40e: set xdp_rxq_info::frag_size\n  xdp: reflect tail increase for MEM_TYPE_XSK_BUFF_POOL\n  ice: update xdp_rxq_info::frag_size for ZC enabled Rx queue\n  intel: xsk: initialize skb_frag_t::bv_offset in ZC drivers\n  ice: remove redundant xdp_rxq_info registration\n  i40e: handle multi-buffer packets that are shrunk by xdp prog\n  ice: work on pre-XDP prog frag count\n  xsk: fix usage of multi-buffer BPF helpers for ZC XDP\n  xsk: make xsk_buff_pool responsible for clearing xdp_buff::flags\n  xsk: recycle buffer in case Rx queue was full\n  riscv"", ' bpf: Fix unpredictable kernel crash about RV64 struct_ops\n====================\n\nLink: https://lore.kernel.org/r/20240125084416.10876-1-daniel@iogearbox.net\nSigned-off-by: Paolo Abeni <pabeni@redhat.com>\n', '']","Merged BPF updates into the net tree, adding 12 commits over 13 files.","BPF, merge, net",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9d71bc833f57a6549c753e37ce47136d35b67fc4,9d71bc833f57a6549c753e37ce47136d35b67fc4,Alexei Starovoitov,ast@kernel.org,1706142247,Alexei Starovoitov,ast@kernel.org,1706142247,ef22ef695dcfca8d7ce9ac5222ebbd98a634560c,1732ebc4a26181c8f116c7639db99754b313edc8 0cbb08707c932b3f004bc1a8ec6200ef572c1f5f,"Merge branch 'net-bpf_xdp_adjust_tail-and-intel-mbuf-fixes'

Maciej Fijalkowski says:

====================
net: bpf_xdp_adjust_tail() and Intel mbuf fixes

Hey","

after a break followed by dealing with sickness","[' here is a v6 that makes\nbpf_xdp_adjust_tail() actually usable for ZC drivers that support XDP\nmulti-buffer. Since v4 I tried also using bpf_xdp_adjust_tail() with\npositive offset which exposed yet another issues', ' which can be observed\nby increased commit count when compared to v3.\n\nJohn', ' in the end I think we should remove handling\nMEM_TYPE_XSK_BUFF_POOL from __xdp_return()', ' but it is out of the scope\nfor fixes set', ' IMHO.\n\nThanks', '\nMaciej\n\nv6:\n- add acks [Magnus]\n- fix spelling mistakes [Magnus]\n- avoid touching xdp_buff in xp_alloc_{reused', 'new_from_fq}() [Magnus]\n- s/shrink_data/bpf_xdp_shrink_data [Jakub]\n- remove __shrink_data() [Jakub]\n- check retvals from __xdp_rxq_info_reg() [Magnus]\n\nv5:\n- pick correct version of patch 5 [Simon]\n- elaborate a bit more on what patch 2 fixes\n\nv4:\n- do not clear frags flag when deleting tail; xsk_buff_pool now does\n  that\n- skip some NULL tests for xsk_buff_get_tail [Martin', ' John]\n- address problems around registering xdp_rxq_info\n- fix bpf_xdp_frags_increase_tail() for ZC mbuf\n\nv3:\n- add acks\n- s/xsk_buff_tail_del/xsk_buff_del_tail\n- address i40e as well (thanks Tirthendu)\n\nv2:\n- fix !CONFIG_XDP_SOCKETS builds\n- add reviewed-by tag to patch 3\n====================\n\nLink: https://lore.kernel.org/r/20240124191602.566724-1-maciej.fijalkowski@intel.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Merge of branch containing fixes for bpf_xdp_adjust_tail and Intel mbuf.,"bpf_xdp_adjust_tail,Intel,fixes",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,['xdp like programs']
fbadd83a612c3b7aad2987893faca6bd24aaebb3,fbadd83a612c3b7aad2987893faca6bd24aaebb3,Maciej Fijalkowski,maciej.fijalkowski@intel.com,1706123760,Alexei Starovoitov,ast@kernel.org,1706142247,d8b7dc0009593267cd7895da2301e00306da5731,3de38c87174225487fc93befeea7d380db80aef6,"xdp: reflect tail increase for MEM_TYPE_XSK_BUFF_POOL

XSK ZC Rx path calculates the size of data that will be posted to XSK Rx
queue via subtracting xdp_buff::data_end from xdp_buff::data.

In bpf_xdp_frags_increase_tail()"," when underlying memory type of
xdp_rxq_info is MEM_TYPE_XSK_BUFF_POOL","[' add offset to data_end in tail\nfragment', ' so that later on user space will be able to take into account\nthe amount of bytes added by XDP program.\n\nFixes: 24ea50127ecf (""xsk: support mbuf on ZC RX"")\nSigned-off-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>\nLink: https://lore.kernel.org/r/20240124191602.566724-10-maciej.fijalkowski@intel.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Reflects tail increase in XDP path for MEM_TYPE_XSK_BUFF_POOL in XSK zero-copy RX path.,"XDP, XSK, buffer",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,['xdp like programs']
290779905d09d5fdf6caa4f58ddefc3f4db0c0a9,290779905d09d5fdf6caa4f58ddefc3f4db0c0a9,Maciej Fijalkowski,maciej.fijalkowski@intel.com,1706123758,Alexei Starovoitov,ast@kernel.org,1706142247,0ff7833f4804e35e127494553bef3a3b4aa83112,2ee788c06493d02ee85855414cca39825e768aaf,"intel: xsk: initialize skb_frag_t::bv_offset in ZC drivers

Ice and i40e ZC drivers currently set offset of a frag within
skb_shared_info to 0"," which is incorrect. xdp_buffs that come from
xsk_buff_pool always have 256 bytes of a headroom","[' so they need to be\ntaken into account to retrieve xdp_buff::data via skb_frag_address().\nOtherwise', ' bpf_xdp_frags_increase_tail() would be starting its job from\nxdp_buff::data_hard_start which would result in overwriting existing\npayload.\n\nFixes: 1c9ba9c14658 (""i40e: xsk: add RX multi-buffer support"")\nFixes: 1bbc04de607b (""ice: xsk: add RX multi-buffer support"")\nAcked-by: Magnus Karlsson <magnus.karlsson@intel.com>\nSigned-off-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>\nLink: https://lore.kernel.org/r/20240124191602.566724-8-maciej.fijalkowski@intel.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Initialize skb_frag_t::bv_offset in Ice and i40e ZC drivers to ensure correct skb_shared_info handling.,"ZC drivers,skb_frag_t,offset",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['xdp like programs']
2ee788c06493d02ee85855414cca39825e768aaf,2ee788c06493d02ee85855414cca39825e768aaf,Maciej Fijalkowski,maciej.fijalkowski@intel.com,1706123757,Alexei Starovoitov,ast@kernel.org,1706142246,8aa66f5fcc39f0312c7f261f26268e241bf43c51,83014323c642b8faa2d64a5f303b41c019322478,"ice: remove redundant xdp_rxq_info registration

xdp_rxq_info struct can be registered by drivers via two functions -
xdp_rxq_info_reg() and __xdp_rxq_info_reg(). The latter one allows
drivers that support XDP multi-buffer to set up xdp_rxq_info::frag_size
which in turn will make it possible to grow the packet via
bpf_xdp_adjust_tail() BPF helper.

Currently"," ice registers xdp_rxq_info in two spots:
1) ice_setup_rx_ring() // via xdp_rxq_info_reg()","[' BUG\n2) ice_vsi_cfg_rxq()   // via __xdp_rxq_info_reg()', ' OK\n\nCited commit under fixes tag took care of setting up frag_size and\nupdated registration scheme in 2) but it did not help as\n1) is called before 2) and as shown above it uses old registration\nfunction. This means that 2) sees that xdp_rxq_info is already\nregistered and never calls __xdp_rxq_info_reg() which leaves us with\nxdp_rxq_info::frag_size being set to 0.\n\nTo fix this misbehavior', ' simply remove xdp_rxq_info_reg() call from\nice_setup_rx_ring().\n\nFixes: 2fba7dc5157b (""ice: Add support for XDP multi-buffer on Rx side"")\nAcked-by: Magnus Karlsson <magnus.karlsson@intel.com>\nSigned-off-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>\nLink: https://lore.kernel.org/r/20240124191602.566724-7-maciej.fijalkowski@intel.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Remove redundant xdp_rxq_info registration in the ice driver to optimize XDP multi-buffer usage.,"xdp_rxq_info, ice, XDP",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['xdp like programs']
83014323c642b8faa2d64a5f303b41c019322478,83014323c642b8faa2d64a5f303b41c019322478,Tirthendu Sarkar,tirthendu.sarkar@intel.com,1706123756,Alexei Starovoitov,ast@kernel.org,1706142246,2bfb6d09ea8288c8c84cafac9b3bd8930d6cba85,ad2047cf5d9313200e308612aed516548873d124,"i40e: handle multi-buffer packets that are shrunk by xdp prog

XDP programs can shrink packets by calling the bpf_xdp_adjust_tail()
helper function. For multi-buffer packets this may lead to reduction of
frag count stored in skb_shared_info area of the xdp_buff struct. This
results in issues with the current handling of XDP_PASS and XDP_DROP
cases.

For XDP_PASS"," currently skb is being built using frag count of
xdp_buffer before it was processed by XDP prog and thus will result in
an inconsistent skb when frag count gets reduced by XDP prog. To fix
this","[' get correct frag count while building the skb instead of using\npre-obtained frag count.\n\nFor XDP_DROP', ' current page recycling logic will not reuse the page but\ninstead will adjust the pagecnt_bias so that the page can be freed. This\nagain results in inconsistent behavior as the page refcnt has already\nbeen changed by the helper while freeing the frag(s) as part of\nshrinking the packet. To fix this', ' only adjust pagecnt_bias for buffers\nthat are stillpart of the packet post-xdp prog run.\n\nFixes: e213ced19bef (""i40e: add support for XDP multi-buffer Rx"")\nReported-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>\nSigned-off-by: Tirthendu Sarkar <tirthendu.sarkar@intel.com>\nLink: https://lore.kernel.org/r/20240124191602.566724-6-maciej.fijalkowski@intel.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix handling of multi-buffer packets that are shrunk by XDP programs in the i40e driver.,"XDP, multi-buffer, i40e",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The syscall interface,['xdp like programs']
ad2047cf5d9313200e308612aed516548873d124,ad2047cf5d9313200e308612aed516548873d124,Maciej Fijalkowski,maciej.fijalkowski@intel.com,1706123755,Alexei Starovoitov,ast@kernel.org,1706142246,072a44e3d79d4a2093430b2cc5073aedcd106f3b,c5114710c8ce86b8317e9b448f4fd15c711c2a82,"ice: work on pre-XDP prog frag count

Fix an OOM panic in XDP_DRV mode when a XDP program shrinks a
multi-buffer packet by 4k bytes and then redirects it to an AF_XDP
socket.

Since support for handling multi-buffer frames was added to XDP"," usage
of bpf_xdp_adjust_tail() helper within XDP program can free the page
that given fragment occupies and in turn decrease the fragment count
within skb_shared_info that is embedded in xdp_buff struct. In current
ice driver codebase","[' it can become problematic when page recycling logic\ndecides not to reuse the page. In such case', ' __page_frag_cache_drain()\nis used with ice_rx_buf::pagecnt_bias that was not adjusted after\nrefcount of page was changed by XDP prog which in turn does not drain\nthe refcount to 0 and page is never freed.\n\nTo address this', ' let us store the count of frags before the XDP program\nwas executed on Rx ring struct. This will be used to compare with\ncurrent frag count from skb_shared_info embedded in xdp_buff. A smaller\nvalue in the latter indicates that XDP prog freed frag(s). Then', ' for\ngiven delta decrement pagecnt_bias for XDP_DROP verdict.\n\nWhile at it', ' let us also handle the EOP frag within\nice_set_rx_bufs_act() to make our life easier', ' so all of the adjustments\nneeded to be applied against freed frags are performed in the single\nplace.\n\nFixes: 2fba7dc5157b (""ice: Add support for XDP multi-buffer on Rx side"")\nAcked-by: Magnus Karlsson <magnus.karlsson@intel.com>\nSigned-off-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>\nLink: https://lore.kernel.org/r/20240124191602.566724-5-maciej.fijalkowski@intel.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes an OOM panic issue when shrinking multi-buffer packets in XDP_DRV mode for the ice driver.,"OOM panic,XDP_DRV,multi-buffer",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['xdp like programs']
c5114710c8ce86b8317e9b448f4fd15c711c2a82,c5114710c8ce86b8317e9b448f4fd15c711c2a82,Maciej Fijalkowski,maciej.fijalkowski@intel.com,1706123754,Alexei Starovoitov,ast@kernel.org,1706142246,e2ee89bdcbbf9b34c3a32ff0a5fd97bb3dbde6ba,f7f6aa8e24383fbb11ac55942e66da9660110f80,"xsk: fix usage of multi-buffer BPF helpers for ZC XDP

Currently when packet is shrunk via bpf_xdp_adjust_tail() and memory
type is set to MEM_TYPE_XSK_BUFF_POOL"," null ptr dereference happens:

[1136314.192256] BUG: kernel NULL pointer dereference","[' address:\n0000000000000034\n[1136314.203943] #PF: supervisor read access in kernel mode\n[1136314.213768] #PF: error_code(0x0000) - not-present page\n[1136314.223550] PGD 0 P4D 0\n[1136314.230684] Oops: 0000 [#1] PREEMPT SMP NOPTI\n[1136314.239621] CPU: 8 PID: 54203 Comm: xdpsock Not tainted 6.6.0+ #257\n[1136314.250469] Hardware name: Intel Corporation S2600WFT/S2600WFT', '\nBIOS SE5C620.86B.02.01.0008.031920191559 03/19/2019\n[1136314.265615] RIP: 0010:__xdp_return+0x6c/0x210\n[1136314.274653] Code: ad 00 48 8b 47 08 49 89 f8 a8 01 0f 85 9b 01 00 00 0f 1f 44 00 00 f0 41 ff 48 34 75 32 4c 89 c7 e9 79 cd 80 ff 83 fe 03 75 17 <f6> 41 34 01 0f 85 02 01 00 00 48 89 cf e9 22 cc 1e 00 e9 3d d2 86\n[1136314.302907] RSP: 0018:ffffc900089f8db0 EFLAGS: 00010246\n[1136314.312967] RAX: ffffc9003168aed0 RBX: ffff8881c3300000 RCX:\n0000000000000000\n[1136314.324953] RDX: 0000000000000000 RSI: 0000000000000003 RDI:\nffffc9003168c000\n[1136314.336929] RBP: 0000000000000ae0 R08: 0000000000000002 R09:\n0000000000010000\n[1136314.348844] R10: ffffc9000e495000 R11: 0000000000000040 R12:\n0000000000000001\n[1136314.360706] R13: 0000000000000524 R14: ffffc9003168aec0 R15:\n0000000000000001\n[1136314.373298] FS:  00007f8df8bbcb80(0000) GS:ffff8897e0e00000(0000)\nknlGS:0000000000000000\n[1136314.386105] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[1136314.396532] CR2: 0000000000000034 CR3: 00000001aa912002 CR4:\n00000000007706f0\n[1136314.408377] DR0: 0000000000000000 DR1: 0000000000000000 DR2:\n0000000000000000\n[1136314.420173] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7:\n0000000000000400\n[1136314.431890] PKRU: 55555554\n[1136314.439143] Call Trace:\n[1136314.446058]  <IRQ>\n[1136314.452465]  ? __die+0x20/0x70\n[1136314.459881]  ? page_fault_oops+0x15b/0x440\n[1136314.468305]  ? exc_page_fault+0x6a/0x150\n[1136314.476491]  ? asm_exc_page_fault+0x22/0x30\n[1136314.484927]  ? __xdp_return+0x6c/0x210\n[1136314.492863]  bpf_xdp_adjust_tail+0x155/0x1d0\n[1136314.501269]  bpf_prog_ccc47ae29d3b6570_xdp_sock_prog+0x15/0x60\n[1136314.511263]  ice_clean_rx_irq_zc+0x206/0xc60 [ice]\n[1136314.520222]  ? ice_xmit_zc+0x6e/0x150 [ice]\n[1136314.528506]  ice_napi_poll+0x467/0x670 [ice]\n[1136314.536858]  ? ttwu_do_activate.constprop.0+0x8f/0x1a0\n[1136314.546010]  __napi_poll+0x29/0x1b0\n[1136314.553462]  net_rx_action+0x133/0x270\n[1136314.561619]  __do_softirq+0xbe/0x28e\n[1136314.569303]  do_softirq+0x3f/0x60\n\nThis comes from __xdp_return() call with xdp_buff argument passed as\nNULL which is supposed to be consumed by xsk_buff_free() call.\n\nTo address this properly', ' in ZC case', ' a node that represents the frag\nbeing removed has to be pulled out of xskb_list. Introduce\nappropriate xsk helpers to do such node operation and use them\naccordingly within bpf_xdp_adjust_tail().\n\nFixes: 24ea50127ecf (""xsk: support mbuf on ZC RX"")\nAcked-by: Magnus Karlsson <magnus.karlsson@intel.com> # For the xsk header part\nSigned-off-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>\nLink: https://lore.kernel.org/r/20240124191602.566724-4-maciej.fijalkowski@intel.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes null pointer dereference in xsk multi-buffer BPF helpers for ZC XDP.,"xsk, multi-buffer, BPF helpers",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['xdp like programs']
f7f6aa8e24383fbb11ac55942e66da9660110f80,f7f6aa8e24383fbb11ac55942e66da9660110f80,Maciej Fijalkowski,maciej.fijalkowski@intel.com,1706123753,Alexei Starovoitov,ast@kernel.org,1706142246,81c548183db7e624ea9b3287a8cc5041a3ea831d,269009893146c495f41e9572dd9319e787c2eba9,"xsk: make xsk_buff_pool responsible for clearing xdp_buff::flags

XDP multi-buffer support introduced XDP_FLAGS_HAS_FRAGS flag that is
used by drivers to notify data path whether xdp_buff contains fragments
or not. Data path looks up mentioned flag on first buffer that occupies
the linear part of xdp_buff"," so drivers only modify it there. This is
sufficient for SKB and XDP_DRV modes as usually xdp_buff is allocated on
stack or it resides within struct representing driver's queue and
fragments are carried via skb_frag_t structs. IOW","[' we are dealing with\nonly one xdp_buff.\n\nZC mode though relies on list of xdp_buff structs that is carried via\nxsk_buff_pool::xskb_list', ' so ZC data path has to make sure that\nfragments do *not* have XDP_FLAGS_HAS_FRAGS set. Otherwise', '\nxsk_buff_free() could misbehave if it would be executed against xdp_buff\nthat carries a frag with XDP_FLAGS_HAS_FRAGS flag set. Such scenario can\ntake place when within supplied XDP program bpf_xdp_adjust_tail() is\nused with negative offset that would in turn release the tail fragment\nfrom multi-buffer frame.\n\nCalling xsk_buff_free() on tail fragment with XDP_FLAGS_HAS_FRAGS would\nresult in releasing all the nodes from xskb_list that were produced by\ndriver before XDP program execution', ' which is not what is intended -\nonly tail fragment should be deleted from xskb_list and then it should\nbe put onto xsk_buff_pool::free_list. Such multi-buffer frame will never\nmake it up to user space', ' so from AF_XDP application POV there would be\nno traffic running', ' however due to free_list getting constantly new\nnodes', ' driver will be able to feed HW Rx queue with recycled buffers.\nBottom line is that instead of traffic being redirected to user space', '\nit would be continuously dropped.\n\nTo fix this', ' let us clear the mentioned flag on xsk_buff_pool side\nduring xdp_buff initialization', ' which is what should have been done\nright from the start of XSK multi-buffer support.\n\nFixes: 1bbc04de607b (""ice: xsk: add RX multi-buffer support"")\nFixes: 1c9ba9c14658 (""i40e: xsk: add RX multi-buffer support"")\nFixes: 24ea50127ecf (""xsk: support mbuf on ZC RX"")\nSigned-off-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>\nLink: https://lore.kernel.org/r/20240124191602.566724-3-maciej.fijalkowski@intel.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit ensures xsk_buff_pool handles the clearing of xdp_buff::flags for XDP multi-buffer support.,"xdp_buff, xsk_buff_pool, flags",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,['xdp like programs']
c8632acf193beac64bbdaebef013368c480bf74f,c8632acf193beac64bbdaebef013368c480bf74f,Andrii Nakryiko,andrii@kernel.org,1706125378,Alexei Starovoitov,ast@kernel.org,1706142063,d9b85c5c1cc0518b3c7d98fbd814a4aa51b636d5,c9f115564561af63db662791e9a35fcf1dfefd2a 906ee42cb1be1152ef24465704cc89edc3f571c1,"Merge branch 'bpf-token'

Andrii Nakryiko says:

====================
BPF token

This patch set is a combination of three BPF token-related patch sets ([0]","
[1]","[' [2]) with fixes ([3]) to kernel-side token_fd passing APIs incorporated\ninto relevant patches', ' bpf_token_capable() changes requested by\nChristian Brauner', ' and necessary libbpf and BPF selftests side adjustments.\n\nThis patch set introduces an ability to delegate a subset of BPF subsystem\nfunctionality from privileged system-wide daemon (e.g.', ' systemd or any other\ncontainer manager) through special mount options for userns-bound BPF FS to\na *trusted* unprivileged application. Trust is the key here. This\nfunctionality is not about allowing unconditional unprivileged BPF usage.\nEstablishing trust', ' though', ' is completely up to the discretion of respective\nprivileged application that would create and mount a BPF FS instance with\ndelegation enabled', ' as different production setups can and do achieve it\nthrough a combination of different means (signing', ' LSM', ' code reviews', ' etc)', ""\nand it's undesirable and infeasible for kernel to enforce any particular way\nof validating trustworthiness of particular process.\n\nThe main motivation for this work is a desire to enable containerized BPF\napplications to be used together with user namespaces. This is currently\nimpossible"", ' as CAP_BPF', ' required for BPF subsystem usage', ' cannot be namespaced\nor sandboxed', ' as a general rule. E.g.', ' tracing BPF programs', ' thanks to BPF\nhelpers like bpf_probe_read_kernel() and bpf_probe_read_user() can safely read\narbitrary memory', "" and it's impossible to ensure that they only read memory of\nprocesses belonging to any given namespace. This means that it's impossible to\nhave a mechanically verifiable namespace-aware CAP_BPF capability"", ' and as such\nanother mechanism to allow safe usage of BPF functionality is necessary.\n\nBPF FS delegation mount options and BPF token derived from such BPF FS instance\nis such a mechanism. Kernel makes no assumption about what ""trusted""\nconstitutes in any particular case', "" and it's up to specific privileged\napplications and their surrounding infrastructure to decide that. What kernel\nprovides is a set of APIs to setup and mount special BPF FS instance and\nderive BPF tokens from it. BPF FS and BPF token are both bound to its owning\nuserns and in such a way are constrained inside intended container. Users can\nthen pass BPF token FD to privileged bpf() syscall commands"", ' like BPF map\ncreation and BPF program loading', ' to perform such operations without having\ninit userns privileges.\n\nThis version incorporates feedback and suggestions ([4]) received on earlier\niterations of BPF token approach', ' and instead of allowing to create BPF tokens\ndirectly assuming capable(CAP_SYS_ADMIN)', ' we instead enhance BPF FS to accept\na few new delegation mount options. If these options are used and BPF FS itself\nis properly created', ' set up', ' and mounted inside the user namespaced container', '\nuser application is able to derive a BPF token object from BPF FS instance', ' and\npass that token to bpf() syscall. As explained in patch #3', "" BPF token itself\ndoesn't grant access to BPF functionality"", ' but instead allows kernel to do\nnamespaced capabilities checks (ns_capable() vs capable()) for CAP_BPF', '\nCAP_PERFMON', ' CAP_NET_ADMIN', ' and CAP_SYS_ADMIN', ' as applicable. So it forms one\nhalf of a puzzle and allows container managers and sys admins to have safe and\nflexible configuration options: determining which containers get delegation of\nBPF functionality through BPF FS', ' and then which applications within such\ncontainers are allowed to perform bpf() commands', ' based on namespaces\ncapabilities.\n\nPrevious attempt at addressing this very same problem ([5]) attempted to\nutilize authoritative LSM approach', ' but was conclusively rejected by upstream\nLSM maintainers. BPF token concept is not changing anything about LSM\napproach', ' but can be combined with LSM hooks for very fine-grained security\npolicy. Some ideas about making BPF token more convenient to use with LSM (in\nparticular custom BPF LSM programs) was briefly described in recent LSF/MM/BPF\n2023 presentation ([6]). E.g.', ' an ability to specify user-provided data\n(context)', ' which in combination with BPF LSM would allow implementing a very\ndynamic and fine-granular custom security policies on top of BPF token. In the\ninterest of minimizing API surface area and discussions this was relegated to\nfollow up patches', "" as it's not essential to the fundamental concept of\ndelegatable BPF token.\n\nIt should be noted that BPF token is conceptually quite similar to the idea of\n/dev/bpf device file"", ' proposed by Song a while ago ([7]). The biggest\ndifference is the idea of using virtual anon_inode file to hold BPF token and\nallowing multiple independent instances of them', ' each (potentially) with its\nown set of restrictions. And also', ' crucially', ' BPF token approach is not using\nany special stateful task-scoped flags. Instead', ' bpf() syscall accepts\ntoken_fd parameters explicitly for each relevant BPF command. This addresses\nmain concerns brought up during the /dev/bpf discussion', "" and fits better with\noverall BPF subsystem design.\n\nSecond part of this patch set adds full support for BPF token in libbpf's BPF\nobject high-level API. Good chunk of the changes rework libbpf feature\ndetection internals"", ' which are the most affected by BPF token presence.\n\nBesides internal refactorings', ' libbpf allows to pass location of BPF FS from\nwhich BPF token should be created by libbpf. This can be done explicitly though\na new bpf_object_open_opts.bpf_token_path field. But we also add implicit BPF\ntoken creation logic to BPF object load step', ' even without any explicit\ninvolvement of the user. If the environment is setup properly', ' BPF token will\nbe created transparently and used implicitly. This allows for all existing\napplication to gain BPF token support by just linking with latest version of\nlibbpf library. No source code modifications are required.  All that under\nassumption that privileged container management agent properly set up default\nBPF FS instance at /sys/bpf/fs to allow BPF token creation.\n\nlibbpf adds support to override default BPF FS location for BPF token creation\nthrough LIBBPF_BPF_TOKEN_PATH envvar knowledge. This allows admins or container\nmanagers to mount BPF token-enabled BPF FS at non-standard location without the\nneed to coordinate with applications.  LIBBPF_BPF_TOKEN_PATH can also be used\nto disable BPF token implicit creation by setting it to an empty value.\n\n  [0] https://patchwork.kernel.org/project/netdevbpf/list/?series=805707&state=*\n  [1] https://patchwork.kernel.org/project/netdevbpf/list/?series=810260&state=*\n  [2] https://patchwork.kernel.org/project/netdevbpf/list/?series=809800&state=*\n  [3] https://patchwork.kernel.org/project/netdevbpf/patch/20231219053150.336991-1-andrii@kernel.org/\n  [4] https://lore.kernel.org/bpf/20230704-hochverdient-lehne-eeb9eeef785e@brauner/\n  [5] https://lore.kernel.org/bpf/20230412043300.360803-1-andrii@kernel.org/\n  [6] http://vger.kernel.org/bpfconf2023_material/Trusted_unprivileged_BPF_LSFMM2023.pdf\n  [7] https://lore.kernel.org/bpf/20190627201923.2589391-2-songliubraving@fb.com/\n\nv1->v2:\n  - disable BPF token creation in init userns', ' and simplify\n    bpf_token_capable() logic (Christian);\n  - use kzalloc/kfree instead of kvzalloc/kvfree (Linus);\n  - few more selftest cases to validate LSM and BPF token interations.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n====================\n\nLink: https://lore.kernel.org/r/20240124022127.2379740-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Merge and integrate BPF token-related patch sets into the main branch.,"BPF, token, merge",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
906ee42cb1be1152ef24465704cc89edc3f571c1,906ee42cb1be1152ef24465704cc89edc3f571c1,Andrii Nakryiko,andrii@kernel.org,1706062887,Alexei Starovoitov,ast@kernel.org,1706142063,d9b85c5c1cc0518b3c7d98fbd814a4aa51b636d5,fadf54935e859c4d512aed6ad54f639b87a3b4d3,"selftests/bpf: Incorporate LSM policy to token-based tests

Add tests for LSM interactions (both bpf_token_capable and bpf_token_cmd
LSM hooks) with BPF token in bpf() subsystem. Now child process passes
back token FD for parent to be able to do tests with token originating
in ""wrong"" userns. But we also create token in initns and check that
token LSMs don't accidentally reject BPF operations when capable()
checks pass without BPF token.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/bpf/20240124022127.2379740-31-andrii@kernel.org
",,Adds tests for LSM interactions with BPF tokens in the bpf() subsystem.,"LSM,bpf,tests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['LSM like programs']
fadf54935e859c4d512aed6ad54f639b87a3b4d3,fadf54935e859c4d512aed6ad54f639b87a3b4d3,Andrii Nakryiko,andrii@kernel.org,1706062886,Alexei Starovoitov,ast@kernel.org,1706142063,04bafd43cb6fe0948b896ff162971f681cfc5994,cac270ad79afe212ed7986e8d271c72521cd8212,"selftests/bpf: Add tests for LIBBPF_BPF_TOKEN_PATH envvar

Add new subtest validating LIBBPF_BPF_TOKEN_PATH envvar semantics.
Extend existing test to validate that LIBBPF_BPF_TOKEN_PATH allows to
disable implicit BPF token creation by setting envvar to empty string.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/bpf/20240124022127.2379740-30-andrii@kernel.org
",,Add new tests for validating LIBBPF_BPF_TOKEN_PATH environment variable semantics in selftests.,"selftests,BPF,LIBBPF",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
cac270ad79afe212ed7986e8d271c72521cd8212,cac270ad79afe212ed7986e8d271c72521cd8212,Andrii Nakryiko,andrii@kernel.org,1706062885,Alexei Starovoitov,ast@kernel.org,1706142063,704597af62843f5a714b1c4668bf3d8ed2d81220,b73d08d1318a2dde5bacbab77d0e2fd2aa47c933,"libbpf: Support BPF token path setting through LIBBPF_BPF_TOKEN_PATH envvar

To allow external admin authority to override default BPF FS location
(/sys/fs/bpf) for implicit BPF token creation"," teach libbpf to recognize
LIBBPF_BPF_TOKEN_PATH envvar. If it is specified and user application
didn't explicitly specify bpf_token_path option","[' it will be treated\nexactly like bpf_token_path option', ' overriding default /sys/fs/bpf\nlocation and making BPF token mandatory.\n\nSuggested-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nLink: https://lore.kernel.org/bpf/20240124022127.2379740-29-andrii@kernel.org\n', '']",Add support for setting BPF token path via LIBBPF_BPF_TOKEN_PATH environment variable in libbpf.,"libbpf, envvar, BPF",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b73d08d1318a2dde5bacbab77d0e2fd2aa47c933,b73d08d1318a2dde5bacbab77d0e2fd2aa47c933,Andrii Nakryiko,andrii@kernel.org,1706062884,Alexei Starovoitov,ast@kernel.org,1706142063,0809ecfbdc0da2d20074ffb45e140dab820c7d54,d5baf0cac627fb3a00d9235955a388e5930b6d0e,"selftests/bpf: Add tests for BPF object load with implicit token

Add a test to validate libbpf's implicit BPF token creation from default
BPF FS location (/sys/fs/bpf). Also validate that disabling this
implicit BPF token creation works.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/bpf/20240124022127.2379740-28-andrii@kernel.org
",,Add tests for validating implicit BPF token creation and disabling in libbpf.,"tests, implicit token, libbpf",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d5baf0cac627fb3a00d9235955a388e5930b6d0e,d5baf0cac627fb3a00d9235955a388e5930b6d0e,Andrii Nakryiko,andrii@kernel.org,1706062883,Alexei Starovoitov,ast@kernel.org,1706142063,4cd6e9ced35654a88e0658976f8cf7fd1a39d63e,6b434b61b4d9e0e59f2947ce0f58f6fb4de048d8,"selftests/bpf: Add BPF object loading tests with explicit token passing

Add a few tests that attempt to load BPF object containing privileged
map", program,"[' and the one requiring mandatory BTF uploading into the\nkernel (to validate token FD propagation to BPF_BTF_LOAD command).\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nLink: https://lore.kernel.org/bpf/20240124022127.2379740-27-andrii@kernel.org\n', '']",Add tests to load BPF objects with explicit token passing in selftests.,"tests,BPF object,token passing",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6b434b61b4d9e0e59f2947ce0f58f6fb4de048d8,6b434b61b4d9e0e59f2947ce0f58f6fb4de048d8,Andrii Nakryiko,andrii@kernel.org,1706062882,Alexei Starovoitov,ast@kernel.org,1706142062,a0bcb278e5e454b2f0d16c1a38d265348f928364,f3dcee938f485cf403ba2acf1f1548afe637c904,"libbpf: Wire up BPF token support at BPF object level

Add BPF token support to BPF object-level functionality.

BPF token is supported by BPF object logic either as an explicitly
provided BPF token from outside (through BPF FS path)"," or implicitly
(unless prevented through bpf_object_open_opts).

Implicit mode is assumed to be the most common one for user namespaced
unprivileged workloads. The assumption is that privileged container
manager sets up default BPF FS mount point at /sys/fs/bpf with BPF token
delegation options (delegate_{cmds","['maps', 'progs', 'attachs} mount options).\nBPF object during loading will attempt to create BPF token from\n/sys/fs/bpf location', ' and pass it for all relevant operations\n(currently', ' map creation', ' BTF load', ' and program load).\n\nIn this implicit mode', ' if BPF token creation fails due to whatever\nreason (BPF FS is not mounted', "" or kernel doesn't support BPF token"", '\netc)', ' this is not considered an error. BPF object loading sequence will\nproceed with no BPF token.\n\nIn explicit BPF token mode', ' user provides explicitly custom BPF FS mount\npoint path. In such case', ' BPF object will attempt to create BPF token\nfrom provided BPF FS location. If BPF token creation fails', ' that is\nconsidered a critical error and BPF object load fails with an error.\n\nLibbpf provides a way to disable implicit BPF token creation', "" if it\ncauses any troubles (BPF token is designed to be completely optional and\nshouldn't cause any problems even if provided"", ' but in the world of BPF\nLSM', "" custom security logic can be installed that might change outcome\ndepending on the presence of BPF token). To disable libbpf's default BPF\ntoken creation behavior user should provide either invalid BPF token FD\n(negative)"", "" or empty bpf_token_path option.\n\nBPF token presence can influence libbpf's feature probing"", ' so if BPF\nobject has associated BPF token', ' feature probing is instructed to use\nBPF object-specific feature detection cache and token FD.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nLink: https://lore.kernel.org/bpf/20240124022127.2379740-26-andrii@kernel.org\n', '']",Add support for BPF token at the BPF object level in libbpf.,"BPF token, BPF object, libbpf",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f3dcee938f485cf403ba2acf1f1548afe637c904,f3dcee938f485cf403ba2acf1f1548afe637c904,Andrii Nakryiko,andrii@kernel.org,1706062881,Alexei Starovoitov,ast@kernel.org,1706142062,8bdb88a3455d9395770e6cca76eee597453bd33e,05f9cdd55d61cf9c6283fd3dc0edc7cad09bd7fe,"libbpf: Wire up token_fd into feature probing logic

Adjust feature probing callbacks to take into account optional token_fd.
In unprivileged contexts"," some feature detectors would fail to detect
kernel support just because BPF program","[' BPF map', "" or BTF object can't be\nloaded due to privileged nature of those operations. So when BPF object\nis loaded with BPF token"", ' this token should be used for feature probing.\n\nThis patch is setting support for this scenario', "" but we don't yet pass\nnon-zero token FD. This will be added in the next patch.\n\nWe also switched BPF cookie detector from using kprobe program to\ntracepoint one"", ' as tracepoint is somewhat less dangerous BPF program\ntype and has higher likelihood of being allowed through BPF token in the\nfuture. This change has no effect on detection behavior.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nLink: https://lore.kernel.org/bpf/20240124022127.2379740-25-andrii@kernel.org\n', '']",Adjust feature probing logic to incorporate optional token_fd in unprivileged contexts.,"libbpf, token_fd, feature-probing",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
05f9cdd55d61cf9c6283fd3dc0edc7cad09bd7fe,05f9cdd55d61cf9c6283fd3dc0edc7cad09bd7fe,Andrii Nakryiko,andrii@kernel.org,1706062880,Alexei Starovoitov,ast@kernel.org,1706142062,beee721bec04ba2a6e3e9a21adfd8183827ca4d3,d6dd1d49367ab03832b3c4b6f8211765d488c82b,"libbpf: Move feature detection code into its own file

It's quite a lot of well isolated code"," so it seems like a good
candidate to move it out of libbpf.c to reduce its size.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/bpf/20240124022127.2379740-24-andrii@kernel.org
",[''],Refactored libbpf by moving feature detection code to a separate file to reduce libbpf.c size.,"libbpf,refactoring,feature detection",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d6dd1d49367ab03832b3c4b6f8211765d488c82b,d6dd1d49367ab03832b3c4b6f8211765d488c82b,Andrii Nakryiko,andrii@kernel.org,1706062879,Alexei Starovoitov,ast@kernel.org,1706142062,09255745717e9116be414f12956f0e854eb15dde,ea4d587354eb5e32dfa93cebb055b072f518b193,"libbpf: Further decouple feature checking logic from bpf_object

Add feat_supported() helper that accepts feature cache instead of
bpf_object. This allows low-level code in bpf.c to not know or care
about higher-level concept of bpf_object"," yet it will be able to utilize
custom feature checking in cases where BPF token might influence the
outcome.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/bpf/20240124022127.2379740-23-andrii@kernel.org
",[''],The commit adds a feat_supported() helper to decouple feature checking logic from bpf_object in libbpf.,"feat_supported, feature checking, libbpf",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ea4d587354eb5e32dfa93cebb055b072f518b193,ea4d587354eb5e32dfa93cebb055b072f518b193,Andrii Nakryiko,andrii@kernel.org,1706062878,Alexei Starovoitov,ast@kernel.org,1706142062,c017487dd6721f90b5be6d2be7b78aba4ddedf17,0350f9d99ee538f2ccf179f0216e704a5f39b317,"libbpf: Split feature detectors definitions from cached results

Split a list of supported feature detectors with their corresponding
callbacks from actual cached supported/missing values. This will allow
to have more flexible per-token or per-object feature detectors in
subsequent refactorings.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/bpf/20240124022127.2379740-22-andrii@kernel.org
",,The commit refactors libbpf feature detectors to separate definitions from cached results for improved flexibility.,"libbpf,refactoring,feature detectors",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0350f9d99ee538f2ccf179f0216e704a5f39b317,0350f9d99ee538f2ccf179f0216e704a5f39b317,Andrii Nakryiko,andrii@kernel.org,1706062877,Alexei Starovoitov,ast@kernel.org,1706142062,8b393c90f699150e64a07a9e1eae7d15cc6707ca,6c1752e0b6ca8c7021d6da3926738d8d88f601a9,"selftests/bpf: Utilize string values for delegate_xxx mount options

Use both hex-based and string-based way to specify delegate mount
options for BPF FS.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/bpf/20240124022127.2379740-21-andrii@kernel.org
",,The commit updates selftests to support string values for delegate mount options in BPF file system.,"selftests, BPF FS, mount options",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6c1752e0b6ca8c7021d6da3926738d8d88f601a9,6c1752e0b6ca8c7021d6da3926738d8d88f601a9,Andrii Nakryiko,andrii@kernel.org,1706062876,Alexei Starovoitov,ast@kernel.org,1706142062,c5c26149ea47fdc30c6d7395c71878b9fcf03968,aeaa97b006ddc7a8bf13e4adfdd02b3526f648a7,"bpf: Support symbolic BPF FS delegation mount options

Besides already supported special ""any"" value and hex bit mask"," support
string-based parsing of delegation masks based on exact enumerator
names. Utilize BTF information of `enum bpf_cmd`","[' `enum bpf_map_type`', '\n`enum bpf_prog_type`', ' and `enum bpf_attach_type` types to find supported\nsymbolic names (ignoring __MAX_xxx guard values and stripping repetitive\nprefixes like BPF_ for cmd and attach types', ' BPF_MAP_TYPE_ for maps', "" and\nBPF_PROG_TYPE_ for prog types). The case doesn't matter"", ' but it is\nnormalized to lower case in mount option output. So ""PROG_LOAD""', '\n""prog_load""', ' and ""MAP_create"" are all valid values to specify for\ndelegate_cmds options', ' ""array"" is among supported for map types', ' etc.\n\nBesides supporting string values', ' we also support multiple values\nspecified at the same time', "" using colon (':') separator.\n\nThere are corresponding changes on bpf_show_options side to use known\nvalues to print them in human-readable format"", ' falling back to hex mask\nprinting', "" if there are any unrecognized bits. This shouldn't be\nnecessary when enum BTF information is present"", ' but in general we should\nalways be able to fall back to this even if kernel was built without BTF.\nAs mentioned', ' emitted symbolic names are normalized to be all lower case.\n\nExample below shows various ways to specify delegate_cmds options\nthrough mount command and how mount options are printed back:\n\n12/14 14:39:07.604\nvmuser@archvm:~/local/linux/tools/testing/selftests/bpf\n$ mount | rg token\n\n  $ sudo mkdir -p /sys/fs/bpf/token\n  $ sudo mount -t bpf bpffs /sys/fs/bpf/token \\\n               -o delegate_cmds=prog_load:MAP_CREATE \\\n               -o delegate_progs=kprobe \\\n               -o delegate_attachs=xdp\n  $ mount | grep token\n  bpffs on /sys/fs/bpf/token type bpf (rw', 'relatime', 'delegate_cmds=map_create:prog_load', 'delegate_progs=kprobe', 'delegate_attachs=xdp)\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nLink: https://lore.kernel.org/bpf/20240124022127.2379740-20-andrii@kernel.org\n', '']",Enhance BPF FS mount options to support symbolic delegation masks using BTF enum information.,"BPF, symbolic, delegation",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
aeaa97b006ddc7a8bf13e4adfdd02b3526f648a7,aeaa97b006ddc7a8bf13e4adfdd02b3526f648a7,Andrii Nakryiko,andrii@kernel.org,1706062875,Alexei Starovoitov,ast@kernel.org,1706142062,b3ccdcf15c0f24c2ba9ecaf3d3b1808984dfefaa,0054493e5141b16e316b8c52d6aa534397e48b6c,"bpf: Fail BPF_TOKEN_CREATE if no delegation option was set on BPF FS

It's quite confusing in practice when it's possible to successfully
create a BPF token from BPF FS that didn't have any of delegate_xxx
mount options set up. While it's not wrong"," it's actually more
meaningful to reject BPF_TOKEN_CREATE with specific error code (-ENOENT)
to let user-space know that no token delegation is setup up.

So","["" instead of creating empty BPF token that will be always ignored\nbecause it doesn't have any of the allow_xxx bits set"", ' reject it with\n-ENOENT. If we ever need empty BPF token to be possible', ' we can support\nthat with extra flag passed into BPF_TOKEN_CREATE.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nAcked-by: Christian Brauner <brauner@kernel.org>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nLink: https://lore.kernel.org/bpf/20240124022127.2379740-19-andrii@kernel.org\n', '']",Fail BPF_TOKEN_CREATE if no delegation option is set on BPF FS to provide meaningful user-space error.,"BPF_TOKEN_CREATE,delegation,ENOENT",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The syscall interface,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0054493e5141b16e316b8c52d6aa534397e48b6c,0054493e5141b16e316b8c52d6aa534397e48b6c,Andrii Nakryiko,andrii@kernel.org,1706062874,Alexei Starovoitov,ast@kernel.org,1706142062,045ff7cf45922b3eeeca0ddfc2ee440666f9519f,fcb9597ff7d1f7c772c1237dd2d04dd44e622501,bpf,"selinux: Allocate bpf_security_struct per BPF token

Utilize newly added bpf_token_create/bpf_token_free LSM hooks to
allocate struct bpf_security_struct for each BPF token object in
SELinux. This just follows similar pattern for BPF prog and map.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/bpf/20240124022127.2379740-18-andrii@kernel.org
",[''],Add LSM hooks to allocate security structure for BPF token objects in SELinux.,"LSM hooks, SELinux, BPF",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['LSM like programs']
fcb9597ff7d1f7c772c1237dd2d04dd44e622501,fcb9597ff7d1f7c772c1237dd2d04dd44e622501,Andrii Nakryiko,andrii@kernel.org,1706062873,Alexei Starovoitov,ast@kernel.org,1706142062,dc73432da5e07a162b44ab6c0636b10ea2e2aa9e,404cbc149c3866e6ec2bfe1bce52c8864e1f81fc,"selftests/bpf: Add BPF token-enabled tests

Add a selftest that attempts to conceptually replicate intended BPF
token use cases inside user namespaced container.

Child process is forked. It is then put into its own userns and mountns.
Child creates BPF FS context object. This ensures child userns is
captured as the owning userns for this instance of BPF FS. Given setting
delegation mount options is privileged operation"," we ensure that child
cannot set them.

This context is passed back to privileged parent process through Unix
socket","[' where parent sets up delegation options', ' creates', ' and mounts it\nas a detached mount. This mount FD is passed back to the child to be\nused for BPF token creation', ' which allows otherwise privileged BPF\noperations to succeed inside userns.\n\nWe validate that all of token-enabled privileged commands (BPF_BTF_LOAD', '\nBPF_MAP_CREATE', ' and BPF_PROG_LOAD) work as intended. They should only\nsucceed inside the userns if a) BPF token is provided with proper\nallowed sets of commands and types; and b) namespaces CAP_BPF and other\nprivileges are set. Lacking a) or b) should lead to -EPERM failures.\n\nBased on suggested workflow by Christian Brauner ([0]).\n\n  [0] https://lore.kernel.org/bpf/20230704-hochverdient-lehne-eeb9eeef785e@brauner/\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nLink: https://lore.kernel.org/bpf/20240124022127.2379740-17-andrii@kernel.org\n', '']",This commit adds selftests for BPF token use cases within user namespaced containers.,"selftests,BPF,userns",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
404cbc149c3866e6ec2bfe1bce52c8864e1f81fc,404cbc149c3866e6ec2bfe1bce52c8864e1f81fc,Andrii Nakryiko,andrii@kernel.org,1706062872,Alexei Starovoitov,ast@kernel.org,1706142062,49a6a98483bd7c85310c86a867a735fb7c747f83,a3d63e85253b6c9b6aa34b99208e835358a91320,"libbpf: Add BPF token support to bpf_prog_load() API

Wire through token_fd into bpf_prog_load().

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/bpf/20240124022127.2379740-16-andrii@kernel.org
",,Add BPF token support in libbpf library's bpf_prog_load() API.,"BPF token support, bpf_prog_load, libbpf",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a3d63e85253b6c9b6aa34b99208e835358a91320,a3d63e85253b6c9b6aa34b99208e835358a91320,Andrii Nakryiko,andrii@kernel.org,1706062871,Alexei Starovoitov,ast@kernel.org,1706142062,fdf847731b6ff09709d6974714e7a49a48dd241f,364f848375af311150210a1ad3c5bcb800b65b48,"libbpf: Add BPF token support to bpf_btf_load() API

Allow user to specify token_fd for bpf_btf_load() API that wraps
kernel's BPF_BTF_LOAD command. This allows loading BTF from unprivileged
process as long as it has BPF token allowing BPF_BTF_LOAD command"," which
can be created and delegated by privileged process.

Wire through new btf_flags as well","[' so that user can provide\nBPF_F_TOKEN_FD flag', ' if necessary.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nLink: https://lore.kernel.org/bpf/20240124022127.2379740-15-andrii@kernel.org\n', '']",Adds BPF token support to the bpf_btf_load() API for unprivileged process access to BPF_BTF_LOAD.,"BPF token support, bpf_btf_load API, unprivileged access",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
364f848375af311150210a1ad3c5bcb800b65b48,364f848375af311150210a1ad3c5bcb800b65b48,Andrii Nakryiko,andrii@kernel.org,1706062870,Alexei Starovoitov,ast@kernel.org,1706142061,acdf69ee43fa21a47b81f24c6f0e961382ca5a91,639ecd7d6247c48a0175f5b458b648f5d4b6dc34,"libbpf: Add BPF token support to bpf_map_create() API

Add ability to provide token_fd for BPF_MAP_CREATE command through
bpf_map_create() API.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/bpf/20240124022127.2379740-14-andrii@kernel.org
",,Added support for providing token_fd in BPF_MAP_CREATE using bpf_map_create() API in libbpf.,"libbpf, BPF token, bpf_map_create",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
639ecd7d6247c48a0175f5b458b648f5d4b6dc34,639ecd7d6247c48a0175f5b458b648f5d4b6dc34,Andrii Nakryiko,andrii@kernel.org,1706062869,Alexei Starovoitov,ast@kernel.org,1706142061,1ebb6c82e96c2b0fd9af87770ce333c6be45191e,f568a3d49af9aed813a184353592efe29b0e3d16,"libbpf: Add bpf_token_create() API

Add low-level wrapper API for BPF_TOKEN_CREATE command in bpf() syscall.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/bpf/20240124022127.2379740-13-andrii@kernel.org
",,Introduced bpf_token_create() API as a low-level wrapper for BPF_TOKEN_CREATE syscall.,"bpf_token_create, API, syscall",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['socket like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f568a3d49af9aed813a184353592efe29b0e3d16,f568a3d49af9aed813a184353592efe29b0e3d16,Andrii Nakryiko,andrii@kernel.org,1706062868,Alexei Starovoitov,ast@kernel.org,1706142061,0a3490cd91384780d1c045b2c5df6b7904f53384,a2431c7eabcf9bd5a1e7a1f7ecded40fdda4a8c5,bpf,"lsm: Add BPF token LSM hooks

Wire up bpf_token_create and bpf_token_free LSM hooks","[' which allow to\nallocate LSM security blob (we add `void *security` field to struct\nbpf_token for that)', "" but also control who can instantiate BPF token.\nThis follows existing pattern for BPF map and BPF prog.\n\nAlso add security_bpf_token_allow_cmd() and security_bpf_token_capable()\nLSM hooks that allow LSM implementation to control and negate (if\nnecessary) BPF token's delegation of a specific bpf_cmd and capability"", '\nrespectively.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nAcked-by: Paul Moore <paul@paul-moore.com>\nLink: https://lore.kernel.org/bpf/20240124022127.2379740-12-andrii@kernel.org\n', '']",Introduce LSM hooks for bpf_token_create and bpf_token_free in BPF.,"LSM hooks, bpf_token_create, bpf_token_free",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['LSM like programs']
a2431c7eabcf9bd5a1e7a1f7ecded40fdda4a8c5,a2431c7eabcf9bd5a1e7a1f7ecded40fdda4a8c5,Andrii Nakryiko,andrii@kernel.org,1706062867,Alexei Starovoitov,ast@kernel.org,1706142061,fff1b6e0aa61984bc2c2aea9ddaac2a1b95780f9,1b67772e4e3f16cd647b229cae95fc06d120be08,bpf,"lsm: Refactor bpf_map_alloc/bpf_map_free LSM hooks

Similarly to bpf_prog_alloc LSM hook","[' rename and extend bpf_map_alloc\nhook into bpf_map_create', ' taking not just struct bpf_map', ' but also\nbpf_attr and bpf_token', ' to give a fuller context to LSMs.\n\nUnlike bpf_prog_alloc', ' there is no need to move the hook around', ' as it\ncurrently is firing right before allocating BPF map ID and FD', ' which\nseems to be a sweet spot.\n\nBut like bpf_prog_alloc/bpf_prog_free combo', ' make sure that bpf_map_free\nLSM hook is called even if bpf_map_create hook returned error', ' as if few\nLSMs are combined together it could be that one LSM successfully\nallocated security blob for its needs', ' while subsequent LSM rejected BPF\nmap creation. The former LSM would still need to free up LSM blob', ' so we\nneed to ensure security_bpf_map_free() is called regardless of the\noutcome.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nAcked-by: Paul Moore <paul@paul-moore.com>\nLink: https://lore.kernel.org/bpf/20240124022127.2379740-11-andrii@kernel.org\n', '']",Refactor bpf_map_alloc and bpf_map_free LSM hooks for consistency with bpf_prog_alloc.,"refactor,bpf_map_alloc,LSM",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,['LSM like programs']
1b67772e4e3f16cd647b229cae95fc06d120be08,1b67772e4e3f16cd647b229cae95fc06d120be08,Andrii Nakryiko,andrii@kernel.org,1706062866,Alexei Starovoitov,ast@kernel.org,1706142061,a6d7ab948fcd8d3f138e2f7b67fcf4c0cfe18a45,d79a3549754725bb90e58104417449edddf3da3d,bpf,"lsm: Refactor bpf_prog_alloc/bpf_prog_free LSM hooks

Based on upstream discussion ([0])","[' rework existing\nbpf_prog_alloc_security LSM hook. Rename it to bpf_prog_load and instead\nof passing bpf_prog_aux', ' pass proper bpf_prog pointer for a full BPF\nprogram struct. Also', ' we pass bpf_attr union with all the user-provided\narguments for BPF_PROG_LOAD command.  This will give LSMs as much\ninformation as we can basically provide.\n\nThe hook is also BPF token-aware now', ' and optional bpf_token struct is\npassed as a third argument. bpf_prog_load LSM hook is called after\na bunch of sanity checks were performed', ' bpf_prog and bpf_prog_aux were\nallocated and filled out', ' but right before performing full-fledged BPF\nverification step.\n\nbpf_prog_free LSM hook is now accepting struct bpf_prog argument', ' for\nconsistency. SELinux code is adjusted to all new names', ' types', ' and\nsignatures.\n\nNote', ' given that bpf_prog_load (previously bpf_prog_alloc) hook can be\nused by some LSMs to allocate extra security blob', ' but also by other\nLSMs to reject BPF program loading', "" we need to make sure that\nbpf_prog_free LSM hook is called after bpf_prog_load/bpf_prog_alloc one\n*even* if the hook itself returned error. If we don't do that"", ' we run\nthe risk of leaking memory. This seems to be possible today when\ncombining SELinux and BPF LSM', ' as one example', ' depending on their\nrelative ordering.\n\nAlso', ' for BPF LSM setup', ' add bpf_prog_load and bpf_prog_free to\nsleepable LSM hooks list', ' as they are both executed in sleepable\ncontext. Also drop bpf_prog_load hook from untrusted', ' as there is no\nissue with refcount or anything else anymore', ' that originally forced us\nto add it to untrusted list in c0c852dd1876 (""bpf: Do not mark certain LSM\nhook arguments as trusted""). We now trigger this hook much later and it\nshould not be an issue anymore.\n\n  [0] https://lore.kernel.org/bpf/9fe88aef7deabbe87d3fc38c4aea3c69.paul@paul-moore.com/\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nAcked-by: Paul Moore <paul@paul-moore.com>\nLink: https://lore.kernel.org/bpf/20240124022127.2379740-10-andrii@kernel.org\n', '']",Refactor LSM hooks for bpf_prog_alloc and bpf_prog_free functions.,"LSM hooks, refactor, allocation",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['LSM like programs']
d79a3549754725bb90e58104417449edddf3da3d,d79a3549754725bb90e58104417449edddf3da3d,Andrii Nakryiko,andrii@kernel.org,1706062865,Alexei Starovoitov,ast@kernel.org,1706142061,dbcb8b033e1d9bc85127d229aa6d7bd3b933e356,bbc1d24724e110b86a1a7c3c1724ce0d62cc1e2e,"bpf: Consistently use BPF token throughout BPF verifier logic

Remove remaining direct queries to perfmon_capable() and bpf_capable()
in BPF verifier logic and instead use BPF token (if available) to make
decisions about privileges.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/bpf/20240124022127.2379740-9-andrii@kernel.org
",,The commit updates the BPF verifier to consistently use BPF tokens for privilege checks.,"BPF token, verifier, privileges",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
bbc1d24724e110b86a1a7c3c1724ce0d62cc1e2e,bbc1d24724e110b86a1a7c3c1724ce0d62cc1e2e,Andrii Nakryiko,andrii@kernel.org,1706062864,Alexei Starovoitov,ast@kernel.org,1706142061,b9fdd4d3c3693de18200ab474b48566137367e86,caf8f28e036c4ba1e823355da6c0c01c39e70ab9,"bpf: Take into account BPF token when fetching helper protos

Instead of performing unconditional system-wide bpf_capable() and
perfmon_capable() calls inside bpf_base_func_proto() function (and other
similar ones) to determine eligibility of a given BPF helper for a given
program"," use previously recorded BPF token during BPF_PROG_LOAD command
handling to inform the decision.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/bpf/20240124022127.2379740-8-andrii@kernel.org
",[''],The commit enhances BPF helper eligibility check using BPF token instead of global capability checks.,"BPF token, helper protos, eligibility",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
caf8f28e036c4ba1e823355da6c0c01c39e70ab9,caf8f28e036c4ba1e823355da6c0c01c39e70ab9,Andrii Nakryiko,andrii@kernel.org,1706062863,Alexei Starovoitov,ast@kernel.org,1706142061,bc60a1165bbbf9e13a1fa840f27298af3cbee67d,9ea7c4bf17e39d463eb4782f948f401d9764b1b3,"bpf: Add BPF token support to BPF_PROG_LOAD command

Add basic support of BPF token to BPF_PROG_LOAD. BPF_F_TOKEN_FD flag
should be set in prog_flags field when providing prog_token_fd.

Wire through a set of allowed BPF program types and attach types","
derived from BPF FS at BPF token creation time. Then make sure we
perform bpf_token_capable() checks everywhere where it's relevant.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/bpf/20240124022127.2379740-7-andrii@kernel.org
",[''],Add BPF token support to BPF_PROG_LOAD command with required security checks.,"BPF token, BPF_PROG_LOAD, prog_flags",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The syscall interface,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9ea7c4bf17e39d463eb4782f948f401d9764b1b3,9ea7c4bf17e39d463eb4782f948f401d9764b1b3,Andrii Nakryiko,andrii@kernel.org,1706062862,Alexei Starovoitov,ast@kernel.org,1706142061,9cf0cc9d7b7ceb2ec8b7b2fe37baa0b5ce0bd30c,a177fc2bf6fd83704854feaf7aae926b1df4f0b9,"bpf: Add BPF token support to BPF_BTF_LOAD command

Accept BPF token FD in BPF_BTF_LOAD command to allow BTF data loading
through delegated BPF token. BPF_F_TOKEN_FD flag has to be specified
when passing BPF token FD. Given BPF_BTF_LOAD command didn't have flags
field before"," we also add btf_flags field.

BTF loading is a pretty straightforward operation","[' so as long as BPF\ntoken is created with allow_cmds granting BPF_BTF_LOAD command', ' kernel\nproceeds to parsing BTF data and creating BTF object.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nLink: https://lore.kernel.org/bpf/20240124022127.2379740-6-andrii@kernel.org\n', '']",Add BPF token support to BPF_BTF_LOAD command for loading BTF data using delegated tokens.,"BPF token, BTF_LOAD, delegation",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a177fc2bf6fd83704854feaf7aae926b1df4f0b9,a177fc2bf6fd83704854feaf7aae926b1df4f0b9,Andrii Nakryiko,andrii@kernel.org,1706062861,Alexei Starovoitov,ast@kernel.org,1706142061,74cafa2a721c24e10f9cbbeacd7acf518584edcb,35f96de04127d332a5c5e8a155d31f452f88c76d,"bpf: Add BPF token support to BPF_MAP_CREATE command

Allow providing token_fd for BPF_MAP_CREATE command to allow controlled
BPF map creation from unprivileged process through delegated BPF token.
New BPF_F_TOKEN_FD flag is added to specify together with BPF token FD
for BPF_MAP_CREATE command.

Wire through a set of allowed BPF map types to BPF token"," derived from
BPF FS at BPF token creation time. This","[' in combination with allowed_cmds\nallows to create a narrowly-focused BPF token (controlled by privileged\nagent) with a restrictive set of BPF maps that application can attempt\nto create.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nLink: https://lore.kernel.org/bpf/20240124022127.2379740-5-andrii@kernel.org\n', '']",This commit adds BPF token support for controlled map creation from unprivileged processes in the BPF_MAP_CREATE command.,"BPF token, BPF_MAP_CREATE, unprivileged",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The syscall interface,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
35f96de04127d332a5c5e8a155d31f452f88c76d,35f96de04127d332a5c5e8a155d31f452f88c76d,Andrii Nakryiko,andrii@kernel.org,1706062860,Alexei Starovoitov,ast@kernel.org,1706142061,20e268d6358835f0caf0cf82e47e95746c92b465,6fe01d3cbb924a72493eb3f4722dfcfd1c194234,"bpf: Introduce BPF token object

Add new kind of BPF kernel object"," BPF token. BPF token is meant to
allow delegating privileged BPF functionality","[' like loading a BPF\nprogram or creating a BPF map', ' from privileged process to a *trusted*\nunprivileged process', ' all while having a good amount of control over which\nprivileged operations could be performed using provided BPF token.\n\nThis is achieved through mounting BPF FS instance with extra delegation\nmount options', ' which determine what operations are delegatable', ' and also\nconstraining it to the owning user namespace (as mentioned in the\nprevious patch).\n\nBPF token itself is just a derivative from BPF FS and can be created\nthrough a new bpf() syscall command', ' BPF_TOKEN_CREATE', ' which accepts BPF\nFS FD', ' which can be attained through open() API by opening BPF FS mount\npoint. Currently', ' BPF token ""inherits"" delegated command', ' map types', '\nprog type', ' and attach type bit sets from BPF FS as is. In the future', '\nhaving an BPF token as a separate object with its own FD', "" we can allow\nto further restrict BPF token's allowable set of things either at the\ncreation time or after the fact"", ' allowing the process to guard itself\nfurther from unintentionally trying to load undesired kind of BPF\nprograms. But for now we keep things simple and just copy bit sets as is.\n\nWhen BPF token is created from BPF FS mount', "" we take reference to the\nBPF super block's owning user namespace"", ' and then use that namespace for\nchecking all the {CAP_BPF', ' CAP_PERFMON', ' CAP_NET_ADMIN', ' CAP_SYS_ADMIN}\ncapabilities that are normally only checked against init userns (using\ncapable())', ' but now we check them using ns_capable() instead (if BPF\ntoken is provided). See bpf_token_capable() for details.\n\nSuch setup means that BPF token in itself is not sufficient to grant BPF\nfunctionality. User namespaced process has to *also* have necessary\ncombination of capabilities inside that user namespace. So while\npreviously CAP_BPF was useless when granted within user namespace', ' now\nit gains a meaning and allows container managers and sys admins to have\na flexible control over which processes can and need to use BPF\nfunctionality within the user namespace (i.e.', ' container in practice).\nAnd BPF FS delegation mount options and derived BPF tokens serve as\na per-container ""flag"" to grant overall ability to use bpf() (plus further\nrestrict on which parts of bpf() syscalls are treated as namespaced).\n\nNote also', ' BPF_TOKEN_CREATE command itself requires ns_capable(CAP_BPF)\nwithin the BPF FS owning user namespace', ' rounding up the ns_capable()\nstory of BPF token. Also creating BPF token in init user namespace is\ncurrently not supported', "" given BPF token doesn't have any effect in init\nuser namespace anyways.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nAcked-by: Christian Brauner <brauner@kernel.org>\nLink: https://lore.kernel.org/bpf/20240124022127.2379740-4-andrii@kernel.org\n"", '']",Introduces a new BPF token object to delegate privileged BPF functionality.,"BPF token, kernel object, privileged functionality",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The syscall interface,['other']
6fe01d3cbb924a72493eb3f4722dfcfd1c194234,6fe01d3cbb924a72493eb3f4722dfcfd1c194234,Andrii Nakryiko,andrii@kernel.org,1706062859,Alexei Starovoitov,ast@kernel.org,1706142060,9388ec7de8315a4a262564b34206c192777ebc93,ed1ad5a7415de8be121055e7ab1303d2be5407e0,"bpf: Add BPF token delegation mount options to BPF FS

Add few new mount options to BPF FS that allow to specify that a given
BPF FS instance allows creation of BPF token (added in the next patch)","
and what sort of operations are allowed under BPF token. As such","[' we get\n4 new mount options', ' each is a bit mask\n  - `delegate_cmds` allow to specify which bpf() syscall commands are\n    allowed with BPF token derived from this BPF FS instance;\n  - if BPF_MAP_CREATE command is allowed', ' `delegate_maps` specifies\n    a set of allowable BPF map types that could be created with BPF token;\n  - if BPF_PROG_LOAD command is allowed', ' `delegate_progs` specifies\n    a set of allowable BPF program types that could be loaded with BPF token;\n  - if BPF_PROG_LOAD command is allowed', ' `delegate_attachs` specifies\n    a set of allowable BPF program attach types that could be loaded with\n    BPF token; delegate_progs and delegate_attachs are meant to be used\n    together', ' as full BPF program type is', ' in general', ' determined\n    through both program type and program attach type.\n\nCurrently', ' these mount options accept the following forms of values:\n  - a special value ""any""', ' that enables all possible values of a given\n  bit set;\n  - numeric value (decimal or hexadecimal', ' determined by kernel\n  automatically) that specifies a bit mask value directly;\n  - all the values for a given mount option are combined', ' if specified\n  multiple times. E.g.', ' `mount -t bpf nodev /path/to/mount -o\n  delegate_maps=0x1 -o delegate_maps=0x2` will result in a combined 0x3\n  mask.\n\nIdeally', ' more convenient (for humans) symbolic form derived from\ncorresponding UAPI enums would be accepted (e.g.', ' `-o\ndelegate_progs=kprobe|tracepoint`) and I intend to implement this', ' but\nit requires a bunch of UAPI header churn', ' so I postponed it until this\nfeature lands upstream or at least there is a definite consensus that\nthis feature is acceptable and is going to make it', ' just to minimize\namount of wasted effort and not increase amount of non-essential code to\nbe reviewed.\n\nAttentive reader will notice that BPF FS is now marked as\nFS_USERNS_MOUNT', ' which theoretically makes it mountable inside non-init\nuser namespace as long as the process has sufficient *namespaced*\ncapabilities within that user namespace. But in reality we still\nrestrict BPF FS to be mountable only by processes with CAP_SYS_ADMIN *in\ninit userns* (extra check in bpf_fill_super()). FS_USERNS_MOUNT is added\nto allow creating BPF FS context object (i.e.', ' fsopen(""bpf"")) from\ninside unprivileged process inside non-init userns', ' to capture that\nuserns as the owning userns. It will still be required to pass this\ncontext object back to privileged process to instantiate and mount it.\n\nThis manipulation is important', ' because capturing non-init userns as the\nowning userns of BPF FS instance (super block) allows to use that userns\nto constraint BPF token to that userns later on (see next patch). So\ncreating BPF FS with delegation inside unprivileged userns will restrict\nderived BPF token objects to only ""work"" inside that intended userns', '\nmaking it scoped to a intended ""container"". Also', ' setting these\ndelegation options requires capable(CAP_SYS_ADMIN)', ' so unprivileged\nprocess cannot set this up without involvement of a privileged process.\n\nThere is a set of selftests at the end of the patch set that simulates\nthis sequence of steps and validates that everything works as intended.\nBut careful review is requested to make sure there are no missed gaps in\nthe implementation and testing.\n\nThis somewhat subtle set of aspects is the result of previous\ndiscussions ([0]) about various user namespace implications and\ninteractions with BPF token functionality and is necessary to contain\nBPF token inside intended user namespace.\n\n  [0] https://lore.kernel.org/bpf/20230704-hochverdient-lehne-eeb9eeef785e@brauner/\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nAcked-by: Christian Brauner <brauner@kernel.org>\nLink: https://lore.kernel.org/bpf/20240124022127.2379740-3-andrii@kernel.org\n', '']",Add new mount options to BPF FS for BPF token delegation.,"BPF FS,mount options,token",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The syscall interface,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ed1ad5a7415de8be121055e7ab1303d2be5407e0,ed1ad5a7415de8be121055e7ab1303d2be5407e0,Andrii Nakryiko,andrii@kernel.org,1706062858,Alexei Starovoitov,ast@kernel.org,1706142060,b9da489b27e66f93b861aae564e7bb93d70939db,c9f115564561af63db662791e9a35fcf1dfefd2a,"bpf: Align CAP_NET_ADMIN checks with bpf_capable() approach

Within BPF syscall handling code CAP_NET_ADMIN checks stand out a bit
compared to CAP_BPF and CAP_PERFMON checks. For the latter"," CAP_BPF or
CAP_PERFMON are checked first","[' but if they are not set', ' CAP_SYS_ADMIN\ntakes over and grants whatever part of BPF syscall is required.\n\nSimilar kind of checks that involve CAP_NET_ADMIN are not so consistent.\nOne out of four uses does follow CAP_BPF/CAP_PERFMON model: during\nBPF_PROG_LOAD', ' if the type of BPF program is ""network-related"" either\nCAP_NET_ADMIN or CAP_SYS_ADMIN is required to proceed.\n\nBut in three other cases CAP_NET_ADMIN is required even if CAP_SYS_ADMIN\nis set:\n  - when creating DEVMAP/XDKMAP/CPU_MAP maps;\n  - when attaching CGROUP_SKB programs;\n  - when handling BPF_PROG_QUERY command.\n\nThis patch is changing the latter three cases to follow BPF_PROG_LOAD\nmodel', ' that is allowing to proceed under either CAP_NET_ADMIN or\nCAP_SYS_ADMIN.\n\nThis also makes it cleaner in subsequent BPF token patches to switch\nwholesomely to a generic bpf_token_capable(int cap) check', ' that always\nfalls back to CAP_SYS_ADMIN if requested capability is missing.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nAcked-by: Yafang Shao <laoar.shao@gmail.com>\nLink: https://lore.kernel.org/bpf/20240124022127.2379740-2-andrii@kernel.org\n', '']",Aligns CAP_NET_ADMIN checks with existing bpf_capable() approach for consistency in BPF syscall handling.,"CAP_NET_ADMIN,bpf_capable,BPF",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The syscall interface,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c9f115564561af63db662791e9a35fcf1dfefd2a,c9f115564561af63db662791e9a35fcf1dfefd2a,Martin KaFai Lau,martin.lau@kernel.org,1706136258,Alexei Starovoitov,ast@kernel.org,1706141979,6806e7bb3c8becfd5478b199b0aaa4d8543515d0,ce6f6cffaeaa0a3bcdafcae7fe03c68c3afae631,"libbpf: Ensure undefined bpf_attr field stays 0

The commit 9e926acda0c2 (""libbpf: Find correct module BTFs for struct_ops maps and progs."")
sets a newly added field (value_type_btf_obj_fd) to -1 in libbpf when
the caller of the libbpf's bpf_map_create did not define this field by
passing a NULL ""opts"" or passing in a ""opts"" that does not cover this
new field. OPT_HAS(opts"," field) is used to decide if the field is
defined or not:

	((opts) && opts->sz >= offsetofend(typeof(*(opts))","[' field))\n\nOnce OPTS_HAS decided the field is not defined', ' that field should\nbe set to 0. For this particular new field (value_type_btf_obj_fd)', '\nits corresponding map_flags ""BPF_F_VTYPE_BTF_OBJ_FD"" is not set.\nThus', ' the kernel does not treat it as an fd field.\n\nFixes: 9e926acda0c2 (""libbpf: Find correct module BTFs for struct_ops maps and progs."")\nReported-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240124224418.2905133-1-martin.lau@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit ensures that undefined bpf_attr fields in libbpf remain zero to prevent unintended behavior.,"libbpf, bpf_attr, zero",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ce6f6cffaeaa0a3bcdafcae7fe03c68c3afae631,ce6f6cffaeaa0a3bcdafcae7fe03c68c3afae631,Martin KaFai Lau,martin.lau@kernel.org,1705730718,Andrii Nakryiko,andrii@kernel.org,1706119426,ff244dfc081b96282efd56f5a44fda09d3b16591,177f1d083a19af58f4b1206d299ed73689249fd8,"selftests/bpf: Wait for the netstamp_needed_key static key to be turned on

After the previous patch that speeded up the test (by avoiding neigh
discovery in IPv6)"," the BPF CI occasionally hits this error:

rcv tstamp unexpected pkt rcv tstamp: actual 0 == expected 0

The test complains about the cmsg returned from the recvmsg() does not
have the rcv timestamp. Setting skb->tstamp or not is
controlled by a kernel static key ""netstamp_needed_key"". The static
key is enabled whenever this is at least one sk with the SOCK_TIMESTAMP
set.

The test_redirect_dtime does use setsockopt() to turn on
the SOCK_TIMESTAMP for the reading sk. In the kernel
net_enable_timestamp() has a delay to enable the ""netstamp_needed_key""
when CONFIG_JUMP_LABEL is set. This potential delay is the likely reason
for packet missing rcv timestamp occasionally.

This patch is to create udp sockets with SOCK_TIMESTAMP set.
It sends and receives some packets until the received packet
has a rcv timestamp. It currently retries at most 5 times with 1s
in between. This should be enough to wait for the ""netstamp_needed_key"".
It then holds on to the socket and only closes it at the end of the test.
This guarantees that the test has the ""netstamp_needed_key"" key turned
on from the beginning.

To simplify the udp sockets setup","[' they are sending/receiving packets\nin the same netns (ns_dst is used) and communicate over the ""lo"" dev.\nHence', ' the patch enables the ""lo"" dev in the ns_dst.\n\nFixes: c803475fd8dd (""bpf: selftests: test skb->tstamp in redirect_neigh"")\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240120060518.3604920-2-martin.lau@linux.dev\n', '']",The commit updates selftests to ensure netstamp_needed_key static key is active for correct timestamping in tests.,"selftests, netstamp_needed_key, timestamp",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
177f1d083a19af58f4b1206d299ed73689249fd8,177f1d083a19af58f4b1206d299ed73689249fd8,Martin KaFai Lau,martin.lau@kernel.org,1705730717,Andrii Nakryiko,andrii@kernel.org,1706119426,8d1f4e2907ef8bca18cba5f404cda8cf7b7e85a5,d47b9f68d2899b390a3655f2365f332a63396adf,"selftests/bpf: Fix the flaky tc_redirect_dtime test

BPF CI has been reporting the tc_redirect_dtime test failing
from time to time:

test_inet_dtime:PASS:setns src 0 nsec
(network_helpers.c:253: errno: No route to host) Failed to connect to server
close_netns:PASS:setns 0 nsec
test_inet_dtime:FAIL:connect_to_fd unexpected connect_to_fd: actual -1 < expected 0
test_tcp_clear_dtime:PASS:tcp ip6 clear dtime ingress_fwdns_p100 0 nsec

The connect_to_fd failure (EHOSTUNREACH) is from the
test_tcp_clear_dtime() test and it is the very first IPv6 traffic
after setting up all the links", addresses,"[' and routes.\n\nThe symptom is this first connect() is always slow. In my setup', ' it\ncould take ~3s.\n\nAfter some tracing and tcpdump', ' the slowness is mostly spent in\nthe neighbor solicitation in the ""ns_fwd"" namespace while\nthe ""ns_src"" and ""ns_dst"" are fine.\n\nI forced the kernel to drop the neighbor solicitation messages.\nI can then reproduce EHOSTUNREACH. What actually happen could be:\n- the neighbor advertisement came back a little slow.\n- the ""ns_fwd"" namespace concluded a neighbor discovery failure\n  and triggered the ndisc_error_report() => ip6_link_failure() =>\n  icmpv6_send(skb', ' ICMPV6_DEST_UNREACH', ' ICMPV6_ADDR_UNREACH', ' 0)\n- the client\'s connect() reports EHOSTUNREACH after receiving\n  the ICMPV6_DEST_UNREACH message.\n\nThe neigh table of both ""ns_src"" and ""ns_dst"" namespace has already\nbeen manually populated but not the ""ns_fwd"" namespace. This patch\nfixes it by manually populating the neigh table also in the ""ns_fwd""\nnamespace.\n\nAlthough the namespace configuration part had been existed before\nthe tc_redirect_dtime test', ' still Fixes-tagging the patch when\nthe tc_redirect_dtime test was added since it is the only test\nhitting it so far.\n\nFixes: c803475fd8dd (""bpf: selftests: test skb->tstamp in redirect_neigh"")\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240120060518.3604920-1-martin.lau@linux.dev\n', '']",Fixes the flaky tc_redirect_dtime test in BPF selftests due to IPv6 traffic issues.,"flaky, tc_redirect_dtime, test",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['tc/netfilter like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d47b9f68d2899b390a3655f2365f332a63396adf,d47b9f68d2899b390a3655f2365f332a63396adf,Dima Tisnek,dimaqq@gmail.com,1705816886,Andrii Nakryiko,andrii@kernel.org,1706070597,723509362b741cbd2b96e158dc47245cff95ec47,32749605e3a9726f2cf277cbc032cf243c2da689,"libbpf: Correct bpf_core_read.h comment wrt bpf_core_relo struct

Past commit ([0]) removed the last vestiges of struct bpf_field_reloc","
it's called struct bpf_core_relo now.

  [0] 28b93c64499a (""libbpf: Clean up and improve CO-RE reloc logging"")

Signed-off-by: Dima Tisnek <dimaqq@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/bpf/20240121060126.15650-1-dimaqq@gmail.com
",[''],This commit corrects comments in libbpf related to struct bpf_core_relo.,"libbpf, comments, bpf_core_relo",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
32749605e3a9726f2cf277cbc032cf243c2da689,32749605e3a9726f2cf277cbc032cf243c2da689,Andrii Nakryiko,andrii@kernel.org,1706070378,Andrii Nakryiko,andrii@kernel.org,1706070486,f9509b14e129f75f49d815c7182f99c714da7ee3,8b593021319d4893a8fbeb7bd1f668657e68403c 0b50478fd8774f42721f4297293b711e17bc4b7b,"Merge branch 'skip-callback-tests-if-jit-is-disabled-in-test_verifier'

Tiezhu Yang says:

====================
Skip callback tests if jit is disabled in test_verifier

Thanks very much for the feedbacks from Eduard", John,"[' Jiri', ' Daniel', '\nHou Tao', ' Song Liu and Andrii.\n\nv7:\n  -- Add an explicit flag F_NEEDS_JIT_ENABLED for checking', '\n     thanks Andrii.\n\nv6:\n  -- Copy insn_is_pseudo_func() into testing_helpers', '\n     thanks Andrii.\n\nv5:\n  -- Reuse is_ldimm64_insn() and insn_is_pseudo_func()', '\n     thanks Song Liu.\n\nv4:\n  -- Move the not-allowed-checking into ""if (expected_ret ...)""\n     block', ' thanks Hou Tao.\n  -- Do some small changes to avoid checkpatch warning\n     about ""line length exceeds 100 columns"".\n\nv3:\n  -- Rebase on the latest bpf-next tree.\n  -- Address the review comments by Hou Tao', '\n     remove the second argument ""0"" of open()', '\n     check only once whether jit is disabled', '\n     check fd_prog', ' saved_errno and jit_disabled to skip.\n====================\n\nLink: https://lore.kernel.org/r/20240123090351.2207-1-yangtiezhu@loongson.cn\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n', '']",Skip eBPF callback tests in test_verifier when JIT is disabled.,"callback,JIT,test_verifier",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0b50478fd8774f42721f4297293b711e17bc4b7b,0b50478fd8774f42721f4297293b711e17bc4b7b,Tiezhu Yang,yangtiezhu@loongson.cn,1706000631,Andrii Nakryiko,andrii@kernel.org,1706070461,f9509b14e129f75f49d815c7182f99c714da7ee3,15b4f88dcc0a751f790bfea5ef9dcc6385c62236,"selftests/bpf: Skip callback tests if jit is disabled in test_verifier

If CONFIG_BPF_JIT_ALWAYS_ON is not set and bpf_jit_enable is 0"," there
exist 6 failed tests.

  [root@linux bpf]# echo 0 > /proc/sys/net/core/bpf_jit_enable
  [root@linux bpf]# echo 0 > /proc/sys/kernel/unprivileged_bpf_disabled
  [root@linux bpf]# ./test_verifier | grep FAIL
  #106/p inline simple bpf_loop call FAIL
  #107/p don't inline bpf_loop call","["" flags non-zero FAIL\n  #108/p don't inline bpf_loop call"", ' callback non-constant FAIL\n  #109/p bpf_loop_inline and a dead func FAIL\n  #110/p bpf_loop_inline stack locations for loop vars FAIL\n  #111/p inline bpf_loop call in a big program FAIL\n  Summary: 768 PASSED', ' 15 SKIPPED', ' 6 FAILED\n\nThe test log shows that callbacks are not allowed in non-JITed programs', ""\ninterpreter doesn't support them yet"", ' thus these tests should be skipped\nif jit is disabled.\n\nAdd an explicit flag F_NEEDS_JIT_ENABLED to those tests to mark that they\nrequire JIT enabled in bpf_loop_inline.c', ' check the flag and jit_disabled\nat the beginning of do_test_single() to handle this case.\n\nWith this patch:\n\n  [root@linux bpf]# echo 0 > /proc/sys/net/core/bpf_jit_enable\n  [root@linux bpf]# echo 0 > /proc/sys/kernel/unprivileged_bpf_disabled\n  [root@linux bpf]# ./test_verifier | grep FAIL\n  Summary: 768 PASSED', ' 21 SKIPPED', ' 0 FAILED\n\nSuggested-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Tiezhu Yang <yangtiezhu@loongson.cn>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20240123090351.2207-3-yangtiezhu@loongson.cn\n', '']",Skip callback tests in selftests/bpf if JIT is disabled in test_verifier.,"skip, JIT, tests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
15b4f88dcc0a751f790bfea5ef9dcc6385c62236,15b4f88dcc0a751f790bfea5ef9dcc6385c62236,Tiezhu Yang,yangtiezhu@loongson.cn,1706000630,Andrii Nakryiko,andrii@kernel.org,1706070377,166a41af24d6304c34d61e2f797bbaf07f1765f8,8b593021319d4893a8fbeb7bd1f668657e68403c,"selftests/bpf: Move is_jit_enabled() into testing_helpers

Currently", is_jit_enabled() is only used in test_progs,"[' move it into\ntesting_helpers so that it can be used in test_verifier. While at it', '\nremove the second argument ""0"" of open() as Hou Tao suggested.\n\nSigned-off-by: Tiezhu Yang <yangtiezhu@loongson.cn>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Hou Tao <houtao1@huawei.com>\nAcked-by: Song Liu <song@kernel.org>\nLink: https://lore.kernel.org/bpf/20240123090351.2207-2-yangtiezhu@loongson.cn\n', '']",The function is_jit_enabled() is moved to testing_helpers for better organization in selftests.,"selftests,bpf,testing_helpers",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tracepoints like programs']
8b593021319d4893a8fbeb7bd1f668657e68403c,8b593021319d4893a8fbeb7bd1f668657e68403c,Martin KaFai Lau,martin.lau@kernel.org,1706056794,Martin KaFai Lau,martin.lau@kernel.org,1706058772,85add1361db079527e9798ff1f78d180e9f08180,b7d1af3791036a619ca8ffde5f832111b05ca833 0253e0590e2dc46996534371d56b5297099aed4e,"Merge branch 'Registrating struct_ops types from modules'

Kui-Feng Lee says:

====================
Given the current constraints of the current implementation","
struct_ops cannot be registered dynamically. This presents a
significant limitation for modules like coming fuse-bpf","[' which seeks\nto implement a new struct_ops type. To address this issue', ' a new API\nis introduced that allows the registration of new struct_ops types\nfrom modules.\n\nPreviously', ' struct_ops types were defined in bpf_struct_ops_types.h\nand collected as a static array. The new API lets callers add new\nstruct_ops types dynamically. The static array has been removed and\nreplaced by the per-btf struct_ops_tab.\n\nThe struct_ops subsystem relies on BTF to determine the layout of\nvalues in a struct_ops map and identify the subsystem that the\nstruct_ops map registers to. However', ' the kernel BTF does not include\nthe type information of struct_ops types defined by a module. The\nstruct_ops subsystem requires knowledge of the corresponding module\nfor a given struct_ops map and the utilization of BTF information from\nthat module. We empower libbpf to determine the correct module for\naccessing the BTF information and pass an identity (FD) of the module\nbtf to the kernel. The kernel looks up type information and registered\nstruct_ops types directly from the given btf.\n\nIf a module exits while one or more struct_ops maps still refer to a\nstruct_ops type defined by the module', ' it can lead to unforeseen\ncomplications. Therefore', ' it is crucial to ensure that a module\nremains intact as long as any struct_ops map is still linked to a\nstruct_ops type defined by the module. To achieve this', ' every\nstruct_ops map holds a reference to the module while being registered.\n\nChanges from v16:\n\n - Fix unnecessary bpf_struct_ops_link_create() removing/adding.\n\n - Rename REGISTER_BPF_STRUCT_OPS() to register_bpf_struct_ops().\n\n - Implement bpf_map_struct_ops_info_fill() for !CONFIG_BPF_JIT.\n\nChanges from v15:\n\n - Fix the misleading commit message of part 4.\n\n - Introduce BPF_F_VTYPE_BTF_OBJ_FD flag to struct bpf_attr to tell\n   if value_type_btf_obj_fd is set or not.\n\n - Introduce links_cnt to struct bpf_struct_ops_map to avoid accessing\n   struct bpf_struct_ops_desc in bpf_struct_ops_map_put_progs() after\n   calling module_put() against the owner module of the struct_ops\n   type. (Part 9)\n\nChanges from v14:\n\n - Rebase. Add cif_stub required by\n   the commit 2cd3e3772e413 (""x86/cfi', 'bpf: Fix bpf_struct_ops CFI"")\n\n - Remove creating struct_ops map without bpf_testmod.ko from the\n   test.\n\n - Check the name of btf returned by bpf_map_info by getting the name\n   with bpf_btf_get_info_by_fd().\n\n - Change value_type_btf_obj_fd to a signed type to allow the 0 fd.\n\nChanges from v13:\n\n - Change the test case to use bpf_map_create() to create a struct_ops\n   map while testmod.ko is unloaded.\n\n - Move bpf_struct_ops_find*() to btf.c.\n\n - Use btf_is_module() to replace btf != btf_vmlinux.\n\nChanges from v12:\n\n - Rebase to for-next to fix conflictions.\n\nChanges from v11:\n\n - bpf_struct_ops_maps hold only the refcnt to the module', ' but not\n   btf. (patch 1)\n\n - Fix warning messages. (patch 1', ' 9 and 10)\n\n - Remove unnecessary conditional compiling of CONFIG_BPF_JIT.\n   (patch 4', "" 9 and 10)\n\n - Fix the commit log of the patch 7 to explain how a btf is pass from\n   the user space and how the kernel handle it.\n\n - bpf_struct_ops_maps hold the module defining it's type"", "" but not\n   btf. A map will hold the module through its life-span from\n   allocating to being free. (patch 8)\n\n - Change selftests and tracing __bpf_struct_ops_map_free() to wait\n   for the release of the bpf_testmod module.\n\n - Include btf_obj_id in bpf_map_info. (patch 14)\n\nChanges from v10:\n\n - Guard btf.c from CONFIG_BPF_JIT=n. This patchset has introduced\n   symbols from bpf_struct_ops.c which is only built when\n   CONFIG_BPF_JIT=y.\n\n - Fix the warning of unused errout_free label by moving code that is\n   leaked to patch 8 to patch 7.\n\nChanges from v9:\n\n - Remove the call_rcu_tasks_trace() changes from kern_sync_rcu().\n\n - Trace btf_put() in the test case to ensure the release of kmod's\n   btf"", "" or the consequent tests may fail for using kmod's unloaded old\n   btf instead the new one created after loading again. The kmod's btf\n   may live for awhile after unloading the kmod"", ' for a map being freed\n   asynchronized is still holding the btf.\n\n - Split ""add struct_ops_tab to btf"" into tow patches by adding\n   ""make struct_ops_map support btfs other than btf_vmlinux"".\n\n - Flip the order of ""pass attached BTF to the bpf_struct_ops\n   subsystem"" and ""hold module for bpf_struct_ops_map"" to make it more\n   reasonable.\n\n - Fix the compile errors of a missing header file.\n\nChanges from v8:\n\n - Rename bpf_struct_ops_init_one() to bpf_struct_ops_desc_init().\n\n - Move code that using BTF_ID_LIST to the newly added patch 2.\n\n - Move code that lookup struct_ops types from a given module to the\n   newly added patch 5.\n\n - Store the pointers of btf at st_maps.\n\n - Add test cases for the cases of modules being unload.\n\n - Call bpf_struct_ops_init() in btf_add_struct_ops() to fix an\n   inconsistent issue.\n\nChanges from v7:\n\n - Fix check_struct_ops_btf_id() to use attach btf if there is instead\n   of btf_vmlinux.\n\nChanges from v6:\n\n - Change returned error code to -EINVAL for the case of\n   bpf_try_get_module().\n\n - Return an error code from bpf_struct_ops_init().\n\n - Fix the dependency issue of testing_helpers.c and\n   rcu_tasks_trace_gp.skel.h.\n\nChanges from v5:\n\n - As the 2nd patch', ' we introduce ""bpf_struct_ops_desc"". This change\n   involves moving certain members of ""bpf_struct_ops"" to\n   ""bpf_struct_ops_desc""', ' which becomes a part of\n   ""btf_struct_ops_tab"". This ensures that these members remain\n   accessible even when the owner module of a ""bpf_struct_ops"" is\n   unloaded.\n\n - Correct the order of arguments when calling\n    in the 3rd patch.\n\n - Remove the owner argument from bpf_struct_ops_init_one(). Instead', ""\n   callers should fill in st_ops->owner.\n\n - Make sure to hold the owner module when calling\n   bpf_struct_ops_find() and bpf_struct_ops_find_value() in the 6th\n   patch.\n\n - Merge the functions register_bpf_struct_ops_btf() and\n   register_bpf_struct_ops() into a single function and relocate it to\n   btf.c for better organization and clarity.\n\n - Undo the name modifications made to find_kernel_btf_id() and\n   find_ksym_btf_id() in the 8th patch.\n\nChanges from v4:\n\n - Fix the dependency between testing_helpers.o and\n   rcu_tasks_trace_gp.skel.h.\n\nChanges from v3:\n\n - Fix according to the feedback for v3.\n\n   - Change of the order of arguments to make btf as the first\n     argument.\n\n   - Use btf_try_get_module() instead of try_get_module() since the\n     module pointed by st_ops->owner can gone while some one is still\n     holding its btf.\n\n   - Move variables defined by BPF_STRUCT_OPS_COMMON_VALUE to struct\n     bpf_struct_ops_common_value to validation easier.\n\n   - Register the struct_ops type defined by bpf_testmod in its init\n     function.\n\n   - Rename field name to 'value_type_btf_obj_fd' to make it explicit.\n\n   - Fix leaking of btf objects on error.\n\n   - st_maps hold their modules to keep modules alive and prevent they\n     from unloading.\n\n   - bpf_map of libbpf keeps mod_btf_fd instead of a pointer to module_btf.\n\n   - Do call_rcu_tasks_trace() in kern_sync_rcu() to ensure the\n     bpf_testmod is unloaded properly. It uses rcu_tasks_trace_gp to\n     trigger call_rcu_tasks_trace() in the kernel.\n\n - Merge and reorder patches in a reasonable order.\n\nChanges from v2:\n\n - Remove struct_ops array"", ' and add a per-btf (module) struct_ops_tab\n   to collect registered struct_ops types.\n\n - Validate value_type by checking member names and types.\n---\nv16: https://lore.kernel.org/all/20240118014930.1992551-1-thinker.li@gmail.com/\nv15: https://lore.kernel.org/all/20231220222654.1435895-1-thinker.li@gmail.com/\nv14: https://lore.kernel.org/all/20231217081132.1025020-1-thinker.li@gmail.com/\nv13: https://lore.kernel.org/all/20231209002709.535966-1-thinker.li@gmail.com/\nv12: https://lore.kernel.org/all/20231207013950.1689269-1-thinker.li@gmail.com/\nv11: https://lore.kernel.org/all/20231106201252.1568931-1-thinker.li@gmail.com/\nv10: https://lore.kernel.org/all/20231103232202.3664407-1-thinker.li@gmail.com/\nv9: https://lore.kernel.org/all/20231101204519.677870-1-thinker.li@gmail.com/\nv8: https://lore.kernel.org/all/20231030192810.382942-1-thinker.li@gmail.com/\nv7: https://lore.kernel.org/all/20231027211702.1374597-1-thinker.li@gmail.com/\nv6: https://lore.kernel.org/all/20231022050335.2579051-11-thinker.li@gmail.com/\nv5: https://lore.kernel.org/all/20231017162306.176586-1-thinker.li@gmail.com/\nv4: https://lore.kernel.org/all/20231013224304.187218-1-thinker.li@gmail.com/\nv3: https://lore.kernel.org/all/20230920155923.151136-1-thinker.li@gmail.com/\nv2: https://lore.kernel.org/all/20230913061449.1918219-1-thinker.li@gmail.com/\n====================\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",This commit addresses the limitation of dynamically registering struct_ops in eBPF modules.,"struct_ops,dynamic registration,modules",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['other']
0253e0590e2dc46996534371d56b5297099aed4e,0253e0590e2dc46996534371d56b5297099aed4e,Kui-Feng Lee,thinker.li@gmail.com,1705704605,Martin KaFai Lau,martin.lau@kernel.org,1706058772,85add1361db079527e9798ff1f78d180e9f08180,7c81c2490c73e614c6d48e4f339f4f224140b565,"selftests/bpf: test case for register_bpf_struct_ops().

Create a new struct_ops type called bpf_testmod_ops within the bpf_testmod
module. When a struct_ops object is registered"," the bpf_testmod module will
invoke test_2 from the module.

Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240119225005.668602-15-thinker.li@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Add a new test case for register_bpf_struct_ops in the bpf_testmod module.,"bpf_testmod,struct_ops,test case",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7c81c2490c73e614c6d48e4f339f4f224140b565,7c81c2490c73e614c6d48e4f339f4f224140b565,Kui-Feng Lee,thinker.li@gmail.com,1705704604,Martin KaFai Lau,martin.lau@kernel.org,1706058772,e4818b6ed76d5c6cb7148ac56db2a826c36272e5,9e926acda0c2e21bca431a1818665ddcd6939755,"bpf: export btf_ctx_access to modules.

The module requires the use of btf_ctx_access() to invoke
bpf_tracing_btf_ctx_access() from a module. This function is valuable for
implementing validation functions that ensure proper access to ctx.

Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240119225005.668602-14-thinker.li@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,The commit exports btf_ctx_access to modules for implementing validation functions in eBPF.,"btf_ctx_access, modules, validation",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['kprobe/uprobe/ftrace like programs', 'tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9e926acda0c2e21bca431a1818665ddcd6939755,9e926acda0c2e21bca431a1818665ddcd6939755,Kui-Feng Lee,thinker.li@gmail.com,1705704603,Martin KaFai Lau,martin.lau@kernel.org,1706058772,4d4f1f22b84386dcd06c0402d196ffb748be121b,f6be98d19985411ca1f3d53413d94d5b7f41c200,"libbpf: Find correct module BTFs for struct_ops maps and progs.

Locate the module BTFs for struct_ops maps and progs and pass them to the
kernel. This ensures that the kernel correctly resolves type IDs from the
appropriate module BTFs.

For the map of a struct_ops object"," the FD of the module BTF is set to
bpf_map to keep a reference to the module BTF. The FD is passed to the
kernel as value_type_btf_obj_fd when the struct_ops object is loaded.

For a bpf_struct_ops prog","[' attach_btf_obj_fd of bpf_prog is the FD of a\nmodule BTF in the kernel.\n\nSigned-off-by: Kui-Feng Lee <thinker.li@gmail.com>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240119225005.668602-13-thinker.li@gmail.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",The commit ensures correct module BTFs are used for struct_ops maps and progs in libbpf.,"libbpf, module BTFs, struct_ops",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f6be98d19985411ca1f3d53413d94d5b7f41c200,f6be98d19985411ca1f3d53413d94d5b7f41c200,Kui-Feng Lee,thinker.li@gmail.com,1705704602,Martin KaFai Lau,martin.lau@kernel.org,1706058766,42992e3ac7a76fbb27a46dabeb2bf93ca7dc6f61,612d087d4ba54cef47946e22e5dabad762dd7ed5,bpf," net: switch to dynamic registration

Replace the static list of struct_ops types with per-btf struct_ops_tab to
enable dynamic registration.

Both bpf_dummy_ops and bpf_tcp_ca now utilize the registration function
instead of being listed in bpf_struct_ops_types.h.

Cc: netdev@vger.kernel.org
Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240119225005.668602-12-thinker.li@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Introduce dynamic registration for bpf struct operations using per-btf struct_ops_tab in lieu of static listing.,"dynamic registration, struct_ops, bpf",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['socket like programs', 'tc/netfilter like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
612d087d4ba54cef47946e22e5dabad762dd7ed5,612d087d4ba54cef47946e22e5dabad762dd7ed5,Kui-Feng Lee,thinker.li@gmail.com,1705704601,Martin KaFai Lau,martin.lau@kernel.org,1706056665,7044e668fc1d4277daac80e05425caf566aedc02,e3f87fdfed7b770dd7066b02262b12747881e76d,"bpf: validate value_type

A value_type should consist of three components: refcnt", state,"[' and data.\nrefcnt and state has been move to struct bpf_struct_ops_common_value to\nmake it easier to check the value type.\n\nSigned-off-by: Kui-Feng Lee <thinker.li@gmail.com>\nLink: https://lore.kernel.org/r/20240119225005.668602-11-thinker.li@gmail.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",This commit ensures that value_type in eBPF is validated to contain three components including refcnt.,"validate,value_type,refcnt",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e3f87fdfed7b770dd7066b02262b12747881e76d,e3f87fdfed7b770dd7066b02262b12747881e76d,Kui-Feng Lee,thinker.li@gmail.com,1705704600,Martin KaFai Lau,martin.lau@kernel.org,1706056664,aba3b44c97564fd8d0e61f4b1eec1b90d7b13ee2,fcc2c1fb0651477c8ed78a3a293c175ccd70697a,"bpf: hold module refcnt in bpf_struct_ops map creation and prog verification.

To ensure that a module remains accessible whenever a struct_ops object of
a struct_ops type provided by the module is still in use.

struct bpf_struct_ops_map doesn't hold a refcnt to btf anymore since a
module will hold a refcnt to it's btf already. But"," struct_ops programs are
different. They hold their associated btf","[' not the module since they need\nonly btf to assure their types (signatures).\n\nHowever', ' verifier holds the refcnt of the associated module of a struct_ops\ntype temporarily when verify a struct_ops prog. Verifier needs the help\nfrom the verifier operators (struct bpf_verifier_ops) provided by the owner\nmodule to verify data access of a prog', ' provide information', ' and generate\ncode.\n\nThis patch also add a count of links (links_cnt) to bpf_struct_ops_map. It\navoids bpf_struct_ops_map_put_progs() from accessing btf after calling\nmodule_put() in bpf_struct_ops_map_free().\n\nSigned-off-by: Kui-Feng Lee <thinker.li@gmail.com>\nLink: https://lore.kernel.org/r/20240119225005.668602-10-thinker.li@gmail.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Ensure module refcount is maintained for struct_ops objects during map creation and program verification.,"module, refcnt, struct_ops",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fcc2c1fb0651477c8ed78a3a293c175ccd70697a,fcc2c1fb0651477c8ed78a3a293c175ccd70697a,Kui-Feng Lee,thinker.li@gmail.com,1705704599,Martin KaFai Lau,martin.lau@kernel.org,1706056664,5db50a9fefdd357c802c97bfe3962f1c6e0fee90,689423db3bda2244c24db8a64de4cdb37be1de41,"bpf: pass attached BTF to the bpf_struct_ops subsystem

Pass the fd of a btf from the userspace to the bpf() syscall"," and then
convert the fd into a btf. The btf is generated from the module that
defines the target BPF struct_ops type.

In order to inform the kernel about the module that defines the target
struct_ops type","["" the userspace program needs to provide a btf fd for the\nrespective module's btf. This btf contains essential information on the\ntypes defined within the module"", ' including the target struct_ops type.\n\nA btf fd must be provided to the kernel for struct_ops maps and for the bpf\nprograms attached to those maps.\n\nIn the case of the bpf programs', ' the attach_btf_obj_fd parameter is passed\nas part of the bpf_attr and is converted into a btf. This btf is then\nstored in the prog->aux->attach_btf field. Here', ' it just let the verifier\naccess attach_btf directly.\n\nIn the case of struct_ops maps', ' a btf fd is passed as value_type_btf_obj_fd\nof bpf_attr. The bpf_struct_ops_map_alloc() function converts the fd to a\nbtf and stores it as st_map->btf. A flag BPF_F_VTYPE_BTF_OBJ_FD is added\nfor map_flags to indicate that the value of value_type_btf_obj_fd is set.\n\nSigned-off-by: Kui-Feng Lee <thinker.li@gmail.com>\nLink: https://lore.kernel.org/r/20240119225005.668602-9-thinker.li@gmail.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Added functionality to pass BTF fd from userspace to bpf() syscall for struct_ops support.,"BTF, struct_ops, syscall",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
689423db3bda2244c24db8a64de4cdb37be1de41,689423db3bda2244c24db8a64de4cdb37be1de41,Kui-Feng Lee,thinker.li@gmail.com,1705704598,Martin KaFai Lau,martin.lau@kernel.org,1706056664,a76dfd5a3ca0c8f459c06a9306ebbbb7fbc78c6d,1338b93346587a2a6ac79bbcf55ef5b357745573,"bpf: lookup struct_ops types from a given module BTF.

This is a preparation for searching for struct_ops types from a specified
module. BTF is always btf_vmlinux now. This patch passes a pointer of BTF
to bpf_struct_ops_find_value() and bpf_struct_ops_find(). Once the new
registration API of struct_ops types is used"," other BTFs besides
btf_vmlinux can also be passed to them.

Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240119225005.668602-8-thinker.li@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],This commit prepares for searching struct_ops types from specified module BTF by passing BTF pointers to struct_ops functions.,"struct_ops,BTF,module",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1338b93346587a2a6ac79bbcf55ef5b357745573,1338b93346587a2a6ac79bbcf55ef5b357745573,Kui-Feng Lee,thinker.li@gmail.com,1705704597,Martin KaFai Lau,martin.lau@kernel.org,1706056664,3200810e4d2c138d8ecec7ab4303446db88a1bf7,47f4f657acd5d04c78c5c5ac7022cba9ce3b4a7d,"bpf: pass btf object id in bpf_map_info.

Include btf object id (btf_obj_id) in bpf_map_info so that tools (ex:
bpftools struct_ops dump) know the correct btf from the kernel to look up
type information of struct_ops types.

Since struct_ops types can be defined and registered in a module. The
type information of a struct_ops type are defined in the btf of the
module defining it.  The userspace tools need to know which btf is for
the module defining a struct_ops type.

Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240119225005.668602-7-thinker.li@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,The commit adds btf_obj_id to bpf_map_info for proper type information lookup by tools.,"btf_obj_id,bpf_map_info,struct_ops",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
47f4f657acd5d04c78c5c5ac7022cba9ce3b4a7d,47f4f657acd5d04c78c5c5ac7022cba9ce3b4a7d,Kui-Feng Lee,thinker.li@gmail.com,1705704596,Martin KaFai Lau,martin.lau@kernel.org,1706056664,5b68fada69c50bef366af6a183fa544887cdab12,e61995111a76633376419d1bccede8696e94e6e5,"bpf: make struct_ops_map support btfs other than btf_vmlinux.

Once new struct_ops can be registered from modules"," btf_vmlinux is no
longer the only btf that struct_ops_map would face.  st_map should remember
what btf it should use to get type information.

Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240119225005.668602-6-thinker.li@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],The commit extends struct_ops_map to support BTFs from modules beyond btf_vmlinux.,"struct_ops_map,BTF,module",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e61995111a76633376419d1bccede8696e94e6e5,e61995111a76633376419d1bccede8696e94e6e5,Kui-Feng Lee,thinker.li@gmail.com,1705704595,Martin KaFai Lau,martin.lau@kernel.org,1706056664,9b9e91ce328a506687b11d4bb03c6f38f2b4657a,4c5763ed996a61b51d721d0968d0df957826ea49,"bpf: add struct_ops_tab to btf.

Maintain a registry of registered struct_ops types in the per-btf (module)
struct_ops_tab. This registry allows for easy lookup of struct_ops types
that are registered by a specific module.

It is a preparation work for supporting kernel module struct_ops in a
latter patch. Each struct_ops will be registered under its own kernel
module btf and will be stored in the newly added btf->struct_ops_tab. The
bpf verifier and bpf syscall (e.g. prog and map cmd) can find the
struct_ops and its btf type/size/id... information from
btf->struct_ops_tab.

Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240119225005.668602-5-thinker.li@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,This commit adds struct_ops_tab to BTF for registering and looking up struct_ops types within kernel modules.,struct_ops BTF registry,It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4c5763ed996a61b51d721d0968d0df957826ea49,4c5763ed996a61b51d721d0968d0df957826ea49,Kui-Feng Lee,thinker.li@gmail.com,1705704594,Martin KaFai Lau,martin.lau@kernel.org,1706056664,12d428d0eb3ea1e409f6f78d4545881b6acbc4b0,95678395386d45fa0a075d2e7a6866326a469d76,bpf," net: introduce bpf_struct_ops_desc.

Move some of members of bpf_struct_ops to bpf_struct_ops_desc.  type_id is
unavailabe in bpf_struct_ops anymore. Modules should get it from the btf
received by kmod's init function.

Cc: netdev@vger.kernel.org
Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240119225005.668602-4-thinker.li@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],The commit updates bpf_struct_ops by moving members to bpf_struct_ops_desc and modifies BTF handling.,"bpf_struct_ops,bpf_struct_ops_desc,BTF",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
95678395386d45fa0a075d2e7a6866326a469d76,95678395386d45fa0a075d2e7a6866326a469d76,Kui-Feng Lee,thinker.li@gmail.com,1705704593,Martin KaFai Lau,martin.lau@kernel.org,1706056663,272be15c9b5ae3c0b0758ef982f48d30facc5868,3b1f89e747cd4b24244f2798a35d28815b744303,"bpf: get type information with BTF_ID_LIST

Get ready to remove bpf_struct_ops_init() in the future. By using
BTF_ID_LIST"," it is possible to gather type information while building
instead of runtime.

Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240119225005.668602-3-thinker.li@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Enhances BTF usage by enabling type information gathering during the build to eventually remove bpf_struct_ops_init().,"BTF_ID_LIST,type information,bpf_struct_ops_init",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),['other']
3b1f89e747cd4b24244f2798a35d28815b744303,3b1f89e747cd4b24244f2798a35d28815b744303,Kui-Feng Lee,thinker.li@gmail.com,1705704592,Martin KaFai Lau,martin.lau@kernel.org,1706056663,8be9712b5832eaf504966010fc01e0a338eefb35,b7d1af3791036a619ca8ffde5f832111b05ca833,"bpf: refactory struct_ops type initialization to a function.

Move the majority of the code to bpf_struct_ops_init_one()"," which can then
be utilized for the initialization of newly registered dynamically
allocated struct_ops types in the following patches.

Signed-off-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/20240119225005.668602-2-thinker.li@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Refactor the struct_ops initialization into a dedicated function for dynamic type registration.,"refactor, struct_ops, initialization",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b7d1af3791036a619ca8ffde5f832111b05ca833,b7d1af3791036a619ca8ffde5f832111b05ca833,Alexei Starovoitov,ast@kernel.org,1706054728,Alexei Starovoitov,ast@kernel.org,1706054742,0d0caf63683de1d45c4c3aba0aa399fe2dee65c6,bbc094b3052647c188d6f155f5c09cb9492ce106 b0dc037399b19a777d569dbd9e2e9bbd62f3b3b1,"Merge branch 'bpf-add-cookies-retrieval-for-perf-kprobe-multi-links'

Jiri Olsa says:

====================
bpf: Add cookies retrieval for perf/kprobe multi links

hi","
this patchset adds support to retrieve cookies from existing tracing
links that still did not support it plus changes to bpftool to display
them. It's leftover we discussed some time ago [1].

thanks","['\njirka\n\nv2 changes:\n - added review/ack tags\n - fixed memory leak [Quentin]\n - align the uapi fields properly [Yafang Shao]\n\n[1] https://lore.kernel.org/bpf/CALOAHbAZ6=A9j3VFCLoAC_WhgQKU7injMf06=cM2sU4Hi4Sx+Q@mail.gmail.com/\nReviewed-by: Quentin Monnet <quentin@isovalent.com>\n---\n====================\n\nReviewed-by: Quentin Monnet <quentin@isovalent.com>\nLink: https://lore.kernel.org/r/20240119110505.400573-1-jolsa@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit adds cookie retrieval support for perf and kprobe multi-links and updates bpftool to display them.,"cookies,retrieval,bpftool",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
b0dc037399b19a777d569dbd9e2e9bbd62f3b3b1,b0dc037399b19a777d569dbd9e2e9bbd62f3b3b1,Jiri Olsa,jolsa@kernel.org,1705662305,Alexei Starovoitov,ast@kernel.org,1706054728,0d0caf63683de1d45c4c3aba0aa399fe2dee65c6,54258324b934aa8552c239c443272ec7aea55285,"bpftool: Display cookie for kprobe multi link

Displaying cookies for kprobe multi link"," in plain mode:

  # bpftool link
  ...
  1397: kprobe_multi  prog 47532
          kretprobe.multi  func_cnt 3
          addr             cookie           func [module]
          ffffffff82b370c0 3                bpf_fentry_test1
          ffffffff82b39780 1                bpf_fentry_test2
          ffffffff82b397a0 2                bpf_fentry_test3

And in json mode:

  # bpftool link -j | jq
  ...
    {
      ""id"": 1397","['\n      ""type"": ""kprobe_multi""', '\n      ""prog_id"": 47532', '\n      ""retprobe"": true', '\n      ""func_cnt"": 3', '\n      ""missed"": 0', '\n      ""funcs"": [\n        {\n          ""addr"": 18446744071607382208', '\n          ""func"": ""bpf_fentry_test1""', '\n          ""module"": null', '\n          ""cookie"": 3\n        }', '\n        {\n          ""addr"": 18446744071607392128', '\n          ""func"": ""bpf_fentry_test2""', '\n          ""module"": null', '\n          ""cookie"": 1\n        }', '\n        {\n          ""addr"": 18446744071607392160', '\n          ""func"": ""bpf_fentry_test3""', '\n          ""module"": null', '\n          ""cookie"": 2\n        }\n      ]\n    }\n\nCookie is attached to specific address', ' and because we sort addresses\nbefore printing', ' we need to sort cookies the same way', ' hence adding\nthe struct addr_cookie to keep and sort them together.\n\nAlso adding missing dd.sym_count check to show_kprobe_multi_json.\n\nSigned-off-by: Jiri Olsa <jolsa@kernel.org>\nAcked-by: Song Liu <song@kernel.org>\nLink: https://lore.kernel.org/r/20240119110505.400573-9-jolsa@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Enhance bpftool to display cookies for kprobe multi links in plain and JSON mode.,"bpftool,kprobe,cookie",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The bpftool utility,['kprobe/uprobe/ftrace like programs']
54258324b934aa8552c239c443272ec7aea55285,54258324b934aa8552c239c443272ec7aea55285,Jiri Olsa,jolsa@kernel.org,1705662304,Alexei Starovoitov,ast@kernel.org,1706054728,4301ff25445e88ff823d6c9e6814017e0f30e978,b7896486688af36e3bc5e27a6d5369cc5dcbcf69,"bpftool: Display cookie for perf event link probes

Displaying cookie for perf event link probes"," in plain mode:

  # bpftool link
  17: perf_event  prog 90
          kprobe ffffffff82b1c2b0 bpf_fentry_test1  cookie 3735928559
  18: perf_event  prog 90
          kretprobe ffffffff82b1c2b0 bpf_fentry_test1  cookie 3735928559
  20: perf_event  prog 92
          tracepoint sched_switch  cookie 3735928559
  21: perf_event  prog 93
          event software:page-faults  cookie 3735928559
  22: perf_event  prog 91
          uprobe /proc/self/exe+0xd703c  cookie 3735928559

And in json mode:

  # bpftool link -j | jq

  {
    ""id"": 30","['\n    ""type"": ""perf_event""', '\n    ""prog_id"": 160', '\n    ""retprobe"": false', '\n    ""addr"": 18446744071607272112', '\n    ""func"": ""bpf_fentry_test1""', '\n    ""offset"": 0', '\n    ""missed"": 0', '\n    ""cookie"": 3735928559\n  }\n\n  {\n    ""id"": 33', '\n    ""type"": ""perf_event""', '\n    ""prog_id"": 162', '\n    ""tracepoint"": ""sched_switch""', '\n    ""cookie"": 3735928559\n  }\n\n  {\n    ""id"": 34', '\n    ""type"": ""perf_event""', '\n    ""prog_id"": 163', '\n    ""event_type"": ""software""', '\n    ""event_config"": ""page-faults""', '\n    ""cookie"": 3735928559\n  }\n\n  {\n    ""id"": 35', '\n    ""type"": ""perf_event""', '\n    ""prog_id"": 161', '\n    ""retprobe"": false', '\n    ""file"": ""/proc/self/exe""', '\n    ""offset"": 880700', '\n    ""cookie"": 3735928559\n  }\n\nReviewed-by: Quentin Monnet <quentin@isovalent.com>\nSigned-off-by: Jiri Olsa <jolsa@kernel.org>\nAcked-by: Song Liu <song@kernel.org>\nLink: https://lore.kernel.org/r/20240119110505.400573-8-jolsa@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit adds a feature to display cookies for perf event links in bpftool.,"bpftool, perf event, cookie",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The bpftool utility,['kprobe/uprobe/ftrace like programs']
b7896486688af36e3bc5e27a6d5369cc5dcbcf69,b7896486688af36e3bc5e27a6d5369cc5dcbcf69,Jiri Olsa,jolsa@kernel.org,1705662303,Alexei Starovoitov,ast@kernel.org,1706054728,fc35b13c4c2420472d3cfba90a888fdf688fec64,d74179708473c649c653f1db280e29875a532e99,"selftests/bpf: Add fill_link_info test for perf event

Adding fill_link_info test for perf event and testing we
get its values back through the bpf_link_info interface.

Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Acked-by: Song Liu <song@kernel.org>
Link: https://lore.kernel.org/r/20240119110505.400573-7-jolsa@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add test case to verify bpf_link_info values for perf events.,"fill_link_info, perf event, bpf_link_info",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tracepoints like programs']
d74179708473c649c653f1db280e29875a532e99,d74179708473c649c653f1db280e29875a532e99,Jiri Olsa,jolsa@kernel.org,1705662302,Alexei Starovoitov,ast@kernel.org,1706054727,c3506f046691e6866ce1c6e2aa16e32c0991253b,59a89706c40c153a74a3a9570b4d696cf9eebb0b,"selftests/bpf: Add cookies check for perf_event fill_link_info test

Now that we get cookies for perf_event probes"," adding tests
for cookie for kprobe/uprobe/tracepoint.

The perf_event test needs to be added completely and is coming
in following change.

Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Acked-by: Song Liu <song@kernel.org>
Link: https://lore.kernel.org/r/20240119110505.400573-6-jolsa@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Add selftest for cookies check in perf_event fill_link_info for kprobe/uprobe/tracepoint.,"cookies, perf_event, tests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['kprobe/uprobe/ftrace like programs', 'tracepoints like programs']"
59a89706c40c153a74a3a9570b4d696cf9eebb0b,59a89706c40c153a74a3a9570b4d696cf9eebb0b,Jiri Olsa,jolsa@kernel.org,1705662301,Alexei Starovoitov,ast@kernel.org,1706054727,ce1a51a3cbe58add05cd1be9abf04f9585144600,2adb2e0fcdf3c6d8e28a5a9c33e458e1037ae5ad,"selftests/bpf: Add cookies check for kprobe_multi fill_link_info test

Adding cookies check for kprobe_multi fill_link_info test","
plus tests for invalid values related to cookies.

Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Acked-by: Song Liu <song@kernel.org>
Link: https://lore.kernel.org/r/20240119110505.400573-5-jolsa@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Add cookies check and tests for kprobe_multi fill_link_info in selftests/bpf.,"cookies,kprobe_multi,tests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
2adb2e0fcdf3c6d8e28a5a9c33e458e1037ae5ad,2adb2e0fcdf3c6d8e28a5a9c33e458e1037ae5ad,Jiri Olsa,jolsa@kernel.org,1705662300,Alexei Starovoitov,ast@kernel.org,1706054727,a22f6d48ba9745fd24a348248113671c63d40802,9fd112b1f82b587ffb12fb67dd032f551fdb571a,"bpftool: Fix wrong free call in do_show_link

The error path frees wrong array"," it should be ref_ctr_offsets.

Acked-by: Yafang Shao <laoar.shao@gmail.com>
Reviewed-by: Quentin Monnet <quentin@isovalent.com>
Fixes: a7795698f8b6 (""bpftool: Add support to display uprobe_multi links"")
Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Acked-by: Song Liu <song@kernel.org>
Link: https://lore.kernel.org/r/20240119110505.400573-4-jolsa@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Fixed incorrect memory deallocation in bpftool's do_show_link function.,"bpftool, free call, do_show_link",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9fd112b1f82b587ffb12fb67dd032f551fdb571a,9fd112b1f82b587ffb12fb67dd032f551fdb571a,Jiri Olsa,jolsa@kernel.org,1705662299,Alexei Starovoitov,ast@kernel.org,1706054727,d8abc67a33285f67e790a48f801488c73c70b6e6,d5c16492c66fbfca85f36e42363d32212df5927b,"bpf: Store cookies in kprobe_multi bpf_link_info data

Storing cookies in kprobe_multi bpf_link_info data. The cookies
field is optional and if provided it needs to be an array of
__u64 with kprobe_multi.count length.

Acked-by: Yafang Shao <laoar.shao@gmail.com>
Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Acked-by: Song Liu <song@kernel.org>
Link: https://lore.kernel.org/r/20240119110505.400573-3-jolsa@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Store optional cookies array in kprobe_multi bpf_link_info data for better tracking.,"cookies,kprobe_multi,bpf_link_info",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
d5c16492c66fbfca85f36e42363d32212df5927b,d5c16492c66fbfca85f36e42363d32212df5927b,Jiri Olsa,jolsa@kernel.org,1705662298,Alexei Starovoitov,ast@kernel.org,1706054727,9b3398711339bf2660ed056fee3d49eff741d153,bbc094b3052647c188d6f155f5c09cb9492ce106,"bpf: Add cookie to perf_event bpf_link_info records

At the moment we don't store cookie for perf_event probes","
while we do that for the rest of the probes.

Adding cookie fields to struct bpf_link_info perf event
probe records:

  perf_event.uprobe
  perf_event.kprobe
  perf_event.tracepoint
  perf_event.perf_event

And the code to store that in bpf_link_info struct.

Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Acked-by: Song Liu <song@kernel.org>
Acked-by: Yafang Shao <laoar.shao@gmail.com>
Link: https://lore.kernel.org/r/20240119110505.400573-2-jolsa@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Add cookie field to perf_event bpf_link_info records for more event probe types.,"cookie,perf_event,bpf_link_info",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['kprobe/uprobe/ftrace like programs', 'tracepoints like programs', 'profile like programs']"
bbc094b3052647c188d6f155f5c09cb9492ce106,bbc094b3052647c188d6f155f5c09cb9492ce106,Jose E. Marchesi,jose.marchesi@oracle.com,1706033589,Alexei Starovoitov,ast@kernel.org,1706054146,41826ba20b74c0663b8cdf0a13b8c09e710702a1,756e34da5380e4c0ed2cfbe5259e1b015567a099,"bpf: Use r constraint instead of p constraint in selftests

Some of the BPF selftests use the ""p"" constraint in inline assembly
snippets"," for input operands for MOV (rN = rM) instructions.

This is mainly done via the __imm_ptr macro defined in
tools/testing/selftests/bpf/progs/bpf_misc.h:

  #define __imm_ptr(name) [name]""p""(&name)

Example:

  int consume_first_item_only(void *ctx)
  {
        struct bpf_iter_num iter;
        asm volatile (
                /* create iterator */
                ""r1 = %[iter];""
                [...]
                :
                : __imm_ptr(iter)
                : CLOBBERS);
        [...]
  }

The ""p"" constraint is a tricky one.  It is documented in the GCC manual
section ""Simple Constraints"":

  An operand that is a valid memory address is allowed.  This is for
  ``load address'' and ``push address'' instructions.

  p in the constraint must be accompanied by address_operand as the
  predicate in the match_operand.  This predicate interprets the mode
  specified in the match_operand as the mode of the memory reference for
  which the address would be valid.

There are two problems:

1. It is questionable whether that constraint was ever intended to be
   used in inline assembly templates","[' because its behavior really\n   depends on compiler internals.  A ""memory address"" is not the same\n   than a ""memory operand"" or a ""memory reference"" (constraint ""m"")', ' and\n   in fact its usage in the template above results in an error in both\n   x86_64-linux-gnu and bpf-unkonwn-none:\n\n     foo.c: In function ‘bar’:\n     foo.c:6:3: error: invalid \'asm\': invalid expression as operand\n        6 |   asm volatile (""r1 = %[jorl]"" : : [jorl]""p""(&jorl));\n          |   ^~~\n\n   I would assume the same happens with aarch64', ' riscv', ' and most/all\n   other targets in GCC', ' that do not accept operands of the form A + B\n   that are not wrapped either in a const or in a memory reference.\n\n   To avoid that error', ' the usage of the ""p"" constraint in internal GCC\n   instruction templates is supposed to be complemented by the \'a\'\n   modifier', ' like in:\n\n     asm volatile (""r1 = %a[jorl]"" : : [jorl]""p""(&jorl));\n\n   Internally documented (in GCC\'s final.cc) as:\n\n     %aN means expect operand N to be a memory address\n        (not a memory reference!) and print a reference\n        to that address.\n\n   That works because when the modifier \'a\' is found', ' GCC prints an\n   ""operand address""', ' which is not the same than an ""operand"".\n\n   But...\n\n2. Even if we used the internal \'a\' modifier (we shouldn\'t) the \'rN =\n   rM\' instruction really requires a register argument.  In cases\n   involving automatics', ' like in the examples above', ' we easily end with:\n\n     bar:\n        #APP\n            r1 = r10-4\n        #NO_APP\n\n   In other cases we could conceibly also end with a 64-bit label that\n   may overflow the 32-bit immediate operand of `rN = imm32\'\n   instructions:\n\n        r1 = foo\n\n   All of which is clearly wrong.\n\nclang happens to do ""the right thing"" in the current usage of __imm_ptr\nin the BPF tests', ' because even with -O2 it seems to ""reload"" the\nfp-relative address of the automatic to a register like in:\n\n  bar:\n\tr1 = r10\n\tr1 += -4\n\t#APP\n\tr1 = r1\n\t#NO_APP\n\nWhich is what GCC would generate with -O0.  Whether this is by chance\nor by design', ' the compiler shouln\'t be expected to do that reload\ndriven by the ""p"" constraint.\n\nThis patch changes the usage of the ""p"" constraint in the BPF\nselftests macros to use the ""r"" constraint instead.  If a register is\nwhat is required', ' we should let the compiler know.\n\nPrevious discussion in bpf@vger:\nhttps://lore.kernel.org/bpf/87h6p5ebpb.fsf@oracle.com/T/#ef0df83d6975c34dff20bf0dd52e078f5b8ca2767\n\nTested in bpf-next master.\nNo regressions.\n\nSigned-off-by: Jose E. Marchesi <jose.marchesi@oracle.com>\nCc: Yonghong Song <yonghong.song@linux.dev>\nCc: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240123181309.19853-1-jose.marchesi@oracle.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit replaces 'p' constraint with 'r' constraint in BPF selftests inline assembly for better compatibility and correctness.,"BPF,selftests,constraint",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
756e34da5380e4c0ed2cfbe5259e1b015567a099,756e34da5380e4c0ed2cfbe5259e1b015567a099,Jose E. Marchesi,jose.marchesi@oracle.com,1706043384,Alexei Starovoitov,ast@kernel.org,1706053984,7a2fa6f17bda4a2e9fd2f656aebe254ad62e1c61,edb799035dd7d41c3e81e1bef83e2a2120b08abb,"bpf: fix constraint in test_tcpbpf_kern.c

GCC emits a warning:

  progs/test_tcpbpf_kern.c:60:9: error: ‘op’ is used uninitialized [-Werror=uninitialized]

when an uninialized op is used with a ""+r"" constraint.  The + modifier
means a read-write operand"," but that operand in the selftest is just
written to.

This patch changes the selftest to use a ""=r"" constraint.  This
pacifies GCC.

Tested in bpf-next master.
No regressions.

Signed-off-by: Jose E. Marchesi <jose.marchesi@oracle.com>
Cc: Yonghong Song <yhs@meta.com>
Cc: Eduard Zingerman <eddyz87@gmail.com>
Cc: david.faust@oracle.com
Cc: cupertino.miranda@oracle.com
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20240123205624.14746-1-jose.marchesi@oracle.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Fixed a GCC warning by changing a constraint in a selftest for BPF.,"GCC, constraint, selftest",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
edb799035dd7d41c3e81e1bef83e2a2120b08abb,edb799035dd7d41c3e81e1bef83e2a2120b08abb,Jose E. Marchesi,jose.marchesi@oracle.com,1706041049,Alexei Starovoitov,ast@kernel.org,1706053847,2b59e35655f7dd697e9e22c894ee7dd0570b9606,bc308d011ab8cc61bf1be15a2920bcd7d7b9b9d3,"bpf: avoid VLAs in progs/test_xdp_dynptr.c

VLAs are not supported by either the BPF port of clang nor GCC.  The
selftest test_xdp_dynptr.c contains the following code:

  const size_t tcphdr_sz = sizeof(struct tcphdr);
  const size_t udphdr_sz = sizeof(struct udphdr);
  const size_t ethhdr_sz = sizeof(struct ethhdr);
  const size_t iphdr_sz = sizeof(struct iphdr);
  const size_t ipv6hdr_sz = sizeof(struct ipv6hdr);

  [...]

  static __always_inline int handle_ipv4(struct xdp_md *xdp"," struct bpf_dynptr *xdp_ptr)
  {
	__u8 eth_buffer[ethhdr_sz + iphdr_sz + ethhdr_sz];
	__u8 iph_buffer_tcp[iphdr_sz + tcphdr_sz];
	__u8 iph_buffer_udp[iphdr_sz + udphdr_sz];
	[...]
  }

The eth_buffer","[' iph_buffer_tcp and other automatics are fixed size\nonly if the compiler optimizes away the constant global variables.\nclang does this', ' but GCC does not', ' turning these automatics into\nvariable length arrays.\n\nThis patch removes the global variables and turns these values into\npreprocessor constants.  This makes the selftest to build properly\nwith GCC.\n\nTested in bpf-next master.\nNo regressions.\n\nSigned-off-by: Jose E. Marchesi <jose.marchesi@oracle.com>\nCc: Yonghong Song <yhs@meta.com>\nCc: Eduard Zingerman <eddyz87@gmail.com>\nCc: david.faust@oracle.com\nCc: cupertino.miranda@oracle.com\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240123201729.16173-1-jose.marchesi@oracle.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit removes VLAs from the test_xdp_dynptr.c to maintain compatibility with BPF port of clang and GCC.,"VLAs,selftest,compatibility",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['xdp like programs']
bc308d011ab8cc61bf1be15a2920bcd7d7b9b9d3,bc308d011ab8cc61bf1be15a2920bcd7d7b9b9d3,Andrii Nakryiko,andrii@kernel.org,1705698121,Alexei Starovoitov,ast@kernel.org,1706051627,54d3d250ff01c286ac139a659b9ed24af74b9b46,c80c6434aaccc689b2c7ff432d43abad8f4217b2,"libbpf: call dup2() syscall directly

We've ran into issues with using dup2() API in production setting"," where
libbpf is linked into large production environment and ends up calling
unintended custom implementations of dup2(). These custom implementations
don't provide atomic FD replacement guarantees of dup2() syscall","['\nleading to subtle and hard to debug issues.\n\nTo prevent this in the future and guarantee that no libc implementation\nwill do their own custom non-atomic dup2() implementation', "" call dup2()\nsyscall directly with syscall(SYS_dup2).\n\nNote that some architectures don't seem to provide dup2 and have dup3\ninstead. Try to detect and pick best syscall.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Song Liu <song@kernel.org>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240119210201.1295511-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']","The commit alters libbpf to directly use the dup2() syscall, bypassing custom implementations causing production issues.","libbpf, dup2, syscall",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c80c6434aaccc689b2c7ff432d43abad8f4217b2,c80c6434aaccc689b2c7ff432d43abad8f4217b2,Alexei Starovoitov,ast@kernel.org,1706051483,Alexei Starovoitov,ast@kernel.org,1706051483,eabaee12da6ad1bd91e948cab9a6d99f13e5c979,20e109ea9842158a153b24ef42ec5cc3d44e9485 29f868887a7dd3efc6faecc6fc91b28fc25cf5b0,"Merge branch 'enable-the-inline-of-kptr_xchg-for-arm64'

Hou Tao says:

====================
Enable the inline of kptr_xchg for arm64

From: Hou Tao <houtao1@huawei.com>

Hi","

The patch set is just a follow-up for ""bpf: inline bpf_kptr_xchg()"". It
enables the inline of bpf_kptr_xchg() and kptr_xchg_inline test for
arm64.

Please see individual patches for more details. And comments are always
welcome.
====================

Link: https://lore.kernel.org/r/20240119102529.99581-1-houtao@huaweicloud.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Enable inline support for bpf_kptr_xchg() on arm64 architecture.,"bpf_kptr_xchg, inline, arm64",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
29f868887a7dd3efc6faecc6fc91b28fc25cf5b0,29f868887a7dd3efc6faecc6fc91b28fc25cf5b0,Hou Tao,houtao1@huawei.com,1705659929,Alexei Starovoitov,ast@kernel.org,1706051483,eabaee12da6ad1bd91e948cab9a6d99f13e5c979,18a45f12d746c06b7361b0cce59cf8e8b9e38da6,"selftests/bpf: Enable kptr_xchg_inline test for arm64

Now arm64 bpf jit has enable bpf_jit_supports_ptr_xchg()"," so enable
the test for arm64 as well.

Signed-off-by: Hou Tao <houtao1@huawei.com>
Link: https://lore.kernel.org/r/20240119102529.99581-3-houtao@huaweicloud.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Enable kptr_xchg_inline test for arm64 in bpf selftests after JIT support update.,"kptr_xchg_inline, arm64, bpf_jit",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
18a45f12d746c06b7361b0cce59cf8e8b9e38da6,18a45f12d746c06b7361b0cce59cf8e8b9e38da6,Hou Tao,houtao1@huawei.com,1705659928,Alexei Starovoitov,ast@kernel.org,1706051483,58dc3aeffe29eb0e935fb73bb024be2a376f8145,20e109ea9842158a153b24ef42ec5cc3d44e9485,bpf," arm64: Enable the inline of bpf_kptr_xchg()

ARM64 bpf jit satisfies the following two conditions:
1) support BPF_XCHG() on pointer-sized word.
2) the implementation of xchg is the same as atomic_xchg() on
   pointer-sized words. Both of these two functions use arch_xchg() to
   implement the exchange.

So enable the inline of bpf_kptr_xchg() for arm64 bpf jit.

Signed-off-by: Hou Tao <houtao1@huawei.com>
Link: https://lore.kernel.org/r/20240119102529.99581-2-houtao@huaweicloud.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Enable inline implementation of bpf_kptr_xchg for arm64 bpf jit.,"bpf_kptr_xchg,ARM64,JIT",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
20e109ea9842158a153b24ef42ec5cc3d44e9485,20e109ea9842158a153b24ef42ec5cc3d44e9485,Dave Thaler,dthaler1968@googlemail.com,1705620594,Alexei Starovoitov,ast@kernel.org,1706051408,ba89b7c2fba858d3ad06c588e2cf7c5621ca0a84,b3f086a7a136d721d112f35fe4cd7272e93cf06b,bpf," docs: Clarify that MOVSX is only for BPF_X not BPF_K

Per discussion on the mailing list at
https://mailarchive.ietf.org/arch/msg/bpf/uQiqhURdtxV_ZQOTgjCdm-seh74/
the MOVSX operation is only defined to support register extension.

The document didn't previously state this and incorrectly implied
that one could use an immediate value.

Signed-off-by: Dave Thaler <dthaler1968@gmail.com>
Acked-by: David Vernet <void@manifault.com>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20240118232954.27206-1-dthaler1968@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],"Clarified documentation for MOVSX operation to indicate it's only for BPF_X, not BPF_K.","MOVSX,BPF_X,BPF_K",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
b3f086a7a136d721d112f35fe4cd7272e93cf06b,b3f086a7a136d721d112f35fe4cd7272e93cf06b,Kuniyuki Iwashima,kuniyu@amazon.com,1705612671,Alexei Starovoitov,ast@kernel.org,1706051283,bb5a1af3bcae81082c1c5dc901ce4aa54fa3a93c,2ce793ebe207328b1210bb53effd702740987148,"bpf: Define struct bpf_tcp_req_attrs when CONFIG_SYN_COOKIES=n.

kernel test robot reported the warning below:

  >> net/core/filter.c:11842:13: warning: declaration of 'struct bpf_tcp_req_attrs' will not be visible outside of this function [-Wvisibility]
      11842 |                                         struct bpf_tcp_req_attrs *attrs"," int attrs__sz)
            |                                                ^
     1 warning generated.

struct bpf_tcp_req_attrs is defined under CONFIG_SYN_COOKIES
but used in kfunc without the config.

Let's move struct bpf_tcp_req_attrs definition outside of
CONFIG_SYN_COOKIES guard.

Fixes: e472f88891ab (""bpf: tcp: Support arbitrary SYN Cookie."")
Reported-by: kernel test robot <lkp@intel.com>
Closes: https://lore.kernel.org/oe-kbuild-all/202401180418.CUVc0hxF-lkp@intel.com/
Signed-off-by: Kuniyuki Iwashima <kuniyu@amazon.com>
Link: https://lore.kernel.org/r/20240118211751.25790-1-kuniyu@amazon.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Fix visibility issue by defining struct bpf_tcp_req_attrs outside CONFIG_SYN_COOKIES guard.,"struct bpf_tcp_req_attrs, visibility, CONFIG_SYN_COOKIES",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2ce793ebe207328b1210bb53effd702740987148,2ce793ebe207328b1210bb53effd702740987148,Hao Sun,sunhao.th@gmail.com,1705484412,Alexei Starovoitov,ast@kernel.org,1706050899,b3f25ff4be3cc4edd51e70d5c1330e31cfae9742,40628f9fff73adecac77a9aa390f8016724cad99,"bpf: Refactor ptr alu checking rules to allow alu explicitly

Current checking rules are structured to disallow alu on particular ptr
types explicitly"," so default cases are allowed implicitly. This may lead
to newly added ptr types being allowed unexpectedly. So restruture it to
allow alu explicitly. The tradeoff is mainly a bit more cases added in
the switch. The following table from Eduard summarizes the rules:

        | Pointer type        | Arithmetics allowed |
        |---------------------+---------------------|
        | PTR_TO_CTX          | yes                 |
        | CONST_PTR_TO_MAP    | conditionally       |
        | PTR_TO_MAP_VALUE    | yes                 |
        | PTR_TO_MAP_KEY      | yes                 |
        | PTR_TO_STACK        | yes                 |
        | PTR_TO_PACKET_META  | yes                 |
        | PTR_TO_PACKET       | yes                 |
        | PTR_TO_PACKET_END   | no                  |
        | PTR_TO_FLOW_KEYS    | conditionally       |
        | PTR_TO_SOCKET       | no                  |
        | PTR_TO_SOCK_COMMON  | no                  |
        | PTR_TO_TCP_SOCK     | no                  |
        | PTR_TO_TP_BUFFER    | yes                 |
        | PTR_TO_XDP_SOCK     | no                  |
        | PTR_TO_BTF_ID       | yes                 |
        | PTR_TO_MEM          | yes                 |
        | PTR_TO_BUF          | yes                 |
        | PTR_TO_FUNC         | yes                 |
        | CONST_PTR_TO_DYNPTR | yes                 |

The refactored rules are equivalent to the original one. Note that
PTR_TO_FUNC and CONST_PTR_TO_DYNPTR are not reject here because: (1)
check_mem_access() rejects load/store on those ptrs","[' and those ptrs\nwith offset passing to calls are rejected check_func_arg_reg_off();\n(2) someone may rely on the verifier not rejecting programs earily.\n\nSigned-off-by: Hao Sun <sunhao.th@gmail.com>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20240117094012.36798-1-sunhao.th@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Refactor ptr alu checking rules to explicitly allow certain arithmetic operations on pointer types in eBPF.,"pointer, alu, refactor",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
40628f9fff73adecac77a9aa390f8016724cad99,40628f9fff73adecac77a9aa390f8016724cad99,Andrey Grafin,conquistador@yandex-team.ru,1705496779,Alexei Starovoitov,ast@kernel.org,1706049792,c960edc3617755ecdff1b2bcf9c14d24172e586b,f04deb90e516e8e48bf8693397529bc942a9e80b,"selftest/bpf: Add map_in_maps with BPF_MAP_TYPE_PERF_EVENT_ARRAY values

Check that bpf_object__load() successfully creates map_in_maps
with BPF_MAP_TYPE_PERF_EVENT_ARRAY values.
These changes cover fix in the previous patch
""libbpf: Apply map_set_def_max_entries() for inner_maps on creation"".

A command line output is:
- w/o fix
$ sudo ./test_maps
libbpf: map 'mim_array_pe': failed to create inner map: -22
libbpf: map 'mim_array_pe': failed to create: Invalid argument(-22)
libbpf: failed to load object './test_map_in_map.bpf.o'
Failed to load test prog

- with fix
$ sudo ./test_maps
...
test_maps: OK"," 0 SKIPPED

Fixes: 646f02ffdd49 (""libbpf: Add BTF-defined map-in-map support"")
Signed-off-by: Andrey Grafin <conquistador@yandex-team.ru>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Acked-by: Hou Tao <houtao1@huawei.com>
Link: https://lore.kernel.org/bpf/20240117130619.9403-2-conquistador@yandex-team.ru
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Adds selftest to ensure map_in_maps with BPF_MAP_TYPE_PERF_EVENT_ARRAY values are correctly loaded.,"selftest,map_in_maps,PERF_EVENT_ARRAY",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f04deb90e516e8e48bf8693397529bc942a9e80b,f04deb90e516e8e48bf8693397529bc942a9e80b,Andrey Grafin,conquistador@yandex-team.ru,1705496778,Alexei Starovoitov,ast@kernel.org,1706049792,f69af605856dedb79f0f1a0f767cd94503fb01c2,091f2bf60d52ac205c48dffcb8646ed9299078c9,"libbpf: Apply map_set_def_max_entries() for inner_maps on creation

This patch allows to auto create BPF_MAP_TYPE_ARRAY_OF_MAPS and
BPF_MAP_TYPE_HASH_OF_MAPS with values of BPF_MAP_TYPE_PERF_EVENT_ARRAY
by bpf_object__load().

Previous behaviour created a zero filled btf_map_def for inner maps and
tried to use it for a map creation but the linux kernel forbids to create
a BPF_MAP_TYPE_PERF_EVENT_ARRAY map with max_entries=0.

Fixes: 646f02ffdd49 (""libbpf: Add BTF-defined map-in-map support"")
Signed-off-by: Andrey Grafin <conquistador@yandex-team.ru>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Acked-by: Hou Tao <houtao1@huawei.com>
Link: https://lore.kernel.org/bpf/20240117130619.9403-1-conquistador@yandex-team.ru
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,This commit updates libbpf to correctly set max_entries for inner maps on creation.,"libbpf, inner_maps, max_entries",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
091f2bf60d52ac205c48dffcb8646ed9299078c9,091f2bf60d52ac205c48dffcb8646ed9299078c9,Daniel Borkmann,daniel@iogearbox.net,1705482971,Alexei Starovoitov,ast@kernel.org,1706049792,ddeb882389e6364b536cff7f5259eeb7108f735f,f98df79bf7f772597313adca2720cb38770490dd,"bpf: Sync uapi bpf.h header for the tooling infra

Both commit 91051f003948 (""tcp: Dump bound-only sockets in inet_diag."")
and commit 985b8ea9ec7e (""bpf"," docs: Fix bpf_redirect_peer header doc"")
missed the tooling header sync. Fix it.

Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Sync the uapi bpf.h header for the tooling infrastructure to fix missed commits.,"sync, tooling, header",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f98df79bf7f772597313adca2720cb38770490dd,f98df79bf7f772597313adca2720cb38770490dd,Victor Stewart,v@nametag.social,1705436992,Alexei Starovoitov,ast@kernel.org,1706049792,4bd5d27f3e34ce6a567e1cdfb3c4a0d0c08278bd,4eaafe5a5b7b5f2fcec22914bc5b8b2d860896b7,bpf," docs: Fix bpf_redirect_peer header doc

Amend the bpf_redirect_peer() header documentation to also mention
support for the netkit device type.

Signed-off-by: Victor Stewart <v@nametag.social>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20240116202952.241009-1-v@nametag.social
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Amend the bpf_redirect_peer header documentation to mention netkit device support.,"bpf_redirect_peer, header, documentation",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4eaafe5a5b7b5f2fcec22914bc5b8b2d860896b7,4eaafe5a5b7b5f2fcec22914bc5b8b2d860896b7,Martin KaFai Lau,martin.lau@kernel.org,1705444960,Alexei Starovoitov,ast@kernel.org,1706049771,e9af2ccb810881632330d014ecc83b1726537a16,d177c1be06ce28aa8c8710ac55be1b5ad3f314c6 a74712241b4675175cd8e3310fa206d8756ad5a1,"Merge branch 'bpf: tcp: Support arbitrary SYN Cookie at TC.'

Kuniyuki Iwashima says:

====================
Under SYN Flood"," the TCP stack generates SYN Cookie to remain stateless
for the connection request until a valid ACK is responded to the SYN+ACK.

The cookie contains two kinds of host-specific bits","[' a timestamp and\nsecrets', ' so only can it be validated by the generator.  It means SYN\nCookie consumes network resources between the client and the server;\nintermediate nodes must remember which nodes to route ACK for the cookie.\n\nSYN Proxy reduces such unwanted resource allocation by handling 3WHS at\nthe edge network.  After SYN Proxy completes 3WHS', ' it forwards SYN to the\nbackend server and completes another 3WHS.  However', "" since the server's\nISN differs from the cookie"", ' the proxy must manage the ISN mappings and\nfix up SEQ/ACK numbers in every packet for each connection.  If a proxy\nnode goes down', ' all the connections through it are terminated.  Keeping\na state at proxy is painful from that perspective.\n\nAt AWS', ' we use a dirty hack to build truly stateless SYN Proxy at scale.\nOur SYN Proxy consists of the front proxy layer and the backend kernel\nmodule.  (See slides of LPC2023 [0]', "" p37 - p48)\n\nThe cookie that SYN Proxy generates differs from the kernel's cookie in\nthat it contains a secret (called rolling salt) (i) shared by all the proxy\nnodes so that any node can validate ACK and (ii) updated periodically so\nthat old cookies cannot be validated and we need not encode a timestamp for\nthe cookie.  Also"", ' ISN contains WScale', ' SACK', ' and ECN', ' not in TS val.  This\nis not to sacrifice any connection quality', ' where some customers turn off\nTCP timestamps option due to retro CVE.\n\nAfter 3WHS', ' the proxy restores SYN', ' encapsulates ACK into SYN', ' and forward\nthe TCP-in-TCP packet to the backend server.  Our kernel module works at\nNetfilter input/output hooks and first feeds SYN to the TCP stack to\ninitiate 3WHS.  When the module is triggered for SYN+ACK', "" it looks up the\ncorresponding request socket and overwrites tcp_rsk(req)->snt_isn with the\nproxy's cookie.  Then"", ' the module can complete 3WHS with the original ACK\nas is.\n\nThis way', "" our SYN Proxy does not manage the ISN mappings nor wait for\nSYN+ACK from the backend thus can remain stateless.  It's working very\nwell for high-bandwidth services like multiple Tbps"", ' but we are looking\nfor a way to drop the dirty hack and further optimise the sequences.\n\nIf we could validate an arbitrary SYN Cookie on the backend server with\nBPF', ' the proxy would need not restore SYN nor pass it.  After validating\nACK', ' the proxy node just needs to forward it', ' and then the server can do\nthe lightweight validation (e.g. check if ACK came from proxy nodes', ' etc)\nand create a connection from the ACK.\n\nThis series allows us to create a full sk from an arbitrary SYN Cookie', '\nwhich is done in 3 steps.\n\n  1) At tc', ' BPF prog calls a new kfunc to create a reqsk and configure\n     it based on the argument populated from SYN Cookie.  The reqsk has\n     its listener as req->rsk_listener and is passed to the TCP stack as\n     skb->sk.\n\n  2) During TCP socket lookup for the skb', ' skb_steal_sock() returns a\n     listener in the reuseport group that inet_reqsk(skb->sk)->rsk_listener\n     belongs to.\n\n  3) In cookie_v[46]_check()', ' the reqsk (skb->sk) is fully initialised and\n     a full sk is created.\n\nThe kfunc usage is as follows:\n\n    struct bpf_tcp_req_attrs attrs = {\n        .mss = mss', '\n        .wscale_ok = wscale_ok', '\n        .rcv_wscale = rcv_wscale', "" /* Server's WScale < 15 */\n        .snd_wscale = snd_wscale"", "" /* Client's WScale < 15 */\n        .tstamp_ok = tstamp_ok"", '\n        .rcv_tsval = tsval', '\n        .rcv_tsecr = tsecr', "" /* Server's Initial TSval */\n        .usec_ts_ok = usec_ts_ok"", '\n        .sack_ok = sack_ok', '\n        .ecn_ok = ecn_ok', '\n    }\n\n    skc = bpf_skc_lookup_tcp(...);\n    sk = (struct sock *)bpf_skc_to_tcp_sock(skc);\n    bpf_sk_assign_tcp_reqsk(skb', ' sk', ' attrs', "" sizeof(attrs));\n    bpf_sk_release(skc);\n\n[0]: https://lpc.events/event/17/contributions/1645/attachments/1350/2701/SYN_Proxy_at_Scale_with_BPF.pdf\n\nChanges:\n  v8\n    * Rebase on Yonghong's cpuv4 fix\n    * Patch 5\n      * Fill the trailing 3-bytes padding in struct bpf_tcp_req_attrs\n        and test it as null\n    * Patch 6\n      * Remove unused IPPROTP_MPTCP definition\n\n  v7: https://lore.kernel.org/bpf/20231221012806.37137-1-kuniyu@amazon.com/\n    * Patch 5 & 6\n      * Drop MPTCP support\n\n  v6: https://lore.kernel.org/bpf/20231214155424.67136-1-kuniyu@amazon.com/\n    * Patch 5 & 6\n      * /struct /s/tcp_cookie_attributes/bpf_tcp_req_attrs/\n      * Don't reuse struct tcp_options_received and use u8 for each attrs\n    * Patch 6\n      * Check retval of test__start_subtest()\n\n  v5: https://lore.kernel.org/netdev/20231211073650.90819-1-kuniyu@amazon.com/\n    * Split patch 1-3\n    * Patch 3\n      * Clear req->rsk_listener in skb_steal_sock()\n    * Patch 4 & 5\n      * Move sysctl validation and tsoff init from cookie_bpf_check() to kfunc\n    * Patch 5\n      * Do not increment LINUX_MIB_SYNCOOKIES(RECV|FAILED)\n    * Patch 6\n      * Remove __always_inline\n      * Test if tcp_handle_{syn"", ""ack}() is executed\n      * Move some definition to bpf_tracing_net.h\n      * s/BPF_F_CURRENT_NETNS/-1/\n\n  v4: https://lore.kernel.org/bpf/20231205013420.88067-1-kuniyu@amazon.com/\n    * Patch 1 & 2\n      * s/CONFIG_SYN_COOKIE/CONFIG_SYN_COOKIES/\n    * Patch 1\n      * Don't set rcv_wscale for BPF SYN Cookie case.\n    * Patch 2\n      * Add test for tcp_opt.{unused"", 'rcv_wscale} in kfunc\n      * Modify skb_steal_sock() to avoid resetting skb-sk\n      * Support SO_REUSEPORT lookup\n    * Patch 3\n      * Add CONFIG_SYN_COOKIES to Kconfig for CI\n      * Define BPF_F_CURRENT_NETNS\n\n  v3: https://lore.kernel.org/netdev/20231121184245.69569-1-kuniyu@amazon.com/\n    * Guard kfunc and req->syncookie part in inet6?_steal_sock() with\n      CONFIG_SYN_COOKIE\n\n  v2: https://lore.kernel.org/netdev/20231120222341.54776-1-kuniyu@amazon.com/\n    * Drop SOCK_OPS and move SYN Cookie validation logic to TC with kfunc.\n    * Add cleanup patches to reduce discrepancy between cookie_v[46]_check()\n\n  v1: https://lore.kernel.org/bpf/20231013220433.70792-1-kuniyu@amazon.com/\n====================\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Support added for arbitrary SYN Cookie in TCP under TC to handle SYN Floods.,"SYN Cookie, TCP, TC",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['tc/netfilter like programs']
a74712241b4675175cd8e3310fa206d8756ad5a1,a74712241b4675175cd8e3310fa206d8756ad5a1,Kuniyuki Iwashima,kuniyu@amazon.com,1705352114,Alexei Starovoitov,ast@kernel.org,1706049624,e9af2ccb810881632330d014ecc83b1726537a16,e472f88891abbc535a5e16a68a104073985f6061,"selftest: bpf: Test bpf_sk_assign_tcp_reqsk().

This commit adds a sample selftest to demonstrate how we can use
bpf_sk_assign_tcp_reqsk() as the backend of SYN Proxy.

The test creates IPv4/IPv6 x TCP connections and transfer messages
over them on lo with BPF tc prog attached.

The tc prog will process SYN and returns SYN+ACK with the following
ISN and TS.  In a real use case"," this part will be done by other
hosts.

        MSB                                   LSB
  ISN:  | 31 ... 8 | 7 6 |   5 |    4 | 3 2 1 0 |
        |   Hash_1 | MSS | ECN | SACK |  WScale |

  TS:   | 31 ... 8 |          7 ... 0           |
        |   Random |           Hash_2           |

  WScale in SYN is reused in SYN+ACK.

The client returns ACK","["" and tc prog will recalculate ISN and TS\nfrom ACK and validate SYN Cookie.\n\nIf it's valid"", ' the prog calls kfunc to allocate a reqsk for skb and\nconfigure the reqsk based on the argument created from SYN Cookie.\n\nLater', ' the reqsk will be processed in cookie_v[46]_check() to create\na connection.\n\nSigned-off-by: Kuniyuki Iwashima <kuniyu@amazon.com>\nLink: https://lore.kernel.org/r/20240115205514.68364-7-kuniyu@amazon.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit adds a selftest for bpf_sk_assign_tcp_reqsk function using BPF tc program for TCP SYN Proxy backend.,"selftest,BPF tc,bpf_sk_assign_tcp_reqsk",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tc/netfilter like programs']
e472f88891abbc535a5e16a68a104073985f6061,e472f88891abbc535a5e16a68a104073985f6061,Kuniyuki Iwashima,kuniyu@amazon.com,1705352113,Alexei Starovoitov,ast@kernel.org,1706049624,bf5fa7d7e631cb74d6bc29759fd1cfefc7927d3b,695751e31a63efd2bbe6779873adf1e4deb00cd5,"bpf: tcp: Support arbitrary SYN Cookie.

This patch adds a new kfunc available at TC hook to support arbitrary
SYN Cookie.

The basic usage is as follows:

    struct bpf_tcp_req_attrs attrs = {
        .mss = mss","
        .wscale_ok = wscale_ok","['\n        .rcv_wscale = rcv_wscale', "" /* Server's WScale < 15 */\n        .snd_wscale = snd_wscale"", "" /* Client's WScale < 15 */\n        .tstamp_ok = tstamp_ok"", '\n        .rcv_tsval = tsval', '\n        .rcv_tsecr = tsecr', "" /* Server's Initial TSval */\n        .usec_ts_ok = usec_ts_ok"", '\n        .sack_ok = sack_ok', '\n        .ecn_ok = ecn_ok', '\n    }\n\n    skc = bpf_skc_lookup_tcp(...);\n    sk = (struct sock *)bpf_skc_to_tcp_sock(skc);\n    bpf_sk_assign_tcp_reqsk(skb', ' sk', ' attrs', ' sizeof(attrs));\n    bpf_sk_release(skc);\n\nbpf_sk_assign_tcp_reqsk() takes skb', ' a listener sk', ' and struct\nbpf_tcp_req_attrs and allocates reqsk and configures it.  Then', '\nbpf_sk_assign_tcp_reqsk() links reqsk with skb and the listener.\n\nThe notable thing here is that we do not hold refcnt for both reqsk\nand listener.  To differentiate that', ' we mark reqsk->syncookie', ' which\nis only used in TX for now.  So', ' if reqsk->syncookie is 1 in RX', ' it\nmeans that the reqsk is allocated by kfunc.\n\nWhen skb is freed', ' sock_pfree() checks if reqsk->syncookie is 1', '\nand in that case', ' we set NULL to reqsk->rsk_listener before calling\nreqsk_free() as reqsk does not hold a refcnt of the listener.\n\nWhen the TCP stack looks up a socket from the skb', ' we steal the\nlistener from the reqsk in skb_steal_sock() and create a full sk\nin cookie_v[46]_check().\n\nThe refcnt of reqsk will finally be set to 1 in tcp_get_cookie_sock()\nafter creating a full sk.\n\nNote that we can extend struct bpf_tcp_req_attrs in the future when\nwe add a new attribute that is determined in 3WHS.\n\nSigned-off-by: Kuniyuki Iwashima <kuniyu@amazon.com>\nLink: https://lore.kernel.org/r/20240115205514.68364-6-kuniyu@amazon.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add a kfunc for arbitrary SYN Cookie support at TC hook in BPF.,"SYN Cookie, TC hook, kfunc",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['tc/netfilter like programs']
695751e31a63efd2bbe6779873adf1e4deb00cd5,695751e31a63efd2bbe6779873adf1e4deb00cd5,Kuniyuki Iwashima,kuniyu@amazon.com,1705352112,Alexei Starovoitov,ast@kernel.org,1706049624,41904868bb6f47e98aa75ab19e148d03c52514a2,8b5ac68fb5ee416537c1214cbacf0ddc4293cce9,"bpf: tcp: Handle BPF SYN Cookie in cookie_v[46]_check().

We will support arbitrary SYN Cookie with BPF in the following
patch.

If BPF prog validates ACK and kfunc allocates a reqsk"," it will
be carried to cookie_[46]_check() as skb->sk.  If skb->sk is not
NULL","[' we call cookie_bpf_check().\n\nThen', ' we clear skb->sk and skb->destructor', ' which are needed not\nto hold refcnt for reqsk and the listener.  See the following patch\nfor details.\n\nAfter that', ' we finish initialisation for the remaining fields with\ncookie_tcp_reqsk_init().\n\nNote that the server side WScale is set only for non-BPF SYN Cookie.\n\nSigned-off-by: Kuniyuki Iwashima <kuniyu@amazon.com>\nLink: https://lore.kernel.org/r/20240115205514.68364-5-kuniyu@amazon.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Enhances TCP handling by managing BPF SYN Cookies in the cookie_v[46]_check functions.,"SYN Cookie,BPF,ACK",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['tc/netfilter like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8b5ac68fb5ee416537c1214cbacf0ddc4293cce9,8b5ac68fb5ee416537c1214cbacf0ddc4293cce9,Kuniyuki Iwashima,kuniyu@amazon.com,1705352111,Alexei Starovoitov,ast@kernel.org,1706049624,b34d2e597746829ffeb492a42a3532605e5ddb3c,95e752b5299fa8c90099f7bc2aa1ee3e2e2c95ab,"bpf: tcp: Handle BPF SYN Cookie in skb_steal_sock().

We will support arbitrary SYN Cookie with BPF.

If BPF prog validates ACK and kfunc allocates a reqsk"," it will
be carried to TCP stack as skb->sk with req->syncookie 1.  Also","['\nthe reqsk has its listener as req->rsk_listener with no refcnt\ntaken.\n\nWhen the TCP stack looks up a socket from the skb', ' we steal\ninet_reqsk(skb->sk)->rsk_listener in skb_steal_sock() so that\nthe skb will be processed in cookie_v[46]_check() with the\nlistener.\n\nNote that we do not clear skb->sk and skb->destructor so that we\ncan carry the reqsk to cookie_v[46]_check().\n\nSigned-off-by: Kuniyuki Iwashima <kuniyu@amazon.com>\nLink: https://lore.kernel.org/r/20240115205514.68364-4-kuniyu@amazon.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Enhance BPF to handle arbitrary SYN cookies in TCP with skb_steal_sock().,"BPF,SYN Cookie,TCP",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).', 'other']"
d177c1be06ce28aa8c8710ac55be1b5ad3f314c6,d177c1be06ce28aa8c8710ac55be1b5ad3f314c6,Artem Savkov,asavkov@redhat.com,1704877057,Alexei Starovoitov,ast@kernel.org,1706049623,ab822b88b22a6f8892eda0a9752092fedb63bf3a,f5f30386c78105cba520e443a6a9ee945ec1d066,"selftests/bpf: Fix potential premature unload in bpf_testmod

It is possible for bpf_kfunc_call_test_release() to be called from
bpf_map_free_deferred() when bpf_testmod is already unloaded and
perf_test_stuct.cnt which it tries to decrease is no longer in memory.
This patch tries to fix the issue by waiting for all references to be
dropped in bpf_testmod_exit().

The issue can be triggered by running 'test_progs -t map_kptr' in 6.5","
but is obscured in 6.6 by d119357d07435 (""rcu-tasks: Treat only
synchronous grace periods urgently"").

Fixes: 65eb006d85a2 (""bpf: Move kernel test kfuncs to bpf_testmod"")
Signed-off-by: Artem Savkov <asavkov@redhat.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Cc: Jiri Olsa <jolsa@kernel.org>
Link: https://lore.kernel.org/bpf/82f55c0e-0ec8-4fe1-8d8c-b1de07558ad9@linux.dev
Link: https://lore.kernel.org/bpf/20240110085737.8895-1-asavkov@redhat.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Fixes potential premature unloading issue in bpf_testmod during reference drop in selftests.,"premature unload,selftests,bpf_testmod",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f5f30386c78105cba520e443a6a9ee945ec1d066,f5f30386c78105cba520e443a6a9ee945ec1d066,Tiezhu Yang,yangtiezhu@loongson.cn,1705385960,Alexei Starovoitov,ast@kernel.org,1706049623,db009a8d2aabeac49a997c93f2743365558642c9,49c06547d5218b54fbcc6011864b8c8e3aa0b565,"bpftool: Silence build warning about calloc()

There exists the following warning when building bpftool:

  CC      prog.o
prog.c: In function ‘profile_open_perf_events’:
prog.c:2301:24: warning: ‘calloc’ sizes specified with ‘sizeof’ in the earlier argument and not in the later argument [-Wcalloc-transposed-args]
 2301 |                 sizeof(int)"," obj->rodata->num_cpu * obj->rodata->num_metric);
      |                        ^~~
prog.c:2301:24: note: earlier argument should specify number of elements","[' later size of each element\n\nTested with the latest upstream GCC which contains a new warning option\n-Wcalloc-transposed-args. The first argument to calloc is documented to\nbe number of elements in array', ' while the second argument is size of each\nelement', ' just switch the first and second arguments of calloc() to silence\nthe build warning', ' compile tested only.\n\nFixes: 47c09d6a9f67 (""bpftool: Introduce ""prog profile"" command"")\nSigned-off-by: Tiezhu Yang <yangtiezhu@loongson.cn>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Quentin Monnet <quentin@isovalent.com>\nLink: https://lore.kernel.org/bpf/20240116061920.31172-1-yangtiezhu@loongson.cn\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix build warning in bpftool related to incorrect usage of calloc.,"bpftool, calloc, warning",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"[""It's not related to any of the above.""]"
49c06547d5218b54fbcc6011864b8c8e3aa0b565,49c06547d5218b54fbcc6011864b8c8e3aa0b565,Alexei Starovoitov,ast@kernel.org,1705096894,Alexei Starovoitov,ast@kernel.org,1706049623,16ac97b8b9e0c296cdffe5603c10c33cd7b52665,88031b929c01fe3686d34a848c413c2e51e6a7c8,"bpf: Minor improvements for bpf_cmp.

Few minor improvements for bpf_cmp() macro:
. reduce number of args in __bpf_cmp()
. rename NOFLIP to UNLIKELY
. add a comment about 64-bit truncation in ""i"" constraint
. use ""ri"" constraint for sizeof(rhs) <= 4
. improve error message for bpf_cmp_likely()

Before:
progs/iters_task_vma.c:31:7: error: variable 'ret' is uninitialized when used here [-Werror","-Wuninitialized]
   31 |                 if (bpf_cmp_likely(seen","[' <==', "" 1000))\n      |                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n../bpf/bpf_experimental.h:325:3: note: expanded from macro 'bpf_cmp_likely'\n  325 |                 ret;\n      |                 ^~~\nprogs/iters_task_vma.c:31:7: note: variable 'ret' is declared here\n../bpf/bpf_experimental.h:310:3: note: expanded from macro 'bpf_cmp_likely'\n  310 |                 bool ret;\n      |                 ^\n\nAfter:\nprogs/iters_task_vma.c:31:7: error: invalid operand for instruction\n   31 |                 if (bpf_cmp_likely(seen"", ' <==', ' 1000))\n      |                     ^\n../bpf/bpf_experimental.h:324:17: note: expanded from macro \'bpf_cmp_likely\'\n  324 |                         asm volatile(""r0 "" #OP "" invalid compare"");\n      |                                      ^\n<inline asm>:1:5: note: instantiated into assembly here\n    1 |         r0 <== invalid compare\n      |            ^\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/bpf/20240112220134.71209-1-alexei.starovoitov@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Minor improvements made to bpf_cmp macro for better usage and error handling.,"bpf_cmp, macro, improvements",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
88031b929c01fe3686d34a848c413c2e51e6a7c8,88031b929c01fe3686d34a848c413c2e51e6a7c8,Yonghong Song,yonghong.song@linux.dev,1704950496,Alexei Starovoitov,ast@kernel.org,1706049623,01abae8ed27f9b646851e7b0662fa53ed401f2ac,6ae99ac8b7da30c9fdb15e380624dbc41f8200c8,"docs/bpf: Fix an incorrect statement in verifier.rst

In verifier.rst"," I found an incorrect statement (maybe a typo) in section
'Liveness marks tracking'. Basically","[' the wrong register is attributed\nto have a read mark. This may confuse the user.\n\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20240111052136.3440417-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes an incorrect statement in the BPF verifier documentation under 'Liveness marks tracking' section.,verifier fix documentation,It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6ae99ac8b7da30c9fdb15e380624dbc41f8200c8,6ae99ac8b7da30c9fdb15e380624dbc41f8200c8,Yonghong Song,yonghong.song@linux.dev,1704863635,Alexei Starovoitov,ast@kernel.org,1706049623,f5c6c46df17c2350447ed9c8bad37bc2a4aeee47,9a4c57f52b5e0de3a6b1f40c5b656730ce33ee01,"selftests/bpf: Add a selftest with not-8-byte aligned BPF_ST

Add a selftest with a 4 bytes BPF_ST of 0 where the store is not
8-byte aligned. The goal is to ensure that STACK_ZERO is properly
marked in stack slots and the STACK_ZERO value can propagate
properly during the load.

Acked-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20240110051355.2737232-1-yonghong.song@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add a selftest to ensure proper STACK_ZERO propagation with non-8-byte aligned BPF_ST operations.,"selftest, BPF_ST, STACK_ZERO",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9a4c57f52b5e0de3a6b1f40c5b656730ce33ee01,9a4c57f52b5e0de3a6b1f40c5b656730ce33ee01,Yonghong Song,yonghong.song@linux.dev,1704863628,Alexei Starovoitov,ast@kernel.org,1706049623,8932505083b07bde8123fea88f57aad54ef120a7,3893f0b6a0698aeeb3d27cb22baef7c4ca1a07f1,"bpf: Track aligned st store as imprecise spilled registers

With patch set [1]"," precision backtracing supports register spill/fill
to/from the stack. The patch [2] allows initial imprecise register spill
with content 0. This is a common case for cpuv3 and lower for
initializing the stack variables with pattern
  r1 = 0
  *(u64 *)(r10 - 8) = r1
and the [2] has demonstrated good verification improvement.

For cpuv4","[' the initialization could be\n  *(u64 *)(r10 - 8) = 0\nThe current verifier marks the r10-8 contents with STACK_ZERO.\nSimilar to [2]', ' let us permit the above insn to behave like\nimprecise register spill which can reduce number of verified states.\nThe change is in function check_stack_write_fixed_off().\n\nBefore this patch', ' spilled zero will be marked as STACK_ZERO\nwhich can provide precise values. In check_stack_write_var_off()', ""\nSTACK_ZERO will be maintained if writing a const zero\nso later it can provide precise values if needed.\n\nThe above handling of '*(u64 *)(r10 - 8) = 0' as a spill\nwill have issues in check_stack_write_var_off() as the spill\nwill be converted to STACK_MISC and the precise value 0\nis lost. To fix this issue"", ' if the spill slots with const\nzero and the BPF_ST write also with const zero', ' the spill slots\nare preserved', ' which can later provide precise values\nif needed. Without the change in check_stack_write_var_off()', ""\nthe test_verifier subtest 'BPF_ST_MEM stack imm zero"", "" variable offset'\nwill fail.\n\nI checked cpuv3 and cpuv4 with and without this patch with veristat.\nThere is no state change for cpuv3 since '*(u64 *)(r10 - 8) = 0'\nis only generated with cpuv4.\n\nFor cpuv4:\n$ ../veristat -C old.cpuv4.csv new.cpuv4.csv -e file"", 'prog', 'insns', ""states -f 'insns_diff!=0'\nFile                                        Program              Insns (A)  Insns (B)  Insns    (DIFF)  States (A)  States (B)  States (DIFF)\n------------------------------------------  -------------------  ---------  ---------  ---------------  ----------  ----------  -------------\nlocal_storage_bench.bpf.linked3.o           get_local                  228        168    -60 (-26.32%)          17          14   -3 (-17.65%)\npyperf600_bpf_loop.bpf.linked3.o            on_event                  6066       4889  -1177 (-19.40%)         403         321  -82 (-20.35%)\ntest_cls_redirect.bpf.linked3.o             cls_redirect             35483      35387     -96 (-0.27%)        2179        2177    -2 (-0.09%)\ntest_l4lb_noinline.bpf.linked3.o            balancer_ingress          4494       4522     +28 (+0.62%)         217         219    +2 (+0.92%)\ntest_l4lb_noinline_dynptr.bpf.linked3.o     balancer_ingress          1432       1455     +23 (+1.61%)          92          94    +2 (+2.17%)\ntest_xdp_noinline.bpf.linked3.o             balancer_ingress_v6       3462       3458      -4 (-0.12%)         216         216    +0 (+0.00%)\nverifier_iterating_callbacks.bpf.linked3.o  widening                    52         41    -11 (-21.15%)           4           3   -1 (-25.00%)\nxdp_synproxy_kern.bpf.linked3.o             syncookie_tc             12412      11719    -693 (-5.58%)         345         330   -15 (-4.35%)\nxdp_synproxy_kern.bpf.linked3.o             syncookie_xdp            12478      11794    -684 (-5.48%)         346         331   -15 (-4.34%)\n\ntest_l4lb_noinline and test_l4lb_noinline_dynptr has minor regression"", ' but\npyperf600_bpf_loop and local_storage_bench gets pretty good improvement.\n\n  [1] https://lore.kernel.org/all/20231205184248.1502704-1-andrii@kernel.org/\n  [2] https://lore.kernel.org/all/20231205184248.1502704-9-andrii@kernel.org/\n\nCc: Kuniyuki Iwashima <kuniyu@amazon.com>\nCc: Martin KaFai Lau <kafai@fb.com>\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nTested-by: Kuniyuki Iwashima <kuniyu@amazon.com>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240110051348.2737007-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit improves precision of register spill/fill verification for aligned store in eBPF programs.,"aligned store, register spill, precision",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3893f0b6a0698aeeb3d27cb22baef7c4ca1a07f1,3893f0b6a0698aeeb3d27cb22baef7c4ca1a07f1,Maxim Mikityanskiy,maxim@isovalent.com,1704747123,Alexei Starovoitov,ast@kernel.org,1706049623,f74b1463fa15dbfdbf1bd765f939b9906631b2f2,8ecfc371d829bfed75e0ef2cab45b2290b982f64,"selftests/bpf: Test assigning ID to scalars on spill

The previous commit implemented assigning IDs to registers holding
scalars before spill. Add the test cases to check the new functionality.

Signed-off-by: Maxim Mikityanskiy <maxim@isovalent.com>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20240108205209.838365-10-maxtram95@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit adds test cases for assigning IDs to scalar registers before spill in selftests.,"test cases, scalars, spill",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8ecfc371d829bfed75e0ef2cab45b2290b982f64,8ecfc371d829bfed75e0ef2cab45b2290b982f64,Maxim Mikityanskiy,maxim@isovalent.com,1704747122,Alexei Starovoitov,ast@kernel.org,1706049623,5d245cf62f2a544b828f743091ca1fbcde6ee8b6,87e51ac6cb19c5d33d70d4cae9e26d2a3a5fcba0,"bpf: Assign ID to scalars on spill

Currently", when a scalar bounded register is spilled to the stack,"[' its\nID is preserved', ' but only if was already assigned', ' i.e. if this register\nwas MOVed before.\n\nAssign an ID on spill if none is set', ' so that equal scalars could be\ntracked if a register is spilled to the stack and filled into another\nregister.\n\nOne test is adjusted to reflect the change in register IDs.\n\nSigned-off-by: Maxim Mikityanskiy <maxim@isovalent.com>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20240108205209.838365-9-maxtram95@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Assign unique IDs to scalars when they are spilled to the stack in the BPF verifier.,"scalars, IDs, spill",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
87e51ac6cb19c5d33d70d4cae9e26d2a3a5fcba0,87e51ac6cb19c5d33d70d4cae9e26d2a3a5fcba0,Maxim Mikityanskiy,maxim@isovalent.com,1704747121,Alexei Starovoitov,ast@kernel.org,1706049623,2d101b89155501e3ece3705a989a57ad327b44ff,8e0e074aafb8fec227363ed905ddd2ac7e4575e4,"bpf: Add the get_reg_width function

Put calculation of the register value width into a dedicated function.
This function will also be used in a following commit.

Signed-off-by: Maxim Mikityanskiy <maxim@isovalent.com>
Link: https://lore.kernel.org/r/20240108205209.838365-8-maxtram95@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Introduces a dedicated function to calculate register value width in eBPF.,"register,function,get_reg_width",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8e0e074aafb8fec227363ed905ddd2ac7e4575e4,8e0e074aafb8fec227363ed905ddd2ac7e4575e4,Maxim Mikityanskiy,maxim@isovalent.com,1704747120,Alexei Starovoitov,ast@kernel.org,1706049622,a8a939758f2ad18de7b344d1980e87ab0cd2c322,b827eee4c4d83ad92094b38d49cfec6844fb5863,"bpf: Add the assign_scalar_id_before_mov function

Extract the common code that generates a register ID for src_reg before
MOV if needed into a new function. This function will also be used in
a following commit.

Signed-off-by: Maxim Mikityanskiy <maxim@isovalent.com>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20240108205209.838365-7-maxtram95@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Extracts common code for generating register ID into a new function for reuse before MOV operations.,"register, function, MOV",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b827eee4c4d83ad92094b38d49cfec6844fb5863,b827eee4c4d83ad92094b38d49cfec6844fb5863,Maxim Mikityanskiy,maxim@isovalent.com,1704747119,Alexei Starovoitov,ast@kernel.org,1706049622,10886b0e37fadc9d6c9abacb4b96b8fd42b5cd90,32f55dd4add4df1a5bc8febc1fafd3086290dbf6,"selftests/bpf: Add a test case for 32-bit spill tracking

When a range check is performed on a register that was 32-bit spilled to
the stack", the IDs of the two instances of the register are the same,"[' so\nthe range should also be the same.\n\nSigned-off-by: Maxim Mikityanskiy <maxim@isovalent.com>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20240108205209.838365-6-maxtram95@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Added a selftest for verifying 32-bit spill tracking in BPF programs.,"selftests,32-bit,spill",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
32f55dd4add4df1a5bc8febc1fafd3086290dbf6,32f55dd4add4df1a5bc8febc1fafd3086290dbf6,Maxim Mikityanskiy,maxim@isovalent.com,1704747118,Alexei Starovoitov,ast@kernel.org,1706049622,fe863af03a5060bd15176ee4d484dba73e6c8919,c035b3e555b5642f786fb2d089a6ddf7b00eb374,"bpf: Make bpf_for_each_spilled_reg consider narrow spills

Adjust the check in bpf_get_spilled_reg to take into account spilled
registers narrower than 64 bits. That allows find_equal_scalars to
properly adjust the range of all spilled registers that have the same
ID. Before this change"," it was possible for a register and a spilled
register to have the same IDs but different ranges if the spill was
narrower than 64 bits and a range check was performed on the register.

Signed-off-by: Maxim Mikityanskiy <maxim@isovalent.com>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20240108205209.838365-5-maxtram95@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The commit adjusts the bpf_get_spilled_reg function to handle narrower spills under 64 bits properly.,"bpf,narrower spills,registers",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c035b3e555b5642f786fb2d089a6ddf7b00eb374,c035b3e555b5642f786fb2d089a6ddf7b00eb374,Eduard Zingerman,eddyz87@gmail.com,1704747117,Alexei Starovoitov,ast@kernel.org,1706049622,568c8bfd477b4610624c43ebcd1dd0137ea95ca8,d5b892fd607abec2a1e49b6a2afc278c329a0ee2,"selftests/bpf: check if imprecise stack spills confuse infinite loop detection

Verify that infinite loop detection logic separates states with
identical register states but different imprecise scalars spilled to
stack.

Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20240108205209.838365-4-maxtram95@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit adds a selftest to verify eBPF's infinite loop detection when dealing with imprecise stack spills.,"selftests, detection, stack spills",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d5b892fd607abec2a1e49b6a2afc278c329a0ee2,d5b892fd607abec2a1e49b6a2afc278c329a0ee2,Eduard Zingerman,eddyz87@gmail.com,1704747116,Alexei Starovoitov,ast@kernel.org,1706049622,50975743c8d1ad2caf70a4487f7f37f276dd71e8,242d18514149d86b431b6f5db5a33579ea79ebad,"bpf: make infinite loop detection in is_state_visited() exact

Current infinite loops detection mechanism is speculative:
- first"," states_maybe_looping() check is done which simply does memcmp
  for R1-R10 in current frame;
- second","[' states_equal(...', ' exact=false) is called. With exact=false\n  states_equal() would compare scalars for equality only if in old\n  state scalar has precision mark.\n\nSuch logic might be problematic if compiler makes some unlucky stack\nspill/fill decisions. An artificial example of a false positive looks\nas follows:\n\n        r0 = ... unknown scalar ...\n        r0 &= 0xff;\n        *(u64 *)(r10 - 8) = r0;\n        r0 = 0;\n    loop:\n        r0 = *(u64 *)(r10 - 8);\n        if r0 > 10 goto exit_;\n        r0 += 1;\n        *(u64 *)(r10 - 8) = r0;\n        r0 = 0;\n        goto loop;\n\nThis commit updates call to states_equal to use exact=true', ' forcing\nall scalar comparisons to be exact.\n\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20240108205209.838365-3-maxtram95@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit improves the detection of infinite loops in is_state_visited() within the bpf verification process.,"infinite loops,detection,verification",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
242d18514149d86b431b6f5db5a33579ea79ebad,242d18514149d86b431b6f5db5a33579ea79ebad,Maxim Mikityanskiy,maxim@isovalent.com,1704747115,Alexei Starovoitov,ast@kernel.org,1706049622,f672979d6f27e721f583bcf165f14dbc70512249,f067074bafd5060428211ee7bb8a3f86ff6bc58d,"selftests/bpf: Fix the u64_offset_to_skb_data test

The u64_offset_to_skb_data test is supposed to make a 64-bit fill"," but
instead makes a 16-bit one. Fix the test according to its intention and
update the comments accordingly (umax is no longer 0xffff). The 16-bit
fill is covered by u16_offset_to_skb_data.

Signed-off-by: Maxim Mikityanskiy <maxim@isovalent.com>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20240108205209.838365-2-maxtram95@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Fix the u64_offset_to_skb_data test to properly perform 64-bit fill and update comments.,"fix,test,64-bit",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f067074bafd5060428211ee7bb8a3f86ff6bc58d,f067074bafd5060428211ee7bb8a3f86ff6bc58d,Nathan Chancellor,nathan@kernel.org,1705004208,Alexei Starovoitov,ast@kernel.org,1706049622,a96fdd2853f261cfeee38c8df26e64bb6f09c40e,56d3e44af80c6b4c7cb89a73061ee35d4a7aee18,"selftests/bpf: Update LLVM Phabricator links

reviews.llvm.org was LLVM's Phabricator instances for code review. It
has been abandoned in favor of GitHub pull requests. While the majority
of links in the kernel sources still work because of the work Fangrui
has done turning the dynamic Phabricator instance into a static archive","
there are some issues with that work","[' so preemptively convert all the\nlinks in the kernel sources to point to the commit on GitHub.\n\nMost of the commits have the corresponding differential review link in\nthe commit message itself so there should not be any loss of fidelity in\nthe relevant information.\n\nAdditionally', ' fix a typo in the xdpwall.c print (""LLMV"" -> ""LLVM"") while\nin the area.\n\nLink: https://discourse.llvm.org/t/update-on-github-pull-requests/71540/172\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Nathan Chancellor <nathan@kernel.org>\nLink: https://lore.kernel.org/r/20240111-bpf-update-llvm-phabricator-links-v2-1-9a7ae976bd64@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Update LLVM Phabricator links in selftests to use new GitHub pull request locations.,"LLVM,Phabricator,GitHub",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
56d3e44af80c6b4c7cb89a73061ee35d4a7aee18,56d3e44af80c6b4c7cb89a73061ee35d4a7aee18,Andrii Nakryiko,andrii@kernel.org,1704842258,Alexei Starovoitov,ast@kernel.org,1706049622,fce1436714441a69d07d5e22171399b916e5a984,81777efbf59305fa145bede97dd4abdc35540578,"selftests/bpf: detect testing prog flags support

Various tests specify extra testing prog_flags when loading BPF
programs", like BPF_F_TEST_RND_HI32,"[' and more recently also\nBPF_F_TEST_REG_INVARIANTS. While BPF_F_TEST_RND_HI32 is old enough to\nnot cause much problem on older kernels', ' BPF_F_TEST_REG_INVARIANTS is\nvery fresh and unconditionally specifying it causes selftests to fail on\neven slightly outdated kernels.\n\nThis breaks libbpf CI test against 4.9 and 5.15 kernels', ' it can break\nsome local development (done outside of VM)', ' etc.\n\nTo prevent this', ' and guard against similar problems in the future', ' do\nruntime detection of supported ""testing flags""', ' and only provide those\nthat host kernel recognizes.\n\nAcked-by: Song Liu <song@kernel.org>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240109231738.575844-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Enable selftests to detect support for testing prog_flags when loading BPF programs.,"selftests, prog_flags, BPF",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tracepoints like programs']
15b8b0be985592fd19ee4e661d13d291877b09c7,15b8b0be985592fd19ee4e661d13d291877b09c7,Randy Dunlap,rdunlap@infradead.org,1704524145,Alexei Starovoitov,ast@kernel.org,1706049622,51b2adbba6d5c5104a7814083ee0cd2ac18f44e3,522bb2c1f82b12eb7befaae815d1d959b8e6bba2,"net: filter: fix spelling mistakes

Fix spelling errors as reported by codespell.

Signed-off-by: Randy Dunlap <rdunlap@infradead.org>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Andrii Nakryiko <andrii@kernel.org>
Cc: bpf@vger.kernel.org
Cc: ""David S. Miller"" <davem@davemloft.net>
Cc: Eric Dumazet <edumazet@google.com>
Cc: Jakub Kicinski <kuba@kernel.org>
Cc: Paolo Abeni <pabeni@redhat.com>
Reviewed-by: Simon Horman <horms@kernel.org>
Link: https://lore.kernel.org/r/20240106065545.16855-1-rdunlap@infradead.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,This commit fixes spelling mistakes in the net filter code.,"spelling, mistakes, codespell",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","[""It's not related to any of the above.""]"
522bb2c1f82b12eb7befaae815d1d959b8e6bba2,522bb2c1f82b12eb7befaae815d1d959b8e6bba2,Andrii Nakryiko,andrii@kernel.org,1704413345,Alexei Starovoitov,ast@kernel.org,1706049621,7ff504f352fe6f75aa63f2c612504b0ffbe22483,54c11ec4935a61af32bb03fc52e7172c97bd7203,"bpf: support multiple tags per argument

Add ability to iterate multiple decl_tag types pointed to the same
function argument. Use this to support multiple __arg_xxx tags per
global subprog argument.

We leave btf_find_decl_tag_value() intact"," but change its implementation
to use a new btf_find_next_decl_tag() which can be straightforwardly
used to find next BTF type ID of a matching btf_decl_tag type.
btf_prepare_func_args() is switched from btf_find_decl_tag_value() to
btf_find_next_decl_tag() to gain multiple tags per argument support.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20240105000909.2818934-5-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],This commit adds support for multiple declaration tags per function argument in eBPF.,"multiple tags, function argument, btf",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
54c11ec4935a61af32bb03fc52e7172c97bd7203,54c11ec4935a61af32bb03fc52e7172c97bd7203,Andrii Nakryiko,andrii@kernel.org,1704413344,Alexei Starovoitov,ast@kernel.org,1706049621,655a4689d743a3b584a9247ffcaf64415efa2ed4,18810ad3929ff6b5d8e67e3adc40d690bd780fd6,"bpf: prepare btf_prepare_func_args() for multiple tags per argument

Add btf_arg_tag flags enum to be able to record multiple tags per
argument. Also streamline pointer argument processing some more.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20240105000909.2818934-4-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Enhances btf_prepare_func_args to support multiple tags per argument and improves pointer argument processing.,"multiple tags, argument, btf",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
18810ad3929ff6b5d8e67e3adc40d690bd780fd6,18810ad3929ff6b5d8e67e3adc40d690bd780fd6,Andrii Nakryiko,andrii@kernel.org,1704413343,Alexei Starovoitov,ast@kernel.org,1706049621,d40ce39247e62ac7f5a412cc1d90bd44c4983981,e31f98c1af810a13395ee9ab57402d82272445af,"bpf: make sure scalar args don't accept __arg_nonnull tag

Move scalar arg processing in btf_prepare_func_args() after all pointer
arg processing is done. This makes it easier to do validation. One
example of unintended behavior right now is ability to specify
__arg_nonnull for integer/enum arguments. This patch fixes this.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20240105000909.2818934-3-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Fixes scalar argument processing in btf_prepare_func_args to prevent __arg_nonnull for non-pointer args.,"scalar,args,validation",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e31f98c1af810a13395ee9ab57402d82272445af,e31f98c1af810a13395ee9ab57402d82272445af,Andrii Nakryiko,andrii@kernel.org,1704413342,Alexei Starovoitov,ast@kernel.org,1706049621,ad3d1f489a9369c14d6c9a1c8f2045ea7ffc35b6,55c14321dbf06c9e32050e99b2555c2f8f6429da,"selftests/bpf: fix test_loader check message

Seeing:

  process_subtest:PASS:Can't alloc specs array 0 nsec

... in verbose successful test log is very confusing. Use smaller
identifier-like test tag to denote that we are asserting specs array
allocation success.

Now it's much less distracting:

  process_subtest:PASS:specs_alloc 0 nsec

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20240105000909.2818934-2-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,This commit clarifies the test message in selftests for BPF regarding specs array allocation checks.,"selftests,BPF,message",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
55c14321dbf06c9e32050e99b2555c2f8f6429da,55c14321dbf06c9e32050e99b2555c2f8f6429da,Alexei Starovoitov,ast@kernel.org,1705026185,Alexei Starovoitov,ast@kernel.org,1706049621,5bcce9245203d486367b3b41f121cb9ee14b8ab7,2121c43f88f593eea51d483bedd638cb0623c7e2 17bda53e43bc41d881ca6a02b3c6f5376c55b3d3,"Merge branch 'bpf-inline-bpf_kptr_xchg'

Hou Tao says:

====================
The motivation of inlining bpf_kptr_xchg() comes from the performance
profiling of bpf memory allocator benchmark [1]. The benchmark uses
bpf_kptr_xchg() to stash the allocated objects and to pop the stashed
objects for free. After inling bpf_kptr_xchg()"," the performance for
object free on 8-CPUs VM increases about 2%~10%. However the performance
gain comes with costs: both the kasan and kcsan checks on the pointer
will be unavailable. Initially the inline is implemented in do_jit() for
x86-64 directly","[' but I think it will more portable to implement the\ninline in verifier.\n\nPatch #1 supports inlining bpf_kptr_xchg() helper and enables it on\nx86-4. Patch #2 factors out a helper for newly-added test in patch #3.\nPatch #3 tests whether the inlining of bpf_kptr_xchg() is expected.\nPlease see individual patches for more details. And comments are always\nwelcome.\n\nChange Log:\nv3:\n  * rebased on bpf-next tree\n  * patch 1 & 2: Add Rvb-by and Ack-by tags from Eduard\n  * patch 3: use inline assembly and naked function instead of c code\n             (suggested by Eduard)\n\nv2: https://lore.kernel.org/bpf/20231223104042.1432300-1-houtao@huaweicloud.com/\n  * rebased on bpf-next tree\n  * drop patch #1 in v1 due to discussion in [2]\n  * patch #1: add the motivation in the commit message', ' merge patch #1\n              and #3 into the new patch in v2. (Daniel)\n  * patch #2/#3: newly-added patch to test the inlining of\n                 bpf_kptr_xchg() (Eduard)\n\nv1: https://lore.kernel.org/bpf/95b8c2cd-44d5-5fe1-60b5-7e8218779566@huaweicloud.com/\n\n[1]: https://lore.kernel.org/bpf/20231221141501.3588586-1-houtao@huaweicloud.com/\n[2]: https://lore.kernel.org/bpf/fd94efb9-4a56-c982-dc2e-c66be5202cb7@huaweicloud.com/\n====================\n\nLink: https://lore.kernel.org/r/20240105104819.3916743-1-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit merges changes for inlining bpf_kptr_xchg to improve memory allocator benchmark performance.,"bpf_kptr_xchg, inlining, performance",It's a performance optimization.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
17bda53e43bc41d881ca6a02b3c6f5376c55b3d3,17bda53e43bc41d881ca6a02b3c6f5376c55b3d3,Hou Tao,houtao1@huawei.com,1704451699,Alexei Starovoitov,ast@kernel.org,1706049621,5bcce9245203d486367b3b41f121cb9ee14b8ab7,b4b7a4099b8ccea224577003fcf9d321bf0817b7,"selftests/bpf: Test the inlining of bpf_kptr_xchg()

The test uses bpf_prog_get_info_by_fd() to obtain the xlated
instructions of the program first. Since these instructions have
already been rewritten by the verifier"," the tests then checks whether
the rewritten instructions are as expected. And to ensure LLVM generates
code exactly as expected","[' use inline assembly and a naked function.\n\nSuggested-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20240105104819.3916743-4-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add selftests to verify the inlining of bpf_kptr_xchg through bpf_prog_get_info_by_fd().,"selftests,inlining,bpf_kptr_xchg",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b4b7a4099b8ccea224577003fcf9d321bf0817b7,b4b7a4099b8ccea224577003fcf9d321bf0817b7,Hou Tao,houtao1@huawei.com,1704451698,Alexei Starovoitov,ast@kernel.org,1706049621,e7b5deffde0f7169e3545f4c0809c7fdc9946b67,7c05e7f3e74e7e550534d524e04d7e6f78d6fa24,"selftests/bpf: Factor out get_xlated_program() helper

Both test_verifier and test_progs use get_xlated_program()"," so moving
the helper into testing_helpers.h to reuse it.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Hou Tao <houtao1@huawei.com>
Link: https://lore.kernel.org/r/20240105104819.3916743-3-houtao@huaweicloud.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Refactor by moving get_xlated_program() helper into testing_helpers.h for reuse in selftests/bpf.,"refactor,reuse,tests",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7c05e7f3e74e7e550534d524e04d7e6f78d6fa24,7c05e7f3e74e7e550534d524e04d7e6f78d6fa24,Hou Tao,houtao1@huawei.com,1704451697,Alexei Starovoitov,ast@kernel.org,1706049621,83d12bcddc908580f8bc73f5572ddeda96561665,2121c43f88f593eea51d483bedd638cb0623c7e2,"bpf: Support inlining bpf_kptr_xchg() helper

The motivation of inlining bpf_kptr_xchg() comes from the performance
profiling of bpf memory allocator benchmark. The benchmark uses
bpf_kptr_xchg() to stash the allocated objects and to pop the stashed
objects for free. After inling bpf_kptr_xchg()"," the performance for
object free on 8-CPUs VM increases about 2%~10%. The inline also has
downside: both the kasan and kcsan checks on the pointer will be
unavailable.

bpf_kptr_xchg() can be inlined by converting the calling of
bpf_kptr_xchg() into an atomic_xchg() instruction. But the conversion
depends on two conditions:
1) JIT backend supports atomic_xchg() on pointer-sized word
2) For the specific arch","[' the implementation of xchg is the same as\n   atomic_xchg() on pointer-sized words.\n\nIt seems most 64-bit JIT backends satisfies these two conditions. But\nas a precaution', ' defining a weak function bpf_jit_supports_ptr_xchg()\nto state whether such conversion is safe and only supporting inline for\n64-bit host.\n\nFor x86-64', ' it supports BPF_XCHG atomic operation and both xchg() and\natomic_xchg() use arch_xchg() to implement the exchange', ' so enabling the\ninline of bpf_kptr_xchg() on x86-64 first.\n\nReviewed-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20240105104819.3916743-2-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit improves performance by inlining the bpf_kptr_xchg() helper function for better efficiency in memory allocation benchmarks.,"bpf_kptr_xchg, inlining, performance",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['other']
1732ebc4a26181c8f116c7639db99754b313edc8,1732ebc4a26181c8f116c7639db99754b313edc8,Pu Lehui,pulehui@huawei.com,1705977127,Daniel Borkmann,daniel@iogearbox.net,1706048498,61926561755d53e7889e47ebc4f92cf341898c04,1347775dea7f62798b4d5ef60771cdd7cfff25d8,riscv," bpf: Fix unpredictable kernel crash about RV64 struct_ops

We encountered a kernel crash triggered by the bpf_tcp_ca testcase as
show below:

Unable to handle kernel paging request at virtual address ff60000088554500
Oops [#1]
...
CPU: 3 PID: 458 Comm: test_progs Tainted: G           OE      6.8.0-rc1-kselftest_plain #1
Hardware name: riscv-virtio","['qemu (DT)\nepc : 0xff60000088554500\n ra : tcp_ack+0x288/0x1232\nepc : ff60000088554500 ra : ffffffff80cc7166 sp : ff2000000117ba50\n gp : ffffffff82587b60 tp : ff60000087be0040 t0 : ff60000088554500\n t1 : ffffffff801ed24e t2 : 0000000000000000 s0 : ff2000000117bbc0\n s1 : 0000000000000500 a0 : ff20000000691000 a1 : 0000000000000018\n a2 : 0000000000000001 a3 : ff60000087be03a0 a4 : 0000000000000000\n a5 : 0000000000000000 a6 : 0000000000000021 a7 : ffffffff8263f880\n s2 : 000000004ac3c13b s3 : 000000004ac3c13a s4 : 0000000000008200\n s5 : 0000000000000001 s6 : 0000000000000104 s7 : ff2000000117bb00\n s8 : ff600000885544c0 s9 : 0000000000000000 s10: ff60000086ff0b80\n s11: 000055557983a9c0 t3 : 0000000000000000 t4 : 000000000000ffc4\n t5 : ffffffff8154f170 t6 : 0000000000000030\nstatus: 0000000200000120 badaddr: ff60000088554500 cause: 000000000000000c\nCode: c796 67d7 0000 0000 0052 0002 c13b 4ac3 0000 0000 (0001) 0000\n---[ end trace 0000000000000000 ]---\n\nThe reason is that commit 2cd3e3772e41 (""x86/cfi', 'bpf: Fix bpf_struct_ops\nCFI"") changes the func_addr of arch_prepare_bpf_trampoline in struct_ops\nfrom NULL to non-NULL', ' while we use func_addr on RV64 to differentiate\nbetween struct_ops and regular trampoline. When the struct_ops testcase\nis triggered', ' it emits wrong prologue and epilogue', ' and lead to\nunpredictable issues. After commit 2cd3e3772e41', ' we can use\nBPF_TRAMP_F_INDIRECT to distinguish them as it always be set in\nstruct_ops.\n\nFixes: 2cd3e3772e41 (""x86/cfi', 'bpf: Fix bpf_struct_ops CFI"")\nSigned-off-by: Pu Lehui <pulehui@huawei.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Björn Töpel <bjorn@rivosinc.com>\nAcked-by: Björn Töpel <bjorn@kernel.org>\nLink: https://lore.kernel.org/bpf/20240123023207.1917284-1-pulehui@huaweicloud.com\n', '']",Fixes a kernel crash related to struct_ops in RISC-V when running bpf_tcp_ca test cases.,"kernel crash, struct_ops, RISC-V",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
999eea92e8d7a1ffa83f7dc89c83d8ed1e746fa9,999eea92e8d7a1ffa83f7dc89c83d8ed1e746fa9,Thomas Richter,tmricht@linux.ibm.com,1704703209,Namhyung Kim,namhyung@kernel.org,1705954099,16c33ebb7331f2fe72888775ff2ea9eba48307f5,6613476e225e090cc9aad49be7fa504e290dd33d,"perf test: raise limit to 20 percent for perf_stat_--bpf-counters_test

This test case often fails on s390 (about 2 out of 10) because the
10% percent limit on the difference between --bpf-counters event counting
and s390 hardware counting is more than 10% in all failure cases.
Raise the limit to 20% on s390 and the test case succeeds.

Signed-off-by: Thomas Richter <tmricht@linux.ibm.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: gor@linux.ibm.com
Cc: hca@linux.ibm.com
Cc: sumanthk@linux.ibm.com
Cc: svens@linux.ibm.com
Link: https://lore.kernel.org/r/20240108084009.3959211-1-tmricht@linux.ibm.com
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
",,Raise the limit for perf_stat bpf-counters test from 10% to 20% to reduce failures on s390 architecture.,"perf,test,s390",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9d64bf433c53cab2f48a3fff7a1f2a696bc5229a,9d64bf433c53cab2f48a3fff7a1f2a696bc5229a,Linus Torvalds,torvalds@linux-foundation.org,1705703123,Linus Torvalds,torvalds@linux-foundation.org,1705703123,0535254c177c27ec34adbc153d494cea9a9625a0,57f22c8dab6b266ae36b89b073a4a33dea71e762 d988c9f511af71a3445b6a4f3a2c67208ff8e480,"Merge tag 'perf-tools-for-v6.8-1-2024-01-09' of git://git.kernel.org/pub/scm/linux/kernel/git/perf/perf-tools

Pull perf tools updates from Arnaldo Carvalho de Melo:
 ""Add Namhyung Kim as tools/perf/ co-maintainer"," we're taking turns
  processing patches","[' switching roles from perf-tools to perf-tools-next\n  at each Linux release.\n\n  Data profiling:\n\n   - Associate samples that identify loads and stores with data\n     structures. This uses events available on Intel', "" AMD and others and\n     DWARF info:\n\n       # To get memory access samples in kernel for 1 second (on Intel)\n       $ perf mem record -a -K --ldlat=4 -- sleep 1\n\n       # Similar for the AMD (but it requires 6.3+ kernel for BPF filters)\n       $ perf mem record -a --filter 'mem_op == load || mem_op == store"", "" ip > 0x8000000000000000' -- sleep 1\n\n     Then"", ' amongst several modes of post processing', ' one can do things like:\n\n       $ perf report -s type', ""typeoff --hierarchy --group --stdio\n       ...\n       #\n       # Samples: 10K of events 'cpu/mem-loads"", 'ldlat=4/P', ' cpu/mem-stores/P', "" dummy:u'\n       # Event count (approx.): 602758064\n       #\n       #                    Overhead  Data Type / Data Type Offset\n       # ...........................  ............................\n       #\n           26.09%   3.28%   0.00%     long unsigned int\n              26.09%   3.28%   0.00%     long unsigned int +0 (no field)\n           18.48%   0.73%   0.00%     struct page\n              10.83%   0.02%   0.00%     struct page +8 (lru.next)\n               3.90%   0.28%   0.00%     struct page +0 (flags)\n               3.45%   0.06%   0.00%     struct page +24 (mapping)\n               0.25%   0.28%   0.00%     struct page +48 (_mapcount.counter)\n               0.02%   0.06%   0.00%     struct page +32 (index)\n               0.02%   0.00%   0.00%     struct page +52 (_refcount.counter)\n               0.02%   0.01%   0.00%     struct page +56 (memcg_data)\n               0.00%   0.01%   0.00%     struct page +16 (lru.prev)\n           15.37%  17.54%   0.00%     (stack operation)\n              15.37%  17.54%   0.00%     (stack operation) +0 (no field)\n           11.71%  50.27%   0.00%     (unknown)\n              11.71%  50.27%   0.00%     (unknown) +0 (no field)\n\n       $ perf annotate --data-type\n       ...\n       Annotate type: 'struct cfs_rq' in [kernel.kallsyms] (13 samples):\n       ============================================================================\n           samples     offset       size  field\n                13          0        640  struct cfs_rq         {\n                 2          0         16      struct load_weight       load {\n                 2          0          8          unsigned long        weight;\n                 0          8          4          u32  inv_weight;\n                                              };\n                 0         16          8      unsigned long    runnable_weight;\n                 0         24          4      unsigned int     nr_running;\n                 1         28          4      unsigned int     h_nr_running;\n       ...\n\n       $ perf annotate --data-type=page --group\n       Annotate type: 'struct page' in [kernel.kallsyms] (480 samples):\n        event[0] = cpu/mem-loads"", 'ldlat=4/P\n        event[1] = cpu/mem-stores/P\n        event[2] = dummy:u\n       ===================================================================================\n                samples  offset  size  field\n       447  33        0       0    64  struct page     {\n       108   8        0       0     8\t long unsigned int  flags;\n       319  13        0       8    40\t union       {\n       319  13        0       8    40          struct          {\n       236   2        0       8    16              union       {\n       236   2        0       8    16                  struct list_head       lru {\n       236   1        0       8     8                      struct list_head*  next;\n         0   1        0      16     8                      struct list_head*  prev;\n                                                       };\n       236   2        0       8    16                  struct          {\n       236   1        0       8     8                      void*      __filler;\n         0   1        0      16     4                      unsigned int       mlock_count;\n                                                       };\n       236   2        0       8    16                  struct list_head       buddy_list {\n       236   1        0       8     8                      struct list_head*  next;\n         0   1        0      16     8                      struct list_head*  prev;\n                                                       };\n       236   2        0       8    16                  struct list_head       pcp_list {\n       236   1        0       8     8                      struct list_head*  next;\n         0   1        0      16     8                      struct list_head*  prev;\n                                                       };\n                                                   };\n        82   4        0      24     8              struct address_space*      mapping;\n         1   7        0      32     8              union       {\n         1   7        0      32     8                  long unsigned int      index;\n         1   7        0      32     8                  long unsigned int      share;\n                                                   };\n         0   0        0      40     8              long unsigned int  private;\n                                                                 };\n\n     This uses the existing annotate code', ' calling objdump to do the\n     disassembly', ' with improvements to avoid having this take too long', '\n     but longer term a switch to a disassembler library', ' possibly\n     reusing code in the kernel will be pursued.\n\n     This is the initial implementation', ' please use it and report\n     impressions and bugs. Make sure the kernel-debuginfo packages match\n     the running kernel. The \'perf report\' phase for non short perf.data\n     files may take a while.\n\n     There is a great article about it on LWN:\n\n       https://lwn.net/Articles/955709/ - ""Data-type profiling for perf""\n\n     One last test I did while writing this text', ' on a AMD Ryzen 5950X', '\n     using a distro kernel', "" while doing a simple 'find /' on an\n     otherwise idle system resulted in:\n\n     # uname -r\n     6.6.9-100.fc38.x86_64\n     # perf -vv | grep BPF_\n                      bpf: [ on  ]  # HAVE_LIBBPF_SUPPORT\n            bpf_skeletons: [ on  ]  # HAVE_BPF_SKEL\n     # rpm -qa | grep kernel-debuginfo\n     kernel-debuginfo-common-x86_64-6.6.9-100.fc38.x86_64\n     kernel-debuginfo-6.6.9-100.fc38.x86_64\n     #\n     # perf mem record -a --filter 'mem_op == load || mem_op == store"", "" ip > 0x8000000000000000'\n     ^C[ perf record: Woken up 1 times to write data ]\n     [ perf record: Captured and wrote 2.199 MB perf.data (2913 samples) ]\n     #\n     # ls -la perf.data\n     -rw-------. 1 root root 2346486 Jan  9 18:36 perf.data\n     # perf evlist\n     ibs_op//\n     dummy:u\n     # perf evlist -v\n     ibs_op//: type: 11"", ' size: 136', ' config: 0', ' { sample_period', ' sample_freq }: 4000', ' sample_type: IP|TID|TIME|ADDR|CPU|PERIOD|IDENTIFIER|DATA_SRC|WEIGHT', ' read_format: ID', ' disabled: 1', ' inherit: 1', ' freq: 1', ' sample_id_all: 1\n     dummy:u: type: 1 (PERF_TYPE_SOFTWARE)', ' size: 136', ' config: 0x9 (PERF_COUNT_SW_DUMMY)', ' { sample_period', ' sample_freq }: 1', ' sample_type: IP|TID|TIME|ADDR|CPU|IDENTIFIER|DATA_SRC|WEIGHT', ' read_format: ID', ' inherit: 1', ' exclude_kernel: 1', ' exclude_hv: 1', ' mmap: 1', ' comm: 1', ' task: 1', ' mmap_data: 1', ' sample_id_all: 1', ' exclude_guest: 1', ' mmap2: 1', ' comm_exec: 1', ' ksymbol: 1', ' bpf_event: 1\n     #\n     # perf report -s type', ""typeoff --hierarchy --group --stdio\n     # Total Lost Samples: 0\n     #\n     # Samples: 2K of events 'ibs_op//"", "" dummy:u'\n     # Event count (approx.): 1904553038\n     #\n     #            Overhead  Data Type / Data Type Offset\n     # ...................  ............................\n     #\n         73.70%   0.00%     (unknown)\n            73.70%   0.00%     (unknown) +0 (no field)\n          3.01%   0.00%     long unsigned int\n             3.00%   0.00%     long unsigned int +0 (no field)\n             0.01%   0.00%     long unsigned int +2 (no field)\n          2.73%   0.00%     struct task_struct\n             1.71%   0.00%     struct task_struct +52 (on_cpu)\n             0.38%   0.00%     struct task_struct +2104 (rcu_read_unlock_special.b.blocked)\n             0.23%   0.00%     struct task_struct +2100 (rcu_read_lock_nesting)\n             0.14%   0.00%     struct task_struct +2384 ()\n             0.06%   0.00%     struct task_struct +3096 (signal)\n             0.05%   0.00%     struct task_struct +3616 (cgroups)\n             0.05%   0.00%     struct task_struct +2344 (active_mm)\n             0.02%   0.00%     struct task_struct +46 (flags)\n             0.02%   0.00%     struct task_struct +2096 (migration_disabled)\n             0.01%   0.00%     struct task_struct +24 (__state)\n             0.01%   0.00%     struct task_struct +3956 (mm_cid_active)\n             0.01%   0.00%     struct task_struct +1048 (cpus_ptr)\n             0.01%   0.00%     struct task_struct +184 (se.group_node.next)\n             0.01%   0.00%     struct task_struct +20 (thread_info.cpu)\n             0.00%   0.00%     struct task_struct +104 (on_rq)\n             0.00%   0.00%     struct task_struct +2456 (pid)\n          1.36%   0.00%     struct module\n             0.59%   0.00%     struct module +952 (kallsyms)\n             0.42%   0.00%     struct module +0 (state)\n             0.23%   0.00%     struct module +8 (list.next)\n             0.12%   0.00%     struct module +216 (syms)\n          0.95%   0.00%     struct inode\n             0.41%   0.00%     struct inode +40 (i_sb)\n             0.22%   0.00%     struct inode +0 (i_mode)\n             0.06%   0.00%     struct inode +76 (i_rdev)\n             0.06%   0.00%     struct inode +56 (i_security)\n     <SNIP>\n\n  perf top/report:\n\n   - Don't ignore job control"", "" allowing control+Z + bg to work.\n\n   - Add s390 raw data interpretation for PAI (Processor Activity\n     Instrumentation) counters.\n\n  perf archive:\n\n   - Add new option '--all' to pack perf.data with DSOs.\n\n   - Add new option '--unpack' to expand tarballs.\n\n  Initialization speedups:\n\n   - Lazily initialize zstd streams to save memory when not using it.\n\n   - Lazily allocate/size mmap event copy.\n\n   - Lazy load kernel symbols in 'perf record'.\n\n   - Be lazier in allocating lost samples buffer in 'perf record'.\n\n   - Don't synthesize BPF events when disabled via the command line\n     (perf record --no-bpf-event).\n\n  Assorted improvements:\n\n   - Show note on AMD systems that the :p"", ' :pp', ' :ppp and :P are all the\n     same', ' as IBS (Instruction Based Sampling) is used and it is\n     inherentely precise', "" not having levels of precision like in Intel\n     systems.\n\n   - When 'cycles' isn't available"", ' fall back to the ""task-clock"" event\n     when not system wide', "" not to 'cpu-clock'.\n\n   - Add --debug-file option to redirect debug output"", "" e.g.:\n\n       $ perf --debug-file /tmp/perf.log record -v true\n\n   - Shrink 'struct map' to under one cacheline by avoiding function\n     pointers for selecting if addresses are identity or DSO relative"", ""\n     and using just a byte for some boolean struct members.\n\n   - Resolve the arch specific strerrno just once to use in\n     perf_env__arch_strerrno().\n\n   - Reduce memory for recording PERF_RECORD_LOST_SAMPLES event.\n\n  Assorted fixes:\n\n   - Fix the default 'perf top' usage on Intel hybrid systems"", ' now it\n     starts with a browser showing the number of samples for Efficiency\n     (cpu_atom/cycles/P) and Performance (cpu_core/cycles/P). This\n     behaviour is similar on ARM64', "" with its respective set of\n     big.LITTLE processors.\n\n   - Fix segfault on build_mem_topology() error path.\n\n   - Fix 'perf mem' error on hybrid related to availability of mem event\n     in a PMU.\n\n   - Fix missing reference count gets (map"", "" maps) in the db-export code.\n\n   - Avoid recursively taking env->bpf_progs.lock in the 'perf_env'\n     code.\n\n   - Use the newly introduced maps__for_each_map() to add missing\n     locking around iteration of 'struct map' entries.\n\n   - Parse NOTE segments until the build id is found"", "" don't stop on the\n     first one"", "" ELF files may have several such NOTE segments.\n\n   - Remove 'egrep' usage"", ' its deprecated', "" use 'grep -E' instead.\n\n   - Warn first about missing libelf"", ' not libbpf', "" that depends on\n     libelf.\n\n   - Use alternative to 'find ... -printf' as this isn't supported in\n     busybox.\n\n   - Address python 3.6 DeprecationWarning for string scapes.\n\n   - Fix memory leak in uniq() in libsubcmd.\n\n   - Fix man page formatting for 'perf lock'\n\n   - Fix some spelling mistakes.\n\n  perf tests:\n\n   - Fail shell tests that needs some symbol in perf itself if it is\n     stripped. These tests check if a symbol is resolved"", ' if some hot\n     function is indeed detected by profiling', "" etc.\n\n   - The 'perf test sigtrap' test is currently failing on PREEMPT_RT"", '\n     skip it if sleeping spinlocks are detected (using BTF) and point to\n     the mailing list discussion about it. This test is also being\n     skipped on several architectures (powerpc', ' s390x', "" arm and aarch64)\n     due to other pending issues with intruction breakpoints.\n\n   - Adjust test case perf record offcpu profiling tests for s390.\n\n   - Fix 'Setup struct perf_event_attr' fails on s390 on z/VM guest"", ""\n     addressing issues caused by the fallback from cycles to task-clock\n     done in this release.\n\n   - Fix mask for VG register in the user-regs test.\n\n   - Use shellcheck on 'perf test' shell scripts automatically to make\n     sure changes don't introduce things it flags as problematic.\n\n   - Add option to change objdump binary and allow it to be set via\n     'perf config'.\n\n   - Add basic 'perf script'"", ' \'perf list --json"" and \'perf diff\' tests.\n\n   - Basic branch counter support.\n\n   - Make DSO tests a suite rather than individual.\n\n   - Remove atomics from test_loop to avoid test failures.\n\n   - Fix call chain match on powerpc for the record+probe_libc_inet_pton\n     test.\n\n   - Improve Intel hybrid tests.\n\n  Vendor event files (JSON):\n\n  powerpc:\n\n   - Update datasource event name to fix duplicate events on IBM\'s\n     Power10.\n\n   - Add PVN for HX-C2000 CPU with Power8 Architecture.\n\n  Intel:\n\n   - Alderlake/rocketlake metric fixes.\n\n   - Update emeraldrapids events to v1.02.\n\n   - Update icelakex events to v1.23.\n\n   - Update sapphirerapids events to v1.17.\n\n   - Add skx', ' clx', ' icx and spr upi bandwidth metric.\n\n  AMD:\n\n   - Add Zen 4 memory controller events.\n\n  RISC-V:\n\n   - Add StarFive Dubhe-80 and Dubhe-90 JSON files.\n       https://www.starfivetech.com/en/site/cpu-u\n\n   - Add T-HEAD C9xx JSON file.\n       https://github.com/riscv-software-src/opensbi/blob/master/docs/platform/thead-c9xx.md\n\n  ARM64:\n\n   - Remove UTF-8 characters from cmn.json', "" that were causing build\n     failure in some distros.\n\n   - Add core PMU events and metrics for Ampere One X.\n\n   - Rename Ampere One's BPU_FLUSH_MEM_FAULT to GPC_FLUSH_MEM_FAULT\n\n  libperf:\n\n   - Rename several perf_cpu_map constructor names to clarify what they\n     really do.\n\n   - Ditto for some other methods"", ' coping with some issues in their\n     semantics', ' like perf_cpu_map__empty() ->\n     perf_cpu_map__has_any_cpu_or_is_empty().\n\n   - Document perf_cpu_map__nr()\'s behavior\n\n  perf stat:\n\n   - Exit if parse groups fails.\n\n   - Combine the -A/--no-aggr and --no-merge options.\n\n   - Fix help message for --metric-no-threshold option.\n\n  Hardware tracing:\n\n  ARM64 CoreSight:\n\n   - Bump minimum OpenCSD version to ensure a bugfix is present.\n\n   - Add \'T\' itrace option for timestamp trace\n\n   - Set start vm addr of exectable file to 0 and don\'t ignore first\n     sample on the arm-cs-trace-disasm.py \'perf script\'""\n\n* tag \'perf-tools-for-v6.8-1-2024-01-09\' of git://git.kernel.org/pub/scm/linux/kernel/git/perf/perf-tools: (179 commits)\n  MAINTAINERS: Add Namhyung as tools/perf/ co-maintainer\n  perf test: test case \'Setup struct perf_event_attr\' fails on s390 on z/vm\n  perf db-export: Fix missing reference count get in call_path_from_sample()\n  perf tests: Add perf script test\n  libsubcmd: Fix memory leak in uniq()\n  perf TUI: Don\'t ignore job control\n  perf vendor events intel: Update sapphirerapids events to v1.17\n  perf vendor events intel: Update icelakex events to v1.23\n  perf vendor events intel: Update emeraldrapids events to v1.02\n  perf vendor events intel: Alderlake/rocketlake metric fixes\n  perf x86 test: Add hybrid test for conflicting legacy/sysfs event\n  perf x86 test: Update hybrid expectations\n  perf vendor events amd: Add Zen 4 memory controller events\n  perf stat: Fix hard coded LL miss units\n  perf record: Reduce memory for recording PERF_RECORD_LOST_SAMPLES event\n  perf env: Avoid recursively taking env->bpf_progs.lock\n  perf annotate: Add --insn-stat option for debugging\n  perf annotate: Add --type-stat option for debugging\n  perf annotate: Support event group display\n  perf annotate: Add --data-type option\n  ...\n', '']",Merge perf tools updates adding Namhyung Kim as co-maintainer for tools/perf.,"perf,tools,maintainer",It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
736b5545d39ca59d4332a60e56cc8a1a5e264a8e,736b5545d39ca59d4332a60e56cc8a1a5e264a8e,Linus Torvalds,torvalds@linux-foundation.org,1705628030,Linus Torvalds,torvalds@linux-foundation.org,1705628030,3200528110fab00e0f0d3a311b6e3ad2fcd86edd,ed8d84530ab0a3b7b370e8b28f12179314dcfcc3 925781a471d8156011e8f8c1baf61bbe020dac55,"Merge tag 'net-6.8-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Jakub Kicinski:
 ""Including fixes from bpf and netfilter.

  Previous releases - regressions:

   - Revert ""net: rtnetlink: Enslave device before bringing it up""","
     breaks the case inverse to the one it was trying to fix

   - net: dsa: fix oob access in DSA's netdevice event handler
     dereference netdev_priv() before check its a DSA port

   - sched: track device in tcf_block_get/put_ext() only for clsact
     binder types

   - net: tls","["" fix WARNING in __sk_msg_free when record becomes full\n     during splice and MORE hint set\n\n   - sfp-bus: fix SFP mode detect from bitrate\n\n   - drv: stmmac: prevent DSA tags from breaking COE\n\n  Previous releases - always broken:\n\n   - bpf: fix no forward progress in in bpf_iter_udp if output buffer is\n     too small\n\n   - bpf: reject variable offset alu on registers with a type of\n     PTR_TO_FLOW_KEYS to prevent oob access\n\n   - netfilter: tighten input validation\n\n   - net: add more sanity check in virtio_net_hdr_to_skb()\n\n   - rxrpc: fix use of Don't Fragment flag on RESPONSE packets"", ' avoid\n     infinite loop\n\n   - amt: do not use the portion of skb->cb area which may get clobbered\n\n   - mptcp: improve validation of the MPTCPOPT_MP_JOIN MCTCP option\n\n  Misc:\n\n   - spring cleanup of inactive maintainers""\n\n* tag \'net-6.8-rc1\' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (88 commits)\n  i40e: Include types.h to some headers\n  ipv6: mcast: fix data-race in ipv6_mc_down / mld_ifc_work\n  selftests: mlxsw: qos_pfc: Adjust the test to support 8 lanes\n  selftests: mlxsw: qos_pfc: Remove wrong description\n  mlxsw: spectrum_router: Register netdevice notifier before nexthop\n  mlxsw: spectrum_acl_tcam: Fix stack corruption\n  mlxsw: spectrum_acl_tcam: Fix NULL pointer dereference in error path\n  mlxsw: spectrum_acl_erp: Fix error flow of pool allocation failure\n  ethtool: netlink: Add missing ethnl_ops_begin/complete\n  selftests: bonding: Add more missing config options\n  selftests: netdevsim: add a config file\n  libbpf: warn on unexpected __arg_ctx type when rewriting BTF\n  selftests/bpf: add tests confirming type logic in kernel for __arg_ctx\n  bpf: enforce types for __arg_ctx-tagged arguments in global subprogs\n  bpf: extract bpf_ctx_convert_map logic and make it more reusable\n  libbpf: feature-detect arg:ctx tag support in kernel\n  ipvs: avoid stat macros calls from preemptible context\n  netfilter: nf_tables: reject NFT_SET_CONCAT with not field length description\n  netfilter: nf_tables: skip dead set elements in netlink dump\n  netfilter: nf_tables: do not allow mismatch field size and set key length\n  ...\n', '']",Merge of networking fixes including bpf and netfilter regressions,"networking,fixes,bpf",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","['tc/netfilter like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4349efc52b83af3851df7a4199567ad50b3d1f03,4349efc52b83af3851df7a4199567ad50b3d1f03,Jakub Kicinski,kuba@kernel.org,1705600464,Jakub Kicinski,kuba@kernel.org,1705600464,2f8475b57657b0f5666266df5005622c9aa05200,9cfd3b502153810b66ac0ce47f1fba682228f2d2 35ac085a94efe82d906d3a812612d432aa267cbe,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Daniel Borkmann says:

====================
pull-request: bpf 2024-01-18

We've added 10 non-merge commits during the last 5 day(s) which contain
a total of 12 files changed", 806 insertions(+),"[' 51 deletions(-).\n\nThe main changes are:\n\n1) Fix an issue in bpf_iter_udp under backward progress which prevents\n   user space process from finishing iteration', ' from Martin KaFai Lau.\n\n2) Fix BPF verifier to reject variable offset alu on registers with a type\n   of PTR_TO_FLOW_KEYS to prevent oob access', ' from Hao Sun.\n\n3) Follow up fixes for kernel- and libbpf-side logic around handling\n   arg:ctx tagged arguments of BPF global subprogs', "" from Andrii Nakryiko.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  libbpf: warn on unexpected __arg_ctx type when rewriting BTF\n  selftests/bpf: add tests confirming type logic in kernel for __arg_ctx\n  bpf: enforce types for __arg_ctx-tagged arguments in global subprogs\n  bpf: extract bpf_ctx_convert_map logic and make it more reusable\n  libbpf: feature-detect arg:ctx tag support in kernel\n  selftests/bpf: Add test for alu on PTR_TO_FLOW_KEYS\n  bpf: Reject variable offset alu on PTR_TO_FLOW_KEYS\n  selftests/bpf: Test udp and tcp iter batching\n  bpf: Avoid iter->offset making backward progress in bpf_iter_udp\n  bpf: iter_udp: Retry with a larger batch size without going back to the previous bucket\n====================\n\nLink: https://lore.kernel.org/r/20240118153936.11769-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n"", '']",Merges recent non-merge commits from bpf to for-netdev tag affecting 12 files.,"merge, commits, bpf",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
35ac085a94efe82d906d3a812612d432aa267cbe,35ac085a94efe82d906d3a812612d432aa267cbe,Alexei Starovoitov,ast@kernel.org,1705551606,Alexei Starovoitov,ast@kernel.org,1705551606,f8a2ed263a3ea89d0307e293ebc57b795c281a86,33772ff3b887eb2f426ed66bcb1808837a40669c 76ec90a996e3c707eb6772510afa36faeba2ecff,"Merge branch 'tighten-up-arg-ctx-type-enforcement'

Andrii Nakryiko says:

====================
Tighten up arg:ctx type enforcement

Follow up fixes for kernel-side and libbpf-side logic around handling arg:ctx
(__arg_ctx) tagged arguments of BPF global subprogs.

Patch #1 adds libbpf feature detection of kernel-side __arg_ctx support to
avoid unnecessary rewriting BTF types. With stricter kernel-side type
enforcement this is now mandatory to avoid problems with using `struct
bpf_user_pt_regs_t` instead of actual typedef. For __arg_ctx tagged arguments
verifier is now supporting either `bpf_user_pt_regs_t` typedef or resolves it
down to the actual struct (pt_regs/user_pt_regs/user_regs_struct)"," depending
on architecture)","["" but for old kernels without __arg_ctx support it's more\nbackwards compatible for libbpf to use `struct bpf_user_pt_regs_t` rewrite\nwhich will work on wider range of kernels. So feature detection prevent libbpf\naccidentally breaking global subprogs on new kernels.\n\nWe also adjust selftests to do similar feature detection (much simpler"", ' but\npotentially breaking due to kernel source code refactoring', ' which is fine for\nselftests)', "" and skip tests expecting libbpf's BTF type rewrites.\n\nPatch #2 is preparatory refactoring for patch #3 which adds type enforcement\nfor arg:ctx tagged global subprog args. See the patch for specifics.\n\nPatch #4 adds many new cases to ensure type logic works as expected.\n\nFinally"", "" patch #5 adds a relevant subset of kernel-side type checks to\n__arg_ctx cases that libbpf supports rewrite of. In libbpf's case"", ' type\nviolations are reported as warnings and BTF rewrite is not performed', ' which\nwill eventually lead to BPF verifier complaining at program verification time.\n\nGood care was taken to avoid conflicts between bpf and bpf-next tree (which\nhas few follow up refactorings in the same code area). Once trees converge\nsome of the code will be moved around a bit (and some will be deleted)', ' but\nwith no change to functionality or general shape of the code.\n\nv2->v3:\n  - support `bpf_user_pt_regs_t` typedef for KPROBE and PERF_EVENT (CI);\nv1->v2:\n  - add user_pt_regs and user_regs_struct support for PERF_EVENT (CI);\n  - drop FEAT_ARG_CTX_TAG enum leftover from patch #1;\n  - fix warning about default: without break in the switch (CI).\n====================\n\nLink: https://lore.kernel.org/r/20240118033143.3384355-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Enhance type enforcement for BPF arg:ctx in kernel and libbpf for stricter verifier checks.,"type enforcement, libbpf, BPF",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
76ec90a996e3c707eb6772510afa36faeba2ecff,76ec90a996e3c707eb6772510afa36faeba2ecff,Andrii Nakryiko,andrii@kernel.org,1705548703,Alexei Starovoitov,ast@kernel.org,1705551606,f8a2ed263a3ea89d0307e293ebc57b795c281a86,989410cde81959c4033dc287d79b42b6eb04f04f,"libbpf: warn on unexpected __arg_ctx type when rewriting BTF

On kernel that don't support arg:ctx tag"," before adjusting global
subprog BTF information to match kernel's expected canonical type names","['\nmake sure that types used by user are meaningful', ' and if not', "" warn and\ndon't do BTF adjustments.\n\nThis is similar to checks that kernel performs"", ' but narrower in scope', '\nas only a small subset of BPF program types can be accommodated by\nlibbpf using canonical type names.\n\nLibbpf unconditionally allows `struct pt_regs *` for perf_event program\ntypes', ' unlike kernel', ' which supports that conditionally on architecture.\nThis is done to keep things simple and not cause unnecessary false\npositives. This seems like a minor and harmless deviation', ' which in\nreal-world programs will be caught by kernels with arg:ctx tag support\nanyways. So KISS principle.\n\nThis logic is hard to test (especially on latest kernels)', "" so manual\ntesting was performed instead. Libbpf emitted the following warning for\nperf_event program with wrong context argument type:\n\n  libbpf: prog 'arg_tag_ctx_perf': subprog 'subprog_ctx_tag' arg#0 is expected to be of `struct bpf_perf_event_data *` type\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240118033143.3384355-6-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Add warning in libbpf for unexpected __arg_ctx type during BTF rewriting on unsupported kernels.,"libbpf, BTF, warning",It's a documentation change or typo fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
989410cde81959c4033dc287d79b42b6eb04f04f,989410cde81959c4033dc287d79b42b6eb04f04f,Andrii Nakryiko,andrii@kernel.org,1705548702,Alexei Starovoitov,ast@kernel.org,1705551606,5cf0c298e829a66889b975c7f7fa02ef6c0db801,0ba971511d16603599f947459e59b435cc465b0d,"selftests/bpf: add tests confirming type logic in kernel for __arg_ctx

Add a bunch of global subprogs across variety of program types to
validate expected kernel type enforcement logic for __arg_ctx arguments.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240118033143.3384355-5-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add tests in selftests/bpf to validate type enforcement logic for __arg_ctx arguments across various program types.,"type logic,__arg_ctx,selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0ba971511d16603599f947459e59b435cc465b0d,0ba971511d16603599f947459e59b435cc465b0d,Andrii Nakryiko,andrii@kernel.org,1705548701,Alexei Starovoitov,ast@kernel.org,1705551606,efdc21275d6199a7ed86c12e1829f8420c6b8295,66967a32d3b16ed447e76fed4d946bab52e43d86,"bpf: enforce types for __arg_ctx-tagged arguments in global subprogs

Add enforcement of expected types for context arguments tagged with
arg:ctx (__arg_ctx) tag.

First"," any program type will accept generic `void *` context type when
combined with __arg_ctx tag.

Besides accepting ""canonical"" struct names and `void *`","[' for a bunch of\nprogram types for which program context is actually a named struct', ' we\nallows a bunch of pragmatic exceptions to match real-world and expected\nusage:\n\n  - for both kprobes and perf_event we allow `bpf_user_pt_regs_t *` as\n    canonical context argument type', ' where `bpf_user_pt_regs_t` is a\n    *typedef*', ' not a struct;\n  - for kprobes', ' we also always accept `struct pt_regs *`', "" as that's what\n    actually is passed as a context to any kprobe program;\n  - for perf_event"", "" we resolve typedefs (unless it's `bpf_user_pt_regs_t`)\n    down to actual struct type and accept `struct pt_regs *`"", ' or\n    `struct user_pt_regs *`', ' or `struct user_regs_struct *`', ' depending\n    on the actual struct type kernel architecture points `bpf_user_pt_regs_t`\n    typedef to; otherwise', ' canonical `struct bpf_perf_event_data *` is\n    expected;\n  - for raw_tp/raw_tp.w programs', ' `u64/long *` are accepted', "" as that's\n    what's expected with BPF_PROG() usage; otherwise"", ' canonical\n    `struct bpf_raw_tracepoint_args *` is expected;\n  - tp_btf supports both `struct bpf_raw_tracepoint_args *` and `u64 *`\n    formats', ' both are coded as expections as tp_btf is actually a TRACING\n    program type', ' which has no canonical context type;\n  - iterator programs accept `struct bpf_iter__xxx *` structs', ' currently\n    with no further iterator-type specific enforcement;\n  - fentry/fexit/fmod_ret/lsm/struct_ops all accept `u64 *`;\n  - classic tracepoint programs', "" as well as syscall and freplace\n    programs allow any user-provided type.\n\nIn all other cases kernel will enforce exact match of struct name to\nexpected canonical type. And if user-provided type doesn't match that\nexpectation"", ' verifier will emit helpful message with expected type name.\n\nNote a bit unnatural way the check is done after processing all the\narguments. This is done to avoid conflict between bpf and bpf-next\ntrees. Once trees converge', ' a small follow up patch will place a simple\nbtf_validate_prog_ctx_type() check into a proper ARG_PTR_TO_CTX branch\n(which bpf-next tree patch refactored already)', ' removing duplicated\narg:ctx detection logic.\n\nSuggested-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240118033143.3384355-4-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Enforces expected types for context arguments with __arg_ctx tag in global subprograms in eBPF.,"enforce, context, __arg_ctx",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
66967a32d3b16ed447e76fed4d946bab52e43d86,66967a32d3b16ed447e76fed4d946bab52e43d86,Andrii Nakryiko,andrii@kernel.org,1705548700,Alexei Starovoitov,ast@kernel.org,1705551605,cf12401fd7bc09c7a4b63ce9eadbe67ce63038b2,01b55f4f0cd6ad1a16eca6c43a3190005892ef91,"bpf: extract bpf_ctx_convert_map logic and make it more reusable

Refactor btf_get_prog_ctx_type() a bit to allow reuse of
bpf_ctx_convert_map logic in more than one places. Simplify interface by
returning btf_type instead of btf_member (field reference in BTF).

To do the above we need to touch and start untangling
btf_translate_to_vmlinux() implementation. We do the bare minimum to
not regress anything for btf_translate_to_vmlinux()"," but its
implementation is very questionable for what it claims to be doing.
Mapping kfunc argument types to kernel corresponding types conceptually
is quite different from recognizing program context types. Fixing this
is out of scope for this change though.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240118033143.3384355-3-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Refactors btf_get_prog_ctx_type to enhance reusability of bpf_ctx_convert_map logic.,"refactor,reusability,btf",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
01b55f4f0cd6ad1a16eca6c43a3190005892ef91,01b55f4f0cd6ad1a16eca6c43a3190005892ef91,Andrii Nakryiko,andrii@kernel.org,1705548699,Alexei Starovoitov,ast@kernel.org,1705551605,379519a1519a94a55e0e0948c405959f1eadc984,33772ff3b887eb2f426ed66bcb1808837a40669c,"libbpf: feature-detect arg:ctx tag support in kernel

Add feature detector of kernel-side arg:ctx (__arg_ctx) tag support. If
this is detected"," libbpf will avoid doing any __arg_ctx-related BTF
rewriting and checks in favor of letting kernel handle this completely.

test_global_funcs/ctx_arg_rewrite subtest is adjusted to do the same
feature detection (albeit in much simpler","[' though round-about and\ninefficient', ' way)', ' and skip the tests. This is done to still be able to\nexecute this test on older kernels (like in libbpf CI).\n\nNote', ' BPF token series ([0]) does a major refactor and code moving of\nlibbpf-internal feature detection ""framework""', ' so to avoid unnecessary\nconflicts we keep newly added feature detection stand-alone with ad-hoc\nresult caching. Once things settle', ' there will be a small follow up to\nre-integrate everything back and move code into its final place in\nnewly-added (by BPF token series) features.c file.\n\n  [0] https://patchwork.kernel.org/project/netdevbpf/list/?series=814209&state=*\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240118033143.3384355-2-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Added feature detection for kernel support of arg:ctx tag in libbpf.,"feature detection,arg:ctx,libbpf",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
36a87385e31c9343af9a4756598e704741250a67,36a87385e31c9343af9a4756598e704741250a67,Hengqi Chen,hengqi.chen@gmail.com,1705466593,Huacai Chen,chenhuacai@loongson.cn,1705466593,37abebd6a08c9764bb5285f0b3661b697d842a49,21c5ae5cc1eee70f7f3b09f1d6b237d9812d4b9c,"LoongArch: BPF: Prevent out-of-bounds memory access

The test_tag test triggers an unhandled page fault:

  # ./test_tag
  [  130.640218] CPU 0 Unable to handle kernel paging request at virtual address ffff80001b898004", era == 9000000003137f7c,"[' ra == 9000000003139e70\n  [  130.640501] Oops[#3]:\n  [  130.640553] CPU: 0 PID: 1326 Comm: test_tag Tainted: G      D    O       6.7.0-rc4-loong-devel-gb62ab1a397cf #47 61985c1d94084daa2432f771daa45b56b10d8d2a\n  [  130.640764] Hardware name: QEMU QEMU Virtual Machine', ' BIOS unknown 2/2/2022\n  [  130.640874] pc 9000000003137f7c ra 9000000003139e70 tp 9000000104cb4000 sp 9000000104cb7a40\n  [  130.641001] a0 ffff80001b894000 a1 ffff80001b897ff8 a2 000000006ba210be a3 0000000000000000\n  [  130.641128] a4 000000006ba210be a5 00000000000000f1 a6 00000000000000b3 a7 0000000000000000\n  [  130.641256] t0 0000000000000000 t1 00000000000007f6 t2 0000000000000000 t3 9000000004091b70\n  [  130.641387] t4 000000006ba210be t5 0000000000000004 t6 fffffffffffffff0 t7 90000000040913e0\n  [  130.641512] t8 0000000000000005 u0 0000000000000dc0 s9 0000000000000009 s0 9000000104cb7ae0\n  [  130.641641] s1 00000000000007f6 s2 0000000000000009 s3 0000000000000095 s4 0000000000000000\n  [  130.641771] s5 ffff80001b894000 s6 ffff80001b897fb0 s7 9000000004090c50 s8 0000000000000000\n  [  130.641900]    ra: 9000000003139e70 build_body+0x1fcc/0x4988\n  [  130.642007]   ERA: 9000000003137f7c build_body+0xd8/0x4988\n  [  130.642112]  CRMD: 000000b0 (PLV0 -IE -DA +PG DACF=CC DACM=CC -WE)\n  [  130.642261]  PRMD: 00000004 (PPLV0 +PIE -PWE)\n  [  130.642353]  EUEN: 00000003 (+FPE +SXE -ASXE -BTE)\n  [  130.642458]  ECFG: 00071c1c (LIE=2-4', '10-12 VS=7)\n  [  130.642554] ESTAT: 00010000 [PIL] (IS= ECode=1 EsubCode=0)\n  [  130.642658]  BADV: ffff80001b898004\n  [  130.642719]  PRID: 0014c010 (Loongson-64bit', ' Loongson-3A5000)\n  [  130.642815] Modules linked in: [last unloaded: bpf_testmod(O)]\n  [  130.642924] Process test_tag (pid: 1326', ' threadinfo=00000000f7f4015f', ' task=000000006499f9fd)\n  [  130.643062] Stack : 0000000000000000 9000000003380724 0000000000000000 0000000104cb7be8\n  [  130.643213]         0000000000000000 25af8d9b6e600558 9000000106250ea0 9000000104cb7ae0\n  [  130.643378]         0000000000000000 0000000000000000 9000000104cb7be8 90000000049f6000\n  [  130.643538]         0000000000000090 9000000106250ea0 ffff80001b894000 ffff80001b894000\n  [  130.643685]         00007ffffb917790 900000000313ca94 0000000000000000 0000000000000000\n  [  130.643831]         ffff80001b894000 0000000000000ff7 0000000000000000 9000000100468000\n  [  130.643983]         0000000000000000 0000000000000000 0000000000000040 25af8d9b6e600558\n  [  130.644131]         0000000000000bb7 ffff80001b894048 0000000000000000 0000000000000000\n  [  130.644276]         9000000104cb7be8 90000000049f6000 0000000000000090 9000000104cb7bdc\n  [  130.644423]         ffff80001b894000 0000000000000000 00007ffffb917790 90000000032acfb0\n  [  130.644572]         ...\n  [  130.644629] Call Trace:\n  [  130.644641] [<9000000003137f7c>] build_body+0xd8/0x4988\n  [  130.644785] [<900000000313ca94>] bpf_int_jit_compile+0x228/0x4ec\n  [  130.644891] [<90000000032acfb0>] bpf_prog_select_runtime+0x158/0x1b0\n  [  130.645003] [<90000000032b3504>] bpf_prog_load+0x760/0xb44\n  [  130.645089] [<90000000032b6744>] __sys_bpf+0xbb8/0x2588\n  [  130.645175] [<90000000032b8388>] sys_bpf+0x20/0x2c\n  [  130.645259] [<9000000003f6ab38>] do_syscall+0x7c/0x94\n  [  130.645369] [<9000000003121c5c>] handle_syscall+0xbc/0x158\n  [  130.645507]\n  [  130.645539] Code: 380839f6  380831f9  28412bae <24000ca6> 004081ad  0014cb50  004083e8  02bff34c  58008e91\n  [  130.645729]\n  [  130.646418] ---[ end trace 0000000000000000 ]---\n\nOn my machine', ' which has CONFIG_PAGE_SIZE_16KB=y', ' the test failed at\nloading a BPF prog with 2039 instructions:\n\n  prog = (struct bpf_prog *)ffff80001b894000\n  insn = (struct bpf_insn *)(prog->insnsi)ffff80001b894048\n  insn + 2039 = (struct bpf_insn *)ffff80001b898000 <- end of the page\n\nIn the build_insn() function', ' we are trying to access next instruction\nunconditionally', ' i.e. `(insn + 1)->imm`. The address lies in the next\npage and can be not owned by the current process', ' thus an page fault is\ninevitable and then segfault.\n\nSo', "" let's access next instruction only under `dst = imm64` context.\n\nWith this fix"", ' we have:\n\n  # ./test_tag\n  test_tag: OK (40945 tests)\n\nFixes: bbfddb904df6f82 (""LoongArch: BPF: Avoid declare variables in switch-case"")\nTested-by: Tiezhu Yang <yangtiezhu@loongson.cn>\nSigned-off-by: Hengqi Chen <hengqi.chen@gmail.com>\nSigned-off-by: Huacai Chen <chenhuacai@loongson.cn>\n', '']",The commit prevents out-of-bounds memory access on LoongArch architecture for BPF.,"LoongArch,BPF,memory",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
21c5ae5cc1eee70f7f3b09f1d6b237d9812d4b9c,21c5ae5cc1eee70f7f3b09f1d6b237d9812d4b9c,Hengqi Chen,hengqi.chen@gmail.com,1705466593,Huacai Chen,chenhuacai@loongson.cn,1705466593,b43792773494abb6c9264c8a1998110a054d121e,91af17cd7d03db8836554c91ba7c38b0817aa980,"LoongArch: BPF: Support 64-bit pointers to kfuncs

Like commit 1cf3bfc60f9836f (""bpf: Support 64-bit pointers to kfuncs"")
for s390x"," add support for 64-bit pointers to kfuncs for LoongArch.
Since the infrastructure is already implemented in BPF core","[' the only\nthing need to be done is to override bpf_jit_supports_far_kfunc_call().\n\nBefore this change', "" several test_verifier tests failed:\n\n  # ./test_verifier | grep # | grep FAIL\n  #119/p calls: invalid kfunc call: ptr_to_mem to struct with non-scalar FAIL\n  #120/p calls: invalid kfunc call: ptr_to_mem to struct with nesting depth > 4 FAIL\n  #121/p calls: invalid kfunc call: ptr_to_mem to struct with FAM FAIL\n  #122/p calls: invalid kfunc call: reg->type != PTR_TO_CTX FAIL\n  #123/p calls: invalid kfunc call: void * not allowed in func proto without mem size arg FAIL\n  #124/p calls: trigger reg2btf_ids[reg->type] for reg->type > __BPF_REG_TYPE_MAX FAIL\n  #125/p calls: invalid kfunc call: reg->off must be zero when passed to release kfunc FAIL\n  #126/p calls: invalid kfunc call: don't match first member type when passed to release kfunc FAIL\n  #127/p calls: invalid kfunc call: PTR_TO_BTF_ID with negative offset FAIL\n  #128/p calls: invalid kfunc call: PTR_TO_BTF_ID with variable offset FAIL\n  #129/p calls: invalid kfunc call: referenced arg needs refcounted PTR_TO_BTF_ID FAIL\n  #130/p calls: valid kfunc call: referenced arg needs refcounted PTR_TO_BTF_ID FAIL\n  #486/p map_kptr: ref: reference state created and released on xchg FAIL\n\nThis is because the kfuncs in the loaded module are far away from\n__bpf_call_base:\n\n  ffff800002009440 t bpf_kfunc_call_test_fail1    [bpf_testmod]\n  9000000002e128d8 T __bpf_call_base\n\nThe offset relative to __bpf_call_base does NOT fit in s32"", ' which breaks\nthe assumption in BPF core. Enable bpf_jit_supports_far_kfunc_call() lifts\nthis limit.\n\nNote that to reproduce the above result', ' tools/testing/selftests/bpf/config\nshould be applied', ' and run the test with JIT enabled', ' unpriv BPF enabled.\n\nWith this change', ' the test_verifier tests now all passed:\n\n  # ./test_verifier\n  ...\n  Summary: 777 PASSED', ' 0 SKIPPED', ' 0 FAILED\n\nTested-by: Tiezhu Yang <yangtiezhu@loongson.cn>\nSigned-off-by: Hengqi Chen <hengqi.chen@gmail.com>\nSigned-off-by: Huacai Chen <chenhuacai@loongson.cn>\n', '']",Enable 64-bit pointer support for kfuncs in LoongArch architecture.,"LoongArch, 64-bit, kfuncs",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
33772ff3b887eb2f426ed66bcb1808837a40669c,33772ff3b887eb2f426ed66bcb1808837a40669c,Hao Sun,sunhao.th@gmail.com,1705306828,Daniel Borkmann,daniel@iogearbox.net,1705421568,61761765fc9b6a76a9f4baddb9e63aa6cfe1a016,22c7fa171a02d310e3a3f6ed46a698ca8a0060ed,"selftests/bpf: Add test for alu on PTR_TO_FLOW_KEYS

Add a test case for PTR_TO_FLOW_KEYS alu. Testing if alu with variable
offset on flow_keys is rejected. For the fixed offset success case"," we
already have C code coverage to verify (e.g. via bpf_flow.c).

Signed-off-by: Hao Sun <sunhao.th@gmail.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/bpf/20240115082028.9992-2-sunhao.th@gmail.com
",[''],Add a test case for validating alu operations on PTR_TO_FLOW_KEYS in selftests.,"alu, PTR_TO_FLOW_KEYS, test",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tracepoints like programs']
22c7fa171a02d310e3a3f6ed46a698ca8a0060ed,22c7fa171a02d310e3a3f6ed46a698ca8a0060ed,Hao Sun,sunhao.th@gmail.com,1705306827,Daniel Borkmann,daniel@iogearbox.net,1705421549,25d757455c4e813c372b4407539ef27566547f9b,8e33d5db7d014ea2fb2994bbe42010d043997d60,"bpf: Reject variable offset alu on PTR_TO_FLOW_KEYS

For PTR_TO_FLOW_KEYS"," check_flow_keys_access() only uses fixed off
for validation. However","[' variable offset ptr alu is not prohibited\nfor this ptr kind. So the variable offset is not checked.\n\nThe following prog is accepted:\n\n  func#0 @0\n  0: R1=ctx() R10=fp0\n  0: (bf) r6 = r1                       ; R1=ctx() R6_w=ctx()\n  1: (79) r7 = *(u64 *)(r6 +144)        ; R6_w=ctx() R7_w=flow_keys()\n  2: (b7) r8 = 1024                     ; R8_w=1024\n  3: (37) r8 /= 1                       ; R8_w=scalar()\n  4: (57) r8 &= 1024                    ; R8_w=scalar(smin=smin32=0', '\n  smax=umax=smax32=umax32=1024', 'var_off=(0x0; 0x400))\n  5: (0f) r7 += r8\n  mark_precise: frame0: last_idx 5 first_idx 0 subseq_idx -1\n  mark_precise: frame0: regs=r8 stack= before 4: (57) r8 &= 1024\n  mark_precise: frame0: regs=r8 stack= before 3: (37) r8 /= 1\n  mark_precise: frame0: regs=r8 stack= before 2: (b7) r8 = 1024\n  6: R7_w=flow_keys(smin=smin32=0', 'smax=umax=smax32=umax32=1024', 'var_off\n  =(0x0; 0x400)) R8_w=scalar(smin=smin32=0', 'smax=umax=smax32=umax32=1024', '\n  var_off=(0x0; 0x400))\n  6: (79) r0 = *(u64 *)(r7 +0)          ; R0_w=scalar()\n  7: (95) exit\n\nThis prog loads flow_keys to r7', ' and adds the variable offset r8\nto r7', ' and finally causes out-of-bounds access:\n\n  BUG: unable to handle page fault for address: ffffc90014c80038\n  [...]\n  Call Trace:\n   <TASK>\n   bpf_dispatcher_nop_func include/linux/bpf.h:1231 [inline]\n   __bpf_prog_run include/linux/filter.h:651 [inline]\n   bpf_prog_run include/linux/filter.h:658 [inline]\n   bpf_prog_run_pin_on_cpu include/linux/filter.h:675 [inline]\n   bpf_flow_dissect+0x15f/0x350 net/core/flow_dissector.c:991\n   bpf_prog_test_run_flow_dissector+0x39d/0x620 net/bpf/test_run.c:1359\n   bpf_prog_test_run kernel/bpf/syscall.c:4107 [inline]\n   __sys_bpf+0xf8f/0x4560 kernel/bpf/syscall.c:5475\n   __do_sys_bpf kernel/bpf/syscall.c:5561 [inline]\n   __se_sys_bpf kernel/bpf/syscall.c:5559 [inline]\n   __x64_sys_bpf+0x73/0xb0 kernel/bpf/syscall.c:5559\n   do_syscall_x64 arch/x86/entry/common.c:52 [inline]\n   do_syscall_64+0x3f/0x110 arch/x86/entry/common.c:83\n   entry_SYSCALL_64_after_hwframe+0x63/0x6b\n\nFix this by rejecting ptr alu with variable offset on flow_keys.\nApplying the patch rejects the program with ""R7 pointer arithmetic\non flow_keys prohibited"".\n\nFixes: d58e468b1112 (""flow_dissector: implements flow dissector BPF hook"")\nSigned-off-by: Hao Sun <sunhao.th@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/bpf/20240115082028.9992-1-sunhao.th@gmail.com\n', '']",This commit rejects variable offset ALU operations on PTR_TO_FLOW_KEYS to ensure fixed offset validation.,"PTR_TO_FLOW_KEYS,variable offset,validation",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['tc/netfilter like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8e33d5db7d014ea2fb2994bbe42010d043997d60,8e33d5db7d014ea2fb2994bbe42010d043997d60,Alexei Starovoitov,ast@kernel.org,1705172504,Alexei Starovoitov,ast@kernel.org,1705172504,71e53516b735b032818495974d52ea94d669012e,894d7508316e7ad722df597d68b4b1797a9eee11 dbd7db7787ba1743a505a495e479550932836fa4,"Merge branch 'bpf-fix-backward-progress-bug-in-bpf_iter_udp'

Martin KaFai Lau says:

====================
bpf: Fix backward progress bug in bpf_iter_udp

From: Martin KaFai Lau <martin.lau@kernel.org>

This patch set fixes an issue in bpf_iter_udp that makes backward
progress and prevents the user space process from finishing. There is
a test at the end to reproduce the bug.

Please see individual patches for details.

v3:
- Fixed the iter_fd check and local_port check in the
  patch 3 selftest. (Yonghong)
- Moved jhash2 to test_jhash.h in the patch 3. (Yonghong)
- Added explanation in the bucket selection in the patch 3. (Yonghong)

v2:
- Added patch 1 to fix another bug that goes back to
  the previous bucket
- Simplify the fix in patch 2 to always reset iter->offset to 0
- Add a test case to close all udp_sk in a bucket while
  in the middle of the iteration.
====================

Link: https://lore.kernel.org/r/20240112190530.3751661-1-martin.lau@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Fixes backward progress bug in bpf_iter_udp that prevents user space process completion.,"bpf_iter_udp, bug fix, backward progress",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
dbd7db7787ba1743a505a495e479550932836fa4,dbd7db7787ba1743a505a495e479550932836fa4,Martin KaFai Lau,martin.lau@kernel.org,1705086330,Alexei Starovoitov,ast@kernel.org,1705172504,71e53516b735b032818495974d52ea94d669012e,2242fd537fab52d5f4d2fbb1845f047c01fad0cf,"selftests/bpf: Test udp and tcp iter batching

The patch adds a test to exercise the bpf_iter_udp batching
logic. It specifically tests the case that there are multiple
so_reuseport udp_sk in a bucket of the udp_table.

The test creates two sets of so_reuseport sockets and
each set on a different port. Meaning there will be
two buckets in the udp_table.

The test does the following:
1. read() 3 out of 4 sockets in the first bucket.
2. close() all sockets in the first bucket. This
   will ensure the current bucket's offset in
   the kernel does not affect the read() of the
   following bucket.
3. read() all 4 sockets in the second bucket.

The test also reads one udp_sk at a time from
the bpf_iter_udp prog. The true case in
""do_test(..."," bool onebyone)"". This is the buggy case
that the previous patch fixed.

It also tests the ""false"" case in ""do_test(...","[' bool onebyone)""', '\nmeaning the userspace reads the whole bucket. There is\nno bug in this case but adding this test also while\nat it.\n\nConsidering the way to have multiple tcp_sk in the same\nbucket is similar (by using so_reuseport)', '\nthis patch also tests the bpf_iter_tcp even though the\nbpf_iter_tcp batching logic works correctly.\n\nBoth IP v4 and v6 are exercising the same bpf_iter batching\ncode path', ' so only v6 is tested.\n\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nLink: https://lore.kernel.org/r/20240112190530.3751661-4-martin.lau@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit adds a test for bpf_iter_udp batching in selftests.,"bpf_iter_udp, batching, udp_sk",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2242fd537fab52d5f4d2fbb1845f047c01fad0cf,2242fd537fab52d5f4d2fbb1845f047c01fad0cf,Martin KaFai Lau,martin.lau@kernel.org,1705086329,Alexei Starovoitov,ast@kernel.org,1705172504,edc0bcbd15a6c566dcdeb7fbd1e1ce40b39f56ff,19ca0823f6eaad01d18f664a00550abe912c034c,"bpf: Avoid iter->offset making backward progress in bpf_iter_udp

There is a bug in the bpf_iter_udp_batch() function that stops
the userspace from making forward progress.

The case that triggers the bug is the userspace passed in
a very small read buffer. When the bpf prog does bpf_seq_printf","
the userspace read buffer is not enough to capture the whole bucket.

When the read buffer is not large enough","[' the kernel will remember\nthe offset of the bucket in iter->offset such that the next userspace\nread() can continue from where it left off.\n\nThe kernel will skip the number (== ""iter->offset"") of sockets in\nthe next read(). However', ' the code directly decrements the\n""--iter->offset"". This is incorrect because the next read() may\nnot consume the whole bucket either and then the next-next read()\nwill start from offset 0. The net effect is the userspace will\nkeep reading from the beginning of a bucket and the process will\nnever finish. ""iter->offset"" must always go forward until the\nwhole bucket is consumed.\n\nThis patch fixes it by using a local variable ""resume_offset""\nand ""resume_bucket"". ""iter->offset"" is always reset to 0 before\nit may be used. ""iter->offset"" will be advanced to the\n""resume_offset"" when it continues from the ""resume_bucket"" (i.e.\n""state->bucket == resume_bucket""). This brings it closer to\nthe bpf_iter_tcp\'s offset handling which does not suffer\nthe same bug.\n\nCc: Aditi Ghag <aditi.ghag@isovalent.com>\nFixes: c96dac8d369f (""bpf: udp: Implement batching for sockets iterator"")\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nReviewed-by: Aditi Ghag <aditi.ghag@isovalent.com>\nLink: https://lore.kernel.org/r/20240112190530.3751661-3-martin.lau@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes a bug in bpf_iter_udp_batch to ensure forward progress with small userspace read buffers.,"bug, bpf_iter_udp, userspace",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The syscall interface,['socket like programs']
19ca0823f6eaad01d18f664a00550abe912c034c,19ca0823f6eaad01d18f664a00550abe912c034c,Martin KaFai Lau,martin.lau@kernel.org,1705086328,Alexei Starovoitov,ast@kernel.org,1705172504,f3b56edf62d964d24064b1ffb659697cb71f2408,894d7508316e7ad722df597d68b4b1797a9eee11,"bpf: iter_udp: Retry with a larger batch size without going back to the previous bucket

The current logic is to use a default size 16 to batch the whole bucket.
If it is too small"," it will retry with a larger batch size.

The current code accidentally does a state->bucket-- before retrying.
This goes back to retry with the previous bucket which has already
been done. This patch fixed it.

It is hard to create a selftest. I added a WARN_ON(state->bucket < 0)","['\nforced a particular port to be hashed to the first bucket', '\ncreated >16 sockets', ' and observed the for-loop went back\nto the ""-1"" bucket.\n\nCc: Aditi Ghag <aditi.ghag@isovalent.com>\nFixes: c96dac8d369f (""bpf: udp: Implement batching for sockets iterator"")\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nReviewed-by: Aditi Ghag <aditi.ghag@isovalent.com>\nLink: https://lore.kernel.org/r/20240112190530.3751661-2-martin.lau@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']","Fixes issue in iter_udp logic where retries incorrectly decrease bucket index, causing redundant processing of previous bucket.","iter_udp, batch, fix",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"[""It's not related to any of the above.""]"
fef018d8199661962b5fc0f0d1501caa54b2b533,fef018d8199661962b5fc0f0d1501caa54b2b533,Linus Torvalds,torvalds@linux-foundation.org,1705099513,Linus Torvalds,torvalds@linux-foundation.org,1705099513,df2bb3503feec710d84bca3ba37487b5822cded1,d97a78423c33f68ca6543de510a409167baed6f5 0b43615af19742e1f4f71d332e72381430804804,"Merge tag 'hid-for-linus-2024010801' of git://git.kernel.org/pub/scm/linux/kernel/git/hid/hid

Pull HID updates from Jiri Kosina:

 - assorted functional fixes for hid-steam ported from SteamOS betas
   (Vicki Pfau)

 - fix for custom sensor-hub sensors (hinge angle sensor and LISS
   sensors) not working (Yauhen Kharuzhy)

 - functional fix for handling Confidence in Wacom driver (Jason
   Gerecke)

 - support for Ilitek ili2901 touchscreen (Zhengqiao Xia)

 - power management fix for Wacom userspace battery exporting
   (Tatsunosuke Tobita)

 - rework of wait-for-reset in order to reduce the need for
   I2C_HID_QUIRK_NO_IRQ_AFTER_RESET qurk; the success rate is now 50%
   better"," but there are still further improvements to be made (Hans de
   Goede)

 - greatly improved coverage of Tablets in hid-selftests (Benjamin
   Tissoires)

 - support for Nintendo NSO controllers -- SNES","["" Genesis and N64 (Ryan\n   McClelland)\n\n - support for controlling mcp2200 GPIOs (Johannes Roith)\n\n - power management improvement for EHL OOB wakeup in intel-ish\n   (Kai-Heng Feng)\n\n - other assorted device-specific fixes and code cleanups\n\n* tag 'hid-for-linus-2024010801' of git://git.kernel.org/pub/scm/linux/kernel/git/hid/hid: (53 commits)\n  HID: amd_sfh: Add a new interface for exporting ALS data\n  HID: amd_sfh: Add a new interface for exporting HPD data\n  HID: amd_sfh: rename float_to_int() to amd_sfh_float_to_int()\n  HID: i2c-hid: elan: Add ili2901 timing\n  dt-bindings: HID: i2c-hid: elan: Introduce Ilitek ili2901\n  HID: bpf: make bus_type const in struct hid_bpf_ops\n  HID: make ishtp_cl_bus_type const\n  HID: make hid_bus_type const\n  HID: hid-steam: Add gamepad-only mode switched to by holding options\n  HID: hid-steam: Better handling of serial number length\n  HID: hid-steam: Update list of identifiers from SDL\n  HID: hid-steam: Make client_opened a counter\n  HID: hid-steam: Clean up locking\n  HID: hid-steam: Disable watchdog instead of using a heartbeat\n  HID: hid-steam: Avoid overwriting smoothing parameter\n  HID: magicmouse: fix kerneldoc for struct magicmouse_sc\n  HID: sensor-hub: Enable hid core report processing for all devices\n  HID: wacom: Add additional tests of confidence behavior\n  HID: wacom: Correct behavior when processing some confidence == false touches\n  HID: nintendo: add support for nso controllers\n  ...\n"", '']","Merged HID updates including functional fixes, sensor support, power management fixes, and improved self-tests.","HID, fixes, support",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
3e7aeb78ab01c2c2f0e1f784e5ddec88fcd3d106,3e7aeb78ab01c2c2f0e1f784e5ddec88fcd3d106,Linus Torvalds,torvalds@linux-foundation.org,1704996449,Linus Torvalds,torvalds@linux-foundation.org,1704996449,bdbfd45f8d8e967b06ed2d9cb92f67f686d02659,de927f6c0b07d9e698416c5b287c521b07694cac a7fe0881d9b78d402bbd9067dd4503a57c57a1d9,"Merge tag 'net-next-6.8' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net-next

Pull networking updates from Paolo Abeni:
 ""The most interesting thing is probably the networking structs
  reorganization and a significant amount of changes is around
  self-tests.

  Core & protocols:

   - Analyze and reorganize core networking structs (socks", netdev,"['\n     netns', ' mibs) to optimize cacheline consumption and set up build\n     time warnings to safeguard against future header changes\n\n     This improves TCP performances with many concurrent connections up\n     to 40%\n\n   - Add page-pool netlink-based introspection', ' exposing the memory\n     usage and recycling stats. This helps indentify bad PP users and\n     possible leaks\n\n   - Refine TCP/DCCP source port selection to no longer favor even\n     source port at connect() time when IP_LOCAL_PORT_RANGE is set. This\n     lowers the time taken by connect() for hosts having many active\n     connections to the same destination\n\n   - Refactor the TCP bind conflict code', ' shrinking related socket\n     structs\n\n   - Refactor TCP SYN-Cookie handling', ' as a preparation step to allow\n     arbitrary SYN-Cookie processing via eBPF\n\n   - Tune optmem_max for 0-copy usage', ' increasing the default value to\n     128KB and namespecifying it\n\n   - Allow coalescing for cloned skbs coming from page pools', ' improving\n     RX performances with some common configurations\n\n   - Reduce extension header parsing overhead at GRO time\n\n   - Add bridge MDB bulk deletion support', ' allowing user-space to\n     request the deletion of matching entries\n\n   - Reorder nftables struct members', ' to keep data accessed by the\n     datapath first\n\n   - Introduce TC block ports tracking and use. This allows supporting\n     multicast-like behavior at the TC layer\n\n   - Remove UAPI support for retired TC qdiscs (dsmark', ' CBQ and ATM) and\n     classifiers (RSVP and tcindex)\n\n   - More data-race annotations\n\n   - Extend the diag interface to dump TCP bound-only sockets\n\n   - Conditional notification of events for TC qdisc class and actions\n\n   - Support for WPAN dynamic associations with nearby devices', ' to form\n     a sub-network using a specific PAN ID\n\n   - Implement SMCv2.1 virtual ISM device support\n\n   - Add support for Batman-avd mulicast packet type\n\n  BPF:\n\n   - Tons of verifier improvements:\n       - BPF register bounds logic and range support along with a large\n         test suite\n       - log improvements\n       - complete precision tracking support for register spills\n       - track aligned STACK_ZERO cases as imprecise spilled registers.\n         This improves the verifier ""instructions processed"" metric from\n         single digit to 50-60% for some programs\n       - support for user\'s global BPF subprogram arguments with few\n         commonly requested annotations for a better developer\n         experience\n       - support tracking of BPF_JNE which helps cases when the compiler\n         transforms (unsigned) ""a > 0"" into ""if a == 0 goto xxx"" and the\n         like\n       - several fixes\n\n   - Add initial TX metadata implementation for AF_XDP with support in\n     mlx5 and stmmac drivers. Two types of offloads are supported right\n     now', ' that is', ' TX timestamp and TX checksum offload\n\n   - Fix kCFI bugs in BPF all forms of indirect calls from BPF into\n     kernel and from kernel into BPF work with CFI enabled. This allows\n     BPF to work with CONFIG_FINEIBT=y\n\n   - Change BPF verifier logic to validate global subprograms lazily\n     instead of unconditionally before the main program', ' so they can be\n     guarded using BPF CO-RE techniques\n\n   - Support uid/gid options when mounting bpffs\n\n   - Add a new kfunc which acquires the associated cgroup of a task\n     within a specific cgroup v1 hierarchy where the latter is\n     identified by its id\n\n   - Extend verifier to allow bpf_refcount_acquire() of a map value\n     field obtained via direct load which is a use-case needed in\n     sched_ext\n\n   - Add BPF link_info support for uprobe multi link along with bpftool\n     integration for the latter\n\n   - Support for VLAN tag in XDP hints\n\n   - Remove deprecated bpfilter kernel leftovers given the project is\n     developed in user-space (https://github.com/facebook/bpfilter)\n\n  Misc:\n\n   - Support for parellel TC self-tests execution\n\n   - Increase MPTCP self-tests coverage\n\n   - Updated the bridge documentation', ' including several so-far\n     undocumented features\n\n   - Convert all the net self-tests to run in unique netns', ' to avoid\n     random failures due to conflict and allow concurrent runs\n\n   - Add TCP-AO self-tests\n\n   - Add kunit tests for both cfg80211 and mac80211\n\n   - Autogenerate Netlink families documentation from YAML spec\n\n   - Add yml-gen support for fixed headers and recursive nests', ' the tool\n     can now generate user-space code for all genetlink families for\n     which we have specs\n\n   - A bunch of additional module descriptions fixes\n\n   - Catch incorrect freeing of pages belonging to a page pool\n\n  Driver API:\n\n   - Rust abstractions for network PHY drivers; do not cover yet the\n     full C API', ' but already allow implementing functional PHY drivers\n     in rust\n\n   - Introduce queue and NAPI support in the netdev Netlink interface', '\n     allowing complete access to the device <> NAPIs <> queues\n     relationship\n\n   - Introduce notifications filtering for devlink to allow control\n     application scale to thousands of instances\n\n   - Improve PHY validation', ' requesting rate matching information for\n     each ethtool link mode supported by both the PHY and host\n\n   - Add support for ethtool symmetric-xor RSS hash\n\n   - ACPI based Wifi band RFI (WBRF) mitigation feature for the AMD\n     platform\n\n   - Expose pin fractional frequency offset value over new DPLL generic\n     netlink attribute\n\n   - Convert older drivers to platform remove callback returning void\n\n   - Add support for PHY package MMD read/write\n\n  New hardware / drivers:\n\n   - Ethernet:\n       - Octeon CN10K devices\n       - Broadcom 5760X P7\n       - Qualcomm SM8550 SoC\n       - Texas Instrument DP83TG720S PHY\n\n   - Bluetooth:\n       - IMC Networks Bluetooth radio\n\n  Removed:\n\n   - WiFi:\n       - libertas 16-bit PCMCIA support\n       - Atmel at76c50x drivers\n       - HostAP ISA/PCMCIA style 802.11b driver\n       - zd1201 802.11b USB dongles\n       - Orinoco ISA/PCMCIA 802.11b driver\n       - Aviator/Raytheon driver\n       - Planet WL3501 driver\n       - RNDIS USB 802.11b driver\n\n  Driver updates:\n\n   - Ethernet high-speed NICs:\n       - Intel (100G', ' ice', "" idpf):\n          - allow one by one port representors creation and removal\n          - add temperature and clock information reporting\n          - add get/set for ethtool's header split ringparam\n          - add again FW logging\n          - adds support switchdev hardware packet mirroring\n          - iavf: implement symmetric-xor RSS hash\n          - igc: add support for concurrent physical and free-running\n            timers\n          - i40e: increase the allowable descriptors\n       - nVidia/Mellanox:\n          - Preparation for Socket-Direct multi-dev netdev. That will\n            allow in future releases combining multiple PFs devices\n            attached to different NUMA nodes under the same netdev\n       - Broadcom (bnxt):\n          - TX completion handling improvements\n          - add basic ntuple filter support\n          - reduce MSIX vectors usage for MQPRIO offload\n          - add VXLAN support"", ' USO offload and TX coalesce completion\n            for P7\n       - Marvell Octeon EP:\n          - xmit-more support\n          - add PF-VF mailbox support and use it for FW notifications\n            for VFs\n       - Wangxun (ngbe/txgbe):\n          - implement ethtool functions to operate pause param', ' ring\n            param', ' coalesce channel number and msglevel\n       - Netronome/Corigine (nfp):\n          - add flow-steering support\n          - support UDP segmentation offload\n\n   - Ethernet NICs embedded', ' slower', ' virtual:\n       - Xilinx AXI: remove duplicate DMA code adopting the dma engine\n         driver\n       - stmmac: add support for HW-accelerated VLAN stripping\n       - TI AM654x sw: add mqprio', ' frame preemption & coalescing\n       - gve: add support for non-4k page sizes.\n       - virtio-net: support dynamic coalescing moderation\n\n   - nVidia/Mellanox Ethernet datacenter switches:\n       - allow firmware upgrade without a reboot\n       - more flexible support for bridge flooding via the compressed\n         FID flooding mode\n\n   - Ethernet embedded switches:\n       - Microchip:\n          - fine-tune flow control and speed configurations in KSZ8xxx\n          - KSZ88X3: enable setting rmii reference\n       - Renesas:\n          - add jumbo frames support\n       - Marvell:\n          - 88E6xxx: add ""eth-mac"" and ""rmon"" stats support\n\n   - Ethernet PHYs:\n       - aquantia: add firmware load support\n       - at803x: refactor the driver to simplify adding support for more\n         chip variants\n       - NXP C45 TJA11xx: Add MACsec offload support\n\n   - Wifi:\n       - MediaTek (mt76):\n          - NVMEM EEPROM improvements\n          - mt7996 Extremely High Throughput (EHT) improvements\n          - mt7996 Wireless Ethernet Dispatcher (WED) support\n          - mt7996 36-bit DMA support\n       - Qualcomm (ath12k):\n          - support for a single MSI vector\n          - WCN7850: support AP mode\n       - Intel (iwlwifi):\n          - new debugfs file fw_dbg_clear\n          - allow concurrent P2P operation on DFS channels\n\n   - Bluetooth:\n       - QCA2066: support HFP offload\n       - ISO: more broadcast-related improvements\n       - NXP: better recovery in case receiver/transmitter get out of sync""\n\n* tag \'net-next-6.8\' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net-next: (1714 commits)\n  lan78xx: remove redundant statement in lan78xx_get_eee\n  lan743x: remove redundant statement in lan743x_ethtool_get_eee\n  bnxt_en: Fix RCU locking for ntuple filters in bnxt_rx_flow_steer()\n  bnxt_en: Fix RCU locking for ntuple filters in bnxt_srxclsrldel()\n  bnxt_en: Remove unneeded variable in bnxt_hwrm_clear_vnic_filter()\n  tcp: Revert no longer abort SYN_SENT when receiving some ICMP\n  Revert ""mlx5 updates 2023-12-20""\n  Revert ""net: stmmac: Enable Per DMA Channel interrupt""\n  ipvlan: Remove usage of the deprecated ida_simple_xx() API\n  ipvlan: Fix a typo in a comment\n  net/sched: Remove ipt action tests\n  net: stmmac: Use interrupt mode INTM=1 for per channel irq\n  net: stmmac: Add support for TX/RX channel interrupt\n  net: stmmac: Make MSI interrupt routine generic\n  dt-bindings: net: snps', 'dwmac: per channel irq\n  net: phy: at803x: make read_status more generic\n  net: phy: at803x: add support for cdt cross short test for qca808x\n  net: phy: at803x: refactor qca808x cable test get status function\n  net: phy: at803x: generalize cdt fault length function\n  net: ethernet: cortina: Drop TSO support\n  ...\n', '']",Merge networking updates from Paolo Abeni including core structs reorganization and self-tests.,"networking, structs, reorganization",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
e3977e0609a07d86406029fceea0fd40d7849368,e3977e0609a07d86406029fceea0fd40d7849368,Tejun Heo,tj@kernel.org,1704836882,Greg Kroah-Hartman,gregkh@linuxfoundation.org,1704970287,f60922c1cf2e540d4b4647f14e1c3e076b2beeb2,c312828c37a72fe2d033a961c47c227b0767e9f8,"Revert ""kernfs: convert kernfs_idr_lock to an irq safe raw spinlock""

This reverts commit dad3fb67ca1cbef87ce700e83a55835e5921ce8a.

The commit converted kernfs_idr_lock to an IRQ-safe raw_spinlock because it
could be acquired while holding an rq lock through bpf_cgroup_from_id().
However"," kernfs_idr_lock is held while doing GPF_NOWAIT allocations which
involves acquiring an non-IRQ-safe and non-raw lock leading to the following
lockdep warning:

  =============================
  [ BUG: Invalid wait context ]
  6.7.0-rc5-kzm9g-00251-g655022a45b1c #578 Not tainted
  -----------------------------
  swapper/0/0 is trying to lock:
  dfbcd488 (&c->lock){....}-{3:3}","[' at: local_lock_acquire+0x0/0xa4\n  other info that might help us debug this:\n  context-{5:5}\n  2 locks held by swapper/0/0:\n   #0: dfbc9c60 (lock){+.+.}-{3:3}', ' at: local_lock_acquire+0x0/0xa4\n   #1: c0c012a8 (kernfs_idr_lock){....}-{2:2}', "" at: __kernfs_new_node.constprop.0+0x68/0x258\n  stack backtrace:\n  CPU: 0 PID: 0 Comm: swapper/0 Not tainted 6.7.0-rc5-kzm9g-00251-g655022a45b1c #578\n  Hardware name: Generic SH73A0 (Flattened Device Tree)\n   unwind_backtrace from show_stack+0x10/0x14\n   show_stack from dump_stack_lvl+0x68/0x90\n   dump_stack_lvl from __lock_acquire+0x3cc/0x168c\n   __lock_acquire from lock_acquire+0x274/0x30c\n   lock_acquire from local_lock_acquire+0x28/0xa4\n   local_lock_acquire from ___slab_alloc+0x234/0x8a8\n   ___slab_alloc from __slab_alloc.constprop.0+0x30/0x44\n   __slab_alloc.constprop.0 from kmem_cache_alloc+0x7c/0x148\n   kmem_cache_alloc from radix_tree_node_alloc.constprop.0+0x44/0xdc\n   radix_tree_node_alloc.constprop.0 from idr_get_free+0x110/0x2b8\n   idr_get_free from idr_alloc_u32+0x9c/0x108\n   idr_alloc_u32 from idr_alloc_cyclic+0x50/0xb8\n   idr_alloc_cyclic from __kernfs_new_node.constprop.0+0x88/0x258\n   __kernfs_new_node.constprop.0 from kernfs_create_root+0xbc/0x154\n   kernfs_create_root from sysfs_init+0x18/0x5c\n   sysfs_init from mnt_init+0xc4/0x220\n   mnt_init from vfs_caches_init+0x6c/0x88\n   vfs_caches_init from start_kernel+0x474/0x528\n   start_kernel from 0x0\n\nLet's rever the commit. It's undesirable to spread out raw spinlock usage\nanyway and the problem can be solved by protecting the lookup path with RCU\ninstead.\n\nSigned-off-by: Tejun Heo <tj@kernel.org>\nCc: Andrea Righi <andrea.righi@canonical.com>\nReported-by: Geert Uytterhoeven <geert@linux-m68k.org>\nLink: http://lkml.kernel.org/r/CAMuHMdV=AKt+mwY7svEq5gFPx41LoSQZ_USME5_MEdWQze13ww@mail.gmail.com\nLink: https://lore.kernel.org/r/20240109214828.252092-2-tj@kernel.org\nTested-by: Andrea Righi <andrea.righi@canonical.com>\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>\n"", '']",Revert the conversion of kernfs_idr_lock to an IRQ-safe raw spinlock due to lockdep warning issues.,"revert, spinlock, lockdep",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['cgroup like programs']
8158a50f9058ce882a6a020c41cef6bae2c3eae3,8158a50f9058ce882a6a020c41cef6bae2c3eae3,Jakub Kicinski,kuba@kernel.org,1704510932,Jakub Kicinski,kuba@kernel.org,1704510932,7b0eef570ee9a02971813e074afa674a54e8e403,795fd9342c628839ac9c3f3133d063ce2e577ea7 5fe4ee6ae187523f710f1b93024437a073d88b17,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next

Daniel Borkmann says:

====================
pull-request: bpf-next 2024-01-05

We've added 40 non-merge commits during the last 2 day(s) which contain
a total of 73 files changed", 1526 insertions(+),"[' 951 deletions(-).\n\nThe main changes are:\n\n1) Fix a memory leak when streaming AF_UNIX sockets were inserted\n   into multiple sockmap slots/maps', ' from John Fastabend.\n\n2) Fix gotol in s390 BPF JIT with large offsets', ' from Ilya Leoshkevich.\n\n3) Fix reattachment branch in bpf_tracing_prog_attach() and reject\n   the request if there is no valid attach_btf', ' from Jiri Olsa.\n\n4) Remove deprecated bpfilter kernel leftovers given the project\n   is developed in user space (https://github.com/facebook/bpfilter)', '\n   from Quentin Deslandes.\n\n5) Relax tracing BPF program recursive attach rules given right now\n   it is not possible to create tracing program call cycles', '\n   from Dmitrii Dolgov.\n\n6) Fix excessive memory consumption for the bpf_global_percpu_ma\n   for systems with a large number of CPUs', ' from Yonghong Song.\n\n7) Small x86 BPF JIT cleanup to reuse emit_nops instead of open-coding\n   memcpy of x86_nops', ' from Leon Hwang.\n\n8) Follow-up for libbpf to support __arg_ctx global function argument tag\n   semantics to complement the merged kernel side', ' from Andrii Nakryiko.\n\n9) Introduce ""volatile compare"" macros for BPF selftests in order\n   to make the latter more robust against compiler optimization', ""\n   from Alexei Starovoitov.\n\n10) Small simplification in verifier's size checking of helper accesses\n    along with additional selftests"", "" from Andrei Matei.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next: (40 commits)\n  selftests/bpf: Test re-attachment fix for bpf_tracing_prog_attach\n  bpf: Fix re-attachment branch in bpf_tracing_prog_attach\n  selftests/bpf: Add test for recursive attachment of tracing progs\n  bpf: Relax tracing prog recursive attach rules\n  bpf"", "" x86: Use emit_nops to replace memcpy x86_nops\n  selftests/bpf: Test gotol with large offsets\n  selftests/bpf: Double the size of test_loader log\n  s390/bpf: Fix gotol with large offsets\n  bpfilter: remove bpfilter\n  bpf: Remove unnecessary cpu == 0 check in memalloc\n  selftests/bpf: add __arg_ctx BTF rewrite test\n  selftests/bpf: add arg:ctx cases to test_global_funcs tests\n  libbpf: implement __arg_ctx fallback logic\n  libbpf: move BTF loading step after relocation step\n  libbpf: move exception callbacks assignment logic into relocation step\n  libbpf: use stable map placeholder FDs\n  libbpf: don't rely on map->fd as an indicator of map being created\n  libbpf: use explicit map reuse flag to skip map creation steps\n  libbpf: make uniform use of btf__fd() accessor inside libbpf\n  selftests/bpf: Add a selftest with > 512-byte percpu allocation size\n  ...\n====================\n\nLink: https://lore.kernel.org/r/20240105170105.21070-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n"", '']",Merged 'bpf-next' changes with 73 files affected and 1526 insertions.,"merge, bpf-next, changes",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5fe4ee6ae187523f710f1b93024437a073d88b17,5fe4ee6ae187523f710f1b93024437a073d88b17,Alexei Starovoitov,ast@kernel.org,1704429094,Alexei Starovoitov,ast@kernel.org,1704429654,0597b83407e92f101be92851c0b2e0eb5181b045,00bc8988807985e32f5103f1ac099baf593bd8a3 e02feb3f1f47509ec1e07b604bfbeff8c3b4e639,"Merge branch 'relax-tracing-prog-recursive-attach-rules'

Dmitrii Dolgov says:

====================
Relax tracing prog recursive attach rules

Currently"," it's not allowed to attach an fentry/fexit prog to another
fentry/fexit. At the same time it's not uncommon to see a tracing
program with lots of logic in use","[' and the attachment limitation\nprevents usage of fentry/fexit for performance analysis (e.g. with\n""bpftool prog profile"" command) in this case. An example could be\nfalcosecurity libs project that uses tp_btf tracing programs for\noffloading certain part of logic into tail-called programs', ' but the\nuse-case is still generic enough -- a tracing program could be\ncomplicated and heavy enough to warrant its profiling', "" yet frustratingly\nit's not possible to do so use best tooling for that.\n\nFollowing the corresponding discussion [1]"", ' the reason for that is to\navoid tracing progs call cycles without introducing more complex\nsolutions. But currently it seems impossible to load and attach tracing\nprograms in a way that will form such a cycle. Replace ""no same type""\nrequirement with verification that no more than one level of attachment\nnesting is allowed. In this way only one fentry/fexit program could be\nattached to another fentry/fexit to cover profiling use case', ' and still\nno cycle could be formed.\n\nThe series contains a test for recursive attachment', ' as well as a fix +\ntest for an issue in re-attachment branch of bpf_tracing_prog_attach.\nWhen preparing the test for the main change set', "" I've stumbled upon the\npossibility to construct a sequence of events when attach_btf would be\nNULL while computing a trampoline key. It doesn't look like this issue\nis triggered by the main change"", "" because the reproduces doesn't actually\nneed to have an fentry attachment chain.\n\n[1]: https://lore.kernel.org/bpf/20191108064039.2041889-16-ast@kernel.org/\n====================\n\nLink: https://lore.kernel.org/r/20240103190559.14750-1-9erthalion6@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",This commit relaxes the rules for recursively attaching fentry/fexit tracing programs.,tracing recursive rules,It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['tracepoints like programs', 'kprobe/uprobe/ftrace like programs']"
e02feb3f1f47509ec1e07b604bfbeff8c3b4e639,e02feb3f1f47509ec1e07b604bfbeff8c3b4e639,Dmitrii Dolgov,9erthalion6@gmail.com,1704308747,Alexei Starovoitov,ast@kernel.org,1704429649,0597b83407e92f101be92851c0b2e0eb5181b045,715d82ba636cb3629a6e18a33bb9dbe53f9936ee,"selftests/bpf: Test re-attachment fix for bpf_tracing_prog_attach

Add a test case to verify the fix for ""prog->aux->dst_trampoline and
tgt_prog is NULL"" branch in bpf_tracing_prog_attach. The sequence of
events:

1. load rawtp program
2. load fentry program with rawtp as target_fd
3. create tracing link for fentry program with target_fd = 0
4. repeat 3

Acked-by: Jiri Olsa <olsajiri@gmail.com>
Acked-by: Song Liu <song@kernel.org>
Signed-off-by: Dmitrii Dolgov <9erthalion6@gmail.com>
Link: https://lore.kernel.org/r/20240103190559.14750-5-9erthalion6@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add a test case to verify the fix for re-attachment in bpf_tracing_prog_attach.,"test case, re-attachment, bpf_tracing_prog_attach",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['tracepoints like programs', 'kprobe/uprobe/ftrace like programs']"
715d82ba636cb3629a6e18a33bb9dbe53f9936ee,715d82ba636cb3629a6e18a33bb9dbe53f9936ee,Jiri Olsa,olsajiri@gmail.com,1704308746,Alexei Starovoitov,ast@kernel.org,1704429619,c164ed8ec5abb70af2adb3809e49542232ba26c6,5c5371e069e1ffc204dda8b20c609b170b823165,"bpf: Fix re-attachment branch in bpf_tracing_prog_attach

The following case can cause a crash due to missing attach_btf:

1) load rawtp program
2) load fentry program with rawtp as target_fd
3) create tracing link for fentry program with target_fd = 0
4) repeat 3

In the end we have:

- prog->aux->dst_trampoline == NULL
- tgt_prog == NULL (because we did not provide target_fd to link_create)
- prog->aux->attach_btf == NULL (the program was loaded with attach_prog_fd=X)
- the program was loaded for tgt_prog but we have no way to find out which one

    BUG: kernel NULL pointer dereference"," address: 0000000000000058
    Call Trace:
     <TASK>
     ? __die+0x20/0x70
     ? page_fault_oops+0x15b/0x430
     ? fixup_exception+0x22/0x330
     ? exc_page_fault+0x6f/0x170
     ? asm_exc_page_fault+0x22/0x30
     ? bpf_tracing_prog_attach+0x279/0x560
     ? btf_obj_id+0x5/0x10
     bpf_tracing_prog_attach+0x439/0x560
     __sys_bpf+0x1cf4/0x2de0
     __x64_sys_bpf+0x1c/0x30
     do_syscall_64+0x41/0xf0
     entry_SYSCALL_64_after_hwframe+0x6e/0x76

Return -EINVAL in this situation.

Fixes: f3a95075549e0 (""bpf: Allow trampoline re-attach for tracing and lsm programs"")
Cc: stable@vger.kernel.org
Signed-off-by: Jiri Olsa <olsajiri@gmail.com>
Acked-by: Jiri Olsa <olsajiri@gmail.com>
Acked-by: Song Liu <song@kernel.org>
Signed-off-by: Dmitrii Dolgov <9erthalion6@gmail.com>
Link: https://lore.kernel.org/r/20240103190559.14750-4-9erthalion6@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Fix crash due to missing attach_btf in bpf_tracing_prog_attach when re-attaching fentry programs.,"crash, attach_btf, bpf_tracing",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['tracepoints like programs', 'kprobe/uprobe/ftrace like programs']"
5c5371e069e1ffc204dda8b20c609b170b823165,5c5371e069e1ffc204dda8b20c609b170b823165,Dmitrii Dolgov,9erthalion6@gmail.com,1704308745,Alexei Starovoitov,ast@kernel.org,1704429614,9c069886df0b11d18f024da451c384615b2f1200,19bfcdf9498aa968ea293417fbbc39e523527ca8,"selftests/bpf: Add test for recursive attachment of tracing progs

Verify the fact that only one fentry prog could be attached to another
fentry"," building up an attachment chain of limited size. Use existing
bpf_testmod as a start of the chain.

Acked-by: Jiri Olsa <olsajiri@gmail.com>
Acked-by: Song Liu <song@kernel.org>
Signed-off-by: Dmitrii Dolgov <9erthalion6@gmail.com>
Link: https://lore.kernel.org/r/20240103190559.14750-3-9erthalion6@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Added a test case for recursive attachment of tracing programs in eBPF selftests.,"selftests,bpf,tracing",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tracepoints like programs']
19bfcdf9498aa968ea293417fbbc39e523527ca8,19bfcdf9498aa968ea293417fbbc39e523527ca8,Dmitrii Dolgov,9erthalion6@gmail.com,1704308744,Alexei Starovoitov,ast@kernel.org,1704429094,b6f41738ec49d90299a77b1eab8fea793cf04dfd,00bc8988807985e32f5103f1ac099baf593bd8a3,"bpf: Relax tracing prog recursive attach rules

Currently"," it's not allowed to attach an fentry/fexit prog to another
one fentry/fexit. At the same time it's not uncommon to see a tracing
program with lots of logic in use","[' and the attachment limitation\nprevents usage of fentry/fexit for performance analysis (e.g. with\n""bpftool prog profile"" command) in this case. An example could be\nfalcosecurity libs project that uses tp_btf tracing programs.\n\nFollowing the corresponding discussion [1]', ' the reason for that is to\navoid tracing progs call cycles without introducing more complex\nsolutions. But currently it seems impossible to load and attach tracing\nprograms in a way that will form such a cycle. The limitation is coming\nfrom the fact that attach_prog_fd is specified at the prog load (thus\nmaking it impossible to attach to a program loaded after it in this\nway)', ' as well as tracing progs not implementing link_detach.\n\nReplace ""no same type"" requirement with verification that no more than\none level of attachment nesting is allowed. In this way only one\nfentry/fexit program could be attached to another fentry/fexit to cover\nprofiling use case', ' and still no cycle could be formed. To implement', '\nadd a new field into bpf_prog_aux to track nested attachment for tracing\nprograms.\n\n[1]: https://lore.kernel.org/bpf/20191108064039.2041889-16-ast@kernel.org/\n\nAcked-by: Jiri Olsa <olsajiri@gmail.com>\nAcked-by: Song Liu <song@kernel.org>\nSigned-off-by: Dmitrii Dolgov <9erthalion6@gmail.com>\nLink: https://lore.kernel.org/r/20240103190559.14750-2-9erthalion6@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit relaxes restrictions on attaching tracing programs like fentry/fexit to allow recursive attachment.,"tracing, recursive, attach",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['tracepoints like programs', 'kprobe/uprobe/ftrace like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
00bc8988807985e32f5103f1ac099baf593bd8a3,00bc8988807985e32f5103f1ac099baf593bd8a3,Leon Hwang,hffilwlqm@gmail.com,1704378143,Alexei Starovoitov,ast@kernel.org,1704428530,d649b54630cb71b10e84e48ebb281a36a0253ac0,61a40c12496a763fdb95edc08d59f816a594a87a,bpf," x86: Use emit_nops to replace memcpy x86_nops

Move emit_nops() before emit_prologue() and replace
memcpy(prog","[' x86_nops[5]', ' X86_PATCH_SIZE) with emit_nops(&prog', ' X86_PATCH_SIZE).\n\nSigned-off-by: Leon Hwang <hffilwlqm@gmail.com>\nLink: https://lore.kernel.org/r/20240104142226.87869-2-hffilwlqm@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Optimize x86 nop insertion by moving emit_nops() before emit_prologue() and replacing memcpy usage.,"x86,emit_nops,optimization",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
61a40c12496a763fdb95edc08d59f816a594a87a,61a40c12496a763fdb95edc08d59f816a594a87a,Alexei Starovoitov,ast@kernel.org,1704396940,Alexei Starovoitov,ast@kernel.org,1704407845,7269325aad0d4d47fab766b3f8dcfc07cfa8f0a5,98e20e5e13d2811898921f999288be7151a11954 63fac34669e4cc666f943173ed2aa76b8db999f0,"Merge branch 's390-bpf-fix-gotol-with-large-offsets'

Ilya Leoshkevich says:

====================
s390/bpf: Fix gotol with large offsets

Hi","

While looking at a pyperf180 failure on s390x (must be related to [1]","[""\nI'm not done with the investigation yet) I noticed that I have\nunfortunately messed up the gotol implementation. Patch 1 is the fix"", '\npatch 2 is a small test infrastructure tweak', ' and patch 3 adds a\ntest.\n\n[1] https://github.com/llvm/llvm-project/issues/55669\n\nBest regards', '\nIlya\n====================\n\nLink: https://lore.kernel.org/r/20240102193531.3169422-1-iii@linux.ibm.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix for BPF gotol instruction handling on s390 architecture with large offsets.,"s390,bpf,gotol",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
63fac34669e4cc666f943173ed2aa76b8db999f0,63fac34669e4cc666f943173ed2aa76b8db999f0,Ilya Leoshkevich,iii@linux.ibm.com,1704223837,Alexei Starovoitov,ast@kernel.org,1704407845,7269325aad0d4d47fab766b3f8dcfc07cfa8f0a5,445aea5afda4759c13dc5c492b309cc1d5c1c486,"selftests/bpf: Test gotol with large offsets

Test gotol with offsets that don't fit into a short (i.e."," larger than
32k or smaller than -32k).

Signed-off-by: Ilya Leoshkevich <iii@linux.ibm.com>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/r/20240102193531.3169422-4-iii@linux.ibm.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],This commit adds tests for gotol instruction with large offsets exceeding 32k in BPF selftests.,"gotol, offsets, selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
445aea5afda4759c13dc5c492b309cc1d5c1c486,445aea5afda4759c13dc5c492b309cc1d5c1c486,Ilya Leoshkevich,iii@linux.ibm.com,1704223836,Alexei Starovoitov,ast@kernel.org,1704407735,a8eaf31cb3a84b7da0454d32837dec0775d18645,ecba66cb36e3428e9f0c2362b45e213ad43ba8d0,"selftests/bpf: Double the size of test_loader log

Testing long jumps requires having >32k instructions. That many
instructions require the verifier log buffer of 2 megabytes.

The regular test_progs run doesn't need an increased buffer"," since
gotol test with 40k instructions doesn't request a log","['\nbut test_progs -v will set the verifier log level.\nHence to avoid breaking gotol test with -v increase the buffer size.\n\nSigned-off-by: Ilya Leoshkevich <iii@linux.ibm.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nLink: https://lore.kernel.org/r/20240102193531.3169422-3-iii@linux.ibm.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Increase the test_loader log size for selftests involving >32k instructions.,selftests log size,It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ecba66cb36e3428e9f0c2362b45e213ad43ba8d0,ecba66cb36e3428e9f0c2362b45e213ad43ba8d0,Ilya Leoshkevich,iii@linux.ibm.com,1704223835,Alexei Starovoitov,ast@kernel.org,1704396940,27f069acb175e293df7874bfd48b73011ca38a3f,98e20e5e13d2811898921f999288be7151a11954,"s390/bpf: Fix gotol with large offsets

The gotol implementation uses a wrong data type for the offset: it
should be s32"," not s16.

Fixes: c690191e23d8 (""s390/bpf: Implement unconditional jump with 32-bit offset"")
Signed-off-by: Ilya Leoshkevich <iii@linux.ibm.com>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/r/20240102193531.3169422-2-iii@linux.ibm.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The commit fixes the offset data type for gotol implementation in s390 architecture of BPF.,"gotol,offset,s390",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
98e20e5e13d2811898921f999288be7151a11954,98e20e5e13d2811898921f999288be7151a11954,Quentin Deslandes,qde@naccy.de,1703596062,Alexei Starovoitov,ast@kernel.org,1704392590,194da196f85df00ebcc907347627265ea1fa2d72,9ddf872b47e3ac8f27dbfc4a4737a976c7588de6,"bpfilter: remove bpfilter

bpfilter was supposed to convert iptables filtering rules into
BPF programs on the fly", from the kernel,"[' through a usermode\nhelper. The base code for the UMH was introduced in 2018', ' and\ncouple of attempts (2', ' 3) tried to introduce the BPF program\ngenerate features but were abandoned.\n\nbpfilter now sits in a kernel tree unused and unusable', ' occasionally\ncausing confusion amongst Linux users (4', ' 5).\n\nAs bpfilter is now developed in a dedicated repository on GitHub (6)', '\nit was suggested a couple of times this year (LSFMM/BPF 2023', '\nLPC 2023) to remove the deprecated kernel part of the project. This\nis the purpose of this patch.\n\n[1]: https://lore.kernel.org/lkml/20180522022230.2492505-1-ast@kernel.org/\n[2]: https://lore.kernel.org/bpf/20210829183608.2297877-1-me@ubique.spb.ru/#t\n[3]: https://lore.kernel.org/lkml/20221224000402.476079-1-qde@naccy.de/\n[4]: https://dxuuu.xyz/bpfilter.html\n[5]: https://github.com/linuxkit/linuxkit/pull/3904\n[6]: https://github.com/facebook/bpfilter\n\nSigned-off-by: Quentin Deslandes <qde@naccy.de>\nLink: https://lore.kernel.org/r/20231226130745.465988-1-qde@naccy.de\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Remove bpfilter module responsible for converting iptables rules into BPF programs.,"bpfilter, iptables, removal",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tc/netfilter like programs']
9ddf872b47e3ac8f27dbfc4a4737a976c7588de6,9ddf872b47e3ac8f27dbfc4a4737a976c7588de6,Yonghong Song,yonghong.song@linux.dev,1704387464,Alexei Starovoitov,ast@kernel.org,1704392294,3cbc51ba9cbb22d6bcb1deb127146fadf31c260e,c040e902b07e946ff73e81d4abb4347d2c0b6044,"bpf: Remove unnecessary cpu == 0 check in memalloc

After merging the patch set [1] to reduce memory usage
for bpf_global_percpu_ma"," Alexei found a redundant check (cpu == 0)
in function bpf_mem_alloc_percpu_unit_init() ([2]).
Indeed","[' the check is unnecessary since c->unit_size will\nbe all NULL or all non-NULL for all cpus before\nfor_each_possible_cpu() loop.\nRemoving the check makes code less confusing.\n\n  [1] https://lore.kernel.org/all/20231222031729.1287957-1-yonghong.song@linux.dev/\n  [2] https://lore.kernel.org/all/20231222031745.1289082-1-yonghong.song@linux.dev/\n\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20240104165744.702239-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Removed an unnecessary cpu check in bpf_mem_alloc_percpu_unit_init function.,"cpu, check, memalloc",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c312828c37a72fe2d033a961c47c227b0767e9f8,c312828c37a72fe2d033a961c47c227b0767e9f8,Andrea Righi,andrea.righi@canonical.com,1703836156,Greg Kroah-Hartman,gregkh@linuxfoundation.org,1704384795,7fd234070dac3a103b59bab0b39e5ed709a418e8,93ec4a3b76404bce01bd5c9032bef5df6feb1d62,"kernfs: convert kernfs_idr_lock to an irq safe raw spinlock

bpf_cgroup_from_id() is basically a wrapper to cgroup_get_from_id()","
that is relying on kernfs to determine the right cgroup associated to
the target id.

As a kfunc","[' it has the potential to be attached to any function through\nBPF', ' particularly in contexts where certain locks are held.\n\nHowever', ' kernfs is not using an irq safe spinlock for kernfs_idr_lock', '\nthat means any kernfs function that is acquiring this lock can be\ninterrupted and potentially hit bpf_cgroup_from_id() in the process', '\ntriggering a deadlock.\n\nFor example', ' it is really easy to trigger a lockdep splat between\nkernfs_idr_lock and rq->_lock', ' attaching a small BPF program to\n__set_cpus_allowed_ptr_locked() that just calls bpf_cgroup_from_id():\n\n =====================================================\n WARNING: HARDIRQ-safe -> HARDIRQ-unsafe lock order detected\n 6.7.0-rc7-virtme #5 Not tainted\n -----------------------------------------------------\n repro/131 [HC0[0]:SC0[0]:HE0:SE1] is trying to acquire:\n ffffffffb2dc4578 (kernfs_idr_lock){+.+.}-{2:2}', ' at: kernfs_find_and_get_node_by_id+0x1d/0x80\n\n and this task is already holding:\n ffff911cbecaf218 (&rq->__lock){-.-.}-{2:2}', ' at: task_rq_lock+0x50/0xc0\n which would create a new lock dependency:\n  (&rq->__lock){-.-.}-{2:2} -> (kernfs_idr_lock){+.+.}-{2:2}\n\n but this new dependency connects a HARDIRQ-irq-safe lock:\n  (&rq->__lock){-.-.}-{2:2}\n\n ... which became HARDIRQ-irq-safe at:\n   lock_acquire+0xbf/0x2b0\n   _raw_spin_lock_nested+0x2e/0x40\n   scheduler_tick+0x5d/0x170\n   update_process_times+0x9c/0xb0\n   tick_periodic+0x27/0xe0\n   tick_handle_periodic+0x24/0x70\n   __sysvec_apic_timer_interrupt+0x64/0x1a0\n   sysvec_apic_timer_interrupt+0x6f/0x80\n   asm_sysvec_apic_timer_interrupt+0x1a/0x20\n   memcpy+0xc/0x20\n   arch_dup_task_struct+0x15/0x30\n   copy_process+0x1ce/0x1eb0\n   kernel_clone+0xac/0x390\n   kernel_thread+0x6f/0xa0\n   kthreadd+0x199/0x230\n   ret_from_fork+0x31/0x50\n   ret_from_fork_asm+0x1b/0x30\n\n to a HARDIRQ-irq-unsafe lock:\n  (kernfs_idr_lock){+.+.}-{2:2}\n\n ... which became HARDIRQ-irq-unsafe at:\n ...\n   lock_acquire+0xbf/0x2b0\n   _raw_spin_lock+0x30/0x40\n   __kernfs_new_node.isra.0+0x83/0x280\n   kernfs_create_root+0xf6/0x1d0\n   sysfs_init+0x1b/0x70\n   mnt_init+0xd9/0x2a0\n   vfs_caches_init+0xcf/0xe0\n   start_kernel+0x58a/0x6a0\n   x86_64_start_reservations+0x18/0x30\n   x86_64_start_kernel+0xc5/0xe0\n   secondary_startup_64_no_verify+0x178/0x17b\n\n other info that might help us debug this:\n\n  Possible interrupt unsafe locking scenario:\n\n        CPU0                    CPU1\n        ----                    ----\n   lock(kernfs_idr_lock);\n                                local_irq_disable();\n                                lock(&rq->__lock);\n                                lock(kernfs_idr_lock);\n   <Interrupt>\n     lock(&rq->__lock);\n\n  *** DEADLOCK ***\n\nPrevent this deadlock condition converting kernfs_idr_lock to a raw irq\nsafe spinlock.\n\nThe performance impact of this change should be negligible and it also\nhelps to prevent similar deadlock conditions with any other subsystems\nthat may depend on kernfs.\n\nFixes: 332ea1f697be (""bpf: Add bpf_cgroup_from_id() kfunc"")\nCc: stable <stable@kernel.org>\nSigned-off-by: Andrea Righi <andrea.righi@canonical.com>\nAcked-by: Tejun Heo <tj@kernel.org>\nLink: https://lore.kernel.org/r/20231229074916.53547-1-andrea.righi@canonical.com\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>\n', '']",Convert kernfs_idr_lock to irq safe raw spinlock for bpf_cgroup_from_id function.,"kernfs, irq, spinlock",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['cgroup like programs']
c040e902b07e946ff73e81d4abb4347d2c0b6044,c040e902b07e946ff73e81d4abb4347d2c0b6044,Alexei Starovoitov,ast@kernel.org,1704345770,Alexei Starovoitov,ast@kernel.org,1704346689,60b32e18321347e5c34c7cf03ac24aa8d3650b68,f8506c5734902ebda5c7b4778859b46d0a2ae5f3 95226f5a36695fd5740e130016d9ed697cfb2bad,"Merge branch 'libbpf-side-__arg_ctx-fallback-support'

Andrii Nakryiko says:

====================
Libbpf-side __arg_ctx fallback support

Support __arg_ctx global function argument tag semantics even on older kernels
that don't natively support it through btf_decl_tag(""arg:ctx"").

Patches #2-#6 are preparatory work to allow to postpone BTF loading into the
kernel until after all the BPF program relocations (including global func
appending to main programs) are done. Patch #4 is perhaps the most important
and establishes pre-created stable placeholder FDs"," so that relocations can
embed valid map FDs into ldimm64 instructions.

Once BTF is done after relocation","["" what's left is to adjust BTF information to\nhave each main program's copy of each used global subprog to point to its own\nadjusted FUNC -> FUNC_PROTO type chain (if they use __arg_ctx) in such a way\nas to satisfy type expectations of BPF verifier regarding the PTR_TO_CTX\nargument definition. See patch #8 for details.\n\nPatch #8 adds few more __arg_ctx use cases (edge cases like multiple arguments\nhaving __arg_ctx"", ' etc) to test_global_func_ctx_args.c', ' to make it simple to\nvalidate that this logic indeed works on old kernels. It does. But just to be\n100% sure patch #9 adds a test validating that libbpf uploads func_info with\nproperly modified BTF data.\n\nv2->v3:\n  - drop renaming patch (Alexei', ' Eduard);\n  - use memfd_create() instead of /dev/null for placeholder FD (Eduard);\n  - add one more test for validating BTF rewrite logic (Eduard);\n  - fixed wrong -errno usage', ' reshuffled some BTF rewrite bits (Eduard);\nv1->v2:\n  - do internal functions renaming in patch #1 (Alexei);\n  - extract cloning of FUNC -> FUNC_PROTO information into separate function\n    (Alexei);\n====================\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20240104013847.3875810-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit merges support for __arg_ctx fallback in libbpf to older kernels without native support.,"libbpf, __arg_ctx, BTF",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
95226f5a36695fd5740e130016d9ed697cfb2bad,95226f5a36695fd5740e130016d9ed697cfb2bad,Andrii Nakryiko,andrii@kernel.org,1704332327,Alexei Starovoitov,ast@kernel.org,1704345769,60b32e18321347e5c34c7cf03ac24aa8d3650b68,67fe459144dd629855bd9fb4b12bd9c4f792a8cf,"selftests/bpf: add __arg_ctx BTF rewrite test

Add a test validating that libbpf uploads BTF and func_info with
rewritten type information for arguments of global subprogs that are
marked with __arg_ctx tag.

Suggested-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240104013847.3875810-10-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add a selftest to validate BTF and func_info type rewriting for global subprograms with __arg_ctx tag.,"selftests,bpf,BTF",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
67fe459144dd629855bd9fb4b12bd9c4f792a8cf,67fe459144dd629855bd9fb4b12bd9c4f792a8cf,Andrii Nakryiko,andrii@kernel.org,1704332326,Alexei Starovoitov,ast@kernel.org,1704345769,2b5cc2eb9763c03f430888445f6bdc77f113e349,2f38fe689470055440bf80fc644920023a643a82,"selftests/bpf: add arg:ctx cases to test_global_funcs tests

Add a few extra cases of global funcs with context arguments. This time
rely on ""arg:ctx"" decl_tag (__arg_ctx macro)"," but put it next to
""classic"" cases where context argument has to be of an exact type that
BPF verifier expects (e.g.","[' bpf_user_pt_regs_t for kprobe/uprobe).\n\nColocating all these cases separately from other global func args that\nrely on arg:xxx decl tags (in verifier_global_subprogs.c) allows for\nsimpler backwards compatibility testing on old kernels. All the cases in\ntest_global_func_ctx_args.c are supposed to work on older kernels', ' which\nwas manually validated during development.\n\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240104013847.3875810-9-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']","Add test cases for global functions with context arguments using ""arg:ctx"" macro in BPF selftests.","test cases, global funcs, context arguments",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2f38fe689470055440bf80fc644920023a643a82,2f38fe689470055440bf80fc644920023a643a82,Andrii Nakryiko,andrii@kernel.org,1704332325,Alexei Starovoitov,ast@kernel.org,1704345769,01d770885ccc081748e36076f3b70b868d5e5632,1004742d7ff03a088e74133af2401556ac80092b,"libbpf: implement __arg_ctx fallback logic

Out of all special global func arg tag annotations"," __arg_ctx is
practically is the most immediately useful and most critical to have
working across multitude kernel version","[' if possible. This would allow\nend users to write much simpler code if __arg_ctx semantics worked for\nolder kernels that don\'t natively understand btf_decl_tag(""arg:ctx"") in\nverifier logic.\n\nLuckily', ' it is possible to ensure __arg_ctx works on old kernels through\na bit of extra work done by libbpf', ' at least in a lot of common cases.\n\nTo explain the overall idea', ' we need to go back at how context argument\nwas supported in global funcs before __arg_ctx support was added. This\nwas done based on special struct name checks in kernel. E.g.', ' for\nBPF_PROG_TYPE_PERF_EVENT the expectation is that argument type `struct\nbpf_perf_event_data *` mark that argument as PTR_TO_CTX. This is all\ngood as long as global function is used from the same BPF program types\nonly', ' which is often not the case. If the same subprog has to be called\nfrom', ' say', ' kprobe and perf_event program types', ' there is no single\ndefinition that would satisfy BPF verifier. Subprog will have context\nargument either for kprobe (if using bpf_user_pt_regs_t struct name) or\nperf_event (with bpf_perf_event_data struct name)', ' but not both.\n\nThis limitation was the reason to add btf_decl_tag(""arg:ctx"")', ' making\nthe actual argument type not important', ' so that user can just define\n""generic"" signature:\n\n  __noinline int global_subprog(void *ctx __arg_ctx) { ... }\n\nI won\'t belabor how libbpf is implementing subprograms', "" see a huge\ncomment next to bpf_object_relocate_calls() function. The idea is that\neach main/entry BPF program gets its own copy of global_subprog's code\nappended.\n\nThis per-program copy of global subprog code *and* associated func_info\n.BTF.ext information"", ' pointing to FUNC -> FUNC_PROTO BTF type chain\nallows libbpf to simulate __arg_ctx behavior transparently', "" even if the\nkernel doesn't yet support __arg_ctx annotation natively.\n\nThe idea is straightforward: each time we append global subprog's code\nand func_info information"", ' we adjust its FUNC -> FUNC_PROTO type\ninformation', ' if necessary (that is', ' libbpf can detect the presence of\nbtf_decl_tag(""arg:ctx"") just like BPF verifier would do it).\n\nThe rest is just mechanical and somewhat painful BTF manipulation code.\nIt\'s painful because we need to clone FUNC -> FUNC_PROTO', ' instead of\nreusing it', ' as same FUNC -> FUNC_PROTO chain might be used by another\nmain BPF program within the same BPF object', "" so we can't just modify it\nin-place (and cloning BTF types within the same struct btf object is\npainful due to constant memory invalidation"", "" see comments in code).\nUploaded BPF object's BTF information has to work for all BPF\nprograms at the same time.\n\nOnce we have FUNC -> FUNC_PROTO clones"", ' we make sure that instead of\nusing some `void *ctx` parameter definition', ' we have an expected `struct\nbpf_perf_event_data *ctx` definition (as far as BPF verifier and kernel\nis concerned)', "" which will mark it as context for BPF verifier. Same\nglobal subprog relocated and copied into another main BPF program will\nget different type information according to main program's type. It all\nworks out in the end in a completely transparent way for end user.\n\nLibbpf maintains internal program type -> expected context struct name\nmapping internally. Note"", ' not all BPF program types have named context\nstruct', "" so this approach won't work for such programs (just like it\ndidn't before __arg_ctx). So native __arg_ctx is still important to have\nin kernel to have generic context support across all BPF program types.\n\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240104013847.3875810-8-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Implement __arg_ctx fallback logic in libbpf to ensure compatibility across various kernel versions.,"libbpf, __arg_ctx, fallback",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1004742d7ff03a088e74133af2401556ac80092b,1004742d7ff03a088e74133af2401556ac80092b,Andrii Nakryiko,andrii@kernel.org,1704332324,Alexei Starovoitov,ast@kernel.org,1704345769,5d133fc7e5e29a75f513ad0169f2ec7ff9743561,fb03be7c4a27c25696287df4ee06c5aafa31267c,"libbpf: move BTF loading step after relocation step

With all the preparations in previous patches done we are ready to
postpone BTF loading and sanitization step until after all the
relocations are performed.

Acked-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240104013847.3875810-7-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Postpone BTF loading until after relocations in libbpf.,"BTF,relocation,libbpf",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fb03be7c4a27c25696287df4ee06c5aafa31267c,fb03be7c4a27c25696287df4ee06c5aafa31267c,Andrii Nakryiko,andrii@kernel.org,1704332323,Alexei Starovoitov,ast@kernel.org,1704345769,11cfbb2f44610b9064a7ae73502d571642bbf3b9,dac645b950ea4fc0896fe46a645365cb8d9ab92b,"libbpf: move exception callbacks assignment logic into relocation step

Move the logic of finding and assigning exception callback indices from
BTF sanitization step to program relocations step"," which seems more
logical and will unblock moving BTF loading to after relocation step.

Exception callbacks discovery and assignment has no dependency on BTF
being loaded into the kernel","[' it only uses BTF information. It does need\nto happen before subprogram relocations happen', ' though. Which is why the\nsplit.\n\nNo functional changes.\n\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240104013847.3875810-6-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Refactor the exception callbacks assignment logic from BTF sanitization to program relocations step in libbpf.,"libbpf, exception callbacks, relocation",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
dac645b950ea4fc0896fe46a645365cb8d9ab92b,dac645b950ea4fc0896fe46a645365cb8d9ab92b,Andrii Nakryiko,andrii@kernel.org,1704332322,Alexei Starovoitov,ast@kernel.org,1704345769,246b69d04cdbeaa2b277cfb0ecb855e61a13a847,f08c18e083adfef92946ae1d44b07bb81e727e08,"libbpf: use stable map placeholder FDs

Move map creation to later during BPF object loading by pre-creating
stable placeholder FDs (utilizing memfd_create()). Use dup2()
syscall to then atomically make those placeholder FDs point to real
kernel BPF map objects.

This change allows to delay BPF map creation to after all the BPF
program relocations. That", in turn,"["" allows to delay BTF finalization and\nloading into kernel to after all the relocations as well. We'll take\nadvantage of the latter in subsequent patches to allow libbpf to adjust\nBTF in a way that helps with BPF global function usage.\n\nClean up a few places where we close map->fd"", "" which now shouldn't\nhappen"", "" because map->fd should be a valid FD regardless of whether map\nwas created or not. Surprisingly and nicely it simplifies a bunch of\nerror handling code. If this change doesn't backfire"", "" I'm tempted to\npre-create such stable FDs for other entities (progs"", ' maybe even BTF).\nWe previously did some manipulations to make gen_loader work with fake\nmap FDs', ' with stable map FDs this hack is not necessary for maps (we\nstill have it for BTF', ' but I left it as is for now).\n\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240104013847.3875810-5-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit introduces stable map placeholder FDs for delayed BPF map creation in libbpf.,"libbpf,placeholder FDs,map creation",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f08c18e083adfef92946ae1d44b07bb81e727e08,f08c18e083adfef92946ae1d44b07bb81e727e08,Andrii Nakryiko,andrii@kernel.org,1704332321,Alexei Starovoitov,ast@kernel.org,1704345769,7b16972d9d1a08dfd503e61129548f672cce1846,fa98b54bff39f51c46fc96d3385c6292391c277b,"libbpf: don't rely on map->fd as an indicator of map being created

With the upcoming switch to preallocated placeholder FDs for maps","
switch various getters/setter away from checking map->fd. Use
map_is_created() helper that detect whether BPF map can be modified based
on map->obj->loaded state","[' with special provision for maps set up with\nbpf_map__reuse_fd().\n\nFor backwards compatibility', ' we take map_is_created() into account in\nbpf_map__fd() getter as well. This way before bpf_object__load() phase\nbpf_map__fd() will always return -1', ' just as before the changes in\nsubsequent patches adding stable map->fd placeholders.\n\nWe also get rid of all internal uses of bpf_map__fd() getter', "" as it's\nmore oriented for uses external to libbpf. The above map_is_created()\ncheck actually interferes with some of the internal uses"", ' if map FD is\nfetched through bpf_map__fd().\n\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20240104013847.3875810-4-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Switch libbpf to use map_is_created() instead of map->fd to detect map modification eligibility.,"libbpf,map,fd",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fa98b54bff39f51c46fc96d3385c6292391c277b,fa98b54bff39f51c46fc96d3385c6292391c277b,Andrii Nakryiko,andrii@kernel.org,1704332320,Alexei Starovoitov,ast@kernel.org,1704345769,e044d275ee39e66f4c4724a3f92476a08326082f,df7c3f7d3a3ddab31ca8cfa9b86a8729ec43fd2e,"libbpf: use explicit map reuse flag to skip map creation steps

Instead of inferring whether map already point to previously
created/pinned BPF map (which user can specify with bpf_map__reuse_fd()) API)","
use explicit map->reused flag that is set in such case.

Acked-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240104013847.3875810-3-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The commit introduces an explicit map reuse flag to simplify map creation in libbpf.,"explicit,map,reuse",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
df7c3f7d3a3ddab31ca8cfa9b86a8729ec43fd2e,df7c3f7d3a3ddab31ca8cfa9b86a8729ec43fd2e,Andrii Nakryiko,andrii@kernel.org,1704332319,Alexei Starovoitov,ast@kernel.org,1704345768,2384aefbdffa70db6527877f102e6aac2c7a5a4a,f8506c5734902ebda5c7b4778859b46d0a2ae5f3,"libbpf: make uniform use of btf__fd() accessor inside libbpf

It makes future grepping and code analysis a bit easier.

Acked-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20240104013847.3875810-2-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Standardize the use of btf__fd() accessor in libbpf for easier code maintenance.,"libbpf, btf__fd, accessor",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f8506c5734902ebda5c7b4778859b46d0a2ae5f3,f8506c5734902ebda5c7b4778859b46d0a2ae5f3,Alexei Starovoitov,ast@kernel.org,1704344906,Alexei Starovoitov,ast@kernel.org,1704344907,33e7bd54cb6f7ee386fa8abca5ab0ae9cea74d64,417fa6d163df6f13fb2cfad5132eff354c8a472e adc8c4549d9e74d2359c217d2478b18ecdd15c91,"Merge branch 'bpf-reduce-memory-usage-for-bpf_global_percpu_ma'

Yonghong Song says:

====================
bpf: Reduce memory usage for bpf_global_percpu_ma

Currently when a bpf program intends to allocate memory for percpu kptr","
the verifier will call bpf_mem_alloc_init() to prefill all supported
unit sizes and this caused memory consumption very big for large number
of cpus. For example","[' for 128-cpu system', ' the total memory consumption\nwith initial prefill is ~175MB. Things will become worse for systems\nwith even more cpus.\n\nPatch 1 avoids unnecessary extra percpu memory allocation.\nPatch 2 adds objcg to bpf_mem_alloc at init stage so objcg can be\nassociated with root cgroup and objcg can be passed to later\nbpf_mem_alloc_percpu_unit_init().\nPatch 3 addresses memory consumption issue by avoiding to prefill\nwith all unit sizes', ' i.e. only prefilling with user specified size.\nPatch 4 further reduces memory consumption by limiting the\nnumber of prefill entries for percpu memory allocation.\nPatch 5 has much smaller low/high watermarks for percpu allocation\nto reduce memory consumption.\nPatch 6 rejects percpu memory allocation with bpf_global_percpu_ma\nwhen allocation size is greater than 512 bytes.\nPatch 7 fixed test_bpf_ma test due to Patch 5.\nPatch 8 added one test to show the verification failure log message.\n\nChangelogs:\n  v5 -> v6:\n    . Change bpf_mem_alloc_percpu_init() to add objcg as one of parameters.\n      For bpf_global_percpu_ma', ' the objcg is NULL', ' corresponding root memcg.\n  v4 -> v5:\n    . Do not do bpf_global_percpu_ma initialization at init stage', "" instead\n      doing initialization when the verifier knows it is going to be used\n      by bpf prog.\n    . Using much smaller low/high watermarks for percpu allocation.\n  v3 -> v4:\n    . Add objcg to bpf_mem_alloc during init stage.\n    . Initialize objcg at init stage but use it in bpf_mem_alloc_percpu_unit_init().\n    . Remove check_obj_size() in bpf_mem_alloc_percpu_unit_init().\n  v2 -> v3:\n    . Clear the bpf_mem_cache if prefill fails.\n    . Change test_bpf_ma percpu allocation tests to use bucket_size\n      as allocation size instead of bucket_size - 8.\n    . Remove __GFP_ZERO flag from __alloc_percpu_gfp() call.\n  v1 -> v2:\n    . Avoid unnecessary extra percpu memory allocation.\n    . Add a separate function to do bpf_global_percpu_ma initialization\n    . promote.\n    . Promote function static 'sizes' array to file static.\n    . Add comments to explain to refill only one item for percpu alloc.\n====================\n\nLink: https://lore.kernel.org/r/20231222031729.1287957-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Optimize memory usage in bpf programs by adjusting bpf_global_percpu_ma behavior.,"bpf, memory, optimization",It's a performance optimization.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
adc8c4549d9e74d2359c217d2478b18ecdd15c91,adc8c4549d9e74d2359c217d2478b18ecdd15c91,Yonghong Song,yonghong.song@linux.dev,1703215092,Alexei Starovoitov,ast@kernel.org,1704344906,33e7bd54cb6f7ee386fa8abca5ab0ae9cea74d64,21f5a801c171dff4e728e38f62cf626c4197d07c,"selftests/bpf: Add a selftest with > 512-byte percpu allocation size

Add a selftest to capture the verification failure when the allocation
size is greater than 512.

Acked-by: Hou Tao <houtao1@huawei.com>
Signed-off-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20231222031812.1293190-1-yonghong.song@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,This commit adds a selftest for verification failure due to percpu allocation size exceeding 512 bytes.,"selftest, percpu, allocation",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
21f5a801c171dff4e728e38f62cf626c4197d07c,21f5a801c171dff4e728e38f62cf626c4197d07c,Yonghong Song,yonghong.song@linux.dev,1703215087,Alexei Starovoitov,ast@kernel.org,1704344906,876d4710deae0593e8aa7c6ad61b95295ddd3880,5c1a37653260ed5d9c8b26fb7fe7b99629612982,"selftests/bpf: Cope with 512 bytes limit with bpf_global_percpu_ma

In the previous patch"," the maximum data size for bpf_global_percpu_ma
is 512 bytes. This breaks selftest test_bpf_ma. The test is adjusted
in two aspects:
  - Since the maximum allowed data size for bpf_global_percpu_ma is
    512","[' remove all tests beyond that', ' names sizes 1024', ' 2048 and 4096.\n  - Previously the percpu data size is bucket_size - 8 in order to\n    avoid percpu allocation into the next bucket. This patch removed\n    such data size adjustment thanks to Patch 1.\n\nAlso', ' a better way to generate BTF type is used than adding\na member to the value struct.\n\nAcked-by: Hou Tao <houtao1@huawei.com>\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20231222031807.1292853-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Adjust selftests to accommodate 512-byte limit of bpf_global_percpu_ma.,"selftests, bpf_global_percpu_ma, limit",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['other']
5c1a37653260ed5d9c8b26fb7fe7b99629612982,5c1a37653260ed5d9c8b26fb7fe7b99629612982,Yonghong Song,yonghong.song@linux.dev,1703215081,Alexei Starovoitov,ast@kernel.org,1704344906,9cd3e4d1531ee6e46147d65ebc3dce1259409b15,0e2ba9f96f9b82893ba19170ae48d46003f8ef44,"bpf: Limit up to 512 bytes for bpf_global_percpu_ma allocation

For percpu data structure allocation with bpf_global_percpu_ma","
the maximum data size is 4K. But for a system with large
number of cpus","[' bigger data size (e.g.', ' 2K', ' 4K) might consume\na lot of memory. For example', ' the percpu memory consumption\nwith unit size 2K and 1024 cpus will be 2K * 1K * 1k = 2GB\nmemory.\n\nWe should discourage such usage. Let us limit the maximum data\nsize to be 512 for bpf_global_percpu_ma allocation.\n\nAcked-by: Hou Tao <houtao1@huawei.com>\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20231222031801.1290841-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit limits bpf_global_percpu_ma allocation size to 512 bytes for handling large CPU systems.,"bpf, percpu, allocation",It's a performance optimization.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0e2ba9f96f9b82893ba19170ae48d46003f8ef44,0e2ba9f96f9b82893ba19170ae48d46003f8ef44,Yonghong Song,yonghong.song@linux.dev,1703215075,Alexei Starovoitov,ast@kernel.org,1704344905,5b253ef511576f6cf1247fad149ecdd81401f5a0,5b95e638f134e552b5ba2976326c02babe248615,"bpf: Use smaller low/high marks for percpu allocation

Currently"," refill low/high marks are set with the assumption
of normal non-percpu memory allocation. For example","[' for\nan allocation size 256', ' for non-percpu memory allocation', '\nlow mark is 32 and high mark is 96', ' resulting in the\nbatch allocation of 48 elements and the allocated memory\nwill be 48 * 256 = 12KB for this particular cpu.\nAssuming an 128-cpu system', ' the total memory consumption\nacross all cpus will be 12K * 128 = 1.5MB memory.\n\nThis might be okay for non-percpu allocation', ' but may not be\ngood for percpu allocation', ' which will consume 1.5MB * 128 = 192MB\nmemory in the worst case if every cpu has a chance of memory\nallocation.\n\nIn practice', ' percpu allocation is very rare compared to\nnon-percpu allocation. So let us have smaller low/high marks\nwhich can avoid unnecessary memory consumption.\n\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nAcked-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20231222031755.1289671-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Adjust low and high marks for more efficient percpu memory allocation in BPF.,"BPF, percpu, allocation",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5b95e638f134e552b5ba2976326c02babe248615,5b95e638f134e552b5ba2976326c02babe248615,Yonghong Song,yonghong.song@linux.dev,1703215070,Alexei Starovoitov,ast@kernel.org,1704344905,ea6a83156f646dd70e550b31b67c441f008da0a6,c39aa3b289e9c10d0d246cd919b06809f13b72b8,"bpf: Refill only one percpu element in memalloc

Typically for percpu map element or data structure", once allocated,"['\nmost operations are lookup or in-place update. Deletion are really\nrare. Currently', ' for percpu data strcture', ' 4 elements will be\nrefilled if the size is <= 256. Let us just do with one element\nfor percpu data. For example', ' for size 256 and 128 cpus', ' the\npotential saving will be 3 * 256 * 128 * 128 = 12MB.\n\nAcked-by: Hou Tao <houtao1@huawei.com>\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20231222031750.1289290-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Optimize memory allocation by refilling only one percpu element in memalloc.,"bpf, percpu, memalloc",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c39aa3b289e9c10d0d246cd919b06809f13b72b8,c39aa3b289e9c10d0d246cd919b06809f13b72b8,Yonghong Song,yonghong.song@linux.dev,1703215065,Alexei Starovoitov,ast@kernel.org,1704344905,b819faee48f6f8860e5571af8f1a46c0b3a30257,9fc8e802048ad150e8032c4f3dbf40112160cfe9,"bpf: Allow per unit prefill for non-fix-size percpu memory allocator

Commit 41a5db8d8161 (""Add support for non-fix-size percpu mem allocation"")
added support for non-fix-size percpu memory allocation.
Such allocation will allocate percpu memory for all buckets on all
cpus and the memory consumption is in the order to quadratic.
For example", let us say,"[' 4 cpus', ' unit size 16 bytes', ' so each\ncpu has 16 * 4 = 64 bytes', ' with 4 cpus', ' total will be 64 * 4 = 256 bytes.\nThen let us say', ' 8 cpus with the same unit size', ' each cpu\nhas 16 * 8 = 128 bytes', ' with 8 cpus', ' total will be 128 * 8 = 1024 bytes.\nSo if the number of cpus doubles', ' the number of memory consumption\nwill be 4 times. So for a system with large number of cpus', ' the\nmemory consumption goes up quickly with quadratic order.\nFor example', ' for 4KB percpu allocation', ' 128 cpus. The total memory\nconsumption will 4KB * 128 * 128 = 64MB. Things will become\nworse if the number of cpus is bigger (e.g.', ' 512', ' 1024', ' etc.)\n\nIn Commit 41a5db8d8161', ' the non-fix-size percpu memory allocation is\ndone in boot time', ' so for system with large number of cpus', ' the initial\npercpu memory consumption is very visible. For example', ' for 128 cpu\nsystem', ' the total percpu memory allocation will be at least\n(16 + 32 + 64 + 96 + 128 + 196 + 256 + 512 + 1024 + 2048 + 4096)\n  * 128 * 128 = ~138MB.\nwhich is pretty big. It will be even bigger for larger number of cpus.\n\nNote that the current prefill also allocates 4 entries if the unit size\nis less than 256. So on top of 138MB memory consumption', ' this will\nadd more consumption with\n3 * (16 + 32 + 64 + 96 + 128 + 196 + 256) * 128 * 128 = ~38MB.\nNext patch will try to reduce this memory consumption.\n\nLater on', ' Commit 1fda5bb66ad8 (""bpf: Do not allocate percpu memory\nat init stage"") moved the non-fix-size percpu memory allocation\nto bpf verificaiton stage. Once a particular bpf_percpu_obj_new()\nis called by bpf program', ' the memory allocator will try to fill in\nthe cache with all sizes', ' causing the same amount of percpu memory\nconsumption as in the boot stage.\n\nTo reduce the initial percpu memory consumption for non-fix-size\npercpu memory allocation', ' instead of filling the cache with all\nsupported allocation sizes', ' this patch intends to fill the cache\nonly for the requested size. As typically users will not use large\npercpu data structure', ' this can save memory significantly.\nFor example', ' the allocation size is 64 bytes with 128 cpus.\nThen total percpu memory amount will be 64 * 128 * 128 = 1MB', '\nmuch less than previous 138MB.\n\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nAcked-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20231222031745.1289082-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit allows per-unit prefill for non-fixed-size percpu memory allocator to optimize memory usage.,"percpu,memory,allocator",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9fc8e802048ad150e8032c4f3dbf40112160cfe9,9fc8e802048ad150e8032c4f3dbf40112160cfe9,Yonghong Song,yonghong.song@linux.dev,1703215059,Alexei Starovoitov,ast@kernel.org,1704344905,a77e0d24b1ba2a4d53645bbed8a724e7f6145c45,9beda16c257d55213f70adee2f16d7f13a8502e1,"bpf: Add objcg to bpf_mem_alloc

The objcg is a bpf_mem_alloc level property since all bpf_mem_cache's
are with the same objcg. This patch made such a property explicit.
The next patch will use this property to save and restore objcg
for percpu unit allocator.

Acked-by: Hou Tao <houtao1@huawei.com>
Signed-off-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20231222031739.1288590-1-yonghong.song@linux.dev
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,This commit adds objcg as a property to bpf_mem_alloc to enhance its functionality.,"objcg,bpf_mem_alloc,property",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9beda16c257d55213f70adee2f16d7f13a8502e1,9beda16c257d55213f70adee2f16d7f13a8502e1,Yonghong Song,yonghong.song@linux.dev,1703215054,Alexei Starovoitov,ast@kernel.org,1704344905,808b110d7b573d9567de037bfad6783898857d6c,417fa6d163df6f13fb2cfad5132eff354c8a472e,"bpf: Avoid unnecessary extra percpu memory allocation

Currently", for percpu memory allocation,"[' say if the user\nrequests allocation size to be 32 bytes', ' the actually\ncalculated size will be 40 bytes and it further rounds\nto 64 bytes', ' and eventually 64 bytes are allocated', '\nwasting 32-byte memory.\n\nChange bpf_mem_alloc() to calculate the cache index\nbased on the user-provided allocation size so unnecessary\nextra memory can be avoided.\n\nSuggested-by: Hou Tao <houtao1@huawei.com>\nAcked-by: Hou Tao <houtao1@huawei.com>\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20231222031734.1288400-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Optimize bpf by preventing extra percpu memory allocation.,"bpf, percpu, memory",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
bdbca46d3f84a4455cd5c15a7483666218851549,bdbca46d3f84a4455cd5c15a7483666218851549,John Fastabend,john.fastabend@gmail.com,1703201007,Martin KaFai Lau,martin.lau@kernel.org,1704329422,d8a0d5f195e29edc68c8095a224b082f57ef2dfc,f1300467dd9f67293a7aae86fd26471520fac36d,bpf: sockmap," add tests for proto updates replace socket

Add test that replaces the same socket with itself. This exercises a
corner case where old element and new element have the same posck.
Test protocols: TCP","[' UDP', ' stream af_unix and dgram af_unix.\n\nSigned-off-by: John Fastabend <john.fastabend@gmail.com>\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nReviewed-by: Jakub Sitnicki <jakub@cloudflare.com>\nLink: https://lore.kernel.org/r/20231221232327.43678-6-john.fastabend@gmail.com\n', '']","Added tests to handle cases where a socket element is replaced with itself in sockmap, particularly focusing on TCP protocols.","sockmap, tests, TCP",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
f1300467dd9f67293a7aae86fd26471520fac36d,f1300467dd9f67293a7aae86fd26471520fac36d,John Fastabend,john.fastabend@gmail.com,1703201006,Martin KaFai Lau,martin.lau@kernel.org,1704329421,dac441fa7d18eb830409885d90bb0aed52789a1d,8c1b382a555adcd2008ae964047a35b739dfaf24,bpf: sockmap," add tests for proto updates single socket to many map

Add test with multiple maps where each socket is inserted in multiple
maps. Test protocols: TCP","[' UDP', ' stream af_unix and dgram af_unix.\n\nSigned-off-by: John Fastabend <john.fastabend@gmail.com>\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nReviewed-by: Jakub Sitnicki <jakub@cloudflare.com>\nLink: https://lore.kernel.org/r/20231221232327.43678-5-john.fastabend@gmail.com\n', '']",Add tests for handling multiple maps with single socket updates for TCP protocols.,"sockmap,TCP,multiple maps",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
8c1b382a555adcd2008ae964047a35b739dfaf24,8c1b382a555adcd2008ae964047a35b739dfaf24,John Fastabend,john.fastabend@gmail.com,1703201005,Martin KaFai Lau,martin.lau@kernel.org,1704329419,8f8dcf31c600ed2677b100f02a4953df5d528c60,7865dfb1eb941ddd25802a9e13b6ff5f3f4dc02f,bpf: sockmap," add tests for proto updates many to single map

Add test with a single map where each socket is inserted multiple
times. Test protocols: TCP","[' UDP', ' stream af_unix and dgram af_unix.\n\nSigned-off-by: John Fastabend <john.fastabend@gmail.com>\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nReviewed-by: Jakub Sitnicki <jakub@cloudflare.com>\nLink: https://lore.kernel.org/r/20231221232327.43678-4-john.fastabend@gmail.com\n', '']",Add test cases for TCP protocol updates using a single sockmap with multiple socket entries.,"test,TCP,sockmap",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
7865dfb1eb941ddd25802a9e13b6ff5f3f4dc02f,7865dfb1eb941ddd25802a9e13b6ff5f3f4dc02f,John Fastabend,john.fastabend@gmail.com,1703201004,Martin KaFai Lau,martin.lau@kernel.org,1704329416,80e1650f741a44c94e7ed22c15545aa603839b8f,16b2f264983dc264c1560cc0170e760dec1bf54f,bpf: sockmap," added comments describing update proto rules

Add a comment describing that the psock update proto callbback can be
called multiple times and this must be safe.

Signed-off-by: John Fastabend <john.fastabend@gmail.com>
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
Reviewed-by: Jakub Sitnicki <jakub@cloudflare.com>
Link: https://lore.kernel.org/r/20231221232327.43678-3-john.fastabend@gmail.com
",[''],Add comments in sockmap for psock update proto callback safety.,"sockmap, psock, comments",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF maps,['socket like programs']
16b2f264983dc264c1560cc0170e760dec1bf54f,16b2f264983dc264c1560cc0170e760dec1bf54f,John Fastabend,john.fastabend@gmail.com,1703201003,Martin KaFai Lau,martin.lau@kernel.org,1704329406,6193fe6512ba7c9095c01278510cefc390cd2e7f,b4560055c8f11c5e2cfffb4de928b3cfd4eae3b4,bpf: sockmap," fix proto update hook to avoid dup calls

When sockets are added to a sockmap or sockhash we allocate and init a
psock. Then update the proto ops with sock_map_init_proto the flow is

  sock_hash_update_common
    sock_map_link
      psock = sock_map_psock_get_checked() <-returns existing psock
      sock_map_init_proto(sk","[' psock)       <- updates sk_proto\n\nIf the socket is already in a map this results in the sock_map_init_proto\nbeing called multiple times on the same socket. We do this because when\na socket is added to multiple maps this might result in a new set of BPF\nprograms being attached to the socket requiring an updated ops struct.\n\nThis creates a rule where it must be safe to call psock_update_sk_prot\nmultiple times. When we added a fix for UAF through unix sockets in patch\n4dd9a38a753fc we broke this rule by adding a sock_hold in that path\nto ensure the sock is not released. The result is if a af_unix stream sock\nis placed in multiple maps it results in a memory leak because we call\nsock_hold multiple times with only a single sock_put on it.\n\nFixes: 8866730aed51 (""bpf', ' sockmap: af_unix stream sockets need to hold ref for pair sock"")\nReported-by: Xingwei Lee <xrivendell7@gmail.com>\nSigned-off-by: John Fastabend <john.fastabend@gmail.com>\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\nReviewed-by: Jakub Sitnicki <jakub@cloudflare.com>\nLink: https://lore.kernel.org/r/20231221232327.43678-2-john.fastabend@gmail.com\n', '']",Fixes proto update hook to prevent duplicate calls when adding sockets to sockmaps or sockhashes.,"proto update, sockmap, duplicate calls",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['socket like programs']
9c51f8788b5d4e9f46afbcf563255cfd355690b3,9c51f8788b5d4e9f46afbcf563255cfd355690b3,Ian Rogers,irogers@google.com,1701913615,Arnaldo Carvalho de Melo,acme@redhat.com,1704315294,573d20cc7b23f03374165ffd9f0c6597c4c7d1a8,58824fa0087e1cb732edbf1f112a5ea0b2205c8b,"perf env: Avoid recursively taking env->bpf_progs.lock

Add variants of perf_env__insert_bpf_prog_info()"," perf_env__insert_btf()
and perf_env__find_btf prefixed with __ to indicate the
env->bpf_progs.lock is assumed held.

Call these variants when the lock is held to avoid recursively taking it
and potentially having a thread deadlock with itself.

Fixes: f8dfeae009effc0b (""perf bpf: Show more BPF program info in print_bpf_prog_info()"")
Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Acked-by: Song Liu <song@kernel.org>
Cc: Adrian Hunter <adrian.hunter@intel.com>
Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Ingo Molnar <mingo@redhat.com>
Cc: K Prateek Nayak <kprateek.nayak@amd.com>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Ming Wang <wangming01@loongson.cn>
Cc: Namhyung Kim <namhyung@kernel.org>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Link: https://lore.kernel.org/r/20231207014655.1252484-1-irogers@google.com
Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
",[''],This commit addresses a potential deadlock issue in perf env by modifying lock usage when handling bpf prog information.,"perf, deadlock, lock",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b4560055c8f11c5e2cfffb4de928b3cfd4eae3b4,b4560055c8f11c5e2cfffb4de928b3cfd4eae3b4,Andrii Nakryiko,andrii@kernel.org,1704307282,Andrii Nakryiko,andrii@kernel.org,1704308904,0cd08e41ae266dee372fd04ba167791dbbf252ac,a640de4cf9fec0caf43ccb7404ec9f0fde9a6a65 7e3811cb998f0e2493677c7daf6cefb4ece27111,"Merge branch 'bpf-volatile-compare'

Alexei Starovoitov says:

====================
bpf: volatile compare

From: Alexei Starovoitov <ast@kernel.org>

v2->v3:
Debugged profiler.c regression. It was caused by basic block layout.
Introduce bpf_cmp_likely() and bpf_cmp_unlikely() macros.
Debugged redundant <<=32"," >>=32 with u32 variables. Added cast workaround.

v1->v2:
Fixed issues pointed out by Daniel","[' added more tests', ' attempted to convert profiler.c', '\nbut barrier_var() wins vs bpf_cmp(). To be investigated.\nPatches 1-4 are good to go', ' but 5 needs more work.\n====================\n\nLink: https://lore.kernel.org/r/20231226191148.48536-1-alexei.starovoitov@gmail.com\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n', '']",Introduce bpf_cmp_likely() and bpf_cmp_unlikely() macros for optimizing volatile comparisons in BPF programs.,"bpf,cmp,macros",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7e3811cb998f0e2493677c7daf6cefb4ece27111,7e3811cb998f0e2493677c7daf6cefb4ece27111,Alexei Starovoitov,ast@kernel.org,1703617908,Andrii Nakryiko,andrii@kernel.org,1704308903,0cd08e41ae266dee372fd04ba167791dbbf252ac,0bcc62aa9813f519db58df14ddf1d523fa971e62,"selftests/bpf: Convert profiler.c to bpf_cmp.

Convert profiler[123].c to ""volatile compare"" to compare barrier_var() approach vs bpf_cmp_likely() vs bpf_cmp_unlikely().

bpf_cmp_unlikely() produces correct code"," but takes much longer to verify:

./veristat -C -e prog","['insns', 'states before after_with_unlikely\nProgram                               Insns (A)  Insns (B)  Insns       (DIFF)  States (A)  States (B)  States     (DIFF)\n------------------------------------  ---------  ---------  ------------------  ----------  ----------  -----------------\nkprobe__proc_sys_write                     1603      19606  +18003 (+1123.08%)         123        1678  +1555 (+1264.23%)\nkprobe__vfs_link                          11815      70305   +58490 (+495.05%)         971        4967   +3996 (+411.53%)\nkprobe__vfs_symlink                        5464      42896   +37432 (+685.07%)         434        3126   +2692 (+620.28%)\nkprobe_ret__do_filp_open                   5641      44578   +38937 (+690.25%)         446        3162   +2716 (+608.97%)\nraw_tracepoint__sched_process_exec         2770      35962  +33192 (+1198.27%)         226        3121  +2895 (+1280.97%)\nraw_tracepoint__sched_process_exit         1526       2135      +609 (+39.91%)         133         208      +75 (+56.39%)\nraw_tracepoint__sched_process_fork          265        337       +72 (+27.17%)          19          24       +5 (+26.32%)\ntracepoint__syscalls__sys_enter_kill      18782     140407  +121625 (+647.56%)        1286       12176  +10890 (+846.81%)\n\nbpf_cmp_likely() is equivalent to barrier_var():\n\n./veristat -C -e prog', 'insns', 'states before after_with_likely\nProgram                               Insns (A)  Insns (B)  Insns   (DIFF)  States (A)  States (B)  States (DIFF)\n------------------------------------  ---------  ---------  --------------  ----------  ----------  -------------\nkprobe__proc_sys_write                     1603       1663    +60 (+3.74%)         123         127    +4 (+3.25%)\nkprobe__vfs_link                          11815      12090   +275 (+2.33%)         971         971    +0 (+0.00%)\nkprobe__vfs_symlink                        5464       5448    -16 (-0.29%)         434         426    -8 (-1.84%)\nkprobe_ret__do_filp_open                   5641       5739    +98 (+1.74%)         446         446    +0 (+0.00%)\nraw_tracepoint__sched_process_exec         2770       2608   -162 (-5.85%)         226         216   -10 (-4.42%)\nraw_tracepoint__sched_process_exit         1526       1526     +0 (+0.00%)         133         133    +0 (+0.00%)\nraw_tracepoint__sched_process_fork          265        265     +0 (+0.00%)          19          19    +0 (+0.00%)\ntracepoint__syscalls__sys_enter_kill      18782      18970   +188 (+1.00%)        1286        1286    +0 (+0.00%)\nkprobe__proc_sys_write                     2700       2809   +109 (+4.04%)         107         109    +2 (+1.87%)\nkprobe__vfs_link                          12238      12366   +128 (+1.05%)         267         269    +2 (+0.75%)\nkprobe__vfs_symlink                        7139       7365   +226 (+3.17%)         167         175    +8 (+4.79%)\nkprobe_ret__do_filp_open                   7264       7070   -194 (-2.67%)         180         182    +2 (+1.11%)\nraw_tracepoint__sched_process_exec         3768       3453   -315 (-8.36%)         211         199   -12 (-5.69%)\nraw_tracepoint__sched_process_exit         3138       3138     +0 (+0.00%)          83          83    +0 (+0.00%)\nraw_tracepoint__sched_process_fork          265        265     +0 (+0.00%)          19          19    +0 (+0.00%)\ntracepoint__syscalls__sys_enter_kill      26679      24327  -2352 (-8.82%)        1067        1037   -30 (-2.81%)\nkprobe__proc_sys_write                     1833       1833     +0 (+0.00%)         157         157    +0 (+0.00%)\nkprobe__vfs_link                           9995      10127   +132 (+1.32%)         803         803    +0 (+0.00%)\nkprobe__vfs_symlink                        5606       5672    +66 (+1.18%)         451         451    +0 (+0.00%)\nkprobe_ret__do_filp_open                   5716       5782    +66 (+1.15%)         462         462    +0 (+0.00%)\nraw_tracepoint__sched_process_exec         3042       3042     +0 (+0.00%)         278         278    +0 (+0.00%)\nraw_tracepoint__sched_process_exit         1680       1680     +0 (+0.00%)         146         146    +0 (+0.00%)\nraw_tracepoint__sched_process_fork          299        299     +0 (+0.00%)          25          25    +0 (+0.00%)\ntracepoint__syscalls__sys_enter_kill      18372      18372     +0 (+0.00%)        1558        1558    +0 (+0.00%)\n\ndefault (mcpu=v3)', ' no_alu32', ' cpuv4 have similar differences.\n\nNote one place where bpf_nop_mov() is used to workaround the verifier lack of link\nbetween the scalar register and its spill to stack.\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20231226191148.48536-7-alexei.starovoitov@gmail.com\n', '']",Convert profiler test files to use bpf_cmp for volatile comparison.,"selftests,bpf_cmp,profiler",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0bcc62aa9813f519db58df14ddf1d523fa971e62,0bcc62aa9813f519db58df14ddf1d523fa971e62,Alexei Starovoitov,ast@kernel.org,1703617907,Andrii Nakryiko,andrii@kernel.org,1704308903,884e35b466cf0bda2af66675bc3379dae60d37e1,907dbd3ede5ffd4f9519dd1fae2a8a983603bf3b,"bpf: Add bpf_nop_mov() asm macro.

bpf_nop_mov(var) asm macro emits nop register move: rX = rX.
If 'var' is a scalar and not a fixed constant the verifier will assign ID to it.
If it's later spilled the stack slot will carry that ID as well.
Hence the range refining comparison ""if rX < const"" will update all copies
including spilled slot.
This macro is a temporary workaround until the verifier gets smarter.

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20231226191148.48536-6-alexei.starovoitov@gmail.com
",,Introduces a new bpf_nop_mov() macro for improved control over variable registration and ID tracking.,"bpf_nop_mov, asm macro, verifier",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
907dbd3ede5ffd4f9519dd1fae2a8a983603bf3b,907dbd3ede5ffd4f9519dd1fae2a8a983603bf3b,Alexei Starovoitov,ast@kernel.org,1703617906,Andrii Nakryiko,andrii@kernel.org,1704308903,806a284aa90422430f92c32be1e180822b62be9d,624cd2a17672f4596fee97a5558bc990778bbcf9,"selftests/bpf: Remove bpf_assert_eq-like macros.

Since the last user was converted to bpf_cmp"," remove bpf_assert_eq/ne/... macros.

__bpf_assert_op() macro is kept for experiments","["" since it's slightly more efficient\nthan bpf_assert(bpf_cmp_unlikely()) until LLVM is fixed.\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nAcked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nLink: https://lore.kernel.org/bpf/20231226191148.48536-5-alexei.starovoitov@gmail.com\n"", '']",The commit removes bpf_assert_eq macros from selftests as they are redundant with the new bpf_cmp macro.,"selftests, macros, bpf_cmp",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
624cd2a17672f4596fee97a5558bc990778bbcf9,624cd2a17672f4596fee97a5558bc990778bbcf9,Alexei Starovoitov,ast@kernel.org,1703617905,Andrii Nakryiko,andrii@kernel.org,1704308903,8b24caf8e239bea1bbc4313d0f4a9aaed3c832e0,a8b242d77bd72556b7a9d8be779f7d27b95ba73c,"selftests/bpf: Convert exceptions_assert.c to bpf_cmp

Convert exceptions_assert.c to bpf_cmp_unlikely() macro.

Since

bpf_assert(bpf_cmp_unlikely(var", ==,"["" 100));\nother code;\n\nwill generate assembly code:\n\n  if r1 == 100 goto L2;\n  r0 = 0\n  call bpf_throw\nL1:\n  other code;\n  ...\n\nL2: goto L1;\n\nLLVM generates redundant basic block with extra goto. LLVM will be fixed eventually.\nRight now it's less efficient than __bpf_assert(var"", ' ==', "" 100) macro that produces:\n  if r1 == 100 goto L1;\n  r0 = 0\n  call bpf_throw\nL1:\n  other code;\n\nBut extra goto doesn't hurt the verification process.\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nAcked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nLink: https://lore.kernel.org/bpf/20231226191148.48536-4-alexei.starovoitov@gmail.com\n"", '']",Convert exceptions_assert.c in selftests to use bpf_cmp_unlikely() macro.,"exceptions_assert,bpf_cmp_unlikely,selftests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a8b242d77bd72556b7a9d8be779f7d27b95ba73c,a8b242d77bd72556b7a9d8be779f7d27b95ba73c,Alexei Starovoitov,ast@kernel.org,1703617904,Andrii Nakryiko,andrii@kernel.org,1704308322,ee646501c5045d276c5b9ecced32a85eac557be9,495d2d8133fd1407519170a5238f455abbd9ec9b,"bpf: Introduce ""volatile compare"" macros

Compilers optimize conditional operators at will"," but often bpf programmers
want to force compilers to keep the same operator in asm as it's written in C.
Introduce bpf_cmp_likely/unlikely(var1","[' conditional_op', ' var2) macros that can be used as:\n\n-               if (seen >= 1000)\n+               if (bpf_cmp_unlikely(seen', ' >=', "" 1000))\n\nThe macros take advantage of BPF assembly that is C like.\n\nThe macros check the sign of variable 'seen' and emits either\nsigned or unsigned compare.\n\nFor example:\nint a;\nbpf_cmp_unlikely(a"", ' >', "" 0) will be translated to 'if rX s> 0 goto' in BPF assembly.\n\nunsigned int a;\nbpf_cmp_unlikely(a"", ' >', "" 0) will be translated to 'if rX > 0 goto' in BPF assembly.\n\nC type conversions coupled with comparison operator are tricky.\n  int i = -1;\n  unsigned int j = 1;\n  if (i < j) // this is false.\n\n  long i = -1;\n  unsigned int j = 1;\n  if (i < j) // this is true.\n\nMake sure BPF program is compiled with -Wsign-compare then the macros will catch\nthe mistake.\n\nThe macros check LHS (left hand side) only to figure out the sign of compare.\n\n'if 0 < rX goto' is not allowed in the assembly"", ' so the users\nhave to use a variable on LHS anyway.\n\nThe patch updates few tests to demonstrate the use of the macros.\n\nThe macro allows to use BPF_JSET in C code', "" since LLVM doesn't generate it at\npresent. For example:\n\nif (i & j) compiles into r0 &= r1; if r0 == 0 goto\n\nwhile\n\nif (bpf_cmp_unlikely(i"", ' &', ' j)) compiles into if r0 & r1 goto\n\nNote that the macros has to be careful with RHS assembly predicate.\nSince:\nu64 __rhs = 1ull << 42;\nasm goto(""if r0 < %[rhs] goto +1"" :: [rhs] ""ri"" (__rhs));\nLLVM will silently truncate 64-bit constant into s32 imm.\n\nNote that [lhs] ""r""((short)LHS) the type cast is a workaround for LLVM issue.\nWhen LHS is exactly 32-bit LLVM emits redundant <<=32', "" >>=32 to zero upper 32-bits.\nWhen LHS is 64 or 16 or 8-bit variable there are no shifts.\nWhen LHS is 32-bit the (u64) cast doesn't help. Hence use (short) cast.\nIt does _not_ truncate the variable before it's assigned to a register.\n\nTraditional likely()/unlikely() macros that use __builtin_expect(!!(x)"", ' 1 or 0)\nhave no effect on these macros', "" hence macros implement the logic manually.\nbpf_cmp_unlikely() macro preserves compare operator as-is while\nbpf_cmp_likely() macro flips the compare.\n\nConsider two cases:\nA.\n  for() {\n    if (foo >= 10) {\n      bar += foo;\n    }\n    other code;\n  }\n\nB.\n  for() {\n    if (foo >= 10)\n       break;\n    other code;\n  }\n\nIt's ok to use either bpf_cmp_likely or bpf_cmp_unlikely macros in both cases"", ""\nbut consider that 'break' is effectively 'goto out_of_the_loop'.\nHence it's better to use bpf_cmp_unlikely in the B case.\nWhile 'bar += foo' is better to keep as 'fallthrough' == likely code path in the A case.\n\nWhen it's written as:\nA.\n  for() {\n    if (bpf_cmp_likely(foo"", ' >=', ' 10)) {\n      bar += foo;\n    }\n    other code;\n  }\n\nB.\n  for() {\n    if (bpf_cmp_unlikely(foo', ' >=', ' 10))\n       break;\n    other code;\n  }\n\nThe assembly will look like:\nA.\n  for() {\n    if r1 < 10 goto L1;\n      bar += foo;\n  L1:\n    other code;\n  }\n\nB.\n  for() {\n    if r1 >= 10 goto L2;\n    other code;\n  }\n  L2:\n\nThe bpf_cmp_likely vs bpf_cmp_unlikely changes basic block layout', ' hence it will\ngreatly influence the verification process. The number of processed instructions\nwill be different', ' since the verifier walks the fallthrough first.\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nAcked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nLink: https://lore.kernel.org/bpf/20231226191148.48536-3-alexei.starovoitov@gmail.com\n', '']",This commit introduces macros for volatile comparisons to aid bpf programmers in controlling compiler optimizations.,"volatile, macros, operators",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
495d2d8133fd1407519170a5238f455abbd9ec9b,495d2d8133fd1407519170a5238f455abbd9ec9b,Alexei Starovoitov,ast@kernel.org,1703617903,Andrii Nakryiko,andrii@kernel.org,1704307282,12f60945f5c43cbd7daaaf7be7e3594612a477c4,a640de4cf9fec0caf43ccb7404ec9f0fde9a6a65,"selftests/bpf: Attempt to build BPF programs with -Wsign-compare

GCC's -Wall includes -Wsign-compare while clang does not.
Since BPF programs are built with clang we need to add this flag explicitly
to catch problematic comparisons like:

  int i = -1;
  unsigned int j = 1;
  if (i < j) // this is false.

  long i = -1;
  unsigned int j = 1;
  if (i < j) // this is true.

C standard for reference:

- If either operand is unsigned long the other shall be converted to unsigned long.

- Otherwise", if one operand is a long int and the other unsigned int,"[' then if a\nlong int can represent all the values of an unsigned int', ' the unsigned int\nshall be converted to a long int; otherwise both operands shall be converted to\nunsigned long int.\n\n- Otherwise', ' if either operand is long', ' the other shall be converted to long.\n\n- Otherwise', ' if either operand is unsigned', "" the other shall be converted to unsigned.\n\nUnfortunately clang's -Wsign-compare is very noisy.\nIt complains about (s32)a == (u32)b which is safe and doen't have surprising behavior.\n\nThis patch fixes some of the issues. It needs a follow up to fix the rest.\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nAcked-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nLink: https://lore.kernel.org/bpf/20231226191148.48536-2-alexei.starovoitov@gmail.com\n"", '']",Add -Wsign-compare flag to clang when building BPF programs to catch signed/unsigned comparison issues.,"BPF programs, -Wsign-compare, clang",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a640de4cf9fec0caf43ccb7404ec9f0fde9a6a65,a640de4cf9fec0caf43ccb7404ec9f0fde9a6a65,Andrii Nakryiko,andrii@kernel.org,1704307077,Andrii Nakryiko,andrii@kernel.org,1704307077,d58e59ba6536fc754d8aed14bd7ef6a2a3fe2be0,2ab1efad60ad119b616722b81eeb73060728028c 72187506de4f19fcc8ae63a2b2f36d75e5259d9d,"Merge branch 'bpf-simplify-checking-size-of-helper-accesses'

Andrei Matei says:

====================
bpf: Simplify checking size of helper accesses

v3->v4:
- kept only the minimal change"," undoing debatable changes (Andrii)
- dropped the second patch from before","[' with changes to the error\n  message (Andrii)\n- extracted the new test into a separate patch (Andrii)\n- added Acked by Andrii\n\nv2->v3:\n- split the error-logging function to a separate patch (Andrii)\n- make the error buffers smaller (Andrii)\n- include size of memory region for PTR_TO_MEM (Andrii)\n- nits from Andrii and Eduard\n\nv1->v2:\n- make the error message include more info about the context of the\n  zero-sized access (Andrii)\n====================\n\nLink: https://lore.kernel.org/r/20231221232225.568730-1-andreimatei1@gmail.com\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n', '']",Simplifies checking the size of eBPF helper accesses by retaining minimal changes.,"bpf, helper, simplify",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
72187506de4f19fcc8ae63a2b2f36d75e5259d9d,72187506de4f19fcc8ae63a2b2f36d75e5259d9d,Andrei Matei,andreimatei1@gmail.com,1703200945,Andrii Nakryiko,andrii@kernel.org,1704307076,d58e59ba6536fc754d8aed14bd7ef6a2a3fe2be0,8a021e7fa10576eeb3938328f39bbf98fe7d4715,"bpf: Add a possibly-zero-sized read test

This patch adds a test for the condition that the previous patch mucked
with - illegal zero-sized helper memory access. As opposed to existing
tests", this new one uses a size whose lower bound is zero,"[' as opposed to\na known-zero one.\n\nSigned-off-by: Andrei Matei <andreimatei1@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20231221232225.568730-3-andreimatei1@gmail.com\n', '']",Add test for zero-sized helper memory access in eBPF.,"test, zero-sized, memory",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8a021e7fa10576eeb3938328f39bbf98fe7d4715,8a021e7fa10576eeb3938328f39bbf98fe7d4715,Andrei Matei,andreimatei1@gmail.com,1703200944,Andrii Nakryiko,andrii@kernel.org,1704307076,6373692e4954ec6a180b35ac37665395c703f8a7,2ab1efad60ad119b616722b81eeb73060728028c,"bpf: Simplify checking size of helper accesses

This patch simplifies the verification of size arguments associated to
pointer arguments to helpers and kfuncs. Many helpers take a pointer
argument followed by the size of the memory access performed to be
performed through that pointer. Before this patch"," the handling of the
size argument in check_mem_size_reg() was confusing and wasteful: if the
size register's lower bound was 0","[' then the verification was done twice:\nonce considering the size of the access to be the lower-bound of the\nrespective argument', ' and once considering the upper bound (even if the\ntwo are the same). The upper bound checking is a super-set of the\nlower-bound checking(*)', ' except: the only point of the lower-bound check\nis to handle the case where zero-sized-accesses are explicitly not\nallowed and the lower-bound is zero. This static condition is now\nchecked explicitly', ' replacing a much more complex', ' expensive and\nconfusing verification call to check_helper_mem_access().\n\nError messages change in this patch. Before', ' messages about illegal\nzero-size accesses depended on the type of the pointer and on other\nconditions', ' and sometimes the message was plain wrong: in some tests\nthat changed you\'ll see that the old message was something like ""R1 min\nvalue is outside of the allowed memory range""', ' where R1 is the pointer\nregister; the error was wrongly claiming that the pointer was bad\ninstead of the size being bad. Other times the information that the size\ncame for a register with a possible range of values was wrong', ' and the\nerror presented the size as a fixed zero. Now the errors refer to the\nright register. However', ' the old error messages did contain useful\ninformation about the pointer register which is now lost; recovering\nthis information was deemed not important enough.\n\n(*) Besides standing to reason that the checks for a bigger size access\nare a super-set of the checks for a smaller size access', "" I have also\nmechanically verified this by reading the code for all types of\npointers. I could convince myself that it's true for all but\nPTR_TO_BTF_ID (check_ptr_to_btf_access). There"", ' simply looking\nline-by-line does not immediately prove what we want. If anyone has any\nqualms', ' let me know.\n\nSigned-off-by: Andrei Matei <andreimatei1@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20231221232225.568730-2-andreimatei1@gmail.com\n', '']",This commit simplifies the verification of size arguments for helper and kfunc pointer accesses in eBPF.,"simplify, helper, verification",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9b0a3839e8d29663cd9ee2c43d38b06c3b91619e,9b0a3839e8d29663cd9ee2c43d38b06c3b91619e,Greg Kroah-Hartman,gregkh@linuxfoundation.org,1703057928,Jiri Kosina,jkosina@suse.com,1704191128,ee9eff7ed1ea9cf1e98084619f9081bd3175d8c4,c4a9743699f3b093bad4bcc472c4ee34c7929f33,"HID: bpf: make bus_type const in struct hid_bpf_ops

The struct bus_type pointer in hid_bpf_ops just passes the pointer to
the driver core", and the driver core can handle,"[' and expects', ' a constant\npointer', ' so also make the pointer constant in hid_bpf_ops.\n\nPart of the process of moving all usages of struct bus_type to be\nconstant to move them all to read-only memory.\n\nCc: Jiri Kosina <jikos@kernel.org>\nCc: Benjamin Tissoires <benjamin.tissoires@redhat.com>\nCc: linux-input@vger.kernel.org\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>\nSigned-off-by: Jiri Kosina <jkosina@suse.com>\n', '']",Make bus_type const in struct hid_bpf_ops to work with driver core.,"HID,bus_type,const",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['HID driver like programs']
240436c06ce992879d59e504b0df3d32deebb43e,240436c06ce992879d59e504b0df3d32deebb43e,David S. Miller,davem@davemloft.net,1704120321,David S. Miller,davem@davemloft.net,1704120321,0c1653f11b3e4aca68269bacb978e8e985bb0ee7,cff9c565e65f3622e8dc1dcc21c1520a083dff35 5abde62465222edd3080b70099bd809f166d5d7d,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next

Daniel Borkmann says:

====================
bpf-next-for-netdev
The following pull-request contains BPF updates for your *net-next* tree.

We've added 22 non-merge commits during the last 3 day(s) which contain
a total of 23 files changed", 652 insertions(+),"["" 431 deletions(-).\n\nThe main changes are:\n\n1) Add verifier support for annotating user's global BPF subprogram arguments\n   with few commonly requested annotations for a better developer experience"", '\n   from Andrii Nakryiko.\n\n   These tags are:\n     - Ability to annotate a special PTR_TO_CTX argument\n     - Ability to annotate a generic PTR_TO_MEM as non-NULL\n\n2) Support BPF verifier tracking of BPF_JNE which helps cases when the compiler\n   transforms (unsigned) ""a > 0"" into ""if a == 0 goto xxx"" and the like', "" from\n   Menglong Dong.\n\n3) Fix a warning in bpf_mem_cache's check_obj_size() as reported by LKP"", ' from Hou Tao.\n\n4) Re-support uid/gid options when mounting bpffs which had to be reverted with\n   the prior token series revert to avoid conflicts', ' from Daniel Borkmann.\n\n5) Fix a libbpf NULL pointer dereference in bpf_object__collect_prog_relos() found\n   from fuzzing the library with malformed ELF files', "" from Mingyi Zhang.\n\n6) Skip DWARF sections in libbpf's linker sanity check given compiler options to\n   generate compressed debug sections can trigger a rejection due to misalignment"", '\n   from Alyssa Ross.\n\n7) Fix an unnecessary use of the comma operator in BPF verifier', ' from Simon Horman.\n\n8) Fix format specifier for unsigned long values in cpustat sample', ' from Colin Ian King.\n====================\n\nSigned-off-by: David S. Miller <davem@davemloft.net>\n', '']",Merge bpf-next branch into the net-next tree with updates containing various BPF enhancements.,"BPF, merge, updates",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fc044c53b99fad039ac30b95b289992ebf7dd6b4,fc044c53b99fad039ac30b95b289992ebf7dd6b4,Namhyung Kim,namhyung@kernel.org,1702426390,Arnaldo Carvalho de Melo,acme@redhat.com,1703381982,bb61a7d8a1a77612e1af59f7262b5bd6a8f1216a,b9c87f536c6f28c75ace8a014646faad00f0e1ec,"perf annotate-data: Add dso->data_types tree

To aggregate accesses to the same data type"," add 'data_types' tree in
DSO to maintain data types and find it by name and size.

It might have different data types that happen to have the same name","[""\nso it also compares the size of the type.\n\nEven if it doesn't 100% guarantee"", "" it reduces the possibility of\nmis-handling of such conflicts.\n\nAnd I don't think it's common to have different types with the same\nname.\n\nCommitter notes:\n\nVery few cases on the Linux kernel"", ' but there are some different types\nwith the same name', ' unsure if there is a debug mode in libbpf dedup that\nwarns about such cases', ' but there are provisions in pahole for that', '\nsee:\n\n  ""emit: Notice type shadowing', ' i.e. multiple types with the same name (enum', ' struct', ' union', ' etc)""\n    https://git.kernel.org/pub/scm/devel/pahole/pahole.git/commit/?id=4f332dbfd02072e4f410db7bdcda8d6e3422974b\n\n  $ pahole --compile > vmlinux.h\n  $ rm -f a ; make a\n  cc     a.c   -o a\n  $ grep __[0-9] vmlinux.h\n  union irte__1 {\n  struct map_info__1;\n  struct map_info__1 {\n  \tstruct map_info__1 *       next;                 /*     0     8 */\n  $\n\n  drivers/iommu/amd/amd_iommu_types.h \'union irte\'\n  include/linux/dmar.h                \'struct irte\'\n\n  include/linux/device-mapper.h:\n\n    union map_info {\n            void *ptr;\n    };\n\n  include/linux/mtd/map.h:\n\n    struct map_info {\n        const char *name;\n        unsigned long size;\n        resource_size_t phys;\n   <SNIP>\n\n  kernel/events/uprobes.c:\n\n   struct map_info {\n        struct map_info *next;\n        struct mm_struct *mm;\n        unsigned long vaddr;\n  };\n\nSigned-off-by: Namhyung Kim <namhyung@kernel.org>\nCc: Adrian Hunter <adrian.hunter@intel.com>\nCc: Ian Rogers <irogers@google.com>\nCc: Ingo Molnar <mingo@kernel.org>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: Linus Torvalds <torvalds@linux-foundation.org>\nCc: Masami Hiramatsu <mhiramat@kernel.org>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Stephane Eranian <eranian@google.com>\nCc: linux-toolchains@vger.kernel.org\nCc: linux-trace-devel@vger.kernel.org\nLink: https://lore.kernel.org/r/20231213001323.718046-5-namhyung@kernel.org\nSigned-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>\n', '']",Add a data tree structure in DSO to manage and differentiate data types by name and size.,"data tree, DSO, data types",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","[""It's not related to any of the above.""]"
2437c0f5147b82b92075af6085b99051753f4a3c,2437c0f5147b82b92075af6085b99051753f4a3c,David S. Miller,davem@davemloft.net,1703291192,David S. Miller,davem@davemloft.net,1703291192,d63af2761cdb517aceee0e7789c749e7d3d82fcb,6530b29f77c8960bd21639ce71070499d155396b 9d0b4ad82d6117e6d7ead50f64be54ec782aa1fe,"Merge branch 'net-selftests-unique-namespace-last-part'

Hangbin Liu says:

====================
Convert net selftests to run in unique namespace (last part)

Here is the last part of converting net selftests to run in unique namespace.
This part converts all left tests. After the conversion"," we can run the net
sleftests in parallel. e.g.

 # ./run_kselftest.sh -n -t net:reuseport_bpf
 TAP version 13
 1..1
 # selftests: net: reuseport_bpf
 ok 1 selftests: net: reuseport_bpf
  mod 10...
 # Socket 0: 0
 # Socket 1: 1
 ...
 # Socket 4: 19
 # Testing filter add without bind...
 # SUCCESS

 # ./run_kselftest.sh -p -n -t net:cmsg_so_mark.sh -t net:cmsg_time.sh -t net:cmsg_ipv6.sh
 TAP version 13
 1..3
 # selftests: net: cmsg_so_mark.sh
 ok 1 selftests: net: cmsg_so_mark.sh
 # selftests: net: cmsg_time.sh
 ok 2 selftests: net: cmsg_time.sh
 # selftests: net: cmsg_ipv6.sh
 ok 3 selftests: net: cmsg_ipv6.sh

 # ./run_kselftest.sh -p -n -c net
 TAP version 13
 1..95
 # selftests: net: reuseport_bpf_numa
 ok 3 selftests: net: reuseport_bpf_numa
 # selftests: net: reuseport_bpf_cpu
 ok 2 selftests: net: reuseport_bpf_cpu
 # selftests: net: sk_bind_sendto_listen
 ok 9 selftests: net: sk_bind_sendto_listen
 # selftests: net: reuseaddr_conflict
 ok 5 selftests: net: reuseaddr_conflict
 ...

Here is the part 1 link:
https://lore.kernel.org/netdev/20231202020110.362433-1-liuhangbin@gmail.com
part 2 link:
https://lore.kernel.org/netdev/20231206070801.1691247-1-liuhangbin@gmail.com
part 3 link:
https://lore.kernel.org/netdev/20231213060856.4030084-1-liuhangbin@gmail.com
====================

Signed-off-by: David S. Miller <davem@davemloft.net>
",[''],Convert remaining net selftests to run in unique namespaces for parallel execution.,"net selftests, unique namespace, parallel execution",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"[""It's not related to any of the above.""]"
5abde62465222edd3080b70099bd809f166d5d7d,5abde62465222edd3080b70099bd809f166d5d7d,Simon Horman,horms@kernel.org,1703178232,Daniel Borkmann,daniel@iogearbox.net,1703194825,766b65b7e90551fd0e302979345a1d048a124e3f,b08c8fc0411dce0fc44b78ce4d67f1b67c35c196,"bpf: Avoid unnecessary use of comma operator in verifier

Although it does not seem to have any untoward side-effects"," the use
of ';' to separate to assignments seems more appropriate than '","[""'.\n\nFlagged by clang-17 -Wcomma\n\nNo functional change intended. Compile tested only.\n\nSigned-off-by: Simon Horman <horms@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Dave Marchevsky <davemarchevsky@fb.com>\nLink: https://lore.kernel.org/bpf/20231221-bpf-verifier-comma-v1-1-cde2530912e9@kernel.org\n"", '']",This commit improves the eBPF verifier by avoiding unnecessary use of the comma operator in assignments.,"bpf, verifier, comma",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7c5e046bdcb2513f9decb3765d8bf92d604279cf,7c5e046bdcb2513f9decb3765d8bf92d604279cf,Linus Torvalds,torvalds@linux-foundation.org,1703178937,Linus Torvalds,torvalds@linux-foundation.org,1703178937,5f8330fbca28d6bc8daaf4fefd40b2d838ef1547,a4aebe936554dac6a91e5d091179c934f8325708 74769d810ead7e7af1a481f07a4d890861a6a4cc,"Merge tag 'net-6.7-rc7' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Paolo Abeni:
 ""Including fixes from WiFi and bpf.

  Current release - regressions:

   - bpf: syzkaller found null ptr deref in unix_bpf proto add

   - eth: i40e: fix ST code value for clause 45

  Previous releases - regressions:

   - core: return error from sk_stream_wait_connect() if sk_wait_event()
     fails

   - ipv6: revert remove expired routes with a separated list of routes

   - wifi rfkill:
       - set GPIO direction
       - fix crash with WED rx support enabled

   - bluetooth:
       - fix deadlock in vhci_send_frame
       - fix use-after-free in bt_sock_recvmsg

   - eth: mlx5e: fix a race in command alloc flow

   - eth: ice: fix PF with enabled XDP going no-carrier after reset

   - eth: bnxt_en: do not map packet buffers twice

  Previous releases - always broken:

   - core:
       - check vlan filter feature in vlan_vids_add_by_dev() and
         vlan_vids_del_by_dev()
       - check dev->gso_max_size in gso_features_check()

   - mptcp: fix inconsistent state on fastopen race

   - phy: skip LED triggers on PHYs on SFP modules

   - eth: mlx5e:
       - fix double free of encap_header
       - fix slab-out-of-bounds in mlx5_query_nic_vport_mac_list()""

* tag 'net-6.7-rc7' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (69 commits)
  net: check dev->gso_max_size in gso_features_check()
  kselftest: rtnetlink.sh: use grep_fail when expecting the cmd fail
  net/ipv6: Revert remove expired routes with a separated list of routes
  net: avoid build bug in skb extension length calculation
  net: ethernet: mtk_wed: fix possible NULL pointer dereference in mtk_wed_wo_queue_tx_clean()
  net: stmmac: fix incorrect flag check in timestamp interrupt
  selftests: add vlan hw filter tests
  net: check vlan filter feature in vlan_vids_add_by_dev() and vlan_vids_del_by_dev()
  net: hns3: add new maintainer for the HNS3 ethernet driver
  net: mana: select PAGE_POOL
  net: ks8851: Fix TX stall caused by TX buffer overrun
  ice: Fix PF with enabled XDP going no-carrier after reset
  ice: alter feature support check for SRIOV and LAG
  ice: stop trashing VF VSI aggregator node ID information
  mailmap: add entries for Geliang Tang
  mptcp: fill in missing MODULE_DESCRIPTION()
  mptcp: fix inconsistent state on fastopen race
  selftests: mptcp: join: fix subflow_send_ack lookup
  net: phy: skip LED triggers on PHYs on SFP modules
  bpf: Add missing BPF_LINK_TYPE invocations
  ...
",,Merge networking fixes including bpf and WiFi enhancements for current and previous release regressions.,"networking, fixes, bpf",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['xdp like programs', 'socket like programs', 'tc/netfilter like programs']"
b08c8fc0411dce0fc44b78ce4d67f1b67c35c196,b08c8fc0411dce0fc44b78ce4d67f1b67c35c196,Daniel Borkmann,daniel@iogearbox.net,1703079485,Daniel Borkmann,daniel@iogearbox.net,1703165070,4939fe5cb33dab0c69fcb62808f63cc982ce6d7b,fc3a5534e2a8855427403113cbeb54af5837bbe0,"bpf: Re-support uid and gid when mounting bpffs

For a clean"," conflict-free revert of the token-related patches in commit
d17aff807f84 (""Revert BPF token-related functionality"")","[' the bpf fs commit\n750e785796bb (""bpf: Support uid and gid when mounting bpffs"") was undone\ntemporarily as well.\n\nThis patch manually re-adds the functionality from the original one back\nin 750e785796bb', ' no other functional changes intended.\n\nTesting:\n\n  # mount -t bpf -o uid=65534', 'gid=65534 bpffs ./foo\n  # ls -la . | grep foo\n  drwxrwxrwt   2 nobody nogroup          0 Dec 20 13:16 foo\n  # mount -t bpf\n  bpffs on /root/foo type bpf (rw', 'relatime', 'uid=65534', 'gid=65534)\n\nAlso', ' passing invalid arguments for uid/gid are properly rejected as expected.\n\nFixes: d17aff807f84 (""Revert BPF token-related functionality"")\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Christian Brauner <brauner@kernel.org>\nCc: Jie Jiang <jiejiang@chromium.org>\nCc: Andrii Nakryiko <andrii@kernel.org>\nCc: linux-fsdevel@vger.kernel.org\nLink: https://lore.kernel.org/bpf/20231220133805.20953-1-daniel@iogearbox.net\n', '']",Re-supporting uid and gid functionality when mounting bpf filesystem with bpffs.,"uid,gid,bpffs",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
74769d810ead7e7af1a481f07a4d890861a6a4cc,74769d810ead7e7af1a481f07a4d890861a6a4cc,Paolo Abeni,pabeni@redhat.com,1703158048,Paolo Abeni,pabeni@redhat.com,1703158049,7145a1990f8133b5d490447ad1022fb6cad2b623,24ab059d2ebd62fdccc43794796f6ffbabe49ebc 117211aa739a926e6555cfea883be84bee6f1695,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Daniel Borkmann says:

====================
pull-request: bpf 2023-12-21

Hi David", hi Jakub,"[' hi Paolo', ' hi Eric', ""\n\nThe following pull-request contains BPF updates for your *net* tree.\n\nWe've added 3 non-merge commits during the last 5 day(s) which contain\na total of 4 files changed"", ' 45 insertions(+).\n\nThe main changes are:\n\n1) Fix a syzkaller splat which triggered an oob issue in bpf_link_show_fdinfo()', '\n   from Jiri Olsa.\n\n2) Fix another syzkaller-found issue which triggered a NULL pointer dereference\n   in BPF sockmap for unconnected unix sockets', "" from John Fastabend.\n\nbpf-for-netdev\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  bpf: Add missing BPF_LINK_TYPE invocations\n  bpf: sockmap"", ' test for unconnected af_unix sock\n  bpf: syzkaller found null ptr deref in unix_bpf proto add\n====================\n\nLink: https://lore.kernel.org/r/20231221104844.1374-1-daniel@iogearbox.net\nSigned-off-by: Paolo Abeni <pabeni@redhat.com>\n', '']",Merge branch 'for-netdev' from bpf to merge the latest changes.,"merge, netdev, bpf",It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
fc3a5534e2a8855427403113cbeb54af5837bbe0,fc3a5534e2a8855427403113cbeb54af5837bbe0,Mingyi Zhang,zhangmingyi5@huawei.com,1703129987,Daniel Borkmann,daniel@iogearbox.net,1703149542,e47f022a97855c56325801ded581662c275a8d0c,812d8bf87678f77055b575d20636fdbbbf15edaf,"libbpf: Fix NULL pointer dereference in bpf_object__collect_prog_relos

An issue occurred while reading an ELF file in libbpf.c during fuzzing:

	Program received signal SIGSEGV"," Segmentation fault.
	0x0000000000958e97 in bpf_object.collect_prog_relos () at libbpf.c:4206
	4206 in libbpf.c
	(gdb) bt
	#0 0x0000000000958e97 in bpf_object.collect_prog_relos () at libbpf.c:4206
	#1 0x000000000094f9d6 in bpf_object.collect_relos () at libbpf.c:6706
	#2 0x000000000092bef3 in bpf_object_open () at libbpf.c:7437
	#3 0x000000000092c046 in bpf_object.open_mem () at libbpf.c:7497
	#4 0x0000000000924afa in LLVMFuzzerTestOneInput () at fuzz/bpf-object-fuzzer.c:16
	#5 0x000000000060be11 in testblitz_engine::fuzzer::Fuzzer::run_one ()
	#6 0x000000000087ad92 in tracing::span::Span::in_scope ()
	#7 0x00000000006078aa in testblitz_engine::fuzzer::util::walkdir ()
	#8 0x00000000005f3217 in testblitz_engine::entrypoint::main::{{closure}} ()
	#9 0x00000000005f2601 in main ()
	(gdb)

scn_data was null at this code(tools/lib/bpf/src/libbpf.c):

	if (rel->r_offset % BPF_INSN_SZ || rel->r_offset >= scn_data->d_size) {

The scn_data is derived from the code above:

	scn = elf_sec_by_idx(obj","[' sec_idx);\n\tscn_data = elf_sec_data(obj', ' scn);\n\n\trelo_sec_name = elf_sec_str(obj', ' shdr->sh_name);\n\tsec_name = elf_sec_name(obj', "" scn);\n\tif (!relo_sec_name || !sec_name)// don't check whether scn_data is NULL\n\t\treturn -EINVAL;\n\nIn certain special scenarios"", ' such as reading a malformed ELF file', '\nit is possible that scn_data may be a null pointer\n\nSigned-off-by: Mingyi Zhang <zhangmingyi5@huawei.com>\nSigned-off-by: Xin Liu <liuxin350@huawei.com>\nSigned-off-by: Changye Wu <wuchangye@huawei.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20231221033947.154564-1-liuxin350@huawei.com\n', '']",Fix a NULL pointer dereference in libbpf during ELF file processing.,"NULL,libbpf,dereference",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
812d8bf87678f77055b575d20636fdbbbf15edaf,812d8bf87678f77055b575d20636fdbbbf15edaf,Alyssa Ross,hi@alyssa.is,1702983804,Daniel Borkmann,daniel@iogearbox.net,1703149515,a5f0ff77c9bc6860c18f6a746118d98655ca4661,92999245102a09ab2645424a9c9a0a5b16fda833,"libbpf: Skip DWARF sections in linker sanity check

clang can generate (with -g -Wa","--compress-debug-sections) 4-byte
aligned DWARF sections that declare themselves to be 8-byte aligned in
the section header.  Since DWARF sections are dropped during linking
anyway","[' just skip running the sanity checks on them.\n\nReported-by: Sergei Trofimovich <slyich@gmail.com>\nSuggested-by: Andrii Nakryiko <andrii.nakryiko@gmail.com>\nSigned-off-by: Alyssa Ross <hi@alyssa.is>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Daniel Borkmann <daniel@iogearbox.net>\nCloses: https://lore.kernel.org/bpf/ZXcFRJVKbKxtEL5t@nz.home/\nLink: https://lore.kernel.org/bpf/20231219110324.8989-1-hi@alyssa.is\n', '']",The commit modifies libbpf to skip DWARF sections in the linker sanity check.,"libbpf, DWARF, linker",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
92999245102a09ab2645424a9c9a0a5b16fda833,92999245102a09ab2645424a9c9a0a5b16fda833,Alexei Starovoitov,ast@kernel.org,1703107547,Alexei Starovoitov,ast@kernel.org,1703107547,40e8e9008dc0f3a7b2eca992662d5266e13b28d8,32f24938a1fce95fce314c1fa9a72af74588ea6c 69ff403d87be4812571c54b1159e24998414bcab,"Merge branch 'bpf-fix-warning-in-check_obj_size'

Hou Tao says:

====================
bpf: Fix warning in check_obj_size()

From: Hou Tao <houtao1@huawei.com>

Hi","

The patch set aims to fix the warning in check_obj_size() as reported by
lkp [1]. Patch #1 fixes the warning by selecting target cache for free
request through c->unit_size","[' so the unnecessary adjustment of\nsize_index and the checking in check_obj_size() can be removed. Patch #2\nfixes the test failure in test_bpf_ma after applying patch #1.\n\nPlease see individual patches for more details. And comments are always\nwelcome.\n\n[1]: https://lore.kernel.org/bpf/202310302113.9f8fe705-oliver.sang@intel.com/\n====================\n\nLink: https://lore.kernel.org/r/20231216131052.27621-1-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes a warning in check_obj_size function within the BPF subsystem.,"warning, check_obj_size, fix",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
69ff403d87be4812571c54b1159e24998414bcab,69ff403d87be4812571c54b1159e24998414bcab,Hou Tao,houtao1@huawei.com,1702732252,Alexei Starovoitov,ast@kernel.org,1703107546,40e8e9008dc0f3a7b2eca992662d5266e13b28d8,7ac5c53e00735d183a0f5e2cfce5eeb6c16319f2,"selftests/bpf: Remove tests for zeroed-array kptr

bpf_mem_alloc() doesn't support zero-sized allocation"," so removing these
tests from test_bpf_ma test. After the removal","[' there will no definition\nfor bin_data_8', ' so remove 8 from data_sizes array and adjust the index\nof data_btf_ids array in all test cases accordingly.\n\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20231216131052.27621-3-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Removed tests for zeroed-array kptr in selftests due to unsupported zero-sized allocations in bpf_mem_alloc().,"zeroed-array kptr, bpf_mem_alloc, selftests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7ac5c53e00735d183a0f5e2cfce5eeb6c16319f2,7ac5c53e00735d183a0f5e2cfce5eeb6c16319f2,Hou Tao,houtao1@huawei.com,1702732251,Alexei Starovoitov,ast@kernel.org,1703107546,e8e69df257fc7993351a6c3889c8da3687affa6e,32f24938a1fce95fce314c1fa9a72af74588ea6c,"bpf: Use c->unit_size to select target cache during free

At present"," bpf memory allocator uses check_obj_size() to ensure that
ksize() of allocated pointer is equal with the unit_size of used
bpf_mem_cache. Its purpose is to prevent bpf_mem_free() from selecting
a bpf_mem_cache which has different unit_size compared with the
bpf_mem_cache used for allocation. But as reported by lkp","[' the return\nvalue of ksize() or kmalloc_size_roundup() may change due to slab merge\nand it will lead to the warning report in check_obj_size().\n\nThe reported warning happened as follows:\n(1) in bpf_mem_cache_adjust_size()', ' kmalloc_size_roundup(96) returns the\nobject_size of kmalloc-96 instead of kmalloc-cg-96. The object_size of\nkmalloc-96 is 96', ' so size_index for 96 is not adjusted accordingly.\n(2) the object_size of kmalloc-cg-96 is adjust from 96 to 128 due to\nslab merge in __kmem_cache_alias(). For SLAB', ' SLAB_HWCACHE_ALIGN is\nenabled by default for kmalloc slab', ' so align is 64 and size is 128 for\nkmalloc-cg-96. SLUB has a similar merge logic', ' but its object_size will\nnot be changed', ' because its align is 8 under x86-64.\n(3) when unit_alloc() does kmalloc_node(96', ' __GFP_ACCOUNT', ' node)', '\nksize() returns 128 instead of 96 for the returned pointer.\n(4) the warning in check_obj_size() is triggered.\n\nConsidering the slab merge can happen in anytime (e.g', ' a slab created in\na new module)', ' the following case is also possible: during the\ninitialization of bpf_global_ma', ' there is no slab merge and ksize() for\na 96-bytes object returns 96. But after that a new slab created by a\nkernel module is merged to kmalloc-cg-96 and the object_size of\nkmalloc-cg-96 is adjust from 96 to 128 (which is possible for x86-64 +\nCONFIG_SLAB', ' because its alignment requirement is 64 for 96-bytes slab).\nSo soon or later', ' when bpf_global_ma frees a 96-byte-sized pointer\nwhich is allocated from bpf_mem_cache with unit_size=96', ' bpf_mem_free()\nwill free the pointer through a bpf_mem_cache in which unit_size is 128', '\nbecause the return value of ksize() changes. The warning for the\nmismatch will be triggered again.\n\nA feasible fix is introducing similar APIs compared with ksize() and\nkmalloc_size_roundup() to return the actually-allocated size instead of\nsize which may change due to slab merge', ' but it will introduce\nunnecessary dependency on the implementation details of mm subsystem.\n\nAs for now the pointer of bpf_mem_cache is saved in the 8-bytes area\n(or 4-bytes under 32-bit host) above the returned pointer', ' using\nunit_size in the saved bpf_mem_cache to select the target cache instead\nof inferring the size from the pointer itself. Beside no extra\ndependency on mm subsystem', ' the performance for bpf_mem_free_rcu() is\nalso improved as shown below.\n\nBefore applying the patch', ' the performances of bpf_mem_alloc() and\nbpf_mem_free_rcu() on 8-CPUs VM with one producer are as follows:\n\nkmalloc : alloc 11.69 ± 0.28M/s free 29.58 ± 0.93M/s\npercpu  : alloc 14.11 ± 0.52M/s free 14.29 ± 0.99M/s\n\nAfter apply the patch', ' the performance for bpf_mem_free_rcu() increases\n9% and 146% for kmalloc memory and per-cpu memory respectively:\n\nkmalloc: alloc 11.01 ± 0.03M/s free   32.42 ± 0.48M/s\npercpu:  alloc 12.84 ± 0.12M/s free   35.24 ± 0.23M/s\n\nAfter the fixes', ' there is no need to adjust size_index to fix the\nmismatch between allocation and free', ' so remove it as well. Also return\nNULL instead of ZERO_SIZE_PTR for zero-sized alloc in bpf_mem_alloc()', '\nbecause there is no bpf_mem_cache pointer saved above ZERO_SIZE_PTR.\n\nFixes: 9077fc228f09 (""bpf: Use kmalloc_size_roundup() to adjust size_index"")\nReported-by: kernel test robot <oliver.sang@intel.com>\nCloses: https://lore.kernel.org/bpf/202310302113.9f8fe705-oliver.sang@intel.com\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20231216131052.27621-2-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixed unit size selection in bpf_mem_free to match allocation cache unit size.,"unit_size, bpf_mem_cache, allocation",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e77b0236cd0cd1572c6a9b25097b207eab799e74,e77b0236cd0cd1572c6a9b25097b207eab799e74,Ian Rogers,irogers@google.com,1701911813,Arnaldo Carvalho de Melo,acme@redhat.com,1703094970,f5a696d86e7d54804b39f6b817559549ee1545f1,9084952704ba075de28684301ec282b6626b5e7a,"perf maps: Add maps__load_first()

Avoid bpf_lock_contention_read touching the internal maps data structure
by adding a helper function. As access is done directly on the map in
maps"," hold the read lock to stop it being removed.

Signed-off-by: Ian Rogers <irogers@google.com>
Cc: Adrian Hunter <adrian.hunter@intel.com>
Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
Cc: Andi Kleen <ak@linux.intel.com>
Cc: Athira Rajeev <atrajeev@linux.vnet.ibm.com>
Cc: Changbin Du <changbin.du@huawei.com>
Cc: Colin Ian King <colin.i.king@gmail.com>
Cc: Dmitrii Dolgov <9erthalion6@gmail.com>
Cc: German Gomez <german.gomez@arm.com>
Cc: Guilherme Amadio <amadio@gentoo.org>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Ingo Molnar <mingo@redhat.com>
Cc: James Clark <james.clark@arm.com>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: K Prateek Nayak <kprateek.nayak@amd.com>
Cc: Kajol Jain <kjain@linux.ibm.com>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: Leo Yan <leo.yan@linaro.org>
Cc: Li Dong <lidong@vivo.com>
Cc: Liam Howlett <liam.howlett@oracle.com>
Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Masami Hiramatsu <mhiramat@kernel.org>
Cc: Miguel Ojeda <ojeda@kernel.org>
Cc: Ming Wang <wangming01@loongson.cn>
Cc: Namhyung Kim <namhyung@kernel.org>
Cc: Nick Terrell <terrelln@fb.com>
Cc: Paolo Bonzini <pbonzini@redhat.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Sandipan Das <sandipan.das@amd.com>
Cc: Sean Christopherson <seanjc@google.com>
Cc: Steinar H. Gunderson <sesse@google.com>
Cc: Vincent Whitchurch <vincent.whitchurch@axis.com>
Cc: Wenyu Liu <liuwenyu7@huawei.com>
Cc: Yang Jihong <yangjihong1@huawei.com>
Link: https://lore.kernel.org/r/20231207011722.1220634-20-irogers@google.com
Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
",[''],Introduces the maps__load_first() helper function to reduce bpf_lock_contention_read's interaction with internal map data structures.,"perf maps, helper function, lock contention",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
32f24938a1fce95fce314c1fa9a72af74588ea6c,32f24938a1fce95fce314c1fa9a72af74588ea6c,Colin Ian King,colin.i.king@gmail.com,1702999387,Daniel Borkmann,daniel@iogearbox.net,1703082539,f9927d4134246e6cdbe7d57f6e9e6e46ef6f034d,441c725ed592cb22f2a82f2827dccd045356cc81,"samples/bpf: Use %lu format specifier for unsigned long values

Currently %ld format specifiers are being used for unsigned long
values. Fix this by using %lu instead. Cleans up cppcheck warnings:

warning: %ld in format string (no. 1) requires 'long' but the argument
type is 'unsigned long'. [invalidPrintfArgType_sint]

Signed-off-by: Colin Ian King <colin.i.king@gmail.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Reviewed-by: Randy Dunlap <rdunlap@infradead.org>
Link: https://lore.kernel.org/bpf/20231219152307.368921-1-colin.i.king@gmail.com
",,Fix format specifiers in sample BPF code from %ld to %lu for unsigned long values to resolve cppcheck warnings.,"format specifiers, cppcheck, cleanup",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
441c725ed592cb22f2a82f2827dccd045356cc81,441c725ed592cb22f2a82f2827dccd045356cc81,Hou Tao,houtao1@huawei.com,1702994247,Alexei Starovoitov,ast@kernel.org,1703038931,9cac0236c309a0f046fcdbcc5987e947fa2055e6,85dd93ac6e00adf09fc27e4d2e7f5c9aaf275d38,"selftests/bpf: Close cgrp fd before calling cleanup_cgroup_environment()

There is error log when htab-mem benchmark completes. The error log
looks as follows:

$ ./bench htab-mem -d1
Setting up benchmark 'htab-mem'...
Benchmark 'htab-mem' started.
......
(cgroup_helpers.c:353: errno: Device or resource busy) umount cgroup2

Fix it by closing cgrp fd before invoking cleanup_cgroup_environment().

Signed-off-by: Hou Tao <houtao1@huawei.com>
Link: https://lore.kernel.org/r/20231219135727.2661527-1-houtao@huaweicloud.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Fix htab-mem benchmark error by closing cgroup file descriptor before cleanup.,"htab-mem,close,cgroup",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
85dd93ac6e00adf09fc27e4d2e7f5c9aaf275d38,85dd93ac6e00adf09fc27e4d2e7f5c9aaf275d38,Alexei Starovoitov,ast@kernel.org,1703038007,Alexei Starovoitov,ast@kernel.org,1703038007,48f3b6ea5e3a22eed329e643098b62564b85e910,c337f237291b41b308c80124236876cf66c77906 f0a5056222f2cfa6d40b4c888cb6b01e8569e282,"Merge branch 'enhance-bpf-global-subprogs-with-argument-tags'

Andrii Nakryiko says:

====================
Enhance BPF global subprogs with argument tags

This patch set adds verifier support for annotating user's global BPF subprog
arguments with few commonly requested annotations"," to improve global subprog
verification experience.

These tags are:
  - ability to annotate a special PTR_TO_CTX argument;
  - ability to annotate a generic PTR_TO_MEM as non-null.

We utilize btf_decl_tag attribute for this and provide two helper macros as
part of bpf_helpers.h in libbpf (patch #8).

Besides this we also add abilit to pass a pointer to dynptr into global
subprog. This is done based on type name match (struct bpf_dynptr *). This
allows to pass dynptrs into global subprogs","[' for use cases that deal with\nvariable-sized generic memory pointers.\n\nBig chunk of the patch set (patches #1 through #5) are various refactorings to\nmake verifier internals around global subprog validation logic easier to\nextend and support long term', ' eliminating BTF parsing logic duplication', '\nfactoring out argument expectation definitions from BTF parsing', ' etc.\n\nNew functionality is added in patch #6 (ctx and non-null) and patch #7\n(dynptr)', ' extending global subprog checks with awareness for arg tags.\n\nPatch #9 adds simple tests validating each of the added tags and dynptr\nargument passing.\n\nPatch #10 adds a simple negative case for freplace programs to make sure that\ntarget BPF programs with ""unreliable"" BTF func proto cannot be freplaced.\n\nv2->v3:\n  - patch #10 improved by checking expected verifier error (Eduard);\nv1->v2:\n  - dropped packet args for now (Eduard);\n  - added back unreliable=true detection for entry BPF programs (Eduard);\n  - improved subprog arg validation (Eduard);\n  - switched dynptr arg from tag to just type name based check (Eduard).\n====================\n\nLink: https://lore.kernel.org/r/20231215011334.2307144-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Enhance BPF subprograms with argument tags for improved global subprogram verification experience.,"BPF, argument, tags",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f0a5056222f2cfa6d40b4c888cb6b01e8569e282,f0a5056222f2cfa6d40b4c888cb6b01e8569e282,Andrii Nakryiko,andrii@kernel.org,1702602814,Alexei Starovoitov,ast@kernel.org,1703038007,48f3b6ea5e3a22eed329e643098b62564b85e910,0a0ffcac92d5b41133c97d260ad1f320572783a5,"selftests/bpf: add freplace of BTF-unreliable main prog test

Add a test validating that freplace'ing another main (entry) BPF program
fails if the target BPF program doesn't have valid/expected func proto BTF.

We extend fexit_bpf2bpf test to allow to specify expected log message
for negative test cases (where freplace program is expected to fail to
load).

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231215011334.2307144-11-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,This commit adds a self-test for freplace of BTF-unreliable main BPF programs.,"self-test,BTF-unreliable,freplace",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0a0ffcac92d5b41133c97d260ad1f320572783a5,0a0ffcac92d5b41133c97d260ad1f320572783a5,Andrii Nakryiko,andrii@kernel.org,1702602813,Alexei Starovoitov,ast@kernel.org,1703038007,d3ab441e7f404c20aa86baa9bea9ebc3f4327619,aae9c25dda159045b223ecb471cd0729ccec8285,"selftests/bpf: add global subprog annotation tests

Add test cases to validate semantics of global subprog argument
annotations:
  - non-null pointers;
  - context argument;
  - const dynptr passing;
  - packet pointers (data", metadata,"[' end).\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231215011334.2307144-10-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add test cases for global subprog argument annotations in BPF selftests.,"selftests, annotations, subprog",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['other']
aae9c25dda159045b223ecb471cd0729ccec8285,aae9c25dda159045b223ecb471cd0729ccec8285,Andrii Nakryiko,andrii@kernel.org,1702602812,Alexei Starovoitov,ast@kernel.org,1703038007,9deb9267269fb33e487df552afa5fa6bd416942b,a64bfe618665ea9c722f922cba8c6e3234eac5ac,"libbpf: add __arg_xxx macros for annotating global func args

Add a set of __arg_xxx macros which can be used to augment BPF global
subprogs/functions with extra information for use by BPF verifier.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231215011334.2307144-9-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit adds __arg_xxx macros to annotate global BPF functions for the verifier.,"macros, global functions, verifier",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a64bfe618665ea9c722f922cba8c6e3234eac5ac,a64bfe618665ea9c722f922cba8c6e3234eac5ac,Andrii Nakryiko,andrii@kernel.org,1702602811,Alexei Starovoitov,ast@kernel.org,1703038006,da7ae244a52d141b473dfe288f537fa07d248350,94e1c70a34523b5e1529e4ec508316acc6a26a2b,"bpf: add support for passing dynptr pointer to global subprog

Add ability to pass a pointer to dynptr into global functions.
This allows to have global subprogs that accept and work with generic
dynptrs that are created by caller. Dynptr argument is detected based on
the name of a struct type"," if it's ""bpf_dynptr""","["" it's assumed to be\na proper dynptr pointer. Both actual struct and forward struct\ndeclaration types are supported.\n\nThis is conceptually exactly the same semantics as\nbpf_user_ringbuf_drain()'s use of dynptr to pass a variable-sized\npointer to ringbuf record. So we heavily rely on CONST_PTR_TO_DYNPTR\nbits of already existing logic in the verifier.\n\nDuring global subprog validation"", ' we mark such CONST_PTR_TO_DYNPTR as\nhaving LOCAL type', "" as that's the most unassuming type of dynptr and it\ndoesn't have any special helpers that can try to free or acquire extra\nreferences (unlike skb"", ' xdp', ' or ringbuf dynptr). So that seems like a safe\n""choice"" to make from correctness standpoint. It\'s still possible to\npass any type of dynptr to such subprog', ' though', ' because generic dynptr\nhelpers', ' like getting data/slice pointers', ' read/write memory copying\nroutines', ' dynptr adjustment and getter routines all work correctly with\nany type of dynptr.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231215011334.2307144-8-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add support for passing dynamic pointer to global subprograms in BPF.,"dynptr, global, subprog",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
94e1c70a34523b5e1529e4ec508316acc6a26a2b,94e1c70a34523b5e1529e4ec508316acc6a26a2b,Andrii Nakryiko,andrii@kernel.org,1702602810,Alexei Starovoitov,ast@kernel.org,1703038006,05e9543579a9017dfd5f38bd6dfbcc95400b4ccb,f18c3d88deedf0defc3e4800341cc7bcaaabcdf9,"bpf: support 'arg:xxx' btf_decl_tag-based hints for global subprog args

Add support for annotating global BPF subprog arguments to provide more
information about expected semantics of the argument. Currently","
verifier relies purely on argument's BTF type information","[' and supports\nthree general use cases: scalar', ' pointer-to-context', ' and\npointer-to-fixed-size-memory.\n\nScalar and pointer-to-fixed-mem work well in practice and are quite\nnatural to use. But pointer-to-context is a bit problematic', "" as typical\nBPF users don't realize that they need to use a special type name to\nsignal to verifier that argument is not just some pointer"", ' but actually\na PTR_TO_CTX. Further', ' even if users do know which type to use', ' it is\nlimiting in situations where the same BPF program logic is used across\nfew different program types. Common case is kprobes', ' tracepoints', ' and\nperf_event programs having a helper to send some data over BPF perf\nbuffer. bpf_perf_event_output() requires `ctx` argument', "" and so it's\nquite cumbersome to share such global subprog across few BPF programs of\ndifferent types"", ' necessitating extra static subprog that is context\ntype-agnostic.\n\nLong story short', ' there is a need to go beyond types and allow users to\nadd hints to global subprog arguments to define expectations.\n\nThis patch adds such support for two initial special tags:\n  - pointer to context;\n  - non-null qualifier for generic pointer arguments.\n\nAll of the above came up in practice already and seem generally useful\nadditions. Non-null qualifier is an often requested feature', ' which\ncurrently has to be worked around by having unnecessary NULL checks\ninside subprogs even if we know that arguments are never NULL. Pointer\nto context was discussed earlier.\n\nAs for implementation', ' we utilize btf_decl_tag attribute and set up an\n""arg:xxx"" convention to specify argument hint. As such:\n  - btf_decl_tag(""arg:ctx"") is a PTR_TO_CTX hint;\n  - btf_decl_tag(""arg:nonnull"") marks pointer argument as not allowed to\n    be NULL', ' making NULL check inside global subprog unnecessary.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231215011334.2307144-7-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add support for BTF declaration tag-based hints for global eBPF subprogram arguments.,"BTF, subprogram, hints",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f18c3d88deedf0defc3e4800341cc7bcaaabcdf9,f18c3d88deedf0defc3e4800341cc7bcaaabcdf9,Andrii Nakryiko,andrii@kernel.org,1702602809,Alexei Starovoitov,ast@kernel.org,1703038006,d57714bbf760073e1542452360d88ebc854d443b,c5a7244759b1eeacc59d0426fb73859afa942d0d,"bpf: reuse subprog argument parsing logic for subprog call checks

Remove duplicated BTF parsing logic when it comes to subprog call check.
Instead"," use (potentially cached) results of btf_prepare_func_args() to
abstract away expectations of each subprog argument in generic terms
(e.g.","[' ""this is pointer to context""', ' or ""this is a pointer to memory of\nsize X"")', ' and then use those simple high-level argument type\nexpectations to validate actual register states to check if they match\nexpectations.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231215011334.2307144-6-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit removes duplicated BTF parsing logic for subprogram call checks and improves argument parsing.,"BTF, parsing, subprog",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c5a7244759b1eeacc59d0426fb73859afa942d0d,c5a7244759b1eeacc59d0426fb73859afa942d0d,Andrii Nakryiko,andrii@kernel.org,1702602808,Alexei Starovoitov,ast@kernel.org,1703038006,bdc7b9d4e0dc6d2d81f457fdb87a9209b7597d75,e26080d0da87f20222ca6712b65f95a856fadee0,"bpf: move subprog call logic back to verifier.c

Subprog call logic in btf_check_subprog_call() currently has both a lot
of BTF parsing logic (which is", presumably,"[' what justified putting it\ninto btf.c)', ' but also a bunch of register state checks', ' some of each\nutilize deep verifier logic helpers', ' necessarily exported from\nverifier.c: check_ptr_off_reg()', ' check_func_arg_reg_off()', '\nand check_mem_reg().\n\nGoing forward', ' btf_check_subprog_call() will have a minimum of\nBTF-related logic', ' but will get more internal verifier logic related to\nregister state manipulation. So move it into verifier.c to minimize\namount of verifier-specific logic exposed to btf.c.\n\nWe do this move before refactoring btf_check_func_arg_match() to\npreserve as much history post-refactoring as possible.\n\nNo functional changes.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231215011334.2307144-5-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit moves subprogram call logic back to verifier.c to separate it from BTF parsing logic.,"subprog, verifier, BTF",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e26080d0da87f20222ca6712b65f95a856fadee0,e26080d0da87f20222ca6712b65f95a856fadee0,Andrii Nakryiko,andrii@kernel.org,1702602807,Alexei Starovoitov,ast@kernel.org,1703038006,9640fff87f7876017c029fdc24cdce42b91e1f93,5eccd2db42d77e3570619c32d39e39bf486607cf,"bpf: prepare btf_prepare_func_args() for handling static subprogs

Generalize btf_prepare_func_args() to support both global and static
subprogs. We are going to utilize this property in the next patch","
reusing btf_prepare_func_args() for subprog call logic instead of
reparsing BTF information in a completely separate implementation.

btf_prepare_func_args() now detects whether subprog is global or static
makes slight logic adjustments for static func cases","[' like not failing\nfatally (-EFAULT) for conditions that are allowable for static subprogs.\n\nSomewhat subtle (but major!) difference is the handling of pointer arguments.\nBoth global and static functions need to handle special context\narguments (which are pointers to predefined type names)', ' but static\nsubprogs give up on any other pointers', ' falling back to marking subprog\nas ""unreliable""', ' disabling the use of BTF type information altogether.\n\nFor global functions', ' though', ' we are assuming that such pointers to\nunrecognized types are just pointers to fixed-sized memory region (or\nerror out if size cannot be established', ' like for `void *` pointers).\n\nThis patch accommodates these small differences and sets up a stage for\nrefactoring in the next patch', ' eliminating a separate BTF-based parsing\nlogic in btf_check_func_arg_match().\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231215011334.2307144-4-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Generalize btf_prepare_func_args() to support both global and static subprograms for BTF information parsing.,"BTF, subprog, function",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5eccd2db42d77e3570619c32d39e39bf486607cf,5eccd2db42d77e3570619c32d39e39bf486607cf,Andrii Nakryiko,andrii@kernel.org,1702602806,Alexei Starovoitov,ast@kernel.org,1703038006,95ed25214aa13ffbc8b9f4b9733dec093c6f4b53,4ba1d0f23414135e4f426dae4cb5cdc2ce246f89,"bpf: reuse btf_prepare_func_args() check for main program BTF validation

Instead of btf_check_subprog_arg_match()"," use btf_prepare_func_args()
logic to validate ""trustworthiness"" of main BPF program's BTF information","['\nif it is present.\n\nWe ignored results of original BTF check anyway', ' often times producing\nconfusing and ominously-sounding ""reg type unsupported for arg#0\nfunction"" message', ' which has no apparent effect on program correctness\nand verification process.\n\nAll the -EFAULT returning sanity checks are already performed in\ncheck_btf_info_early()', "" so there is zero reason to have this duplication\nof logic between btf_check_subprog_call() and btf_check_subprog_arg_match().\nDropping btf_check_subprog_arg_match() simplifies\nbtf_check_func_arg_match() further removing `bool processing_call` flag.\n\nOne subtle bit that was done by btf_check_subprog_arg_match() was\npotentially marking main program's BTF as unreliable. We do this\nexplicitly now with a dedicated simple check"", ' preserving the original\nbehavior', ' but now based on well factored btf_prepare_func_args() logic.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231215011334.2307144-3-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit improves main BPF program BTF validation by reusing btf_prepare_func_args() check.,"BPF,BTF,validation",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4ba1d0f23414135e4f426dae4cb5cdc2ce246f89,4ba1d0f23414135e4f426dae4cb5cdc2ce246f89,Andrii Nakryiko,andrii@kernel.org,1702602805,Alexei Starovoitov,ast@kernel.org,1703038006,afd2128f045eed09c7d826b44ea423136c1f7369,c337f237291b41b308c80124236876cf66c77906,"bpf: abstract away global subprog arg preparation logic from reg state setup

btf_prepare_func_args() is used to understand expectations and
restrictions on global subprog arguments. But current implementation is
hard to extend"," as it intermixes BTF-based func prototype parsing and
interpretation logic with setting up register state at subprog entry.

Worse still","[' those registers are not completely set up inside\nbtf_prepare_func_args()', ' requiring some more logic later in\ndo_check_common(). Like calling mark_reg_unknown() and similar\ninitialization operations.\n\nThis intermixing of BTF interpretation and register state setup is\nproblematic. First', ' it causes duplication of BTF parsing logic for global\nsubprog verification (to set up initial state of global subprog) and\nglobal subprog call sites analysis (when we need to check that whatever\nis being passed into global subprog matches expectations)', ' performed in\nbtf_check_subprog_call().\n\nGiven we want to extend global func argument with tags later', ' this\nduplication is problematic. So refactor btf_prepare_func_args() to do\nonly BTF-based func proto and args parsing', ' returning high-level\nargument ""expectations"" only', ' with no regard to specifics of register\nstate. I.e.', "" if it's a context argument"", ' instead of setting register\nstate to PTR_TO_CTX', ' we return ARG_PTR_TO_CTX enum for that argument as\n""an argument specification"" for further processing inside\ndo_check_common(). Similarly for SCALAR arguments', ' PTR_TO_MEM', ' etc.\n\nThis allows to reuse btf_prepare_func_args() in following patches at\nglobal subprog call site analysis time. It also keeps register setup\ncode consistently in one place', ' do_check_common().\n\nBesides all this', ' we cache this argument specs information inside\nenv->subprog_info', ' eliminating the need to redo these potentially\nexpensive BTF traversals', "" especially if BPF program's BTF is big and/or\nthere are lots of global subprog calls.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231215011334.2307144-2-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Refactor global subprog argument handling logic for better extensibility in bpf.,"global subprog, argument, extensibility",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c337f237291b41b308c80124236876cf66c77906,c337f237291b41b308c80124236876cf66c77906,Alexei Starovoitov,ast@kernel.org,1703035136,Alexei Starovoitov,ast@kernel.org,1703035136,0d1fa15dd3ee74bc0af37143406f7d19e8a3dddc,1728df7fc11bf09322852ff05e73908244011594 463ea64eb008b7abb63245ed69446b404bf042b1,"Merge branch 'bpf-support-to-track-bpf_jne'

Menglong Dong says:

====================
bpf: support to track BPF_JNE

For now", the reg bounds is not handled for BPF_JNE case,"[' which can cause\nthe failure of following case:\n\n  /* The type of ""a"" is u32 */\n  if (a > 0 && a < 100) {\n    /* the range of the register for a is [0', ' 99]', ' not [1', ' 99]', '\n     * and will cause the following error:\n     *\n     *   invalid zero-sized read\n     *\n     * as a can be 0.\n     */\n    bpf_skb_store_bytes(skb', ' xx', ' xx', ' a', ' 0);\n  }\n\nIn the code above', ' ""a > 0"" will be compiled to ""if a == 0 goto xxx"". In\nthe TRUE branch', ' the dst_reg will be marked as known to 0. However', ' in the\nfallthrough(FALSE) branch', ' the dst_reg will not be handled', ' which makes\nthe [min', ' max] for a is [0', ' 99]', ' not [1', ' 99].\n\nIn the 1st patch', ' we reduce the range of the dst reg if the src reg is a\nconst and is exactly the edge of the dst reg For BPF_JNE.\n\nIn the 2nd patch', ' we remove reduplicated s32 casting in ""crafted_cases"".\n\nIn the 3rd patch', ' we just activate the test case for this logic in\nrange_cond()', ' which is committed by Andrii in the\ncommit 8863238993e2 (""selftests/bpf: BPF register range bounds tester"").\n\nIn the 4th patch', ' we convert the case above to a testcase and add it to\nverifier_bounds.c.\n\nChanges since v4:\n- add the 2nd patch\n- add ""{U32', ' U32', ' {0', ' U32_MAX}', ' {U32_MAX', ' U32_MAX}}"" that we missed in the\n  3rd patch\n- add some comments to the function that we add in the 4th patch\n- add reg_not_equal_const() in the 4th patch\n\nChanges since v3:\n- do some adjustment to the crafted cases that we added in the 2nd patch\n- add the 3rd patch\n\nChanges since v2:\n- fix a typo in the subject of the 1st patch\n- add some comments to the 1st patch', ' as Eduard advised\n- add some cases to the ""crafted_cases""\n\nChanges since v1:\n- simplify the code in the 1st patch\n- introduce the 2nd patch for the testing\n====================\n\nLink: https://lore.kernel.org/r/20231219134800.1550388-1-menglong8.dong@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add support for tracking BPF_JNE instruction in the eBPF verifier.,"BPF_JNE, verifier, tracking",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
463ea64eb008b7abb63245ed69446b404bf042b1,463ea64eb008b7abb63245ed69446b404bf042b1,Menglong Dong,menglong8.dong@gmail.com,1702993680,Alexei Starovoitov,ast@kernel.org,1703035136,0d1fa15dd3ee74bc0af37143406f7d19e8a3dddc,31d9cc96b1e3b28daf74938cb1233231474bbcf6,"selftests/bpf: add testcase to verifier_bounds.c for BPF_JNE

Add testcase for the logic that the verifier tracks the BPF_JNE for regs.
The assembly function ""reg_not_equal_const()"" and ""reg_equal_const"" that
we add is exactly converted from the following case:

  u32 a = bpf_get_prandom_u32();
  u64 b = 0;

  a %= 8;
  /* the ""a > 0"" here will be optimized to ""a != 0"" */
  if (a > 0) {
    /* now the range of a should be [1"," 7] */
    bpf_skb_store_bytes(skb","[' 0', ' &b', ' a', ' 0);\n  }\n\nSigned-off-by: Menglong Dong <menglong8.dong@gmail.com>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231219134800.1550388-5-menglong8.dong@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Added new test case in selftests for BPF_JNE behavior in verifier_bounds.c.,"testcase,BPF_JNE,verifier",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
31d9cc96b1e3b28daf74938cb1233231474bbcf6,31d9cc96b1e3b28daf74938cb1233231474bbcf6,Menglong Dong,menglong8.dong@gmail.com,1702993679,Alexei Starovoitov,ast@kernel.org,1703035135,6d98c10a4b818287d05d9f22f132ad77ca72c650,1de584832375d0dc4234ee406185384a58fb96ac,"selftests/bpf: activate the OP_NE logic in range_cond()

The edge range checking for the registers is supported by the verifier
now"," so we can activate the extended logic in
tools/testing/selftests/bpf/prog_tests/reg_bounds.c/range_cond() to test
such logic.

Besides","[' I added some cases to the ""crafted_cases"" array for this logic.\nThese cases are mainly used to test the edge of the src reg and dst reg.\n\nAll reg bounds testings has passed in the SLOW_TESTS mode:\n\n$ export SLOW_TESTS=1 && ./test_progs -t reg_bounds -j\nSummary: 65/18959832 PASSED', ' 0 SKIPPED', ' 0 FAILED\n\nSigned-off-by: Menglong Dong <menglong8.dong@gmail.com>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231219134800.1550388-4-menglong8.dong@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit activates the OP_NE logic in range_cond() for testing edge range checking in the BPF verifier.,"OP_NE, range_cond, verifier",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1de584832375d0dc4234ee406185384a58fb96ac,1de584832375d0dc4234ee406185384a58fb96ac,Menglong Dong,menglong8.dong@gmail.com,1702993678,Alexei Starovoitov,ast@kernel.org,1703035135,4c5180c94ff7a7c64e7ceaa4e316ca4550a6102b,d028f87517d6775dccff4ddbca2740826f9e53f1,"selftests/bpf: remove reduplicated s32 casting in ""crafted_cases""

The ""S32_MIN"" is already defined with s32 casting"," so there is no need
to do it again.

Signed-off-by: Menglong Dong <menglong8.dong@gmail.com>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231219134800.1550388-3-menglong8.dong@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Removed redundant s32 casting in selftests/bpf 'crafted_cases'.,"reduplicated,s32,casting",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d028f87517d6775dccff4ddbca2740826f9e53f1,d028f87517d6775dccff4ddbca2740826f9e53f1,Menglong Dong,menglong8.dong@gmail.com,1702993677,Alexei Starovoitov,ast@kernel.org,1703035135,809dc8109b72c5ec379d41ed5ff6b928e74c24ee,1728df7fc11bf09322852ff05e73908244011594,"bpf: make the verifier tracks the ""not equal"" for regs

We can derive some new information for BPF_JNE in regs_refine_cond_op().
Take following code for example:

  /* The type of ""a"" is u32 */
  if (a > 0 && a < 100) {
    /* the range of the register for a is [0", 99],"[' not [1', ' 99]', '\n     * and will cause the following error:\n     *\n     *   invalid zero-sized read\n     *\n     * as a can be 0.\n     */\n    bpf_skb_store_bytes(skb', ' xx', ' xx', ' a', ' 0);\n  }\n\nIn the code above', ' ""a > 0"" will be compiled to ""jmp xxx if a == 0"". In the\nTRUE branch', ' the dst_reg will be marked as known to 0. However', ' in the\nfallthrough(FALSE) branch', ' the dst_reg will not be handled', ' which makes\nthe [min', ' max] for a is [0', ' 99]', ' not [1', ' 99].\n\nFor BPF_JNE', ' we can reduce the range of the dst reg if the src reg is a\nconst and is exactly the edge of the dst reg.\n\nSigned-off-by: Menglong Dong <menglong8.dong@gmail.com>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nLink: https://lore.kernel.org/r/20231219134800.1550388-2-menglong8.dong@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Improve the eBPF verifier to track 'not equal' conditions for register refinements.,"verifier, BPF_JNE, refine",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1728df7fc11bf09322852ff05e73908244011594,1728df7fc11bf09322852ff05e73908244011594,Paolo Abeni,pabeni@redhat.com,1703007328,Paolo Abeni,pabeni@redhat.com,1703007328,ea7b744713df95ad4abeba79cb10ef3dbd4c4730,62ed78f3baff396bd928ee77077580c5aa940149 d17aff807f845cf93926c28705216639c7279110,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next

Daniel Borkmann says:

====================
pull-request: bpf-next 2023-12-19

Hi David", hi Jakub,"[' hi Paolo', ' hi Eric', ""\n\nThe following pull-request contains BPF updates for your *net-next* tree.\n\nWe've added 2 non-merge commits during the last 1 day(s) which contain\na total of 40 files changed"", ' 642 insertions(+)', ' 2926 deletions(-).\n\nThe main changes are:\n\n1) Revert all of BPF token-related patches for now as per list discussion [0]', '\n   from Andrii Nakryiko.\n\n   [0] https://lore.kernel.org/bpf/CAHk-=wg7JuFYwGy=GOMbRCtOL+jwSQsdUaBsRWkDVYbxipbM5A@mail.gmail.com\n\n2) Fix a syzbot-reported use-after-free read in nla_find() triggered from\n   bpf_skb_get_nlattr_nest() helper', "" from Jakub Kicinski.\n\nbpf-next-for-netdev\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next:\n  Revert BPF token-related functionality\n  bpf: Use nla_ok() instead of checking nla_len directly\n====================\n\nLink: https://lore.kernel.org/r/20231219170359.11035-1-daniel@iogearbox.net\nSigned-off-by: Paolo Abeni <pabeni@redhat.com>\n"", '']",Merge updates from the bpf-next branch into the main branch.,"merge,bpf-next,update",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d17aff807f845cf93926c28705216639c7279110,d17aff807f845cf93926c28705216639c7279110,Andrii Nakryiko,andrii@kernel.org,1703000255,Andrii Nakryiko,andrii@kernel.org,1703002983,2c7baaedac92384e2d4d083ddebfba920b3390ae,2130c519a401e576647040043cb46d6fdc361dcc,"Revert BPF token-related functionality

This patch includes the following revert (one  conflicting BPF FS
patch and three token patch sets"," represented by merge commits):
  - revert 0f5d5454c723 ""Merge branch 'bpf-fs-mount-options-parsing-follow-ups'"";
  - revert 750e785796bb ""bpf: Support uid and gid when mounting bpffs"";
  - revert 733763285acf ""Merge branch 'bpf-token-support-in-libbpf-s-bpf-object'"";
  - revert c35919dcce28 ""Merge branch 'bpf-token-and-bpf-fs-based-delegation'"".

Link: https://lore.kernel.org/bpf/CAHk-=wg7JuFYwGy=GOMbRCtOL+jwSQsdUaBsRWkDVYbxipbM5A@mail.gmail.com
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
",[''],Revert BPF token-related functionality due to conflicting changes in BPF FS and token patch sets.,"revert, BPF token, conflict",It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['other']
2130c519a401e576647040043cb46d6fdc361dcc,2130c519a401e576647040043cb46d6fdc361dcc,Jakub Kicinski,kuba@kernel.org,1702941544,Daniel Borkmann,daniel@iogearbox.net,1702995640,23eabf7884fd7854517ff7632c6667abb290fee5,f7dd48ea76be30666f0614d6a06061185ed38c60,"bpf: Use nla_ok() instead of checking nla_len directly

nla_len may also be too short to be sane"," in which case after
recent changes nla_len() will return a wrapped value.

Fixes: 172db56d90d2 (""netlink: Return unsigned value for nla_len()"")
Reported-by: syzbot+f43a23b6e622797c7a28@syzkaller.appspotmail.com
Signed-off-by: Jakub Kicinski <kuba@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Reviewed-by: Simon Horman <horms@kernel.org>
Link: https://lore.kernel.org/bpf/20231218231904.260440-1-kuba@kernel.org
",[''],Fix issue with nlattr length checking by using nla_ok() to ensure valid checks in eBPF.,"nla_ok,nla_len,eBPF",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The syscall interface,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
624dda101e03c3a3a155d51e37a7bb7607cb760b,624dda101e03c3a3a155d51e37a7bb7607cb760b,Veronika Molnarova,vmolnaro@redhat.com,1702400348,Arnaldo Carvalho de Melo,acme@redhat.com,1702993699,065d9b9d8a84077a3c4c483c0add835734d85429,ab1c247094e323177a578b38f0325bf79f0317ac,"perf archive: Add new option '--all' to pack perf.data with DSOs

'perf archive' has limited functionality and people from Red Hat Global
Support Services sent a request for a new feature that would pack
perf.data file together with an archive with debug symbols created by
the command 'perf archive' as customers were being confused and often
would forget to send perf.data file with the debug symbols.

With this patch 'perf archive' now accepts an option '--all' that
generates archive 'perf.all-hostname-date-time.tar.bz2' that holds file
'perf.data' and a sub-tar 'perf.symbols.tar.bz2' with debug symbols. The
functionality of the command 'perf archive' was not changed.

Committer testing:

Run 'perf record' on a Intel 14900K machine"," hybrid:

  root@number:~# perf record -a sleep 5s
  [ perf record: Woken up 1 times to write data ]
  [ perf record: Captured and wrote 4.006 MB perf.data (15427 samples) ]
  root@number:~# perf archive --all
  Now please run:

  $ tar xvf perf.all-number-20231219-104854.tar.bz2 && tar xvf perf.symbols.tar.bz2 -C ~/.debug

  wherever you need to run 'perf report' on.
  root@number:~#

  root@number:~# perf report --header-only
  # ========
  # captured on    : Tue Dec 19 10:48:48 2023
  # header version : 1
  # data offset    : 1008
  # data size      : 4199936
  # feat offset    : 4200944
  # hostname : number
  # os release : 6.6.4-200.fc39.x86_64
  # perf version : 6.7.rc6.gca90f8e17b84
  # arch : x86_64
  # nrcpus online : 28
  # nrcpus avail : 28
  # cpudesc : Intel(R) Core(TM) i7-14700K
  # cpuid : GenuineIntel","['6', '183', '1\n  # total memory : 32610508 kB\n  # cmdline : /home/acme/bin/perf (deleted) record -a sleep 5s\n  # event : name = cpu_atom/cycles/P', ' ', ' id = { 5088024', ' 5088025', ' 5088026', ' 5088027', ' 5088028', ' 5088029', ' 5088030', ' 5088031', ' 5088032', ' 5088033', ' 5088034', ' 5088035 }', ' type = 0 (PERF_TYPE_HARDWARE)', ' size>\n  # event : name = cpu_core/cycles/P', ' ', ' id = { 5088036', ' 5088037', ' 5088038', ' 5088039', ' 5088040', ' 5088041', ' 5088042', ' 5088043', ' 5088044', ' 5088045', ' 5088046', ' 5088047', ' 5088048', ' 5088049', ' 5088050', ' 5088051 }', '>\n  # event : name = dummy:u', ' ', ' id = { 5088052', ' 5088053', ' 5088054', ' 5088055', ' 5088056', ' 5088057', ' 5088058', ' 5088059', ' 5088060', ' 5088061', ' 5088062', ' 5088063', ' 5088064', ' 5088065', ' 5088066', ' 5088067', ' 5088068', ' 50>\n  # CPU_TOPOLOGY info available', ' use -I to display\n  # NUMA_TOPOLOGY info available', ' use -I to display\n  # pmu mappings: cpu_atom = 10', ' cpu_core = 4', ' breakpoint = 5', ' cstate_core = 34', ' cstate_pkg = 35', ' i915 = 14', ' intel_bts = 11', ' intel_pt = 12', ' kprobe = 8', ' msr = 13', ' power = 36', ' software = 1', ' trac>\n  # CACHE info available', ' use -I to display\n  # time of first sample : 124739.850375\n  # time of last sample : 124744.855181\n  # sample duration :   5004.806 ms\n  # sample duration :   5004.806 ms\n  # MEM_TOPOLOGY info available', ' use -I to display\n  # bpf_prog_info 2: bpf_prog_7cc47bbf07148bfe_hid_tail_call addr 0xffffffffc0000978 size 113\n  # bpf_prog_info 47: bpf_prog_713a545fe0530ce7_restrict_filesystems addr 0xffffffffc0000748 size 305\n  # bpf_prog_info 163: bpf_prog_bd834b0730296056 addr 0xffffffffc000df14 size 331\n  # bpf_prog_info 258: bpf_prog_ee0e253c78993a24_sd_devices addr 0xffffffffc001fc08 size 264\n  # bpf_prog_info 259: bpf_prog_40ddf486530245f5_sd_devices addr 0xffffffffc00204bc size 318\n  # bpf_prog_info 260: bpf_prog_6deef7357e7b4530_sd_fw_egress addr 0xffffffffc0020630 size 63\n  # bpf_prog_info 261: bpf_prog_6deef7357e7b4530_sd_fw_ingress addr 0xffffffffc0020688 size 63\n  # bpf_prog_info 262: bpf_prog_b37200ab714f0e17_sd_devices addr 0xffffffffc002072c size 110\n  # bpf_prog_info 263: bpf_prog_b90a282ee45cfed9_sd_devices addr 0xffffffffc00207d8 size 393\n  # bpf_prog_info 264: bpf_prog_ee0e253c78993a24_sd_devices addr 0xffffffffc002099c size 264\n  # bpf_prog_info 265: bpf_prog_6deef7357e7b4530_sd_fw_egress addr 0xffffffffc0020ad4 size 63\n  # bpf_prog_info 266: bpf_prog_6deef7357e7b4530_sd_fw_ingress addr 0xffffffffc0020b50 size 63\n  # bpf_prog_info 267: bpf_prog_ee0e253c78993a24_sd_devices addr 0xffffffffc002d98c size 264\n  # bpf_prog_info 268: bpf_prog_be31ae23198a0378_sd_devices addr 0xffffffffc002dac8 size 297\n  # bpf_prog_info 269: bpf_prog_ccbbf91f3c6979c7_sd_devices addr 0xffffffffc002dc54 size 360\n  # bpf_prog_info 270: bpf_prog_3a0ef5414c2f6fca_sd_devices addr 0xffffffffc002dde8 size 456\n  # bpf_prog_info 271: bpf_prog_6deef7357e7b4530_sd_fw_egress addr 0xffffffffc0020bd4 size 63\n  # bpf_prog_info 272: bpf_prog_6deef7357e7b4530_sd_fw_ingress addr 0xffffffffc00299b4 size 63\n  # bpf_prog_info 273: bpf_prog_ee0e253c78993a24_sd_devices addr 0xffffffffc002dfd0 size 264\n  # bpf_prog_info 274: bpf_prog_6deef7357e7b4530_sd_fw_egress addr 0xffffffffc0029a3c size 63\n  # bpf_prog_info 275: bpf_prog_6deef7357e7b4530_sd_fw_ingress addr 0xffffffffc002d71c size 63\n  # bpf_prog_info 276: bpf_prog_6deef7357e7b4530_sd_fw_egress addr 0xffffffffc002d7a8 size 63\n  # bpf_prog_info 277: bpf_prog_6deef7357e7b4530_sd_fw_ingress addr 0xffffffffc002e13c size 63\n  # bpf_prog_info 278: bpf_prog_6deef7357e7b4530_sd_fw_egress addr 0xffffffffc002e1a8 size 63\n  # bpf_prog_info 279: bpf_prog_6deef7357e7b4530_sd_fw_ingress addr 0xffffffffc002e234 size 63\n  # bpf_prog_info 280: bpf_prog_be31ae23198a0378_sd_devices addr 0xffffffffc002e2ac size 297\n  # bpf_prog_info 281: bpf_prog_6deef7357e7b4530_sd_fw_egress addr 0xffffffffc002e42c size 63\n  # bpf_prog_info 282: bpf_prog_6deef7357e7b4530_sd_fw_ingress addr 0xffffffffc002e49c size 63\n  # bpf_prog_info 290: bpf_prog_ee0e253c78993a24_sd_devices addr 0xffffffffc0004b18 size 264\n  # bpf_prog_info 294: bpf_prog_0b1566e4b83190c5_sd_devices addr 0xffffffffc0004c50 size 360\n  # bpf_prog_info 295: bpf_prog_ee0e253c78993a24_sd_devices addr 0xffffffffc001cfc8 size 264\n  # bpf_prog_info 296: bpf_prog_6deef7357e7b4530_sd_fw_egress addr 0xffffffffc0013abc size 63\n  # bpf_prog_info 297: bpf_prog_6deef7357e7b4530_sd_fw_ingress addr 0xffffffffc0013b24 size 63\n  # btf info of id 2\n  # btf info of id 52\n  # HYBRID_TOPOLOGY info available', ' use -I to display\n  # cpu_atom pmu capabilities: branches=32', ' max_precise=3', ' pmu_name=alderlake_hybrid\n  # cpu_core pmu capabilities: branches=32', ' max_precise=3', ' pmu_name=alderlake_hybrid\n  # intel_pt pmu capabilities: topa_multiple_entries=1', ' psb_cyc=1', ' single_range_output=1', ' mtc_periods=249', ' ip_filtering=1', ' output_subsys=0', ' cr3_filtering=1', ' psb_periods=3f', ' event_trace=0', ' cycl>\n  # missing features: TRACING_DATA BRANCH_STACK GROUP_DESC AUXTRACE STAT CLOCKID DIR_FORMAT COMPRESSED CPU_PMU_CAPS CLOCK_DATA\n  # ========\n  #\n  root@number:~#\n\nAnd then transferring it to a ARM64 machine', "" a Libre Computer RK3399-PC:\n\n  root@number:~# scp perf.all-number-20231219-104854.tar.bz2 acme@192.168.86.114:.\n  acme@192.168.86.114's password:\n  perf.all-number-20231219-104854.tar.bz2                           100%  145MB  85.4MB/s   00:01\n  root@number:~#\n  root@number:~# ssh acme@192.168.86.114\n  acme@192.168.86.114's password:\n  Welcome to Ubuntu 23.04 (GNU/Linux 6.1.68-12200-g1c40dda3081e aarch64)\n\n   * Documentation:  https://help.ubuntu.com\n   * Management:     https://landscape.canonical.com\n   * Support:        https://ubuntu.com/advantage\n  Last login: Tue Dec 19 14:53:18 2023 from 192.168.86.42\n  acme@roc-rk3399-pc:~$ tar xvf perf.all-number-20231219-104854.tar.bz2 && tar xvf perf.symbols.tar.bz2 -C ~/.debug\n  perf.data\n  perf.symbols.tar.bz2\n  .build-id/ad/acc227f470409213308050b71f664322e2956c\n  [kernel.kallsyms]/adacc227f470409213308050b71f664322e2956c/\n  [kernel.kallsyms]/adacc227f470409213308050b71f664322e2956c/kallsyms\n  [kernel.kallsyms]/adacc227f470409213308050b71f664322e2956c/probes\n  .build-id/76/c91f4d62baa06bb52e07e20aba36d21a8f9797\n  usr/lib64/libz.so.1.2.13/76c91f4d62baa06bb52e07e20aba36d21a8f9797/\n  <SNIP>\n  .build-id/09/d7e96bc1e3f599d15ca28b36959124b2d74410\n  usr/lib64/librpm_sequoia.so.1/09d7e96bc1e3f599d15ca28b36959124b2d74410/\n  usr/lib64/librpm_sequoia.so.1/09d7e96bc1e3f599d15ca28b36959124b2d74410/elf\n  usr/lib64/librpm_sequoia.so.1/09d7e96bc1e3f599d15ca28b36959124b2d74410/probes\n  acme@roc-rk3399-pc:~$\n  acme@roc-rk3399-pc:~$ perf report --stdio | head -40\n  # To display the perf.data header info"", "" please use --header/--header-only options.\n  #\n  # Total Lost Samples: 0\n  #\n  # Samples: 6K of event 'cpu_atom/cycles/P'\n  # Event count (approx.): 4519946621\n  #\n  # Overhead  Command          Shared Object                                   Symbol\n  # ........  ...............  ..............................................  .........................................................................................................................................................\n  #\n       1.73%  swapper          [kernel.kallsyms]                               [k] intel_idle\n       1.43%  sh               [kernel.kallsyms]                               [k] next_uptodate_folio\n       0.94%  make             ld-linux-x86-64.so.2                            [.] do_lookup_x\n       0.90%  sh               ld-linux-x86-64.so.2                            [.] do_lookup_x\n       0.82%  sh               [kernel.kallsyms]                               [k] perf_event_mmap_output\n       0.74%  sh               [kernel.kallsyms]                               [k] filemap_map_pages\n       0.72%  sh               ld-linux-x86-64.so.2                            [.] _dl_relocate_object\n       0.69%  cc1              [kernel.kallsyms]                               [k] clear_page_erms\n       0.61%  sh               [kernel.kallsyms]                               [k] unmap_page_range\n       0.56%  swapper          [kernel.kallsyms]                               [k] poll_idle\n       0.52%  cc1              ld-linux-x86-64.so.2                            [.] do_lookup_x\n       0.47%  make             ld-linux-x86-64.so.2                            [.] _dl_relocate_object\n       0.44%  cc1              cc1                                             [.] make_node(tree_code)\n       0.43%  sh               [kernel.kallsyms]                               [k] native_irq_return_iret\n       0.38%  sh               libc.so.6                                       [.] _int_malloc\n       0.38%  cc1              cc1                                             [.] decl_attributes(tree_node**"", ' tree_node*', ' int', ' tree_node*)\n       0.38%  sh               [kernel.kallsyms]                               [k] clear_page_erms\n       0.37%  cc1              cc1                                             [.] ht_lookup_with_hash(ht*', ' unsigned char const*', ' unsigned long', ' unsigned int', ' ht_lookup_option)\n       0.37%  make             [kernel.kallsyms]                               [k] perf_event_mmap_output\n       0.37%  make             ld-linux-x86-64.so.2                            [.] _dl_lookup_symbol_x\n       0.35%  sh               [kernel.kallsyms]                               [k] _compound_head\n       0.35%  make             make                                            [.] hash_find_slot\n       0.33%  sh               libc.so.6                                       [.] __strlen_avx2\n       0.33%  cc1              cc1                                             [.] ggc_internal_alloc(unsigned long', ' void (*)(void*)', ' unsigned long', ' unsigned long)\n       0.33%  sh               [kernel.kallsyms]                               [k] perf_iterate_ctx\n       0.31%  make             make                                            [.] jhash_string\n       0.31%  sh               [kernel.kallsyms]                               [k] page_remove_rmap\n       0.30%  cc1              libc.so.6                                       [.] _int_malloc\n       0.30%  make             libc.so.6                                       [.] _int_malloc\n  acme@roc-rk3399-pc:~$\n\nSigned-off-by: Veronika Molnarova <vmolnaro@redhat.com>\nTested-by: Arnaldo Carvalho de Melo <acme@redhat.com>\nCc: Michael Petlan <mpetlan@redhat.com>\nLink: https://lore.kernel.org/r/20231212165909.14459-1-vmolnaro@redhat.com\nSigned-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>\n', '']",Add '--all' option to 'perf archive' for packing perf.data with debug symbols.,perf archive option,It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
c49b292d031e385abf764ded32cd953c77e73f2d,c49b292d031e385abf764ded32cd953c77e73f2d,Jakub Kicinski,kuba@kernel.org,1702946767,Jakub Kicinski,kuba@kernel.org,1702946768,3f13748b32a3c273c5315286a3acaf45447a5437,0ee28c9ae042e77100fae2cd82a54750668aafce 8e432e6197cef6250dfd6fdffd41c06613c874ca,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next

Alexei Starovoitov says:

====================
pull-request: bpf-next 2023-12-18

This PR is larger than usual and contains changes in various parts
of the kernel.

The main changes are:

1) Fix kCFI bugs in BPF"," from Peter Zijlstra.

End result: all forms of indirect calls from BPF into kernel
and from kernel into BPF work with CFI enabled. This allows BPF
to work with CONFIG_FINEIBT=y.

2) Introduce BPF token object","[' from Andrii Nakryiko.\n\nIt adds an ability to delegate a subset of BPF features from privileged\ndaemon (e.g.', ' systemd) through special mount options for userns-bound\nBPF FS to a trusted unprivileged application. The design accommodates\nsuggestions from Christian Brauner and Paul Moore.\n\nExample:\n$ sudo mkdir -p /sys/fs/bpf/token\n$ sudo mount -t bpf bpffs /sys/fs/bpf/token \\\n             -o delegate_cmds=prog_load:MAP_CREATE \\\n             -o delegate_progs=kprobe \\\n             -o delegate_attachs=xdp\n\n3) Various verifier improvements and fixes', ' from Andrii Nakryiko', ' Andrei Matei.\n\n - Complete precision tracking support for register spills\n - Fix verification of possibly-zero-sized stack accesses\n - Fix access to uninit stack slots\n - Track aligned STACK_ZERO cases as imprecise spilled registers.\n   It improves the verifier ""instructions processed"" metric from single\n   digit to 50-60% for some programs.\n - Fix verifier retval logic\n\n4) Support for VLAN tag in XDP hints', ' from Larysa Zaremba.\n\n5) Allocate BPF trampoline via bpf_prog_pack mechanism', ' from Song Liu.\n\nEnd result: better memory utilization and lower I$ miss for calls to BPF\nvia BPF trampoline.\n\n6) Fix race between BPF prog accessing inner map and parallel delete', '\nfrom Hou Tao.\n\n7) Add bpf_xdp_get_xfrm_state() kfunc', ' from Daniel Xu.\n\nIt allows BPF interact with IPSEC infra. The intent is to support\nsoftware RSS (via XDP) for the upcoming ipsec pcpu work.\nExperiments on AWS demonstrate single tunnel pcpu ipsec reaching\nline rate on 100G ENA nics.\n\n8) Expand bpf_cgrp_storage to support cgroup1 non-attach', ' from Yafang Shao.\n\n9) BPF file verification via fsverity', "" from Song Liu.\n\nIt allows BPF progs get fsverity digest.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next: (164 commits)\n  bpf: Ensure precise is reset to false in __mark_reg_const_zero()\n  selftests/bpf: Add more uprobe multi fail tests\n  bpf: Fail uprobe multi link with negative offset\n  selftests/bpf: Test the release of map btf\n  s390/bpf: Fix indirect trampoline generation\n  selftests/bpf: Temporarily disable dummy_struct_ops test on s390\n  x86/cfi"", 'bpf: Fix bpf_exception_cb() signature\n  bpf: Fix dtor CFI\n  cfi: Add CFI_NOSEAL()\n  x86/cfi', 'bpf: Fix bpf_struct_ops CFI\n  x86/cfi', 'bpf: Fix bpf_callback_t CFI\n  x86/cfi', ""bpf: Fix BPF JIT call\n  cfi: Flip headers\n  selftests/bpf: Add test for abnormal cnt during multi-kprobe attachment\n  selftests/bpf: Don't use libbpf_get_error() in kprobe_multi_test\n  selftests/bpf: Add test for abnormal cnt during multi-uprobe attachment\n  bpf: Limit the number of kprobes when attaching program to multiple kprobes\n  bpf: Limit the number of uprobes when attaching program to multiple uprobes\n  bpf: xdp: Register generic_kfunc_set with XDP programs\n  selftests/bpf: utilize string values for delegate_xxx mount options\n  ...\n====================\n\nLink: https://lore.kernel.org/r/20231219000520.34178-1-alexei.starovoitov@gmail.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n"", '']",The commit merges changes including a fix for kCFI bugs and the introduction of the BPF token object.,"kCFI, BPF, token",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8e432e6197cef6250dfd6fdffd41c06613c874ca,8e432e6197cef6250dfd6fdffd41c06613c874ca,Andrii Nakryiko,andrii@kernel.org,1702920961,Daniel Borkmann,daniel@iogearbox.net,1702940061,441e472f39005b2d9a16b69dba9b6b40d726f322,6079ae6376181b49c9e4d65ef9fe954cca4974bd,"bpf: Ensure precise is reset to false in __mark_reg_const_zero()

It is safe to always start with imprecise SCALAR_VALUE register.
Previously __mark_reg_const_zero() relied on caller to reset precise
mark"," but it's very error prone and we already missed it in a few
places. So instead make __mark_reg_const_zero() reset precision always","[""\nas it's a safe default for SCALAR_VALUE. Explanation is basically the\nsame as for why we are resetting (or rather not setting) precision in\ncurrent state. If necessary"", ' precision propagation will set it to\nprecise correctly.\n\nAs such', ' also remove a big comment about forward precision propagation\nin mark_reg_stack_read() and avoid unnecessarily setting precision to\ntrue after reading from STACK_ZERO stack. Again', ' precision propagation\nwill correctly handle this', ' if that SCALAR_VALUE register will ever be\nneeded to be precise.\n\nReported-by: Maxim Mikityanskiy <maxtram95@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nAcked-by: Maxim Mikityanskiy <maxtram95@gmail.com>\nAcked-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20231218173601.53047-1-andrii@kernel.org\n', '']",The commit ensures precision is reset to false in __mark_reg_const_zero() to avoid error prone reliance on callers.,"precision,register,reset",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6079ae6376181b49c9e4d65ef9fe954cca4974bd,6079ae6376181b49c9e4d65ef9fe954cca4974bd,Andrii Nakryiko,andrii@kernel.org,1702921891,Andrii Nakryiko,andrii@kernel.org,1702921937,ac054e373cabd2fb9288318c7d58c34489a60c4c,e58aac1a9a179fa9dab3025ef955cdb548c439f2 f17d1a18a3dd6cc4b38a5226b0acbbad3f2063ae,"Merge branch 'bpf-add-check-for-negative-uprobe-multi-offset'

Jiri Olsa says:

====================
bpf: Add check for negative uprobe multi offset

hi","
adding the check for negative offset for uprobe multi link.

v2 changes:
- add more failure checks [Alan]
- move the offset retrieval/check up in the loop to be done earlier [Song]

thanks","['\njirka\n---\n====================\n\nLink: https://lore.kernel.org/r/20231217215538.3361991-1-jolsa@kernel.org\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n', '']",Add a check for negative offset in uprobe multi-links in eBPF.,"check,offset,uprobe",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
f17d1a18a3dd6cc4b38a5226b0acbbad3f2063ae,f17d1a18a3dd6cc4b38a5226b0acbbad3f2063ae,Jiri Olsa,jolsa@kernel.org,1702850138,Andrii Nakryiko,andrii@kernel.org,1702921910,ac054e373cabd2fb9288318c7d58c34489a60c4c,3983c00281d96af2ba611254d679107b5c390627,"selftests/bpf: Add more uprobe multi fail tests

We fail to create uprobe if we pass negative offset. Add more tests
validating kernel-side error checking code.

Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Song Liu <song@kernel.org>
Link: https://lore.kernel.org/bpf/20231217215538.3361991-3-jolsa@kernel.org
",,Add additional uprobe multi fail tests to ensure kernel-side error checking for negative offsets.,"uprobe,multi fail,tests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
3983c00281d96af2ba611254d679107b5c390627,3983c00281d96af2ba611254d679107b5c390627,Jiri Olsa,jolsa@kernel.org,1702850137,Andrii Nakryiko,andrii@kernel.org,1702921890,61813969a52053d327d24a86eb8dac978853f4a0,e58aac1a9a179fa9dab3025ef955cdb548c439f2,"bpf: Fail uprobe multi link with negative offset

Currently the __uprobe_register will return 0 (success) when called with
negative offset. The reason is that the call to register_for_each_vma and
then build_map_info won't return error for negative offset. They just won't
do anything - no matching vma is found so there's no registered breakpoint
for the uprobe.

I don't think we can change the behaviour of __uprobe_register and fail
for negative uprobe offset"," because apps might depend on that already.

But I think we can still make the change and check for it on bpf multi
link syscall level.

Also moving the __get_user call and check for the offsets to the top of
loop","[' to fail early without extra __get_user calls for ref_ctr_offset\nand cookie arrays.\n\nSigned-off-by: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Song Liu <song@kernel.org>\nLink: https://lore.kernel.org/bpf/20231217215538.3361991-2-jolsa@kernel.org\n', '']",The commit enforces error checks for negative offsets in uprobe multi link syscalls to prevent unnoticed success responses.,"uprobe,negative offset,syscall",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The syscall interface,['kprobe/uprobe/ftrace like programs']
e58aac1a9a179fa9dab3025ef955cdb548c439f2,e58aac1a9a179fa9dab3025ef955cdb548c439f2,Hou Tao,houtao1@huawei.com,1702698910,Daniel Borkmann,daniel@iogearbox.net,1702919749,b65884e81cb7e69ee23755fde1b1c9a34ac2582e,0c970ed2f87c058fe3ddeb4d7d8f64f72cf41d7a,"selftests/bpf: Test the release of map btf

When there is bpf_list_head or bpf_rb_root field in map value"," the free
of map btf and the free of map value may run concurrently and there may
be use-after-free problem","[' so add two test cases to demonstrate it. And\nthe use-after-free problem can been easily reproduced by using bpf_next\ntree and a KASAN-enabled kernel.\n\nThe first test case tests the racing between the free of map btf and the\nfree of array map. It constructs the racing by releasing the array map in\nthe end after other ref-counter of map btf has been released. To delay\nthe free of array map and make it be invoked after btf_free_rcu() is\ninvoked', ' it stresses system_unbound_wq by closing multiple percpu array\nmaps before it closes the array map.\n\nThe second case tests the racing between the free of map btf and the\nfree of inner map. Beside using the similar method as the first one\ndoes', ' it uses bpf_map_delete_elem() to delete the inner map and to defer\nthe release of inner map after one RCU grace period.\n\nThe reason for using two skeletons is to prevent the release of outer\nmap and inner map in map_in_map_btf.c interfering the release of bpf\nmap in normal_map_btf.c.\n\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/bpf/20231216035510.4030605-1-houtao@huaweicloud.com\n', '']",Add test cases to check for use-after-free issues in map BTF with bpf_list_head and bpf_rb_root fields.,selftests use-after-free map,It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0c970ed2f87c058fe3ddeb4d7d8f64f72cf41d7a,0c970ed2f87c058fe3ddeb4d7d8f64f72cf41d7a,Alexei Starovoitov,ast@kernel.org,1702687549,Daniel Borkmann,daniel@iogearbox.net,1702897237,fbc54c4fe55753c3fb80e6832782007a0f6ef186,42d45c45624a098a9fdc477c7a8b86167f948c77,"s390/bpf: Fix indirect trampoline generation

The func_addr used to be NULL for indirect trampolines used by struct_ops.
Now func_addr is a valid function pointer.
Hence use BPF_TRAMP_F_INDIRECT flag to detect such condition.

Fixes: 2cd3e3772e41 (""x86/cfi","bpf: Fix bpf_struct_ops CFI"")
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Reviewed-by: Ilya Leoshkevich <iii@linux.ibm.com>
Link: https://lore.kernel.org/bpf/20231216004549.78355-1-alexei.starovoitov@gmail.com
",[''],Fixes indirect trampoline generation for struct_ops in BPF on s390 architecture.,"indirect, trampoline, struct_ops",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
117211aa739a926e6555cfea883be84bee6f1695,117211aa739a926e6555cfea883be84bee6f1695,Jiri Olsa,jolsa@kernel.org,1702681502,Andrii Nakryiko,andrii@kernel.org,1702686852,e08e8f3efb34dec198c2549985e1a22fcf40a689,2f2fee2bf74a7e31d06fc6cb7ba2bd4dd7753c99,"bpf: Add missing BPF_LINK_TYPE invocations

Pengfei Xu reported [1] Syzkaller/KASAN issue found in bpf_link_show_fdinfo.

The reason is missing BPF_LINK_TYPE invocation for uprobe multi
link and for several other links"," adding that.

[1] https://lore.kernel.org/bpf/ZXptoKRSLspnk2ie@xpf.sh.intel.com/

Fixes: 89ae89f53d20 (""bpf: Add multi uprobe link"")
Fixes: e420bed02507 (""bpf: Add fd-based tcx multi-prog infra with link support"")
Fixes: 84601d6ee68a (""bpf: add bpf_link support for BPF_NETFILTER programs"")
Fixes: 35dfaad7188c (""netkit","[' bpf: Add bpf programmable net device"")\nReported-by: Pengfei Xu <pengfei.xu@intel.com>\nSigned-off-by: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nTested-by: Pengfei Xu <pengfei.xu@intel.com>\nAcked-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/bpf/20231215230502.2769743-1-jolsa@kernel.org\n', '']",Add missing BPF_LINK_TYPE invocations in bpf_link_show_fdinfo to fix Syzkaller/KASAN issue.,"BPF_LINK_TYPE, uprobe, Syzkaller",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['kprobe/uprobe/ftrace like programs', 'tc/netfilter like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
42d45c45624a098a9fdc477c7a8b86167f948c77,42d45c45624a098a9fdc477c7a8b86167f948c77,Alexei Starovoitov,ast@kernel.org,1702686505,Alexei Starovoitov,ast@kernel.org,1702686505,8be166cc613e6e2675ffea9383fb21e563f36002,3c302e14bd9d7698ea24885a7eee2b44c1a014be,"selftests/bpf: Temporarily disable dummy_struct_ops test on s390

Temporarily disable dummy_struct_ops test on s390.
The breakage is likely due to
commit 2cd3e3772e41 (""x86/cfi","bpf: Fix bpf_struct_ops CFI"").

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Temporarily disables dummy_struct_ops test on s390 architecture due to recent breakage.,"selftests,bpf,s390",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3c302e14bd9d7698ea24885a7eee2b44c1a014be,3c302e14bd9d7698ea24885a7eee2b44c1a014be,Alexei Starovoitov,ast@kernel.org,1702668291,Alexei Starovoitov,ast@kernel.org,1702686356,4599c7e80eb113dcf3bda5ea435e8c26b7e2a3bf,1467affd16b236fc86e1b8ec5eaa147e104cd2a6 852486b35f344887786d63250946dd921a05d7e8,"Merge branch 'x86-cfi-bpf-fix-cfi-vs-ebpf'

Peter Zijlstra says:

====================
x86/cfi","bpf: Fix CFI vs eBPF

Hi!

What started with the simple observation that bpf_dispatcher_*_func() was
broken for calling CFI functions with a __nocfi calling context for FineIBT
ended up with a complete BPF wide CFI fixup.

With these changes on the BPF selftest suite passes without crashing -- there's
still a few failures","[' but Alexei has graciously offered to look into those.\n\n(Alexei', ' I have presumed your SoB on the very last patch', ' please update\nas you see fit)\n\nChanges since v2 are numerous but include:\n - cfi_get_offset() -- as a means to communicate the offset (ast)\n - 5 new patches fixing various BPF internals to be CFI clean\n\nNote: it *might* be possible to merge the\nbpf_bpf_tcp_ca.c:unsupported_ops[] thing into the CFI stubs', ' as is\nget_info will have a NULL stub', ' unlike the others.\n---\n arch/riscv/include/asm/cfi.h   |   3 +-\n arch/riscv/kernel/cfi.c        |   2 +-\n arch/x86/include/asm/cfi.h     | 126 +++++++++++++++++++++++++++++++++++++-\n arch/x86/kernel/alternative.c  |  87 +++++++++++++++++++++++---\n arch/x86/kernel/cfi.c          |   4 +-\n arch/x86/net/bpf_jit_comp.c    | 134 +++++++++++++++++++++++++++++++++++------\n include/asm-generic/Kbuild     |   1 +\n include/linux/bpf.h            |  27 ++++++++-\n include/linux/cfi.h            |  12 ++++\n kernel/bpf/bpf_struct_ops.c    |  16 ++---\n kernel/bpf/core.c              |  25 ++++++++\n kernel/bpf/cpumask.c           |   8 ++-\n kernel/bpf/helpers.c           |  18 +++++-\n net/bpf/bpf_dummy_struct_ops.c |  31 +++++++++-\n net/bpf/test_run.c             |  15 ++++-\n net/ipv4/bpf_tcp_ca.c          |  69 +++++++++++++++++++++\n 16 files changed', ' 528 insertions(+)', ' 50 deletions(-)\n====================\n\nLink: https://lore.kernel.org/r/20231215091216.135791411@infradead.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit fixes a compatibility issue between Control Flow Integrity (CFI) and eBPF in the x86 architecture.,"CFI,eBPF,x86",It's a bug fix.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
852486b35f344887786d63250946dd921a05d7e8,852486b35f344887786d63250946dd921a05d7e8,Alexei Starovoitov,alexei.starovoitov@gmail.com,1702631543,Alexei Starovoitov,ast@kernel.org,1702686355,4599c7e80eb113dcf3bda5ea435e8c26b7e2a3bf,e4c00339891c074c76f626ac82981963cbba5332,x86/cfi,"bpf: Fix bpf_exception_cb() signature

As per the earlier patches","[' BPF sub-programs have bpf_callback_t\nsignature and CFI expects callers to have matching signature. This is\nviolated by bpf_prog_aux::bpf_exception_cb().\n\n[peterz: Changelog]\nReported-by: Peter Zijlstra <peterz@infradead.org>\nSigned-off-by: Alexei Starovoitov <alexei.starovoitov@gmail.com>\nSigned-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>\nLink: https://lkml.kernel.org/r/CAADnVQ+Z7UcXXBBhMubhcMM=R-dExk-uHtfOLtoLxQ1XxEpqEA@mail.gmail.com\nLink: https://lore.kernel.org/r/20231215092707.910319166@infradead.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit fixes the signature of the bpf_exception_cb function.,"bpf_exception_cb,fix,signature",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The syscall interface,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e4c00339891c074c76f626ac82981963cbba5332,e4c00339891c074c76f626ac82981963cbba5332,Peter Zijlstra,peterz@infradead.org,1702631542,Alexei Starovoitov,ast@kernel.org,1702686355,4f2231383a2360a9fa0d7e8841343c8c69e2b164,e9d13b9d2f99ccf7afeab490d97eaa5ac9846598,"bpf: Fix dtor CFI

Ensure the various dtor functions match their prototype and retain
their CFI signatures", since they don't have their address taken,"[' they\nare prone to not getting CFI', ' making them impossible to call\nindirectly.\n\nSigned-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>\nLink: https://lore.kernel.org/r/20231215092707.799451071@infradead.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit fixes function prototypes to retain CFI signatures for destructor functions.,"Fix, CFI, dtor",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2cd3e3772e41377f32d6eea643e0590774e9187c,2cd3e3772e41377f32d6eea643e0590774e9187c,Peter Zijlstra,peterz@infradead.org,1702631540,Alexei Starovoitov,ast@kernel.org,1702686355,6731bd8786a091dbf2e2447952df2b5d908efec6,e72d88d18df4e03c80e64c2535f70c64f1dc6fc1,x86/cfi,"bpf: Fix bpf_struct_ops CFI

BPF struct_ops uses __arch_prepare_bpf_trampoline() to write
trampolines for indirect function calls. These tramplines much have
matching CFI.

In order to obtain the correct CFI hash for the various methods","[' add a\nmatching structure that contains stub functions', ' the compiler will\ngenerate correct CFI which we can pilfer for the trampolines.\n\nSigned-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>\nLink: https://lore.kernel.org/r/20231215092707.566977112@infradead.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes the bpf_struct_ops trampoline CFI to ensure correct indirect function call handling in x86 architecture.,"bpf_struct_ops,Cfi,trampolines",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e72d88d18df4e03c80e64c2535f70c64f1dc6fc1,e72d88d18df4e03c80e64c2535f70c64f1dc6fc1,Peter Zijlstra,peterz@infradead.org,1702631539,Alexei Starovoitov,ast@kernel.org,1702686355,b40a94832096c09289083677044e0d6c61601927,4f9087f16651aca4a5f32da840a53f6660f0579a,x86/cfi,"bpf: Fix bpf_callback_t CFI

Where the main BPF program is expected to match bpf_func_t","['\nsub-programs are expected to match bpf_callback_t.\n\nThis fixes things like:\n\ntools/testing/selftests/bpf/progs/bloom_filter_bench.c:\n\n           bpf_for_each_map_elem(&array_map', ' bloom_callback', ' &data', ' 0);\n\nSigned-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>\nLink: https://lore.kernel.org/r/20231215092707.451956710@infradead.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes a CFI issue in x86 architecture related to bpf_callback_t and bpf_func_t compatibility.,"x86, CFI, compatibility",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The syscall interface,['other']
4f9087f16651aca4a5f32da840a53f6660f0579a,4f9087f16651aca4a5f32da840a53f6660f0579a,Peter Zijlstra,peterz@infradead.org,1702631538,Alexei Starovoitov,ast@kernel.org,1702686355,4aae945ff81a7447ed40741a7fc3fce4fbf6fc65,4382159696c9af67ee047ed55f2dbf05480f52f6,x86/cfi,"bpf: Fix BPF JIT call

The current BPF call convention is __nocfi","[' except when it calls !JIT things', '\nthen it calls regular C functions.\n\nIt so happens that with FineIBT the __nocfi and C calling conventions are\nincompatible. Specifically __nocfi will call at func+0', ' while FineIBT will have\nendbr-poison there', ' which is not a valid indirect target. Causing #CP.\n\nNotably this only triggers on IBT enabled hardware', "" which is probably why this\nhasn't been reported (also"", ' most people will have JIT on anyway).\n\nImplement proper CFI prologues for the BPF JIT codegen and drop __nocfi for\nx86.\n\nSigned-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>\nLink: https://lore.kernel.org/r/20231215092707.345270396@infradead.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes BPF JIT call on x86 architecture using current BPF call convention.,"BPF,JIT,x86",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1467affd16b236fc86e1b8ec5eaa147e104cd2a6,1467affd16b236fc86e1b8ec5eaa147e104cd2a6,Hou Tao,houtao1@huawei.com,1702634828,Daniel Borkmann,daniel@iogearbox.net,1702677295,4f635246979dbe7796567907dcb483e89297430e,00cdcd2900bdb9190d1e75438b39cef74cd99232,"selftests/bpf: Add test for abnormal cnt during multi-kprobe attachment

If an abnormally huge cnt is used for multi-kprobes attachment"," the
following warning will be reported:

  ------------[ cut here ]------------
  WARNING: CPU: 1 PID: 392 at mm/util.c:632 kvmalloc_node+0xd9/0xe0
  Modules linked in: bpf_testmod(O)
  CPU: 1 PID: 392 Comm: test_progs Tainted: G ...... 6.7.0-rc3+ #32
  Hardware name: QEMU Standard PC (i440FX + PIIX","[' 1996)\n  ......\n  RIP: 0010:kvmalloc_node+0xd9/0xe0\n   ? __warn+0x89/0x150\n   ? kvmalloc_node+0xd9/0xe0\n   bpf_kprobe_multi_link_attach+0x87/0x670\n   __sys_bpf+0x2a28/0x2bc0\n   __x64_sys_bpf+0x1a/0x30\n   do_syscall_64+0x36/0xb0\n   entry_SYSCALL_64_after_hwframe+0x6e/0x76\n  RIP: 0033:0x7fbe067f0e0d\n  ......\n   </TASK>\n  ---[ end trace 0000000000000000 ]---\n\nSo add a test to ensure the warning is fixed.\n\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20231215100708.2265609-6-houtao@huaweicloud.com\n', '']",Add a new test for handling abnormal count during multi-kprobe attachment in eBPF selftests.,"selftests,bpf,multi-kprobe",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
00cdcd2900bdb9190d1e75438b39cef74cd99232,00cdcd2900bdb9190d1e75438b39cef74cd99232,Hou Tao,houtao1@huawei.com,1702634827,Daniel Borkmann,daniel@iogearbox.net,1702677295,7c7977496850c4fa2e9bc22f18599886a98ee1cb,0d83786f5661154d015b498a3d23d4c37e30f6ef,"selftests/bpf: Don't use libbpf_get_error() in kprobe_multi_test

Since libbpf v1.0"," libbpf doesn't return error code embedded into the
pointer iteself","[' libbpf_get_error() is deprecated and it is basically\nthe same as using -errno directly.\n\nSo replace the invocations of libbpf_get_error() by -errno in\nkprobe_multi_test. For libbpf_get_error() in test_attach_api_fails()', '\nsaving -errno before invoking ASSERT_xx() macros just in case that\nerrno is overwritten by these macros. However', ' the invocation of\nlibbpf_get_error() in get_syms() should be kept intact', ' because\nhashmap__new() still returns a pointer with embedded error code.\n\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20231215100708.2265609-5-houtao@huaweicloud.com\n', '']",Update selftests/bpf to avoid using libbpf_get_error() in kprobe_multi_test due to changes in libbpf v1.0.,"selftests,bpf,libbpf",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0d83786f5661154d015b498a3d23d4c37e30f6ef,0d83786f5661154d015b498a3d23d4c37e30f6ef,Hou Tao,houtao1@huawei.com,1702634826,Daniel Borkmann,daniel@iogearbox.net,1702677295,d118f6335c36c98b0517901f93ee471125ee8bdc,d6d1e6c17cab2dcb7b8530c599f00e7de906d380,"selftests/bpf: Add test for abnormal cnt during multi-uprobe attachment

If an abnormally huge cnt is used for multi-uprobes attachment"," the
following warning will be reported:

  ------------[ cut here ]------------
  WARNING: CPU: 7 PID: 406 at mm/util.c:632 kvmalloc_node+0xd9/0xe0
  Modules linked in: bpf_testmod(O)
  CPU: 7 PID: 406 Comm: test_progs Tainted: G ...... 6.7.0-rc3+ #32
  Hardware name: QEMU Standard PC (i440FX + PIIX","[' 1996) ......\n  RIP: 0010:kvmalloc_node+0xd9/0xe0\n  ......\n  Call Trace:\n   <TASK>\n   ? __warn+0x89/0x150\n   ? kvmalloc_node+0xd9/0xe0\n   bpf_uprobe_multi_link_attach+0x14a/0x480\n   __sys_bpf+0x14a9/0x2bc0\n   do_syscall_64+0x36/0xb0\n   entry_SYSCALL_64_after_hwframe+0x6e/0x76\n   ......\n   </TASK>\n  ---[ end trace 0000000000000000 ]---\n\nSo add a test to ensure the warning is fixed.\n\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20231215100708.2265609-4-houtao@huaweicloud.com\n', '']",Add a selftest for detecting abnormal cnt during multi-uprobe attachment in eBPF.,"selftest, multi-uprobe, abnormal",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
d6d1e6c17cab2dcb7b8530c599f00e7de906d380,d6d1e6c17cab2dcb7b8530c599f00e7de906d380,Hou Tao,houtao1@huawei.com,1702634825,Daniel Borkmann,daniel@iogearbox.net,1702677295,8ec04ed42b761af3105deb4660c8ca566664e2ca,8b2efe51ba85ca83460941672afac6fca4199df6,"bpf: Limit the number of kprobes when attaching program to multiple kprobes

An abnormally big cnt may also be assigned to kprobe_multi.cnt when
attaching multiple kprobes. It will trigger the following warning in
kvmalloc_node():

	if (unlikely(size > INT_MAX)) {
	    WARN_ON_ONCE(!(flags & __GFP_NOWARN));
	    return NULL;
	}

Fix the warning by limiting the maximal number of kprobes in
bpf_kprobe_multi_link_attach(). If the number of kprobes is greater than
MAX_KPROBE_MULTI_CNT"," the attachment will fail and return -E2BIG.

Fixes: 0dcac2725406 (""bpf: Add multi kprobe link"")
Signed-off-by: Hou Tao <houtao1@huawei.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20231215100708.2265609-3-houtao@huaweicloud.com
",[''],Fix a warning by limiting the number of kprobes when attaching programs to multiple kprobes.,"kprobes, warning, limit",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
8b2efe51ba85ca83460941672afac6fca4199df6,8b2efe51ba85ca83460941672afac6fca4199df6,Hou Tao,houtao1@huawei.com,1702634824,Daniel Borkmann,daniel@iogearbox.net,1702677286,55651e550cb7ee3f6980a5edd33bf5ff6bf92181,7489723c2e26504573dbb49b66bbc59092840008,"bpf: Limit the number of uprobes when attaching program to multiple uprobes

An abnormally big cnt may be passed to link_create.uprobe_multi.cnt","
and it will trigger the following warning in kvmalloc_node():

	if (unlikely(size > INT_MAX)) {
		WARN_ON_ONCE(!(flags & __GFP_NOWARN));
		return NULL;
	}

Fix the warning by limiting the maximal number of uprobes in
bpf_uprobe_multi_link_attach(). If the number of uprobes is greater than
MAX_UPROBE_MULTI_CNT","[' the attachment will return -E2BIG.\n\nFixes: 89ae89f53d20 (""bpf: Add multi uprobe link"")\nReported-by: Xingwei Lee <xrivendell7@gmail.com>\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nCloses: https://lore.kernel.org/bpf/CABOYnLwwJY=yFAGie59LFsUsBAgHfroVqbzZ5edAXbFE3YiNVA@mail.gmail.com\nLink: https://lore.kernel.org/bpf/20231215100708.2265609-2-houtao@huaweicloud.com\n', '']",Fix a kvmalloc_node warning by limiting maximally allowed uprobes in bpf_uprobe_multi_link_attach.,"uprobes, warning, limit",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
ff6d413b0b59466e5acf2e42f294b1842ae130a1,ff6d413b0b59466e5acf2e42f294b1842ae130a1,Kees Cook,keescook@chromium.org,1702415860,Greg Kroah-Hartman,gregkh@linuxfoundation.org,1702657510,e0a0a6325a1a2903b0c1865c8158c3b477f457e8,5b56bf5cdb8b7c989055fe4d73fe3f409427d1d5,"kernfs: Convert kernfs_path_from_node_locked() from strlcpy() to strscpy()

One of the last remaining users of strlcpy() in the kernel is
kernfs_path_from_node_locked()"," which passes back the problematic ""length
we _would_ have copied"" return value to indicate truncation.  Convert the
chain of all callers to use the negative return value (some of which
already doing this explicitly). All callers were already also checking
for negative return values","[' so the risk to missed checks looks very low.\n\nIn this analysis', ' it was found that cgroup1_release_agent() actually\ndidn\'t handle the ""too large"" condition', "" so this is technically also a\nbug fix. :)\n\nHere's the chain of callers"", ' and resolution identifying each one as now\nhandling the correct return value:\n\nkernfs_path_from_node_locked()\n        kernfs_path_from_node()\n                pr_cont_kernfs_path()\n                        returns void\n                kernfs_path()\n                        sysfs_warn_dup()\n                                return value ignored\n                        cgroup_path()\n                                blkg_path()\n                                        bfq_bic_update_cgroup()\n                                                return value ignored\n                                TRACE_IOCG_PATH()\n                                        return value ignored\n                                TRACE_CGROUP_PATH()\n                                        return value ignored\n                                perf_event_cgroup()\n                                        return value ignored\n                                task_group_path()\n                                        return value ignored\n                                damon_sysfs_memcg_path_eq()\n                                        return value ignored\n                                get_mm_memcg_path()\n                                        return value ignored\n                                lru_gen_seq_show()\n                                        return value ignored\n                        cgroup_path_from_kernfs_id()\n                                return value ignored\n                cgroup_show_path()\n                        already converted ""too large"" error to negative value\n                cgroup_path_ns_locked()\n                        cgroup_path_ns()\n                                bpf_iter_cgroup_show_fdinfo()\n                                        return value ignored\n                                cgroup1_release_agent()\n                                        wasn\'t checking ""too large"" error\n                        proc_cgroup_show()\n                                already converted ""too large"" to negative value\n\nCc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>\nCc: Tejun Heo <tj@kernel.org>\nCc: Zefan Li <lizefan.x@bytedance.com>\nCc: Johannes Weiner <hannes@cmpxchg.org>\nCc: Waiman Long <longman@redhat.com>\nCc:  <cgroups@vger.kernel.org>\nCo-developed-by: Azeem Shaikh <azeemshaikh38@gmail.com>\nSigned-off-by: Azeem Shaikh <azeemshaikh38@gmail.com>\nLink: https://lore.kernel.org/r/20231116192127.1558276-3-keescook@chromium.org\nSigned-off-by: Kees Cook <keescook@chromium.org>\nLink: https://lore.kernel.org/r/20231212211741.164376-3-keescook@chromium.org\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>\n', '']",Convert kernfs_path_from_node_locked() from strlcpy() to strscpy() to improve truncation return value handling.,"strscpy, kernfs, truncation",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
b84d66b0fd3709e36384a2cd893fbdddfc423f1f,b84d66b0fd3709e36384a2cd893fbdddfc423f1f,David S. Miller,davem@davemloft.net,1702638303,David S. Miller,davem@davemloft.net,1702638303,001ba1c994b7b9a067f8b95c7ea31d294196a068,9ed816b106bb40be6f1254696c6887e48f2a2b8f 00e7f29d9b895cbee58b7071900dd52ed6dcec1e,"Merge branch 'mv88e6xxx-counters'

Tobias Waldekranz says:

====================
net: dsa: mv88e6xxx: Add ""eth-mac"" and ""rmon"" counter group support

The majority of the changes (2/8) are about refactoring the existing
ethtool statistics support to make it possible to read individual
counters"," rather than the whole set.

4/8 tries to collect all information about a stat in a single place
using a mapper macro","[' which is then used to generate the original list\nof stats', ' along with a matching enum. checkpatch is less than amused\nwith this construct', ' but prior art exists (__BPF_FUNC_MAPPER in\ninclude/uapi/linux/bpf.h', ' for example).\n\nTo support the histogram counters from the ""rmon"" group', "" we have to\nchange mv88e6xxx's configuration of them. Instead of counting rx and\ntx"", ' we restrict them to rx-only. 6/8 has the details.\n\nWith that in place', ' adding the actual counter groups is pretty\nstraight forward (5', '7/8).\n\nTie it all together with a selftest (8/8).\n\nv3 -> v4:\n- Return size_t from mv88e6xxx_stats_get_stats\n- Spelling errors in commit message of 6/8\n- Improve selftest:\n  - Report progress per-bucket\n  - Test both ports in the pair\n  - Increase MTU', ' if required\n\nv2 -> v3:\n- Added 6/8\n- Added 8/8\n\nv1 -> v2:\n- Added 1/6\n- Added 3/6\n- Changed prototype of stats operation to reflect the fact that the\n  number of read stats are returned', "" no errors\n- Moved comma into MV88E6XXX_HW_STAT_MAPPER definition\n- Avoid the construction of mapping table iteration which relied on\n  struct layouts outside of mv88e6xxx's control\n====================\n\nSigned-off-by: David S. Miller <davem@davemloft.net>\n"", '']","Add ""eth-mac"" and ""rmon"" counter group support and refactor ethtool statistics for mv88e6xxx.","mv88e6xxx,counter,support",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
7489723c2e26504573dbb49b66bbc59092840008,7489723c2e26504573dbb49b66bbc59092840008,Daniel Xu,dxu@dxuuu.xyz,1702594585,Alexei Starovoitov,ast@kernel.org,1702609936,1a7a5f68c9012ebec507b80fb9c48bc456f5bb2a,0f5d5454c723d5c729d4676860a390c31c466f50,"bpf: xdp: Register generic_kfunc_set with XDP programs

Registering generic_kfunc_set with XDP programs enables some of the
newer BPF features inside XDP -- namely tree based data structures and
BPF exceptions.

The current motivation for this commit is to enable assertions inside
XDP bpf progs. Assertions are a standard and useful tool to encode
intent.

Signed-off-by: Daniel Xu <dxu@dxuuu.xyz>
Link: https://lore.kernel.org/r/d07d4614b81ca6aada44fcb89bb6b618fb66e4ca.1702594357.git.dxu@dxuuu.xyz
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Register generic_kfunc_set with XDP programs to enable assertions and newer BPF features.,"generic_kfunc_set,XDP,assertions",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['xdp like programs']
52eda4641d041667fa059f4855c5f88dcebd8afe,52eda4641d041667fa059f4855c5f88dcebd8afe,Vladimir Oltean,vladimir.oltean@nxp.com,1702512541,Jakub Kicinski,kuba@kernel.org,1702605489,d9edd54ff64067afc1388b1c9a7a26f7a55fc07a,c7402612e2e61b76177f22e6e7f705adcbecc6fe,"net: mscc: ocelot: fix eMAC TX RMON stats for bucket 256-511 and above

There is a typo in the driver due to which we report incorrect TX RMON
counters for the 256-511 octet bucket and all the other buckets larger
than that.

Bug found with the selftest at
https://patchwork.kernel.org/project/netdevbpf/patch/20231211223346.2497157-9-tobias@waldekranz.com/

Fixes: e32036e1ae7b (""net: mscc: ocelot: add support for all sorts of standardized counters present in DSA"")
Signed-off-by: Vladimir Oltean <vladimir.oltean@nxp.com>
Reviewed-by: Florian Fainelli <florian.fainelli@broadcom.com>
Link: https://lore.kernel.org/r/20231214000902.545625-1-vladimir.oltean@nxp.com
Signed-off-by: Jakub Kicinski <kuba@kernel.org>
",,Fixes a typo in the ocelot driver to correct TX RMON stats reporting for certain octet buckets.,fix typo stats,It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['other']
0f5d5454c723d5c729d4676860a390c31c466f50,0f5d5454c723d5c729d4676860a390c31c466f50,Alexei Starovoitov,ast@kernel.org,1702603827,Alexei Starovoitov,ast@kernel.org,1702603827,d431629c4dcedb8f2d12df5d2ed64e96152d9855,403f3e8fda60f1a3e54741742d46aea98ecf671e f2d0ffee1f03395d9ae65f9c615b6a0ee05d0e12,"Merge branch 'bpf-fs-mount-options-parsing-follow-ups'

Andrii Nakryiko says:

====================
BPF FS mount options parsing follow ups

Original BPF token patch set ([0]) added delegate_xxx mount options which
supported only special ""any"" value and hexadecimal bitmask. This patch set
attempts to make specifying and inspecting these mount options more
human-friendly by supporting string constants matching corresponding bpf_cmd","
bpf_map_type","[' bpf_prog_type', "" and bpf_attach_type enumerators.\n\nThis implementation relies on BTF information to find all supported symbolic\nnames. If kernel wasn't built with BTF"", ' BPF FS will still support ""any"" and\nhex-based mask.\n\n  [0] https://patchwork.kernel.org/project/netdevbpf/list/?series=805707&state=*\n\nv1->v2:\n  - strip BPF_', ' BPF_MAP_TYPE_', ' and BPF_PROG_TYPE_ prefixes', '\n    do case-insensitive comparison', ' normalize to lower case (Alexei).\n====================\n\nLink: https://lore.kernel.org/r/20231214225016.1209867-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Improved BPF FS mount options parsing for better usability with human-friendly string constants.,"BPF, mount, parsing",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f2d0ffee1f03395d9ae65f9c615b6a0ee05d0e12,f2d0ffee1f03395d9ae65f9c615b6a0ee05d0e12,Andrii Nakryiko,andrii@kernel.org,1702594216,Alexei Starovoitov,ast@kernel.org,1702603827,d431629c4dcedb8f2d12df5d2ed64e96152d9855,c5707b2146d229691e193d5158ea70b21b8ba180,"selftests/bpf: utilize string values for delegate_xxx mount options

Use both hex-based and string-based way to specify delegate mount
options for BPF FS.

Acked-by: John Fastabend <john.fastabend@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231214225016.1209867-3-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Use string values for delegate mount options in BPF selftests.,"selftests,mount options,string values",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
c5707b2146d229691e193d5158ea70b21b8ba180,c5707b2146d229691e193d5158ea70b21b8ba180,Andrii Nakryiko,andrii@kernel.org,1702594215,Alexei Starovoitov,ast@kernel.org,1702603827,1a9b1faadfa46eb1172440b18d2db54ba88a79c0,403f3e8fda60f1a3e54741742d46aea98ecf671e,"bpf: support symbolic BPF FS delegation mount options

Besides already supported special ""any"" value and hex bit mask"," support
string-based parsing of delegation masks based on exact enumerator
names. Utilize BTF information of `enum bpf_cmd`","[' `enum bpf_map_type`', '\n`enum bpf_prog_type`', ' and `enum bpf_attach_type` types to find supported\nsymbolic names (ignoring __MAX_xxx guard values and stripping repetitive\nprefixes like BPF_ for cmd and attach types', ' BPF_MAP_TYPE_ for maps', "" and\nBPF_PROG_TYPE_ for prog types). The case doesn't matter"", ' but it is\nnormalized to lower case in mount option output. So ""PROG_LOAD""', '\n""prog_load""', ' and ""MAP_create"" are all valid values to specify for\ndelegate_cmds options', ' ""array"" is among supported for map types', ' etc.\n\nBesides supporting string values', ' we also support multiple values\nspecified at the same time', "" using colon (':') separator.\n\nThere are corresponding changes on bpf_show_options side to use known\nvalues to print them in human-readable format"", ' falling back to hex mask\nprinting', "" if there are any unrecognized bits. This shouldn't be\nnecessary when enum BTF information is present"", ' but in general we should\nalways be able to fall back to this even if kernel was built without BTF.\nAs mentioned', ' emitted symbolic names are normalized to be all lower case.\n\nExample below shows various ways to specify delegate_cmds options\nthrough mount command and how mount options are printed back:\n\n12/14 14:39:07.604\nvmuser@archvm:~/local/linux/tools/testing/selftests/bpf\n$ mount | rg token\n\n  $ sudo mkdir -p /sys/fs/bpf/token\n  $ sudo mount -t bpf bpffs /sys/fs/bpf/token \\\n               -o delegate_cmds=prog_load:MAP_CREATE \\\n               -o delegate_progs=kprobe \\\n               -o delegate_attachs=xdp\n  $ mount | grep token\n  bpffs on /sys/fs/bpf/token type bpf (rw', 'relatime', 'delegate_cmds=map_create:prog_load', 'delegate_progs=kprobe', 'delegate_attachs=xdp)\n\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231214225016.1209867-2-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Support added for symbolic BPF FS delegation mount options using BTF information.,"symbolic, delegation, options",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
403f3e8fda60f1a3e54741742d46aea98ecf671e,403f3e8fda60f1a3e54741742d46aea98ecf671e,Alexei Starovoitov,ast@kernel.org,1702602769,Alexei Starovoitov,ast@kernel.org,1702602776,f30b1ef6e9987ff5f3cb2a5d14044748c3d0a866,56925f389e152dcb8d093435d43b78a310539c23 2cd07b0eb08c0ed63b1bd0bf0114146b19a4ab1f,"Merge branch 'add-bpf_xdp_get_xfrm_state-kfunc'

Daniel Xu says:

====================
Add bpf_xdp_get_xfrm_state() kfunc

This patchset adds two kfunc helpers"," bpf_xdp_get_xfrm_state() and
bpf_xdp_xfrm_state_release() that wrap xfrm_state_lookup() and
xfrm_state_put(). The intent is to support software RSS (via XDP) for
the ongoing/upcoming ipsec pcpu work [0]. Recent experiments performed
on (hopefully) reproducible AWS testbeds indicate that single tunnel
pcpu ipsec can reach line rate on 100G ENA nics.

Note this patchset only tests/shows generic xfrm_state access. The
""secret sauce"" (if you can really even call it that) involves accessing
a soon-to-be-upstreamed pcpu_num field in xfrm_state. Early example is
available here [1].

[0]: https://datatracker.ietf.org/doc/draft-ietf-ipsecme-multi-sa-performance/03/
[1]: https://github.com/danobi/xdp-tools/blob/e89a1c617aba3b50d990f779357d6ce2863ecb27/xdp-bench/xdp_redirect_cpumap.bpf.c#L385-L406

Changes from v5:
* Improve kfunc doc comments
* Remove extraneous replay-window setting on selftest reverse path
* Squash two kfunc commits into one
* Rebase to bpf-next to pick up bitfield write patches
* Remove testing of opts.error in selftest prog

Changes from v4:
* Fixup commit message for selftest
* Set opts->error -ENOENT for !x
* Revert single file xfrm + bpf

Changes from v3:
* Place all xfrm bpf integrations in xfrm_bpf.c
* Avoid using nval as a temporary
* Rebase to bpf-next
* Remove extraneous __failure_unpriv annotation for verifier tests

Changes from v2:
* Fix/simplify BPF_CORE_WRITE_BITFIELD() algorithm
* Added verifier tests for bitfield writes
* Fix state leakage across test_tunnel subtests

Changes from v1:
* Move xfrm tunnel tests to test_progs
* Fix writing to opts->error when opts is invalid
* Use __bpf_kfunc_start_defs()
* Remove unused vxlanhdr definition
* Add and use BPF_CORE_WRITE_BITFIELD() macro
* Make series bisect clean

Changes from RFCv2:
* Rebased to ipsec-next
* Fix netns leak

Changes from RFCv1:
* Add Antony's commit tags
* Add KF_ACQUIRE and KF_RELEASE semantics
====================

Reviewed-by: Eyal Birger <eyal.birger@gmail.com>
Link: https://lore.kernel.org/r/cover.1702593901.git.dxu@dxuuu.xyz
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Add bpf_xdp_get_xfrm_state and bpf_xdp_xfrm_state_release kfuncs for improved XDP support in ipsec.,"kfunc, XDP, ipsec",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['xdp like programs']
2cd07b0eb08c0ed63b1bd0bf0114146b19a4ab1f,2cd07b0eb08c0ed63b1bd0bf0114146b19a4ab1f,Daniel Xu,dxu@dxuuu.xyz,1702594146,Alexei Starovoitov,ast@kernel.org,1702602769,f30b1ef6e9987ff5f3cb2a5d14044748c3d0a866,e7adc8291a9e9c232d600d82465cbbb682164ca3,"bpf: xfrm: Add selftest for bpf_xdp_get_xfrm_state()

This commit extends test_tunnel selftest to test the new XDP xfrm state
lookup kfunc.

Co-developed-by: Antony Antony <antony.antony@secunet.com>
Signed-off-by: Antony Antony <antony.antony@secunet.com>
Signed-off-by: Daniel Xu <dxu@dxuuu.xyz>
Link: https://lore.kernel.org/r/e704e9a4332e3eac7b458e4bfdec8fcc6984cdb6.1702593901.git.dxu@dxuuu.xyz
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit adds a selftest for bpf_xdp_get_xfrm_state function in the test_tunnel selftest.,"selftest,xdp,xfrm state",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['xdp like programs']
e7adc8291a9e9c232d600d82465cbbb682164ca3,e7adc8291a9e9c232d600d82465cbbb682164ca3,Daniel Xu,dxu@dxuuu.xyz,1702594145,Alexei Starovoitov,ast@kernel.org,1702602769,c40277183677d835d38103bd9eda01d19b7e7c6b,02b4e126e6a5f5552da2ccec47a028984d2d9654,"bpf: selftests: Move xfrm tunnel test to test_progs

test_progs is better than a shell script b/c C is a bit easier to
maintain than shell. Also it's easier to use new infra like memory
mapped global variables from C via bpf skeleton.

Co-developed-by: Antony Antony <antony.antony@secunet.com>
Signed-off-by: Antony Antony <antony.antony@secunet.com>
Signed-off-by: Daniel Xu <dxu@dxuuu.xyz>
Link: https://lore.kernel.org/r/a350db9e08520c64544562d88ec005a039124d9b.1702593901.git.dxu@dxuuu.xyz
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit moves the xfrm tunnel test from a shell script to the test_progs framework for easier maintenance and new infrastructure compatibility.,"xfrm tunnel, test_progs, bpf skeleton",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
02b4e126e6a5f5552da2ccec47a028984d2d9654,02b4e126e6a5f5552da2ccec47a028984d2d9654,Daniel Xu,dxu@dxuuu.xyz,1702594144,Alexei Starovoitov,ast@kernel.org,1702602769,8c250a11aa648e0d71e26ae415062335b729a141,77a7a8220f0d87c44425c0a12e0a72b14962535b,"bpf: selftests: test_tunnel: Use vmlinux.h declarations

vmlinux.h declarations are more ergnomic"," especially when working with
kfuncs. The uapi headers are often incomplete for kfunc definitions.

This commit also switches bitfield accesses to use CO-RE helpers.
Switching to vmlinux.h definitions makes the verifier very
unhappy with raw bitfield accesses. The error is:

    ; md.u.md2.dir = direction;
    33: (69) r1 = *(u16 *)(r2 +11)
    misaligned stack access off (0x0; 0x0)+-64+11 size 2

Fix by using CO-RE-aware bitfield reads and writes.

Co-developed-by: Antony Antony <antony.antony@secunet.com>
Signed-off-by: Antony Antony <antony.antony@secunet.com>
Signed-off-by: Daniel Xu <dxu@dxuuu.xyz>
Link: https://lore.kernel.org/r/884bde1d9a351d126a3923886b945ea6b1b0776b.1702593901.git.dxu@dxuuu.xyz
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Refactor selftests to use vmlinux.h declarations for improved ergonomics and compatibility with kfuncs.,"vmlinux.h, kfuncs, CO-RE",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['xdp like programs', 'other']"
77a7a8220f0d87c44425c0a12e0a72b14962535b,77a7a8220f0d87c44425c0a12e0a72b14962535b,Daniel Xu,dxu@dxuuu.xyz,1702594143,Alexei Starovoitov,ast@kernel.org,1702602769,d6d8802fab0be3c12762810ffc6e026f4dbe84b1,8f0ec8c681755f523cf842bfe350ea40609b83a9,"bpf: selftests: test_tunnel: Setup fresh topology for each subtest

This helps with determinism b/c individual setup/teardown prevents
leaking state between different subtests.

Signed-off-by: Daniel Xu <dxu@dxuuu.xyz>
Link: https://lore.kernel.org/r/0fb59fa16fb58cca7def5239df606005a3e8dd0e.1702593901.git.dxu@dxuuu.xyz
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit sets up a fresh topology for each subtest in test_tunnel to ensure test determinism.,"selftests, topology, determinism",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8f0ec8c681755f523cf842bfe350ea40609b83a9,8f0ec8c681755f523cf842bfe350ea40609b83a9,Daniel Xu,dxu@dxuuu.xyz,1702594142,Alexei Starovoitov,ast@kernel.org,1702602769,09854f18f530083819738a3c283fe95d16952ee4,56925f389e152dcb8d093435d43b78a310539c23,"bpf: xfrm: Add bpf_xdp_get_xfrm_state() kfunc

This commit adds an unstable kfunc helper to access internal xfrm_state
associated with an SA. This is intended to be used for the upcoming
IPsec pcpu work to assign special pcpu SAs to a particular CPU. In other
words: for custom software RSS.

That being said"," the function that this kfunc wraps is fairly generic
and used for a lot of xfrm tasks. I'm sure people will find uses
elsewhere over time.

This commit also adds a corresponding bpf_xdp_xfrm_state_release() kfunc
to release the refcnt acquired by bpf_xdp_get_xfrm_state(). The verifier
will require that all acquired xfrm_state's are released.

Co-developed-by: Antony Antony <antony.antony@secunet.com>
Signed-off-by: Antony Antony <antony.antony@secunet.com>
Acked-by: Steffen Klassert <steffen.klassert@secunet.com>
Signed-off-by: Daniel Xu <dxu@dxuuu.xyz>
Link: https://lore.kernel.org/r/a29699c42f5fad456b875c98dd11c6afc3ffb707.1702593901.git.dxu@dxuuu.xyz
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Added bpf_xdp_get_xfrm_state() and bpf_xdp_xfrm_state_release() kfuncs for internal xfrm_state management associated with SA.,"bpf_xdp_get_xfrm_state, kfunc, xfrm_state",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['xdp like programs']
56925f389e152dcb8d093435d43b78a310539c23,56925f389e152dcb8d093435d43b78a310539c23,Yonghong Song,yonghong.song@linux.dev,1702586300,Alexei Starovoitov,ast@kernel.org,1702602632,23441311b52d786b1d7ddd06fe92f6bd23d8fab7,59e5791f59dd83e8aa72a4e74217eabb6e8cfd90,"selftests/bpf: Remove flaky test_btf_id test

With previous patch"," one of subtests in test_btf_id becomes
flaky and may fail. The following is a failing example:

  Error: #26 btf
  Error: #26/174 btf/BTF ID
    Error: #26/174 btf/BTF ID
    btf_raw_create:PASS:check 0 nsec
    btf_raw_create:PASS:check 0 nsec
    test_btf_id:PASS:check 0 nsec
    ...
    test_btf_id:PASS:check 0 nsec
    test_btf_id:FAIL:check BTF lingersdo_test_get_info:FAIL:check failed: -1

The test tries to prove a btf_id not available after the map is closed.
But btf_id is freed only after workqueue and a rcu grace period","[' compared\nto previous case just after a rcu grade period.\nDepending on system workload', ' workqueue could take quite some time\nto execute function bpf_map_free_deferred() which may cause the test failure.\nInstead of adding arbitrary delays', ' let us remove the logic to\ncheck btf_id availability after map is closed.\n\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20231214203820.1469402-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit removes a flaky test from the BPF selftests related to BTF ID.,"flaky,test,BTF",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
59e5791f59dd83e8aa72a4e74217eabb6e8cfd90,59e5791f59dd83e8aa72a4e74217eabb6e8cfd90,Yonghong Song,yonghong.song@linux.dev,1702586295,Alexei Starovoitov,ast@kernel.org,1702602632,6c7ed3b9ea78d8e9ebee7262feb358b5e009cd88,04d25ccea2b3199269b7e500da33023b51418fde,"bpf: Fix a race condition between btf_put() and map_free()

When running `./test_progs -j` in my local vm with latest kernel","
I once hit a kasan error like below:

  [ 1887.184724] BUG: KASAN: slab-use-after-free in bpf_rb_root_free+0x1f8/0x2b0
  [ 1887.185599] Read of size 4 at addr ffff888106806910 by task kworker/u12:2/2830
  [ 1887.186498]
  [ 1887.186712] CPU: 3 PID: 2830 Comm: kworker/u12:2 Tainted: G           OEL     6.7.0-rc3-00699-g90679706d486-dirty #494
  [ 1887.188034] Hardware name: QEMU Standard PC (i440FX + PIIX","[' 1996)', ' BIOS rel-1.14.0-0-g155821a1990b-prebuilt.qemu.org 04/01/2014\n  [ 1887.189618] Workqueue: events_unbound bpf_map_free_deferred\n  [ 1887.190341] Call Trace:\n  [ 1887.190666]  <TASK>\n  [ 1887.190949]  dump_stack_lvl+0xac/0xe0\n  [ 1887.191423]  ? nf_tcp_handle_invalid+0x1b0/0x1b0\n  [ 1887.192019]  ? panic+0x3c0/0x3c0\n  [ 1887.192449]  print_report+0x14f/0x720\n  [ 1887.192930]  ? preempt_count_sub+0x1c/0xd0\n  [ 1887.193459]  ? __virt_addr_valid+0xac/0x120\n  [ 1887.194004]  ? bpf_rb_root_free+0x1f8/0x2b0\n  [ 1887.194572]  kasan_report+0xc3/0x100\n  [ 1887.195085]  ? bpf_rb_root_free+0x1f8/0x2b0\n  [ 1887.195668]  bpf_rb_root_free+0x1f8/0x2b0\n  [ 1887.196183]  ? __bpf_obj_drop_impl+0xb0/0xb0\n  [ 1887.196736]  ? preempt_count_sub+0x1c/0xd0\n  [ 1887.197270]  ? preempt_count_sub+0x1c/0xd0\n  [ 1887.197802]  ? _raw_spin_unlock+0x1f/0x40\n  [ 1887.198319]  bpf_obj_free_fields+0x1d4/0x260\n  [ 1887.198883]  array_map_free+0x1a3/0x260\n  [ 1887.199380]  bpf_map_free_deferred+0x7b/0xe0\n  [ 1887.199943]  process_scheduled_works+0x3a2/0x6c0\n  [ 1887.200549]  worker_thread+0x633/0x890\n  [ 1887.201047]  ? __kthread_parkme+0xd7/0xf0\n  [ 1887.201574]  ? kthread+0x102/0x1d0\n  [ 1887.202020]  kthread+0x1ab/0x1d0\n  [ 1887.202447]  ? pr_cont_work+0x270/0x270\n  [ 1887.202954]  ? kthread_blkcg+0x50/0x50\n  [ 1887.203444]  ret_from_fork+0x34/0x50\n  [ 1887.203914]  ? kthread_blkcg+0x50/0x50\n  [ 1887.204397]  ret_from_fork_asm+0x11/0x20\n  [ 1887.204913]  </TASK>\n  [ 1887.204913]  </TASK>\n  [ 1887.205209]\n  [ 1887.205416] Allocated by task 2197:\n  [ 1887.205881]  kasan_set_track+0x3f/0x60\n  [ 1887.206366]  __kasan_kmalloc+0x6e/0x80\n  [ 1887.206856]  __kmalloc+0xac/0x1a0\n  [ 1887.207293]  btf_parse_fields+0xa15/0x1480\n  [ 1887.207836]  btf_parse_struct_metas+0x566/0x670\n  [ 1887.208387]  btf_new_fd+0x294/0x4d0\n  [ 1887.208851]  __sys_bpf+0x4ba/0x600\n  [ 1887.209292]  __x64_sys_bpf+0x41/0x50\n  [ 1887.209762]  do_syscall_64+0x4c/0xf0\n  [ 1887.210222]  entry_SYSCALL_64_after_hwframe+0x63/0x6b\n  [ 1887.210868]\n  [ 1887.211074] Freed by task 36:\n  [ 1887.211460]  kasan_set_track+0x3f/0x60\n  [ 1887.211951]  kasan_save_free_info+0x28/0x40\n  [ 1887.212485]  ____kasan_slab_free+0x101/0x180\n  [ 1887.213027]  __kmem_cache_free+0xe4/0x210\n  [ 1887.213514]  btf_free+0x5b/0x130\n  [ 1887.213918]  rcu_core+0x638/0xcc0\n  [ 1887.214347]  __do_softirq+0x114/0x37e\n\nThe error happens at bpf_rb_root_free+0x1f8/0x2b0:\n\n  00000000000034c0 <bpf_rb_root_free>:\n  ; {\n    34c0: f3 0f 1e fa                   endbr64\n    34c4: e8 00 00 00 00                callq   0x34c9 <bpf_rb_root_free+0x9>\n    34c9: 55                            pushq   %rbp\n    34ca: 48 89 e5                      movq    %rsp', ' %rbp\n  ...\n  ;       if (rec && rec->refcount_off >= 0 &&\n    36aa: 4d 85 ed                      testq   %r13', ' %r13\n    36ad: 74 a9                         je      0x3658 <bpf_rb_root_free+0x198>\n    36af: 49 8d 7d 10                   leaq    0x10(%r13)', ' %rdi\n    36b3: e8 00 00 00 00                callq   0x36b8 <bpf_rb_root_free+0x1f8>\n                                        <==== kasan function\n    36b8: 45 8b 7d 10                   movl    0x10(%r13)', ' %r15d\n                                        <==== use-after-free load\n    36bc: 45 85 ff                      testl   %r15d', ' %r15d\n    36bf: 78 8c                         js      0x364d <bpf_rb_root_free+0x18d>\n\nSo the problem is at rec->refcount_off in the above.\n\nI did some source code analysis and find the reason.\n                                  CPU A                        CPU B\n  bpf_map_put:\n    ...\n    btf_put with rcu callback\n    ...\n    bpf_map_free_deferred\n      with system_unbound_wq\n    ...                          ...                           ...\n    ...                          btf_free_rcu:                 ...\n    ...                          ...                           bpf_map_free_deferred:\n    ...                          ...\n    ...         --------->       btf_struct_metas_free()\n    ...         | race condition ...\n    ...         --------->                                     map->ops->map_free()\n    ...\n    ...                          btf->struct_meta_tab = NULL\n\nIn the above', ' map_free() corresponds to array_map_free() and eventually\ncalling bpf_rb_root_free() which calls:\n  ...\n  __bpf_obj_drop_impl(obj', ' field->graph_root.value_rec', ' false);\n  ...\n\nHere', "" 'value_rec' is assigned in btf_check_and_fixup_fields() with following code:\n\n  meta = btf_find_struct_meta(btf"", ' btf_id);\n  if (!meta)\n    return -EFAULT;\n  rec->fields[i].graph_root.value_rec = meta->record;\n\nSo basically', "" 'value_rec' is a pointer to the record in struct_metas_tab.\nAnd it is possible that that particular record has been freed by\nbtf_struct_metas_free() and hence we have a kasan error here.\n\nActually it is very hard to reproduce the failure with current bpf/bpf-next\ncode"", ' I only got the above error once. To increase reproducibility', ' I added\na delay in bpf_map_free_deferred() to delay map->ops->map_free()', ' which\nsignificantly increased reproducibility.\n\n  diff --git a/kernel/bpf/syscall.c b/kernel/bpf/syscall.c\n  index 5e43ddd1b83f..aae5b5213e93 100644\n  --- a/kernel/bpf/syscall.c\n  +++ b/kernel/bpf/syscall.c\n  @@ -695', '6 +695', '7 @@ static void bpf_map_free_deferred(struct work_struct *work)\n        struct bpf_map *map = container_of(work', ' struct bpf_map', ' work);\n        struct btf_record *rec = map->record;\n\n  +     mdelay(100);\n        security_bpf_map_free(map);\n        bpf_map_release_memcg(map);\n        /* implementation dependent freeing */\n\nHao also provided test cases ([1]) for easily reproducing the above issue.\n\nThere are two ways to fix the issue', ' the v1 of the patch ([2]) moving\nbtf_put() after map_free callback', ' and the v5 of the patch ([3]) using\na kptr style fix which tries to get a btf reference during\nmap_check_btf(). Each approach has its pro and cons. The first approach\ndelays freeing btf while the second approach needs to acquire reference\ndepending on context which makes logic not very elegant and may\ncomplicate things with future new data structures. Alexei\nsuggested in [4] going back to v1 which is what this patch\ntries to do.\n\nRerun \'./test_progs -j\' with the above mdelay() hack for a couple\nof times and didn\'t observe the error for the above rb_root test cases.\nRunning Hou\'s test ([1]) is also successful.\n\n  [1] https://lore.kernel.org/bpf/20231207141500.917136-1-houtao@huaweicloud.com/\n  [2] v1: https://lore.kernel.org/bpf/20231204173946.3066377-1-yonghong.song@linux.dev/\n  [3] v5: https://lore.kernel.org/bpf/20231208041621.2968241-1-yonghong.song@linux.dev/\n  [4] v4: https://lore.kernel.org/bpf/CAADnVQJ3FiXUhZJwX_81sjZvSYYKCFB3BT6P8D59RS2Gu+0Z7g@mail.gmail.com/\n\nCc: Hou Tao <houtao@huaweicloud.com>\nFixes: 958cf2e273f0 (""bpf: Introduce bpf_obj_new"")\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20231214203815.1469107-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes a race condition in bpf related to use-after-free errors in btf_put() and map_free().,"race condition, btf_put, map_free",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
04d25ccea2b3199269b7e500da33023b51418fde,04d25ccea2b3199269b7e500da33023b51418fde,Randy Dunlap,rdunlap@infradead.org,1702442255,Daniel Borkmann,daniel@iogearbox.net,1702568339,9c45da55c1977cb060f9bb8231100cc07ab0f4ff,2e1d6a04116c373fbd25beddba4267178535bc60,net," xdp: Correct grammar

Use the correct verb form in 2 places in the XDP rx-queue comment.

Signed-off-by: Randy Dunlap <rdunlap@infradead.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Jesper Dangaard Brouer <hawk@kernel.org>
Link: https://lore.kernel.org/bpf/20231213043735.30208-1-rdunlap@infradead.org
",[''],Corrects verb form in XDP rx-queue comment for improved grammar.,"grammar, XDP, comment",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF maps,['xdp like programs']
2e1d6a04116c373fbd25beddba4267178535bc60,2e1d6a04116c373fbd25beddba4267178535bc60,Tushar Vyavahare,tushar.vyavahare@intel.com,1702558807,Daniel Borkmann,daniel@iogearbox.net,1702566673,66ed3a51fb09661b55276001751737d0424961a8,c838fe1282df540ebf6e24e386ac34acb3ef3115,"selftests/xsk: Fix for SEND_RECEIVE_UNALIGNED test

Fix test broken by shared umem test and framework enhancement commit.

Correct the current implementation of pkt_stream_replace_half() by
ensuring that nb_valid_entries are not set to half"," as this is not true
for all the tests. Ensure that the expected value for valid_entries for
the SEND_RECEIVE_UNALIGNED test equals the total number of packets sent","['\nwhich is 4096.\n\nCreate a new function called pkt_stream_pkt_set() that allows for packet\nmodification to meet specific requirements while ensuring the accurate\nmaintenance of the valid packet count to prevent inconsistencies in packet\ntracking.\n\nFixes: 6d198a89c004 (""selftests/xsk: Add a test for shared umem feature"")\nReported-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>\nSigned-off-by: Tushar Vyavahare <tushar.vyavahare@intel.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>\nAcked-by: Magnus Karlsson <magnus.karlsson@intel.com>\nLink: https://lore.kernel.org/bpf/20231214130007.33281-1-tushar.vyavahare@intel.com\n', '']",Fixes SEND_RECEIVE_UNALIGNED test in selftests/xsk by correcting pkt_stream_replace_half() implementation.,"selftests,xsk,unaligned",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['other']
c838fe1282df540ebf6e24e386ac34acb3ef3115,c838fe1282df540ebf6e24e386ac34acb3ef3115,Alexei Starovoitov,ast@kernel.org,1702529351,Alexei Starovoitov,ast@kernel.org,1702530160,0b6e496130744349f7e15d3c015e7196e9bb7217,2a0c6b41eec90c2a138ea8b574836744783c67ff dc68540913ac523b46ebda3843cec179362c7a72,"Merge branch 'bpf-use-gfp_kernel-in-bpf_event_entry_gen'

Hou Tao says:

====================
The simple patch set aims to replace GFP_ATOMIC by GFP_KERNEL in
bpf_event_entry_gen(). These two patches in the patch set were
preparatory patches in ""Fix the release of inner map"" patchset [1] and
are not needed for v2"," so re-post it to bpf-next tree.

Patch #1 reduces the scope of rcu_read_lock when updating fd map and
patch #2 replaces GFP_ATOMIC by GFP_KERNEL. Please see individual
patches for more details.

Change Log:
v3:
 * patch #1: fallback to patch #1 in v1. Update comments in
             bpf_fd_htab_map_update_elem() to explain the reason for
	     rcu_read_lock() (Alexei)

v2: https://lore.kernel.org/bpf/20231211073843.1888058-1-houtao@huaweicloud.com/
 * patch #1: add rcu_read_lock/unlock() for bpf_fd_array_map_update_elem
             as well to make it consistent with
	     bpf_fd_htab_map_update_elem and update commit message
             accordingly (Alexei)
 * patch #1/#2: collects ack tags from Yonghong

v1: https://lore.kernel.org/bpf/20231208103357.2637299-1-houtao@huaweicloud.com/

[1]: https://lore.kernel.org/bpf/20231107140702.1891778-1-houtao@huaweicloud.com/
====================

Link: https://lore.kernel.org/r/20231214043010.3458072-1-houtao@huaweicloud.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Replace GFP_ATOMIC with GFP_KERNEL in bpf_event_entry_gen function to optimize memory allocation.,"GFP_KERNEL, bpf_event_entry_gen, memory",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
dc68540913ac523b46ebda3843cec179362c7a72,dc68540913ac523b46ebda3843cec179362c7a72,Hou Tao,houtao1@huawei.com,1702528210,Alexei Starovoitov,ast@kernel.org,1702529351,0b6e496130744349f7e15d3c015e7196e9bb7217,8f82583f9527b3be9d70d9a5d1f33435e29d0480,"bpf: Use GFP_KERNEL in bpf_event_entry_gen()

rcu_read_lock() is no longer held when invoking bpf_event_entry_gen()
which is called by perf_event_fd_array_get_ptr()"," so using GFP_KERNEL
instead of GFP_ATOMIC to reduce the possibility of failures due to
out-of-memory.

Acked-by: Yonghong Song <yonghong.song@linux.dev>
Signed-off-by: Hou Tao <houtao1@huawei.com>
Link: https://lore.kernel.org/r/20231214043010.3458072-3-houtao@huaweicloud.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Commit changes memory allocation from GFP_ATOMIC to GFP_KERNEL in bpf_event_entry_gen to reduce out-of-memory failures.,"GFP_KERNEL,bpf_event_entry_gen,reduce failures",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8f82583f9527b3be9d70d9a5d1f33435e29d0480,8f82583f9527b3be9d70d9a5d1f33435e29d0480,Hou Tao,houtao1@huawei.com,1702528209,Alexei Starovoitov,ast@kernel.org,1702529351,f295c8b23b7beead0a0bb9a2e880b7356299769d,2a0c6b41eec90c2a138ea8b574836744783c67ff,"bpf: Reduce the scope of rcu_read_lock when updating fd map

There is no rcu-read-lock requirement for ops->map_fd_get_ptr() or
ops->map_fd_put_ptr()"," so doesn't use rcu-read-lock for these two
callbacks.

For bpf_fd_array_map_update_elem()","["" accessing array->ptrs doesn't need\nrcu-read-lock because array->ptrs must still be allocated. For\nbpf_fd_htab_map_update_elem()"", ' htab_map_update_elem() only requires\nrcu-read-lock to be held to avoid the WARN_ON_ONCE()', ' so only use\nrcu_read_lock() during the invocation of htab_map_update_elem().\n\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20231214043010.3458072-2-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit reduces the rcu_read_lock scope when updating file descriptor maps in BPF.,"rcu_read_lock, fd map, update",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2a0c6b41eec90c2a138ea8b574836744783c67ff,2a0c6b41eec90c2a138ea8b574836744783c67ff,Hou Tao,houtao1@huawei.com,1702283687,Alexei Starovoitov,ast@kernel.org,1702515702,733a6575e6f7d0cfef20deb2cd5e3d94c38c2469,b13cddf633562b9b2c34fd63471d377019704ebe,"bpf: Update the comments in maybe_wait_bpf_programs()

Since commit 638e4b825d52 (""bpf: Allows per-cpu maps and map-in-map in
sleepable programs"")", sleepable BPF program can also use map-in-map,"["" but\nmaybe_wait_bpf_programs() doesn't handle it accordingly. The main reason\nis that using synchronize_rcu_tasks_trace() to wait for the completions\nof these sleepable BPF programs may incur a very long delay and\nuserspace may think it is hung"", ' so the wait for sleepable BPF programs\nis skipped. Update the comments in maybe_wait_bpf_programs() to reflect\nthe reason.\n\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nLink: https://lore.kernel.org/r/20231211083447.1921178-1-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit updates comments in the maybe_wait_bpf_programs function to reflect new capabilities for sleepable BPF programs.,"comments, maybe_wait_bpf_programs, sleepable BPF",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b13cddf633562b9b2c34fd63471d377019704ebe,b13cddf633562b9b2c34fd63471d377019704ebe,Matt Bobrowski,mattbobrowski@google.com,1702049568,Alexei Starovoitov,ast@kernel.org,1702515379,3756cd5100503ce15d097203ada907c02a514bd1,ec14325c7339bf1d40fc29bb8a0d2121cfe649aa,"bpf: add small subset of SECURITY_PATH hooks to BPF sleepable_lsm_hooks list

security_path_* based LSM hooks appear to be generally missing from
the sleepable_lsm_hooks list. Initially add a small subset of them to
the preexisting sleepable_lsm_hooks list so that sleepable BPF helpers
like bpf_d_path() can be used from sleepable BPF LSM based programs.

The security_path_* hooks added in this patch are similar to the
security_inode_* counterparts that already exist in the
sleepable_lsm_hooks list"," and are called in roughly similar points and
contexts. Presumably","["" making them OK to be also annotated as\nsleepable.\n\nBuilding a kernel with DEBUG_ATOMIC_SLEEP options enabled and running\nreasonable workloads stimulating activity that would be intercepted by\nsuch security hooks didn't show any splats.\n\nNotably"", "" I haven't added all the security_path_* LSM hooks that are\navailable as I don't need them at this point in time.\n\nSigned-off-by: Matt Bobrowski <mattbobrowski@google.com>\nAcked-by: KP Singh <kpsingh@kernel.org>\nLink: https://lore.kernel.org/r/ZXM3IHHXpNY9y82a@google.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Added security_path hooks to sleepable_lsm_hooks list for BPF sleepable LSM programs.,"security_path, LSM hooks, sleepable",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['LSM like programs']
2f2fee2bf74a7e31d06fc6cb7ba2bd4dd7753c99,2f2fee2bf74a7e31d06fc6cb7ba2bd4dd7753c99,Martin KaFai Lau,martin.lau@kernel.org,1702513313,Martin KaFai Lau,martin.lau@kernel.org,1702513997,fa6dcb7f84468e7631a8be8d1f4eb3b318d9d66f,e307b5a845c5951dabafc48d00b6424ee64716c4 50d96f05af6787a34b4eca2ee3fc1993289c4c24,"Merge branch ' bpf fix for unconnect af_unix socket'

John Fastabend says:

====================
Eric reported a syzbot splat from a null ptr deref from recent fix to
resolve a use-after-free with af-unix stream sockets and BPF sockmap
usage.

The issue is I missed is we allow unconnected af_unix STREAM sockets to
be added to the sockmap. Fix this by blocking unconnected sockets.

v2: change sk_is_unix to sk_is_stream_unix (Eric) and remove duplicate
    ASSERTS in selftests the xsocket helper already marks FAIL (Jakub)
====================

Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Fix null pointer dereference by blocking unconnected af_unix STREAM sockets from being added to sockmap.,"af_unix, sockmap, unconnected",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The syscall interface,['socket like programs']
50d96f05af6787a34b4eca2ee3fc1993289c4c24,50d96f05af6787a34b4eca2ee3fc1993289c4c24,John Fastabend,john.fastabend@gmail.com,1701453699,Martin KaFai Lau,martin.lau@kernel.org,1702513981,fa6dcb7f84468e7631a8be8d1f4eb3b318d9d66f,8d6650646ce49e9a5b8c5c23eb94f74b1749f70f,bpf: sockmap," test for unconnected af_unix sock

Add test to sockmap_basic to ensure af_unix sockets that are not connected
can not be added to the map. Ensure we keep DGRAM sockets working however
as these will not be connected typically.

Signed-off-by: John Fastabend <john.fastabend@gmail.com>
Acked-by: Jakub Sitnicki <jakub@cloudflare.com>
Link: https://lore.kernel.org/r/20231201180139.328529-3-john.fastabend@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Add test to ensure unconnected af_unix sockets can't be added to sockmap while keeping DGRAM sockets functional.,"test, sockmap, af_unix",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['socket like programs']
8d6650646ce49e9a5b8c5c23eb94f74b1749f70f,8d6650646ce49e9a5b8c5c23eb94f74b1749f70f,John Fastabend,john.fastabend@gmail.com,1701453698,Martin KaFai Lau,martin.lau@kernel.org,1702513948,19c3a819ecc40da8172fdf7b3836ee8f96b8d9a2,e307b5a845c5951dabafc48d00b6424ee64716c4,"bpf: syzkaller found null ptr deref in unix_bpf proto add

I added logic to track the sock pair for stream_unix sockets so that we
ensure lifetime of the sock matches the time a sockmap could reference
the sock (see fixes tag). I forgot though that we allow af_unix unconnected
sockets into a sock{map|hash} map.

This is problematic because previous fixed expected sk_pair() to exist
and did not NULL check it. Because unconnected sockets have a NULL
sk_pair this resulted in the NULL ptr dereference found by syzkaller.

BUG: KASAN: null-ptr-deref in unix_stream_bpf_update_proto+0x72/0x430 net/unix/unix_bpf.c:171
Write of size 4 at addr 0000000000000080 by task syz-executor360/5073
Call Trace:
 <TASK>
 ...
 sock_hold include/net/sock.h:777 [inline]
 unix_stream_bpf_update_proto+0x72/0x430 net/unix/unix_bpf.c:171
 sock_map_init_proto net/core/sock_map.c:190 [inline]
 sock_map_link+0xb87/0x1100 net/core/sock_map.c:294
 sock_map_update_common+0xf6/0x870 net/core/sock_map.c:483
 sock_map_update_elem_sys+0x5b6/0x640 net/core/sock_map.c:577
 bpf_map_update_value+0x3af/0x820 kernel/bpf/syscall.c:167

We considered just checking for the null ptr and skipping taking a ref
on the NULL peer sock. But"," if the socket is then connected() after
being added to the sockmap we can cause the original issue again. So
instead this patch blocks adding af_unix sockets that are not in the
ESTABLISHED state.

Reported-by: Eric Dumazet <edumazet@google.com>
Reported-by: syzbot+e8030702aefd3444fb9e@syzkaller.appspotmail.com
Fixes: 8866730aed51 (""bpf","[' sockmap: af_unix stream sockets need to hold ref for pair sock"")\nAcked-by: Jakub Sitnicki <jakub@cloudflare.com>\nSigned-off-by: John Fastabend <john.fastabend@gmail.com>\nLink: https://lore.kernel.org/r/20231201180139.328529-2-john.fastabend@gmail.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Fix null pointer dereference issue in unix_bpf protocol by preventing unconnected af_unix sockets from being added to sockmap.,"null pointer, sockmap, af_unix",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The syscall interface,['socket like programs']
ec14325c7339bf1d40fc29bb8a0d2121cfe649aa,ec14325c7339bf1d40fc29bb8a0d2121cfe649aa,Alexei Starovoitov,ast@kernel.org,1702513002,Alexei Starovoitov,ast@kernel.org,1702513002,69dbb3887b907d62888bd4cad1781053d55ddd3c,733763285acfe8dffd6e39ad2ed3d1222b32a901 4c6612f6100c2d85212865dbd1a5d8a7e391d3cb,"Merge branch 'xdp-metadata-via-kfuncs-for-ice-vlan-hint'

Larysa Zaremba says:

====================
XDP metadata via kfuncs for ice + VLAN hint

This series introduces XDP hints via kfuncs [0] to the ice driver.

Series brings the following existing hints to the ice driver:
 - HW timestamp
 - RX hash with type

Series also introduces VLAN tag with protocol XDP hint"," it now be accessed by
XDP and userspace (AF_XDP) programs. They can also be checked with xdp_metadata
test and xdp_hw_metadata program.

Impact of these patches on ice performance:
ZC:
* Full hints implementation decreases pps in ZC mode by less than 3%
  (64B","[' rxdrop)\n\nskb (packets with invalid IP', ' dropped by stack):\n* Overall', ' patchset improves peak performance in skb mode by about 0.5%\n\n[0] https://patchwork.kernel.org/project/netdevbpf/cover/20230119221536.3349901-1-sdf@google.com/\n\nv7:\nhttps://lore.kernel.org/bpf/20231115175301.534113-1-larysa.zaremba@intel.com/\nv6:\nhttps://lore.kernel.org/bpf/20231012170524.21085-1-larysa.zaremba@intel.com/\nIntermediate RFC v2:\nhttps://lore.kernel.org/bpf/20230927075124.23941-1-larysa.zaremba@intel.com/\nIntermediate RFC v1:\nhttps://lore.kernel.org/bpf/20230824192703.712881-1-larysa.zaremba@intel.com/\nv5:\nhttps://lore.kernel.org/bpf/20230811161509.19722-1-larysa.zaremba@intel.com/\nv4:\nhttps://lore.kernel.org/bpf/20230728173923.1318596-1-larysa.zaremba@intel.com/\nv3:\nhttps://lore.kernel.org/bpf/20230719183734.21681-1-larysa.zaremba@intel.com/\nv2:\nhttps://lore.kernel.org/bpf/20230703181226.19380-1-larysa.zaremba@intel.com/\nv1:\nhttps://lore.kernel.org/all/20230512152607.992209-1-larysa.zaremba@intel.com/\n\nChanges since v7:\n* shorten timestamp assignment in ice\n* change first argument of ice_fill_rx_descs back to xsk_buff_pool\n* fix kernel-doc for ice_run_xdp_zc\n* add missing XSK_CHECK_PRIV_TYPE() in ice\n* resolved selftests merge conflicts with TX hints\n* AF_INET patch adds new packet generation', "" not replaces AF_XDP one\n* fix destination port in xdp_metadata\n\nChanges since v6:\n* add ability to fill cb of all xdp_buffs in xsk_buff_pool\n* place just pointer to packet context in ice_xdp_buff\n* add const qualifiers in veth implementation\n* generate uapi for VLAN hint\n\nChanges since v5:\n* drop checksum hint from the patchset entirely\n* Alex's patch that lifts the data_meta size limitation is no longer\n  required in this patchset"", ' so will be sent separately\n* new patch: hide some ice hints code behind a static key\n* fix several bugs in ZC mode (ice)\n* change argument order in VLAN hint kfunc (tci', ' proto -> proto', ' tci)\n* cosmetic changes\n* analyze performance impact\n\nChanges since v4:\n* Drop the concept of partial checksum from the hint design\n* Drop the concept of checksum level from the hint design\n\nChanges since v3:\n* use XDP_CHECKSUM_VALID_LVL0 + csum_level instead of csum_level + 1\n* fix spelling mistakes\n* read XDP timestamp unconditionally\n* add TO_STR() macro\n\nChanges since v2:\n* redesign checksum hint', ' so now it gives full status\n* rename vlan_tag -> vlan_tci', ' where applicable\n* use open_netns() and close_netns() in xdp_metadata\n* improve VLAN hint documentation\n* replace CFI with DEI\n* use VLAN_VID_MASK in xdp_metadata\n* make vlan_get_tag() return -ENODATA\n* remove unused rx_ptype in ice_xsk.c\n* fix ice timestamp code division between patches\n\nChanges since v1:\n* directly return RX hash', ' RX timestamp and RX checksum status\n  in skb-common functions\n* use intermediate enum value for checksum status in ice\n* get rid of ring structure dependency in ice kfunc implementation\n* make variables const', ' when possible', ' in ice implementation\n* use -ENODATA instead of -EOPNOTSUPP for driver implementation\n* instead of having 2 separate functions for c-tag and s-tag', '\n  use 1 function that outputs both VLAN tag and protocol ID\n* improve documentation for introduced hints\n* update xdp_metadata selftest to test new hints\n* implement new hints in veth', ' so they can be tested in xdp_metadata\n* parse VLAN tag in xdp_hw_metadata\n====================\n\nLink: https://lore.kernel.org/r/20231205210847.28460-1-larysa.zaremba@intel.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Introduces XDP metadata via kfuncs for ice driver including VLAN hint and timestamp.,"XDP, metadata, kfuncs",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['xdp like programs']
4c6612f6100c2d85212865dbd1a5d8a7e391d3cb,4c6612f6100c2d85212865dbd1a5d8a7e391d3cb,Larysa Zaremba,larysa.zaremba@intel.com,1701810527,Alexei Starovoitov,ast@kernel.org,1702513001,69dbb3887b907d62888bd4cad1781053d55ddd3c,a3850af4ea25dadc8b35edf132340907d523657e,"selftests/bpf: Check VLAN tag and proto in xdp_metadata

Verify"," whether VLAN tag and proto are set correctly.

To simulate ""stripped"" VLAN tag on veth","[' send test packet from VLAN\ninterface.\n\nAlso', ' add TO_STR() macro for convenience.\n\nAcked-by: Stanislav Fomichev <sdf@google.com>\nSigned-off-by: Larysa Zaremba <larysa.zaremba@intel.com>\nLink: https://lore.kernel.org/r/20231205210847.28460-19-larysa.zaremba@intel.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add selftests to verify VLAN tag and protocol settings in xdp_metadata for veth interfaces.,"VLAN, xdp_metadata, selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['xdp like programs']
a3850af4ea25dadc8b35edf132340907d523657e,a3850af4ea25dadc8b35edf132340907d523657e,Larysa Zaremba,larysa.zaremba@intel.com,1701810526,Alexei Starovoitov,ast@kernel.org,1702513001,4af552e922f067d4436cbc8afae10a1059821694,8e68a4beba943bdffb342c601c649223f44b7329,"selftests/bpf: Add AF_INET packet generation to xdp_metadata

The easiest way to simulate stripped VLAN tag in veth is to send a packet
from VLAN interface", attached to veth. Unfortunately,"[' this approach is\nincompatible with AF_XDP on TX side', ' because VLAN interfaces do not have\nsuch feature.\n\nCheck both packets sent via AF_XDP TX and regular socket.\n\nAF_INET packet will also have a filled-in hash type (XDP_RSS_TYPE_L4)', '\nunlike AF_XDP packet', ' so more values can be checked.\n\nSigned-off-by: Larysa Zaremba <larysa.zaremba@intel.com>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nLink: https://lore.kernel.org/r/20231205210847.28460-18-larysa.zaremba@intel.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add AF_INET packet generation to xdp_metadata selftests in eBPF to simulate stripped VLAN tag using VLAN interface.,"AF_INET, packet generation, xdp_metadata",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['xdp like programs']
8e68a4beba943bdffb342c601c649223f44b7329,8e68a4beba943bdffb342c601c649223f44b7329,Larysa Zaremba,larysa.zaremba@intel.com,1701810525,Alexei Starovoitov,ast@kernel.org,1702513001,0c688336ffa27af91694248f76cd4e64e1d38f8a,e71a9fa7fdb2effcaaed37c207ec4f634c8f4901,"selftests/bpf: Add flags and VLAN hint to xdp_hw_metadata

Add VLAN hint to the xdp_hw_metadata program.

Also", to make metadata layout more straightforward,"[' add flags field\nto pass information about validity of every separate hint separately.\n\nAcked-by: Stanislav Fomichev <sdf@google.com>\nSigned-off-by: Larysa Zaremba <larysa.zaremba@intel.com>\nLink: https://lore.kernel.org/r/20231205210847.28460-17-larysa.zaremba@intel.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add VLAN hint and flags to improve xdp_hw_metadata program's metadata layout in selftests.,"VLAN,xdp_hw_metadata,metadata",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['xdp like programs']
e71a9fa7fdb2effcaaed37c207ec4f634c8f4901,e71a9fa7fdb2effcaaed37c207ec4f634c8f4901,Larysa Zaremba,larysa.zaremba@intel.com,1701810524,Alexei Starovoitov,ast@kernel.org,1702513001,035b34479f63090f232980a99ed9bd5f2ecf6937,7978bad4b6b9265a1e808a5f679ee428d1dd6523,"selftests/bpf: Allow VLAN packets in xdp_hw_metadata

Make VLAN c-tag and s-tag XDP hint testing more convenient
by not skipping VLAN-ed packets.

Allow both 802.1ad and 802.1Q headers.

Acked-by: Stanislav Fomichev <sdf@google.com>
Signed-off-by: Larysa Zaremba <larysa.zaremba@intel.com>
Link: https://lore.kernel.org/r/20231205210847.28460-16-larysa.zaremba@intel.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit updates selftests to include VLAN packets in xdp_hw_metadata for improved testing of XDP hints.,"VLAN,XDP,selftests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['xdp like programs']
537fec0733c4a72e2a2b69fee365459c5b75d92e,537fec0733c4a72e2a2b69fee365459c5b75d92e,Larysa Zaremba,larysa.zaremba@intel.com,1701810522,Alexei Starovoitov,ast@kernel.org,1702513001,037548b81a240152a2d37ad07a9a2a3ed3e930f8,fca783799f64ac0a4f20228ff6a6d7598db11e64,"net: make vlan_get_tag() return -ENODATA instead of -EINVAL

__vlan_hwaccel_get_tag() is used in veth XDP hints implementation","
its return value (-EINVAL if skb is not VLAN tagged) is passed to bpf code","['\nbut XDP hints specification requires drivers to return -ENODATA', ' if a hint\ncannot be provided for a particular packet.\n\nSolve this inconsistency by changing error return value of\n__vlan_hwaccel_get_tag() from -EINVAL to -ENODATA', ' do the same thing to\n__vlan_get_tag()', ' because this function is supposed to follow the same\nconvention. This', ' in turn', ' makes -ENODATA the only non-zero value\nvlan_get_tag() can return. We can do this with no side effects', ' because\nnone of the users of the 3 above-mentioned functions rely on the exact\nvalue.\n\nSuggested-by: Jesper Dangaard Brouer <jbrouer@redhat.com>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nSigned-off-by: Larysa Zaremba <larysa.zaremba@intel.com>\nLink: https://lore.kernel.org/r/20231205210847.28460-14-larysa.zaremba@intel.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Change vlan_get_tag() return value to -ENODATA in the veth XDP hints implementation.,"vlan_get_tag,ENODATA,XDP",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The syscall interface,['xdp like programs']
e6795330f88b4f643c649a02662d47b779340535,e6795330f88b4f643c649a02662d47b779340535,Larysa Zaremba,larysa.zaremba@intel.com,1701810518,Alexei Starovoitov,ast@kernel.org,1702513000,b55bc96555ae1f9d60a1bb60c89e914fb0be148d,d68d707dcbbf6a9cfe378fc2eb3ffffd5b47727e,"xdp: Add VLAN tag hint

Implement functionality that enables drivers to expose VLAN tag
to XDP code.

VLAN tag is represented by 2 variables:
- protocol ID"," which is passed to bpf code in BE
- VLAN TCI","[' in host byte order\n\nAcked-by: Stanislav Fomichev <sdf@google.com>\nSigned-off-by: Larysa Zaremba <larysa.zaremba@intel.com>\nAcked-by: Jesper Dangaard Brouer <hawk@kernel.org>\nLink: https://lore.kernel.org/r/20231205210847.28460-10-larysa.zaremba@intel.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Introduce functionality for XDP to process VLAN tag hints in drivers.,"XDP,VLAN,drivers",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['xdp like programs']
733763285acfe8dffd6e39ad2ed3d1222b32a901,733763285acfe8dffd6e39ad2ed3d1222b32a901,Alexei Starovoitov,ast@kernel.org,1702511226,Alexei Starovoitov,ast@kernel.org,1702511226,666f0c5c466178d6b72de167c368259d011200fe,f04f2ce6018f3cb33ac96270b9153c2920ead190 322122bf8c75b1df78d6608516807a0354f6ab3c,"Merge branch 'bpf-token-support-in-libbpf-s-bpf-object'

Andrii Nakryiko says:

====================
BPF token support in libbpf's BPF object

Add fuller support for BPF token in high-level BPF object APIs. This is the
most frequently used way to work with BPF using libbpf"," so supporting BPF
token there is critical.

Patch #1 is improving kernel-side BPF_TOKEN_CREATE behavior by rejecting to
create ""empty"" BPF token with no delegation. This seems like saner behavior
which also makes libbpf's caching better overall. If we ever want to create
BPF token with no delegate_xxx options set on BPF FS","[' we can use a new flag to\nenable that.\n\nPatches #2-#5 refactor libbpf internals', ' mostly feature detection code', ' to\nprepare it from BPF token FD.\n\nPatch #6 adds options to pass BPF token into BPF object open options. It also\nadds implicit BPF token creation logic to BPF object load step', ' even without\nany explicit involvement of the user. If the environment is setup properly', '\nBPF token will be created transparently and used implicitly. This allows for\nall existing application to gain BPF token support by just linking with\nlatest version of libbpf library. No source code modifications are required.\nAll that under assumption that privileged container management agent properly\nset up default BPF FS instance at /sys/bpf/fs to allow BPF token creation.\n\nPatches #7-#8 adds more selftests', ' validating BPF object APIs work as expected\nunder unprivileged user namespaced conditions in the presence of BPF token.\n\nPatch #9 extends libbpf with LIBBPF_BPF_TOKEN_PATH envvar knowledge', ' which can\nbe used to override custom BPF FS location used for implicit BPF token\ncreation logic without needing to adjust application code. This allows admins\nor container managers to mount BPF token-enabled BPF FS at non-standard\nlocation without the need to coordinate with applications.\nLIBBPF_BPF_TOKEN_PATH can also be used to disable BPF token implicit creation\nby setting it to an empty value. Patch #10 tests this new envvar functionality.\n\nv2->v3:\n  - move some stray feature cache refactorings into patch #4 (Alexei);\n  - add LIBBPF_BPF_TOKEN_PATH envvar support (Alexei);\nv1->v2:\n  - remove minor code redundancies (Eduard', ' John);\n  - add acks and rebase.\n====================\n\nLink: https://lore.kernel.org/r/20231213190842.3844987-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add BPF token support to high-level BPF object APIs in libbpf.,"BPF token,libbpf,support",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
322122bf8c75b1df78d6608516807a0354f6ab3c,322122bf8c75b1df78d6608516807a0354f6ab3c,Andrii Nakryiko,andrii@kernel.org,1702494522,Alexei Starovoitov,ast@kernel.org,1702511225,666f0c5c466178d6b72de167c368259d011200fe,ed54124b88056fd629c6af71664dfcd4d3b3e0b8,"selftests/bpf: add tests for LIBBPF_BPF_TOKEN_PATH envvar

Add new subtest validating LIBBPF_BPF_TOKEN_PATH envvar semantics.
Extend existing test to validate that LIBBPF_BPF_TOKEN_PATH allows to
disable implicit BPF token creation by setting envvar to empty string.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231213190842.3844987-11-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add new subtest to validate behavior of LIBBPF_BPF_TOKEN_PATH environment variable in selftests.,"selftests,LIBBPF_BPF_TOKEN_PATH,subtest",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ed54124b88056fd629c6af71664dfcd4d3b3e0b8,ed54124b88056fd629c6af71664dfcd4d3b3e0b8,Andrii Nakryiko,andrii@kernel.org,1702494521,Alexei Starovoitov,ast@kernel.org,1702511225,e93d0fe0e46fd6111b15a3ea58afaf3c34df0875,18678cf0ee13cf19bac4ecd55665e6d1d63108b3,"libbpf: support BPF token path setting through LIBBPF_BPF_TOKEN_PATH envvar

To allow external admin authority to override default BPF FS location
(/sys/fs/bpf) for implicit BPF token creation"," teach libbpf to recognize
LIBBPF_BPF_TOKEN_PATH envvar. If it is specified and user application
didn't explicitly specify neither bpf_token_path nor bpf_token_fd
option","[' it will be treated exactly like bpf_token_path option', '\noverriding default /sys/fs/bpf location and making BPF token mandatory.\n\nSuggested-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231213190842.3844987-10-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit adds support for setting BPF token path via LIBBPF_BPF_TOKEN_PATH environment variable in libbpf.,"libbpf,BPF token,environment variable",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
18678cf0ee13cf19bac4ecd55665e6d1d63108b3,18678cf0ee13cf19bac4ecd55665e6d1d63108b3,Andrii Nakryiko,andrii@kernel.org,1702494520,Alexei Starovoitov,ast@kernel.org,1702511225,bb34410c2c7e36319fe0849ad74c0672b95075b6,98e0eaa36adfb580a3aa43fca62847ec0f625d3f,"selftests/bpf: add tests for BPF object load with implicit token

Add a test to validate libbpf's implicit BPF token creation from default
BPF FS location (/sys/fs/bpf). Also validate that disabling this
implicit BPF token creation works.

Acked-by: John Fastabend <john.fastabend@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231213190842.3844987-9-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add selftests for BPF object load with implicit token creation in libbpf.,"selftests, BPF, libbpf",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
98e0eaa36adfb580a3aa43fca62847ec0f625d3f,98e0eaa36adfb580a3aa43fca62847ec0f625d3f,Andrii Nakryiko,andrii@kernel.org,1702494519,Alexei Starovoitov,ast@kernel.org,1702511225,5224619e77c256f19d73feee7155c5cbc851c6f8,1d0dd6ea2e38c18e1b31a8c3c59b6bdfe4f4efde,"selftests/bpf: add BPF object loading tests with explicit token passing

Add a few tests that attempt to load BPF object containing privileged
map", program,"[' and the one requiring mandatory BTF uploading into the\nkernel (to validate token FD propagation to BPF_BTF_LOAD command).\n\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231213190842.3844987-8-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add selftests for BPF object loading with explicit token passing focusing on privileged maps.,"selftests,BPF,token",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1d0dd6ea2e38c18e1b31a8c3c59b6bdfe4f4efde,1d0dd6ea2e38c18e1b31a8c3c59b6bdfe4f4efde,Andrii Nakryiko,andrii@kernel.org,1702494518,Alexei Starovoitov,ast@kernel.org,1702511225,ef35de7393a9be3caa6619a303c799dee185d816,a75bb6a16518d4a224f24116633f3f9d5787f6d1,"libbpf: wire up BPF token support at BPF object level

Add BPF token support to BPF object-level functionality.

BPF token is supported by BPF object logic either as an explicitly
provided BPF token from outside (through BPF FS path or explicit BPF
token FD)"," or implicitly (unless prevented through
bpf_object_open_opts).

Implicit mode is assumed to be the most common one for user namespaced
unprivileged workloads. The assumption is that privileged container
manager sets up default BPF FS mount point at /sys/fs/bpf with BPF token
delegation options (delegate_{cmds","['maps', 'progs', 'attachs} mount options).\nBPF object during loading will attempt to create BPF token from\n/sys/fs/bpf location', ' and pass it for all relevant operations\n(currently', ' map creation', ' BTF load', ' and program load).\n\nIn this implicit mode', ' if BPF token creation fails due to whatever\nreason (BPF FS is not mounted', "" or kernel doesn't support BPF token"", '\netc)', ' this is not considered an error. BPF object loading sequence will\nproceed with no BPF token.\n\nIn explicit BPF token mode', ' user provides explicitly either custom BPF\nFS mount point path or creates BPF token on their own and just passes\ntoken FD directly. In such case', ' BPF object will either dup() token FD\n(to not require caller to hold onto it for entire duration of BPF object\nlifetime) or will attempt to create BPF token from provided BPF FS\nlocation. If BPF token creation fails', ' that is considered a critical\nerror and BPF object load fails with an error.\n\nLibbpf provides a way to disable implicit BPF token creation', "" if it\ncauses any troubles (BPF token is designed to be completely optional and\nshouldn't cause any problems even if provided"", ' but in the world of BPF\nLSM', "" custom security logic can be installed that might change outcome\ndependin on the presence of BPF token). To disable libbpf's default BPF\ntoken creation behavior user should provide either invalid BPF token FD\n(negative)"", "" or empty bpf_token_path option.\n\nBPF token presence can influence libbpf's feature probing"", ' so if BPF\nobject has associated BPF token', ' feature probing is instructed to use\nBPF object-specific feature detection cache and token FD.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231213190842.3844987-7-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit adds BPF token support to BPF object-level functionality in libbpf.,"BPF token, BPF object, libbpf",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a75bb6a16518d4a224f24116633f3f9d5787f6d1,a75bb6a16518d4a224f24116633f3f9d5787f6d1,Andrii Nakryiko,andrii@kernel.org,1702494517,Alexei Starovoitov,ast@kernel.org,1702511225,274590f941b41c8b6565c9e1c7d99cac00062594,ab8fc393b27cd2d6dd1ced1ba2358ddcd123fc15,"libbpf: wire up token_fd into feature probing logic

Adjust feature probing callbacks to take into account optional token_fd.
In unprivileged contexts"," some feature detectors would fail to detect
kernel support just because BPF program","[' BPF map', "" or BTF object can't be\nloaded due to privileged nature of those operations. So when BPF object\nis loaded with BPF token"", ' this token should be used for feature probing.\n\nThis patch is setting support for this scenario', "" but we don't yet pass\nnon-zero token FD. This will be added in the next patch.\n\nWe also switched BPF cookie detector from using kprobe program to\ntracepoint one"", ' as tracepoint is somewhat less dangerous BPF program\ntype and has higher likelihood of being allowed through BPF token in the\nfuture. This change has no effect on detection behavior.\n\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231213190842.3844987-6-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit adjusts feature probing logic to incorporate the optional token_fd in libbpf.,"libbpf, token_fd, feature",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ab8fc393b27cd2d6dd1ced1ba2358ddcd123fc15,ab8fc393b27cd2d6dd1ced1ba2358ddcd123fc15,Andrii Nakryiko,andrii@kernel.org,1702494516,Alexei Starovoitov,ast@kernel.org,1702511225,524a70762bbe40613a41701e3a1487d3b4f8f62c,29c302a2e265a356434b005155990a9e766db75d,"libbpf: move feature detection code into its own file

It's quite a lot of well isolated code"," so it seems like a good
candidate to move it out of libbpf.c to reduce its size.

Acked-by: John Fastabend <john.fastabend@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231213190842.3844987-5-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Refactored libbpf by moving feature detection code to a separate file to reduce libbpf.c size.,"libbpf, refactoring, feature detection",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
29c302a2e265a356434b005155990a9e766db75d,29c302a2e265a356434b005155990a9e766db75d,Andrii Nakryiko,andrii@kernel.org,1702494515,Alexei Starovoitov,ast@kernel.org,1702511225,e40449d783e85ca73b620a87592a13ab9b7bd0c4,c6c5be3eee975ae640966844db66d404c1de79b1,"libbpf: further decouple feature checking logic from bpf_object

Add feat_supported() helper that accepts feature cache instead of
bpf_object. This allows low-level code in bpf.c to not know or care
about higher-level concept of bpf_object"," yet it will be able to utilize
custom feature checking in cases where BPF token might influence the
outcome.

Acked-by: John Fastabend <john.fastabend@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231213190842.3844987-4-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Decouples feature checking logic from bpf_object using a feat_supported helper.,"Libbpf, feature checking, decouple",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c6c5be3eee975ae640966844db66d404c1de79b1,c6c5be3eee975ae640966844db66d404c1de79b1,Andrii Nakryiko,andrii@kernel.org,1702494514,Alexei Starovoitov,ast@kernel.org,1702511224,192b7deee31859e25e5c398eeba69b76fecde9ab,f5fdb51fb980077a4c6c78f3f775821f611fb38b,"libbpf: split feature detectors definitions from cached results

Split a list of supported feature detectors with their corresponding
callbacks from actual cached supported/missing values. This will allow
to have more flexible per-token or per-object feature detectors in
subsequent refactorings.

Acked-by: John Fastabend <john.fastabend@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231213190842.3844987-3-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit separates feature detectors definitions from cached results for more flexibility in libbpf.,"libbpf,feature detectors,refactoring",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f5fdb51fb980077a4c6c78f3f775821f611fb38b,f5fdb51fb980077a4c6c78f3f775821f611fb38b,Andrii Nakryiko,andrii@kernel.org,1702494513,Alexei Starovoitov,ast@kernel.org,1702511224,fa1e7a72820564b8bab55f1c448f446d68b0c41f,f04f2ce6018f3cb33ac96270b9153c2920ead190,"bpf: fail BPF_TOKEN_CREATE if no delegation option was set on BPF FS

It's quite confusing in practice when it's possible to successfully
create a BPF token from BPF FS that didn't have any of delegate_xxx
mount options set up. While it's not wrong"," it's actually more
meaningful to reject BPF_TOKEN_CREATE with specific error code (-ENOENT)
to let user-space know that no token delegation is setup up.

So","["" instead of creating empty BPF token that will be always ignored\nbecause it doesn't have any of the allow_xxx bits set"", ' reject it with\n-ENOENT. If we ever need empty BPF token to be possible', ' we can support\nthat with extra flag passed into BPF_TOKEN_CREATE.\n\nAcked-by: Christian Brauner <brauner@kernel.org>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231213190842.3844987-2-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit modifies BPF_TOKEN_CREATE to fail with -ENOENT if no delegation option is set on BPF FS.,"BPF_TOKEN_CREATE, delegation, ENOENT",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f04f2ce6018f3cb33ac96270b9153c2920ead190,f04f2ce6018f3cb33ac96270b9153c2920ead190,Daniel Xu,dxu@dxuuu.xyz,1702326009,Martin KaFai Lau,martin.lau@kernel.org,1702510939,ac228342dfc73df332fd8e2e6683eda4e974faba,7d19c00e9abc8ad3b3b72a1989331f45287e6bf5,"bpf: selftests: Add verifier tests for CO-RE bitfield writes

Add some tests that exercise BPF_CORE_WRITE_BITFIELD() macro. Since some
non-trivial bit fiddling is going on"," make sure various edge cases (such
as adjacent bitfields and bitfields at the edge of structs) are
exercised.

Acked-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Daniel Xu <dxu@dxuuu.xyz>
Link: https://lore.kernel.org/r/72698a1080fa565f541d5654705255984ea2a029.1702325874.git.dxu@dxuuu.xyz
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Add selftests for CO-RE bitfield writes in the eBPF verifier.,"CO-RE, selftests, bitfield",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7d19c00e9abc8ad3b3b72a1989331f45287e6bf5,7d19c00e9abc8ad3b3b72a1989331f45287e6bf5,Daniel Xu,dxu@dxuuu.xyz,1702326008,Martin KaFai Lau,martin.lau@kernel.org,1702510939,43d32ff70ef9ac3c32d6069727533e8221773375,2f70803532e9b7f14897d17f8944d431755661a7,"bpf: selftests: test_loader: Support __btf_path() annotation

This commit adds support for per-prog btf_custom_path. This is necessary
for testing CO-RE relocations on non-vmlinux types using test_loader
infrastructure.

Acked-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Daniel Xu <dxu@dxuuu.xyz>
Link: https://lore.kernel.org/r/660ea7f2fdbdd5103bc1af87c9fc931f05327926.1702325874.git.dxu@dxuuu.xyz
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,This commit adds support for per-prog BTF custom paths for testing CO-RE relocations.,"selftests,test_loader,BTF",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2f70803532e9b7f14897d17f8944d431755661a7,2f70803532e9b7f14897d17f8944d431755661a7,Daniel Xu,dxu@dxuuu.xyz,1702326007,Martin KaFai Lau,martin.lau@kernel.org,1702510939,ab08d0b4221ea3a86efbe26efcfff7ac2b20bac7,750e785796bb72423b97cac21ecd0fa3b3b65610,"libbpf: Add BPF_CORE_WRITE_BITFIELD() macro

=== Motivation ===

Similar to reading from CO-RE bitfields"," we need a CO-RE aware bitfield
writing wrapper to make the verifier happy.

Two alternatives to this approach are:

1. Use the upcoming `preserve_static_offset` [0] attribute to disable
   CO-RE on specific structs.
2. Use broader byte-sized writes to write to bitfields.

(1) is a bit hard to use. It requires specific and not-very-obvious
annotations to bpftool generated vmlinux.h. It's also not generally
available in released LLVM versions yet.

(2) makes the code quite hard to read and write. And especially if
BPF_CORE_READ_BITFIELD() is already being used","[' it makes more sense to\nto have an inverse helper for writing.\n\n=== Implementation details ===\n\nSince the logic is a bit non-obvious', "" I thought it would be helpful\nto explain exactly what's going on.\n\nTo start"", ' it helps by explaining what LSHIFT_U64 (lshift) and RSHIFT_U64\n(rshift) is designed to mean. Consider the core of the\nBPF_CORE_READ_BITFIELD() algorithm:\n\n        val <<= __CORE_RELO(s', ' field', ' LSHIFT_U64);\n        val = val >> __CORE_RELO(s', ' field', ' RSHIFT_U64);\n\nBasically what happens is we lshift to clear the non-relevant (blank)\nhigher order bits. Then we rshift to bring the relevant bits (bitfield)\ndown to LSB position (while also clearing blank lower order bits). To\nillustrate:\n\n        Start:    ........XXX......\n        Lshift:   XXX......00000000\n        Rshift:   00000000000000XXX\n\nwhere `.` means blank bit', ' `0` means 0 bit', ' and `X` means bitfield bit.\n\nAfter the two operations', ' the bitfield is ready to be interpreted as a\nregular integer.\n\nNext', ' we want to build an alternative (but more helpful) mental model\non lshift and rshift. That is', ' to consider:\n\n* rshift as the total number of blank bits in the u64\n* lshift as number of blank bits left of the bitfield in the u64\n\nTake a moment to consider why that is true by consulting the above\ndiagram.\n\nWith this insight', ' we can now define the following relationship:\n\n              bitfield\n                 _\n                | |\n        0.....00XXX0...00\n        |      |   |    |\n        |______|   |    |\n         lshift    |    |\n                   |____|\n              (rshift - lshift)\n\nThat is', ' we know the number of higher order blank bits is just lshift.\nAnd the number of lower order blank bits is (rshift - lshift).\n\nFinally', ' we can examine the core of the write side algorithm:\n\n        mask = (~0ULL << rshift) >> lshift;              // 1\n        val = (val & ~mask) | ((nval << rpad) & mask);   // 2\n\n1. Compute a mask where the set bits are the bitfield bits. The first\n   left shift zeros out exactly the number of blank bits', ' leaving a\n   bitfield sized set of 1s. The subsequent right shift inserts the\n   correct amount of higher order blank bits.\n\n2. On the left of the `|`', ' mask out the bitfield bits. This creates\n   0s where the new bitfield bits will go. On the right of the `|`', '\n   bring nval into the correct bit position and mask out any bits\n   that fall outside of the bitfield. Finally', "" by bor'ing the two\n   halves"", ' we get the final set of bits to write back.\n\n[0]: https://reviews.llvm.org/D133361\nCo-developed-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nCo-developed-by: Jonathan Lemon <jlemon@aviatrix.com>\nSigned-off-by: Jonathan Lemon <jlemon@aviatrix.com>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Xu <dxu@dxuuu.xyz>\nLink: https://lore.kernel.org/r/4d3dd215a4fd57d980733886f9c11a45e1a9adf3.1702325874.git.dxu@dxuuu.xyz\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Add new macro BPF_CORE_WRITE_BITFIELD() in libbpf for CO-RE bitfield writing.,"macro, libbpf, bitfield",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
750e785796bb72423b97cac21ecd0fa3b3b65610,750e785796bb72423b97cac21ecd0fa3b3b65610,Jie Jiang,jiejiang@chromium.org,1702373963,Andrii Nakryiko,andrii@kernel.org,1702510662,f45a5ce7eeff2440d7a9bce98d8f584666473ed0,62d9a969f4a95219c757831e9ad66cd4dd9edee5,"bpf: Support uid and gid when mounting bpffs

Parse uid and gid in bpf_parse_param() so that they can be passed in as
the `data` parameter when mount() bpffs. This will be useful when we
want to control which user/group has the control to the mounted bpffs","
otherwise a separate chown() call will be needed.

Signed-off-by: Jie Jiang <jiejiang@chromium.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Mike Frysinger <vapier@chromium.org>
Acked-by: Christian Brauner <brauner@kernel.org>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20231212093923.497838-1-jiejiang@chromium.org
",[''],The commit adds support for uid and gid when mounting bpffs to control user/group access.,"uid,gid,bpffs",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
62d9a969f4a95219c757831e9ad66cd4dd9edee5,62d9a969f4a95219c757831e9ad66cd4dd9edee5,Andrii Nakryiko,andrii@kernel.org,1702421623,Alexei Starovoitov,ast@kernel.org,1702492036,ea7d27642c644b1bdaa949b40d68de7a99b8f79d,e1ba7f64b192f083b4423644be03bb9e3dc8ae84,"selftests/bpf: fix compiler warnings in RELEASE=1 mode

When compiling BPF selftests with RELEASE=1"," we get two new
warnings","[' which are treated as errors. Fix them.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nLink: https://lore.kernel.org/r/20231212225343.1723081-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit fixes compiler warnings in BPF selftests when using RELEASE=1.,"compiler, warnings, selftests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
43e8832fed08438e2a27afed9bac21acd0ceffe5,43e8832fed08438e2a27afed9bac21acd0ceffe5,John Hubbard,jhubbard@nvidia.com,1702087304,Andrew Morton,akpm@linux-foundation.org,1702430419,d8bc723f4f4aba6048f5262e2d879350b2aac92c,1dd11e977360ad3493812da0b05ffd9adcdd15a1,"Revert ""selftests: error out if kernel header files are not yet built""

This reverts commit 9fc96c7c19df (""selftests: error out if kernel header
files are not yet built"").

It turns out that requiring the kernel headers to be built as a
prerequisite to building selftests"," does not work in many cases. For
example","[' Peter Zijlstra writes:\n\n""My biggest beef with the whole thing is that I simply do not want to use\n\'make headers\'', "" it doesn't work for me.\n\nI have a ton of output directories and I don't care to build tools into\nthe output dirs"", ' in fact some of them flat out refuse to work that way\n(bpf comes to mind)."" [1]\n\nTherefore', ' stop erroring out on the selftests build. Additional patches\nwill be required in order to change over to not requiring the kernel\nheaders.\n\n[1] https://lore.kernel.org/20231208221007.GO28727@noisy.programming.kicks-ass.net\n\nLink: https://lkml.kernel.org/r/20231209020144.244759-1-jhubbard@nvidia.com\nFixes: 9fc96c7c19df (""selftests: error out if kernel header files are not yet built"")\nSigned-off-by: John Hubbard <jhubbard@nvidia.com>\nCc: Anders Roxell <anders.roxell@linaro.org>\nCc: Muhammad Usama Anjum <usama.anjum@collabora.com>\nCc: David Hildenbrand <david@redhat.com>\nCc: Peter Xu <peterx@redhat.com>\nCc: Jonathan Corbet <corbet@lwn.net>\nCc: Nathan Chancellor <nathan@kernel.org>\nCc: Shuah Khan <shuah@kernel.org>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Marcos Paulo de Souza <mpdesouza@suse.com>\nCc: <stable@vger.kernel.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\n', '']",Revert a change requiring kernel headers to be built before selftests due to compatibility issues.,"revert,selftests,headers",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
e1ba7f64b192f083b4423644be03bb9e3dc8ae84,e1ba7f64b192f083b4423644be03bb9e3dc8ae84,YiFei Zhu,zhuyifei@google.com,1702405751,Andrii Nakryiko,andrii@kernel.org,1702425214,b17c94ac4d510c0f573e4207f1ed02c046aac3cd,745e0311306507ddbe1727ac798c8f956812b810,"selftests/bpf: Relax time_tai test for equal timestamps in tai_forward

We're observing test flakiness on an arm64 platform which might not
have timestamps as precise as x86. The test log looks like:

  test_time_tai:PASS:tai_open 0 nsec
  test_time_tai:PASS:test_run 0 nsec
  test_time_tai:PASS:tai_ts1 0 nsec
  test_time_tai:PASS:tai_ts2 0 nsec
  test_time_tai:FAIL:tai_forward unexpected tai_forward: actual 1702348135471494160 <= expected 1702348135471494160
  test_time_tai:PASS:tai_gettime 0 nsec
  test_time_tai:PASS:tai_future_ts1 0 nsec
  test_time_tai:PASS:tai_future_ts2 0 nsec
  test_time_tai:PASS:tai_range_ts1 0 nsec
  test_time_tai:PASS:tai_range_ts2 0 nsec
  #199     time_tai:FAIL

This patch changes ASSERT_GT to ASSERT_GE in the tai_forward assertion
so that equal timestamps are permitted.

Fixes: 64e15820b987 (""selftests/bpf: Add BPF-helper test for CLOCK_TAI access"")
Signed-off-by: YiFei Zhu <zhuyifei@google.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20231212182911.3784108-1-zhuyifei@google.com
",,Relaxed the tai_forward test assertion to allow equal timestamps to fix flakiness in ARM64 platforms.,"test, timestamps, ARM64",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
745e0311306507ddbe1727ac798c8f956812b810,745e0311306507ddbe1727ac798c8f956812b810,Andrei Matei,andreimatei1@gmail.com,1702248710,Andrii Nakryiko,andrii@kernel.org,1702424132,b21a12da3e98d9621086ab49e6d4b2c2e103db58,56c26d5ad86dfe48a76855a91b523ab4f372c003,"bpf: Comment on check_mem_size_reg

This patch adds a comment to check_mem_size_reg -- a function whose
meaning is not very transparent. The function implicitly deals with two
registers connected by convention"," which is not obvious.

Signed-off-by: Andrei Matei <andreimatei1@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20231210225149.67639-1-andreimatei1@gmail.com
",[''],Added comments to clarify functionality of check_mem_size_reg function in bpf code.,"comments, check_mem_size_reg, function",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5805c82513c444333efb086017be8d666336858a,5805c82513c444333efb086017be8d666336858a,Ian Rogers,irogers@google.com,1701237722,Arnaldo Carvalho de Melo,acme@redhat.com,1702403713,dccb7163cb771cc7637126d4c712fa82a3fb9c38,effe957c6bb70cac12918c0f5fd4cefb35967618,"libperf cpumap: Add for_each_cpu() that skips the ""any CPU"" case

When iterating CPUs in a CPU map it is often desirable to skip the ""any
CPU"" (aka dummy) case. Add a helper for this and use in builtin-record.

Reviewed-by: James Clark <james.clark@arm.com>
Signed-off-by: Ian Rogers <irogers@google.com>
Cc: Adrian Hunter <adrian.hunter@intel.com>
Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
Cc: Alexandre Ghiti <alexghiti@rivosinc.com>
Cc: Andrew Jones <ajones@ventanamicro.com>
Cc: André Almeida <andrealmeid@igalia.com>
Cc: Athira Jajeev <atrajeev@linux.vnet.ibm.com>
Cc: Atish Patra <atishp@rivosinc.com>
Cc: Changbin Du <changbin.du@huawei.com>
Cc: Darren Hart <dvhart@infradead.org>
Cc: Davidlohr Bueso <dave@stgolabs.net>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Ingo Molnar <mingo@redhat.com>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: John Garry <john.g.garry@oracle.com>
Cc: K Prateek Nayak <kprateek.nayak@amd.com>
Cc: Kajol Jain <kjain@linux.ibm.com>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: Leo Yan <leo.yan@linaro.org>
Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Mike Leach <mike.leach@linaro.org>
Cc: Namhyung Kim <namhyung@kernel.org>
Cc: Nick Desaulniers <ndesaulniers@google.com>
Cc: Paolo Bonzini <pbonzini@redhat.com>
Cc: Paran Lee <p4ranlee@gmail.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Sandipan Das <sandipan.das@amd.com>
Cc: Sean Christopherson <seanjc@google.com>
Cc: Steinar H. Gunderson <sesse@google.com>
Cc: Suzuki Poulouse <suzuki.poulose@arm.com>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Will Deacon <will@kernel.org>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Yang Li <yang.lee@linux.alibaba.com>
Cc: Yanteng Si <siyanteng@loongson.cn>
Cc: bpf@vger.kernel.org
Cc: coresight@lists.linaro.org
Cc: linux-arm-kernel@lists.infradead.org
Link: https://lore.kernel.org/r/20231129060211.1890454-6-irogers@google.com
Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
",,"Add a helper function for iterating CPUs in a CPU map that skips the ""any CPU"" case in libperf.","libperf, cpumap, helper",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
effe957c6bb70cac12918c0f5fd4cefb35967618,effe957c6bb70cac12918c0f5fd4cefb35967618,Ian Rogers,irogers@google.com,1701237721,Arnaldo Carvalho de Melo,acme@redhat.com,1702403713,e3c45ab066f748aec276c02f97dfbbd9fd7ffb98,923ca62a7b1edceaa61eb6ac8dc56fdac51913b8,"libperf cpumap: Replace usage of perf_cpu_map__new(NULL) with perf_cpu_map__new_online_cpus()

Passing NULL to perf_cpu_map__new() performs
perf_cpu_map__new_online_cpus()"," just directly call
perf_cpu_map__new_online_cpus() to be more intention revealing.

Reviewed-by: James Clark <james.clark@arm.com>
Signed-off-by: Ian Rogers <irogers@google.com>
Cc: Adrian Hunter <adrian.hunter@intel.com>
Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
Cc: Alexandre Ghiti <alexghiti@rivosinc.com>
Cc: Andrew Jones <ajones@ventanamicro.com>
Cc: André Almeida <andrealmeid@igalia.com>
Cc: Athira Jajeev <atrajeev@linux.vnet.ibm.com>
Cc: Atish Patra <atishp@rivosinc.com>
Cc: Changbin Du <changbin.du@huawei.com>
Cc: Darren Hart <dvhart@infradead.org>
Cc: Davidlohr Bueso <dave@stgolabs.net>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Ingo Molnar <mingo@redhat.com>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: John Garry <john.g.garry@oracle.com>
Cc: K Prateek Nayak <kprateek.nayak@amd.com>
Cc: Kajol Jain <kjain@linux.ibm.com>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: Leo Yan <leo.yan@linaro.org>
Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Mike Leach <mike.leach@linaro.org>
Cc: Namhyung Kim <namhyung@kernel.org>
Cc: Nick Desaulniers <ndesaulniers@google.com>
Cc: Paolo Bonzini <pbonzini@redhat.com>
Cc: Paran Lee <p4ranlee@gmail.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Sandipan Das <sandipan.das@amd.com>
Cc: Sean Christopherson <seanjc@google.com>
Cc: Steinar H. Gunderson <sesse@google.com>
Cc: Suzuki Poulouse <suzuki.poulose@arm.com>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Will Deacon <will@kernel.org>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Yang Li <yang.lee@linux.alibaba.com>
Cc: Yanteng Si <siyanteng@loongson.cn>
Cc: bpf@vger.kernel.org
Cc: coresight@lists.linaro.org
Cc: linux-arm-kernel@lists.infradead.org
Link: https://lore.kernel.org/r/20231129060211.1890454-5-irogers@google.com
Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
",[''],Replaces perf_cpu_map__new(NULL) with perf_cpu_map__new_online_cpus() for clearer intention in libperf cpumap.,"libperf, cpumap, intention",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
923ca62a7b1edceaa61eb6ac8dc56fdac51913b8,923ca62a7b1edceaa61eb6ac8dc56fdac51913b8,Ian Rogers,irogers@google.com,1701237720,Arnaldo Carvalho de Melo,acme@redhat.com,1702403713,4e8e184704835cbf9216d5549b772b6d4ea36443,8f60f870a9af53295ab4301da05ca453f115a6b6,"libperf cpumap: Rename perf_cpu_map__empty() to perf_cpu_map__has_any_cpu_or_is_empty()

The name perf_cpu_map_empty is misleading as true is also returned
when the map contains an ""any"" CPU (aka dummy) map.

Rename to perf_cpu_map__has_any_cpu_or_is_empty()"," later changes will
(re)introduce perf_cpu_map__empty() and perf_cpu_map__has_any_cpu().

Reviewed-by: James Clark <james.clark@arm.com>
Signed-off-by: Ian Rogers <irogers@google.com>
Cc: Adrian Hunter <adrian.hunter@intel.com>
Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
Cc: Alexandre Ghiti <alexghiti@rivosinc.com>
Cc: Andrew Jones <ajones@ventanamicro.com>
Cc: André Almeida <andrealmeid@igalia.com>
Cc: Athira Jajeev <atrajeev@linux.vnet.ibm.com>
Cc: Atish Patra <atishp@rivosinc.com>
Cc: Changbin Du <changbin.du@huawei.com>
Cc: Darren Hart <dvhart@infradead.org>
Cc: Davidlohr Bueso <dave@stgolabs.net>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Ingo Molnar <mingo@redhat.com>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: John Garry <john.g.garry@oracle.com>
Cc: K Prateek Nayak <kprateek.nayak@amd.com>
Cc: Kajol Jain <kjain@linux.ibm.com>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: Leo Yan <leo.yan@linaro.org>
Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Mike Leach <mike.leach@linaro.org>
Cc: Namhyung Kim <namhyung@kernel.org>
Cc: Nick Desaulniers <ndesaulniers@google.com>
Cc: Paolo Bonzini <pbonzini@redhat.com>
Cc: Paran Lee <p4ranlee@gmail.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Sandipan Das <sandipan.das@amd.com>
Cc: Sean Christopherson <seanjc@google.com>
Cc: Steinar H. Gunderson <sesse@google.com>
Cc: Suzuki Poulouse <suzuki.poulose@arm.com>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Will Deacon <will@kernel.org>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Yang Li <yang.lee@linux.alibaba.com>
Cc: Yanteng Si <siyanteng@loongson.cn>
Cc: bpf@vger.kernel.org
Cc: coresight@lists.linaro.org
Cc: linux-arm-kernel@lists.infradead.org
Link: https://lore.kernel.org/r/20231129060211.1890454-4-irogers@google.com
Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
",[''],Renamed a misleading function in libperf cpumap to improve accuracy and clarity.,"function, rename, libperf",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
8f60f870a9af53295ab4301da05ca453f115a6b6,8f60f870a9af53295ab4301da05ca453f115a6b6,Ian Rogers,irogers@google.com,1701237719,Arnaldo Carvalho de Melo,acme@redhat.com,1702403691,fe0d76023e83ba03a938c71e806e21b6297ee12f,48219b089d84f109e8a81d8a7fa1bbc2e6e5f97d,"libperf cpumap: Rename perf_cpu_map__default_new() to perf_cpu_map__new_online_cpus() and prefer sysfs

Rename perf_cpu_map__default_new() to perf_cpu_map__new_online_cpus() to
better indicate what the implementation does.

Read the online CPUs from /sys/devices/system/cpu/online first before
using sysconf() as it can't accurately configure holes in the CPU map.

If sysconf() is used"," warn when the configured and online processors
disagree.

When reading from a file","["" if the read doesn't yield a CPU map then\nreturn an empty map rather than the default online. This avoids\nrecursion but also better yields being able to detect failures.\n\nAdd more comments.\n\nReviewed-by: James Clark <james.clark@arm.com>\nSigned-off-by: Ian Rogers <irogers@google.com>\nCc: Adrian Hunter <adrian.hunter@intel.com>\nCc: Alexander Shishkin <alexander.shishkin@linux.intel.com>\nCc: Alexandre Ghiti <alexghiti@rivosinc.com>\nCc: Andrew Jones <ajones@ventanamicro.com>\nCc: André Almeida <andrealmeid@igalia.com>\nCc: Athira Jajeev <atrajeev@linux.vnet.ibm.com>\nCc: Atish Patra <atishp@rivosinc.com>\nCc: Changbin Du <changbin.du@huawei.com>\nCc: Darren Hart <dvhart@infradead.org>\nCc: Davidlohr Bueso <dave@stgolabs.net>\nCc: Huacai Chen <chenhuacai@kernel.org>\nCc: Ingo Molnar <mingo@redhat.com>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: John Garry <john.g.garry@oracle.com>\nCc: K Prateek Nayak <kprateek.nayak@amd.com>\nCc: Kajol Jain <kjain@linux.ibm.com>\nCc: Kan Liang <kan.liang@linux.intel.com>\nCc: Leo Yan <leo.yan@linaro.org>\nCc: Mark Rutland <mark.rutland@arm.com>\nCc: Mike Leach <mike.leach@linaro.org>\nCc: Namhyung Kim <namhyung@kernel.org>\nCc: Nick Desaulniers <ndesaulniers@google.com>\nCc: Paolo Bonzini <pbonzini@redhat.com>\nCc: Paran Lee <p4ranlee@gmail.com>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Ravi Bangoria <ravi.bangoria@amd.com>\nCc: Sandipan Das <sandipan.das@amd.com>\nCc: Sean Christopherson <seanjc@google.com>\nCc: Steinar H. Gunderson <sesse@google.com>\nCc: Suzuki Poulouse <suzuki.poulose@arm.com>\nCc: Thomas Gleixner <tglx@linutronix.de>\nCc: Will Deacon <will@kernel.org>\nCc: Yang Jihong <yangjihong1@huawei.com>\nCc: Yang Li <yang.lee@linux.alibaba.com>\nCc: Yanteng Si <siyanteng@loongson.cn>\nCc: bpf@vger.kernel.org\nCc: coresight@lists.linaro.org\nCc: linux-arm-kernel@lists.infradead.org\nLink: https://lore.kernel.org/r/20231129060211.1890454-3-irogers@google.com\n[ s/syfs/sysfs/g typo ]\nSigned-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>\n"", '']",The commit renames a function to better describe its function of reading online CPUs from sysfs in the libperf library.,"rename, libperf, cpumap",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
56c26d5ad86dfe48a76855a91b523ab4f372c003,56c26d5ad86dfe48a76855a91b523ab4f372c003,Yang Li,yang.lee@linux.alibaba.com,1702342476,Andrii Nakryiko,andrii@kernel.org,1702403527,4faf507a12b0dd6209e75b4b9b82a32d901c2111,f77d795618b92ac6fdb43de0d4036c6ce49f0b82,"bpf: Remove unused backtrack_state helper functions

The function are defined in the verifier.c file"," but not called
elsewhere","["" so delete the unused function.\n\nkernel/bpf/verifier.c:3448:20: warning: unused function 'bt_set_slot'\nkernel/bpf/verifier.c:3453:20: warning: unused function 'bt_clear_slot'\nkernel/bpf/verifier.c:3488:20: warning: unused function 'bt_is_slot_set'\n\nReported-by: Abaci Robot <abaci@linux.alibaba.com>\nSigned-off-by: Yang Li <yang.lee@linux.alibaba.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/bpf/20231212005436.103829-1-yang.lee@linux.alibaba.com\n\nCloses: https://bugzilla.openanolis.cn/show_bug.cgi?id=7714\n"", '']",Remove unused helper functions from verifier.c file in bpf codebase.,"unused, backtrack, helper",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f77d795618b92ac6fdb43de0d4036c6ce49f0b82,f77d795618b92ac6fdb43de0d4036c6ce49f0b82,Manu Bretelle,chantr4@gmail.com,1702318053,Andrii Nakryiko,andrii@kernel.org,1702403507,bdd7ffd7f63d34d778f1296294fd194ee2da17ec,406a6fa44bfbc8563f0612b08d43df2fa65e8bc5,"selftests/bpf: Fixes tests for filesystem kfuncs

`fs_kfuncs.c`'s `test_xattr` would fail the test even when the
filesystem did not support xattr"," for instance when /tmp is mounted as
tmpfs.

This change checks errno when setxattr fail. If the failure is due to
the operation being unsupported","[' we will skip the test (just like we\nwould if verity was not enabled on the FS.\n\nBefore the change', "" fs_kfuncs test would fail in test_axattr:\n\n $ vmtest -k $(make -s image_name) './tools/testing/selftests/bpf/test_progs -a fs_kfuncs'\n => bzImage\n ===> Booting\n [    0.000000] rcu:        RCU restricting CPUs from NR_CPUS=128 to\n nr_cpu_\n ===> Setting up VM\n ===> Running command\n [    4.157491] bpf_testmod: loading out-of-tree module taints kernel.\n [    4.161515] bpf_testmod: module verification failed: signature and/or\n required key missing - tainting kernel\n test_xattr:PASS:create_file 0 nsec\n test_xattr:FAIL:setxattr unexpected error: -1 (errno 95)\n #90/1    fs_kfuncs/xattr:FAIL\n #90/2    fs_kfuncs/fsverity:SKIP\n #90      fs_kfuncs:FAIL\n\n All error logs:\n test_xattr:PASS:create_file 0 nsec\n test_xattr:FAIL:setxattr unexpected error: -1 (errno 95)\n #90/1    fs_kfuncs/xattr:FAIL\n #90      fs_kfuncs:FAIL\n\n Summary: 0/0 PASSED"", ' 1 SKIPPED', "" 1 FAILED\n\nTest plan:\n\n  $ touch tmpfs_file && truncate -s 1G tmpfs_file && mkfs.ext4 tmpfs_file\n  # /tmp mounted as tmpfs\n  $ vmtest -k $(make -s image_name) './tools/testing/selftests/bpf/test_progs -a fs_kfuncs'\n  => bzImage\n  ===> Booting\n  ===> Setting up VM\n  ===> Running command\n  WARNING! Selftests relying on bpf_testmod.ko will be skipped.\n  Can't find bpf_testmod.ko kernel module: -2\n  #90/1    fs_kfuncs/xattr:SKIP\n  #90/2    fs_kfuncs/fsverity:SKIP\n  #90      fs_kfuncs:SKIP\n  Summary: 1/0 PASSED"", ' 2 SKIPPED', "" 0 FAILED\n  # /tmp mounted as ext4 with xattr enabled but not verity\n  $ vmtest -k $(make -s image_name) 'mount -o loop tmpfs_file /tmp && \\\n    /tools/testing/selftests/bpf/test_progs -a fs_kfuncs'\n  => bzImage\n  ===> Booting\n  ===> Setting up VM\n  ===> Running command\n  [    4.067071] loop0: detected capacity change from 0 to 2097152\n  [    4.191882] EXT4-fs (loop0): mounted filesystem\n  407ffa36-4553-4c8c-8c78-134443630f69 r/w with ordered data mode. Quota\n  mode: none.\n  WARNING! Selftests relying on bpf_testmod.ko will be skipped.\n  Can't find bpf_testmod.ko kernel module: -2\n  #90/1    fs_kfuncs/xattr:OK\n  #90/2    fs_kfuncs/fsverity:SKIP\n  #90      fs_kfuncs:OK (SKIP: 1/2)\n  Summary: 1/1 PASSED"", ' 1 SKIPPED', ' 0 FAILED\n  $ tune2fs -O verity tmpfs_file\n  # /tmp as ext4 with both xattr and verity enabled\n  $ vmtest -k $(make -s image_name) \'mount -o loop tmpfs_file /tmp && \\\n    ./tools/testing/selftests/bpf/test_progs -a fs_kfuncs\'\n  => bzImage\n  ===> Booting\n  ===> Setting up VM\n  ===> Running command\n  [    4.291434] loop0: detected capacity change from 0 to 2097152\n  [    4.460828] EXT4-fs (loop0): recovery complete\n  [    4.468631] EXT4-fs (loop0): mounted filesystem\n  7b4a7b7f-c442-4b06-9ede-254e63cceb52 r/w with ordered data mode. Quota\n  mode: none.\n  [    4.988074] fs-verity: sha256 using implementation ""sha256-generic""\n  WARNING! Selftests relying on bpf_testmod.ko will be skipped.\n  Can\'t find bpf_testmod.ko kernel module: -2\n  #90/1    fs_kfuncs/xattr:OK\n  #90/2    fs_kfuncs/fsverity:OK\n  #90      fs_kfuncs:OK\n  Summary: 1/2 PASSED', ' 0 SKIPPED', ' 0 FAILED\n\nFixes: 341f06fdddf7 (""selftests/bpf: Add tests for filesystem kfuncs"")\nSigned-off-by: Manu Bretelle <chantr4@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nLink: https://lore.kernel.org/bpf/20231211180733.763025-1-chantr4@gmail.com\n', '']",Fixes tests for filesystem kfuncs by checking errno when setxattr fails due to unsupported operations.,"fixes, filesystem, kfuncs",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
48219b089d84f109e8a81d8a7fa1bbc2e6e5f97d,48219b089d84f109e8a81d8a7fa1bbc2e6e5f97d,Ian Rogers,irogers@google.com,1701237718,Arnaldo Carvalho de Melo,acme@redhat.com,1702400507,29d8dcfadc1e834b1755cfe5002ecf10112501d4,8596ba324356a7392a6639024de8c9ae7a9fce92,"libperf cpumap: Rename perf_cpu_map__dummy_new() to perf_cpu_map__new_any_cpu()

Rename perf_cpu_map__dummy_new() to perf_cpu_map__new_any_cpu() to
better indicate this is creating a CPU map for the perf_event_open ""any""
CPU case.

Reviewed-by: James Clark <james.clark@arm.com>
Signed-off-by: Ian Rogers <irogers@google.com>
Cc: Adrian Hunter <adrian.hunter@intel.com>
Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
Cc: Alexandre Ghiti <alexghiti@rivosinc.com>
Cc: Andrew Jones <ajones@ventanamicro.com>
Cc: André Almeida <andrealmeid@igalia.com>
Cc: Athira Jajeev <atrajeev@linux.vnet.ibm.com>
Cc: Atish Patra <atishp@rivosinc.com>
Cc: Changbin Du <changbin.du@huawei.com>
Cc: Darren Hart <dvhart@infradead.org>
Cc: Davidlohr Bueso <dave@stgolabs.net>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Ingo Molnar <mingo@redhat.com>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: John Garry <john.g.garry@oracle.com>
Cc: K Prateek Nayak <kprateek.nayak@amd.com>
Cc: Kajol Jain <kjain@linux.ibm.com>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: Leo Yan <leo.yan@linaro.org>
Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Mike Leach <mike.leach@linaro.org>
Cc: Namhyung Kim <namhyung@kernel.org>
Cc: Nick Desaulniers <ndesaulniers@google.com>
Cc: Paolo Bonzini <pbonzini@redhat.com>
Cc: Paran Lee <p4ranlee@gmail.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Sandipan Das <sandipan.das@amd.com>
Cc: Sean Christopherson <seanjc@google.com>
Cc: Steinar H. Gunderson <sesse@google.com>
Cc: Suzuki Poulouse <suzuki.poulose@arm.com>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Will Deacon <will@kernel.org>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Yang Li <yang.lee@linux.alibaba.com>
Cc: Yanteng Si <siyanteng@loongson.cn>
Cc: bpf@vger.kernel.org
Cc: coresight@lists.linaro.org
Cc: linux-arm-kernel@lists.infradead.org
Link: https://lore.kernel.org/r/20231129060211.1890454-2-irogers@google.com
Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
",,Renamed perf_cpu_map__dummy_new() to perf_cpu_map__new_any_cpu() to clarify its purpose for 'any' CPU in perf_event_open.,"CPU map, renaming, perf_event_open",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
406a6fa44bfbc8563f0612b08d43df2fa65e8bc5,406a6fa44bfbc8563f0612b08d43df2fa65e8bc5,Andrii Nakryiko,andrii@kernel.org,1701733162,Alexei Starovoitov,ast@kernel.org,1702351417,6d216977ef78128f00c85d37d653756217906ffb,1a1ad782dcbbacd9e8d4e2e7ff1bf14d1db80727,"bpf: use bitfields for simple per-subprog bool flags

We have a bunch of bool flags for each subprog. Instead of wasting bytes
for them"," use bitfields instead.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20231204233931.49758-5-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The commit optimizes memory usage by utilizing bitfields for subprogram boolean flags.,"bitfields, bool flags, subprog",It's a performance optimization.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1a1ad782dcbbacd9e8d4e2e7ff1bf14d1db80727,1a1ad782dcbbacd9e8d4e2e7ff1bf14d1db80727,Andrii Nakryiko,andrii@kernel.org,1701733161,Alexei Starovoitov,ast@kernel.org,1702351412,2ef700bf4b474dc18dec4fcb804892f6b0887edd,22b769bb4f87060774bfdd6facbab438ed3b8453,"bpf: tidy up exception callback management a bit

Use the fact that we are passing subprog index around and have
a corresponding struct bpf_subprog_info in bpf_verifier_env for each
subprogram. We don't need to separately pass around a flag whether
subprog is exception callback or not"," each relevant verifier function
can determine this using provided subprog index if we maintain
bpf_subprog_info properly.

Also move out exception callback-specific logic from
btf_prepare_func_args()","[' keeping it generic. We can enforce all these\nrestriction right before exception callback verification pass. We add\nout parameter', ' arg_cnt', ' for now', ' but this will be unnecessary with\nsubsequent refactoring and will be removed.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20231204233931.49758-4-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Refactor exception callback management using bpf_subprog_info with subprog index in bpf_verifier_env.,"exception, subprog, management",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
22b769bb4f87060774bfdd6facbab438ed3b8453,22b769bb4f87060774bfdd6facbab438ed3b8453,Andrii Nakryiko,andrii@kernel.org,1701733160,Alexei Starovoitov,ast@kernel.org,1702351282,6bf0bc18436d65f9bb2586b476c2a2c1dcb74059,1e68485d8299860e68c4e1d29589ff0d20db0287,"bpf: emit more dynptr information in verifier log

Emit dynptr type for CONST_PTR_TO_DYNPTR register. Also emit id","
ref_obj_id","[' and dynptr_id fields for STACK_DYNPTR stack slots.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20231204233931.49758-3-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit enhances the verifier log by emitting more dynptr information including type and ID for CONST_PTR_TO_DYNPTR.,"dynptr,verifier log,CONST_PTR_TO_DYNPTR",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1e68485d8299860e68c4e1d29589ff0d20db0287,1e68485d8299860e68c4e1d29589ff0d20db0287,Andrii Nakryiko,andrii@kernel.org,1701733159,Alexei Starovoitov,ast@kernel.org,1702351282,f31114becd2070bb20ca79ba97020dd419c8c7e3,e72c1ccfd449598f7eda10d3bb7441d501ddcfc3,"bpf: log PTR_TO_MEM memory size in verifier log

Emit valid memory size addressable through PTR_TO_MEM register.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20231204233931.49758-2-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Addability to log memory size for PTR_TO_MEM in the verifier.,"PTR_TO_MEM,memory size,verifier",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e72c1ccfd449598f7eda10d3bb7441d501ddcfc3,e72c1ccfd449598f7eda10d3bb7441d501ddcfc3,Andrii Nakryiko,andrii@kernel.org,1702316491,Alexei Starovoitov,ast@kernel.org,1702350992,7a2c8fc5c837b5a8a74a5360c5129adf9a1a9b0f,2ebe81c814355d000fe49d9c4213983844dcb32b,"selftests/bpf: validate eliminated global subprog is not freplaceable

Add selftest that establishes dead code-eliminated valid global subprog
(global_dead) and makes sure that it's not possible to freplace it"," as
it's effectively not there. This test will fail with unexpected success
before 2afae08c9dcb (""bpf: Validate global subprogs lazily"").

v2->v3:
  - add missing err assignment (Alan);
  - undo unnecessary signature changes in verifier_global_subprogs.c (Eduard);
v1->v2:
  - don't rely on assembly output in verifier log","[' which changes between\n    compiler versions (CI).\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nReviewed-by: Alan Maguire <alan.maguire@oracle.com>\nSuggested-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nLink: https://lore.kernel.org/r/20231211174131.2324306-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add selftest for global subprogs to ensure non-freplaceability of dead code-eliminated subprograms.,"selftest, global subprog, freplace",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2ebe81c814355d000fe49d9c4213983844dcb32b,2ebe81c814355d000fe49d9c4213983844dcb32b,Aleksander Lobakin,aleksander.lobakin@intel.com,1701896359,Daniel Borkmann,daniel@iogearbox.net,1702307376,695a116c8cea02abc891dd2e3181e11adc48ba57,15c79c6507c0eab5ec0d4cd402ac52d42735a43e,net," xdp: Allow metadata > 32

32 bytes may be not enough for some custom metadata. Relax the restriction","['\nallow metadata larger than 32 bytes and make __skb_metadata_differs() work\nwith bigger lengths.\n\nNow size of metadata is only limited by the fact it is stored as u8 in\nskb_shared_info', ' so maximum possible value is 255. Size still has to be\naligned to 4', ' so the actual upper limit becomes 252. Most driver\nimplementations will offer less', ' none can offer more.\n\nOther important conditions', ' such as having enough space for xdp_frame\nbuilding', ' are already checked in bpf_xdp_adjust_meta().\n\nSigned-off-by: Aleksander Lobakin <aleksander.lobakin@intel.com>\nSigned-off-by: Larysa Zaremba <larysa.zaremba@intel.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/eb87653c-8ff8-447d-a7a1-25961f60518a@kernel.org\nLink: https://lore.kernel.org/bpf/20231206205919.404415-3-larysa.zaremba@intel.com\n', '']",The commit relaxes the metadata size restriction in XDP programs from 32 bytes to allow larger custom metadata.,"metadata,XDP,restriction",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF maps,['xdp like programs']
15c79c6507c0eab5ec0d4cd402ac52d42735a43e,15c79c6507c0eab5ec0d4cd402ac52d42735a43e,Larysa Zaremba,larysa.zaremba@intel.com,1701896358,Daniel Borkmann,daniel@iogearbox.net,1702307364,66d682e925a5199c0bf9e747ead7a9cd9455d8f0,5bcbdf72df88a351642627d94b93af7c9301b6e2,"selftests/bpf: Increase invalid metadata size

Changed check expects passed data meta to be deemed invalid. After loosening
the requirement", the size of 36 bytes becomes valid. Therefore,"[' increase\ntested meta size to 256', ' so we do not get an unexpected success.\n\nSigned-off-by: Larysa Zaremba <larysa.zaremba@intel.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20231206205919.404415-2-larysa.zaremba@intel.com\n', '']",Increased invalid metadata size in selftests to ensure 36 bytes is recognized as valid.,"invalid, metadata, selftests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5bcbdf72df88a351642627d94b93af7c9301b6e2,5bcbdf72df88a351642627d94b93af7c9301b6e2,Alexei Starovoitov,ast@kernel.org,1702186653,Alexei Starovoitov,ast@kernel.org,1702186653,21a2ba3658473f297c164c78c15ef1ce6eedec20,5181dc08f79583c6dead80208137a97e68ff07b0 88f6047191e69bdd02cf1b9b5b514f7e514e8b86,"Merge branch 'add-new-bpf_cpumask_weight-kfunc'

David Vernet says:

====================
Add new bpf_cpumask_weight() kfunc

It can be useful to query how many bits are set in a cpumask. For
example"," if you want to perform special logic for the last remaining
core that's set in a mask. This logic is already exposed through the
main kernel's cpumask header as cpumask_weight()","[' so it would be useful\nto add a new bpf_cpumask_weight() kfunc which wraps it and does the\nsame.\n\nThis patch series was built and tested on top of commit 2146f7fe6e02\n(""Merge branch \'allocate-bpf-trampoline-on-bpf_prog_pack\'"").\n====================\n\nLink: https://lore.kernel.org/r/20231207210843.168466-1-void@manifault.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit adds a new bpf_cpumask_weight() kfunc to query the number of set bits in a cpumask.,"bpf_cpumask_weight,kfunc,cpumask",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
88f6047191e69bdd02cf1b9b5b514f7e514e8b86,88f6047191e69bdd02cf1b9b5b514f7e514e8b86,David Vernet,void@manifault.com,1701983323,Alexei Starovoitov,ast@kernel.org,1702186653,21a2ba3658473f297c164c78c15ef1ce6eedec20,a6de18f310a511278c1ff16b96eb2d500eada725,"selftests/bpf: Add test for bpf_cpumask_weight() kfunc

The new bpf_cpumask_weight() kfunc can be used to count the number of
bits that are set in a struct cpumask* kptr. Let's add a selftest to
verify its behavior.

Signed-off-by: David Vernet <void@manifault.com>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20231207210843.168466-3-void@manifault.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add a selftest for the new bpf_cpumask_weight() kfunc for verifying its functionality.,"selftest,kfunc,bpf_cpumask_weight",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a6de18f310a511278c1ff16b96eb2d500eada725,a6de18f310a511278c1ff16b96eb2d500eada725,David Vernet,void@manifault.com,1701983322,Alexei Starovoitov,ast@kernel.org,1702186653,e3a2a52d95faf82312d1e13f815fc797a4b6bf4a,5181dc08f79583c6dead80208137a97e68ff07b0,"bpf: Add bpf_cpumask_weight() kfunc

It can be useful to query how many bits are set in a cpumask. For
example"," if you want to perform special logic for the last remaining
core that's set in a mask. Let's therefore add a new
bpf_cpumask_weight() kfunc which checks how many bits are set in a mask.

Signed-off-by: David Vernet <void@manifault.com>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20231207210843.168466-2-void@manifault.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Added a new kfunc bpf_cpumask_weight to count bits set in a cpumask.,"bpf_cpumask_weight,kfunc,cpumask",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5181dc08f79583c6dead80208137a97e68ff07b0,5181dc08f79583c6dead80208137a97e68ff07b0,Tiezhu Yang,yangtiezhu@loongson.cn,1701922131,Alexei Starovoitov,ast@kernel.org,1702186074,9473a401170286e5d0ecf3e7936fa081ca3215b6,7d8ed51bcb32716a40d71043fcd01c4118858c51,"test_bpf: Rename second ALU64_SMOD_X to ALU64_SMOD_K

Currently"," there are two test cases with same name
""ALU64_SMOD_X: -7 % 2 = -1""","[' the first one is right', '\nthe second one should be ALU64_SMOD_K because its\ncode is BPF_ALU64 | BPF_MOD | BPF_K.\n\nBefore:\ntest_bpf: #170 ALU64_SMOD_X: -7 % 2 = -1 jited:1 4 PASS\ntest_bpf: #171 ALU64_SMOD_X: -7 % 2 = -1 jited:1 4 PASS\n\nAfter:\ntest_bpf: #170 ALU64_SMOD_X: -7 % 2 = -1 jited:1 4 PASS\ntest_bpf: #171 ALU64_SMOD_K: -7 % 2 = -1 jited:1 4 PASS\n\nFixes: daabb2b098e0 (""bpf/tests: add tests for cpuv4 instructions"")\nSigned-off-by: Tiezhu Yang <yangtiezhu@loongson.cn>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20231207040851.19730-1-yangtiezhu@loongson.cn\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit renames a duplicate test case in test_bpf to uniquely identify ALU64_SMOD_X operations.,"rename, test cases, ALU64_SMOD",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7d8ed51bcb32716a40d71043fcd01c4118858c51,7d8ed51bcb32716a40d71043fcd01c4118858c51,Andrii Nakryiko,andrii@kernel.org,1702084198,Alexei Starovoitov,ast@kernel.org,1702176200,767e8c161fbe31ff256f95197b9a96c615134c5d,482d548d40b0af9af730e4869903d4433e44f014,"selftests/bpf: validate fake register spill/fill precision backtracking logic

Add two tests validating that verifier's precision backtracking logic
handles BPF_ST_MEM instructions that produce fake register spill into
register slot. This is happening when non-zero constant is written
directly to a slot", e.g.,"[' *(u64 *)(r10 -8) = 123.\n\nAdd both full 64-bit register spill', ' as well as 32-bit ""sub-spill"".\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20231209010958.66758-2-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Added tests for verifier's precision backtracking logic in BPF register spill handling.,"precision, verifier, tests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
482d548d40b0af9af730e4869903d4433e44f014,482d548d40b0af9af730e4869903d4433e44f014,Andrii Nakryiko,andrii@kernel.org,1702084197,Alexei Starovoitov,ast@kernel.org,1702176200,c557d70945c6e3c8c9478df6b4ebc0639090c5bf,8477fe1de9a631d634ccfda7fe147eba90f55732,"bpf: handle fake register spill to stack with BPF_ST_MEM instruction

When verifier validates BPF_ST_MEM instruction that stores known
constant to stack (e.g.", *(u64 *)(r10 - 8) = 123),"[' it effectively spills\na fake register with a constant (but initially imprecise) value to\na stack slot. Because read-side logic treats it as a proper register\nfill from stack slot', ' we need to mark such stack slot initialization as\nINSN_F_STACK_ACCESS instruction to stop precision backtracking from\nmissing it.\n\nFixes: 41f6f64e6999 (""bpf: support non-r10 register spill/fill to/from stack in precision tracking"")\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20231209010958.66758-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Enhances the eBPF verifier to correctly handle BPF_ST_MEM instruction when storing known constants to stack.,"BPF_ST_MEM, verifier, stack",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8477fe1de9a631d634ccfda7fe147eba90f55732,8477fe1de9a631d634ccfda7fe147eba90f55732,Alexei Starovoitov,ast@kernel.org,1702174354,Alexei Starovoitov,ast@kernel.org,1702174403,c83148f14906289ef86d99908011d97a4fb8aba1,32fa058398624166dd04ff4af49cfef69c94abbc 06e5c999f10269a532304e89a6adb2fbfeb0593c,"Merge branch 'bpf-fixes-for-maybe_wait_bpf_programs'

Hou Tao says:

====================
The patch set aims to fix the problems found when inspecting the code
related with maybe_wait_bpf_programs().

Patch #1 removes unnecessary invocation of maybe_wait_bpf_programs().
Patch #2 calls maybe_wait_bpf_programs() only once for batched update.
Patch #3 adds the missed waiting when doing batched lookup_deletion on
htab of maps. Patch #4 does wait only if the update or deletion
operation succeeds. Patch #5 fixes the value of batch.count when memory
allocation fails.
====================

Link: https://lore.kernel.org/r/20231208102355.2628918-1-houtao@huaweicloud.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit addresses issues with maybe_wait_bpf_programs in batched operations and enhances memory allocation handling for eBPF maps.,"maybe_wait_bpf_programs, batched update, maps",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
06e5c999f10269a532304e89a6adb2fbfeb0593c,06e5c999f10269a532304e89a6adb2fbfeb0593c,Hou Tao,houtao1@huawei.com,1702031033,Alexei Starovoitov,ast@kernel.org,1702174354,c83148f14906289ef86d99908011d97a4fb8aba1,67ad2c73ff29b32bd09135ec07c26e59490dbb3b,"bpf: Set uattr->batch.count as zero before batched update or deletion

generic_map_{delete","update}_batch() doesn't set uattr->batch.count as
zero before it tries to allocate memory for key. If the memory
allocation fails","[' the value of uattr->batch.count will be incorrect.\n\nFix it by setting uattr->batch.count as zero beore batched update or\ndeletion.\n\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20231208102355.2628918-6-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit sets uattr->batch.count to zero before performing memory allocations for batched updates or deletions.,"uattr, batch, update",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
67ad2c73ff29b32bd09135ec07c26e59490dbb3b,67ad2c73ff29b32bd09135ec07c26e59490dbb3b,Hou Tao,houtao1@huawei.com,1702031032,Alexei Starovoitov,ast@kernel.org,1702174354,9345409ae3b7a1e2f94272b4f60bc90d53f1767f,012772581d040607ac1f981f47f6afd2336b4580,"bpf: Only call maybe_wait_bpf_programs() when map operation succeeds

There is no need to call maybe_wait_bpf_programs() if update or deletion
operation fails. So only call maybe_wait_bpf_programs() if update or
deletion operation succeeds.

Signed-off-by: Hou Tao <houtao1@huawei.com>
Link: https://lore.kernel.org/r/20231208102355.2628918-5-houtao@huaweicloud.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Optimize bpf map operation to conditionally call maybe_wait_bpf_programs() only on success.,"bpf,map,operation",It's a performance optimization.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
012772581d040607ac1f981f47f6afd2336b4580,012772581d040607ac1f981f47f6afd2336b4580,Hou Tao,houtao1@huawei.com,1702031031,Alexei Starovoitov,ast@kernel.org,1702174354,fc505f0096d9b01c5dbc856091c2d6553b253093,37ba5b59d6adfa08926acd3a833608487a18c2ef,"bpf: Add missed maybe_wait_bpf_programs() for htab of maps

When doing batched lookup and deletion operations on htab of maps","
maybe_wait_bpf_programs() is needed to ensure all programs don't use the
inner map after the bpf syscall returns.

Instead of adding the wait in __htab_map_lookup_and_delete_batch()","['\nadding the wait in bpf_map_do_batch() and also removing the calling of\nmaybe_wait_bpf_programs() from generic_map_{delete', 'update}_batch().\n\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20231208102355.2628918-4-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add maybe_wait_bpf_programs() to ensure safe usage of maps after batched operations in eBPF.,"maybe_wait_bpf_programs, htab, maps",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
37ba5b59d6adfa08926acd3a833608487a18c2ef,37ba5b59d6adfa08926acd3a833608487a18c2ef,Hou Tao,houtao1@huawei.com,1702031030,Alexei Starovoitov,ast@kernel.org,1702174353,cccd27023efa3c6f4e7e06d5a77864f14bf59391,c26f2a8901393c9f81909da0a4324587092bd3a3,"bpf: Call maybe_wait_bpf_programs() only once for generic_map_update_batch()

Just like commit 9087c6ff8dfe (""bpf: Call maybe_wait_bpf_programs() only
once from generic_map_delete_batch()"")"," there is also no need to call
maybe_wait_bpf_programs() for each update in batched update","[' so only\ncall it once in generic_map_update_batch().\n\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20231208102355.2628918-3-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Optimize the call to maybe_wait_bpf_programs() by executing it once for generic_map_update_batch().,"maybe_wait_bpf_programs, generic_map_update_batch, optimize",It's a performance optimization.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c26f2a8901393c9f81909da0a4324587092bd3a3,c26f2a8901393c9f81909da0a4324587092bd3a3,Hou Tao,houtao1@huawei.com,1702031029,Alexei Starovoitov,ast@kernel.org,1702174353,50adfc5b3ca444245c15cc36ddc1e86ac01fade6,32fa058398624166dd04ff4af49cfef69c94abbc,"bpf: Remove unnecessary wait from bpf_map_copy_value()

Both map_lookup_elem() and generic_map_lookup_batch() use
bpf_map_copy_value() to lookup and copy the value"," and there is no
update operation in bpf_map_copy_value()","[' so just remove the invocation\nof maybe_wait_bpf_programs() from it.\n\nFixes: 15c14a3dca42 (""bpf: Add bpf_map_{value_size', ' update_value', ' map_copy_value} functions"")\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20231208102355.2628918-2-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit removes unnecessary waiting from the function bpf_map_copy_value.,"remove unnecessary wait, map_copy_value, map_lookup_elem",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b10a3ccaf6e39f6290ca29d7c24604082eacaea0,b10a3ccaf6e39f6290ca29d7c24604082eacaea0,Linus Torvalds,torvalds@linux-foundation.org,1702153556,Linus Torvalds,torvalds@linux-foundation.org,1702153556,9d79bc020f449a4304aeeb867eb72300b3dc376b,b8503b215789628d3625ef6aa252f323e32be929 e2f7b3d8b4b300956a77fa1ab084c931ba1c7421,"Merge tag 'loongarch-fixes-6.7-2' of git://git.kernel.org/pub/scm/linux/kernel/git/chenhuacai/linux-loongson

Pull LoongArch fixes from Huacai Chen:
 ""Preserve syscall nr across execve()", slightly clean up drdtime(),"[' fix\n  the Clang built zboot kernel', ' fix a stack unwinder bug and several bpf\n  jit bugs""\n\n* tag \'loongarch-fixes-6.7-2\' of git://git.kernel.org/pub/scm/linux/kernel/git/chenhuacai/linux-loongson:\n  LoongArch: BPF: Fix unconditional bswap instructions\n  LoongArch: BPF: Fix sign-extension mov instructions\n  LoongArch: BPF: Don\'t sign extend function return value\n  LoongArch: BPF: Don\'t sign extend memory load operand\n  LoongArch: Preserve syscall nr across execve()\n  LoongArch: Set unwind stack type to unknown rather than set error flag\n  LoongArch: Slightly clean up drdtime()\n  LoongArch: Apply dynamic relocations for LLD\n', '']",Merge LoongArch fixes for preserving syscall number across execve and cleaning up drdtime.,"LoongArch, syscall, fixes",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
e2f7b3d8b4b300956a77fa1ab084c931ba1c7421,e2f7b3d8b4b300956a77fa1ab084c931ba1c7421,Tiezhu Yang,yangtiezhu@loongson.cn,1702108156,Huacai Chen,chenhuacai@loongson.cn,1702108156,c678faf50b2669118ad237bd7c63959c57f8c760,772cbe948fb07389639d4e698a2d3299f8e538b8,"LoongArch: BPF: Fix unconditional bswap instructions

We can see that ""bswap32: Takes an unsigned 32-bit number in either big-
or little-endian format and returns the equivalent number with the same
bit width but opposite endianness"" in BPF Instruction Set Specification","
so it should clear the upper 32 bits in ""case 32:"" for both BPF_ALU and
BPF_ALU64.

[root@linux fedora]# echo 1 > /proc/sys/net/core/bpf_jit_enable
[root@linux fedora]# modprobe test_bpf

Before:
test_bpf: #313 BSWAP 32: 0x0123456789abcdef -> 0xefcdab89 jited:1 ret 1460850314 != -271733879 (0x5712ce8a != 0xefcdab89)FAIL (1 times)
test_bpf: #317 BSWAP 32: 0xfedcba9876543210 -> 0x10325476 jited:1 ret -1460850316 != 271733878 (0xa8ed3174 != 0x10325476)FAIL (1 times)

After:
test_bpf: #313 BSWAP 32: 0x0123456789abcdef -> 0xefcdab89 jited:1 4 PASS
test_bpf: #317 BSWAP 32: 0xfedcba9876543210 -> 0x10325476 jited:1 4 PASS

Fixes: 4ebf9216e7df (""LoongArch: BPF: Support unconditional bswap instructions"")
Acked-by: Hengqi Chen <hengqi.chen@gmail.com>
Signed-off-by: Tiezhu Yang <yangtiezhu@loongson.cn>
Signed-off-by: Huacai Chen <chenhuacai@loongson.cn>
",[''],Fix the unconditional bswap instruction bug for LoongArch BPF.,"bswap, LoongArch, fix",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The JIT compiler,['other']
772cbe948fb07389639d4e698a2d3299f8e538b8,772cbe948fb07389639d4e698a2d3299f8e538b8,Tiezhu Yang,yangtiezhu@loongson.cn,1702108156,Huacai Chen,chenhuacai@loongson.cn,1702108156,c6382a817363ec69c522b955a705bdd546d86983,5d47ec2e6f4c64e30e392cfe9532df98c9beb106,"LoongArch: BPF: Fix sign-extension mov instructions

We can see that ""Short form of movsx", dst_reg = (s8,"['s16', 's32)src_reg"" in\ninclude/linux/filter.h', ' additionally', ' for BPF_ALU64 the value of the\ndestination register is unchanged whereas for BPF_ALU the upper 32 bits\nof the destination register are zeroed', ' so it should clear the upper 32\nbits for BPF_ALU.\n\n[root@linux fedora]# echo 1 > /proc/sys/net/core/bpf_jit_enable\n[root@linux fedora]# modprobe test_bpf\n\nBefore:\ntest_bpf: #81 ALU_MOVSX | BPF_B jited:1 ret 2 != 1 (0x2 != 0x1)FAIL (1 times)\ntest_bpf: #82 ALU_MOVSX | BPF_H jited:1 ret 2 != 1 (0x2 != 0x1)FAIL (1 times)\n\nAfter:\ntest_bpf: #81 ALU_MOVSX | BPF_B jited:1 6 PASS\ntest_bpf: #82 ALU_MOVSX | BPF_H jited:1 6 PASS\n\nBy the way', ' the bpf selftest case ""./test_progs -t verifier_movsx"" can\nalso be fixed with this patch.\n\nFixes: f48012f16150 (""LoongArch: BPF: Support sign-extension mov instructions"")\nAcked-by: Hengqi Chen <hengqi.chen@gmail.com>\nSigned-off-by: Tiezhu Yang <yangtiezhu@loongson.cn>\nSigned-off-by: Huacai Chen <chenhuacai@loongson.cn>\n', '']",Fixes sign-extension mov instructions for LoongArch in BPF.,"LoongArch,BPF,fix",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5d47ec2e6f4c64e30e392cfe9532df98c9beb106,5d47ec2e6f4c64e30e392cfe9532df98c9beb106,Hengqi Chen,hengqi.chen@gmail.com,1702108156,Huacai Chen,chenhuacai@loongson.cn,1702108156,aef94a75a7ee60b5f638b7fa9afd551c8b9a015f,fe5757553bf9ebe45ae8ecab5922f6937c8d8dfc,"LoongArch: BPF: Don't sign extend function return value

The `cls_redirect` test triggers a kernel panic like:

  # ./test_progs -t cls_redirect
  Can't find bpf_testmod.ko kernel module: -2
  WARNING! Selftests relying on bpf_testmod.ko will be skipped.
  [   30.938489] CPU 3 Unable to handle kernel paging request at virtual address fffffffffd814de0", era == ffff800002009fb8,"[' ra == ffff800002009f9c\n  [   30.939331] Oops[#1]:\n  [   30.939513] CPU: 3 PID: 1260 Comm: test_progs Not tainted 6.7.0-rc2-loong-devel-g2f56bb0d2327 #35 a896aca3f4164f09cc346f89f2e09832e07be5f6\n  [   30.939732] Hardware name: QEMU QEMU Virtual Machine', ' BIOS unknown 2/2/2022\n  [   30.939901] pc ffff800002009fb8 ra ffff800002009f9c tp 9000000104da4000 sp 9000000104da7ab0\n  [   30.940038] a0 fffffffffd814de0 a1 9000000104da7a68 a2 0000000000000000 a3 9000000104da7c10\n  [   30.940183] a4 9000000104da7c14 a5 0000000000000002 a6 0000000000000021 a7 00005555904d7f90\n  [   30.940321] t0 0000000000000110 t1 0000000000000000 t2 fffffffffd814de0 t3 0004c4b400000000\n  [   30.940456] t4 ffffffffffffffff t5 00000000c3f63600 t6 0000000000000000 t7 0000000000000000\n  [   30.940590] t8 000000000006d803 u0 0000000000000020 s9 9000000104da7b10 s0 900000010504c200\n  [   30.940727] s1 fffffffffd814de0 s2 900000010504c200 s3 9000000104da7c10 s4 9000000104da7ad0\n  [   30.940866] s5 0000000000000000 s6 90000000030e65bc s7 9000000104da7b44 s8 90000000044f6fc0\n  [   30.941015]    ra: ffff800002009f9c bpf_prog_846803e5ae81417f_cls_redirect+0xa0/0x590\n  [   30.941535]   ERA: ffff800002009fb8 bpf_prog_846803e5ae81417f_cls_redirect+0xbc/0x590\n  [   30.941696]  CRMD: 000000b0 (PLV0 -IE -DA +PG DACF=CC DACM=CC -WE)\n  [   30.942224]  PRMD: 00000004 (PPLV0 +PIE -PWE)\n  [   30.942330]  EUEN: 00000003 (+FPE +SXE -ASXE -BTE)\n  [   30.942453]  ECFG: 00071c1c (LIE=2-4', '10-12 VS=7)\n  [   30.942612] ESTAT: 00010000 [PIL] (IS= ECode=1 EsubCode=0)\n  [   30.942764]  BADV: fffffffffd814de0\n  [   30.942854]  PRID: 0014c010 (Loongson-64bit', ' Loongson-3A5000)\n  [   30.942974] Modules linked in:\n  [   30.943078] Process test_progs (pid: 1260', ' threadinfo=00000000ce303226', ' task=000000007d10bb76)\n  [   30.943306] Stack : 900000010a064000 90000000044f6fc0 9000000104da7b48 0000000000000000\n  [   30.943495]         0000000000000000 9000000104da7c14 9000000104da7c10 900000010504c200\n  [   30.943626]         0000000000000001 ffff80001b88c000 9000000104da7b70 90000000030e6668\n  [   30.943785]         0000000000000000 9000000104da7b58 ffff80001b88c048 9000000003d05000\n  [   30.943936]         900000000303ac88 0000000000000000 0000000000000000 9000000104da7b70\n  [   30.944091]         0000000000000000 0000000000000001 0000000731eeab00 0000000000000000\n  [   30.944245]         ffff80001b88c000 0000000000000000 0000000000000000 54b99959429f83b8\n  [   30.944402]         ffff80001b88c000 90000000044f6fc0 9000000101d70000 ffff80001b88c000\n  [   30.944538]         000000000000005a 900000010504c200 900000010a064000 900000010a067000\n  [   30.944697]         9000000104da7d88 0000000000000000 9000000003d05000 90000000030e794c\n  [   30.944852]         ...\n  [   30.944924] Call Trace:\n  [   30.945120] [<ffff800002009fb8>] bpf_prog_846803e5ae81417f_cls_redirect+0xbc/0x590\n  [   30.945650] [<90000000030e6668>] bpf_test_run+0x1ec/0x2f8\n  [   30.945958] [<90000000030e794c>] bpf_prog_test_run_skb+0x31c/0x684\n  [   30.946065] [<90000000026d4f68>] __sys_bpf+0x678/0x2724\n  [   30.946159] [<90000000026d7288>] sys_bpf+0x20/0x2c\n  [   30.946253] [<90000000032dd224>] do_syscall+0x7c/0x94\n  [   30.946343] [<9000000002541c5c>] handle_syscall+0xbc/0x158\n  [   30.946492]\n  [   30.946549] Code: 0015030e  5c0009c0  5001d000 <28c00304> 02c00484  29c00304  00150009  2a42d2e4  0280200d\n  [   30.946793]\n  [   30.946971] ---[ end trace 0000000000000000 ]---\n  [   32.093225] Kernel panic - not syncing: Fatal exception in interrupt\n  [   32.093526] Kernel relocated by 0x2320000\n  [   32.093630]  .text @ 0x9000000002520000\n  [   32.093725]  .data @ 0x9000000003400000\n  [   32.093792]  .bss  @ 0x9000000004413200\n  [   34.971998] ---[ end Kernel panic - not syncing: Fatal exception in interrupt ]---\n\nThis is because we signed-extend function return values. When subprog\nmode is enabled', ' we have:\n\n  cls_redirect()\n    -> get_global_metrics() returns pcpu ptr 0xfffffefffc00b480\n\nThe pointer returned is later signed-extended to 0xfffffffffc00b480 at\n`BPF_JMP | BPF_EXIT`. During BPF prog run', ' this triggers unhandled page\nfault and a kernel panic.\n\nDrop the unnecessary signed-extension on return values like other\narchitectures do.\n\nWith this change', "" we have:\n\n  # ./test_progs -t cls_redirect\n  Can't find bpf_testmod.ko kernel module: -2\n  WARNING! Selftests relying on bpf_testmod.ko will be skipped.\n  #51/1    cls_redirect/cls_redirect_inlined:OK\n  #51/2    cls_redirect/IPv4 TCP accept unknown (no hops"", ' flags: SYN):OK\n  #51/3    cls_redirect/IPv6 TCP accept unknown (no hops', ' flags: SYN):OK\n  #51/4    cls_redirect/IPv4 TCP accept unknown (no hops', ' flags: ACK):OK\n  #51/5    cls_redirect/IPv6 TCP accept unknown (no hops', ' flags: ACK):OK\n  #51/6    cls_redirect/IPv4 TCP forward unknown (one hop', ' flags: ACK):OK\n  #51/7    cls_redirect/IPv6 TCP forward unknown (one hop', ' flags: ACK):OK\n  #51/8    cls_redirect/IPv4 TCP accept known (one hop', ' flags: ACK):OK\n  #51/9    cls_redirect/IPv6 TCP accept known (one hop', ' flags: ACK):OK\n  #51/10   cls_redirect/IPv4 UDP accept unknown (no hops', ' flags: none):OK\n  #51/11   cls_redirect/IPv6 UDP accept unknown (no hops', ' flags: none):OK\n  #51/12   cls_redirect/IPv4 UDP forward unknown (one hop', ' flags: none):OK\n  #51/13   cls_redirect/IPv6 UDP forward unknown (one hop', ' flags: none):OK\n  #51/14   cls_redirect/IPv4 UDP accept known (one hop', ' flags: none):OK\n  #51/15   cls_redirect/IPv6 UDP accept known (one hop', ' flags: none):OK\n  #51/16   cls_redirect/cls_redirect_subprogs:OK\n  #51/17   cls_redirect/IPv4 TCP accept unknown (no hops', ' flags: SYN):OK\n  #51/18   cls_redirect/IPv6 TCP accept unknown (no hops', ' flags: SYN):OK\n  #51/19   cls_redirect/IPv4 TCP accept unknown (no hops', ' flags: ACK):OK\n  #51/20   cls_redirect/IPv6 TCP accept unknown (no hops', ' flags: ACK):OK\n  #51/21   cls_redirect/IPv4 TCP forward unknown (one hop', ' flags: ACK):OK\n  #51/22   cls_redirect/IPv6 TCP forward unknown (one hop', ' flags: ACK):OK\n  #51/23   cls_redirect/IPv4 TCP accept known (one hop', ' flags: ACK):OK\n  #51/24   cls_redirect/IPv6 TCP accept known (one hop', ' flags: ACK):OK\n  #51/25   cls_redirect/IPv4 UDP accept unknown (no hops', ' flags: none):OK\n  #51/26   cls_redirect/IPv6 UDP accept unknown (no hops', ' flags: none):OK\n  #51/27   cls_redirect/IPv4 UDP forward unknown (one hop', ' flags: none):OK\n  #51/28   cls_redirect/IPv6 UDP forward unknown (one hop', ' flags: none):OK\n  #51/29   cls_redirect/IPv4 UDP accept known (one hop', ' flags: none):OK\n  #51/30   cls_redirect/IPv6 UDP accept known (one hop', ' flags: none):OK\n  #51/31   cls_redirect/cls_redirect_dynptr:OK\n  #51/32   cls_redirect/IPv4 TCP accept unknown (no hops', ' flags: SYN):OK\n  #51/33   cls_redirect/IPv6 TCP accept unknown (no hops', ' flags: SYN):OK\n  #51/34   cls_redirect/IPv4 TCP accept unknown (no hops', ' flags: ACK):OK\n  #51/35   cls_redirect/IPv6 TCP accept unknown (no hops', ' flags: ACK):OK\n  #51/36   cls_redirect/IPv4 TCP forward unknown (one hop', ' flags: ACK):OK\n  #51/37   cls_redirect/IPv6 TCP forward unknown (one hop', ' flags: ACK):OK\n  #51/38   cls_redirect/IPv4 TCP accept known (one hop', ' flags: ACK):OK\n  #51/39   cls_redirect/IPv6 TCP accept known (one hop', ' flags: ACK):OK\n  #51/40   cls_redirect/IPv4 UDP accept unknown (no hops', ' flags: none):OK\n  #51/41   cls_redirect/IPv6 UDP accept unknown (no hops', ' flags: none):OK\n  #51/42   cls_redirect/IPv4 UDP forward unknown (one hop', ' flags: none):OK\n  #51/43   cls_redirect/IPv6 UDP forward unknown (one hop', ' flags: none):OK\n  #51/44   cls_redirect/IPv4 UDP accept known (one hop', ' flags: none):OK\n  #51/45   cls_redirect/IPv6 UDP accept known (one hop', ' flags: none):OK\n  #51      cls_redirect:OK\n  Summary: 1/45 PASSED', ' 0 SKIPPED', ' 0 FAILED\n\nFixes: 5dc615520c4d (""LoongArch: Add BPF JIT support"")\nSigned-off-by: Hengqi Chen <hengqi.chen@gmail.com>\nSigned-off-by: Huacai Chen <chenhuacai@loongson.cn>\n', '']",Fixes a kernel panic issue on LoongArch architecture by preventing sign extension of function return value in BPF.,"LoongArch, kernel panic, BPF",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['tc/netfilter like programs']
fe5757553bf9ebe45ae8ecab5922f6937c8d8dfc,fe5757553bf9ebe45ae8ecab5922f6937c8d8dfc,Hengqi Chen,hengqi.chen@gmail.com,1702108156,Huacai Chen,chenhuacai@loongson.cn,1702108156,1e495be87bfbc610d5ad9011658b30acd0b543fe,d6c5f06e46a836e6a70c7cfd95bb38a67d9252ec,"LoongArch: BPF: Don't sign extend memory load operand

The `cgrp_local_storage` test triggers a kernel panic like:

  # ./test_progs -t cgrp_local_storage
  Can't find bpf_testmod.ko kernel module: -2
  WARNING! Selftests relying on bpf_testmod.ko will be skipped.
  [  550.930632] CPU 1 Unable to handle kernel paging request at virtual address 0000000000000080", era == ffff80000200be34,"[' ra == ffff80000200be00\n  [  550.931781] Oops[#1]:\n  [  550.931966] CPU: 1 PID: 1303 Comm: test_progs Not tainted 6.7.0-rc2-loong-devel-g2f56bb0d2327 #35 a896aca3f4164f09cc346f89f2e09832e07be5f6\n  [  550.932215] Hardware name: QEMU QEMU Virtual Machine', ' BIOS unknown 2/2/2022\n  [  550.932403] pc ffff80000200be34 ra ffff80000200be00 tp 9000000108350000 sp 9000000108353dc0\n  [  550.932545] a0 0000000000000000 a1 0000000000000517 a2 0000000000000118 a3 00007ffffbb15558\n  [  550.932682] a4 00007ffffbb15620 a5 90000001004e7700 a6 0000000000000021 a7 0000000000000118\n  [  550.932824] t0 ffff80000200bdc0 t1 0000000000000517 t2 0000000000000517 t3 00007ffff1c06ee0\n  [  550.932961] t4 0000555578ae04d0 t5 fffffffffffffff8 t6 0000000000000004 t7 0000000000000020\n  [  550.933097] t8 0000000000000040 u0 00000000000007b8 s9 9000000108353e00 s0 90000001004e7700\n  [  550.933241] s1 9000000004005000 s2 0000000000000001 s3 0000000000000000 s4 0000555555eb2ec8\n  [  550.933379] s5 00007ffffbb15bb8 s6 00007ffff1dafd60 s7 000055555663f610 s8 00007ffff1db0050\n  [  550.933520]    ra: ffff80000200be00 bpf_prog_98f1b9e767be2a84_on_enter+0x40/0x200\n  [  550.933911]   ERA: ffff80000200be34 bpf_prog_98f1b9e767be2a84_on_enter+0x74/0x200\n  [  550.934105]  CRMD: 000000b0 (PLV0 -IE -DA +PG DACF=CC DACM=CC -WE)\n  [  550.934596]  PRMD: 00000004 (PPLV0 +PIE -PWE)\n  [  550.934712]  EUEN: 00000003 (+FPE +SXE -ASXE -BTE)\n  [  550.934836]  ECFG: 00071c1c (LIE=2-4', '10-12 VS=7)\n  [  550.934976] ESTAT: 00010000 [PIL] (IS= ECode=1 EsubCode=0)\n  [  550.935097]  BADV: 0000000000000080\n  [  550.935181]  PRID: 0014c010 (Loongson-64bit', ' Loongson-3A5000)\n  [  550.935291] Modules linked in:\n  [  550.935391] Process test_progs (pid: 1303', ' threadinfo=000000006c3b1c41', ' task=0000000061f84a55)\n  [  550.935643] Stack : 00007ffffbb15bb8 0000555555eb2ec8 0000000000000000 0000000000000001\n  [  550.935844]         9000000004005000 ffff80001b864000 00007ffffbb15450 90000000029aa034\n  [  550.935990]         0000000000000000 9000000108353ec0 0000000000000118 d07d9dfb09721a09\n  [  550.936175]         0000000000000001 0000000000000000 9000000108353ec0 0000000000000118\n  [  550.936314]         9000000101d46ad0 900000000290abf0 000055555663f610 0000000000000000\n  [  550.936479]         0000000000000003 9000000108353ec0 00007ffffbb15450 90000000029d7288\n  [  550.936635]         00007ffff1dafd60 000055555663f610 0000000000000000 0000000000000003\n  [  550.936779]         9000000108353ec0 90000000035dd1f0 00007ffff1dafd58 9000000002841c5c\n  [  550.936939]         0000000000000119 0000555555eea5a8 00007ffff1d78780 00007ffffbb153e0\n  [  550.937083]         ffffffffffffffda 00007ffffbb15518 0000000000000040 00007ffffbb15558\n  [  550.937224]         ...\n  [  550.937299] Call Trace:\n  [  550.937521] [<ffff80000200be34>] bpf_prog_98f1b9e767be2a84_on_enter+0x74/0x200\n  [  550.937910] [<90000000029aa034>] bpf_trace_run2+0x90/0x154\n  [  550.938105] [<900000000290abf0>] syscall_trace_enter.isra.0+0x1cc/0x200\n  [  550.938224] [<90000000035dd1f0>] do_syscall+0x48/0x94\n  [  550.938319] [<9000000002841c5c>] handle_syscall+0xbc/0x158\n  [  550.938477]\n  [  550.938607] Code: 580009ae  50016000  262402e4 <28c20085> 14092084  03a00084  16000024  03240084  00150006\n  [  550.938851]\n  [  550.939021] ---[ end trace 0000000000000000 ]---\n\nFurther investigation shows that this panic is triggered by memory\nload operations:\n\n  ptr = bpf_cgrp_storage_get(&map_a', ' task->cgroups->dfl_cgrp', ' 0', '\n                             BPF_LOCAL_STORAGE_GET_F_CREATE);\n\nThe expression `task->cgroups->dfl_cgrp` involves two memory load.\nSince the field offset fits in imm12 or imm14', ' we use ldd or ldptrd\ninstructions. But both instructions have the side effect that it will\nsigned-extended the imm operand. Finally', ' we got the wrong addresses\nand panics is inevitable.\n\nUse a generic ldxd instruction to avoid this kind of issues.\n\nWith this change', "" we have:\n\n  # ./test_progs -t cgrp_local_storage\n  Can't find bpf_testmod.ko kernel module: -2\n  WARNING! Selftests relying on bpf_testmod.ko will be skipped.\n  test_cgrp_local_storage:PASS:join_cgroup /cgrp_local_storage 0 nsec\n  #48/1    cgrp_local_storage/tp_btf:OK\n  test_attach_cgroup:PASS:skel_open 0 nsec\n  test_attach_cgroup:PASS:prog_attach 0 nsec\n  test_attach_cgroup:PASS:prog_attach 0 nsec\n  libbpf: prog 'update_cookie_tracing': failed to attach: ERROR: strerror_r(-524)=22\n  test_attach_cgroup:FAIL:prog_attach unexpected error: -524\n  #48/2    cgrp_local_storage/attach_cgroup:FAIL\n  test_recursion:PASS:skel_open_and_load 0 nsec\n  libbpf: prog 'on_lookup': failed to attach: ERROR: strerror_r(-524)=22\n  libbpf: prog 'on_lookup': failed to auto-attach: -524\n  test_recursion:FAIL:skel_attach unexpected error: -524 (errno 524)\n  #48/3    cgrp_local_storage/recursion:FAIL\n  #48/4    cgrp_local_storage/negative:OK\n  #48/5    cgrp_local_storage/cgroup_iter_sleepable:OK\n  test_yes_rcu_lock:PASS:skel_open 0 nsec\n  test_yes_rcu_lock:PASS:skel_load 0 nsec\n  libbpf: prog 'yes_rcu_lock': failed to attach: ERROR: strerror_r(-524)=22\n  libbpf: prog 'yes_rcu_lock': failed to auto-attach: -524\n  test_yes_rcu_lock:FAIL:skel_attach unexpected error: -524 (errno 524)\n  #48/6    cgrp_local_storage/yes_rcu_lock:FAIL\n  #48/7    cgrp_local_storage/no_rcu_lock:OK\n  #48      cgrp_local_storage:FAIL\n\n  All error logs:\n  test_cgrp_local_storage:PASS:join_cgroup /cgrp_local_storage 0 nsec\n  test_attach_cgroup:PASS:skel_open 0 nsec\n  test_attach_cgroup:PASS:prog_attach 0 nsec\n  test_attach_cgroup:PASS:prog_attach 0 nsec\n  libbpf: prog 'update_cookie_tracing': failed to attach: ERROR: strerror_r(-524)=22\n  test_attach_cgroup:FAIL:prog_attach unexpected error: -524\n  #48/2    cgrp_local_storage/attach_cgroup:FAIL\n  test_recursion:PASS:skel_open_and_load 0 nsec\n  libbpf: prog 'on_lookup': failed to attach: ERROR: strerror_r(-524)=22\n  libbpf: prog 'on_lookup': failed to auto-attach: -524\n  test_recursion:FAIL:skel_attach unexpected error: -524 (errno 524)\n  #48/3    cgrp_local_storage/recursion:FAIL\n  test_yes_rcu_lock:PASS:skel_open 0 nsec\n  test_yes_rcu_lock:PASS:skel_load 0 nsec\n  libbpf: prog 'yes_rcu_lock': failed to attach: ERROR: strerror_r(-524)=22\n  libbpf: prog 'yes_rcu_lock': failed to auto-attach: -524\n  test_yes_rcu_lock:FAIL:skel_attach unexpected error: -524 (errno 524)\n  #48/6    cgrp_local_storage/yes_rcu_lock:FAIL\n  #48      cgrp_local_storage:FAIL\n  Summary: 0/4 PASSED"", ' 0 SKIPPED', ' 1 FAILED\n\nNo panics any more (The test still failed because lack of BPF trampoline\nwhich I am actively working on).\n\nFixes: 5dc615520c4d (""LoongArch: Add BPF JIT support"")\nSigned-off-by: Hengqi Chen <hengqi.chen@gmail.com>\nSigned-off-by: Huacai Chen <chenhuacai@loongson.cn>\n', '']",Fixes kernel panic issue by modifying memory load operand behavior on LoongArch architecture.,"LoongArch,memory load,kernel panic",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
32fa058398624166dd04ff4af49cfef69c94abbc,32fa058398624166dd04ff4af49cfef69c94abbc,Sergei Trofimovich,slyich@gmail.com,1702072260,Andrii Nakryiko,andrii@kernel.org,1702084278,f32cdfd1ffa633a2877467d11fa9a87a187c50b7,09115c33e6ec4a98a0609ac5fa702b7fe566d8f9,"libbpf: Add pr_warn() for EINVAL cases in linker_sanity_check_elf

Before the change on `i686-linux` `systemd` build failed as:

    $ bpftool gen object src/core/bpf/socket_bind/socket-bind.bpf.o src/core/bpf/socket_bind/socket-bind.bpf.unstripped.o
    Error: failed to link 'src/core/bpf/socket_bind/socket-bind.bpf.unstripped.o': Invalid argument (22)

After the change it fails as:

    $ bpftool gen object src/core/bpf/socket_bind/socket-bind.bpf.o src/core/bpf/socket_bind/socket-bind.bpf.unstripped.o
    libbpf: ELF section #9 has inconsistent alignment addr=8 != d=4 in src/core/bpf/socket_bind/socket-bind.bpf.unstripped.o
    Error: failed to link 'src/core/bpf/socket_bind/socket-bind.bpf.unstripped.o': Invalid argument (22)

Now it's slightly easier to figure out what is wrong with an ELF file.

Signed-off-by: Sergei Trofimovich <slyich@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/bpf/20231208215100.435876-1-slyich@gmail.com
",,The commit enhances libbpf by adding a pr_warn() for better error reporting on EINVAL cases during linker sanity check of ELF files.,"libbpf, pr_warn, EINVAL",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
09115c33e6ec4a98a0609ac5fa702b7fe566d8f9,09115c33e6ec4a98a0609ac5fa702b7fe566d8f9,Martin KaFai Lau,martin.lau@kernel.org,1702081586,Martin KaFai Lau,martin.lau@kernel.org,1702084099,1400435b0ce3665facbd964528234417d9117ec8,1720c42b90c8f14ffcb2f2f39a1abafc82a5b22e a2c6380b17b6339bfedc98d253b6d85e7014953b,"Merge branch 'bpf: Expand bpf_cgrp_storage to support cgroup1 non-attach case'

Yafang Shao says:

====================
In the current cgroup1 environment"," associating operations between a cgroup
and applications in a BPF program requires storing a mapping of cgroup_id
to application either in a hash map or maintaining it in userspace.
However","[' by enabling bpf_cgrp_storage for cgroup1', ' it becomes possible to\nconveniently store application-specific information in cgroup-local storage\nand utilize it within BPF programs. Furthermore', ' enabling this feature for\ncgroup1 involves minor modifications for the non-attach case', ' streamlining\nthe process.\n\nHowever', ' when it comes to enabling this functionality for the cgroup1\nattach case', ' it presents challenges. Therefore', ' the decision is to focus on\nenabling it solely for the cgroup1 non-attach case at present. If\nattempting to attach to a cgroup1 fd', ' the operation will simply fail with\nthe error code -EBADF.\n\nChanges:\n- RFC -> v1:\n  - Collect acked-by\n  - Avoid unnecessary is_cgroup1 check (Yonghong)\n  - Keep the code patterns consistent (Yonghong)\n====================\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",This commit expands the bpf_cgrp_storage to support non-attach cases in cgroup1.,bpf_cgrp_storage cgroup1 non-attach,It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,['cgroup like programs']
a2c6380b17b6339bfedc98d253b6d85e7014953b,a2c6380b17b6339bfedc98d253b6d85e7014953b,Yafang Shao,laoar.shao@gmail.com,1701863606,Martin KaFai Lau,martin.lau@kernel.org,1702084098,1400435b0ce3665facbd964528234417d9117ec8,f4199271dae12ae407fa739e7012914ea6b3f37b,"selftests/bpf: Add selftests for cgroup1 local storage

Expanding the test coverage from cgroup2 to include cgroup1. The result
as follows","

Already existing test cases for cgroup2:
  #48/1    cgrp_local_storage/tp_btf:OK
  #48/2    cgrp_local_storage/attach_cgroup:OK
  #48/3    cgrp_local_storage/recursion:OK
  #48/4    cgrp_local_storage/negative:OK
  #48/5    cgrp_local_storage/cgroup_iter_sleepable:OK
  #48/6    cgrp_local_storage/yes_rcu_lock:OK
  #48/7    cgrp_local_storage/no_rcu_lock:OK

Expanded test cases for cgroup1:
  #48/8    cgrp_local_storage/cgrp1_tp_btf:OK
  #48/9    cgrp_local_storage/cgrp1_recursion:OK
  #48/10   cgrp_local_storage/cgrp1_negative:OK
  #48/11   cgrp_local_storage/cgrp1_iter_sleepable:OK
  #48/12   cgrp_local_storage/cgrp1_yes_rcu_lock:OK
  #48/13   cgrp_local_storage/cgrp1_no_rcu_lock:OK

Summary:
  #48      cgrp_local_storage:OK
  Summary: 1/13 PASSED","[' 0 SKIPPED', ' 0 FAILED\n\nSigned-off-by: Yafang Shao <laoar.shao@gmail.com>\nAcked-by: Tejun Heo <tj@kernel.org>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20231206115326.4295-4-laoar.shao@gmail.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Add selftests for cgroup1 local storage by expanding test coverage from cgroup2.,"selftests,cgroup1,test coverage",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['cgroup like programs']
f4199271dae12ae407fa739e7012914ea6b3f37b,f4199271dae12ae407fa739e7012914ea6b3f37b,Yafang Shao,laoar.shao@gmail.com,1701863605,Martin KaFai Lau,martin.lau@kernel.org,1702084098,f45ea4d4106916951d18033bbe40d446916a779f,73d9eb340d2b95e0e86a656a7f3157c137f10129,"selftests/bpf: Add a new cgroup helper open_classid()

This new helper allows us to obtain the fd of a net_cls cgroup"," which will
be utilized in the subsequent patch.

Signed-off-by: Yafang Shao <laoar.shao@gmail.com>
Acked-by: Tejun Heo <tj@kernel.org>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20231206115326.4295-3-laoar.shao@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Add a new cgroup helper to obtain the file descriptor of a net_cls cgroup.,"cgroup,helper,net_cls",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['cgroup like programs']
73d9eb340d2b95e0e86a656a7f3157c137f10129,73d9eb340d2b95e0e86a656a7f3157c137f10129,Yafang Shao,laoar.shao@gmail.com,1701863604,Martin KaFai Lau,martin.lau@kernel.org,1702084098,a442aeae6b760b983992eda002e9adce995eea10,1720c42b90c8f14ffcb2f2f39a1abafc82a5b22e,"bpf: Enable bpf_cgrp_storage for cgroup1 non-attach case

In the current cgroup1 environment"," associating operations between cgroups
and applications in a BPF program requires storing a mapping of cgroup_id
to application either in a hash map or maintaining it in userspace.
However","[' by enabling bpf_cgrp_storage for cgroup1', ' it becomes possible to\nconveniently store application-specific information in cgroup-local storage\nand utilize it within BPF programs. Furthermore', ' enabling this feature for\ncgroup1 involves minor modifications for the non-attach case', ' streamlining\nthe process.\n\nHowever', ' when it comes to enabling this functionality for the cgroup1\nattach case', ' it presents challenges. Therefore', ' the decision is to focus on\nenabling it solely for the cgroup1 non-attach case at present. If\nattempting to attach to a cgroup1 fd', ' the operation will simply fail with\nthe error code -EBADF.\n\nSigned-off-by: Yafang Shao <laoar.shao@gmail.com>\nAcked-by: Tejun Heo <tj@kernel.org>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20231206115326.4295-2-laoar.shao@gmail.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Enable cgroup storage support for BPF programs in cgroup1 non-attach mode.,"bpf,cgroup1,storage",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,['cgroup like programs']
1720c42b90c8f14ffcb2f2f39a1abafc82a5b22e,1720c42b90c8f14ffcb2f2f39a1abafc82a5b22e,Andrii Nakryiko,andrii@kernel.org,1702078228,Alexei Starovoitov,ast@kernel.org,1702083050,95c5a7d05e387c553ca5c09fd35be2478baaee16,4af20ab9edee62aa2bb5b6f31b7f029de14e0756,"selftests/bpf: fix timer/test_bad_ret subtest on test_progs-cpuv4 flavor

Because test_bad_ret main program is not written in assembly"," we don't
control instruction indices in timer_cb_ret_bad() subprog. This bites us
in timer/test_bad_ret subtest","[' where we see difference between cpuv4 and\nother flavors.\n\nFor now', ' make __msg() expectations not rely on instruction indices by\nanchoring them around bpf_get_prandom_u32 call. Once we have regex/glob\nsupport for __msg()', ' this can be expressed a bit more nicely', ' but for\nnow just mitigating the problem with available means.\n\nFixes: e02dea158dda (""selftests/bpf: validate async callback return value check correctness"")\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231208233028.3412690-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes the issue with timer/test_bad_ret subtest on the test_progs-cpuv4 by handling instruction indices in non-assembly code.,"selftests,bpf,test",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"[""It's not related to any of the above.""]"
4af20ab9edee62aa2bb5b6f31b7f029de14e0756,4af20ab9edee62aa2bb5b6f31b7f029de14e0756,Andrii Nakryiko,andrii@kernel.org,1702073940,Andrii Nakryiko,andrii@kernel.org,1702073941,fc1c424f93e93746a902718f4a0284e6fd002822,8b7b0e5fe47de90ba6c350f9abece589fb637f79 2929bfac006d8f8e22b307d04e0d71bcb84db698,"Merge branch 'bpf-fix-accesses-to-uninit-stack-slots'

Andrei Matei says:

====================
bpf: fix accesses to uninit stack slots

Fix two related issues issues around verifying stack accesses:
1. accesses to uninitialized stack memory was allowed inconsistently
2. the maximum stack depth needed for a program was not always
maintained correctly

The two issues are fixed together in one commit because the code for one
affects the other.

V4 to V5:
- target bpf-next (Alexei)

V3 to V4:
- minor fixup to comment in patch 1 (Eduard)
- C89-style in patch 3 (Andrii)

V2 to V3:
- address review comments from Andrii and Eduard
- drop new verifier tests in favor of editing existing tests to check
  for stack depth
- append a patch with a bit of cleanup coming out of the previous review
====================

Link: https://lore.kernel.org/r/20231208032519.260451-1-andreimatei1@gmail.com
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
",,Fixes issues with verifying accesses to uninitialized stack slots and maintaining maximum stack depth in bpf programs.,"uninitialized,stack,depth",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2929bfac006d8f8e22b307d04e0d71bcb84db698,2929bfac006d8f8e22b307d04e0d71bcb84db698,Andrei Matei,andreimatei1@gmail.com,1702005919,Andrii Nakryiko,andrii@kernel.org,1702073940,fc1c424f93e93746a902718f4a0284e6fd002822,6b4a64bafd107e521c01eec3453ce94a3fb38529,"bpf: Minor cleanup around stack bounds

Push the rounding up of stack offsets into the function responsible for
growing the stack"," rather than relying on all the callers to do it.
Uncertainty about whether the callers did it or not tripped up people in
a previous review.

Signed-off-by: Andrei Matei <andreimatei1@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/bpf/20231208032519.260451-4-andreimatei1@gmail.com
",[''],The commit refactors stack offset rounding into the stack growing function for cleaner code.,"cleanup, stack, bounds",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6b4a64bafd107e521c01eec3453ce94a3fb38529,6b4a64bafd107e521c01eec3453ce94a3fb38529,Andrei Matei,andreimatei1@gmail.com,1702005918,Andrii Nakryiko,andrii@kernel.org,1702073940,413fad563de5cfb78b40f9f067d563e4dcfa4221,92e1567ee3e3f6f160e320890ac77eec50bf8e7d,"bpf: Fix accesses to uninit stack slots

Privileged programs are supposed to be able to read uninitialized stack
memory (ever since 6715df8d5) but", before this patch,"[' these accesses\nwere permitted inconsistently. In particular', ' accesses were permitted\nabove state->allocated_stack', ' but not below it. In other words', ' if the\nstack was already ""large enough""', ' the access was permitted', ' but\notherwise the access was rejected instead of being allowed to ""grow the\nstack"". This undesired rejection was happening in two places:\n- in check_stack_slot_within_bounds()\n- in check_stack_range_initialized()\nThis patch arranges for these accesses to be permitted. A bunch of tests\nthat were relying on the old rejection had to change; all of them were\nchanged to add also run unprivileged', "" in which case the old behavior\npersists. One tests couldn't be updated - global_func16 - because it\ncan't run unprivileged for other reasons.\n\nThis patch also fixes the tracking of the stack size for variable-offset\nreads. This second fix is bundled in the same commit as the first one\nbecause they're inter-related. Before this patch"", ' writes to the stack\nusing registers containing a variable offset (as opposed to registers\nwith fixed', "" known values) were not properly contributing to the\nfunction's needed stack size. As a result"", ' it was possible for a program\nto verify', ' but then to attempt to read out-of-bounds data at runtime\nbecause a too small stack had been allocated for it.\n\nEach function tracks the size of the stack it needs in\nbpf_subprog_info.stack_depth', ' which is maintained by\nupdate_stack_depth(). For regular memory accesses', ' check_mem_access()\nwas calling update_state_depth() but it was passing in only the fixed\npart of the offset register', ' ignoring the variable offset. This was\nincorrect; the minimum possible value of that register should be used\ninstead.\n\nThis tracking is now fixed by centralizing the tracking of stack size in\ngrow_stack_state()', ' and by lifting the calls to grow_stack_state() to\ncheck_stack_access_within_bounds() as suggested by Andrii. The code is\nnow simpler and more convincingly tracks the correct maximum stack size.\ncheck_stack_range_initialized() can now rely on enough stack having been\nallocated for the access; this helps with the fix for the first issue.\n\nA few tests were changed to also check the stack depth computation. The\none that fails without this patch is verifier_var_off:stack_write_priv_vs_unpriv.\n\nFixes: 01f810ace9ed3 (""bpf: Allow variable-offset stack access"")\nReported-by: Hao Sun <sunhao.th@gmail.com>\nSigned-off-by: Andrei Matei <andreimatei1@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20231208032519.260451-3-andreimatei1@gmail.com\n\nCloses: https://lore.kernel.org/bpf/CABWLsev9g8UP_c3a=1qbuZUi20tGoUXoU07FPf-5FLvhOKOY+Q@mail.gmail.com/\n', '']",Fixes issue with privileged programs accessing uninitialized stack memory in eBPF.,"fix,uninitialized,stack",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
92e1567ee3e3f6f160e320890ac77eec50bf8e7d,92e1567ee3e3f6f160e320890ac77eec50bf8e7d,Andrei Matei,andreimatei1@gmail.com,1702005917,Andrii Nakryiko,andrii@kernel.org,1702073940,69bda1ccd633fd5d04916f39eea25e8004fe9cf7,8b7b0e5fe47de90ba6c350f9abece589fb637f79,"bpf: Add some comments to stack representation

Add comments to the datastructure tracking the stack state"," as the
mapping between each stack slot and where its state is stored is not
entirely obvious.

Signed-off-by: Andrei Matei <andreimatei1@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/bpf/20231208032519.260451-2-andreimatei1@gmail.com
",[''],Added comments to clarify the stack representation and state tracking in eBPF.,"comments, stack, representation",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8b7b0e5fe47de90ba6c350f9abece589fb637f79,8b7b0e5fe47de90ba6c350f9abece589fb637f79,David Vernet,void@manifault.com,1702016223,Andrii Nakryiko,andrii@kernel.org,1702057139,905614ac22caa6c66c12122ac46f8181ca105d0e,483af466e4ee3326d150877ea0626e95c67a395e,"bpf: Load vmlinux btf for any struct_ops map

In libbpf", when determining whether we need to load vmlinux btf,"["" we're\ncurrently (among other things) checking whether there is any struct_ops\nprogram present in the object. This works for most realistic struct_ops\nmaps"", ' as a struct_ops map is of course typically composed of one or more\nstruct_ops programs. However', ' that technically need not be the case. A\nstruct_ops interface could be defined which allows a map to be specified\nwhich one or more non-prog fields', ' and which provides default behavior\nif no struct_ops progs is actually provided otherwise. For sched_ext', '\nfor example', ' you technically only need to specify the name of the\nscheduler in the struct_ops map', ' with the core scheduler logic providing\ndefault behavior if no prog is actually specified.\n\nIf we were to define and try to load such a struct_ops map', ' we would\ncrash in libbpf when initializing it as obj->btf_vmlinux will be NULL:\n\nReading symbols from minimal...\n(gdb) r\nStarting program: minimal_example\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library ""/usr/lib/libthread_db.so.1"".\n\nProgram received signal SIGSEGV', ' Segmentation fault.\n0x000055555558308c in btf__type_cnt (btf=0x0) at btf.c:612\n612             return btf->start_id + btf->nr_types;\n(gdb) bt\n    type_name=0x5555555d99e3 ""sched_ext_ops""', ' kind=4) at btf.c:914\n    kind=4) at btf.c:942\n    type=0x7fffffffe558', ' type_id=0x7fffffffe548', ' ...\n    data_member=0x7fffffffe568) at libbpf.c:948\n    kern_btf=0x0) at libbpf.c:1017\n    at libbpf.c:8059\n\nSo as to account for such bare-bones struct_ops maps', "" let's update\nobj_needs_vmlinux_btf() to also iterate over an obj's maps and check\nwhether any of them are struct_ops maps.\n\nSigned-off-by: David Vernet <void@manifault.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nReviewed-by: Alan Maguire <alan.maguire@oracle.com>\nLink: https://lore.kernel.org/bpf/20231208061704.400463-1-void@manifault.com\n"", '']",The commit updates libbpf to load vmlinux BTF for any struct_ops map.,"libbpf,vmlinux,struct_ops",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5e3f5b81de80c98338bcb47c233aebefee5a4801,5e3f5b81de80c98338bcb47c233aebefee5a4801,Linus Torvalds,torvalds@linux-foundation.org,1701997453,Linus Torvalds,torvalds@linux-foundation.org,1701997453,21b4ee9f1d4ff54e810f5c9d0d29638348b1b4dd,9ace34a8e446c1a566f3b0a3e0c4c483987e39a6 b0a930e8d90caf66a94fee7a9d0b8472bc3e7561,"Merge tag 'net-6.7-rc5' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Jakub Kicinski:
 ""Including fixes from bpf and netfilter.

  Current release - regressions:

   - veth: fix packet segmentation in veth_convert_skb_to_xdp_buff

  Current release - new code bugs:

   - tcp: assorted fixes to the new Auth Option support

  Older releases - regressions:

   - tcp: fix mid stream window clamp

   - tls: fix incorrect splice handling

   - ipv4: ip_gre: handle skb_pull() failure in ipgre_xmit()

   - dsa: mv88e6xxx: restore USXGMII support for 6393X

   - arcnet: restore support for multiple Sohard Arcnet cards

  Older releases - always broken:

   - tcp: do not accept ACK of bytes we never sent

   - require admin privileges to receive packet traces via netlink

   - packet: move reference count in packet_sock to atomic_long_t

   - bpf:
      - fix incorrect branch offset comparison with cpu=v4
      - fix prog_array_map_poke_run map poke update

   - netfilter:
      - three fixes for crashes on bad admin commands
      - xt_owner: fix race accessing sk->sk_socket"," TOCTOU null-deref
      - nf_tables: fix 'exist' matching on bigendian arches

   - leds: netdev: fix RTNL handling to prevent potential deadlock

   - eth: tg3: prevent races in error/reset handling

   - eth: r8169: fix rtl8125b PAUSE storm when suspended

   - eth: r8152: improve reset and surprise removal handling

   - eth: hns: fix race between changing features and sending

   - eth: nfp: fix sleep in atomic for bonding offload""

* tag 'net-6.7-rc5' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (62 commits)
  vsock/virtio: fix ""comparison of distinct pointer types lacks a cast"" warning
  net/smc: fix missing byte order conversion in CLC handshake
  net: dsa: microchip: provide a list of valid protocols for xmit handler
  drop_monitor: Require 'CAP_SYS_ADMIN' when joining ""events"" group
  psample: Require 'CAP_NET_ADMIN' when joining ""packets"" group
  bpf: sockmap","[' updating the sg structure should also update curr\n  net: tls', "" update curr on splice as well\n  nfp: flower: fix for take a mutex lock in soft irq context and rcu lock\n  net: dsa: mv88e6xxx: Restore USXGMII support for 6393X\n  tcp: do not accept ACK of bytes we never sent\n  selftests/bpf: Add test for early update in prog_array_map_poke_run\n  bpf: Fix prog_array_map_poke_run map poke update\n  netfilter: xt_owner: Fix for unsafe access of sk->sk_socket\n  netfilter: nf_tables: validate family when identifying table via handle\n  netfilter: nf_tables: bail out on mismatching dynset and set expressions\n  netfilter: nf_tables: fix 'exist' matching on bigendian arches\n  netfilter: nft_set_pipapo: skip inactive elements during set walk\n  netfilter: bpf: fix bad registration on nf_defrag\n  leds: trigger: netdev: fix RTNL handling to prevent potential deadlock\n  octeontx2-af: Update Tx link register range\n  ...\n"", '']",The commit merges networking and eBPF related fixes for various issues in recent and older Linux kernel releases.,"networking, eBPF, fixes",It's a bug fix.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).', ""It's not related to any of the above.""]"
483af466e4ee3326d150877ea0626e95c67a395e,483af466e4ee3326d150877ea0626e95c67a395e,Andrii Nakryiko,andrii@kernel.org,1701975456,Andrii Nakryiko,andrii@kernel.org,1701986294,ceead968fb8ab47e59d6c55e3bc087a68736c8a8,2146f7fe6e028a3905f0658a1a0d8ef7c115d6c1 1d38a9ee81570c4bd61f557832dead4d6f816760,"Merge branch 'bpf-fix-verification-of-indirect-var-off-stack-access'

Andrei Matei says:

====================
bpf: fix verification of indirect var-off stack access

V4 to V5:
  - split the test into a separate patch

V3 to V4:
  - include a test per Eduard's request
  - target bpf-next per Alexei's request (patches didn't change)

V2 to V3:
  - simplify checks for max_off (don't call
    check_stack_slot_within_bounds for it)
  - append a commit to protect against overflow in the addition of the
    register and the offset

V1 to V2:
  - fix max_off calculation for access size = 0
====================

Link: https://lore.kernel.org/r/20231207041150.229139-1-andreimatei1@gmail.com
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
",,The commit fixes the verification of indirect variable offset stack access in the eBPF verifier.,"verification, indirect, stack",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1d38a9ee81570c4bd61f557832dead4d6f816760,1d38a9ee81570c4bd61f557832dead4d6f816760,Andrei Matei,andreimatei1@gmail.com,1701922310,Andrii Nakryiko,andrii@kernel.org,1701986290,ceead968fb8ab47e59d6c55e3bc087a68736c8a8,e28bd359bcc8eb849aaa475f3c3f9705fba26d6e,"bpf: Guard stack limits against 32bit overflow

This patch promotes the arithmetic around checking stack bounds to be
done in the 64-bit domain"," instead of the current 32bit. The arithmetic
implies adding together a 64-bit register with a int offset. The
register was checked to be below 1<<29 when it was variable","[' but not\nwhen it was fixed. The offset either comes from an instruction (in which\ncase it is 16 bit)', ' from another register (in which case the caller\nchecked it to be below 1<<29 [1])', ' or from the size of an argument to a\nkfunc (in which case it can be a u32 [2]). Between the register being\ninconsistently checked to be below 1<<29', ' and the offset being up to an\nu32', ' it appears that we were open to overflowing the `int`s which were\ncurrently used for arithmetic.\n\n[1] https://github.com/torvalds/linux/blob/815fb87b753055df2d9e50f6cd80eb10235fe3e9/kernel/bpf/verifier.c#L7494-L7498\n[2] https://github.com/torvalds/linux/blob/815fb87b753055df2d9e50f6cd80eb10235fe3e9/kernel/bpf/verifier.c#L11904\n\nReported-by: Andrii Nakryiko <andrii.nakryiko@gmail.com>\nSigned-off-by: Andrei Matei <andreimatei1@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20231207041150.229139-4-andreimatei1@gmail.com\n', '']",The commit updates stack checks to use 64-bit arithmetic to prevent potential overflow issues.,"stack,overflow,arithmetic",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e28bd359bcc8eb849aaa475f3c3f9705fba26d6e,e28bd359bcc8eb849aaa475f3c3f9705fba26d6e,Andrei Matei,andreimatei1@gmail.com,1701922309,Andrii Nakryiko,andrii@kernel.org,1701986282,593ce4a11490e2ee7e459dd6f639af64da28ad85,a833a17aeac73b33f79433d7cee68d5cafd71e4f,"bpf: Add verifier regression test for previous patch

Add a regression test for var-off zero-sized reads.

Signed-off-by: Andrei Matei <andreimatei1@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/bpf/20231207041150.229139-3-andreimatei1@gmail.com
",,Added a regression test for zero-sized reads in the BPF verifier.,"verifier,regression,test",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a833a17aeac73b33f79433d7cee68d5cafd71e4f,a833a17aeac73b33f79433d7cee68d5cafd71e4f,Andrei Matei,andreimatei1@gmail.com,1701922308,Andrii Nakryiko,andrii@kernel.org,1701986273,9d0560315fa76d7656e4b951f989c1a699ded1ed,2146f7fe6e028a3905f0658a1a0d8ef7c115d6c1,"bpf: Fix verification of indirect var-off stack access

This patch fixes a bug around the verification of possibly-zero-sized
stack accesses. When the access was done through a var-offset stack
pointer"," check_stack_access_within_bounds was incorrectly computing the
maximum-offset of a zero-sized read to be the same as the register's min
offset. Instead","["" we have to take in account the register's maximum\npossible value. The patch also simplifies how the max offset is checked;\nthe check is now simpler than for min offset.\n\nThe bug was allowing accesses to erroneously pass the\ncheck_stack_access_within_bounds() checks"", ' only to later crash in\ncheck_stack_range_initialized() when all the possibly-affected stack\nslots are iterated (this time with a correct max offset).\ncheck_stack_range_initialized() is relying on\ncheck_stack_access_within_bounds() for its accesses to the\nstack-tracking vector to be within bounds; in the case of zero-sized\naccesses', "" we were essentially only verifying that the lowest possible\nslot was within bounds. We would crash when the max-offset of the stack\npointer was >= 0 (which shouldn't pass verification"", ' and hopefully is\nnot something anyone\'s code attempts to do in practice).\n\nThanks Hao for reporting!\n\nFixes: 01f810ace9ed3 (""bpf: Allow variable-offset stack access"")\nReported-by: Hao Sun <sunhao.th@gmail.com>\nSigned-off-by: Andrei Matei <andreimatei1@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20231207041150.229139-2-andreimatei1@gmail.com\n\nCloses: https://lore.kernel.org/bpf/CACkBjsZGEUaRCHsmaX=h-efVogsRfK1FPxmkgb0Os_frnHiNdw@mail.gmail.com/\n', '']",Fixes a bug in eBPF verifier for incorrect computation of max offset in indirect variable-offset stack access.,"bug fix,verification,stack access",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
bb9aefde5bbaf6c168c77ba635c155b4980c2287,bb9aefde5bbaf6c168c77ba635c155b4980c2287,John Fastabend,john.fastabend@gmail.com,1701905226,Jakub Kicinski,kuba@kernel.org,1701971549,590a28c3a75f9f88fee7c1077f38b5f6996b5958,c5a595000e2677e865a39f249c056bc05d6e55fd,bpf: sockmap," updating the sg structure should also update curr

Curr pointer should be updated when the sg structure is shifted.

Fixes: 7246d8ed4dcce (""bpf: helper to pop data from messages"")
Signed-off-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/r/20231206232706.374377-3-john.fastabend@gmail.com
Signed-off-by: Jakub Kicinski <kuba@kernel.org>
",[''],This commit fixes a curr pointer update issue in the sockmap when the sg structure is shifted.,"sockmap,curr pointer,fix",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,['socket like programs']
4de75d3e6b0ece518a2e6e48c2716f1b223716d3,4de75d3e6b0ece518a2e6e48c2716f1b223716d3,Jakub Kicinski,kuba@kernel.org,1701971009,Jakub Kicinski,kuba@kernel.org,1701971010,ed1191903a9064f5363d278e824dfa0329ba0b18,c85e5594b7456d55103fa1f1bde47cd4e002e7fb 7ae836a3d630e146b732fe8ef7d86b243748751f,"Merge tag 'nf-23-12-06' of git://git.kernel.org/pub/scm/linux/kernel/git/netfilter/nf

Pablo Neira Ayuso says:

====================
Netfilter fixes for net

The following patchset contains Netfilter fixes for net:

1) Incorrect nf_defrag registration for bpf link infra"," from D. Wythe.

2) Skip inactive elements in pipapo set backend walk to avoid double
   deactivation","[' from Florian Westphal.\n\n3) Fix NFT_*_F_PRESENT check with big endian arch', ' also from Florian.\n\n4) Bail out if number of expressions in NFTA_DYNSET_EXPRESSIONS mismatch\n   stateful expressions in set declaration.\n\n5) Honor family in table lookup by handle. Broken since 4.16.\n\n6) Use sk_callback_lock to protect access to sk->sk_socket in xt_owner.\n   sock_orphan() might zap this pointer', "" from Phil Sutter.\n\nAll of these fixes address broken stuff for several releases.\n\n* tag 'nf-23-12-06' of git://git.kernel.org/pub/scm/linux/kernel/git/netfilter/nf:\n  netfilter: xt_owner: Fix for unsafe access of sk->sk_socket\n  netfilter: nf_tables: validate family when identifying table via handle\n  netfilter: nf_tables: bail out on mismatching dynset and set expressions\n  netfilter: nf_tables: fix 'exist' matching on bigendian arches\n  netfilter: nft_set_pipapo: skip inactive elements during set walk\n  netfilter: bpf: fix bad registration on nf_defrag\n====================\n\nLink: https://lore.kernel.org/r/20231206180357.959930-1-pablo@netfilter.org\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n"", '']",Merge Netfilter fixes for net including nf_defrag registration update for BPF link infra.,"Netfilter,BPF link,fixes",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['tc/netfilter like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c85e5594b7456d55103fa1f1bde47cd4e002e7fb,c85e5594b7456d55103fa1f1bde47cd4e002e7fb,Jakub Kicinski,kuba@kernel.org,1701970343,Jakub Kicinski,kuba@kernel.org,1701970344,1c0a09fc3833761d00c051008ebd92eedddab4b1,0ad722bd9ee3a9bdfca9613148645e4c9b7f26cf ffed24eff9e0e52d8e74df1c18db8ed43b4666e6,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Daniel Borkmann says:

====================
pull-request: bpf 2023-12-06

We've added 4 non-merge commits during the last 6 day(s) which contain
a total of 7 files changed", 185 insertions(+),"["" 55 deletions(-).\n\nThe main changes are:\n\n1) Fix race found by syzkaller on prog_array_map_poke_run when\n   a BPF program's kallsym symbols were still missing"", "" from Jiri Olsa.\n\n2) Fix BPF verifier's branch offset comparison for BPF_JMP32 | BPF_JA"", ""\n   from Yonghong Song.\n\n3) Fix xsk's poll handling to only set mask on bound xsk sockets"", ""\n   from Yewon Choi.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  selftests/bpf: Add test for early update in prog_array_map_poke_run\n  bpf: Fix prog_array_map_poke_run map poke update\n  xsk: Skip polling event check for unbound socket\n  bpf: Fix a verifier bug due to incorrect branch offset comparison with cpu=v4\n====================\n\nLink: https://lore.kernel.org/r/20231206220528.12093-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n"", '']",Merge commit for updates in bpf subsystem containing changes to 7 files with 185 insertions.,"merge, bpf, updates",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2146f7fe6e028a3905f0658a1a0d8ef7c115d6c1,2146f7fe6e028a3905f0658a1a0d8ef7c115d6c1,Alexei Starovoitov,ast@kernel.org,1701911841,Alexei Starovoitov,ast@kernel.org,1701911841,9ed227cd85ea4549462a4fecca5b1bada101d3c1,7065eefb38f16c91e9ace36fb7c873e4c9857c27 3ba026fca8786161b0c4d75be396e61d6816e0a1,"Merge branch 'allocate-bpf-trampoline-on-bpf_prog_pack'

Song Liu says:

====================
Allocate bpf trampoline on bpf_prog_pack

This set enables allocating bpf trampoline from bpf_prog_pack on x86. The
majority of this work", however,"[' is the refactoring of trampoline code.\nThis is needed because we need to handle 4 archs and 2 users (trampoline\nand struct_ops).\n\n1/7 through 6/7 refactors trampoline code. A few helpers are added.\n7/7 finally let bpf trampoline on x86 use bpf_prog_pack.\n\nChanges in v7:\n1. Use kvmalloc for rw_image in x86/arch_prepare_bpf_trampoline. (Alexei)\n2. Add comment to explain why we cannot use kvmalloc in\n   x86/arch_bpf_trampoline_size. (Alexei)\n\nChanges in v6:\n1. Rebase.\n2. Add Acked-by and Tested-by from Jiri Olsa and Björn Töpel.\n\nChanges in v5:\n1. Adjust size of trampoline ksym. (Jiri)\n2. Use ""unsigned int size"" arg in image management helpers.(Daniel)\n\nChanges in v4:\n1. Dropped 1/8 in v3', ' which is already merged in bpf-next.\n2. Add Reviewed-by from Björn Töpel.\n\nChanges in v3:\n1. Fix bug in s390. (Thanks to Ilya Leoshkevich).\n2. Fix build error in riscv. (kernel test robot).\n\nChanges in v2:\n1. Add missing changes in net/bpf/bpf_dummy_struct_ops.c.\n2. Reduce one dry run in arch_prepare_bpf_trampoline. (Xu Kuohai)\n3. Other small fixes.\n====================\n\nLink: https://lore.kernel.org/r/20231206224054.492250-1-song@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit enables allocating BPF trampolines from bpf_prog_pack on x86.,"BPF trampolines, bpf_prog_pack, x86",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3ba026fca8786161b0c4d75be396e61d6816e0a1,3ba026fca8786161b0c4d75be396e61d6816e0a1,Song Liu,song@kernel.org,1701902454,Alexei Starovoitov,ast@kernel.org,1701911841,9ed227cd85ea4549462a4fecca5b1bada101d3c1,26ef208c209a0e6eed8942a5d191b39dccfa6e38,x86," bpf: Use bpf_prog_pack for bpf trampoline

There are three major changes here:

1. Add arch_[alloc|free]_bpf_trampoline based on bpf_prog_pack;
2. Let arch_prepare_bpf_trampoline handle ROX input image","[' this requires\n   arch_prepare_bpf_trampoline allocating a temporary RW buffer;\n3. Update __arch_prepare_bpf_trampoline() to handle a RW buffer (rw_image)\n   and a ROX buffer (image). This part is similar to the image/rw_image\n   logic in bpf_int_jit_compile().\n\nSigned-off-by: Song Liu <song@kernel.org>\nAcked-by: Ilya Leoshkevich <iii@linux.ibm.com>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/r/20231206224054.492250-8-song@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit adds arch_alloc and free_bpf_trampoline based on bpf_prog_pack and modifies arch_prepare_bpf_trampoline for ROX input image.,"bpf_prog_pack, bpf_trampoline, ROX",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['tracepoints like programs', 'kprobe/uprobe/ftrace like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
26ef208c209a0e6eed8942a5d191b39dccfa6e38,26ef208c209a0e6eed8942a5d191b39dccfa6e38,Song Liu,song@kernel.org,1701902453,Alexei Starovoitov,ast@kernel.org,1701911840,8db20d8a07885449ac7805d3c8829d1d4697773f,96d1b7c081c0c96cbe8901045f4ff15a2e9974a2,"bpf: Use arch_bpf_trampoline_size

Instead of blindly allocating PAGE_SIZE for each trampoline"," check the size
of the trampoline with arch_bpf_trampoline_size(). This size is saved in
bpf_tramp_image->size","[' and used for modmem charge/uncharge. The fallback\narch_alloc_bpf_trampoline() still allocates a whole page because we need to\nuse set_memory_* to protect the memory.\n\nstruct_ops trampoline still uses a whole page for multiple trampolines.\n\nWith this size check at caller (regular trampoline and struct_ops\ntrampoline)', ' remove arch_bpf_trampoline_size() from\narch_prepare_bpf_trampoline() in archs.\n\nAlso', ' update bpf_image_ksym_add() to handle symbol of different sizes.\n\nSigned-off-by: Song Liu <song@kernel.org>\nAcked-by: Ilya Leoshkevich <iii@linux.ibm.com>\nTested-by: Ilya Leoshkevich <iii@linux.ibm.com>  # on s390x\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nAcked-by: Björn Töpel <bjorn@rivosinc.com>\nTested-by: Björn Töpel <bjorn@rivosinc.com> # on riscv\nLink: https://lore.kernel.org/r/20231206224054.492250-7-song@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Optimize trampoline allocation in BPF by using arch_bpf_trampoline_size instead of default PAGE_SIZE.,"trampoline, allocation, BPF",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
96d1b7c081c0c96cbe8901045f4ff15a2e9974a2,96d1b7c081c0c96cbe8901045f4ff15a2e9974a2,Song Liu,song@kernel.org,1701902452,Alexei Starovoitov,ast@kernel.org,1701911840,1c42f14146f5308976355f4d3d84b4cb4e91a420,38b8b58ae776bf748bd1bd7a24c3fd1d10f76f45,"bpf: Add arch_bpf_trampoline_size()

This helper will be used to calculate the size of the trampoline before
allocating the memory.

arch_prepare_bpf_trampoline() for arm64 and riscv64 can use
arch_bpf_trampoline_size() to check the trampoline fits in the image.

OTOH"," arch_prepare_bpf_trampoline() for s390 has to call the JIT process
twice","[' so it cannot use arch_bpf_trampoline_size().\n\nSigned-off-by: Song Liu <song@kernel.org>\nAcked-by: Ilya Leoshkevich <iii@linux.ibm.com>\nTested-by: Ilya Leoshkevich <iii@linux.ibm.com>  # on s390x\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nAcked-by: Björn Töpel <bjorn@rivosinc.com>\nTested-by: Björn Töpel <bjorn@rivosinc.com> # on riscv\nLink: https://lore.kernel.org/r/20231206224054.492250-6-song@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit adds a helper to calculate trampoline size before memory allocation for arm64 and riscv64 architectures.,"trampoline, arm64, riscv64",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
38b8b58ae776bf748bd1bd7a24c3fd1d10f76f45,38b8b58ae776bf748bd1bd7a24c3fd1d10f76f45,Song Liu,song@kernel.org,1701902451,Alexei Starovoitov,ast@kernel.org,1701911840,af31897df3062fe16cfd7962d0e5dab0a3767be6,82583daa2efc2e336962b231a46bad03a280b3e0,bpf," x86: Adjust arch_prepare_bpf_trampoline return value

x86's implementation of arch_prepare_bpf_trampoline() requires
BPF_INSN_SAFETY buffer space between end of program and image_end. OTOH","[""\nthe return value does not include BPF_INSN_SAFETY. This doesn't cause any\nreal issue at the moment. However"", ' ""image"" of size retval is not enough for\narch_prepare_bpf_trampoline(). This will cause confusion when we introduce\na new helper arch_bpf_trampoline_size(). To avoid future confusion', ' adjust\nthe return value to include BPF_INSN_SAFETY.\n\nSigned-off-by: Song Liu <song@kernel.org>\nAcked-by: Ilya Leoshkevich <iii@linux.ibm.com>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/r/20231206224054.492250-5-song@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Adjust return value of arch_prepare_bpf_trampoline on x86 to ensure buffer space for BPF_INSN_SAFETY.,"x86, bpf trampoline, buffer space",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
82583daa2efc2e336962b231a46bad03a280b3e0,82583daa2efc2e336962b231a46bad03a280b3e0,Song Liu,song@kernel.org,1701902450,Alexei Starovoitov,ast@kernel.org,1701911840,2d4dbd41a6b3f940756a29355ecda952753beff1,7a3d9a159b178e87306a6e989071ed9a114a1a31,"bpf: Add helpers for trampoline image management

As BPF trampoline of different archs moves from bpf_jit_[alloc|free]_exec()
to bpf_prog_pack_[alloc|free]()", we need to use different _alloc,"[' _free for\ndifferent archs during the transition. Add the following helpers for this\ntransition:\n\nvoid *arch_alloc_bpf_trampoline(unsigned int size);\nvoid arch_free_bpf_trampoline(void *image', ' unsigned int size);\nvoid arch_protect_bpf_trampoline(void *image', ' unsigned int size);\nvoid arch_unprotect_bpf_trampoline(void *image', ' unsigned int size);\n\nThe fallback version of these helpers require size <= PAGE_SIZE', ' but they\nare only called with size == PAGE_SIZE. They will be called with size <\nPAGE_SIZE when arch_bpf_trampoline_size() helper is introduced later.\n\nSigned-off-by: Song Liu <song@kernel.org>\nAcked-by: Ilya Leoshkevich <iii@linux.ibm.com>\nTested-by: Ilya Leoshkevich <iii@linux.ibm.com>  # on s390x\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/r/20231206224054.492250-4-song@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add helpers for managing trampoline images in BPF by transitioning from bpf_jit to bpf_prog_pack.,"trampoline, helpers, management",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7a3d9a159b178e87306a6e989071ed9a114a1a31,7a3d9a159b178e87306a6e989071ed9a114a1a31,Song Liu,song@kernel.org,1701902449,Alexei Starovoitov,ast@kernel.org,1701911840,1b447beb17e72ffcf7eef17b14131ef786f7d181,f08a1c658257c73697a819c4ded3a84b6f0ead74,"bpf: Adjust argument names of arch_prepare_bpf_trampoline()

We are using ""im"" for ""struct bpf_tramp_image"" and ""tr"" for ""struct
bpf_trampoline"" in most of the code base. The only exception is the
prototype and fallback version of arch_prepare_bpf_trampoline(). Update
them to match the rest of the code base.

We mix ""orig_call"" and ""func_addr"" for the argument in different versions
of arch_prepare_bpf_trampoline(). s/orig_call/func_addr/g so they match.

Signed-off-by: Song Liu <song@kernel.org>
Acked-by: Ilya Leoshkevich <iii@linux.ibm.com>
Tested-by: Ilya Leoshkevich <iii@linux.ibm.com>  # on s390x
Acked-by: Jiri Olsa <jolsa@kernel.org>
Link: https://lore.kernel.org/r/20231206224054.492250-3-song@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Update argument names in arch_prepare_bpf_trampoline() for consistency across code base.,"argument, names, consistency",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f08a1c658257c73697a819c4ded3a84b6f0ead74,f08a1c658257c73697a819c4ded3a84b6f0ead74,Song Liu,song@kernel.org,1701902448,Alexei Starovoitov,ast@kernel.org,1701911840,447d1a173b1f692cb45d232801e1d855adf315fc,7065eefb38f16c91e9ace36fb7c873e4c9857c27,"bpf: Let bpf_prog_pack_free handle any pointer

Currently"," bpf_prog_pack_free only can only free pointer to struct
bpf_binary_header","[' which is not flexible. Add a size argument to\nbpf_prog_pack_free so that it can handle any pointer.\n\nSigned-off-by: Song Liu <song@kernel.org>\nAcked-by: Ilya Leoshkevich <iii@linux.ibm.com>\nTested-by: Ilya Leoshkevich <iii@linux.ibm.com>  # on s390x\nReviewed-by: Björn Töpel <bjorn@rivosinc.com>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/r/20231206224054.492250-2-song@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Enhanced bpf_prog_pack_free to handle any pointer instead of just bpf_binary_header.,"bpf_prog_pack_free,pointer,enhancement",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7065eefb38f16c91e9ace36fb7c873e4c9857c27,7065eefb38f16c91e9ace36fb7c873e4c9857c27,Andrii Nakryiko,andrii@kernel.org,1701889760,Alexei Starovoitov,ast@kernel.org,1701902476,1b866cccb8f0b22271b857ef62062a03d4c5b12b,c35919dcce2855d68cf45ffa427b8ea78e4f7c68,"bpf: rename MAX_BPF_LINK_TYPE into __MAX_BPF_LINK_TYPE for consistency

To stay consistent with the naming pattern used for similar cases in BPF
UAPI (__MAX_BPF_ATTACH_TYPE", etc),"[' rename MAX_BPF_LINK_TYPE into\n__MAX_BPF_LINK_TYPE.\n\nAlso similar to MAX_BPF_ATTACH_TYPE and MAX_BPF_REG', ' add:\n\n  #define MAX_BPF_LINK_TYPE __MAX_BPF_LINK_TYPE\n\nNot all __MAX_xxx enums have such #define', "" so I'm not sure if we should\nadd it or not"", "" but I figured I'll start with a completely backwards\ncompatible way"", ' and we can drop that', ' if necessary.\n\nAlso adjust a selftest that used MAX_BPF_LINK_TYPE enum.\n\nSuggested-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20231206190920.1651226-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Renamed MAX_BPF_LINK_TYPE to __MAX_BPF_LINK_TYPE for naming consistency.,"rename, consistency, UAPI",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ffed24eff9e0e52d8e74df1c18db8ed43b4666e6,ffed24eff9e0e52d8e74df1c18db8ed43b4666e6,Jiri Olsa,jolsa@kernel.org,1701851441,Daniel Borkmann,daniel@iogearbox.net,1701898843,7c0495e6f3bd9983db78a626ca27cb07f3b4cf25,4b7de801606e504e69689df71475d27e35336fb3,"selftests/bpf: Add test for early update in prog_array_map_poke_run

Adding test that tries to trigger the BUG_IN during early map update
in prog_array_map_poke_run function.

The idea is to share prog array map between thread that constantly
updates it and another one loading a program that uses that prog
array.

Eventually we will hit a place where the program is ok to be updated
(poke->tailcall_target_stable check) but the address is still not
registered in kallsyms"," so the bpf_arch_text_poke returns -EINVAL
and cause imbalance for the next tail call update check","[' which will\nfail with -EBUSY in bpf_arch_text_poke as described in previous fix.\n\nSigned-off-by: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Ilya Leoshkevich <iii@linux.ibm.com>\nLink: https://lore.kernel.org/bpf/20231206083041.1306660-3-jolsa@kernel.org\n', '']",Add test to selftests/bpf for early map update in prog_array_map_poke_run function.,"test, early update, prog_array_map_poke_run",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4b7de801606e504e69689df71475d27e35336fb3,4b7de801606e504e69689df71475d27e35336fb3,Jiri Olsa,jolsa@kernel.org,1701851440,Daniel Borkmann,daniel@iogearbox.net,1701898816,1ab3b1d4f0d0bad6e845121d2cee745cb32d064e,e4d008d49a7135214e0ee70537405b6a069e3a3f,"bpf: Fix prog_array_map_poke_run map poke update

Lee pointed out issue found by syscaller [0] hitting BUG in prog array
map poke update in prog_array_map_poke_run function due to error value
returned from bpf_arch_text_poke function.

There's race window where bpf_arch_text_poke can fail due to missing
bpf program kallsym symbols"," which is accounted for with check for
-EINVAL in that BUG_ON call.

The problem is that in such case we won't update the tail call jump
and cause imbalance for the next tail call update check which will
fail with -EBUSY in bpf_arch_text_poke.

I'm hitting following race during the program load:

  CPU 0                             CPU 1

  bpf_prog_load
    bpf_check
      do_misc_fixups
        prog_array_map_poke_track

                                    map_update_elem
                                      bpf_fd_array_map_update_elem
                                        prog_array_map_poke_run

                                          bpf_arch_text_poke returns -EINVAL

    bpf_prog_kallsyms_add

After bpf_arch_text_poke (CPU 1) fails to update the tail call jump","[' the next\npoke update fails on expected jump instruction check in bpf_arch_text_poke\nwith -EBUSY and triggers the BUG_ON in prog_array_map_poke_run.\n\nSimilar race exists on the program unload.\n\nFixing this by moving the update to bpf_arch_poke_desc_update function which\nmakes sure we call __bpf_arch_text_poke that skips the bpf address check.\n\nEach architecture has slightly different approach wrt looking up bpf address\nin bpf_arch_text_poke', "" so instead of splitting the function or adding new\n'checkip' argument in previous version"", ' it seems best to move the whole\nmap_poke_run update as arch specific code.\n\n  [0] https://syzkaller.appspot.com/bug?extid=97a4fe20470e9bc30810\n\nFixes: ebf7d1f508a7 (""bpf', ' x64: rework pro/epilogue and tailcall handling in JIT"")\nReported-by: syzbot+97a4fe20470e9bc30810@syzkaller.appspotmail.com\nSigned-off-by: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nCc: Lee Jones <lee@kernel.org>\nCc: Maciej Fijalkowski <maciej.fijalkowski@intel.com>\nLink: https://lore.kernel.org/bpf/20231206083041.1306660-2-jolsa@kernel.org\n', '']",Fixes a bug in prog_array_map_poke_run to handle race conditions during bpf_arch_text_poke failures.,"bug,race condition,update",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c35919dcce2855d68cf45ffa427b8ea78e4f7c68,c35919dcce2855d68cf45ffa427b8ea78e4f7c68,Alexei Starovoitov,ast@kernel.org,1701885780,Alexei Starovoitov,ast@kernel.org,1701885781,b25a269f54206b8652cf64b002d7d589d505a8c1,3aee2bf9c49be2144460d7267560232e3d45d367 36fb94944b35062db15ab3059f4123048cac658c,"Merge branch 'bpf-token-and-bpf-fs-based-delegation'

Andrii Nakryiko says:

====================
BPF token and BPF FS-based delegation

This patch set introduces an ability to delegate a subset of BPF subsystem
functionality from privileged system-wide daemon (e.g."," systemd or any other
container manager) through special mount options for userns-bound BPF FS to
a *trusted* unprivileged application. Trust is the key here. This
functionality is not about allowing unconditional unprivileged BPF usage.
Establishing trust","[' though', ' is completely up to the discretion of respective\nprivileged application that would create and mount a BPF FS instance with\ndelegation enabled', ' as different production setups can and do achieve it\nthrough a combination of different means (signing', ' LSM', ' code reviews', ' etc)', ""\nand it's undesirable and infeasible for kernel to enforce any particular way\nof validating trustworthiness of particular process.\n\nThe main motivation for this work is a desire to enable containerized BPF\napplications to be used together with user namespaces. This is currently\nimpossible"", ' as CAP_BPF', ' required for BPF subsystem usage', ' cannot be namespaced\nor sandboxed', ' as a general rule. E.g.', ' tracing BPF programs', ' thanks to BPF\nhelpers like bpf_probe_read_kernel() and bpf_probe_read_user() can safely read\narbitrary memory', "" and it's impossible to ensure that they only read memory of\nprocesses belonging to any given namespace. This means that it's impossible to\nhave a mechanically verifiable namespace-aware CAP_BPF capability"", ' and as such\nanother mechanism to allow safe usage of BPF functionality is necessary.BPF FS\ndelegation mount options and BPF token derived from such BPF FS instance is\nsuch a mechanism. Kernel makes no assumption about what ""trusted"" constitutes\nin any particular case', "" and it's up to specific privileged applications and\ntheir surrounding infrastructure to decide that. What kernel provides is a set\nof APIs to setup and mount special BPF FS instanecs and derive BPF tokens from\nit. BPF FS and BPF token are both bound to its owning userns and in such a way\nare constrained inside intended container. Users can then pass BPF token FD to\nprivileged bpf() syscall commands"", ' like BPF map creation and BPF program\nloading', ' to perform such operations without having init userns privileged.\n\nThis version incorporates feedback and suggestions ([3]) received on v3 of\nthis patch set', ' and instead of allowing to create BPF tokens directly assuming\ncapable(CAP_SYS_ADMIN)', ' we instead enhance BPF FS to accept a few new\ndelegation mount options. If these options are used and BPF FS itself is\nproperly created', ' set up', ' and mounted inside the user namespaced container', '\nuser application is able to derive a BPF token object from BPF FS instance', '\nand pass that token to bpf() syscall. As explained in patch #3', "" BPF token\nitself doesn't grant access to BPF functionality"", ' but instead allows kernel to\ndo namespaced capabilities checks (ns_capable() vs capable()) for CAP_BPF', '\nCAP_PERFMON', ' CAP_NET_ADMIN', ' and CAP_SYS_ADMIN', ' as applicable. So it forms one\nhalf of a puzzle and allows container managers and sys admins to have safe and\nflexible configuration options: determining which containers get delegation of\nBPF functionality through BPF FS', ' and then which applications within such\ncontainers are allowed to perform bpf() commands', ' based on namespaces\ncapabilities.\n\nPrevious attempt at addressing this very same problem ([0]) attempted to\nutilize authoritative LSM approach', ' but was conclusively rejected by upstream\nLSM maintainers. BPF token concept is not changing anything about LSM\napproach', ' but can be combined with LSM hooks for very fine-grained security\npolicy. Some ideas about making BPF token more convenient to use with LSM (in\nparticular custom BPF LSM programs) was briefly described in recent LSF/MM/BPF\n2023 presentation ([1]). E.g.', ' an ability to specify user-provided data\n(context)', ' which in combination with BPF LSM would allow implementing a very\ndynamic and fine-granular custom security policies on top of BPF token. In the\ninterest of minimizing API surface area and discussions this was relegated to\nfollow up patches', "" as it's not essential to the fundamental concept of\ndelegatable BPF token.\n\nIt should be noted that BPF token is conceptually quite similar to the idea of\n/dev/bpf device file"", ' proposed by Song a while ago ([2]). The biggest\ndifference is the idea of using virtual anon_inode file to hold BPF token and\nallowing multiple independent instances of them', ' each (potentially) with its\nown set of restrictions. And also', ' crucially', ' BPF token approach is not using\nany special stateful task-scoped flags. Instead', ' bpf() syscall accepts\ntoken_fd parameters explicitly for each relevant BPF command. This addresses\nmain concerns brought up during the /dev/bpf discussion', ' and fits better with\noverall BPF subsystem design.\n\nThis patch set adds a basic minimum of functionality to make BPF token idea\nuseful and to discuss API and functionality. Currently only low-level libbpf\nAPIs support creating and passing BPF token around', ' allowing to test kernel\nfunctionality', ' but for the most part is not sufficient for real-world\napplications', ' which typically use high-level libbpf APIs based on `struct\nbpf_object` type. This was done with the intent to limit the size of patch set\nand concentrate on mostly kernel-side changes. All the necessary plumbing for\nlibbpf will be sent as a separate follow up patch set kernel support makes it\nupstream.\n\nAnother part that should happen once kernel-side BPF token is established', ' is\na set of conventions between applications (e.g.', ' systemd)', ' tools (e.g.', '\nbpftool)', ' and libraries (e.g.', "" libbpf) on exposing delegatable BPF FS\ninstance(s) at well-defined locations to allow applications take advantage of\nthis in automatic fashion without explicit code changes on BPF application's\nside. But I'd like to postpone this discussion to after BPF token concept\nlands.\n\n  [0] https://lore.kernel.org/bpf/20230412043300.360803-1-andrii@kernel.org/\n  [1] http://vger.kernel.org/bpfconf2023_material/Trusted_unprivileged_BPF_LSFMM2023.pdf\n  [2] https://lore.kernel.org/bpf/20190627201923.2589391-2-songliubraving@fb.com/\n  [3] https://lore.kernel.org/bpf/20230704-hochverdient-lehne-eeb9eeef785e@brauner/\n\nv11->v12:\n  - enforce exact userns match in bpf_token_capable() and\n    bpf_token_allow_cmd() checks"", ' for added strictness (Christian);\nv10->v11:\n  - fix BPF FS root check to disallow using bind-mounted subdirectory of BPF\n    FS instance (Christian);\n  - further restrict BPF_TOKEN_CREATE command to be executed from inside\n    exactly the same user namespace as the one used to create BPF FS instance\n    (Christian);\nv9->v10:\n  - slight adjustments in LSM parts (Paul);\n  - setting delegate_xxx  options require capable(CAP_SYS_ADMIN) (Christian);\n  - simplify BPF_TOKEN_CREATE UAPI by accepting BPF FS FD directly (Christian);\nv8->v9:\n  - fix issue in selftests due to sys/mount.h header (Jiri);\n  - fix warning in doc comments in LSM hooks (kernel test robot);\nv7->v8:\n  - add bpf_token_allow_cmd and bpf_token_capable hooks (Paul);\n  - inline bpf_token_alloc() into bpf_token_create() to prevent accidental\n    divergence with security_bpf_token_create() hook (Paul);\nv6->v7:\n  - separate patches to refactor bpf_prog_alloc/bpf_map_alloc LSM hooks', ' as\n    discussed with Paul', ' and now they also accept struct bpf_token;\n  - added bpf_token_create/bpf_token_free to allow LSMs (SELinux', '\n    specifically) to set up security LSM blob (Paul);\n  - last patch also wires bpf_security_struct setup by SELinux', "" similar to how\n    it's done for BPF map/prog"", "" though I'm not sure if that's enough"", "" so worst\n    case it's easy to drop this patch if more full fledged SELinux\n    implementation will be done separately;\n  - small fixes for issues caught by code reviews (Jiri"", "" Hou);\n  - fix for test_maps test that doesn't use LIBBPF_OPTS() macro (CI);\nv5->v6:\n  - fix possible use of uninitialized variable in selftests (CI);\n  - don't use anon_inode"", "" instead create one from BPF FS instance (Christian);\n  - don't store bpf_token inside struct bpf_map"", ' instead pass it explicitly to\n    map_check_btf(). We do store bpf_token inside prog->aux', "" because it's used\n    during verification and even can be checked during attach time for some\n    program types;\n  - LSM hooks are left intact pending the conclusion of discussion with Paul\n    Moore; I'd prefer to do LSM-related changes as a follow up patch set\n    anyways;\nv4->v5:\n  - add pre-patch unifying CAP_NET_ADMIN handling inside kernel/bpf/syscall.c\n    (Paul Moore);\n  - fix build warnings and errors in selftests and kernel"", "" detected by CI and\n    kernel test robot;\nv3->v4:\n  - add delegation mount options to BPF FS;\n  - BPF token is derived from the instance of BPF FS and associates itself\n    with BPF FS' owning userns;\n  - BPF token doesn't grant BPF functionality directly"", "" it just turns\n    capable() checks into ns_capable() checks within BPF FS' owning user;\n  - BPF token cannot be pinned;\nv2->v3:\n  - make BPF_TOKEN_CREATE pin created BPF token in BPF FS"", ' and disallow\n    BPF_OBJ_PIN for BPF token;\nv1->v2:\n  - fix build failures on Kconfig with CONFIG_BPF_SYSCALL unset;\n  - drop BPF_F_TOKEN_UNKNOWN_* flags and simplify UAPI (Stanislav).\n====================\n\nLink: https://lore.kernel.org/r/20231130185229.2688956-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit introduces BPF token and BPF FS-based delegation to unprivileged applications via trusted system-wide daemons.,"BPF token, delegation, unprivileged",It's a new feature.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",The syscall interface,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
36fb94944b35062db15ab3059f4123048cac658c,36fb94944b35062db15ab3059f4123048cac658c,Andrii Nakryiko,andrii@kernel.org,1701370349,Alexei Starovoitov,ast@kernel.org,1701885780,b25a269f54206b8652cf64b002d7d589d505a8c1,dc5196fac40c2cb96330bcb98eef868a7fd225b3,bpf,"selinux: allocate bpf_security_struct per BPF token

Utilize newly added bpf_token_create/bpf_token_free LSM hooks to
allocate struct bpf_security_struct for each BPF token object in
SELinux. This just follows similar pattern for BPF prog and map.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231130185229.2688956-18-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Allocate bpf_security_struct for each BPF token in SELinux using new LSM hooks.,"LSM hooks, BPF token, SELinux",It's a security fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['cgroup like programs', 'LSM like programs']"
dc5196fac40c2cb96330bcb98eef868a7fd225b3,dc5196fac40c2cb96330bcb98eef868a7fd225b3,Andrii Nakryiko,andrii@kernel.org,1701370348,Alexei Starovoitov,ast@kernel.org,1701885780,adfd0beabe2cf3afa09142802dab5eea60323f27,1571740a9ba036f26cc5211a86021199987219e8,"selftests/bpf: add BPF token-enabled tests

Add a selftest that attempts to conceptually replicate intended BPF
token use cases inside user namespaced container.

Child process is forked. It is then put into its own userns and mountns.
Child creates BPF FS context object. This ensures child userns is
captured as the owning userns for this instance of BPF FS. Given setting
delegation mount options is privileged operation"," we ensure that child
cannot set them.

This context is passed back to privileged parent process through Unix
socket","[' where parent sets up delegation options', ' creates', ' and mounts it\nas a detached mount. This mount FD is passed back to the child to be\nused for BPF token creation', ' which allows otherwise privileged BPF\noperations to succeed inside userns.\n\nWe validate that all of token-enabled privileged commands (BPF_BTF_LOAD', '\nBPF_MAP_CREATE', ' and BPF_PROG_LOAD) work as intended. They should only\nsucceed inside the userns if a) BPF token is provided with proper\nallowed sets of commands and types; and b) namespaces CAP_BPF and other\nprivileges are set. Lacking a) or b) should lead to -EPERM failures.\n\nBased on suggested workflow by Christian Brauner ([0]).\n\n  [0] https://lore.kernel.org/bpf/20230704-hochverdient-lehne-eeb9eeef785e@brauner/\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231130185229.2688956-17-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add selftests for BPF token use cases in user namespaced containers.,BPF token selftests,It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1571740a9ba036f26cc5211a86021199987219e8,1571740a9ba036f26cc5211a86021199987219e8,Andrii Nakryiko,andrii@kernel.org,1701370347,Alexei Starovoitov,ast@kernel.org,1701885780,a1c154e2a1c4845c848d183eddd0055e56cf5fe5,1a8df7fa00aac35aff9ef1941c5334b3a01d09e4,"libbpf: add BPF token support to bpf_prog_load() API

Wire through token_fd into bpf_prog_load().

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231130185229.2688956-16-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add BPF token support to bpf_prog_load API in libbpf.,"BPF, token, libbpf",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1a8df7fa00aac35aff9ef1941c5334b3a01d09e4,1a8df7fa00aac35aff9ef1941c5334b3a01d09e4,Andrii Nakryiko,andrii@kernel.org,1701370346,Alexei Starovoitov,ast@kernel.org,1701885780,59d1151a9cfb1cf98a61ab9ed845ed2873e2128c,37891cea6699200fb83eae464ebe1c0f73040474,"libbpf: add BPF token support to bpf_btf_load() API

Allow user to specify token_fd for bpf_btf_load() API that wraps
kernel's BPF_BTF_LOAD command. This allows loading BTF from unprivileged
process as long as it has BPF token allowing BPF_BTF_LOAD command"," which
can be created and delegated by privileged process.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231130185229.2688956-15-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Added support for BPF token in bpf_btf_load() API to allow BTF loading from unprivileged processes.,"BPF token,BTF loading,unprivileged",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
37891cea6699200fb83eae464ebe1c0f73040474,37891cea6699200fb83eae464ebe1c0f73040474,Andrii Nakryiko,andrii@kernel.org,1701370345,Alexei Starovoitov,ast@kernel.org,1701885780,ce8e64399d02a500998496f74e02231122fe1ce3,ecd435143eb03611e25694141bf59d1c04ad5b9e,"libbpf: add BPF token support to bpf_map_create() API

Add ability to provide token_fd for BPF_MAP_CREATE command through
bpf_map_create() API.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231130185229.2688956-14-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add BPF token support to the bpf_map_create() API in libbpf.,"BPF, token, libbpf",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ecd435143eb03611e25694141bf59d1c04ad5b9e,ecd435143eb03611e25694141bf59d1c04ad5b9e,Andrii Nakryiko,andrii@kernel.org,1701370344,Alexei Starovoitov,ast@kernel.org,1701885780,bdf126a236403522427e17dfb69c834f9248d76a,d734ca7b33dbf60eb15dcf7c44f3da7073356777,"libbpf: add bpf_token_create() API

Add low-level wrapper API for BPF_TOKEN_CREATE command in bpf() syscall.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231130185229.2688956-13-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Introduces a new API bpf_token_create() for BPF_TOKEN_CREATE command in the bpf() syscall.,"API, bpf_token_create, syscall",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The syscall interface,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d734ca7b33dbf60eb15dcf7c44f3da7073356777,d734ca7b33dbf60eb15dcf7c44f3da7073356777,Andrii Nakryiko,andrii@kernel.org,1701370343,Alexei Starovoitov,ast@kernel.org,1701885780,094194f17a60f5e22567a26ba3ae537556a54456,66d636d70a79c1d37e3eea67ab50969e6aaef983,bpf,"lsm: add BPF token LSM hooks

Wire up bpf_token_create and bpf_token_free LSM hooks","[' which allow to\nallocate LSM security blob (we add `void *security` field to struct\nbpf_token for that)', "" but also control who can instantiate BPF token.\nThis follows existing pattern for BPF map and BPF prog.\n\nAlso add security_bpf_token_allow_cmd() and security_bpf_token_capable()\nLSM hooks that allow LSM implementation to control and negate (if\nnecessary) BPF token's delegation of a specific bpf_cmd and capability"", '\nrespectively.\n\nAcked-by: Paul Moore <paul@paul-moore.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231130185229.2688956-12-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Added LSM hooks for BPF token creation and deletion in the BPF subsystem.,"LSM hooks, BPF token, creation",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['LSM like programs']
66d636d70a79c1d37e3eea67ab50969e6aaef983,66d636d70a79c1d37e3eea67ab50969e6aaef983,Andrii Nakryiko,andrii@kernel.org,1701370342,Alexei Starovoitov,ast@kernel.org,1701885779,eb838d10ef24f65149fd1984d73d6b7a755156b8,c3dd6e94df7193f33f45d33303f5e85afb2a72dc,bpf,"lsm: refactor bpf_map_alloc/bpf_map_free LSM hooks

Similarly to bpf_prog_alloc LSM hook","[' rename and extend bpf_map_alloc\nhook into bpf_map_create', ' taking not just struct bpf_map', ' but also\nbpf_attr and bpf_token', ' to give a fuller context to LSMs.\n\nUnlike bpf_prog_alloc', ' there is no need to move the hook around', ' as it\ncurrently is firing right before allocating BPF map ID and FD', ' which\nseems to be a sweet spot.\n\nBut like bpf_prog_alloc/bpf_prog_free combo', ' make sure that bpf_map_free\nLSM hook is called even if bpf_map_create hook returned error', ' as if few\nLSMs are combined together it could be that one LSM successfully\nallocated security blob for its needs', ' while subsequent LSM rejected BPF\nmap creation. The former LSM would still need to free up LSM blob', ' so we\nneed to ensure security_bpf_map_free() is called regardless of the\noutcome.\n\nAcked-by: Paul Moore <paul@paul-moore.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231130185229.2688956-11-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Refactor the bpf_map_alloc and bpf_map_free LSM hooks.,"refactor, LSM hooks, bpf_map",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,['LSM like programs']
c3dd6e94df7193f33f45d33303f5e85afb2a72dc,c3dd6e94df7193f33f45d33303f5e85afb2a72dc,Andrii Nakryiko,andrii@kernel.org,1701370341,Alexei Starovoitov,ast@kernel.org,1701885779,59dbdb263ff295fd81294b57ef45d72d11ada98e,8062fb12de99b2da33754c6a3be1bfc30d9a35f4,bpf,"lsm: refactor bpf_prog_alloc/bpf_prog_free LSM hooks

Based on upstream discussion ([0])","[' rework existing\nbpf_prog_alloc_security LSM hook. Rename it to bpf_prog_load and instead\nof passing bpf_prog_aux', ' pass proper bpf_prog pointer for a full BPF\nprogram struct. Also', ' we pass bpf_attr union with all the user-provided\narguments for BPF_PROG_LOAD command.  This will give LSMs as much\ninformation as we can basically provide.\n\nThe hook is also BPF token-aware now', ' and optional bpf_token struct is\npassed as a third argument. bpf_prog_load LSM hook is called after\na bunch of sanity checks were performed', ' bpf_prog and bpf_prog_aux were\nallocated and filled out', ' but right before performing full-fledged BPF\nverification step.\n\nbpf_prog_free LSM hook is now accepting struct bpf_prog argument', ' for\nconsistency. SELinux code is adjusted to all new names', ' types', ' and\nsignatures.\n\nNote', ' given that bpf_prog_load (previously bpf_prog_alloc) hook can be\nused by some LSMs to allocate extra security blob', ' but also by other\nLSMs to reject BPF program loading', "" we need to make sure that\nbpf_prog_free LSM hook is called after bpf_prog_load/bpf_prog_alloc one\n*even* if the hook itself returned error. If we don't do that"", ' we run\nthe risk of leaking memory. This seems to be possible today when\ncombining SELinux and BPF LSM', ' as one example', ' depending on their\nrelative ordering.\n\nAlso', ' for BPF LSM setup', ' add bpf_prog_load and bpf_prog_free to\nsleepable LSM hooks list', ' as they are both executed in sleepable\ncontext. Also drop bpf_prog_load hook from untrusted', ' as there is no\nissue with refcount or anything else anymore', ' that originally forced us\nto add it to untrusted list in c0c852dd1876 (""bpf: Do not mark certain LSM\nhook arguments as trusted""). We now trigger this hook much later and it\nshould not be an issue anymore.\n\n  [0] https://lore.kernel.org/bpf/9fe88aef7deabbe87d3fc38c4aea3c69.paul@paul-moore.com/\n\nAcked-by: Paul Moore <paul@paul-moore.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231130185229.2688956-10-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Refactor Linux Security Module (LSM) hooks for bpf_prog_alloc and bpf_prog_free functions.,"refactor,LSM hooks,bpf_prog_alloc",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['LSM like programs']
8062fb12de99b2da33754c6a3be1bfc30d9a35f4,8062fb12de99b2da33754c6a3be1bfc30d9a35f4,Andrii Nakryiko,andrii@kernel.org,1701370340,Alexei Starovoitov,ast@kernel.org,1701885779,5c70426f65a08c9b76c69c95fe98f1e44ef05b5e,4cbb270e115bc197ff2046aeb54cc951666b16ec,"bpf: consistently use BPF token throughout BPF verifier logic

Remove remaining direct queries to perfmon_capable() and bpf_capable()
in BPF verifier logic and instead use BPF token (if available) to make
decisions about privileges.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231130185229.2688956-9-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit updates the BPF verifier logic to consistently use BPF token instead of direct capability checks.,"BPF verifier,BPF token,privileges",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4cbb270e115bc197ff2046aeb54cc951666b16ec,4cbb270e115bc197ff2046aeb54cc951666b16ec,Andrii Nakryiko,andrii@kernel.org,1701370339,Alexei Starovoitov,ast@kernel.org,1701885779,649b1a6a47043000dff55125dc5a91ad91fd24b7,e1cef620f598853a90f17701fcb1057a6768f7b8,"bpf: take into account BPF token when fetching helper protos

Instead of performing unconditional system-wide bpf_capable() and
perfmon_capable() calls inside bpf_base_func_proto() function (and other
similar ones) to determine eligibility of a given BPF helper for a given
program"," use previously recorded BPF token during BPF_PROG_LOAD command
handling to inform the decision.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231130185229.2688956-8-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The commit optimizes BPF helper protos fetching by using recorded BPF token rather than system-wide capability checks.,"BPF token, helper protos, bpf_capable",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e1cef620f598853a90f17701fcb1057a6768f7b8,e1cef620f598853a90f17701fcb1057a6768f7b8,Andrii Nakryiko,andrii@kernel.org,1701370338,Alexei Starovoitov,ast@kernel.org,1701885779,95d4f672f64ffeba968c3f8b8174783e52b093cb,ee54b1a910e4d49c9a104f31ae3f5b979131adf8,"bpf: add BPF token support to BPF_PROG_LOAD command

Add basic support of BPF token to BPF_PROG_LOAD. Wire through a set of
allowed BPF program types and attach types"," derived from BPF FS at BPF
token creation time. Then make sure we perform bpf_token_capable()
checks everywhere where it's relevant.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231130185229.2688956-7-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],"Add BPF token support to the BPF_PROG_LOAD command, allowing specific BPF program types and attach types.","BPF token,BPF_PROG_LOAD,support",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ee54b1a910e4d49c9a104f31ae3f5b979131adf8,ee54b1a910e4d49c9a104f31ae3f5b979131adf8,Andrii Nakryiko,andrii@kernel.org,1701370337,Alexei Starovoitov,ast@kernel.org,1701885779,e194d7f010b8356f8530f8c923b899418b6befb7,688b7270b3cb75e8ac78123d719967db40336e5b,"bpf: add BPF token support to BPF_BTF_LOAD command

Accept BPF token FD in BPF_BTF_LOAD command to allow BTF data loading
through delegated BPF token. BTF loading is a pretty straightforward
operation"," so as long as BPF token is created with allow_cmds granting
BPF_BTF_LOAD command","[' kernel proceeds to parsing BTF data and creating\nBTF object.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231130185229.2688956-6-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Added BPF token support to the BPF_BTF_LOAD command for delegated BTF data loading.,"BPF token, BPF_BTF_LOAD, BTF data",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",The syscall interface,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
688b7270b3cb75e8ac78123d719967db40336e5b,688b7270b3cb75e8ac78123d719967db40336e5b,Andrii Nakryiko,andrii@kernel.org,1701370336,Alexei Starovoitov,ast@kernel.org,1701885779,7b15d6aa33bc38a102899cc813bf825cbfe73f6e,4527358b76861dfd64ee34aba45d81648fbc8a61,"bpf: add BPF token support to BPF_MAP_CREATE command

Allow providing token_fd for BPF_MAP_CREATE command to allow controlled
BPF map creation from unprivileged process through delegated BPF token.

Wire through a set of allowed BPF map types to BPF token"," derived from
BPF FS at BPF token creation time. This","[' in combination with allowed_cmds\nallows to create a narrowly-focused BPF token (controlled by privileged\nagent) with a restrictive set of BPF maps that application can attempt\nto create.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231130185229.2688956-5-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Introduce BPF token support for controlled map creation by unprivileged processes using BPF_MAP_CREATE command.,"BPF token support, map creation, unprivileged process",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['cgroup like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4527358b76861dfd64ee34aba45d81648fbc8a61,4527358b76861dfd64ee34aba45d81648fbc8a61,Andrii Nakryiko,andrii@kernel.org,1701370335,Alexei Starovoitov,ast@kernel.org,1701885779,950b40c3026b6596139539d2d33135e742218ff6,40bba140c60fbb3ee8df6203c82fbd3de9f19d95,"bpf: introduce BPF token object

Add new kind of BPF kernel object"," BPF token. BPF token is meant to
allow delegating privileged BPF functionality","[' like loading a BPF\nprogram or creating a BPF map', ' from privileged process to a *trusted*\nunprivileged process', ' all while having a good amount of control over which\nprivileged operations could be performed using provided BPF token.\n\nThis is achieved through mounting BPF FS instance with extra delegation\nmount options', ' which determine what operations are delegatable', ' and also\nconstraining it to the owning user namespace (as mentioned in the\nprevious patch).\n\nBPF token itself is just a derivative from BPF FS and can be created\nthrough a new bpf() syscall command', ' BPF_TOKEN_CREATE', ' which accepts BPF\nFS FD', ' which can be attained through open() API by opening BPF FS mount\npoint. Currently', ' BPF token ""inherits"" delegated command', ' map types', '\nprog type', ' and attach type bit sets from BPF FS as is. In the future', '\nhaving an BPF token as a separate object with its own FD', "" we can allow\nto further restrict BPF token's allowable set of things either at the\ncreation time or after the fact"", ' allowing the process to guard itself\nfurther from unintentionally trying to load undesired kind of BPF\nprograms. But for now we keep things simple and just copy bit sets as is.\n\nWhen BPF token is created from BPF FS mount', "" we take reference to the\nBPF super block's owning user namespace"", ' and then use that namespace for\nchecking all the {CAP_BPF', ' CAP_PERFMON', ' CAP_NET_ADMIN', ' CAP_SYS_ADMIN}\ncapabilities that are normally only checked against init userns (using\ncapable())', ' but now we check them using ns_capable() instead (if BPF\ntoken is provided). See bpf_token_capable() for details.\n\nSuch setup means that BPF token in itself is not sufficient to grant BPF\nfunctionality. User namespaced process has to *also* have necessary\ncombination of capabilities inside that user namespace. So while\npreviously CAP_BPF was useless when granted within user namespace', ' now\nit gains a meaning and allows container managers and sys admins to have\na flexible control over which processes can and need to use BPF\nfunctionality within the user namespace (i.e.', ' container in practice).\nAnd BPF FS delegation mount options and derived BPF tokens serve as\na per-container ""flag"" to grant overall ability to use bpf() (plus further\nrestrict on which parts of bpf() syscalls are treated as namespaced).\n\nNote also', ' BPF_TOKEN_CREATE command itself requires ns_capable(CAP_BPF)\nwithin the BPF FS owning user namespace', ' rounding up the ns_capable()\nstory of BPF token.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231130185229.2688956-4-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Introduce BPF token object for delegating privileged BPF functionality.,"BPF,token,delegating",It's a new feature.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"[""It's an experimental feature that doesn't fit into existing categories.""]"
40bba140c60fbb3ee8df6203c82fbd3de9f19d95,40bba140c60fbb3ee8df6203c82fbd3de9f19d95,Andrii Nakryiko,andrii@kernel.org,1701370334,Alexei Starovoitov,ast@kernel.org,1701885778,de7e3c52bb326cc848119c90a045e016a5874080,909fa05dd3c181e5b403912889057f7cdbf3906c,"bpf: add BPF token delegation mount options to BPF FS

Add few new mount options to BPF FS that allow to specify that a given
BPF FS instance allows creation of BPF token (added in the next patch)","
and what sort of operations are allowed under BPF token. As such","[' we get\n4 new mount options', ' each is a bit mask\n  - `delegate_cmds` allow to specify which bpf() syscall commands are\n    allowed with BPF token derived from this BPF FS instance;\n  - if BPF_MAP_CREATE command is allowed', ' `delegate_maps` specifies\n    a set of allowable BPF map types that could be created with BPF token;\n  - if BPF_PROG_LOAD command is allowed', ' `delegate_progs` specifies\n    a set of allowable BPF program types that could be loaded with BPF token;\n  - if BPF_PROG_LOAD command is allowed', ' `delegate_attachs` specifies\n    a set of allowable BPF program attach types that could be loaded with\n    BPF token; delegate_progs and delegate_attachs are meant to be used\n    together', ' as full BPF program type is', ' in general', ' determined\n    through both program type and program attach type.\n\nCurrently', ' these mount options accept the following forms of values:\n  - a special value ""any""', ' that enables all possible values of a given\n  bit set;\n  - numeric value (decimal or hexadecimal', ' determined by kernel\n  automatically) that specifies a bit mask value directly;\n  - all the values for a given mount option are combined', ' if specified\n  multiple times. E.g.', ' `mount -t bpf nodev /path/to/mount -o\n  delegate_maps=0x1 -o delegate_maps=0x2` will result in a combined 0x3\n  mask.\n\nIdeally', ' more convenient (for humans) symbolic form derived from\ncorresponding UAPI enums would be accepted (e.g.', ' `-o\ndelegate_progs=kprobe|tracepoint`) and I intend to implement this', ' but\nit requires a bunch of UAPI header churn', ' so I postponed it until this\nfeature lands upstream or at least there is a definite consensus that\nthis feature is acceptable and is going to make it', ' just to minimize\namount of wasted effort and not increase amount of non-essential code to\nbe reviewed.\n\nAttentive reader will notice that BPF FS is now marked as\nFS_USERNS_MOUNT', ' which theoretically makes it mountable inside non-init\nuser namespace as long as the process has sufficient *namespaced*\ncapabilities within that user namespace. But in reality we still\nrestrict BPF FS to be mountable only by processes with CAP_SYS_ADMIN *in\ninit userns* (extra check in bpf_fill_super()). FS_USERNS_MOUNT is added\nto allow creating BPF FS context object (i.e.', ' fsopen(""bpf"")) from\ninside unprivileged process inside non-init userns', ' to capture that\nuserns as the owning userns. It will still be required to pass this\ncontext object back to privileged process to instantiate and mount it.\n\nThis manipulation is important', ' because capturing non-init userns as the\nowning userns of BPF FS instance (super block) allows to use that userns\nto constraint BPF token to that userns later on (see next patch). So\ncreating BPF FS with delegation inside unprivileged userns will restrict\nderived BPF token objects to only ""work"" inside that intended userns', '\nmaking it scoped to a intended ""container"". Also', ' setting these\ndelegation options requires capable(CAP_SYS_ADMIN)', ' so unprivileged\nprocess cannot set this up without involvement of a privileged process.\n\nThere is a set of selftests at the end of the patch set that simulates\nthis sequence of steps and validates that everything works as intended.\nBut careful review is requested to make sure there are no missed gaps in\nthe implementation and testing.\n\nThis somewhat subtle set of aspects is the result of previous\ndiscussions ([0]) about various user namespace implications and\ninteractions with BPF token functionality and is necessary to contain\nBPF token inside intended user namespace.\n\n  [0] https://lore.kernel.org/bpf/20230704-hochverdient-lehne-eeb9eeef785e@brauner/\n\nAcked-by: Christian Brauner <brauner@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231130185229.2688956-3-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add new mount options to BPF FS for BPF token delegation.,"BPF token, mount options, delegation",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","[""It's not related to any of the above.""]"
909fa05dd3c181e5b403912889057f7cdbf3906c,909fa05dd3c181e5b403912889057f7cdbf3906c,Andrii Nakryiko,andrii@kernel.org,1701370333,Alexei Starovoitov,ast@kernel.org,1701885778,58ce7e83ddf09f631a85dc19aa9c5703d853996c,3aee2bf9c49be2144460d7267560232e3d45d367,"bpf: align CAP_NET_ADMIN checks with bpf_capable() approach

Within BPF syscall handling code CAP_NET_ADMIN checks stand out a bit
compared to CAP_BPF and CAP_PERFMON checks. For the latter"," CAP_BPF or
CAP_PERFMON are checked first","[' but if they are not set', ' CAP_SYS_ADMIN\ntakes over and grants whatever part of BPF syscall is required.\n\nSimilar kind of checks that involve CAP_NET_ADMIN are not so consistent.\nOne out of four uses does follow CAP_BPF/CAP_PERFMON model: during\nBPF_PROG_LOAD', ' if the type of BPF program is ""network-related"" either\nCAP_NET_ADMIN or CAP_SYS_ADMIN is required to proceed.\n\nBut in three other cases CAP_NET_ADMIN is required even if CAP_SYS_ADMIN\nis set:\n  - when creating DEVMAP/XDKMAP/CPU_MAP maps;\n  - when attaching CGROUP_SKB programs;\n  - when handling BPF_PROG_QUERY command.\n\nThis patch is changing the latter three cases to follow BPF_PROG_LOAD\nmodel', ' that is allowing to proceed under either CAP_NET_ADMIN or\nCAP_SYS_ADMIN.\n\nThis also makes it cleaner in subsequent BPF token patches to switch\nwholesomely to a generic bpf_token_capable(int cap) check', ' that always\nfalls back to CAP_SYS_ADMIN if requested capability is missing.\n\nCc: Jakub Kicinski <kuba@kernel.org>\nAcked-by: Yafang Shao <laoar.shao@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231130185229.2688956-2-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Align CAP_NET_ADMIN checks with bpf_capable() approach in BPF syscall handling.,"CAP_NET_ADMIN,bpf_capable,BPF",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The syscall interface,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1834d62ae88500f37cba4439c3237aa85242272e,1834d62ae88500f37cba4439c3237aa85242272e,D. Wythe,alibuda@linux.alibaba.com,1701329003,Pablo Neira Ayuso,pablo@netfilter.org,1701879266,14d75d7076afade73ea6945190bc860655c2a7a0,54d4434da824460a190d547404530eff12a7907d,"netfilter: bpf: fix bad registration on nf_defrag

We should pass a pointer to global_hook to the get_proto_defrag_hook()
instead of its value"," since the passed value won't be updated even if
the request module was loaded successfully.

Log:

[   54.915713] nf_defrag_ipv4 has bad registration
[   54.915779] WARNING: CPU: 3 PID: 6323 at net/netfilter/nf_bpf_link.c:62 get_proto_defrag_hook+0x137/0x160
[   54.915835] CPU: 3 PID: 6323 Comm: fentry Kdump: loaded Tainted: G            E      6.7.0-rc2+ #35
[   54.915839] Hardware name: QEMU Standard PC (i440FX + PIIX","[' 1996)', ' BIOS rel-1.15.0-0-g2dd4b9b3f840-prebuilt.qemu.org 04/01/2014\n[   54.915841] RIP: 0010:get_proto_defrag_hook+0x137/0x160\n[   54.915844] Code: 4f 8c e8 2c cf 68 ff 80 3d db 83 9a 01 00 0f 85 74 ff ff ff 48 89 ee 48 c7 c7 8f 12 4f 8c c6 05 c4 83 9a 01 01 e8 09 ee 5f ff <0f> 0b e9 57 ff ff ff 49 8b 3c 24 4c 63 e5 e8 36 28 6c ff 4c 89 e0\n[   54.915849] RSP: 0018:ffffb676003fbdb0 EFLAGS: 00010286\n[   54.915852] RAX: 0000000000000023 RBX: ffff9596503d5600 RCX: ffff95996fce08c8\n[   54.915854] RDX: 00000000ffffffd8 RSI: 0000000000000027 RDI: ffff95996fce08c0\n[   54.915855] RBP: ffffffff8c4f12de R08: 0000000000000000 R09: 00000000fffeffff\n[   54.915859] R10: ffffb676003fbc70 R11: ffffffff8d363ae8 R12: 0000000000000000\n[   54.915861] R13: ffffffff8e1f75c0 R14: ffffb676003c9000 R15: 00007ffd15e78ef0\n[   54.915864] FS:  00007fb6e9cab740(0000) GS:ffff95996fcc0000(0000) knlGS:0000000000000000\n[   54.915867] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[   54.915868] CR2: 00007ffd15e75c40 CR3: 0000000101e62006 CR4: 0000000000360ef0\n[   54.915870] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\n[   54.915871] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400\n[   54.915873] Call Trace:\n[   54.915891]  <TASK>\n[   54.915894]  ? __warn+0x84/0x140\n[   54.915905]  ? get_proto_defrag_hook+0x137/0x160\n[   54.915908]  ? __report_bug+0xea/0x100\n[   54.915925]  ? report_bug+0x2b/0x80\n[   54.915928]  ? handle_bug+0x3c/0x70\n[   54.915939]  ? exc_invalid_op+0x18/0x70\n[   54.915942]  ? asm_exc_invalid_op+0x1a/0x20\n[   54.915948]  ? get_proto_defrag_hook+0x137/0x160\n[   54.915950]  bpf_nf_link_attach+0x1eb/0x240\n[   54.915953]  link_create+0x173/0x290\n[   54.915969]  __sys_bpf+0x588/0x8f0\n[   54.915974]  __x64_sys_bpf+0x20/0x30\n[   54.915977]  do_syscall_64+0x45/0xf0\n[   54.915989]  entry_SYSCALL_64_after_hwframe+0x6e/0x76\n[   54.915998] RIP: 0033:0x7fb6e9daa51d\n[   54.916001] Code: 00 c3 66 2e 0f 1f 84 00 00 00 00 00 90 f3 0f 1e fa 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 73 01 c3 48 8b 0d 2b 89 0c 00 f7 d8 64 89 01 48\n[   54.916003] RSP: 002b:00007ffd15e78ed8 EFLAGS: 00000246 ORIG_RAX: 0000000000000141\n[   54.916006] RAX: ffffffffffffffda RBX: 00007ffd15e78fc0 RCX: 00007fb6e9daa51d\n[   54.916007] RDX: 0000000000000040 RSI: 00007ffd15e78ef0 RDI: 000000000000001c\n[   54.916009] RBP: 000000000000002d R08: 00007fb6e9e73a60 R09: 0000000000000001\n[   54.916010] R10: 0000000000000000 R11: 0000000000000246 R12: 0000000000000006\n[   54.916012] R13: 0000000000000006 R14: 0000000000000000 R15: 0000000000000000\n[   54.916014]  </TASK>\n[   54.916015] ---[ end trace 0000000000000000 ]---\n\nFixes: 91721c2d02d3 (""netfilter: bpf: Support BPF_F_NETFILTER_IP_DEFRAG in netfilter link"")\nSigned-off-by: D. Wythe <alibuda@linux.alibaba.com>\nAcked-by: Daniel Xu <dxu@dxuuu.xyz>\nReviewed-by: Simon Horman <horms@kernel.org>\nSigned-off-by: Pablo Neira Ayuso <pablo@netfilter.org>\n', '']",Fix bad registration in nf_defrag by passing a pointer to global_hook in netfilter BPF.,"netfilter, registration, nf_defrag",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tc/netfilter like programs']
3aee2bf9c49be2144460d7267560232e3d45d367,3aee2bf9c49be2144460d7267560232e3d45d367,Alexei Starovoitov,ast@kernel.org,1701812421,Alexei Starovoitov,ast@kernel.org,1701812494,fa3c0247846db9c119d29a1b24960c7674188d61,5ffb260f754bf838507fe0c23d05254b33e2bf3d 064e0bea19b356c5d5f48a4549d80a3c03ce898b,"Merge branch 'complete-bpf-verifier-precision-tracking-support-for-register-spills'

Andrii Nakryiko says:

====================
Complete BPF verifier precision tracking support for register spills

Add support to BPF verifier to track and support register spill/fill to/from
stack regardless if it was done through read-only R10 register (which is the
only form supported today)"," or through a general register after copying R10
into it","[' while also potentially modifying offset.\n\nOnce we add register this generic spill/fill support to precision\nbacktracking', ' we can take advantage of it to stop doing eager STACK_ZERO\nconversion on register spill. Instead we can rely on (im)precision of spilled\nconst zero register to improve verifier state pruning efficiency. This\nsituation of using const zero register to initialize stack slots is very\ncommon with __builtin_memset() usage or just zero-initializing variables on\nthe stack', ' and it causes unnecessary state duplication', ' as that STACK_ZERO\nknowledge is often not necessary for correctness', ' as those zero values are\nnever used in precise context. Thus', ' relying on register imprecision helps\ntremendously', ' especially in real-world BPF programs.\n\nTo make spilled const zero register behave completely equivalently to\nSTACK_ZERO', ' we need to improve few other small pieces', ' which is done in the\nsecond part of the patch set. See individual patches for details. There are\nalso two small bug fixes spotted during STACK_ZERO debugging.\n\nThe patch set consists of logically three changes:\n  - patch #1 (and corresponding tests in patch #2) is fixing/impoving precision\n    propagation for stack spills/fills. This can be landed as a stand-alone\n    improvement;\n  - patches #3 through #9 is improving verification scalability by utilizing\n    register (im)precision instead of eager STACK_ZERO. These changes depend\n    on patch #1.\n  - patch #10 is a memory efficiency improvement to how instruction/jump\n    history is tracked and maintained. It depends on patch #1', ' but is not\n    strictly speaking required', "" even though I believe it's a good long-term\n    solution to have a path-dependent per-instruction information. Kind\n    of like a path-dependent counterpart to path-agnostic insn_aux array.\n\nv3->v3:\n  - fixed up Fixes tag (Alexei);\n  - fixed few more selftests to not use BPF_ST instruction in inline asm\n    directly"", ' checked with CI', ' it was happy (CI);\nv2->v3:\n  - BPF_ST instruction workaround (Eduard);\n  - force dereference in added tests to catch problems (Eduard);\n  - some commit message massaging (Alexei);\nv1->v2:\n  - clean ups', ' WARN_ONCE()', ' insn_flags helpers added (Eduard);\n  - added more selftests for STACK_ZERO/STACK_MISC cases (Eduard);\n  - a bit more detailed explanation of effect of avoiding STACK_ZERO in favor\n    of register spill in patch #8 commit (Alexei);\n  - global shared instruction history refactoring moved to be the last patch\n    in the series to make it easier to revert it', ' if applied (Alexei).\n====================\n\nLink: https://lore.kernel.org/r/20231205184248.1502704-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Enhances BPF verifier with precision tracking for register spills and fills to/from stack.,"verifier, precision, register",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
064e0bea19b356c5d5f48a4549d80a3c03ce898b,064e0bea19b356c5d5f48a4549d80a3c03ce898b,Andrii Nakryiko,andrii@kernel.org,1701801767,Alexei Starovoitov,ast@kernel.org,1701812421,fa3c0247846db9c119d29a1b24960c7674188d61,18a433b62061e3d787bfc3e670fa711fecbd7cb4,"selftests/bpf: validate precision logic in partial_stack_load_preserves_zeros

Enhance partial_stack_load_preserves_zeros subtest with detailed
precision propagation log checks. We know expect fp-16 to be spilled","
initially imprecise","[' zero const register', ' which is later marked as\nprecise even when partial stack slot load is performed', "" even if it's not\na register fill (!).\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231205184248.1502704-10-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Enhance BPF self-tests with precision propagation checks for partial stack load operations.,"selftests, precision, stack",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
18a433b62061e3d787bfc3e670fa711fecbd7cb4,18a433b62061e3d787bfc3e670fa711fecbd7cb4,Andrii Nakryiko,andrii@kernel.org,1701801766,Alexei Starovoitov,ast@kernel.org,1701812421,fd87e3195e34d3a935f659293ddc44e32b85c10f,add1cd7f22e61756987865ada9fe95cd86569025,"bpf: track aligned STACK_ZERO cases as imprecise spilled registers

Now that precision backtracing is supporting register spill/fill to/from
stack"," there is another oportunity to be exploited here: minimizing
precise STACK_ZERO cases. With a simple code change we can rely on
initially imprecise register spill tracking for cases when register
spilled to stack was a known zero.

This is a very common case for initializing on the stack variables","['\nincluding rather large structures. Often times zero has no special\nmeaning for the subsequent BPF program logic and is often overwritten\nwith non-zero values soon afterwards. But due to STACK_ZERO vs\nSTACK_MISC tracking', ' such initial zero initialization actually causes\nduplication of verifier states as STACK_ZERO is clearly different than\nSTACK_MISC or spilled SCALAR_VALUE register.\n\nThe effect of this (now) trivial change is huge', ' as can be seen below.\nThese are differences between BPF selftests', ' Cilium', ' and Meta-internal\nBPF object files relative to previous patch in this series. You can see\nimprovements ranging from single-digit percentage improvement for\ninstructions and states', ' all the way to 50-60% reduction for some of\nMeta-internal host agent programs', ' and even some Cilium programs.\n\nFor Meta-internal ones I left only the differences for largest BPF\nobject files by states/instructions', ' as there were too many differences\nin the overall output. All the differences were improvements', ' reducting\nnumber of states and thus instructions validated.\n\nNote', ' Meta-internal BPF object file names are not printed below.\nMany copies of balancer_ingress are actually many different\nconfigurations of Katran', ' so they are different BPF programs', ' which\nexplains state reduction going from -16% all the way to 31%', "" depending\non BPF program logic complexity.\n\nI also tooked a closer look at a few small-ish BPF programs to validate\nthe behavior. Let's take bpf_iter_netrlink.bpf.o (first row below).\nWhile it's just 8 vs 5 states"", ' verifier log is still pretty long to\ninclude it here. But the reduction in states is due to the following\npiece of C code:\n\n        unsigned long ino;\n\n\t...\n\n        sk = s->sk_socket;\n        if (!sk) {\n                ino = 0;\n        } else {\n                inode = SOCK_INODE(sk);\n                bpf_probe_read_kernel(&ino', ' sizeof(ino)', ' &inode->i_ino);\n        }\n        BPF_SEQ_PRINTF(seq', ' ""%-8u %-8lu\\n""', ' s->sk_drops.counter', ' ino);\n\treturn 0;\n\nYou can see that in some situations `ino` is zero-initialized', "" while in\nothers it's unknown value filled out by bpf_probe_read_kernel(). Before\nthis change code after if/else branches have to be validated twice. Once\nwith (precise) ino == 0"", ' due to eager STACK_ZERO logic', "" and then again\nfor when ino is just STACK_MISC. But BPF_SEQ_PRINTF() doesn't care about\nprecise value of ino"", ' so with the change in this patch verifier is able\nto prune states from after one of the branches', ' reducing number of total\nstates (and instructions) required for successful validation.\n\nSimilar principle applies to bigger real-world applications', ' just at\na much larger scale.\n\nSELFTESTS\n=========\nFile                                     Program                  Insns (A)  Insns (B)  Insns    (DIFF)  States (A)  States (B)  States (DIFF)\n---------------------------------------  -----------------------  ---------  ---------  ---------------  ----------  ----------  -------------\nbpf_iter_netlink.bpf.linked3.o           dump_netlink                   148        104    -44 (-29.73%)           8           5   -3 (-37.50%)\nbpf_iter_unix.bpf.linked3.o              dump_unix                     8474       8404     -70 (-0.83%)         151         147    -4 (-2.65%)\nbpf_loop.bpf.linked3.o                   stack_check                    560        324   -236 (-42.14%)          42          24  -18 (-42.86%)\nlocal_storage_bench.bpf.linked3.o        get_local                      120         77    -43 (-35.83%)           9           6   -3 (-33.33%)\nloop6.bpf.linked3.o                      trace_virtqueue_add_sgs      10167       9868    -299 (-2.94%)         226         206   -20 (-8.85%)\npyperf600_bpf_loop.bpf.linked3.o         on_event                      4872       3423  -1449 (-29.74%)         322         229  -93 (-28.88%)\nstrobemeta.bpf.linked3.o                 on_event                    180697     176036   -4661 (-2.58%)        4780        4734   -46 (-0.96%)\ntest_cls_redirect.bpf.linked3.o          cls_redirect                 65594      65401    -193 (-0.29%)        4230        4212   -18 (-0.43%)\ntest_global_func_args.bpf.linked3.o      test_cls                       145        136      -9 (-6.21%)          10           9   -1 (-10.00%)\ntest_l4lb.bpf.linked3.o                  balancer_ingress              4760       2612  -2148 (-45.13%)         113         102   -11 (-9.73%)\ntest_l4lb_noinline.bpf.linked3.o         balancer_ingress              4845       4877     +32 (+0.66%)         219         221    +2 (+0.91%)\ntest_l4lb_noinline_dynptr.bpf.linked3.o  balancer_ingress              2072       2087     +15 (+0.72%)          97          98    +1 (+1.03%)\ntest_seg6_loop.bpf.linked3.o             __add_egr_x                  12440       9975  -2465 (-19.82%)         364         353   -11 (-3.02%)\ntest_tcp_hdr_options.bpf.linked3.o       estab                         2558       2572     +14 (+0.55%)         179         180    +1 (+0.56%)\ntest_xdp_dynptr.bpf.linked3.o            _xdp_tx_iptunnel               645        596     -49 (-7.60%)          26          24    -2 (-7.69%)\ntest_xdp_noinline.bpf.linked3.o          balancer_ingress_v6           3520       3516      -4 (-0.11%)         216         216    +0 (+0.00%)\nxdp_synproxy_kern.bpf.linked3.o          syncookie_tc                 82661      81241   -1420 (-1.72%)        5073        5155   +82 (+1.62%)\nxdp_synproxy_kern.bpf.linked3.o          syncookie_xdp                84964      82297   -2667 (-3.14%)        5130        5157   +27 (+0.53%)\n\nMETA-INTERNAL\n=============\nProgram                                 Insns (A)  Insns (B)  Insns      (DIFF)  States (A)  States (B)  States   (DIFF)\n--------------------------------------  ---------  ---------  -----------------  ----------  ----------  ---------------\nbalancer_ingress                            27925      23608    -4317 (-15.46%)        1488        1482      -6 (-0.40%)\nbalancer_ingress                            31824      27546    -4278 (-13.44%)        1658        1652      -6 (-0.36%)\nbalancer_ingress                            32213      27935    -4278 (-13.28%)        1689        1683      -6 (-0.36%)\nbalancer_ingress                            32213      27935    -4278 (-13.28%)        1689        1683      -6 (-0.36%)\nbalancer_ingress                            31824      27546    -4278 (-13.44%)        1658        1652      -6 (-0.36%)\nbalancer_ingress                            38647      29562    -9085 (-23.51%)        2069        1835   -234 (-11.31%)\nbalancer_ingress                            38647      29562    -9085 (-23.51%)        2069        1835   -234 (-11.31%)\nbalancer_ingress                            40339      30792    -9547 (-23.67%)        2193        1934   -259 (-11.81%)\nbalancer_ingress                            37321      29055    -8266 (-22.15%)        1972        1795    -177 (-8.98%)\nbalancer_ingress                            38176      29753    -8423 (-22.06%)        2008        1831    -177 (-8.81%)\nbalancer_ingress                            29193      20910    -8283 (-28.37%)        1599        1422   -177 (-11.07%)\nbalancer_ingress                            30013      21452    -8561 (-28.52%)        1645        1447   -198 (-12.04%)\nbalancer_ingress                            28691      24290    -4401 (-15.34%)        1545        1531     -14 (-0.91%)\nbalancer_ingress                            34223      28965    -5258 (-15.36%)        1984        1875    -109 (-5.49%)\nbalancer_ingress                            35481      26158    -9323 (-26.28%)        2095        1806   -289 (-13.79%)\nbalancer_ingress                            35481      26158    -9323 (-26.28%)        2095        1806   -289 (-13.79%)\nbalancer_ingress                            35868      26455    -9413 (-26.24%)        2140        1827   -313 (-14.63%)\nbalancer_ingress                            35868      26455    -9413 (-26.24%)        2140        1827   -313 (-14.63%)\nbalancer_ingress                            35481      26158    -9323 (-26.28%)        2095        1806   -289 (-13.79%)\nbalancer_ingress                            35481      26158    -9323 (-26.28%)        2095        1806   -289 (-13.79%)\nbalancer_ingress                            34844      29485    -5359 (-15.38%)        2036        1918    -118 (-5.80%)\nfbflow_egress                                3256       2652     -604 (-18.55%)         218         192    -26 (-11.93%)\nfbflow_ingress                               1026        944       -82 (-7.99%)          70          63     -7 (-10.00%)\nsslwall_tc_egress                            8424       7360    -1064 (-12.63%)         498         458     -40 (-8.03%)\nsyar_accept_protect                         15040       9539    -5501 (-36.58%)         364         220   -144 (-39.56%)\nsyar_connect_tcp_v6                         15036       9535    -5501 (-36.59%)         360         216   -144 (-40.00%)\nsyar_connect_udp_v4                         15039       9538    -5501 (-36.58%)         361         217   -144 (-39.89%)\nsyar_connect_connect4_protect4              24805      15833    -8972 (-36.17%)         756         480   -276 (-36.51%)\nsyar_lsm_file_open                         167772     151813    -15959 (-9.51%)        1836        1667    -169 (-9.20%)\nsyar_namespace_create_new                   14805       9304    -5501 (-37.16%)         353         209   -144 (-40.79%)\nsyar_python3_detect                         17531      12030    -5501 (-31.38%)         391         247   -144 (-36.83%)\nsyar_ssh_post_fork                          16412      10911    -5501 (-33.52%)         405         261   -144 (-35.56%)\nsyar_enter_execve                           14728       9227    -5501 (-37.35%)         345         201   -144 (-41.74%)\nsyar_enter_execveat                         14728       9227    -5501 (-37.35%)         345         201   -144 (-41.74%)\nsyar_exit_execve                            16622      11121    -5501 (-33.09%)         376         232   -144 (-38.30%)\nsyar_exit_execveat                          16622      11121    -5501 (-33.09%)         376         232   -144 (-38.30%)\nsyar_syscalls_kill                          15288       9787    -5501 (-35.98%)         398         254   -144 (-36.18%)\nsyar_task_enter_pivot_root                  14898       9397    -5501 (-36.92%)         357         213   -144 (-40.34%)\nsyar_syscalls_setreuid                      16678      11177    -5501 (-32.98%)         429         285   -144 (-33.57%)\nsyar_syscalls_setuid                        16678      11177    -5501 (-32.98%)         429         285   -144 (-33.57%)\nsyar_syscalls_process_vm_readv              14959       9458    -5501 (-36.77%)         364         220   -144 (-39.56%)\nsyar_syscalls_process_vm_writev             15757      10256    -5501 (-34.91%)         390         246   -144 (-36.92%)\ndo_uprobe                                   15519      10018    -5501 (-35.45%)         373         229   -144 (-38.61%)\nedgewall                                   179715      55783  -123932 (-68.96%)       12607        3999  -8608 (-68.28%)\nbictcp_state                                 7570       4131    -3439 (-45.43%)         496         269   -227 (-45.77%)\ncubictcp_state                               7570       4131    -3439 (-45.43%)         496         269   -227 (-45.77%)\ntcp_rate_skb_delivered                        447        272     -175 (-39.15%)          29          18    -11 (-37.93%)\nkprobe__bbr_set_state                        4566       2615    -1951 (-42.73%)         209         124    -85 (-40.67%)\nkprobe__bictcp_state                         4566       2615    -1951 (-42.73%)         209         124    -85 (-40.67%)\ninet_sock_set_state                          1501       1337     -164 (-10.93%)          93          85      -8 (-8.60%)\ntcp_retransmit_skb                           1145        981     -164 (-14.32%)          67          59     -8 (-11.94%)\ntcp_retransmit_synack                        1183        951     -232 (-19.61%)          67          55    -12 (-17.91%)\nbpf_tcptuner                                 1459       1187     -272 (-18.64%)          99          80    -19 (-19.19%)\ntw_egress                                     801        776       -25 (-3.12%)          69          66      -3 (-4.35%)\ntw_ingress                                    795        770       -25 (-3.14%)          69          66      -3 (-4.35%)\nttls_tc_ingress                             19025      19383      +358 (+1.88%)         470         465      -5 (-1.06%)\nttls_nat_egress                               490        299     -191 (-38.98%)          33          20    -13 (-39.39%)\nttls_nat_ingress                              448        285     -163 (-36.38%)          32          21    -11 (-34.38%)\ntw_twfw_egress                             511127     212071  -299056 (-58.51%)       16733        8504  -8229 (-49.18%)\ntw_twfw_ingress                            500095     212069  -288026 (-57.59%)       16223        8504  -7719 (-47.58%)\ntw_twfw_tc_eg                              511113     212064  -299049 (-58.51%)       16732        8504  -8228 (-49.18%)\ntw_twfw_tc_in                              500095     212069  -288026 (-57.59%)       16223        8504  -7719 (-47.58%)\ntw_twfw_egress                              12632      12435      -197 (-1.56%)         276         260     -16 (-5.80%)\ntw_twfw_ingress                             12631      12454      -177 (-1.40%)         278         261     -17 (-6.12%)\ntw_twfw_tc_eg                               12595      12435      -160 (-1.27%)         274         259     -15 (-5.47%)\ntw_twfw_tc_in                               12631      12454      -177 (-1.40%)         278         261     -17 (-6.12%)\ntw_xdp_dump                                   266        209      -57 (-21.43%)           9           8     -1 (-11.11%)\n\nCILIUM\n=========\nFile           Program                           Insns (A)  Insns (B)  Insns     (DIFF)  States (A)  States (B)  States  (DIFF)\n-------------  --------------------------------  ---------  ---------  ----------------  ----------  ----------  --------------\nbpf_host.o     cil_to_netdev                          6047       4578   -1469 (-24.29%)         362         249  -113 (-31.22%)\nbpf_host.o     handle_lxc_traffic                     2227       1585    -642 (-28.83%)         156         103   -53 (-33.97%)\nbpf_host.o     tail_handle_ipv4_from_netdev           2244       1458    -786 (-35.03%)         163         106   -57 (-34.97%)\nbpf_host.o     tail_handle_nat_fwd_ipv4              21022      10479  -10543 (-50.15%)        1289         670  -619 (-48.02%)\nbpf_host.o     tail_handle_nat_fwd_ipv6              15433      11375   -4058 (-26.29%)         905         643  -262 (-28.95%)\nbpf_host.o     tail_ipv4_host_policy_ingress          2219       1367    -852 (-38.40%)         161          96   -65 (-40.37%)\nbpf_host.o     tail_nodeport_nat_egress_ipv4         22460      19862   -2598 (-11.57%)        1469        1293  -176 (-11.98%)\nbpf_host.o     tail_nodeport_nat_ingress_ipv4         5526       3534   -1992 (-36.05%)         366         243  -123 (-33.61%)\nbpf_host.o     tail_nodeport_nat_ingress_ipv6         5132       4256    -876 (-17.07%)         241         219    -22 (-9.13%)\nbpf_host.o     tail_nodeport_nat_ipv6_egress          3702       3542     -160 (-4.32%)         215         205    -10 (-4.65%)\nbpf_lxc.o      tail_handle_nat_fwd_ipv4              21022      10479  -10543 (-50.15%)        1289         670  -619 (-48.02%)\nbpf_lxc.o      tail_handle_nat_fwd_ipv6              15433      11375   -4058 (-26.29%)         905         643  -262 (-28.95%)\nbpf_lxc.o      tail_ipv4_ct_egress                    5073       3374   -1699 (-33.49%)         262         172   -90 (-34.35%)\nbpf_lxc.o      tail_ipv4_ct_ingress                   5093       3385   -1708 (-33.54%)         262         172   -90 (-34.35%)\nbpf_lxc.o      tail_ipv4_ct_ingress_policy_only       5093       3385   -1708 (-33.54%)         262         172   -90 (-34.35%)\nbpf_lxc.o      tail_ipv6_ct_egress                    4593       3878    -715 (-15.57%)         194         151   -43 (-22.16%)\nbpf_lxc.o      tail_ipv6_ct_ingress                   4606       3891    -715 (-15.52%)         194         151   -43 (-22.16%)\nbpf_lxc.o      tail_ipv6_ct_ingress_policy_only       4606       3891    -715 (-15.52%)         194         151   -43 (-22.16%)\nbpf_lxc.o      tail_nodeport_nat_ingress_ipv4         5526       3534   -1992 (-36.05%)         366         243  -123 (-33.61%)\nbpf_lxc.o      tail_nodeport_nat_ingress_ipv6         5132       4256    -876 (-17.07%)         241         219    -22 (-9.13%)\nbpf_overlay.o  tail_handle_nat_fwd_ipv4              20524      10114  -10410 (-50.72%)        1271         638  -633 (-49.80%)\nbpf_overlay.o  tail_nodeport_nat_egress_ipv4         22718      19490   -3228 (-14.21%)        1475        1275  -200 (-13.56%)\nbpf_overlay.o  tail_nodeport_nat_ingress_ipv4         5526       3534   -1992 (-36.05%)         366         243  -123 (-33.61%)\nbpf_overlay.o  tail_nodeport_nat_ingress_ipv6         5132       4256    -876 (-17.07%)         241         219    -22 (-9.13%)\nbpf_overlay.o  tail_nodeport_nat_ipv6_egress          3638       3548      -90 (-2.47%)         209         203     -6 (-2.87%)\nbpf_overlay.o  tail_rev_nodeport_lb4                  4368       3820    -548 (-12.55%)         248         215   -33 (-13.31%)\nbpf_overlay.o  tail_rev_nodeport_lb6                  2867       2428    -439 (-15.31%)         167         140   -27 (-16.17%)\nbpf_sock.o     cil_sock6_connect                      1718       1703      -15 (-0.87%)         100          99     -1 (-1.00%)\nbpf_xdp.o      tail_handle_nat_fwd_ipv4              12917      12443     -474 (-3.67%)         875         849    -26 (-2.97%)\nbpf_xdp.o      tail_handle_nat_fwd_ipv6              13515      13264     -251 (-1.86%)         715         702    -13 (-1.82%)\nbpf_xdp.o      tail_lb_ipv4                          39492      36367    -3125 (-7.91%)        2430        2251   -179 (-7.37%)\nbpf_xdp.o      tail_lb_ipv6                          80441      78058    -2383 (-2.96%)        3647        3523   -124 (-3.40%)\nbpf_xdp.o      tail_nodeport_ipv6_dsr                 1038        901    -137 (-13.20%)          61          55     -6 (-9.84%)\nbpf_xdp.o      tail_nodeport_nat_egress_ipv4         13027      12096     -931 (-7.15%)         868         809    -59 (-6.80%)\nbpf_xdp.o      tail_nodeport_nat_ingress_ipv4         7617       5900   -1717 (-22.54%)         522         413  -109 (-20.88%)\nbpf_xdp.o      tail_nodeport_nat_ingress_ipv6         7575       7395     -180 (-2.38%)         383         374     -9 (-2.35%)\nbpf_xdp.o      tail_rev_nodeport_lb4                  6808       6739      -69 (-1.01%)         403         396     -7 (-1.74%)\nbpf_xdp.o      tail_rev_nodeport_lb6                 16173      15847     -326 (-2.02%)        1010         990    -20 (-1.98%)\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231205184248.1502704-9-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit enhances register spill tracking for STACK_ZERO cases as imprecise spilled registers in eBPF.,"aligned, STACK_ZERO, registers",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
add1cd7f22e61756987865ada9fe95cd86569025,add1cd7f22e61756987865ada9fe95cd86569025,Andrii Nakryiko,andrii@kernel.org,1701801765,Alexei Starovoitov,ast@kernel.org,1701812421,4a3a28c109d0c6d293cead323e1b26c883ee70bf,e322f0bcb8d371f4606eaf141c7f967e1a79bcb7,"selftests/bpf: validate zero preservation for sub-slot loads

Validate that 1-", 2-,"[' and 4-byte loads from stack slots not aligned on\n8-byte boundary still preserve zero', ' when loading from all-STACK_ZERO\nsub-slots', ' or when stack sub-slots are covered by spilled register with\nknown constant zero value.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231205184248.1502704-8-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add selftests for validating zero preservation for sub-slot loads in eBPF.,"selftests,zero preservation,sub-slot loads",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e322f0bcb8d371f4606eaf141c7f967e1a79bcb7,e322f0bcb8d371f4606eaf141c7f967e1a79bcb7,Andrii Nakryiko,andrii@kernel.org,1701801764,Alexei Starovoitov,ast@kernel.org,1701812421,465b4dead3816fce4a5b27dafd7f566fb5b75da4,b33ceb6a3d2ee07fdd836373383a6d4783581324,"bpf: preserve constant zero when doing partial register restore

Similar to special handling of STACK_ZERO"," when reading 1/2/4 bytes from
stack from slot that has register spilled into it and that register has
a constant value zero","[' preserve that zero and mark spilled register as\nprecise for that. This makes spilled const zero register and STACK_ZERO\ncases equivalent in their behavior.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231205184248.1502704-7-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit ensures that constant zero values are maintained during partial register restorations in the eBPF verifier.,"constant, register, restore",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b33ceb6a3d2ee07fdd836373383a6d4783581324,b33ceb6a3d2ee07fdd836373383a6d4783581324,Andrii Nakryiko,andrii@kernel.org,1701801763,Alexei Starovoitov,ast@kernel.org,1701812420,6a50eb07c53d941a7aa676db95e91721f883d839,eaf18febd6ebc381aeb61543705148b3e28c7c47,"selftests/bpf: validate STACK_ZERO is preserved on subreg spill

Add tests validating that STACK_ZERO slots are preserved when slot is
partially overwritten with subregister spill.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231205184248.1502704-6-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Added tests to validate STACK_ZERO preservation on subregister spill in bpf selftests.,"STACK_ZERO, subregister, selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
eaf18febd6ebc381aeb61543705148b3e28c7c47,eaf18febd6ebc381aeb61543705148b3e28c7c47,Andrii Nakryiko,andrii@kernel.org,1701801762,Alexei Starovoitov,ast@kernel.org,1701812420,b3f296260d280b9473b456c33da8c9f0af649fd2,ab125ed3ec1c10ccc36bc98c7a4256ad114a3dae,"bpf: preserve STACK_ZERO slots on partial reg spills

Instead of always forcing STACK_ZERO slots to STACK_MISC"," preserve it in
situations where this is possible. E.g.","[' when spilling register as\n1/2/4-byte subslots on the stack', ' all the remaining bytes in the stack\nslot do not automatically become unknown. If we knew they contained\nzeroes', ' we can preserve those STACK_ZERO markers.\n\nAdd a helper mark_stack_slot_misc()', ' similar to scrub_spilled_slot()', ""\nbut that doesn't overwrite either STACK_INVALID nor STACK_ZERO. Note\nthat we need to take into account possibility of being in unprivileged\nmode"", ' in which case STACK_INVALID is forced to STACK_MISC for correctness', '\nas treating STACK_INVALID as equivalent STACK_MISC is only enabled in\nprivileged mode.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231205184248.1502704-5-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit preserves STACK_ZERO slots during partial register spills in the eBPF verifier.,"STACK_ZERO,register spills,verifier",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ab125ed3ec1c10ccc36bc98c7a4256ad114a3dae,ab125ed3ec1c10ccc36bc98c7a4256ad114a3dae,Andrii Nakryiko,andrii@kernel.org,1701801761,Alexei Starovoitov,ast@kernel.org,1701812420,0c4185c31afa6f73b9a5f0ef6b9f9c9621cc662c,876301881c436bf38e83a2c0d276a24b642e4aab,"bpf: fix check for attempt to corrupt spilled pointer

When register is spilled onto a stack as a 1/2/4-byte register"," we set
slot_type[BPF_REG_SIZE - 1] (plus potentially few more below it","['\ndepending on actual spill size). So to check if some stack slot has\nspilled register we need to consult slot_type[7]', ' not slot_type[0].\n\nTo avoid the need to remember and double-check this in the future', ' just\nuse is_spilled_reg() helper.\n\nFixes: 27113c59b6d0 (""bpf: Check the other end of slot_type for STACK_SPILL"")\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231205184248.1502704-4-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes a check for attempts to corrupt spilled pointers in the eBPF verifier.,"fix,corrupt,pointer",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
876301881c436bf38e83a2c0d276a24b642e4aab,876301881c436bf38e83a2c0d276a24b642e4aab,Andrii Nakryiko,andrii@kernel.org,1701801760,Alexei Starovoitov,ast@kernel.org,1701812420,dcac49d7f85b37e4f999fd1d3cf382036eaf565d,41f6f64e6999a837048b1bd13a2f8742964eca6b,"selftests/bpf: add stack access precision test

Add a new selftests that validates precision tracking for stack access
instruction"," using both r10-based and non-r10-based accesses. For
non-r10 ones we also make sure to have non-zero var_off to validate that
final stack offset is tracked properly in instruction history
information inside verifier.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231205184248.1502704-3-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Add a selftest to validate precision tracking for stack access instructions in bpf verifier.,"selftest, stack access, precision",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
41f6f64e6999a837048b1bd13a2f8742964eca6b,41f6f64e6999a837048b1bd13a2f8742964eca6b,Andrii Nakryiko,andrii@kernel.org,1701801759,Alexei Starovoitov,ast@kernel.org,1701812420,b0ec4c4bfd2ae8fc83461d3d92e3292bd265f068,5ffb260f754bf838507fe0c23d05254b33e2bf3d,"bpf: support non-r10 register spill/fill to/from stack in precision tracking

Use instruction (jump) history to record instructions that performed
register spill/fill to/from stack"," regardless if this was done through
read-only r10 register","[' or any other register after copying r10 into it\n*and* potentially adjusting offset.\n\nTo make this work reliably', ' we push extra per-instruction flags into\ninstruction history', "" encoding stack slot index (spi) and stack frame\nnumber in extra 10 bit flags we take away from prev_idx in instruction\nhistory. We don't touch idx field for maximum performance"", "" as it's\nchecked most frequently during backtracking.\n\nThis change removes basically the last remaining practical limitation of\nprecision backtracking logic in BPF verifier. It fixes known\ndeficiencies"", ' but also opens up new opportunities to reduce number of\nverified states', "" explored in the subsequent patches.\n\nThere are only three differences in selftests' BPF object files\naccording to veristat"", ' all in the positive direction (less states).\n\nFile                                    Program        Insns (A)  Insns (B)  Insns  (DIFF)  States (A)  States (B)  States (DIFF)\n--------------------------------------  -------------  ---------  ---------  -------------  ----------  ----------  -------------\ntest_cls_redirect_dynptr.bpf.linked3.o  cls_redirect        2987       2864  -123 (-4.12%)         240         231    -9 (-3.75%)\nxdp_synproxy_kern.bpf.linked3.o         syncookie_tc       82848      82661  -187 (-0.23%)        5107        5073   -34 (-0.67%)\nxdp_synproxy_kern.bpf.linked3.o         syncookie_xdp      85116      84964  -152 (-0.18%)        5162        5130   -32 (-0.62%)\n\nNote', "" I avoided renaming jmp_history to more generic insn_hist to\nminimize number of lines changed and potential merge conflicts between\nbpf and bpf-next trees.\n\nNotice also cur_hist_entry pointer reset to NULL at the beginning of\ninstruction verification loop. This pointer avoids the problem of\nrelying on last jump history entry's insn_idx to determine whether we\nalready have entry for current instruction or not. It can happen that we\nadded jump history entry because current instruction is_jmp_point()"", ' but\nalso we need to add instruction flags for stack access. In this case', "" we\ndon't want to entries"", ' so we need to reuse last added entry', ' if it is\npresent.\n\nRelying on insn_idx comparison has the same ambiguity problem as the one\nthat was fixed recently in [0]', ' so we avoid that.\n\n  [0] https://patchwork.kernel.org/project/netdevbpf/patch/20231110002638.4168352-3-andrii@kernel.org/\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nReported-by: Tao Lyu <tao.lyu@epfl.ch>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231205184248.1502704-2-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add support for non-r10 register spill/fill in precision tracking for bpf.,"register, spill, precision",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5ffb260f754bf838507fe0c23d05254b33e2bf3d,5ffb260f754bf838507fe0c23d05254b33e2bf3d,Stanislav Fomichev,sdf@google.com,1701711863,Daniel Borkmann,daniel@iogearbox.net,1701785484,7f8ad0d113c75357f2f759c58aec83cbf185be84,5c399ae080ae507954f6f2efefc7349f8ed0e051,"selftests/bpf: Make sure we trigger metadata kfuncs for dst 8080

xdp_metadata test is flaky sometimes:

  verify_xsk_metadata:FAIL:rx_hash_type unexpected rx_hash_type: actual 8 != expected 0

Where 8 means XDP_RSS_TYPE_L4_ANY and is exported from veth driver only when
'skb->l4_hash' condition is met. This makes me think that the program is
triggering again for some other packet.

Let's have a filter", similar to xdp_hw_metadata,"[' where we trigger XDP kfuncs\nonly for UDP packets destined to port 8080.\n\nSigned-off-by: Stanislav Fomichev <sdf@google.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20231204174423.3460052-1-sdf@google.com\n', '']",Fix flaky xdp_metadata test by ensuring kfuncs are triggered for destination port 8080.,"xdp_metadata,test,kfuncs",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['xdp like programs']
5c399ae080ae507954f6f2efefc7349f8ed0e051,5c399ae080ae507954f6f2efefc7349f8ed0e051,Stanislav Fomichev,sdf@google.com,1701711751,Daniel Borkmann,daniel@iogearbox.net,1701785330,ef36fb602f7598747f4825cc2aa60218614912fa,1b4c7e20bfd6cfe0efbc51756d930a9406d41ea7,"xsk: Add missing SPDX to AF_XDP TX metadata documentation

Not sure how I missed that. I even acknowledged it explicitly
in the changelog [0]. Add the tag for real now.

  [0] https://lore.kernel.org/bpf/20231127190319.1190813-1-sdf@google.com/

Fixes: 11614723af26 (""xsk: Add option to calculate TX checksum in SW"")
Suggested-by: Simon Horman <horms@kernel.org>
Signed-off-by: Stanislav Fomichev <sdf@google.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20231204174231.3457705-1-sdf@google.com
",,Added missing SPDX license tag to AF_XDP TX metadata documentation.,"SPDX, AF_XDP, documentation",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['socket like programs']
1b4c7e20bfd6cfe0efbc51756d930a9406d41ea7,1b4c7e20bfd6cfe0efbc51756d930a9406d41ea7,Dave Marchevsky,davemarchevsky@fb.com,1701724642,Daniel Borkmann,daniel@iogearbox.net,1701785207,039941b0e3e680eb0957a1cc32f62f43012a19bd,ce3c49da11d77aa7d53cd549d308eb5f7fed8576,"selftests/bpf: Test bpf_kptr_xchg stashing of bpf_rb_root

There was some confusion amongst Meta sched_ext folks regarding whether
stashing bpf_rb_root - the tree itself"," rather than a single node - was
supported. This patch adds a small test which demonstrates this
functionality: a local kptr with rb_root is created","[' a node is created\nand added to the tree', "" then the tree is kptr_xchg'd into a mapval.\n\nSigned-off-by: Dave Marchevsky <davemarchevsky@fb.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/bpf/20231204211722.571346-1-davemarchevsky@fb.com\n"", '']",The commit adds a test for stashing bpf_rb_root in bpf_kptr_xchg.,"bpf_rb_root,test,stashing",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e4d008d49a7135214e0ee70537405b6a069e3a3f,e4d008d49a7135214e0ee70537405b6a069e3a3f,Yewon Choi,woni9911@gmail.com,1701411052,Daniel Borkmann,daniel@iogearbox.net,1701780223,49a625866ba1bff1b71d541004e9045816a92b6c,dfce9cb3140592b886838e06f3e0c25fea2a9cae,"xsk: Skip polling event check for unbound socket

In xsk_poll()"," checking available events and setting mask bits should
be executed only when a socket has been bound. Setting mask bits for
unbound socket is meaningless.

Currently","[' it checks events even when xsk_check_common() failed.\nTo prevent this', ' we move goto location (skip_tx) after that checking.\n\nFixes: 1596dae2f17e (""xsk: check IFF_UP earlier in Tx path"")\nSigned-off-by: Yewon Choi <woni9911@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Magnus Karlsson <magnus.karlsson@intel.com>\nLink: https://lore.kernel.org/bpf/20231201061048.GA1510@libra05\n', '']",The commit optimizes xsk_poll by skipping polling for unbound sockets.,"xsk, polling, sockets",It's a performance optimization.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['socket like programs']
a931c6816078af3e306e0f444f492396ce40de31,a931c6816078af3e306e0f444f492396ce40de31,JP Kobryn,inwardvessel@gmail.com,1701721400,Dominique Martinet,asmadeus@codewreck.org,1701778724,3a79667cd35a6f8f8ea58331c648c835034f4440,2cc14f52aeb78ce3f29677c2de1f06c0e91471ab,"9p: prevent read overrun in protocol dump tracepoint

An out of bounds read can occur within the tracepoint 9p_protocol_dump. In
the fast assign"," there is a memcpy that uses a constant size of 32 (macro
named P9_PROTO_DUMP_SZ). When the copy is invoked","[' the source buffer is not\nguaranteed match this size.  It was found that in some cases the source\nbuffer size is less than 32', ' resulting in a read that overruns.\n\nThe size of the source buffer seems to be known at the time of the\ntracepoint being invoked. The allocations happen within p9_fcall_init()', '\nwhere the capacity field is set to the allocated size of the payload\nbuffer. This patch tries to fix the overrun by changing the fixed array to\na dynamically sized array and using the minimum of the capacity value or\nP9_PROTO_DUMP_SZ as its length. The trace log statement is adjusted to\naccount for this. Note that the trace log no longer splits the payload on\nthe first 16 bytes. The full payload is now logged to a single line.\n\nTo repro the orignal problem', ' operations to a plan 9 managed resource can\nbe used. The simplest approach might just be mounting a shared filesystem\n(between host and guest vm) using the plan 9 protocol while the tracepoint\nis enabled.\n\nmount -t 9p -o trans=virtio <mount_tag> <mount_path>\n\nThe bpftrace program below can be used to show the out of bounds read.\nNote that a recent version of bpftrace is needed for the raw tracepoint\nsupport. The script was tested using v0.19.0.\n\n/* from include/net/9p/9p.h */\nstruct p9_fcall {\n    u32 size;\n    u8 id;\n    u16 tag;\n    size_t offset;\n    size_t capacity;\n    struct kmem_cache *cache;\n    u8 *sdata;\n    bool zc;\n};\n\ntracepoint:9p:9p_protocol_dump\n{\n    /* out of bounds read can happen when this tracepoint is enabled */\n}\n\nrawtracepoint:9p_protocol_dump\n{\n    $pdu = (struct p9_fcall *)arg1;\n    $dump_sz = (uint64)32;\n\n    if ($dump_sz > $pdu->capacity) {\n        printf(""reading %zu bytes from src buffer of %zu bytes\\n""', '\n            $dump_sz', ' $pdu->capacity);\n    }\n}\n\nSigned-off-by: JP Kobryn <inwardvessel@gmail.com>\nMessage-ID: <20231204202321.22730-1-inwardvessel@gmail.com>\nFixes: 60ece0833b6c (""net/9p: allocate appropriate reduced message buffers"")\nCc: stable@vger.kernel.org\nReviewed-by: Christian Schoenebeck <linux_oss@crudebyte.com>\nSigned-off-by: Dominique Martinet <asmadeus@codewreck.org>\n', '']",The commit prevents an out of bounds read in the 9p_protocol_dump tracepoint.,"read overrun, tracepoint, 9p_protocol_dump",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
ce3c49da11d77aa7d53cd549d308eb5f7fed8576,ce3c49da11d77aa7d53cd549d308eb5f7fed8576,Alexei Starovoitov,ast@kernel.org,1701741027,Alexei Starovoitov,ast@kernel.org,1701741027,b00bb98c69f23ce4e8e9ca2b06d056c07bef5b12,153de60e8bfb4501e1462a2f74cb787c137b996c e3dd40828534a67931e0dd00fcd35846271fd4e8,"Merge branch 'bpf-fix-the-release-of-inner-map'

Hou Tao says:

====================
bpf: Fix the release of inner map

From: Hou Tao <houtao1@huawei.com>

Hi","

The patchset aims to fix the release of inner map in map array or map
htab. The release of inner map is different with normal map. For normal
map","[' the map is released after the bpf program which uses the map is\ndestroyed', ' because the bpf program tracks the used maps. However bpf\nprogram can not track the used inner map because these inner map may be\nupdated or deleted dynamically', ' and for now the ref-counter of inner map\nis decreased after the inner map is remove from outer map', ' so the inner\nmap may be freed before the bpf program', ' which is accessing the inner\nmap', ' exits and there will be use-after-free problem as demonstrated by\npatch #6.\n\nThe patchset fixes the problem by deferring the release of inner map.\nThe freeing of inner map is deferred according to the sleepable\nattributes of the bpf programs which own the outer map. Patch #1 fixes\nthe warning when running the newly-added selftest under interpreter\nmode. Patch #2 adds more parameters to .map_fd_put_ptr() to prepare for\nthe fix. Patch #3 fixes the incorrect value of need_defer when freeing\nthe fd array. Patch #4 fixes the potential use-after-free problem by\nusing call_rcu_tasks_trace() and call_rcu() to wait for one tasks trace\nRCU GP and one RCU GP unconditionally. Patch #5 optimizes the free of\ninner map by removing the unnecessary RCU GP waiting. Patch #6 adds a\nselftest to demonstrate the potential use-after-free problem. Patch #7\nupdates a selftest to update outer map in syscall bpf program.\n\nPlease see individual patches for more details. And comments are always\nwelcome.\n\nChange Log:\nv5:\n * patch #3: rename fd_array_map_delete_elem_with_deferred_free() to\n             __fd_array_map_delete_elem() (Alexei)\n * patch #5: use atomic64_t instead of atomic_t to prevent potential\n             overflow (Alexei)\n * patch #7: use ptr_to_u64() helper instead of force casting to initialize\n             pointers in bpf_attr (Alexei)\n\nv4: https://lore.kernel.org/bpf/20231130140120.1736235-1-houtao@huaweicloud.com\n  * patch #2: don\'t use ""deferred""', ' use ""need_defer"" uniformly\n  * patch #3: newly-added', "" fix the incorrect value of need_defer during\n              fd array free.\n  * patch #4: doesn't consider the case in which bpf map is not used by\n              any bpf program and only use sleepable_refcnt to remove\n\t      unnecessary tasks trace RCU GP (Alexei)\n  * patch #4: remove memory barriers added due to cautiousness (Alexei)\n\nv3: https://lore.kernel.org/bpf/20231124113033.503338-1-houtao@huaweicloud.com\n  * multiple variable renamings (Martin)\n  * define BPF_MAP_RCU_GP/BPF_MAP_RCU_TT_GP as bit (Martin)\n  * use call_rcu() and its variants instead of synchronize_rcu() (Martin)\n  * remove unnecessary mask in bpf_map_free_deferred() (Martin)\n  * place atomic_or() and the related smp_mb() together (Martin)\n  * add patch #6 to demonstrate that updating outer map in syscall\n    program is dead-lock free (Alexei)\n  * update comments about the memory barrier in bpf_map_fd_put_ptr()\n  * update commit message for patch #3 and #4 to describe more details\n\nv2: https://lore.kernel.org/bpf/20231113123324.3914612-1-houtao@huaweicloud.com\n  * defer the invocation of ops->map_free() instead of bpf_map_put() (Martin)\n  * update selftest to make it being reproducible under JIT mode (Martin)\n  * remove unnecessary preparatory patches\n\nv1: https://lore.kernel.org/bpf/20231107140702.1891778-1-houtao@huaweicloud.com\n====================\n\nLink: https://lore.kernel.org/r/20231204140425.1480317-1-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Fix the release mechanism for inner maps within map arrays and hash tables in eBPF.,"release,inner map,fix",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e3dd40828534a67931e0dd00fcd35846271fd4e8,e3dd40828534a67931e0dd00fcd35846271fd4e8,Hou Tao,houtao1@huawei.com,1701698665,Alexei Starovoitov,ast@kernel.org,1701741027,b00bb98c69f23ce4e8e9ca2b06d056c07bef5b12,1624918be84a8bcc4f592e55635bc4fe4a96460a,"selftests/bpf: Test outer map update operations in syscall program

Syscall program is running with rcu_read_lock_trace being held"," so if
bpf_map_update_elem() or bpf_map_delete_elem() invokes
synchronize_rcu_tasks_trace() when operating on an outer map","[' there will\nbe dead-lock', ' so add a test to guarantee that it is dead-lock free.\n\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20231204140425.1480317-8-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit tests outer map update operations in syscall programs under rcu_read_lock_trace conditions.,"outer map update, syscall program, rcu_read_lock_trace",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1624918be84a8bcc4f592e55635bc4fe4a96460a,1624918be84a8bcc4f592e55635bc4fe4a96460a,Hou Tao,houtao1@huawei.com,1701698664,Alexei Starovoitov,ast@kernel.org,1701741027,8dfffc1a7125853b34753aac9dd5e51931110cfd,af66bfd3c8538ed21cf72af18426fc4a408665cf,"selftests/bpf: Add test cases for inner map

Add test cases to test the race between the destroy of inner map due to
map-in-map update and the access of inner map in bpf program. The
following 4 combinations are added:
(1) array map in map array + bpf program
(2) array map in map array + sleepable bpf program
(3) array map in map htab + bpf program
(4) array map in map htab + sleepable bpf program

Before applying the fixes", when running `./test_prog -a map_in_map`,"[' the\nfollowing error was reported:\n\n  ==================================================================\n  BUG: KASAN: slab-use-after-free in array_map_update_elem+0x48/0x3e0\n  Read of size 4 at addr ffff888114f33824 by task test_progs/1858\n\n  CPU: 1 PID: 1858 Comm: test_progs Tainted: G           O     6.6.0+ #7\n  Hardware name: QEMU Standard PC (i440FX + PIIX', ' 1996) ......\n  Call Trace:\n   <TASK>\n   dump_stack_lvl+0x4a/0x90\n   print_report+0xd2/0x620\n   kasan_report+0xd1/0x110\n   __asan_load4+0x81/0xa0\n   array_map_update_elem+0x48/0x3e0\n   bpf_prog_be94a9f26772f5b7_access_map_in_array+0xe6/0xf6\n   trace_call_bpf+0x1aa/0x580\n   kprobe_perf_func+0xdd/0x430\n   kprobe_dispatcher+0xa0/0xb0\n   kprobe_ftrace_handler+0x18b/0x2e0\n   0xffffffffc02280f7\n  RIP: 0010:__x64_sys_getpgid+0x1/0x30\n  ......\n   </TASK>\n\n  Allocated by task 1857:\n   kasan_save_stack+0x26/0x50\n   kasan_set_track+0x25/0x40\n   kasan_save_alloc_info+0x1e/0x30\n   __kasan_kmalloc+0x98/0xa0\n   __kmalloc_node+0x6a/0x150\n   __bpf_map_area_alloc+0x141/0x170\n   bpf_map_area_alloc+0x10/0x20\n   array_map_alloc+0x11f/0x310\n   map_create+0x28a/0xb40\n   __sys_bpf+0x753/0x37c0\n   __x64_sys_bpf+0x44/0x60\n   do_syscall_64+0x36/0xb0\n   entry_SYSCALL_64_after_hwframe+0x6e/0x76\n\n  Freed by task 11:\n   kasan_save_stack+0x26/0x50\n   kasan_set_track+0x25/0x40\n   kasan_save_free_info+0x2b/0x50\n   __kasan_slab_free+0x113/0x190\n   slab_free_freelist_hook+0xd7/0x1e0\n   __kmem_cache_free+0x170/0x260\n   kfree+0x9b/0x160\n   kvfree+0x2d/0x40\n   bpf_map_area_free+0xe/0x20\n   array_map_free+0x120/0x2c0\n   bpf_map_free_deferred+0xd7/0x1e0\n   process_one_work+0x462/0x990\n   worker_thread+0x370/0x670\n   kthread+0x1b0/0x200\n   ret_from_fork+0x3a/0x70\n   ret_from_fork_asm+0x1b/0x30\n\n  Last potentially related work creation:\n   kasan_save_stack+0x26/0x50\n   __kasan_record_aux_stack+0x94/0xb0\n   kasan_record_aux_stack_noalloc+0xb/0x20\n   __queue_work+0x331/0x950\n   queue_work_on+0x75/0x80\n   bpf_map_put+0xfa/0x160\n   bpf_map_fd_put_ptr+0xe/0x20\n   bpf_fd_array_map_update_elem+0x174/0x1b0\n   bpf_map_update_value+0x2b7/0x4a0\n   __sys_bpf+0x2551/0x37c0\n   __x64_sys_bpf+0x44/0x60\n   do_syscall_64+0x36/0xb0\n   entry_SYSCALL_64_after_hwframe+0x6e/0x76\n\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20231204140425.1480317-7-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add test cases to evaluate race conditions in inner map handling with map-in-map updates in bpf programs.,"test cases, inner map, race",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
af66bfd3c8538ed21cf72af18426fc4a408665cf,af66bfd3c8538ed21cf72af18426fc4a408665cf,Hou Tao,houtao1@huawei.com,1701698663,Alexei Starovoitov,ast@kernel.org,1701741026,3171b12b303ea941f111d3f6769257e44fc08104,876673364161da50eed6b472d746ef88242b2368,"bpf: Optimize the free of inner map

When removing the inner map from the outer map"," the inner map will be
freed after one RCU grace period and one RCU tasks trace grace
period","[' so it is certain that the bpf program', ' which may access the\ninner map', ' has exited before the inner map is freed.\n\nHowever there is no need to wait for one RCU tasks trace grace period if\nthe outer map is only accessed by non-sleepable program. So adding\nsleepable_refcnt in bpf_map and increasing sleepable_refcnt when adding\nthe outer map into env->used_maps for sleepable program. Although the\nmax number of bpf program is INT_MAX - 1', ' the number of bpf programs\nwhich are being loaded may be greater than INT_MAX', ' so using atomic64_t\ninstead of atomic_t for sleepable_refcnt. When removing the inner map\nfrom the outer map', ' using sleepable_refcnt to decide whether or not a\nRCU tasks trace grace period is needed before freeing the inner map.\n\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20231204140425.1480317-6-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit optimizes the deallocation process for inner maps in eBPF by using RCU grace periods.,"optimize, inner map, RCU",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
876673364161da50eed6b472d746ef88242b2368,876673364161da50eed6b472d746ef88242b2368,Hou Tao,houtao1@huawei.com,1701698662,Alexei Starovoitov,ast@kernel.org,1701741026,784f4476fe01dda46f6ee631a95a42f1abff3dd0,79d93b3c6ffd79abcd8e43345980aa1e904879c4,"bpf: Defer the free of inner map when necessary

When updating or deleting an inner map in map array or map htab"," the map
may still be accessed by non-sleepable program or sleepable program.
However bpf_map_fd_put_ptr() decreases the ref-counter of the inner map
directly through bpf_map_put()","[' if the ref-counter is the last one\n(which is true for most cases)', ' the inner map will be freed by\nops->map_free() in a kworker. But for now', "" most .map_free() callbacks\ndon't use synchronize_rcu() or its variants to wait for the elapse of a\nRCU grace period"", ' so after the invocation of ops->map_free completes', '\nthe bpf program which is accessing the inner map may incur\nuse-after-free problem.\n\nFix the free of inner map by invoking bpf_map_free_deferred() after both\none RCU grace period and one tasks trace RCU grace period if the inner\nmap has been removed from the outer map before. The deferment is\naccomplished by using call_rcu() or call_rcu_tasks_trace() when\nreleasing the last ref-counter of bpf map. The newly-added rcu_head\nfield in bpf_map shares the same storage space with work field to\nreduce the size of bpf_map.\n\nFixes: bba1dc0b55ac (""bpf: Remove redundant synchronize_rcu."")\nFixes: 638e4b825d52 (""bpf: Allows per-cpu maps and map-in-map in sleepable programs"")\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20231204140425.1480317-5-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Defer free of inner map to ensure safe access by non-sleepable or sleepable programs.,"defer, free, map",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
79d93b3c6ffd79abcd8e43345980aa1e904879c4,79d93b3c6ffd79abcd8e43345980aa1e904879c4,Hou Tao,houtao1@huawei.com,1701698661,Alexei Starovoitov,ast@kernel.org,1701741026,3410665d3a66d115e32defd5244e6319f93c6d39,20c20bd11a0702ce4dc9300c3da58acf551d9725,"bpf: Set need_defer as false when clearing fd array during map free

Both map deletion operation"," map release and map free operation use
fd_array_map_delete_elem() to remove the element from fd array and
need_defer is always true in fd_array_map_delete_elem(). For the map
deletion operation and map release operation","[' need_defer=true is\nnecessary', ' because the bpf program', ' which accesses the element in fd\narray', ' may still alive. However for map free operation', ' it is certain\nthat the bpf program which owns the fd array has already been exited', ' so\nsetting need_defer as false is appropriate for map free operation.\n\nSo fix it by adding need_defer parameter to bpf_fd_array_map_clear() and\nadding a new helper __fd_array_map_delete_elem() to handle the map\ndeletion', ' map release and map free operations correspondingly.\n\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20231204140425.1480317-4-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Set need_defer as false when clearing fd array during map deletion in eBPF.,"need_defer,fd_array,map_deletion",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF maps,['tc/netfilter like programs']
20c20bd11a0702ce4dc9300c3da58acf551d9725,20c20bd11a0702ce4dc9300c3da58acf551d9725,Hou Tao,houtao1@huawei.com,1701698660,Alexei Starovoitov,ast@kernel.org,1701741026,4ab874508a5b0c40f1f9671eaf6218ac5241fb5f,169410eba271afc9f0fb476d996795aa26770c6d,"bpf: Add map and need_defer parameters to .map_fd_put_ptr()

map is the pointer of outer map"," and need_defer needs some explanation.
need_defer tells the implementation to defer the reference release of
the passed element and ensure that the element is still alive before
the bpf program","[' which may manipulate it', ' exits.\n\nThe following three cases will invoke map_fd_put_ptr() and different\nneed_defer values will be passed to these callers:\n\n1) release the reference of the old element in the map during map update\n   or map deletion. The release must be deferred', ' otherwise the bpf\n   program may incur use-after-free problem', ' so need_defer needs to be\n   true.\n2) release the reference of the to-be-added element in the error path of\n   map update. The to-be-added element is not visible to any bpf\n   program', ' so it is OK to pass false for need_defer parameter.\n3) release the references of all elements in the map during map release.\n   Any bpf program which has access to the map must have been exited and\n   released', ' so need_defer=false will be OK.\n\nThese two parameters will be used by the following patches to fix the\npotential use-after-free problem for map-in-map.\n\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20231204140425.1480317-3-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add map and need_defer parameters to .map_fd_put_ptr() to manage reference release in BPF programs.,"map, need_defer, reference",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
169410eba271afc9f0fb476d996795aa26770c6d,169410eba271afc9f0fb476d996795aa26770c6d,Hou Tao,houtao1@huawei.com,1701698659,Alexei Starovoitov,ast@kernel.org,1701741026,c4849605f0aa32546c38760e4ec09fdf6eb8a4a5,153de60e8bfb4501e1462a2f74cb787c137b996c,"bpf: Check rcu_read_lock_trace_held() before calling bpf map helpers

These three bpf_map_{lookup",update,"['delete}_elem() helpers are also\navailable for sleepable bpf program', ' so add the corresponding lock\nassertion for sleepable bpf program', ' otherwise the following warning\nwill be reported when a sleepable bpf program manipulates bpf map under\ninterpreter mode (aka bpf_jit_enable=0):\n\n  WARNING: CPU: 3 PID: 4985 at kernel/bpf/helpers.c:40 ......\n  CPU: 3 PID: 4985 Comm: test_progs Not tainted 6.6.0+ #2\n  Hardware name: QEMU Standard PC (i440FX + PIIX', ' 1996) ......\n  RIP: 0010:bpf_map_lookup_elem+0x54/0x60\n  ......\n  Call Trace:\n   <TASK>\n   ? __warn+0xa5/0x240\n   ? bpf_map_lookup_elem+0x54/0x60\n   ? report_bug+0x1ba/0x1f0\n   ? handle_bug+0x40/0x80\n   ? exc_invalid_op+0x18/0x50\n   ? asm_exc_invalid_op+0x1b/0x20\n   ? __pfx_bpf_map_lookup_elem+0x10/0x10\n   ? rcu_lockdep_current_cpu_online+0x65/0xb0\n   ? rcu_is_watching+0x23/0x50\n   ? bpf_map_lookup_elem+0x54/0x60\n   ? __pfx_bpf_map_lookup_elem+0x10/0x10\n   ___bpf_prog_run+0x513/0x3b70\n   __bpf_prog_run32+0x9d/0xd0\n   ? __bpf_prog_enter_sleepable_recur+0xad/0x120\n   ? __bpf_prog_enter_sleepable_recur+0x3e/0x120\n   bpf_trampoline_6442580665+0x4d/0x1000\n   __x64_sys_getpgid+0x5/0x30\n   ? do_syscall_64+0x36/0xb0\n   entry_SYSCALL_64_after_hwframe+0x6e/0x76\n   </TASK>\n\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20231204140425.1480317-2-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add checks for RCU read lock before calling BPF map helpers to ensure safety.,"RCU, lock, helper",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
153de60e8bfb4501e1462a2f74cb787c137b996c,153de60e8bfb4501e1462a2f74cb787c137b996c,Colin Ian King,colin.i.king@gmail.com,1701682780,Daniel Borkmann,daniel@iogearbox.net,1701701982,1e09226260771ebff82d41cd6957cd1a3e24b601,5bd90cdc65ef9ef5e13c9ff23620079db5c608a0,"selftests/bpf: Fix spelling mistake ""get_signaure_size"" -> ""get_signature_size""

There is a spelling mistake in an ASSERT_GT message. Fix it.

Signed-off-by: Colin Ian King <colin.i.king@gmail.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20231204093940.2611954-1-colin.i.king@gmail.com
",,Fixed spelling mistake in selftests related to signature size assertion.,"spelling, selftests, bpf",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
5bd90cdc65ef9ef5e13c9ff23620079db5c608a0,5bd90cdc65ef9ef5e13c9ff23620079db5c608a0,Andrei Matei,andreimatei1@gmail.com,1701652368,Daniel Borkmann,daniel@iogearbox.net,1701701847,765b13f5eb37979fd4aa064425af740489731742,90679706d486d3cb202d1b377a230f1f22edaf00,"bpf: Minor logging improvement

One place where we were logging a register was only logging the variable
part"," not also the fixed part.

Signed-off-by: Andrei Matei <andreimatei1@gmail.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20231204011248.2040084-1-andreimatei1@gmail.com
",[''],The commit improves logging by including both variable and fixed parts of a register.,"logging, register, improvement",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
90679706d486d3cb202d1b377a230f1f22edaf00,90679706d486d3cb202d1b377a230f1f22edaf00,Alexei Starovoitov,ast@kernel.org,1701545811,Alexei Starovoitov,ast@kernel.org,1701545811,e236cae5c30d8c1f05346f4eb167109a433a1db6,6685aadcab8f170ae3e4d508989a85c1b8a58dba 81eff2e36481c5cf4a2ac906ae56c3fbd3e6f305,"Merge branch 'bpf-verifier-retval-logic-fixes'

Andrii Nakryiko says:

====================
BPF verifier retval logic fixes

This patch set fixes BPF verifier logic around validating and enforcing return
values for BPF programs that have specific range of expected return values.
Both sync and async callbacks have similar logic and are fixes as well.
A few tests are added that would fail without the fixes in this patch set.

Also", while at it,"[' we update retval checking logic to use smin/smax range\ninstead of tnum', ' avoiding future potential issues if expected range cannot be\nrepresented precisely by tnum (e.g.', ' [0', ' 2] is not representable by tnum and\nis treated as [0', ' 3]).\n\nThere is a little bit of refactoring to unify async callback and program exit\nlogic to avoid duplication of checks as much as possible.\n\nv4->v5:\n  - fix timer_bad_ret test on no-alu32 flavor (CI);\nv3->v4:\n  - add back bpf_func_state rearrangement patch;\n  - simplified patch #4 as suggested (Shung-Hsi);\nv2->v3:\n  - more carefullly switch from umin/umax to smin/smax;\nv1->v2:\n  - drop tnum from retval checks (Eduard);\n  - use smin/smax instead of umin/umax (Alexei).\n====================\n\nLink: https://lore.kernel.org/r/20231202175705.885270-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']","The commit addresses logic fixes for BPF verifier return value validation and enforcement, including tests.","BPF, verifier, fixes",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
81eff2e36481c5cf4a2ac906ae56c3fbd3e6f305,81eff2e36481c5cf4a2ac906ae56c3fbd3e6f305,Andrii Nakryiko,andrii@kernel.org,1701539825,Alexei Starovoitov,ast@kernel.org,1701545811,e236cae5c30d8c1f05346f4eb167109a433a1db6,5c19e1d05e9e71b42d8e779f41959254239709da,"bpf: simplify tnum output if a fully known constant

Emit tnum representation as just a constant if all bits are known.
Use decimal-vs-hex logic to determine exact format of emitted
constant value"," just like it's done for register range values.
For that move tnum_strn() to kernel/bpf/log.c to reuse decimal-vs-hex
determination logic and constants.

Acked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231202175705.885270-12-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Simplify tnum output to emit constants directly if all bits are known.,"tnum,constant,output",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5c19e1d05e9e71b42d8e779f41959254239709da,5c19e1d05e9e71b42d8e779f41959254239709da,Andrii Nakryiko,andrii@kernel.org,1701539824,Alexei Starovoitov,ast@kernel.org,1701545811,c62d07d54307d750de319df7214292eb9c2548d8,e02dea158ddaebe6e725be715e0009923b96ec8e,"selftests/bpf: adjust global_func15 test to validate prog exit precision

Add one more subtest to  global_func15 selftest to validate that
verifier properly marks r0 as precise and avoids erroneous state pruning
of the branch that has return value outside of expected [0"," 1] value.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231202175705.885270-11-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Added a subtest to global_func15 selftest for verifying exit precision in the eBPF verifier.,"selftest, verifier, precision",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e02dea158ddaebe6e725be715e0009923b96ec8e,e02dea158ddaebe6e725be715e0009923b96ec8e,Andrii Nakryiko,andrii@kernel.org,1701539823,Alexei Starovoitov,ast@kernel.org,1701545811,188fa71703b207c98697a36cc1f76984493a22d2,eabe518de533a4291996020977054a7a7b78c7d3,"selftests/bpf: validate async callback return value check correctness

Adjust timer/timer_ret_1 test to validate more carefully verifier logic
of enforcing async callback return value. This test will pass only if
return result is marked precise and read.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231202175705.885270-10-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Improves selftests/bpf by validating correctness of async callback return value checks.,"selftests,bpf,async",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
eabe518de533a4291996020977054a7a7b78c7d3,eabe518de533a4291996020977054a7a7b78c7d3,Andrii Nakryiko,andrii@kernel.org,1701539822,Alexei Starovoitov,ast@kernel.org,1701545811,a07050432051b4354f9e6ad2d932405c036f3d9b,0ef24c8dfae24a4b8aa2e92eac20faecdc5502e5,"bpf: enforce precision of R0 on program/async callback return

Given we enforce a valid range for program and async callback return
value"," we must mark R0 as precise to avoid incorrect state pruning.

Fixes: b5dc0163d8fd (""bpf: precise scalar_value tracking"")
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231202175705.885270-9-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The commit enforces precision of R0 for program and async callback return values to prevent incorrect state pruning.,"precision,R0,return",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0ef24c8dfae24a4b8aa2e92eac20faecdc5502e5,0ef24c8dfae24a4b8aa2e92eac20faecdc5502e5,Andrii Nakryiko,andrii@kernel.org,1701539821,Alexei Starovoitov,ast@kernel.org,1701545810,d5bddc2016d33b132d23ee00f072cc34015c55b0,c871d0e00f0e8c207ce8ff89025e35cc49a8a3c3,"bpf: unify async callback and program retval checks

Use common logic to verify program return values and async callback
return values. This allows to avoid duplication of any extra steps
necessary", like precision marking,"[' which will be added in the next\npatch.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231202175705.885270-8-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit unifies the logic for verifying program return values and async callback return values in bpf.,"async,callback,retval",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c871d0e00f0e8c207ce8ff89025e35cc49a8a3c3,c871d0e00f0e8c207ce8ff89025e35cc49a8a3c3,Andrii Nakryiko,andrii@kernel.org,1701539820,Alexei Starovoitov,ast@kernel.org,1701545810,c76f08bf825c02b74107045d7e012413ed565936,60a6b2c78c62d0a99ccb7ad5edc950f79e56306a,"bpf: enforce precise retval range on program exit

Similarly to subprog/callback logic"," enforce return value of BPF program
using more precise smin/smax range.

We need to adjust a bunch of tests due to a changed format of an error
message.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Acked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231202175705.885270-7-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],"The commit enforces precise return value ranges for BPF program exits, requiring test adjustments.","precise, retval, tests",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
60a6b2c78c62d0a99ccb7ad5edc950f79e56306a,60a6b2c78c62d0a99ccb7ad5edc950f79e56306a,Andrii Nakryiko,andrii@kernel.org,1701539819,Alexei Starovoitov,ast@kernel.org,1701545810,79f713f33847013456174f352d42e936941bfb18,8fa4ecd49b81ccd9d1d87f1c8b2260e218644878,"selftests/bpf: add selftest validating callback result is enforced

BPF verifier expects callback subprogs to return values from specified
range (typically [0"," 1]). This requires that r0 at exit is both precise
(because we rely on specific value range) and is marked as read
(otherwise state comparison will ignore such register as unimportant).

Add a simple test that validates that all these conditions are enforced.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Acked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231202175705.885270-6-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],This commit adds a selftest for validating callback result enforcement in BPF verifier.,"selftest, callback, verifier",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8fa4ecd49b81ccd9d1d87f1c8b2260e218644878,8fa4ecd49b81ccd9d1d87f1c8b2260e218644878,Andrii Nakryiko,andrii@kernel.org,1701539818,Alexei Starovoitov,ast@kernel.org,1701545810,6c677d87b16c5c361795841d024fb1a5f81c9944,0acd03a5bd188b0c501d285d938439618bd855c4,"bpf: enforce exact retval range on subprog/callback exit

Instead of relying on potentially imprecise tnum representation of
expected return value range for callbacks and subprogs"," validate that
smin/smax range satisfy exact expected range of return values.

E.g.","[' if callback would need to return [0', ' 2] range', "" tnum can't\nrepresent this precisely and instead will allow [0"", ' 3] range. By\nchecking smin/smax range', ' we can make sure that subprog/callback indeed\nreturns only valid [0', ' 2] range.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231202175705.885270-5-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit enforces exact return value range verification for subprograms and callbacks in BPF.,"retval,subprog,callbacks",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0acd03a5bd188b0c501d285d938439618bd855c4,0acd03a5bd188b0c501d285d938439618bd855c4,Andrii Nakryiko,andrii@kernel.org,1701539817,Alexei Starovoitov,ast@kernel.org,1701545810,2922aa43c9b81c4f7925db4abf022cd041f1dcc0,5fad52bee30414270104525e3a0266327a6e9d11,"bpf: enforce precision of R0 on callback return

Given verifier checks actual value", r0 has to be precise,"[' so we need to\npropagate precision properly. r0 also has to be marked as read', '\notherwise subsequent state comparisons will ignore such register as\nunimportant and precision won\'t really help here.\n\nFixes: 69c087ba6225 (""bpf: Add bpf_for_each_map_elem() helper"")\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231202175705.885270-4-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Enforces precision checks on the return value of R0 in callbacks within the eBPF verifier.,"precision,R0,verifier",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5fad52bee30414270104525e3a0266327a6e9d11,5fad52bee30414270104525e3a0266327a6e9d11,Andrii Nakryiko,andrii@kernel.org,1701539816,Alexei Starovoitov,ast@kernel.org,1701545810,ba9a79b5a1a6390bfebb5a70aa86af65e7f45df0,45b5623f2d721c25d1a2fdc8c4600fb4b7b61c75,"bpf: provide correct register name for exception callback retval check

bpf_throw() is checking R1"," so let's report R1 in the log.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Acked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231202175705.885270-3-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Fix incorrect register name reported in bpf_throw() exception callback log.,"register, exception, bpf_throw",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
45b5623f2d721c25d1a2fdc8c4600fb4b7b61c75,45b5623f2d721c25d1a2fdc8c4600fb4b7b61c75,Andrii Nakryiko,andrii@kernel.org,1701539815,Alexei Starovoitov,ast@kernel.org,1701545810,f98ea693a0976bed8837a69d895798359b14a2cf,6685aadcab8f170ae3e4d508989a85c1b8a58dba,"bpf: rearrange bpf_func_state fields to save a bit of memory

It's a trivial rearrangement saving 8 bytes. We have 4 bytes of padding
at the end which can be filled with another field without increasing
struct bpf_func_state.

copy_func_state() logic remains correct without any further changes.

BEFORE
======
struct bpf_func_state {
        struct bpf_reg_state       regs[11];             /*     0  1320 */
        /* --- cacheline 20 boundary (1280 bytes) was 40 bytes ago --- */
        int                        callsite;             /*  1320     4 */
        u32                        frameno;              /*  1324     4 */
        u32                        subprogno;            /*  1328     4 */
        u32                        async_entry_cnt;      /*  1332     4 */
        bool                       in_callback_fn;       /*  1336     1 */

        /* XXX 7 bytes hole"," try to pack */

        /* --- cacheline 21 boundary (1344 bytes) --- */
        struct tnum                callback_ret_range;   /*  1344    16 */
        bool                       in_async_callback_fn; /*  1360     1 */
        bool                       in_exception_callback_fn; /*  1361     1 */

        /* XXX 2 bytes hole","[' try to pack */\n\n        int                        acquired_refs;        /*  1364     4 */\n        struct bpf_reference_state * refs;               /*  1368     8 */\n        int                        allocated_stack;      /*  1376     4 */\n\n        /* XXX 4 bytes hole', ' try to pack */\n\n        struct bpf_stack_state *   stack;                /*  1384     8 */\n\n        /* size: 1392', ' cachelines: 22', ' members: 13 */\n        /* sum members: 1379', ' holes: 3', ' sum holes: 13 */\n        /* last cacheline: 48 bytes */\n};\n\nAFTER\n=====\nstruct bpf_func_state {\n        struct bpf_reg_state       regs[11];             /*     0  1320 */\n        /* --- cacheline 20 boundary (1280 bytes) was 40 bytes ago --- */\n        int                        callsite;             /*  1320     4 */\n        u32                        frameno;              /*  1324     4 */\n        u32                        subprogno;            /*  1328     4 */\n        u32                        async_entry_cnt;      /*  1332     4 */\n        struct tnum                callback_ret_range;   /*  1336    16 */\n        /* --- cacheline 21 boundary (1344 bytes) was 8 bytes ago --- */\n        bool                       in_callback_fn;       /*  1352     1 */\n        bool                       in_async_callback_fn; /*  1353     1 */\n        bool                       in_exception_callback_fn; /*  1354     1 */\n\n        /* XXX 1 byte hole', ' try to pack */\n\n        int                        acquired_refs;        /*  1356     4 */\n        struct bpf_reference_state * refs;               /*  1360     8 */\n        struct bpf_stack_state *   stack;                /*  1368     8 */\n        int                        allocated_stack;      /*  1376     4 */\n\n        /* size: 1384', ' cachelines: 22', ' members: 13 */\n        /* sum members: 1379', ' holes: 1', ' sum holes: 1 */\n        /* padding: 4 */\n        /* last cacheline: 40 bytes */\n};\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231202175705.885270-2-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Rearrange fields in struct bpf_func_state to optimize memory usage by eliminating padding.,"rearrange,memory,optimization",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6685aadcab8f170ae3e4d508989a85c1b8a58dba,6685aadcab8f170ae3e4d508989a85c1b8a58dba,Alexei Starovoitov,ast@kernel.org,1701476463,Alexei Starovoitov,ast@kernel.org,1701476463,0d7e27c7ea846503b8b95abaee14a85242a98347,b6a3451e0847d5d70fb5fa2b2a80ab9f80bf2c7b 1030e9154258b54e3c7dc07c39e7b6dcf24bc3d2,"Merge branch 'bpf-file-verification-with-lsm-and-fsverity'

Song Liu says:

====================
bpf: File verification with LSM and fsverity

Changes v14 => v15:
1. Fix selftest build without CONFIG_FS_VERITY. (Alexei)
2. Add Acked-by from KP.

Changes v13 => v14:
1. Add ""static"" for bpf_fs_kfunc_set.
2. Add Acked-by from Christian Brauner.

Changes v12 => v13:
1. Only keep 4/9 through 9/9 of v12"," as the first 3 patches already
   applied;
2. Use new macro __bpf_kfunc_[start|end]_defs().

Changes v11 => v12:
1. Fix typo (data_ptr => sig_ptr) in bpf_get_file_xattr().

Changes v10 => v11:
1. Let __bpf_dynptr_data() return const void *. (Andrii)
2. Optimize code to reuse output from __bpf_dynptr_size(). (Andrii)
3. Add __diag_ignore_all(""-Wmissing-declarations"") for kfunc definition.
4. Fix an off indentation. (Andrii)

Changes v9 => v10:
1. Remove WARN_ON_ONCE() from check_reg_const_str. (Alexei)

Changes v8 => v9:
1. Fix test_progs kfunc_dynptr_param/dynptr_data_null.

Changes v7 => v8:
1. Do not use bpf_dynptr_slice* in the kernel. Add __bpf_dynptr_data* and
   use them in ther kernel. (Andrii)

Changes v6 => v7:
1. Change ""__const_str"" annotation to ""__str"". (Alexei","[' Andrii)\n2. Add KF_TRUSTED_ARGS flag for both new kfuncs. (KP)\n3. Only allow bpf_get_file_xattr() to read xattr with ""user."" prefix.\n4. Add Acked-by from Eric Biggers.\n\nChanges v5 => v6:\n1. Let fsverity_init_bpf() return void. (Eric Biggers)\n2. Sort things in alphabetic orders. (Eric Biggers)\n\nChanges v4 => v5:\n1. Revise commit logs. (Alexei)\n\nChanges v3 => v4:\n1. Fix error reported by CI.\n2. Update comments of bpf_dynptr_slice* that they may return error pointer.\n\nChanges v2 => v3:\n1. Rebase and resolve conflicts.\n\nChanges v1 => v2:\n1. Let bpf_get_file_xattr() use const string for arg ""name"". (Alexei)\n2. Add recursion prevention with allowlist. (Alexei)\n3. Let bpf_get_file_xattr() use __vfs_getxattr() to avoid recursion', '\n   as vfs_getxattr() calls into other LSM hooks.\n4. Do not use dynptr->data directly', ' use helper insteadd. (Andrii)\n5. Fixes with bpf_get_fsverity_digest. (Eric Biggers)\n6. Add documentation. (Eric Biggers)\n7. Fix some compile warnings. (kernel test robot)\n\nThis set enables file verification with BPF LSM and fsverity.\n\nIn this solution', ' fsverity is used to provide reliable and efficient hash\nof files; and BPF LSM is used to implement signature verification (against\nasymmetric keys)', ' and to enforce access control.\n\nThis solution can be used to implement access control in complicated cases.\nFor example: only signed python binary and signed python script and access\nspecial files/devices/ports.\n\nThanks', '\nSong\n====================\n\nLink: https://lore.kernel.org/r/20231129234417.856536-1-song@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']","Integrate file verification using LSM and fsverity in the BPF subsystem, with multiple incremental fixes and optimizations.","file verification, LSM, fsverity",It's a new feature.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1030e9154258b54e3c7dc07c39e7b6dcf24bc3d2,1030e9154258b54e3c7dc07c39e7b6dcf24bc3d2,Song Liu,song@kernel.org,1701301457,Alexei Starovoitov,ast@kernel.org,1701476463,0d7e27c7ea846503b8b95abaee14a85242a98347,341f06fdddf72cd60a10945152f69f0f1d614519,"selftests/bpf: Add test that uses fsverity and xattr to sign a file

This selftests shows a proof of concept method to use BPF LSM to enforce
file signature. This test is added to verify_pkcs7_sig"," so that some
existing logic can be reused.

This file signature method uses fsverity","[' which provides reliable and\nefficient hash (known as digest) of the file. The file digest is signed\nwith asymmetic key', ' and the signature is stored in xattr. At the run time', '\nBPF LSM reads file digest and the signature', ' and then checks them against\nthe public key.\n\nNote that this solution does NOT require FS_VERITY_BUILTIN_SIGNATURES.\nfsverity is only used to provide file digest. The signature verification\nand access control is all implemented in BPF LSM.\n\nSigned-off-by: Song Liu <song@kernel.org>\nLink: https://lore.kernel.org/r/20231129234417.856536-7-song@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add a selftest to demonstrate using BPF LSM for file signature enforcement with fsverity and xattr.,"selftests,BPF LSM,fsverity",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['LSM like programs']
341f06fdddf72cd60a10945152f69f0f1d614519,341f06fdddf72cd60a10945152f69f0f1d614519,Song Liu,song@kernel.org,1701301456,Alexei Starovoitov,ast@kernel.org,1701476463,0b17fcf04dd1fc3dd848eee2d9c2421b310c6587,6b0ae4566aba566a2ab4a2de9c59ab3d7f4b43c2,"selftests/bpf: Add tests for filesystem kfuncs

Add selftests for two new filesystem kfuncs:
  1. bpf_get_file_xattr
  2. bpf_get_fsverity_digest

These tests simply make sure the two kfuncs work. Another selftest will be
added to demonstrate how to use these kfuncs to verify file signature.

CONFIG_FS_VERITY is added to selftests config. However"," this is not
sufficient to guarantee bpf_get_fsverity_digest works. This is because
fsverity need to be enabled at file system level (for example","["" with tune2fs\non ext4). If local file system doesn't have this feature enabled"", ' just skip\nthe test.\n\nSigned-off-by: Song Liu <song@kernel.org>\nLink: https://lore.kernel.org/r/20231129234417.856536-6-song@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add selftests for two new filesystem kfuncs: bpf_get_file_xattr and bpf_get_fsverity_digest.,"selftests,kfuncs,filesystem",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"[""It's not related to any of the above.""]"
6b0ae4566aba566a2ab4a2de9c59ab3d7f4b43c2,6b0ae4566aba566a2ab4a2de9c59ab3d7f4b43c2,Song Liu,song@kernel.org,1701301455,Alexei Starovoitov,ast@kernel.org,1701476463,36d3e8acaa5a6f6a5c69984487ef954e275ed870,0de267d9ec6574536ec5ea2f2242df5c92bcdd4b,"selftests/bpf: Sort config in alphabetic order

Move CONFIG_VSOCKETS up"," so the CONFIGs are in alphabetic order.

Signed-off-by: Song Liu <song@kernel.org>
Link: https://lore.kernel.org/r/20231129234417.856536-5-song@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The commit sorts the selftests/bpf configuration in alphabetical order by moving CONFIG_VSOCKETS up.,"selftests, configuration, alphabetic",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
0de267d9ec6574536ec5ea2f2242df5c92bcdd4b,0de267d9ec6574536ec5ea2f2242df5c92bcdd4b,Song Liu,song@kernel.org,1701301454,Alexei Starovoitov,ast@kernel.org,1701476463,bdc5dd0be0ca62d766798b4f94a92bd6ac1795b9,67814c00de3161181cddd06c77aeaf86ac4cc584,"Documentation/bpf: Add documentation for filesystem kfuncs

Add a brief introduction for file system kfuncs:

  bpf_get_file_xattr()
  bpf_get_fsverity_digest()

The documentation highlights the strategy to avoid recursions of these
kfuncs.

Signed-off-by: Song Liu <song@kernel.org>
Link: https://lore.kernel.org/r/20231129234417.856536-4-song@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,"The commit adds documentation for filesystem kfuncs, specifically bpf_get_file_xattr() and bpf_get_fsverity_digest().","documentation, filesystem, kfuncs",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
67814c00de3161181cddd06c77aeaf86ac4cc584,67814c00de3161181cddd06c77aeaf86ac4cc584,Song Liu,song@kernel.org,1701301453,Alexei Starovoitov,ast@kernel.org,1701476463,ec467b83873691b94b7e4ded55a4abdfa46ef41c,ac9c05e0e453cfcab2866f6d28f257590e4f66e5,bpf," fsverity: Add kfunc bpf_get_fsverity_digest

fsverity provides fast and reliable hash of files","[' namely fsverity_digest.\nThe digest can be used by security solutions to verify file contents.\n\nAdd new kfunc bpf_get_fsverity_digest() so that we can access fsverity from\nBPF LSM programs. This kfunc is added to fs/verity/measure.c because some\ndata structure used in the function is private to fsverity\n(fs/verity/fsverity_private.h).\n\nTo avoid recursion', ' bpf_get_fsverity_digest is only allowed in BPF LSM\nprograms.\n\nSigned-off-by: Song Liu <song@kernel.org>\nAcked-by: Eric Biggers <ebiggers@google.com>\nLink: https://lore.kernel.org/r/20231129234417.856536-3-song@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add kfunc bpf_get_fsverity_digest for fast and reliable file hash in fsverity.,"fsverity,kfunc,hash",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ac9c05e0e453cfcab2866f6d28f257590e4f66e5,ac9c05e0e453cfcab2866f6d28f257590e4f66e5,Song Liu,song@kernel.org,1701301452,Alexei Starovoitov,ast@kernel.org,1701476463,aebe277c80b949f0a40681bdb8244ae7ba2b0a8f,b6a3451e0847d5d70fb5fa2b2a80ab9f80bf2c7b,"bpf: Add kfunc bpf_get_file_xattr

It is common practice for security solutions to store tags/labels in
xattrs. To implement similar functionalities in BPF LSM"," add new kfunc
bpf_get_file_xattr().

The first use case of bpf_get_file_xattr() is to implement file
verifications with asymmetric keys. Specificially","[' security applications\ncould use fsverity for file hashes and use xattr to store file signatures.\n(kfunc for fsverity hash will be added in a separate commit.)\n\nCurrently', ' only xattrs with ""user."" prefix can be read with kfunc\nbpf_get_file_xattr(). As use cases evolve', ' we may add a dedicated prefix\nfor bpf_get_file_xattr().\n\nTo avoid recursion', ' bpf_get_file_xattr can be only called from LSM hooks.\n\nSigned-off-by: Song Liu <song@kernel.org>\nAcked-by: Christian Brauner <brauner@kernel.org>\nAcked-by: KP Singh <kpsingh@kernel.org>\nLink: https://lore.kernel.org/r/20231129234417.856536-2-song@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add new kfunc bpf_get_file_xattr to support file verifications with BPF LSM.,"kfunc,xattr,LSM",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['LSM like programs']
dfce9cb3140592b886838e06f3e0c25fea2a9cae,dfce9cb3140592b886838e06f3e0c25fea2a9cae,Yonghong Song,yonghong.song@linux.dev,1701398800,Andrii Nakryiko,andrii@kernel.org,1701474110,e3e3996806c2f48fb223715059d780f66af89db6,830139e7b6911266a84a77e1f18abf758995cc89,"bpf: Fix a verifier bug due to incorrect branch offset comparison with cpu=v4

Bpf cpu=v4 support is introduced in [1] and Commit 4cd58e9af8b9
(""bpf: Support new 32bit offset jmp instruction"") added support for new
32bit offset jmp instruction. Unfortunately"," in function
bpf_adj_delta_to_off()","[' for new branch insn with 32bit offset', ' the offset\n(plus/minor a small delta) compares to 16-bit offset bound\n[S16_MIN', ' S16_MAX]', "" which caused the following verification failure:\n  $ ./test_progs-cpuv4 -t verif_scale_pyperf180\n  ...\n  insn 10 cannot be patched due to 16-bit range\n  ...\n  libbpf: failed to load object 'pyperf180.bpf.o'\n  scale_test:FAIL:expect_success unexpected error: -12 (errno 12)\n  #405     verif_scale_pyperf180:FAIL\n\nNote that due to recent llvm18 development"", ' the patch [2] (already applied\nin bpf-next) needs to be applied to bpf tree for testing purpose.\n\nThe fix is rather simple. For 32bit offset branch insn', ' the adjusted\noffset compares to [S32_MIN', ' S32_MAX] and then verification succeeded.\n\n  [1] https://lore.kernel.org/all/20230728011143.3710005-1-yonghong.song@linux.dev\n  [2] https://lore.kernel.org/bpf/20231110193644.3130906-1-yonghong.song@linux.dev\n\nFixes: 4cd58e9af8b9 (""bpf: Support new 32bit offset jmp instruction"")\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20231201024640.3417057-1-yonghong.song@linux.dev\n', '']",Fixes a verifier bug related to incorrect branch offset comparison for CPU version v4 in eBPF.,"verifier, bug, offset",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b6a3451e0847d5d70fb5fa2b2a80ab9f80bf2c7b,b6a3451e0847d5d70fb5fa2b2a80ab9f80bf2c7b,Jeroen van Ingen Schenau,jeroen.vaningenschenau@novoserve.com,1701345833,Daniel Borkmann,daniel@iogearbox.net,1701443565,49e0a5f9345088f240b5bff686f8978b4589e8fe,15bc81212f593fbd7bda787598418b931842dc14,"selftests/bpf: Fix erroneous bitmask operation

xdp_synproxy_kern.c is a BPF program that generates SYN cookies on
allowed TCP ports and sends SYNACKs to clients"," accelerating synproxy
iptables module.

Fix the bitmask operation when checking the status of an existing
conntrack entry within tcp_lookup() function. Do not AND with the bit
position number","[' but with the bitmask value to check whether the entry\nfound has the IPS_CONFIRMED flag set.\n\nFixes: fb5cd0ce70d4 (""selftests/bpf: Add selftests for raw syncookie helpers"")\nSigned-off-by: Jeroen van Ingen Schenau <jeroen.vaningenschenau@novoserve.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Minh Le Hoang <minh.lehoang@novoserve.com>\nLink: https://lore.kernel.org/xdp-newbies/CAAi1gX7owA+Tcxq-titC-h-KPM7Ri-6ZhTNMhrnPq5gmYYwKow@mail.gmail.com/T/#u\nLink: https://lore.kernel.org/bpf/20231130120353.3084-1-jeroen.vaningenschenau@novoserve.com\n', '']",This commit fixes an erroneous bitmask operation in the xdp_synproxy_kern BPF program for tracking TCP connections.,"bitmask, synproxy, conntrack",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['xdp like programs', 'socket like programs']"
753c8608f3e579307493a63b9242667aee35a751,753c8608f3e579307493a63b9242667aee35a751,Jakub Kicinski,kuba@kernel.org,1701392169,Jakub Kicinski,kuba@kernel.org,1701392322,4197358069e8db7bc0d36a474612f7ffefc7ba72,975f2d73a99f35b57ffa2ad7bff8562225cdcfcb f690ff9122d2ca8e38769f3bcf217bd3df681a36,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next

Daniel Borkmann says:

====================
pull-request: bpf-next 2023-11-30

We've added 30 non-merge commits during the last 7 day(s) which contain
a total of 58 files changed", 1598 insertions(+),"[' 154 deletions(-).\n\nThe main changes are:\n\n1) Add initial TX metadata implementation for AF_XDP with support in mlx5\n   and stmmac drivers. Two types of offloads are supported right now', ' that\n   is', ' TX timestamp and TX checksum offload', ' from Stanislav Fomichev with\n   stmmac implementation from Song Yoong Siang.\n\n2) Change BPF verifier logic to validate global subprograms lazily instead\n   of unconditionally before the main program', ' so they can be guarded using\n   BPF CO-RE techniques', ' from Andrii Nakryiko.\n\n3) Add BPF link_info support for uprobe multi link along with bpftool\n   integration for the latter', ' from Jiri Olsa.\n\n4) Use pkg-config in BPF selftests to determine ld flags which is\n   in particular needed for linking statically', ' from Akihiko Odaki.\n\n5) Fix a few BPF selftest failures to adapt to the upcoming LLVM18', '\n   from Yonghong Song.\n\n* tag \'for-netdev\' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next: (30 commits)\n  bpf/tests: Remove duplicate JSGT tests\n  selftests/bpf: Add TX side to xdp_hw_metadata\n  selftests/bpf: Convert xdp_hw_metadata to XDP_USE_NEED_WAKEUP\n  selftests/bpf: Add TX side to xdp_metadata\n  selftests/bpf: Add csum helpers\n  selftests/xsk: Support tx_metadata_len\n  xsk: Add option to calculate TX checksum in SW\n  xsk: Validate xsk_tx_metadata flags\n  xsk: Document tx_metadata_len layout\n  net: stmmac: Add Tx HWTS support to XDP ZC\n  net/mlx5e: Implement AF_XDP TX timestamp and checksum offload\n  tools: ynl: Print xsk-features from the sample\n  xsk: Add TX timestamp and TX checksum offload support\n  xsk: Support tx_metadata_len\n  selftests/bpf: Use pkg-config for libelf\n  selftests/bpf: Override PKG_CONFIG for static builds\n  selftests/bpf: Choose pkg-config for the target\n  bpftool: Add support to display uprobe_multi links\n  selftests/bpf: Add link_info test for uprobe_multi link\n  selftests/bpf: Use bpf_link__destroy in fill_link_info tests\n  ...\n====================\n\nConflicts:\n\nDocumentation/netlink/specs/netdev.yaml:\n  839ff60df3ab (""net: page_pool: add nlspec for basic access to page pools"")\n  48eb03dd2630 (""xsk: Add TX timestamp and TX checksum offload support"")\nhttps://lore.kernel.org/all/20231201094705.1ee3cab8@canb.auug.org.au/\n\nWhile at it also regen', ' tree is dirty after:\n  48eb03dd2630 (""xsk: Add TX timestamp and TX checksum offload support"")\nlooks like code wasn\'t re-rendered after ""render-max"" was removed.\n\nLink: https://lore.kernel.org/r/20231130145708.32573-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Merged branch 'for-netdev' containing multiple eBPF related changes into the main tree.,"merge,eBPF,changes",It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6172a5180fcc65170bfa2d49e55427567860f2a7,6172a5180fcc65170bfa2d49e55427567860f2a7,Linus Torvalds,torvalds@linux-foundation.org,1701386686,Linus Torvalds,torvalds@linux-foundation.org,1701386686,54617c32c60bdbd06ab0cde16f8c56d913ef68ba,e8f60209d6cf652a9cfda64371acea69f62770aa 777f245eec8152926b411e3d4f4545310f52cbed,"Merge tag 'net-6.7-rc4' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Paolo Abeni:
 ""Including fixes from bpf and wifi.

  Current release - regressions:

   - neighbour: fix __randomize_layout crash in struct neighbour

   - r8169: fix deadlock on RTL8125 in jumbo mtu mode

  Previous releases - regressions:

   - wifi:
       - mac80211: fix warning at station removal time
       - cfg80211: fix CQM for non-range use

   - tools: ynl-gen: fix unexpected response handling

   - octeontx2-af: fix possible buffer overflow

   - dpaa2: recycle the RX buffer only after all processing done

   - rswitch: fix missing dev_kfree_skb_any() in error path

  Previous releases - always broken:

   - ipv4: fix uaf issue when receiving igmp query packet

   - wifi: mac80211: fix debugfs deadlock at device removal time

   - bpf:
       - sockmap: af_unix stream sockets need to hold ref for pair sock
       - netdevsim: don't accept device bound programs

   - selftests: fix a char signedness issue

   - dsa: mv88e6xxx: fix marvell 6350 probe crash

   - octeontx2-pf: restore TC ingress police rules when interface is up

   - wangxun: fix memory leak on msix entry

   - ravb: keep reverse order of operations in ravb_remove()""

* tag 'net-6.7-rc4' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (51 commits)
  net: ravb: Keep reverse order of operations in ravb_remove()
  net: ravb: Stop DMA in case of failures on ravb_open()
  net: ravb: Start TX queues after HW initialization succeeded
  net: ravb: Make write access to CXR35 first before accessing other EMAC registers
  net: ravb: Use pm_runtime_resume_and_get()
  net: ravb: Check return value of reset_control_deassert()
  net: libwx: fix memory leak on msix entry
  ice: Fix VF Reset paths when interface in a failed over aggregate
  bpf"," sockmap: Add af_unix test with both sockets in map
  bpf","["" sockmap: af_unix stream sockets need to hold ref for pair sock\n  tools: ynl-gen: always construct struct ynl_req_state\n  ethtool: don't propagate EOPNOTSUPP from dumps\n  ravb: Fix races between ravb_tx_timeout_work() and net related ops\n  r8169: prevent potential deadlock in rtl8169_close\n  r8169: fix deadlock on RTL8125 in jumbo mtu mode\n  neighbour: Fix __randomize_layout crash in struct neighbour\n  octeontx2-pf: Restore TC ingress police rules when interface is up\n  octeontx2-pf: Fix adding mbox work queue entry when num_vfs > 64\n  net: stmmac: xgmac: Disable FPE MMC interrupts\n  octeontx2-af: Fix possible buffer overflow\n  ...\n"", '']","Merge networking fixes for various components including bpf, wifi, and others.","networking, fixes, bpf",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).', 'other']"
f9893fdac319bb2817e5e7818870264d7fb2eb02,f9893fdac319bb2817e5e7818870264d7fb2eb02,Eric Dumazet,edumazet@google.com,1701336179,Jakub Kicinski,kuba@kernel.org,1701368098,112a72a1ec47a1d0c1db138d2592001805031538,7e0222686316f5506e51182f02c1d83ecc34c471,"net: page_pool: fix general protection fault in page_pool_unlist

syzbot was able to trigger a crash [1] in page_pool_unlist()

page_pool_list() only inserts a page pool into a netdev page pool list
if a netdev was set in params.

Even if the kzalloc() call in page_pool_create happens to initialize
pool->user.list"," I chose to be more explicit in page_pool_list()
adding one INIT_HLIST_NODE().

We could test in page_pool_unlist() if netdev was set","['\nbut since netdev can be changed to lo', ' it seems more robust to\ncheck if pool->user.list is hashed  before calling hlist_del().\n\n[1]\n\nIllegal XDP return value 4294946546 on prog  (id 2) dev N/A', ' expect packet loss!\ngeneral protection fault', ' probably for non-canonical address 0xdffffc0000000000: 0000 [#1] PREEMPT SMP KASAN\nKASAN: null-ptr-deref in range [0x0000000000000000-0x0000000000000007]\nCPU: 0 PID: 5064 Comm: syz-executor391 Not tainted 6.7.0-rc2-syzkaller-00533-ga379972973a8 #0\nHardware name: Google Google Compute Engine/Google Compute Engine', ' BIOS Google 11/10/2023\nRIP: 0010:__hlist_del include/linux/list.h:988 [inline]\nRIP: 0010:hlist_del include/linux/list.h:1002 [inline]\nRIP: 0010:page_pool_unlist+0xd1/0x170 net/core/page_pool_user.c:342\nCode: df 48 89 fa 48 c1 ea 03 80 3c 02 00 0f 85 90 00 00 00 4c 8b a3 f0 06 00 00 48 b8 00 00 00 00 00 fc ff df 4c 89 e2 48 c1 ea 03 <80> 3c 02 00 75 68 48 85 ed 49 89 2c 24 74 24 e8 1b ca 07 f9 48 8d\nRSP: 0018:ffffc900039ff768 EFLAGS: 00010246\nRAX: dffffc0000000000 RBX: ffff88814ae02000 RCX: 0000000000000000\nRDX: 0000000000000000 RSI: 0000000000000004 RDI: ffff88814ae026f0\nRBP: 0000000000000000 R08: 0000000000000000 R09: fffffbfff1d57fdc\nR10: ffffffff8eabfee3 R11: ffffffff8aa0008b R12: 0000000000000000\nR13: ffff88814ae02000 R14: dffffc0000000000 R15: 0000000000000001\nFS:  000055555717a380(0000) GS:ffff8880b9800000(0000) knlGS:0000000000000000\nCS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\nCR2: 0000000002555398 CR3: 0000000025044000 CR4: 00000000003506f0\nDR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\nDR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400\nCall Trace:\n <TASK>\n __page_pool_destroy net/core/page_pool.c:851 [inline]\n page_pool_release+0x507/0x6b0 net/core/page_pool.c:891\n page_pool_destroy+0x1ac/0x4c0 net/core/page_pool.c:956\n xdp_test_run_teardown net/bpf/test_run.c:216 [inline]\n bpf_test_run_xdp_live+0x1578/0x1af0 net/bpf/test_run.c:388\n bpf_prog_test_run_xdp+0x827/0x1530 net/bpf/test_run.c:1254\n bpf_prog_test_run kernel/bpf/syscall.c:4041 [inline]\n __sys_bpf+0x11bf/0x4920 kernel/bpf/syscall.c:5402\n __do_sys_bpf kernel/bpf/syscall.c:5488 [inline]\n __se_sys_bpf kernel/bpf/syscall.c:5486 [inline]\n __x64_sys_bpf+0x78/0xc0 kernel/bpf/syscall.c:5486\n\nFixes: 083772c9f972 (""net: page_pool: record pools per netdev"")\nReported-and-tested-by: syzbot+f9f8efb58a4db2ca98d0@syzkaller.appspotmail.com\nSigned-off-by: Eric Dumazet <edumazet@google.com>\nTested-by: Andrew Lunn <andrew@lunn.ch>\nLink: https://lore.kernel.org/r/20231130092259.3797753-1-edumazet@google.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Fix protection fault issue in page_pool_unlist caused by missing netdev initialization.,"net, page_pool, fix",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['tc/netfilter like programs']
f690ff9122d2ca8e38769f3bcf217bd3df681a36,f690ff9122d2ca8e38769f3bcf217bd3df681a36,Yujie Liu,yujie.liu@intel.com,1701315618,Daniel Borkmann,daniel@iogearbox.net,1701343053,50e26a16ffd821ff4715c363f22e9e230a4da3c7,b5145153a7f33e33f729ee67a11a8901a5609064,"bpf/tests: Remove duplicate JSGT tests

It seems unnecessary that JSGT is tested twice (one before JSGE and one
after JSGE) since others are tested only once. Remove the duplicate JSGT
tests.

Fixes: 0bbaa02b4816 (""bpf/tests: Add tests to check source register zero-extension"")
Signed-off-by: Yujie Liu <yujie.liu@intel.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Johan Almbladh <johan.almbladh@anyfinetworks.com>
Link: https://lore.kernel.org/bpf/20231130034018.2144963-1-yujie.liu@intel.com
",,The commit removes duplicate JSGT tests in the BPF test suite to avoid redundancy.,"JSGT,tests,duplicate",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0d47fa5cc91b9c8a0c90833bf1705048b2295714,0d47fa5cc91b9c8a0c90833bf1705048b2295714,Jakub Kicinski,kuba@kernel.org,1701315604,Jakub Kicinski,kuba@kernel.org,1701315604,d90f72f17b5c75dbdd67c344859984c8b8a1ec34,83f2df9d66bc9e1e0dbd5d5586a701088f6a1d42 51354f700d400e55b329361e1386b04695e6e5c1,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Daniel Borkmann says:

====================
pull-request: bpf 2023-11-30

We've added 5 non-merge commits during the last 7 day(s) which contain
a total of 10 files changed", 66 insertions(+),"[' 15 deletions(-).\n\nThe main changes are:\n\n1) Fix AF_UNIX splat from use after free in BPF sockmap', '\n   from John Fastabend.\n\n2) Fix a syzkaller splat in netdevsim by properly handling offloaded\n   programs (and not device-bound ones)', ' from Stanislav Fomichev.\n\n3) Fix bpf_mem_cache_alloc_flags() to initialize the allocation hint', '\n   from Hou Tao.\n\n4) Fix netkit by rejecting IFLA_NETKIT_PEER_INFO in changelink', ""\n   from Daniel Borkmann.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  bpf"", ' sockmap: Add af_unix test with both sockets in map\n  bpf', "" sockmap: af_unix stream sockets need to hold ref for pair sock\n  netkit: Reject IFLA_NETKIT_PEER_INFO in netkit_change_link\n  bpf: Add missed allocation hint for bpf_mem_cache_alloc_flags()\n  netdevsim: Don't accept device bound programs\n====================\n\nLink: https://lore.kernel.org/r/20231129234916.16128-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n"", '']",Merge a series of bpf updates from the last 7 days with changes to 10 files.,"merge, updates, bpf",It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
51354f700d400e55b329361e1386b04695e6e5c1,51354f700d400e55b329361e1386b04695e6e5c1,John Fastabend,john.fastabend@gmail.com,1701221157,Daniel Borkmann,daniel@iogearbox.net,1701300325,608c6dca192498fb00374a535ad1083b0efa2ca1,8866730aed5100f06d3d965c22f1c61f74942541,bpf," sockmap: Add af_unix test with both sockets in map

This adds a test where both pairs of a af_unix paired socket are put into a
BPF map. This ensures that when we tear down the af_unix pair we don't have
any issues on sockmap side with ordering and reference counting.

Signed-off-by: John Fastabend <john.fastabend@gmail.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Reviewed-by: Jakub Sitnicki <jakub@cloudflare.com>
Link: https://lore.kernel.org/bpf/20231129012557.95371-3-john.fastabend@gmail.com
",[''],Add a test for af_unix socket pairs in a BPF map to ensure no ordering or reference counting issues.,"af_unix,bpf map,sockmap",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
8866730aed5100f06d3d965c22f1c61f74942541,8866730aed5100f06d3d965c22f1c61f74942541,John Fastabend,john.fastabend@gmail.com,1701221156,Daniel Borkmann,daniel@iogearbox.net,1701300316,66fd1fbd894a628549f2c42e841f43b89e4bce1e,0bad281d0ecdf8391b0f42678b663336e7c3ceb0,bpf," sockmap: af_unix stream sockets need to hold ref for pair sock

AF_UNIX stream sockets are a paired socket. So sending on one of the pairs
will lookup the paired socket as part of the send operation. It is possible
however to put just one of the pairs in a BPF map. This currently increments
the refcnt on the sock in the sockmap to ensure it is not free'd by the
stack before sockmap cleans up its state and stops any skbs being sent/recv'd
to that socket.

But we missed a case. If the peer socket is closed it will be free'd by the
stack. However","["" the paired socket can still be referenced from BPF sockmap\nside because we hold a reference there. Then if we are sending traffic through\nBPF sockmap to that socket it will try to dereference the free'd pair in its\nsend logic creating a use after free. And following splat:\n\n   [59.900375] BUG: KASAN: slab-use-after-free in sk_wake_async+0x31/0x1b0\n   [59.901211] Read of size 8 at addr ffff88811acbf060 by task kworker/1:2/954\n   [...]\n   [59.905468] Call Trace:\n   [59.905787]  <TASK>\n   [59.906066]  dump_stack_lvl+0x130/0x1d0\n   [59.908877]  print_report+0x16f/0x740\n   [59.910629]  kasan_report+0x118/0x160\n   [59.912576]  sk_wake_async+0x31/0x1b0\n   [59.913554]  sock_def_readable+0x156/0x2a0\n   [59.914060]  unix_stream_sendmsg+0x3f9/0x12a0\n   [59.916398]  sock_sendmsg+0x20e/0x250\n   [59.916854]  skb_send_sock+0x236/0xac0\n   [59.920527]  sk_psock_backlog+0x287/0xaa0\n\nTo fix let BPF sockmap hold a refcnt on both the socket in the sockmap and its\npaired socket. It wasn't obvious how to contain the fix to bpf_unix logic. The\nprimarily problem with keeping this logic in bpf_unix was: In the sock close()\nwe could handle the deref by having a close handler. But"", ' when we are destroying\nthe psock through a map delete operation we wouldn\'t have gotten any signal\nthorugh the proto struct other than it being replaced. If we do the deref from\nthe proto replace its too early because we need to deref the sk_pair after the\nbacklog worker has been stopped.\n\nGiven all this it seems best to just cache it at the end of the psock and eat 8B\nfor the af_unix and vsock users. Notice dgram sockets are OK because they handle\nlocking already.\n\nFixes: 94531cfcbe79 (""af_unix: Add unix_stream_proto for sockmap"")\nSigned-off-by: John Fastabend <john.fastabend@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Jakub Sitnicki <jakub@cloudflare.com>\nLink: https://lore.kernel.org/bpf/20231129012557.95371-2-john.fastabend@gmail.com\n', '']",Fix issue with AF_UNIX stream sockets in sockmap by handling peer socket closure.,"AF_UNIX, sockmap, refcnt",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,['socket like programs']
b5145153a7f33e33f729ee67a11a8901a5609064,b5145153a7f33e33f729ee67a11a8901a5609064,Alexei Starovoitov,ast@kernel.org,1701298781,Alexei Starovoitov,ast@kernel.org,1701298781,a20ef3fd347f9419cbf9006016b3b3bf7358381c,40d0eb0259ae77ace3e81d7454d1068c38bc95c2 60523115c1b10c8855492d84c1ba88af452e221c,"Merge branch 'xsk-tx-metadata'

Stanislav Fomichev says:

====================
xsk: TX metadata

This series implements initial TX metadata (offloads) for AF_XDP.
See patch #2 for the main implementation and mlx5/stmmac ones for the
example on how to consume the metadata on the device side.

Starting with two types of offloads:
- request TX timestamp (and write it back into the metadata area)
- request TX checksum offload

Changes since v5:
- preserve xsk_tx_metadata flags across tx and completion by moving
  them out of 'request' union (Jesper)
- fix xdp_metadata checksum failure in big endian (Alexei)
- add SPDX to xdp-rx-metadata.rst (Simon)

v5: https://lore.kernel.org/bpf/20231102225837.1141915-1-sdf@google.com/

Performance (mlx5):

I've implemented a small xskgen tool to try to saturate single tx queue:
https://github.com/fomichev/xskgen/tree/master

Here are the performance numbers with some analysis.

1. Baseline. Running with commit eb62e6aef940 (""Merge branch 'bpf:
Support bpf_get_func_ip helper in uprobes'"")"," nothing from this series:

- with 1400 bytes of payload: 98 gbps","[' 8 mpps\n./xskgen -s 1400 -b eth3 10:70:fd:48:10:77 10:70:fd:48:10:87 fe80::1270:fdff:fe48:1077 fe80::1270:fdff:fe48:1087 1 1\nsent 10000000 packets 116960000000 bits', ' took 1.189130 sec', ' 98.357623 gbps 8.409509 mpps\n\n- with 200 bytes of payload: 49 gbps', ' 23 mpps\n./xskgen -s 200 -b eth3 10:70:fd:48:10:77 10:70:fd:48:10:87 fe80::1270:fdff:fe48:1077 fe80::1270:fdff:fe48:1087 1 1\nsent 10000064 packets 20960134144 bits', ' took 0.422235 sec', ' 49.640921 gbps 23.683645 mpps\n\n2. Adding single commit that supports reserving tx_metadata_len\n   changes nothing numbers-wise.\n\n- baseline for 1400\n./xskgen -s 1400 -b eth3 10:70:fd:48:10:77 10:70:fd:48:10:87 fe80::1270:fdff:fe48:1077 fe80::1270:fdff:fe48:1087 1 1\nsent 10000000 packets 116960000000 bits', ' took 1.189247 sec', ' 98.347946 gbps 8.408682 mpps\n\n- baseline for 200\n./xskgen -s 200 -b eth3 10:70:fd:48:10:77 10:70:fd:48:10:87 fe80::1270:fdff:fe48:1077 fe80::1270:fdff:fe48:1087 1 1\nsent 10000000 packets 20960000000 bits', ' took 0.421248 sec', ' 49.756913 gbps 23.738985 mpps\n\n3. Adding -M flag causes xskgen to reserve the metadata and fill it', "" but\n   doesn't set XDP_TX_METADATA descriptor option.\n\n- new baseline for 1400 (with only filling the metadata)\n./xskgen -M -s 1400 -b eth3 10:70:fd:48:10:77 10:70:fd:48:10:87 fe80::1270:fdff:fe48:1077 fe80::1270:fdff:fe48:1087 1 1\nsent 10000000 packets 116960000000 bits"", ' took 1.188767 sec', ' 98.387657 gbps 8.412077 mpps\n\n- new baseline for 200 (with only filling the metadata)\n./xskgen -M -s 200 -b eth3 10:70:fd:48:10:77 10:70:fd:48:10:87 fe80::1270:fdff:fe48:1077 fe80::1270:fdff:fe48:1087 1 1\nsent 10000000 packets 20960000000 bits', ' took 0.410213 sec', ' 51.095407 gbps 24.377579 mpps\n(the numbers go sligtly up here', ' not really sure why', ' maybe some cache-related\nside-effects?\n\n4. Next', ' I\'m running the same test but with the commit that adds actual\n   general infra to parse XDP_TX_METADATA (but no driver support).\n   Essentially applying ""xsk: add TX timestamp and TX checksum offload support""\n   from this series. Numbers are the same.\n\n- fill metadata for 1400\n./xskgen -M -s 1400 -b eth3 10:70:fd:48:10:77 10:70:fd:48:10:87 fe80::1270:fdff:fe48:1077 fe80::1270:fdff:fe48:1087 1 1\nsent 10000000 packets 116960000000 bits', ' took 1.188430 sec', ' 98.415557 gbps 8.414463 mpps\n\n- fill metadata for 200\n./xskgen -M -s 200 -b eth3 10:70:fd:48:10:77 10:70:fd:48:10:87 fe80::1270:fdff:fe48:1077 fe80::1270:fdff:fe48:1087 1 1\nsent 10000000 packets 20960000000 bits', ' took 0.411559 sec', ' 50.928299 gbps 24.297853 mpps\n\n- request metadata for 1400\n./xskgen -m -s 1400 -b eth3 10:70:fd:48:10:77 10:70:fd:48:10:87 fe80::1270:fdff:fe48:1077 fe80::1270:fdff:fe48:1087 1 1\nsent 10000000 packets 116960000000 bits', ' took 1.188723 sec', ' 98.391299 gbps 8.412389 mpps\n\n- request metadata for 200\n./xskgen -m -s 200 -b eth3 10:70:fd:48:10:77 10:70:fd:48:10:87 fe80::1270:fdff:fe48:1077 fe80::1270:fdff:fe48:1087 1 1\nsent 10000064 packets 20960134144 bits', ' took 0.411240 sec', ' 50.968131 gbps 24.316856 mpps\n\n5. Now', ' for the most interesting part', "" I'm adding mlx5 driver support.\n   The mpps for 200 bytes case goes down from 23 mpps to 19 mpps"", ' but\n   _only_ when I enable the metadata. This looks like a side effect\n   of me pushing extra metadata pointer via mlx5e_xdpi_fifo_push.\n   Hence', "" this part is wrapped into 'if (xp_tx_metadata_enabled)'\n   to not affect the existing non-metadata use-cases. Since this is not\n   regressing existing workloads"", "" I'm not spending any time trying to\n   optimize it more (and leaving it up to mlx owners to purse if\n   they see any good way to do it).\n\n- same baseline\n./xskgen -s 1400 -b eth3 10:70:fd:48:10:77 10:70:fd:48:10:87 fe80::1270:fdff:fe48:1077 fe80::1270:fdff:fe48:1087 1 1\nsent 10000000 packets 116960000000 bits"", ' took 1.189434 sec', ' 98.332484 gbps 8.407360 mpps\n\n./xskgen -s 200 -b eth3 10:70:fd:48:10:77 10:70:fd:48:10:87 fe80::1270:fdff:fe48:1077 fe80::1270:fdff:fe48:1087 1 1\nsent 10000128 packets 20960268288 bits', ' took 0.425254 sec', ' 49.288821 gbps 23.515659 mpps\n\n- fill metadata for 1400\n./xskgen -M -s 1400 -b eth3 10:70:fd:48:10:77 10:70:fd:48:10:87 fe80::1270:fdff:fe48:1077 fe80::1270:fdff:fe48:1087 1 1\nsent 10000000 packets 116960000000 bits', ' took 1.189528 sec', ' 98.324714 gbps 8.406696 mpps\n\n- fill metadata for 200\n./xskgen -M -s 200 -b eth3 10:70:fd:48:10:77 10:70:fd:48:10:87 fe80::1270:fdff:fe48:1077 fe80::1270:fdff:fe48:1087 1 1\nsent 10000128 packets 20960268288 bits', ' took 0.519085 sec', ' 40.379260 gbps 19.264914 mpps\n\n- request metadata for 1400\n./xskgen -m -s 1400 -b eth3 10:70:fd:48:10:77 10:70:fd:48:10:87 fe80::1270:fdff:fe48:1077 fe80::1270:fdff:fe48:1087 1 1\nsent 10000000 packets 116960000000 bits', ' took 1.189329 sec', ' 98.341165 gbps 8.408102 mpps\n\n- request metadata for 200\n./xskgen -m -s 200 -b eth3 10:70:fd:48:10:77 10:70:fd:48:10:87 fe80::1270:fdff:fe48:1077 fe80::1270:fdff:fe48:1087 1 1\nsent 10000128 packets 20960268288 bits', ' took 0.519929 sec', ' 40.313713 gbps 19.233642 mpps\n\nAcked-by: Magnus Karlsson <magnus.karlsson@intel.com>\nAcked-by: Jakub Kicinski <kuba@kernel.org>\n====================\n\nLink: https://lore.kernel.org/r/20231127190319.1190813-1-sdf@google.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Implements initial TX metadata offloads for AF_XDP including TX timestamp and checksum offloads.,"TX metadata, offloads, AF_XDP",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['xdp like programs']
60523115c1b10c8855492d84c1ba88af452e221c,60523115c1b10c8855492d84c1ba88af452e221c,Stanislav Fomichev,sdf@google.com,1701111799,Alexei Starovoitov,ast@kernel.org,1701298781,a20ef3fd347f9419cbf9006016b3b3bf7358381c,12b4b7963d3cca253db3c31aa7611b988699e30f,"selftests/bpf: Add TX side to xdp_hw_metadata

When we get a packet on port 9091"," we swap src/dst and send it out.
At this point we also request the timestamp and checksum offloads.

Checksum offload is verified by looking at the tcpdump on the other side.
The tool prints pseudo-header csum and the final one it expects.
The final checksum actually matches the incoming packets checksum
because we only flip the src/dst and don't change the payload.

Some other related changes:
- switched to zerocopy mode by default; new flag can be used to force
  old behavior
- request fixed tx_metadata_len headroom
- some other small fixes (umem size","[' fill idx+i', ' etc)\n\nmvbz3:~# ./xdp_hw_metadata eth3\n...\nxsk_ring_cons__peek: 1\n0x19546f8: rx_desc[0]->addr=80100 addr=80100 comp_addr=80100\nrx_hash: 0x80B7EA8B with RSS type:0x2A\nrx_timestamp:  1697580171852147395 (sec:1697580171.8521)\nHW RX-time:   1697580171852147395 (sec:1697580171.8521)', ' delta to User RX-time sec:0.2797 (279673.082 usec)\nXDP RX-time:   1697580172131699047 (sec:1697580172.1317)', ' delta to User RX-time sec:0.0001 (121.430 usec)\n0x19546f8: ping-pong with csum=3b8e (want d862) csum_start=54 csum_offset=6\n0x19546f8: complete tx idx=0 addr=8\ntx_timestamp:  1697580172056756493 (sec:1697580172.0568)\nHW TX-complete-time:   1697580172056756493 (sec:1697580172.0568)', ' delta to User TX-complete-time sec:0.0852 (85175.537 usec)\nXDP RX-time:   1697580172131699047 (sec:1697580172.1317)', ' delta to User TX-complete-time sec:0.0102 (10232.983 usec)\nHW RX-time:   1697580171852147395 (sec:1697580171.8521)', ' delta to HW TX-complete-time sec:0.2046 (204609.098 usec)\n0x19546f8: complete rx idx=128 addr=80100\n\nmvbz4:~# nc  -Nu -q1 ${MVBZ3_LINK_LOCAL_IP}%eth3 9091\n\nmvbz4:~# tcpdump -vvx -i eth3 udp\n        tcpdump: listening on eth3', ' link-type EN10MB (Ethernet)', ' snapshot length 262144 bytes\n12:26:09.301074 IP6 (flowlabel 0x35fa5', ' hlim 127', ' next-header UDP (17) payload length: 11) fe80::1270:fdff:fe48:1087.55807 > fe80::1270:fdff:fe48:1077.9091: [bad udp cksum 0x3b8e -> 0xde7e!] UDP', ' length 3\n        0x0000:  6003 5fa5 000b 117f fe80 0000 0000 0000\n        0x0010:  1270 fdff fe48 1087 fe80 0000 0000 0000\n        0x0020:  1270 fdff fe48 1077 d9ff 2383 000b 3b8e\n        0x0030:  7864 70\n12:26:09.301976 IP6 (flowlabel 0x35fa5', ' hlim 127', ' next-header UDP (17) payload length: 11) fe80::1270:fdff:fe48:1077.9091 > fe80::1270:fdff:fe48:1087.55807: [udp sum ok] UDP', ' length 3\n        0x0000:  6003 5fa5 000b 117f fe80 0000 0000 0000\n        0x0010:  1270 fdff fe48 1077 fe80 0000 0000 0000\n        0x0020:  1270 fdff fe48 1087 2383 d9ff 000b de7e\n        0x0030:  7864 70\n\nSigned-off-by: Stanislav Fomichev <sdf@google.com>\nLink: https://lore.kernel.org/r/20231127190319.1190813-14-sdf@google.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']","This commit adds TX functionality to xdp_hw_metadata selftests, including swapping src/dst and verifying checksum offloads.","xdp_hw_metadata,checksum,zerocopy",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['xdp like programs']
12b4b7963d3cca253db3c31aa7611b988699e30f,12b4b7963d3cca253db3c31aa7611b988699e30f,Stanislav Fomichev,sdf@google.com,1701111798,Alexei Starovoitov,ast@kernel.org,1701298781,aea3b91f9f7e44a5a5a0ee22f40e3a4fe0bf162f,40808a237d9c8fcaa3eaeefe2ac59e4733907478,"selftests/bpf: Convert xdp_hw_metadata to XDP_USE_NEED_WAKEUP

This is the recommended way to run AF_XDP"," so let's use it in the test.

Also","[' some unrelated changes to now blow up the log too much:\n- change default mode to zerocopy and add -c to use copy mode\n- small fixes for the flags/sizes/prints\n- add print_tstamp_delta to print timestamp + reference\n\nSigned-off-by: Stanislav Fomichev <sdf@google.com>\nLink: https://lore.kernel.org/r/20231127190319.1190813-13-sdf@google.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Convert selftests of xdp_hw_metadata to use XDP_USE_NEED_WAKEUP for AF_XDP.,"selftests, xdp_hw_metadata, XDP_USE_NEED_WAKEUP",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['xdp like programs']
40808a237d9c8fcaa3eaeefe2ac59e4733907478,40808a237d9c8fcaa3eaeefe2ac59e4733907478,Stanislav Fomichev,sdf@google.com,1701111797,Alexei Starovoitov,ast@kernel.org,1701298781,0630bec77c29dfa97741ff59a7e8d067777865ba,f6642de0c3e94d3ef6f44e127d11fcf4138873f7,"selftests/bpf: Add TX side to xdp_metadata

Request TX timestamp and make sure it's not empty.
Request TX checksum offload (SW-only) and make sure it's resolved
to the correct one.

Signed-off-by: Stanislav Fomichev <sdf@google.com>
Link: https://lore.kernel.org/r/20231127190319.1190813-12-sdf@google.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add transmission side handling to xdp_metadata selftests and verify TX timestamp and checksum offload.,"xdp_metadata, TX timestamp, checksum offload",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['xdp like programs']
f6642de0c3e94d3ef6f44e127d11fcf4138873f7,f6642de0c3e94d3ef6f44e127d11fcf4138873f7,Stanislav Fomichev,sdf@google.com,1701111796,Alexei Starovoitov,ast@kernel.org,1701298781,ed3f7280ac39e5502e48c08bbfff99e16467e896,df3ed0003ec4994ce8ed4818c435c481281df89e,"selftests/bpf: Add csum helpers

Checksum helpers will be used to calculate pseudo-header checksum in
AF_XDP metadata selftests.

The helpers are mirroring existing kernel ones:
- csum_tcpudp_magic : IPv4 pseudo header csum
- csum_ipv6_magic : IPv6 pseudo header csum
- csum_fold : fold csum and do one's complement

Signed-off-by: Stanislav Fomichev <sdf@google.com>
Link: https://lore.kernel.org/r/20231127190319.1190813-11-sdf@google.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add checksum helpers for AF_XDP metadata selftests in BPF.,"checksum, helpers, AF_XDP",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,['socket like programs']
1347b419318d6afa1c86d7865d82ca0a6cdf30ce,1347b419318d6afa1c86d7865d82ca0a6cdf30ce,Song Yoong Siang,yoong.siang.song@intel.com,1701111791,Alexei Starovoitov,ast@kernel.org,1701298780,bde2e77272746023942585a6e19a6b8975e99db0,ec706a860eba99bf934d59f74b5db90af44e882e,"net: stmmac: Add Tx HWTS support to XDP ZC

This patch enables transmit hardware timestamp support to XDP zero copy
via XDP Tx metadata framework.

This patchset is tested with tools/testing/selftests/bpf/xdp_hw_metadata
on Intel Tiger Lake platform. Below are the test steps and results.

Command on DUT:
sudo ./xdp_hw_metadata <interface name>
sudo hwstamp_ctl -i <interface name> -t 1 -r 1

Command on Link Partner:
echo -n xdp | nc -u -q1 <destination IPv4 addr> 9091

Result:
xsk_ring_cons__peek: 1
0x55bbbf08b6d0: rx_desc[2]->addr=8c100 addr=8c100 comp_addr=8c100 EoP
No rx_hash err=-95
rx_timestamp:  1677762688429141540 (sec:1677762688.4291)
HW RX-time:   1677762688429141540 (sec:1677762688.4291) delta to User RX-time sec:0.0003 (250.665 usec)
XDP RX-time:   1677762688429375597 (sec:1677762688.4294) delta to User RX-time sec:0.0000 (16.608 usec)
0x55bbbf08b6d0: ping-pong with csum=561c (want f488) csum_start=34 csum_offset=6
0x55bbbf08b6d0: complete tx idx=2 addr=2008
tx_timestamp:  1677762688431127273 (sec:1677762688.4311)
HW TX-complete-time:   1677762688431127273 (sec:1677762688.4311) delta to User TX-complete-time sec:0.0083 (8331.655 usec)
XDP RX-time:   1677762688429375597 (sec:1677762688.4294) delta to User TX-complete-time sec:0.0101 (10083.331 usec)
HW RX-time:   1677762688429141540 (sec:1677762688.4291) delta to HW TX-complete-time sec:0.0020 (1985.733 usec)
0x55bbbf08b6d0: complete rx idx=130 addr=8c100

Signed-off-by: Song Yoong Siang <yoong.siang.song@intel.com>
Signed-off-by: Stanislav Fomichev <sdf@google.com>
Link: https://lore.kernel.org/r/20231127190319.1190813-6-sdf@google.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit adds transmit hardware timestamp support to XDP zero copy in the stmmac driver.,"XDP,timestamp,stmmac",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,['xdp like programs']
40d0eb0259ae77ace3e81d7454d1068c38bc95c2,40d0eb0259ae77ace3e81d7454d1068c38bc95c2,Andrii Nakryiko,andrii@kernel.org,1701238529,Andrii Nakryiko,andrii@kernel.org,1701238530,0ce3896096bf17db577b084f544e8aa5b69335f1,d4e7dd4842b190e87a5b7179a460f54b13da3ac4 8998a479fd96b0b209dcb2feb468eba7eddb4ddb,"Merge branch 'selftests-bpf-use-pkg-config-to-determine-ld-flags'

Akihiko Odaki says:

====================
selftests/bpf: Use pkg-config to determine ld flags

When linking statically"," libraries may require other dependencies to be
included to ld flags. In particular","[' libelf may require libzstd. Use\npkg-config to determine such dependencies.\n\nV4 -> V5: Introduced variables LIBELF_CFLAGS and LIBELF_LIBS.\n          (Daniel Borkmann)\n          Added patch ""selftests/bpf: Choose pkg-config for the target"".\nV3 -> V4: Added ""2> /dev/null"".\nV2 -> V3: Added missing ""echo"".\nV1 -> V2: Implemented fallback', ' referring to HOSTPKG_CONFIG.\n====================\n\nLink: https://lore.kernel.org/r/20231125084253.85025-1-akihiko.odaki@daynix.com\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n', '']",Use pkg-config for determining ld flags in selftests/bpf linking process.,"pkg-config, ld flags, selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"[""It's not related to any of the above.""]"
8998a479fd96b0b209dcb2feb468eba7eddb4ddb,8998a479fd96b0b209dcb2feb468eba7eddb4ddb,Akihiko Odaki,akihiko.odaki@daynix.com,1700901772,Andrii Nakryiko,andrii@kernel.org,1701238529,0ce3896096bf17db577b084f544e8aa5b69335f1,18f6f9de98d1d0f7040e6e6c39fce8939f55520f,"selftests/bpf: Use pkg-config for libelf

When linking statically"," libraries may require other dependencies to be
included to ld flags. In particular","[' libelf may require libzstd. Use\npkg-config to determine such dependencies.\n\nSigned-off-by: Akihiko Odaki <akihiko.odaki@daynix.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20231125084253.85025-4-akihiko.odaki@daynix.com\n', '']",The commit updates selftests/bpf to use pkg-config for obtaining libelf dependencies when linking statically.,"selftests,bpf,libelf",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
18f6f9de98d1d0f7040e6e6c39fce8939f55520f,18f6f9de98d1d0f7040e6e6c39fce8939f55520f,Akihiko Odaki,akihiko.odaki@daynix.com,1700901771,Andrii Nakryiko,andrii@kernel.org,1701238529,fbf3c868350fef8bbf5d167b133d499a9d348fa1,2ce344b6891618063c0bebe22d9cdf9c086e0aa8,"selftests/bpf: Override PKG_CONFIG for static builds

A library may need to depend on additional archive files for static
builds so pkg-config should be instructed to list them.

Signed-off-by: Akihiko Odaki <akihiko.odaki@daynix.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20231125084253.85025-3-akihiko.odaki@daynix.com
",,Override PKG_CONFIG for static builds in selftests for enhanced library dependency handling.,"static, PKG_CONFIG, selftests",It's a build system or CI/CD change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"[""It's not related to any of the above.""]"
2ce344b6891618063c0bebe22d9cdf9c086e0aa8,2ce344b6891618063c0bebe22d9cdf9c086e0aa8,Akihiko Odaki,akihiko.odaki@daynix.com,1700901770,Andrii Nakryiko,andrii@kernel.org,1701238529,044a6da576331c259cbb5941fb66cf451928e2cc,d4e7dd4842b190e87a5b7179a460f54b13da3ac4,"selftests/bpf: Choose pkg-config for the target

pkg-config is used to build sign-file executable. It should use the
library for the target instead of the host as it is called during tests.

Signed-off-by: Akihiko Odaki <akihiko.odaki@daynix.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20231125084253.85025-2-akihiko.odaki@daynix.com
",,The commit updates selftests to use pkg-config for the target during tests instead of the host.,"selftests,pkg-config,target",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
d4e7dd4842b190e87a5b7179a460f54b13da3ac4,d4e7dd4842b190e87a5b7179a460f54b13da3ac4,Andrii Nakryiko,andrii@kernel.org,1701237010,Andrii Nakryiko,andrii@kernel.org,1701237010,d7b96a4e60e1de0d7d151849a505efc0b4c705f2,cf9791631027a476f7cdb0e1b3ac6add16eff264 a7795698f8b6c48283fa4334eb313bc1350b2864,"Merge branch 'bpf-add-link_info-support-for-uprobe-multi-link'

Jiri Olsa says:

====================
bpf: Add link_info support for uprobe multi link

hi","
this patchset adds support to get bpf_link_info details for
uprobe_multi links and adding support for bpftool link to
display them.

v4 changes:
  - move flags field up in bpf_uprobe_multi_link [Andrii]
  - include zero terminating byte in path_size [Andrii]
  - return d_path error directly [Yonghong]
  - use SEC("".probes"") for semaphores [Yonghong]
  - fix ref_ctr_offsets leak in test [Yonghong]
  - other smaller fixes [Yonghong]

thanks","['\njirka\n---\n====================\n\nLink: https://lore.kernel.org/r/20231125193130.834322-1-jolsa@kernel.org\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n', '']",Enhances bpf_link_info with support for uprobe multi-link and updates bpftool link display.,"uprobe, bpf_link_info, bpftool",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
a7795698f8b6c48283fa4334eb313bc1350b2864,a7795698f8b6c48283fa4334eb313bc1350b2864,Jiri Olsa,jolsa@kernel.org,1700940690,Andrii Nakryiko,andrii@kernel.org,1701237009,d7b96a4e60e1de0d7d151849a505efc0b4c705f2,147c69307bcf67f1f01246f9acb794da9837f299,"bpftool: Add support to display uprobe_multi links

Adding support to display details for uprobe_multi links","
both plain:

  # bpftool link -p
  ...
  24: uprobe_multi  prog 126
          uprobe.multi  path /home/jolsa/bpf/test_progs  func_cnt 3  pid 4143
          offset             ref_ctr_offset     cookies
          0xd1f88            0xf5d5a8           0xdead
          0xd1f8f            0xf5d5aa           0xbeef
          0xd1f96            0xf5d5ac           0xcafe

and json:

  # bpftool link -p
  [{
  ...
      }","['{\n          ""id"": 24', '\n          ""type"": ""uprobe_multi""', '\n          ""prog_id"": 126', '\n          ""retprobe"": false', '\n          ""path"": ""/home/jolsa/bpf/test_progs""', '\n          ""func_cnt"": 3', '\n          ""pid"": 4143', '\n          ""funcs"": [{\n                  ""offset"": 860040', '\n                  ""ref_ctr_offset"": 16111016', '\n                  ""cookie"": 57005\n              }', '{\n                  ""offset"": 860047', '\n                  ""ref_ctr_offset"": 16111018', '\n                  ""cookie"": 48879\n              }', '{\n                  ""offset"": 860054', '\n                  ""ref_ctr_offset"": 16111020', '\n                  ""cookie"": 51966\n              }\n          ]\n      }\n  ]\n\nSigned-off-by: Jiri Olsa <jolsa@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nReviewed-by: Quentin Monnet <quentin@isovalent.com>\nAcked-by: Song Liu <song@kernel.org>\nLink: https://lore.kernel.org/bpf/20231125193130.834322-7-jolsa@kernel.org\n', '']",Added support in bpftool to display details for uprobe_multi links.,"bpftool, uprobe_multi, links",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The bpftool utility,['kprobe/uprobe/ftrace like programs']
147c69307bcf67f1f01246f9acb794da9837f299,147c69307bcf67f1f01246f9acb794da9837f299,Jiri Olsa,jolsa@kernel.org,1700940689,Andrii Nakryiko,andrii@kernel.org,1701237009,d0c2e8df90ff8558fb0b081b24ba227d426cf80d,1703612885723869064f18e8816c6f3f87987748,"selftests/bpf: Add link_info test for uprobe_multi link

Adding fill_link_info test for uprobe_multi link.

Setting up uprobes with bogus ref_ctr_offsets and cookie values
to test all the bpf_link_info::uprobe_multi fields.

Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Song Liu <song@kernel.org>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/bpf/20231125193130.834322-6-jolsa@kernel.org
",,Add and test link_info for uprobe_multi link in BPF selftests.,"uprobe_multi, bpf_link_info, selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
1703612885723869064f18e8816c6f3f87987748,1703612885723869064f18e8816c6f3f87987748,Jiri Olsa,jolsa@kernel.org,1700940688,Andrii Nakryiko,andrii@kernel.org,1701237009,8fb956a4f362b70c73e4cd71d5b803bb1a5ec151,e56fdbfb06e26a7066b070967badef4148528df2,"selftests/bpf: Use bpf_link__destroy in fill_link_info tests

The fill_link_info test keeps skeleton open and just creates
various links. We are wrongly calling bpf_link__detach after
each test to close them"," we need to call bpf_link__destroy.

Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Acked-by: Yafang Shao <laoar.shao@gmail.com>
Link: https://lore.kernel.org/bpf/20231125193130.834322-5-jolsa@kernel.org
",[''],The commit updates fill_link_info tests to use bpf_link__destroy instead of bpf_link__detach to properly close links.,"test update, bpf_link__destroy, fill_link_info",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e56fdbfb06e26a7066b070967badef4148528df2,e56fdbfb06e26a7066b070967badef4148528df2,Jiri Olsa,jolsa@kernel.org,1700940687,Andrii Nakryiko,andrii@kernel.org,1701237009,beb6f242eaecc16d3f1db0732fdaae0618df552e,4930b7f53a298533bc31d7540b6ea8b79a000331,"bpf: Add link_info support for uprobe multi link

Adding support to get uprobe_link details through bpf_link_info
interface.

Adding new struct uprobe_multi to struct bpf_link_info to carry
the uprobe_multi link details.

The uprobe_multi.count is passed from user space to denote size
of array fields (offsets/ref_ctr_offsets/cookies). The actual
array size is stored back to uprobe_multi.count (allowing user
to find out the actual array size) and array fields are populated
up to the user passed size.

All the non-array fields (path/count/flags/pid) are always set.

Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/bpf/20231125193130.834322-4-jolsa@kernel.org
",,Added support for uprobe multi link details in bpf_link_info interface.,"uprobe,multi link,bpf_link_info",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
4930b7f53a298533bc31d7540b6ea8b79a000331,4930b7f53a298533bc31d7540b6ea8b79a000331,Jiri Olsa,jolsa@kernel.org,1700940686,Andrii Nakryiko,andrii@kernel.org,1701237009,9356c7fa6715d3c6c50b4d0b403cec9706cb8333,48f0dfd8d3e212ab27b6db147ed10407ff6aaa88,"bpf: Store ref_ctr_offsets values in bpf_uprobe array

We will need to return ref_ctr_offsets values through link_info
interface in following change"," so we need to keep them around.

Storing ref_ctr_offsets values directly into bpf_uprobe array.

Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Song Liu <song@kernel.org>
Link: https://lore.kernel.org/bpf/20231125193130.834322-3-jolsa@kernel.org
",[''],The commit stores ref_ctr_offsets values in the bpf_uprobe array for future link_info interface usage.,"ref_ctr_offsets, bpf_uprobe, link_info",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['kprobe/uprobe/ftrace like programs']
48f0dfd8d3e212ab27b6db147ed10407ff6aaa88,48f0dfd8d3e212ab27b6db147ed10407ff6aaa88,Jiri Olsa,jolsa@kernel.org,1700940685,Andrii Nakryiko,andrii@kernel.org,1701237009,346ef8da903564feb9d80aba778b6a8684ea69cf,cf9791631027a476f7cdb0e1b3ac6add16eff264,"libbpf: Add st_type argument to elf_resolve_syms_offsets function

We need to get offsets for static variables in following changes","
so making elf_resolve_syms_offsets to take st_type value as argument
and passing it to elf_sym_iter_new.

Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Song Liu <song@kernel.org>
Link: https://lore.kernel.org/bpf/20231125193130.834322-2-jolsa@kernel.org
",[''],Add st_type argument to elf_resolve_syms_offsets in libbpf for static variable offsets.,"libbpf, elf_resolve_syms_offsets, st_type",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a79d8ba734bdbd2574ad16dd1b96506e5f642c4a,a79d8ba734bdbd2574ad16dd1b96506e5f642c4a,Pedro Tammela,pctammela@mojatatu.com,1700840564,Jakub Kicinski,kuba@kernel.org,1701137742,1b4bb920a3b6025c6444bcf1b41078be6d3b2b51,cae0de45c8fd62612e1ee429134fd82c2c0e335e,"selftests: tc-testing: remove buildebpf plugin

As tdc only tests loading/deleting and anything more complicated is
better left to the ebpf test suite"," provide a pre-compiled version of
'action.c' and don't bother compiling it in kselftests or on the fly
at all.

Cc: Davide Caratti <dcaratti@redhat.com>
Signed-off-by: Pedro Tammela <pctammela@mojatatu.com>
Acked-by: Jamal Hadi Salim <jhs@mojatatu.com>
Link: https://lore.kernel.org/r/20231124154248.315470-2-pctammela@mojatatu.com
Signed-off-by: Jakub Kicinski <kuba@kernel.org>
",[''],Remove buildebpf plugin from tc-testing as complex tasks are handled by the ebpf test suite.,"buildebpf, tc-testing, selftests",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tc/netfilter like programs']
cf9791631027a476f7cdb0e1b3ac6add16eff264,cf9791631027a476f7cdb0e1b3ac6add16eff264,Stanislav Fomichev,sdf@google.com,1701109257,Martin KaFai Lau,martin.lau@kernel.org,1701131024,6db3e1c51b10b4e9c53a7451319d02bcebf70eba,876843ce1e4897e8ceade50bfa3d9a4ec483abf3,"selftests/bpf: update test_offload to use new orphaned property

- filter orphaned programs by default
- when trying to query orphaned program"," don't expect bpftool failure

Cc: netdev@vger.kernel.org
Signed-off-by: Stanislav Fomichev <sdf@google.com>
Link: https://lore.kernel.org/r/20231127182057.1081138-2-sdf@google.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Update selftests to use a new orphaned property for offload testing in BPF.,"selftests, offload, orphaned",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
876843ce1e4897e8ceade50bfa3d9a4ec483abf3,876843ce1e4897e8ceade50bfa3d9a4ec483abf3,Stanislav Fomichev,sdf@google.com,1701109256,Martin KaFai Lau,martin.lau@kernel.org,1701131018,ecf7a17de846ca0963c22ed2ad89bc4709245956,b16904fd9f01b580db357ef2b1cc9e86d89576c2,"bpftool: mark orphaned programs during prog show

Commit ef01f4e25c17 (""bpf: restore the ebpf program ID for BPF_AUDIT_UNLOAD
and PERF_BPF_EVENT_PROG_UNLOAD"") stopped removing program's id from
idr when the offloaded/bound netdev goes away. I was supposed to
take a look and check in [0]"," but apparently I did not.

Martin points out it might be useful to keep it that way for
observability sake","[' but we at least need to mark those programs as\nunusable.\n\nMark those programs as \'orphaned\' and keep printing the list when\nwe encounter ENODEV.\n\n0: unspec  tag 0000000000000000\n        xlated 0B  not jited  memlock 4096B  orphaned\n\n[0]: https://lore.kernel.org/all/CAKH8qBtyR20ZWAc11z1-6pGb3Hd47AQUTbE_cfoktG59TqaJ7Q@mail.gmail.com/\n\nv3:\n* use two spaces for ""  orphaned"" (Quentin)\n\nCc: netdev@vger.kernel.org\nFixes: ef01f4e25c17 (""bpf: restore the ebpf program ID for BPF_AUDIT_UNLOAD and PERF_BPF_EVENT_PROG_UNLOAD"")\nSigned-off-by: Stanislav Fomichev <sdf@google.com>\nReviewed-by: Quentin Monnet <quentin@isovalent.com>\nLink: https://lore.kernel.org/r/20231127182057.1081138-1-sdf@google.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",This commit marks orphaned programs during 'prog show' in bpftool for improved observability.,"orphaned, bpftool, observability",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The bpftool utility,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0bad281d0ecdf8391b0f42678b663336e7c3ceb0,0bad281d0ecdf8391b0f42678b663336e7c3ceb0,Daniel Borkmann,daniel@iogearbox.net,1701115533,Martin KaFai Lau,martin.lau@kernel.org,1701130054,d6a13a746e74f4a8f848216427f189e79b4db30c,75a442581d05edaee168222ffbe00d4389785636,"netkit: Reject IFLA_NETKIT_PEER_INFO in netkit_change_link

The IFLA_NETKIT_PEER_INFO attribute can only be used during device
creation"," but not via changelink callback. Hence reject it there.

Fixes: 35dfaad7188c (""netkit","[' bpf: Add bpf programmable net device"")\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Nikolay Aleksandrov <razor@blackwall.org>\nCc: Jakub Kicinski <kuba@kernel.org>\nReviewed-by: Jakub Kicinski <kuba@kernel.org>\nLink: https://lore.kernel.org/r/e86a277a1e8d3b19890312779e42f790b0605ea4.1701115314.git.daniel@iogearbox.net\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Reject inappropriate use of IFLA_NETKIT_PEER_INFO in netkit_change_link.,"netkit, ifla_netkit_peer_info, changelink",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1638b11ef8156c8551f5aaa5799069633593c5fe,1638b11ef8156c8551f5aaa5799069633593c5fe,Athira Rajeev,atrajeev@linux.vnet.ibm.com,1700755352,Arnaldo Carvalho de Melo,acme@redhat.com,1701096513,b3e6e94e8957720fe2304f630396b80dba582569,5ebe2f4bf0a8fe8cceb5664a7dea4c17e2cf8477,"perf tools: Add perf binary dependent rule for shellcheck log in Makefile.perf

Add rule in new Makefile ""tests/Makefile.tests"" for running shellcheck
on shell test scripts. This automates below shellcheck into the build.

	$ for F in $(find tests/shell/ -perm -o=x -name '*.sh'); do shellcheck -S warning $F; done

Condition for shellcheck is added in Makefile.perf to avoid build
breakage in the absence of shellcheck binary. Update Makefile.perf to
contain new rule for ""SHELLCHECK_TEST"" which is for making shellcheck
test as a dependency on perf binary.

Added ""tests/Makefile.tests"" to run shellcheck on shellscripts in
tests/shell. The make rule ""SHLLCHECK_RUN"" ensures that"," every time
during make","[' shellcheck will be run only on modified files during\nsubsequent invocations. By this', ' if any newly added shell scripts or\nfixes in existing scripts breaks coding/formatting style', ' it will get\ncaptured during the perf build.\n\nExample build failure by modifying probe_vfs_getname.sh in tests/shell:\n\n\tIn tests/shell/probe_vfs_getname.sh line 8:\n\t. $(dirname $0)/lib/probe.sh\n\t  ^-----------^ SC2046 (warning): Quote this to prevent word splitting.\n\n\tFor more information:\n\t  https://www.shellcheck.net/wiki/SC2046 -- Quote this to prevent word splitt...\n\tmake[3]: *** [/root/athira/perf-tools-next/tools/perf/tests/Makefile.tests:18: tests/shell/.probe_vfs_getname.sh.shellcheck_log] Error 1\n\tmake[2]: *** [Makefile.perf:686: SHELLCHECK_TEST] Error 2\n\tmake[2]: *** Waiting for unfinished jobs....\n\tmake[1]: *** [Makefile.perf:244: sub-make] Error 2\n\tmake: *** [Makefile:70: all] Error 2\n\nHere', ' like other files which gets created during compilation (ex:\n.builtin-bench.o.cmd or .perf.o.cmd )', ' create .shellcheck_log also as a\nhidden file.  Example: tests/shell/.probe_vfs_getname.sh.shellcheck_log\nshellcheck is re-run if any of the script gets modified based on its\ndependency of this log file.\n\nAfter this', ' for testing', ' changed ""tests/shell/trace+probe_vfs_getname.sh"" to\nbreak shellcheck format. In the next make run', ' it is also captured:\n\n\tIn tests/shell/probe_vfs_getname.sh line 8:\n\t. $(dirname $0)/lib/probe.sh\n\t  ^-----------^ SC2046 (warning): Quote this to prevent word splitting.\n\n\tFor more information:\n\t  https://www.shellcheck.net/wiki/SC2046 -- Quote this to prevent word splitt...\n\tmake[3]: *** [/root/athira/perf-tools-next/tools/perf/tests/Makefile.tests:18: tests/shell/.probe_vfs_getname.sh.shellcheck_log] Error 1\n\tmake[3]: *** Waiting for unfinished jobs....\n\n\tIn tests/shell/trace+probe_vfs_getname.sh line 14:\n\t. $(dirname $0)/lib/probe.sh\n\t  ^-----------^ SC2046 (warning): Quote this to prevent word splitting.\n\n\tFor more information:\n\t  https://www.shellcheck.net/wiki/SC2046 -- Quote this to prevent word splitt...\n\tmake[3]: *** [/root/athira/perf-tools-next/tools/perf/tests/Makefile.tests:18: tests/shell/.trace+probe_vfs_getname.sh.shellcheck_log] Error 1\n\tmake[2]: *** [Makefile.perf:686: SHELLCHECK_TEST] Error 2\n\tmake[2]: *** Waiting for unfinished jobs....\n\tmake[1]: *** [Makefile.perf:244: sub-make] Error 2\n\tmake: *** [Makefile:70: all] Error 2\n\nFailure log can be found in the stdout of make itself.\n\nThis is reported at build time. To be able to go ahead with the build or\ndisable shellcheck even though it is known that some test is broken', ' add\na ""NO_SHELLCHECK"" option. Example:\n\n  make NO_SHELLCHECK=1\n\n\t  INSTALL libsubcmd_headers\n\t  INSTALL libsymbol_headers\n\t  INSTALL libapi_headers\n\t  INSTALL libperf_headers\n\t  INSTALL libbpf_headers\n\t  LINK    perf\n\nNote:\n\nThis is tested on RHEL and also SLES. Use below check:\n""$(shell which shellcheck 2> /dev/null)"" to look for presence\nof shellcheck binary. The approach ""shell command -v"" is not\nused here. In some of the distros(RHEL)', ' command is available\nas executable file (/usr/bin/command). But in some distros(SLES)', '\nit is a shell builtin and not available as executable file.\n\nCommitter testing:\n\n  $ type shellcheck\n  shellcheck is hashed (/usr/bin/shellcheck)\n  $ rpm -qf /usr/bin/shellcheck\n  ShellCheck-0.9.0-2.fc38.x86_64\n  $\n  $ alias m\n  $ git diff\n  diff --git a/tools/perf/tests/shell/probe_vfs_getname.sh b/tools/perf/tests/shell/probe_vfs_getname.sh\n  index 554e12e83c55fd56..dbc14634678e2bf6 100755\n  --- a/tools/perf/tests/shell/probe_vfs_getname.sh\n  +++ b/tools/perf/tests/shell/probe_vfs_getname.sh\n  @@ -5', '7 +5', '7 @@\n   # Arnaldo Carvalho de Melo <acme@kernel.org>', ' 2017\n\n   # shellcheck source=lib/probe.sh\n  -. ""$(dirname $0)""/lib/probe.sh\n  +. $(dirname $0)/lib/probe.sh\n\n   skip_if_no_perf_probe || exit 2\n\n  alias m=\'rm -rf ~/libexec/perf-core/ ; make -k CORESIGHT=1 O=/tmp/build/$(basename $PWD) -C tools/perf install-bin && perf test python\'\n  $ m\n  make: Entering directory \'/home/acme/git/perf-tools-next/tools/perf\'\n    BUILD:   Doing \'make -j32\' parallel build\n<SNIP>\n    INSTALL libbpf_headers\n\n  In tests/shell/probe_vfs_getname.sh line 8:\n  . $(dirname $0)/lib/probe.sh\n    ^-----------^ SC2046 (warning): Quote this to prevent word splitting.\n\n  For more information:\n    https://www.shellcheck.net/wiki/SC2046 -- Quote this to prevent word splitt...\n  make[3]: *** [/home/acme/git/perf-tools-next/tools/perf/tests/Makefile.tests:18: tests/shell/.probe_vfs_getname.sh.shellcheck_log] Error 1\n  make[2]: *** [Makefile.perf:686: SHELLCHECK_TEST] Error 2\n  make[2]: *** Waiting for unfinished jobs....\n  make[1]: *** [Makefile.perf:244: sub-make] Error 2\n  make: *** [Makefile:113: install-bin] Error 2\n  make: Leaving directory \'/home/acme/git/perf-tools-next/tools/perf\'\n  $\n\nReviewed-by: James Clark <james.clark@arm.com>\nSigned-off-by: Athira Jajeev <atrajeev@linux.vnet.ibm.com>\nTested-by: Arnaldo Carvalho de Melo <acme@redhat.com>\nCc: Adrian Hunter <adrian.hunter@intel.com>\nCc: Disha Goel <disgoel@linux.vnet.ibm.com>\nCc: Ian Rogers <irogers@google.com>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: Kajol Jain <kjain@linux.ibm.com>\nCc: Madhavan Srinivasan <maddy@linux.ibm.com>\nCc: Namhyung Kim <namhyung@kernel.org>\nCc: linuxppc-dev@lists.ozlabs.org\nLink: https://lore.kernel.org/r/20231123160232.94253-1-atrajeev@linux.vnet.ibm.com\nSigned-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>\n', '']",Added a rule in Makefile to run shellcheck on shell scripts and prevent build breakage if the shellcheck binary is missing.,"shellcheck, Makefile, tests",It's a build system or CI/CD change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
b16904fd9f01b580db357ef2b1cc9e86d89576c2,b16904fd9f01b580db357ef2b1cc9e86d89576c2,Yonghong Song,yonghong.song@linux.dev,1701061422,Daniel Borkmann,daniel@iogearbox.net,1701093219,d09f1e29a712d5b694f206b2b6023fe2fbe1dc34,e8a339b5235e294f29153149ea7cf26a9a87dbea,"bpf: Fix a few selftest failures due to llvm18 change

With latest upstream llvm18"," the following test cases failed:

  $ ./test_progs -j
  #13/2    bpf_cookie/multi_kprobe_link_api:FAIL
  #13/3    bpf_cookie/multi_kprobe_attach_api:FAIL
  #13      bpf_cookie:FAIL
  #77      fentry_fexit:FAIL
  #78/1    fentry_test/fentry:FAIL
  #78      fentry_test:FAIL
  #82/1    fexit_test/fexit:FAIL
  #82      fexit_test:FAIL
  #112/1   kprobe_multi_test/skel_api:FAIL
  #112/2   kprobe_multi_test/link_api_addrs:FAIL
  [...]
  #112     kprobe_multi_test:FAIL
  #356/17  test_global_funcs/global_func17:FAIL
  #356     test_global_funcs:FAIL

Further analysis shows llvm upstream patch [1] is responsible for the above
failures. For example","[' for function bpf_fentry_test7() in net/bpf/test_run.c', '\nwithout [1]', ' the asm code is:\n\n  0000000000000400 <bpf_fentry_test7>:\n     400: f3 0f 1e fa                   endbr64\n     404: e8 00 00 00 00                callq   0x409 <bpf_fentry_test7+0x9>\n     409: 48 89 f8                      movq    %rdi', ' %rax\n     40c: c3                            retq\n     40d: 0f 1f 00                      nopl    (%rax)\n\n... and with [1]', ' the asm code is:\n\n  0000000000005d20 <bpf_fentry_test7.specialized.1>:\n    5d20: e8 00 00 00 00                callq   0x5d25 <bpf_fentry_test7.specialized.1+0x5>\n    5d25: c3                            retq\n\n... and <bpf_fentry_test7.specialized.1> is called instead of <bpf_fentry_test7>\nand this caused test failures for #13/#77 etc. except #356.\n\nFor test case #356/17', ' with [1] (progs/test_global_func17.c))', "" the main prog\nlooks like:\n\n  0000000000000000 <global_func17>:\n       0:       b4 00 00 00 2a 00 00 00 w0 = 0x2a\n       1:       95 00 00 00 00 00 00 00 exit\n\n... which passed verification while the test itself expects a verification\nfailure.\n\nLet us add 'barrier_var' style asm code in both places to prevent function\nspecialization which caused selftests failure.\n\n  [1] https://github.com/llvm/llvm-project/pull/72903\n\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20231127050342.1945270-1-yonghong.song@linux.dev\n"", '']",Fixes selftest failures caused by llvm18 changes in the Linux eBPF subsystem.,"bpf,selftest,llvm18",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['tracepoints like programs', 'kprobe/uprobe/ftrace like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
75a442581d05edaee168222ffbe00d4389785636,75a442581d05edaee168222ffbe00d4389785636,Hou Tao,houtao1@huawei.com,1699677501,Alexei Starovoitov,ast@kernel.org,1701050426,6e7f8564ef1db21b3c0ab3e335142df1d53a6065,c0c6bde586c7dce82719b4ff32a2db6af9ee3d65,"bpf: Add missed allocation hint for bpf_mem_cache_alloc_flags()

bpf_mem_cache_alloc_flags() may call __alloc() directly when there is no
free object in free list"," but it doesn't initialize the allocation hint
for the returned pointer. It may lead to bad memory dereference when
freeing the pointer","[' so fix it by initializing the allocation hint.\n\nFixes: 822fb26bdb55 (""bpf: Add a hint to allocated objects."")\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20231111043821.2258513-1-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add an allocation hint to bpf_mem_cache_alloc_flags() to prevent bad memory dereference.,"allocation,memory,dereference",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e8a339b5235e294f29153149ea7cf26a9a87dbea,e8a339b5235e294f29153149ea7cf26a9a87dbea,Andrii Nakryiko,andrii@kernel.org,1700798377,Daniel Borkmann,daniel@iogearbox.net,1700818806,11c36122a9d80c9c3ad9525f47973326ae348c30,2afae08c9dcb8ac648414277cec70c2fe6a34d9e,"selftests/bpf: Add lazy global subprog validation tests

Add a few test that validate BPF verifier's lazy approach to validating
global subprogs.

We check that global subprogs that are called transitively through
another global subprog is validated.

We also check that invalid global subprog is not validated"," if it's not
called from the main program.

And we also check that main program is always validated first","[' before\nany of the subprogs.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20231124035937.403208-4-andrii@kernel.org\n', '']",Add selftests for validating the BPF verifier's lazy approach to global subprog validation.,"selftests,BPF verifier,validation",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2afae08c9dcb8ac648414277cec70c2fe6a34d9e,2afae08c9dcb8ac648414277cec70c2fe6a34d9e,Andrii Nakryiko,andrii@kernel.org,1700798376,Daniel Borkmann,daniel@iogearbox.net,1700818806,e6cdbe3962bbf30de73715d3b501a744c5b6df97,491dd8edecbc5027ee317f3f1e7e9800fb66d88f,"bpf: Validate global subprogs lazily

Slightly change BPF verifier logic around eagerness and order of global
subprog validation. Instead of going over every global subprog eagerly
and validating it before main (entry) BPF program is verified"," turn it
around. Validate main program first","[' mark subprogs that were called from\nmain program for later verification', ' but otherwise assume it is valid.\nAfterwards', ' go over marked global subprogs and validate those', ""\npotentially marking some more global functions as being called. Continue\nthis process until all (transitively) callable global subprogs are\nvalidated. It's a BFS traversal at its heart and will always converge.\n\nThis is an important change because it allows to feature-gate some\nsubprograms that might not be verifiable on some older kernel"", ' depending\non supported set of features.\n\nE.g.', ' at some point', ' global functions were allowed to accept a pointer\nto memory', ' which size is identified by user-provided type.\nUnfortunately', "" older kernels don't support this feature. With BPF CO-RE\napproach"", "" the natural way would be to still compile BPF object file once\nand guard calls to this global subprog with some CO-RE check or using\n.rodata variables. That's what people do to guard usage of new helpers\nor kfuncs"", "" and any other new BPF-side feature that might be missing on\nold kernels.\n\nThat's currently impossible to do with global subprogs"", ' unfortunately', '\nbecause they are eagerly and unconditionally validated. This patch set\naims to change this', ' so that in the future when global funcs gain new\nfeatures', "" those can be guarded using BPF CO-RE techniques in the same\nfashion as any other new kernel feature.\n\nTwo selftests had to be adjusted in sync with these changes.\n\ntest_global_func12 relied on eager global subprog validation failing\nbefore main program failure is detected (unknown return value). Fix by\nmaking sure that main program is always valid.\n\nverifier_subprog_precision's parent_stack_slot_precise subtest relied on\nverifier checkpointing heuristic to do a checkpoint at instruction #5"", ""\nbut that's no longer true because we don't have enough jumps validated\nbefore reaching insn #5 due to global subprogs being validated later.\n\nOther than that"", ' no changes', ' as one would expect.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20231124035937.403208-3-andrii@kernel.org\n', '']","This commit changes the BPF verifier's approach to validate global subprograms lazily, focusing first on the main program.","BPF verifier, global subprogs, validation",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
491dd8edecbc5027ee317f3f1e7e9800fb66d88f,491dd8edecbc5027ee317f3f1e7e9800fb66d88f,Andrii Nakryiko,andrii@kernel.org,1700798375,Daniel Borkmann,daniel@iogearbox.net,1700818806,01a62066f165441f5cb4db1b0a7267b4fab811eb,b8d78cb2e24d92352878a9f6525aec002c891528,"bpf: Emit global subprog name in verifier logs

We have the name"," instead of emitting just func#N to identify global
subprog","[' augment verifier log messages with actual function name to make\nit more user-friendly.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20231124035937.403208-2-andrii@kernel.org\n', '']",Emit global subprogram names in eBPF verifier logs for better identification.,"verifier,logs,subprog",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b8d78cb2e24d92352878a9f6525aec002c891528,b8d78cb2e24d92352878a9f6525aec002c891528,Eduard Zingerman,eddyz87@gmail.com,1700697879,Daniel Borkmann,daniel@iogearbox.net,1700776181,f4ca61a4565a67953930b4445555d12223d5636b,45c226dde742a92e22dcd65b96bf7e02620a9c19,"libbpf: Start v1.4 development cycle

Bump libbpf.map to v1.4.0 to start a new libbpf version cycle.

Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20231123000439.12025-1-eddyz87@gmail.com
",,Bump libbpf.map to v1.4.0 to start a new libbpf version cycle.,"libbpf, version, development",It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"[""It's not related to any of the above.""]"
c0c6bde586c7dce82719b4ff32a2db6af9ee3d65,c0c6bde586c7dce82719b4ff32a2db6af9ee3d65,Stanislav Fomichev,sdf@google.com,1699937692,Alexei Starovoitov,ast@kernel.org,1700773444,fa3610ce4bae16c4ea1ab3fa962ad79b6bb275da,d3fa86b1a7b4cdc4367acacea16b72e0a200b3d7,"netdevsim: Don't accept device bound programs

Commit 2b3486bc2d23 (""bpf: Introduce device-bound XDP programs"") introduced
device-bound programs by largely reusing existing offloading infrastructure.
This changed the semantics of 'prog->aux->offload' a bit. Now"," it's non-NULL
for both offloaded and device-bound programs.

Instead of looking at 'prog->aux->offload' let's call bpf_prog_is_offloaded
which should be true iff the program is offloaded and not merely device-bound.

Fixes: 2b3486bc2d23 (""bpf: Introduce device-bound XDP programs"")
Reported-by: syzbot+44c2416196b7c607f226@syzkaller.appspotmail.com
Signed-off-by: Stanislav Fomichev <sdf@google.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Reviewed-by: Jakub Kicinski <kuba@kernel.org>
Cc: Dipendra Khadka <kdipendra88@gmail.com>
Link: https://lore.kernel.org/bpf/20231114045453.1816995-2-sdf@google.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],This commit prevents netdevsim from accepting device-bound XDP programs by correctly checking program offloading status.,"netdevsim, XDP program, offloading",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['xdp like programs']
45c226dde742a92e22dcd65b96bf7e02620a9c19,45c226dde742a92e22dcd65b96bf7e02620a9c19,Jakub Kicinski,kuba@kernel.org,1700770789,Jakub Kicinski,kuba@kernel.org,1700770858,abaedb7f2ddf75914659c7b9a48af34ca89a9208,c5b9f4792ea6b9abfcfb9486ba256f55e296aaa7 d3fa86b1a7b4cdc4367acacea16b72e0a200b3d7,"Merge git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Cross-merge networking fixes after downstream PR.

Conflicts:

drivers/net/ethernet/intel/ice/ice_main.c
  c9663f79cd82 (""ice: adjust switchdev rebuild path"")
  7758017911a4 (""ice: restore timestamp configuration after device reset"")
https://lore.kernel.org/all/20231121211259.3348630-1-anthony.l.nguyen@intel.com/

Adjacent changes:

kernel/bpf/verifier.c
  bb124da69c47 (""bpf: keep track of max number of bpf_loop callback iterations"")
  5f99f312bd3b (""bpf: add register bounds sanity checks and sanitization"")

Signed-off-by: Jakub Kicinski <kuba@kernel.org>
",,Cross-merge of networking fixes including changes to ethernet and eBPF verifier subsystems.,"networking, merge, fixes",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d3fa86b1a7b4cdc4367acacea16b72e0a200b3d7,d3fa86b1a7b4cdc4367acacea16b72e0a200b3d7,Linus Torvalds,torvalds@linux-foundation.org,1700764813,Linus Torvalds,torvalds@linux-foundation.org,1700764813,fd40e9d155e34998831dc46c70dbda3d09bd6da6,9b6de136b5f0158c60844f85286a593cb70fb364 39f04b1406b23fcc129a67e70d6205d5a7322f38,"Merge tag 'net-6.7-rc3' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Jakub Kicinski:
 ""Including fixes from bpf.

  Current release - regressions:

   - Revert ""net: r8169: Disable multicast filter for RTL8168H and
     RTL8107E""

   - kselftest: rtnetlink: fix ip route command typo

  Current release - new code bugs:

   - s390/ism: make sure ism driver implies smc protocol in kconfig

   - two build fixes for tools/net

  Previous releases - regressions:

   - rxrpc: couple of ACK/PING/RTT handling fixes

  Previous releases - always broken:

   - bpf: verify bpf_loop() callbacks as if they are called unknown
     number of times

   - improve stability of auto-bonding with Hyper-V

   - account BPF-neigh-redirected traffic in interface statistics

  Misc:

   - net: fill in some more MODULE_DESCRIPTION()s""

* tag 'net-6.7-rc3' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (58 commits)
  tools: ynl: fix duplicate op name in devlink
  tools: ynl: fix header path for nfsd
  net: ipa: fix one GSI register field width
  tls: fix NULL deref on tls_sw_splice_eof() with empty record
  net: axienet: Fix check for partial TX checksum
  vsock/test: fix SEQPACKET message bounds test
  i40e: Fix adding unsupported cloud filters
  ice: restore timestamp configuration after device reset
  ice: unify logic for programming PFINT_TSYN_MSK
  ice: remove ptp_tx ring parameter flag
  amd-xgbe: propagate the correct speed and duplex status
  amd-xgbe: handle the corner-case during tx completion
  amd-xgbe: handle corner-case during sfp hotplug
  net: veth: fix ethtool stats reporting
  octeontx2-pf: Fix ntuple rule creation to direct packet to VF with higher Rx queue than its PF
  net: usb: qmi_wwan: claim interface 4 for ZTE MF290
  Revert ""net: r8169: Disable multicast filter for RTL8168H and RTL8107E""
  net/smc: avoid data corruption caused by decline
  nfc: virtual_ncidev: Add variable to check if ndev is running
  dpll: Fix potential msg memleak when genlmsg_put_reply failed
  ...
",,Merge networking fixes that include BPF-related improvements and bug resolutions.,"networking,BPF,fixes",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
53475287dad9b314ef477fc9a27b48b6999da053,53475287dad9b314ef477fc9a27b48b6999da053,Jakub Kicinski,kuba@kernel.org,1700617969,Jakub Kicinski,kuba@kernel.org,1700618000,879406230b20e986706aa37dacd999c63494328b,340bf2dbb11b4d2d44055fa5851d75fd335e3d45 3cbbf9192abdc9183eb215b5e8b06c778e5c2214,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next

Daniel Borkmann says:

====================
pull-request: bpf-next 2023-11-21

We've added 85 non-merge commits during the last 12 day(s) which contain
a total of 63 files changed", 4464 insertions(+),"[' 1484 deletions(-).\n\nThe main changes are:\n\n1) Huge batch of verifier changes to improve BPF register bounds logic\n   and range support along with a large test suite', ' and verifier log\n   improvements', ' all from Andrii Nakryiko.\n\n2) Add a new kfunc which acquires the associated cgroup of a task within\n   a specific cgroup v1 hierarchy where the latter is identified by its id', '\n   from Yafang Shao.\n\n3) Extend verifier to allow bpf_refcount_acquire() of a map value field\n   obtained via direct load which is a use-case needed in sched_ext', '\n   from Dave Marchevsky.\n\n4) Fix bpf_get_task_stack() helper to add the correct crosstask check\n   for the get_perf_callchain()', ' from Jordan Rome.\n\n5) Fix BPF task_iter internals where lockless usage of next_thread()\n   was wrong. The rework also simplifies the code', ' from Oleg Nesterov.\n\n6) Fix uninitialized tail padding via LIBBPF_OPTS_RESET', ' and another\n   fix for certain BPF UAPI structs to fix verifier failures seen\n   in bpf_dynptr usage', ' from Yonghong Song.\n\n7) Add BPF selftest fixes for map_percpu_stats flakes due to per-CPU BPF\n   memory allocator not being able to allocate per-CPU pointer successfully', '\n   from Hou Tao.\n\n8) Add prep work around dynptr and string handling for kfuncs which\n   is later going to be used by file verification via BPF LSM and fsverity', '\n   from Song Liu.\n\n9) Improve BPF selftests to update multiple prog_tests to use ASSERT_*\n   macros', ' from Yuran Pereira.\n\n10) Optimize LPM trie lookup to check prefixlen before walking the trie', '\n    from Florian Lehner.\n\n11) Consolidate virtio/9p configs from BPF selftests in config.vm file\n    given they are needed consistently across archs', ' from Manu Bretelle.\n\n12) Small BPF verifier refactor to remove register_is_const()', ""\n    from Shung-Hsi Yu.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next: (85 commits)\n  selftests/bpf: Replaces the usage of CHECK calls for ASSERTs in vmlinux\n  selftests/bpf: Replaces the usage of CHECK calls for ASSERTs in bpf_obj_id\n  selftests/bpf: Replaces the usage of CHECK calls for ASSERTs in bind_perm\n  selftests/bpf: Replaces the usage of CHECK calls for ASSERTs in bpf_tcp_ca\n  selftests/bpf: reduce verboseness of reg_bounds selftest logs\n  bpf: bpf_iter_task_next: use next_task(kit->task) rather than next_task(kit->pos)\n  bpf: bpf_iter_task_next: use __next_thread() rather than next_thread()\n  bpf: task_group_seq_get_next: use __next_thread() rather than next_thread()\n  bpf: emit frameno for PTR_TO_STACK regs if it differs from current one\n  bpf: smarter verifier log number printing logic\n  bpf: omit default off=0 and imm=0 in register state log\n  bpf: emit map name in register state if applicable and available\n  bpf: print spilled register state in stack slot\n  bpf: extract register state printing\n  bpf: move verifier state printing code to kernel/bpf/log.c\n  bpf: move verbose_linfo() into kernel/bpf/log.c\n  bpf: rename BPF_F_TEST_SANITY_STRICT to BPF_F_TEST_REG_INVARIANTS\n  bpf: Remove test for MOVSX32 with offset=32\n  selftests/bpf: add iter test requiring range x range logic\n  veristat: add ability to set BPF_F_TEST_SANITY_STRICT flag with -r flag\n  ...\n====================\n\nLink: https://lore.kernel.org/r/20231122000500.28126-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n"", '']","Merge branch 'for-netdev' with updates from bpf-next into the main project, including 85 non-merge commits affecting 63 files.","merge, bpf-next, non-merge",It's a new feature.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b2d66643dcf2c395207f9373c624e0ab32166e57,b2d66643dcf2c395207f9373c624e0ab32166e57,Jakub Kicinski,kuba@kernel.org,1700610570,Jakub Kicinski,kuba@kernel.org,1700610571,a9be214abb19a9f0f41a6ad2c8b42a39a64bd363,495ec91b48e489afefb2ad714f0d9b68c3016c6c acb12c859ac7c36d6d7632280fd1e263188cb07f,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Daniel Borkmann says:

====================
pull-request: bpf 2023-11-21

We've added 19 non-merge commits during the last 4 day(s) which contain
a total of 18 files changed", 1043 insertions(+),"[' 416 deletions(-).\n\nThe main changes are:\n\n1) Fix BPF verifier to validate callbacks as if they are called an unknown\n   number of times in order to fix not detecting some unsafe programs', '\n   from Eduard Zingerman.\n\n2) Fix bpf_redirect_peer() handling which missed proper stats accounting\n   for veth and netkit and also generally fix missing stats for the latter', '\n   from Peilin Ye', "" Daniel Borkmann et al.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  selftests/bpf: check if max number of bpf_loop iterations is tracked\n  bpf: keep track of max number of bpf_loop callback iterations\n  selftests/bpf: test widening for iterating callbacks\n  bpf: widening for callback iterators\n  selftests/bpf: tests for iterating callbacks\n  bpf: verify callbacks as if they are called unknown number of times\n  bpf: extract setup_func_entry() utility function\n  bpf: extract __check_reg_arg() utility function\n  selftests/bpf: fix bpf_loop_bench for new callback verification scheme\n  selftests/bpf: track string payload offset as scalar in strobemeta\n  selftests/bpf: track tcp payload offset as scalar in xdp_synproxy\n  selftests/bpf: Add netkit to tc_redirect selftest\n  selftests/bpf: De-veth-ize the tc_redirect test case\n  bpf"", "" netkit: Add indirect call wrapper for fetching peer dev\n  bpf: Fix dev's rx stats for bpf_redirect_peer traffic\n  veth: Use tstats per-CPU traffic counters\n  netkit: Add tstats per-CPU traffic counters\n  net: Move {l"", 't', 'd}stats allocation to core and convert veth & vrf\n  net', ' vrf: Move dstats structure to core\n====================\n\nLink: https://lore.kernel.org/r/20231121193113.11796-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Merged 'for-netdev' tag containing 19 non-merge commits into the bpf tree.,"merge, commits, bpf",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3cbbf9192abdc9183eb215b5e8b06c778e5c2214,3cbbf9192abdc9183eb215b5e8b06c778e5c2214,Andrii Nakryiko,andrii@kernel.org,1700592183,Andrii Nakryiko,andrii@kernel.org,1700592326,44db270715ffcdfdf3c099a61d5b3c5e0106dd25,57b97ecb40caeb116c22451bbdaaa9a1d12c0b43 3ece0e85f679c23d2a5128993846c58a2f5f890e,"Merge branch 'selftests-bpf-update-multiple-prog_tests-to-use-assert_-macros'

Yuran Pereira says:

====================
selftests/bpf: Update multiple prog_tests to use ASSERT_ macros

Multiple files/programs in `tools/testing/selftests/bpf/prog_tests/` still
heavily use the `CHECK` macro"," even when better `ASSERT_` alternatives are
available.

As it was already pointed out by Yonghong Song [1] in the bpf selftests the use
of the ASSERT_* series of macros is preferred over the CHECK macro.

This patchset replaces the usage of `CHECK(` macros to the equivalent `ASSERT_`
family of macros in the following prog_tests:
- bind_perm.c
- bpf_obj_id.c
- bpf_tcp_ca.c
- vmlinux.c

[1] https://lore.kernel.org/lkml/0a142924-633c-44e6-9a92-2dc019656bf2@linux.dev

Changes in v3:
- Addressed the following points mentioned by Yonghong Song
- Improved `bpf_map_lookup_elem` assertion in bpf_tcp_ca.
- Replaced assertion introduced in v2 with one that checks `thread_ret`
  instead of `pthread_join`. This ensures that `server`'s return value
  (thread_ret) is the one being checked","["" as oposed to `pthread_join`'s\n  return value"", ' since the latter one is less likely to fail.\n\nChanges in v2:\n- Fixed pthread_join assertion that broke the previous test\n\nPrevious version:\nv2 - https://lore.kernel.org/lkml/GV1PR10MB6563AECF8E94798A1E5B36A4E8B6A@GV1PR10MB6563.EURPRD10.PROD.OUTLOOK.COM\nv1 - https://lore.kernel.org/lkml/GV1PR10MB6563FCFF1C5DEBE84FEA985FE8B0A@GV1PR10MB6563.EURPRD10.PROD.OUTLOOK.COM\n====================\n\nLink: https://lore.kernel.org/r/GV1PR10MB6563BEFEA4269E1DDBC264B1E8BBA@GV1PR10MB6563.EURPRD10.PROD.OUTLOOK.COM\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n', '']",Update multiple BPF selftests to use ASSERT_ macros instead of CHECK.,"selftests, ASSERT_ macros, prog_tests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3ece0e85f679c23d2a5128993846c58a2f5f890e,3ece0e85f679c23d2a5128993846c58a2f5f890e,Yuran Pereira,yuran.pereira@hotmail.com,1700525441,Andrii Nakryiko,andrii@kernel.org,1700592326,44db270715ffcdfdf3c099a61d5b3c5e0106dd25,f125d09b99fc0ee43f865810390f10b8f23a2c98,"selftests/bpf: Replaces the usage of CHECK calls for ASSERTs in vmlinux

vmlinux.c uses the `CHECK` calls even though the use of ASSERT_ series
of macros is preferred in the bpf selftests.

This patch replaces all `CHECK` calls for equivalent `ASSERT_`
macro calls.

Signed-off-by: Yuran Pereira <yuran.pereira@hotmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/GV1PR10MB6563ED1023A2A3AEF30BDA5DE8BBA@GV1PR10MB6563.EURPRD10.PROD.OUTLOOK.COM
",,This commit replaces CHECK calls with ASSERT macros in vmlinux bpf selftests.,"bpf,selftests,macros",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f125d09b99fc0ee43f865810390f10b8f23a2c98,f125d09b99fc0ee43f865810390f10b8f23a2c98,Yuran Pereira,yuran.pereira@hotmail.com,1700525365,Andrii Nakryiko,andrii@kernel.org,1700592324,b8c5a66cc6120605a5c7a110d05ed01be3a47f2d,3ec1114a97457398077e45b231d502d1cc30439d,"selftests/bpf: Replaces the usage of CHECK calls for ASSERTs in bpf_obj_id

bpf_obj_id uses the `CHECK` calls even though the use of
ASSERT_ series of macros is preferred in the bpf selftests.

This patch replaces all `CHECK` calls for equivalent `ASSERT_`
macro calls.

Signed-off-by: Yuran Pereira <yuran.pereira@hotmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/GV1PR10MB65639AA3A10B4BBAA79952C7E8BBA@GV1PR10MB6563.EURPRD10.PROD.OUTLOOK.COM
",,Replaced CHECK calls with ASSERT macros in bpf_obj_id selftests for better consistency.,"selftests,ASSERT,macros",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3ec1114a97457398077e45b231d502d1cc30439d,3ec1114a97457398077e45b231d502d1cc30439d,Yuran Pereira,yuran.pereira@hotmail.com,1700525263,Andrii Nakryiko,andrii@kernel.org,1700592183,7b34819126ba133a7f55209e83ecdd32af7cf447,b0e2a0395312f4e53504ae84eeb5902e5518d1d7,"selftests/bpf: Replaces the usage of CHECK calls for ASSERTs in bind_perm

bind_perm uses the `CHECK` calls even though the use of
ASSERT_ series of macros is preferred in the bpf selftests.

This patch replaces all `CHECK` calls for equivalent `ASSERT_`
macro calls.

Signed-off-by: Yuran Pereira <yuran.pereira@hotmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/GV1PR10MB656314F467E075A106CA02BFE8BBA@GV1PR10MB6563.EURPRD10.PROD.OUTLOOK.COM
",,Replaced CHECK calls with ASSERT_ macros in the bind_perm bpf selftests.,"ASSERT, CHECK, selftests",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
b0e2a0395312f4e53504ae84eeb5902e5518d1d7,b0e2a0395312f4e53504ae84eeb5902e5518d1d7,Yuran Pereira,yuran.pereira@hotmail.com,1700525139,Andrii Nakryiko,andrii@kernel.org,1700592183,e2b324248b2a501fef66ed7507015deb9fcf31c0,57b97ecb40caeb116c22451bbdaaa9a1d12c0b43,"selftests/bpf: Replaces the usage of CHECK calls for ASSERTs in bpf_tcp_ca

bpf_tcp_ca uses the `CHECK` calls even though the use of
ASSERT_ series of macros is preferred in the bpf selftests.

This patch replaces all `CHECK` calls for equivalent `ASSERT_`
macro calls.

Signed-off-by: Yuran Pereira <yuran.pereira@hotmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/GV1PR10MB6563F180C0F2BB4F6CFA5130E8BBA@GV1PR10MB6563.EURPRD10.PROD.OUTLOOK.COM
",,Refactors selftests by replacing CHECK calls with ASSERT macros in bpf_tcp_ca.,"selftests, ASSERT, bpf_tcp_ca",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
29b8e94dcf2575c17541f843741ee96691ff1ded,29b8e94dcf2575c17541f843741ee96691ff1ded,Yang Jihong,yangjihong1@huawei.com,1700275737,Namhyung Kim,namhyung@kernel.org,1700589758,b7965c350dce54c8a63b51a7e51ef213d5e19228,a6dda77a752d918b35ef4a3f94e6b8c7d7ba4a73,"perf lock contention: Fix a build error on 32-bit

Fix a build error on 32-bit system:

  util/bpf_lock_contention.c: In function 'lock_contention_get_name':
  util/bpf_lock_contention.c:253:50: error: format '%lu' expects argument of type 'long unsigned int'"," but argument 4 has type 'u64 {aka long long unsigned int}' [-Werror=format=]
     snprintf(name_buf","[' sizeof(name_buf)', ' ""cgroup:%lu""', ' cgrp_id);\n                                                  ~~^\n                                                  %llu\n  cc1: all warnings being treated as errors\n\nFixes: d0c502e46e97 (""perf lock contention: Prepare to handle cgroups"")\nSigned-off-by: Yang Jihong <yangjihong1@huawei.com>\nAcked-by: Namhyung Kim <namhyung@kernel.org>\nCc: avagin@google.com\nCc: daniel.diaz@linaro.org\nLink: https://lore.kernel.org/r/20231118024858.1567039-3-yangjihong1@huawei.com\nSigned-off-by: Namhyung Kim <namhyung@kernel.org>\n', '']",Fix a build error related to format specifier on 32-bit systems in perf lock contention code.,"build,error,32-bit",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['other']
acb12c859ac7c36d6d7632280fd1e263188cb07f,acb12c859ac7c36d6d7632280fd1e263188cb07f,Alexei Starovoitov,ast@kernel.org,1700534016,Alexei Starovoitov,ast@kernel.org,1700534201,807b0cdc43a76fe532c17fc31e96413c82161e1a,fcb905d831336ee0a67dd953837a904173cf7390 57e2a52deeb12ab84c15c6d0fb93638b5b94001b,"Merge branch 'verify-callbacks-as-if-they-are-called-unknown-number-of-times'

Eduard Zingerman says:

====================
verify callbacks as if they are called unknown number of times

This series updates verifier logic for callback functions handling.
Current master simulates callback body execution exactly once","
which leads to verifier not detecting unsafe programs like below:

    static int unsafe_on_zero_iter_cb(__u32 idx","[' struct num_context *ctx)\n    {\n        ctx->i = 0;\n        return 0;\n    }\n\n    SEC(""?raw_tp"")\n    int unsafe_on_zero_iter(void *unused)\n    {\n        struct num_context loop_ctx = { .i = 32 };\n        __u8 choice_arr[2] = { 0', ' 1 };\n\n        bpf_loop(100', ' unsafe_on_zero_iter_cb', ' &loop_ctx', ' 0);\n        return choice_arr[loop_ctx.i];\n    }\n\nThis was reported previously in [0].\nThe basic idea of the fix is to schedule callback entry state for\nverification in env->head until some identical', ' previously visited\nstate in current DFS state traversal is found. Same logic as with open\ncoded iterators', ' and builds on top recent fixes [1] for those.\n\nThe series is structured as follows:\n- patches #1', '2', '3 update strobemeta', ' xdp_synproxy selftests and\n  bpf_loop_bench benchmark to allow convergence of the bpf_loop\n  callback states;\n- patches #4', '5 just shuffle the code a bit;\n- patch #6 is the main part of the series;\n- patch #7 adds test cases for #6;\n- patch #8 extend patch #6 with same speculative scalar widening\n  logic', ' as used for open coded iterators;\n- patch #9 adds test cases for #8;\n- patch #10 extends patch #6 to track maximal number of callback\n  executions specifically for bpf_loop();\n- patch #11 adds test cases for #10.\n\nVeristat results comparing this series to master+patches #1', '2', '3 using selftests\nshow the following difference:\n\nFile                       Program        States (A)  States (B)  States (DIFF)\n-------------------------  -------------  ----------  ----------  -------------\nbpf_loop_bench.bpf.o       benchmark               1           2  +1 (+100.00%)\npyperf600_bpf_loop.bpf.o   on_event              322         407  +85 (+26.40%)\nstrobemeta_bpf_loop.bpf.o  on_event              113         151  +38 (+33.63%)\nxdp_synproxy_kern.bpf.o    syncookie_tc          341         291  -50 (-14.66%)\nxdp_synproxy_kern.bpf.o    syncookie_xdp         344         301  -43 (-12.50%)\n\nVeristat results comparing this series to master using Tetragon BPF\nfiles [2] also show some differences.\nStates diff varies from +2% to +15% on 23 programs out of 186', '\nno new failures.\n\nChangelog:\n- V3 [5] -> V4', "" changes suggested by Andrii:\n  - validate mark_chain_precision() result in patch #10;\n  - renaming s/cumulative_callback_depth/callback_unroll_depth/.\n- V2 [4] -> V3:\n  - fixes in expected log messages for test cases:\n    - callback_result_precise;\n    - parent_callee_saved_reg_precise_with_callback;\n    - parent_stack_slot_precise_with_callback;\n  - renamings (suggested by Alexei):\n    - s/callback_iter_depth/cumulative_callback_depth/\n    - s/is_callback_iter_next/calls_callback/\n    - s/mark_callback_iter_next/mark_calls_callback/\n  - prepare_func_exit() updated to exit with -EFAULT when\n    callee->in_callback_fn is true but calls_callback() is not true\n    for callsite;\n  - test case 'bpf_loop_iter_limit_nested' rewritten to use return\n    value check instead of verifier log message checks\n    (suggested by Alexei).\n- V1 [3] -> V2"", "" changes suggested by Andrii:\n  - small changes for error handling code in __check_func_call();\n  - callback body processing log is now matched in relevant\n    verifier_subprog_precision.c tests;\n  - R1 passed to bpf_loop() is now always marked as precise;\n  - log level 2 message for bpf_loop() iteration termination instead of\n    iteration depth messages;\n  - __no_msg macro removed;\n  - bpf_loop_iter_limit_nested updated to avoid using __no_msg;\n  - commit message for patch #3 updated according to Alexei's request.\n\n[0] https://lore.kernel.org/bpf/CA+vRuzPChFNXmouzGG+wsy=6eMcfr1mFG0F3g7rbg-sedGKW3w@mail.gmail.com/\n[1] https://lore.kernel.org/bpf/20231024000917.12153-1-eddyz87@gmail.com/\n[2] git@github.com:cilium/tetragon.git\n[3] https://lore.kernel.org/bpf/20231116021803.9982-1-eddyz87@gmail.com/T/#t\n[4] https://lore.kernel.org/bpf/20231118013355.7943-1-eddyz87@gmail.com/T/#t\n[5] https://lore.kernel.org/bpf/20231120225945.11741-1-eddyz87@gmail.com/T/#t\n====================\n\nLink: https://lore.kernel.org/r/20231121020701.26440-1-eddyz87@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Update verifier logic to handle callbacks as being called an unknown number of times.,"verifier,callbacks,logic",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
57e2a52deeb12ab84c15c6d0fb93638b5b94001b,57e2a52deeb12ab84c15c6d0fb93638b5b94001b,Eduard Zingerman,eddyz87@gmail.com,1700532421,Alexei Starovoitov,ast@kernel.org,1700534200,807b0cdc43a76fe532c17fc31e96413c82161e1a,bb124da69c47dd98d69361ec13244ece50bec63e,"selftests/bpf: check if max number of bpf_loop iterations is tracked

Check that even if bpf_loop() callback simulation does not converge to
a specific state"," verification could proceed via ""brute force""
simulation of maximal number of callback calls.

Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20231121020701.26440-12-eddyz87@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Add a test to verify if the maximum number of bpf_loop iterations is correctly tracked in selftests.,"bpf_loop,selftests,iterations",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
bb124da69c47dd98d69361ec13244ece50bec63e,bb124da69c47dd98d69361ec13244ece50bec63e,Eduard Zingerman,eddyz87@gmail.com,1700532420,Alexei Starovoitov,ast@kernel.org,1700534200,471ffe5db4c4853832fd01de3a5113715b14f715,9f3330aa644d6d979eb064c46e85c62d4b4eac75,"bpf: keep track of max number of bpf_loop callback iterations

In some cases verifier can't infer convergence of the bpf_loop()
iteration. E.g. for the following program:

    static int cb(__u32 idx"," struct num_context* ctx)
    {
        ctx->i++;
        return 0;
    }

    SEC(""?raw_tp"")
    int prog(void *_)
    {
        struct num_context ctx = { .i = 0 };
        __u8 choice_arr[2] = { 0","[' 1 };\n\n        bpf_loop(2', ' cb', ' &ctx', "" 0);\n        return choice_arr[ctx.i];\n    }\n\nEach 'cb' simulation would eventually return to 'prog' and reach\n'return choice_arr[ctx.i]' statement. At which point ctx.i would be\nmarked precise"", ' thus forcing verifier to track multitude of separate\nstates with {.i=0}', ' {.i=1}', ' ... at bpf_loop() callback entry.\n\nThis commit allows ""brute force"" handling for such cases by limiting\nnumber of callback body simulations using \'umax\' value of the first\nbpf_loop() parameter.\n\nFor this', "" extend bpf_func_state with 'callback_depth' field.\nIncrement this field when callback visiting state is pushed to states\ntraversal stack. For frame #N it's 'callback_depth' field counts how\nmany times callback with frame depth N+1 had been executed.\nUse bpf_func_state specifically to allow independent tracking of\ncallback depths when multiple nested bpf_loop() calls are present.\n\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20231121020701.26440-11-eddyz87@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",The commit enhances the verifier to track the maximum number of iterations for bpf_loop callbacks.,"bpf,verifier,loop",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9f3330aa644d6d979eb064c46e85c62d4b4eac75,9f3330aa644d6d979eb064c46e85c62d4b4eac75,Eduard Zingerman,eddyz87@gmail.com,1700532419,Alexei Starovoitov,ast@kernel.org,1700534200,339ae1382e4f1ac5b3f2939a3b7431e6c6a9347d,cafe2c21508a38cdb3ed22708842e957b2572c3e,"selftests/bpf: test widening for iterating callbacks

A test case to verify that imprecise scalars widening is applied to
callback entering state"," when callback call is simulated repeatedly.

Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20231121020701.26440-10-eddyz87@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],This commit adds a test case to ensure imprecise scalars are widened in callback entering states during repeated simulations.,"test,widening,callback",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
cafe2c21508a38cdb3ed22708842e957b2572c3e,cafe2c21508a38cdb3ed22708842e957b2572c3e,Eduard Zingerman,eddyz87@gmail.com,1700532418,Alexei Starovoitov,ast@kernel.org,1700534200,b93ff2494a5347ae9e13f76e51dbba0147560cbe,958465e217dbf5fc6677d42d8827fb3073d86afd,"bpf: widening for callback iterators

Callbacks are similar to open coded iterators"," so add imprecise
widening logic for callback body processing. This makes callback based
loops behave identically to open coded iterators","[' e.g. allowing to\nverify programs like below:\n\n  struct ctx { u32 i; };\n  int cb(u32 idx', ' struct ctx* ctx)\n  {\n          ++ctx->i;\n          return 0;\n  }\n  ...\n  struct ctx ctx = { .i = 0 };\n  bpf_loop(100', ' cb', ' &ctx', ' 0);\n  ...\n\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20231121020701.26440-9-eddyz87@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add imprecise widening logic for callback iterators in eBPF to match open coded iterators.,"callback,iterators,widening",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
958465e217dbf5fc6677d42d8827fb3073d86afd,958465e217dbf5fc6677d42d8827fb3073d86afd,Eduard Zingerman,eddyz87@gmail.com,1700532417,Alexei Starovoitov,ast@kernel.org,1700534200,f7d2e4937e28bd7157da6815ca29fea42be3c284,ab5cfac139ab8576fb54630d4cca23c3e690ee90,"selftests/bpf: tests for iterating callbacks

A set of test cases to check behavior of callback handling logic","
check if verifier catches the following situations:
- program not safe on second callback iteration;
- program not safe on zero callback iterations;
- infinite loop inside a callback.

Verify that callback logic works for bpf_loop","[' bpf_for_each_map_elem', '\nbpf_user_ringbuf_drain', ' bpf_find_vma.\n\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20231121020701.26440-8-eddyz87@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Adds test cases for verifying callback handling logic in selftests for BPF.,"test cases, callback, iteration",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ab5cfac139ab8576fb54630d4cca23c3e690ee90,ab5cfac139ab8576fb54630d4cca23c3e690ee90,Eduard Zingerman,eddyz87@gmail.com,1700532416,Alexei Starovoitov,ast@kernel.org,1700534144,897259c37acdd692a381d54633514ca83e3aa6d3,58124a98cb8eda69d248d7f1de954c8b2767c945,"bpf: verify callbacks as if they are called unknown number of times

Prior to this patch callbacks were handled as regular function calls","
execution of callback body was modeled exactly once.
This patch updates callbacks handling logic as follows:
- introduces a function push_callback_call() that schedules callback
  body verification in env->head stack;
- updates prepare_func_exit() to reschedule callback body verification
  upon BPF_EXIT;
- as calls to bpf_*_iter_next()","[' calls to callback invoking functions\n  are marked as checkpoints;\n- is_state_visited() is updated to stop callback based iteration when\n  some identical parent state is found.\n\nPaths with callback function invoked zero times are now verified first', '\nwhich leads to necessity to modify some selftests:\n- the following negative tests required adding release/unlock/drop\n  calls to avoid previously masked unrelated error reports:\n  - cb_refs.c:underflow_prog\n  - exceptions_fail.c:reject_rbtree_add_throw\n  - exceptions_fail.c:reject_with_cp_reference\n- the following precision tracking selftests needed change in expected\n  log trace:\n  - verifier_subprog_precision.c:callback_result_precise\n    (note: r0 precision is no longer propagated inside callback and\n           I think this is a correct behavior)\n  - verifier_subprog_precision.c:parent_callee_saved_reg_precise_with_callback\n  - verifier_subprog_precision.c:parent_stack_slot_precise_with_callback\n\nReported-by: Andrew Werner <awerner32@gmail.com>\nCloses: https://lore.kernel.org/bpf/CA+vRuzPChFNXmouzGG+wsy=6eMcfr1mFG0F3g7rbg-sedGKW3w@mail.gmail.com/\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20231121020701.26440-7-eddyz87@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Update callback handling in eBPF to verify as called unknown number of times.,"callbacks, verification, bpf",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
58124a98cb8eda69d248d7f1de954c8b2767c945,58124a98cb8eda69d248d7f1de954c8b2767c945,Eduard Zingerman,eddyz87@gmail.com,1700532415,Alexei Starovoitov,ast@kernel.org,1700534015,b11131ec02dcffa6d6a53e6a0e1f3bdabc534c11,683b96f9606ab7308ffb23c46ab43cecdef8a241,"bpf: extract setup_func_entry() utility function

Move code for simulated stack frame creation to a separate utility
function. This function would be used in the follow-up change for
callbacks handling.

Acked-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20231121020701.26440-6-eddyz87@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit refactors code by extracting simulated stack frame creation to a separate utility function setup_func_entry.,"utility function, stack frame, refactoring",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
683b96f9606ab7308ffb23c46ab43cecdef8a241,683b96f9606ab7308ffb23c46ab43cecdef8a241,Eduard Zingerman,eddyz87@gmail.com,1700532414,Alexei Starovoitov,ast@kernel.org,1700534015,de0eccbd211f39fe44075f6ef5012a502735117d,f40bfd1679446b22d321e64a1fa98b7d07d2be08,"bpf: extract __check_reg_arg() utility function

Split check_reg_arg() into two utility functions:
- check_reg_arg() operating on registers from current verifier state;
- __check_reg_arg() operating on a specific set of registers passed as
  a parameter;

The __check_reg_arg() function would be used by a follow-up change for
callbacks handling.

Acked-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20231121020701.26440-5-eddyz87@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Refactors check_reg_arg into two functions for better handling of register arguments in the eBPF verifier.,"utility function,refactor,verifier",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f40bfd1679446b22d321e64a1fa98b7d07d2be08,f40bfd1679446b22d321e64a1fa98b7d07d2be08,Eduard Zingerman,eddyz87@gmail.com,1700532413,Alexei Starovoitov,ast@kernel.org,1700534015,b945d735226e100b89d9b9e39e5c0fa0f010d1ba,87eb0152bcc102ecbda866978f4e54db5a3be1ef,"selftests/bpf: fix bpf_loop_bench for new callback verification scheme

This is a preparatory change. A follow-up patch ""bpf: verify callbacks
as if they are called unknown number of times"" changes logic for
callbacks handling. While previously callbacks were verified as a
single function call"," new scheme takes into account that callbacks
could be executed unknown number of times.

This has dire implications for bpf_loop_bench:

    SEC(""fentry/"" SYS_PREFIX ""sys_getpgid"")
    int benchmark(void *ctx)
    {
            for (int i = 0; i < 1000; i++) {
                    bpf_loop(nr_loops","[' empty_callback', ' NULL', ' 0);\n                    __sync_add_and_fetch(&hits', ' nr_loops);\n            }\n            return 0;\n    }\n\nW/o callbacks change verifier sees it as a 1000 calls to\nempty_callback(). However', ' with callbacks change things become\nexponential:\n- i=0: state exploring empty_callback is scheduled with i=0 (a);\n- i=1: state exploring empty_callback is scheduled with i=1;\n  ...\n- i=999: state exploring empty_callback is scheduled with i=999;\n- state (a) is popped from stack;\n- i=1: state exploring empty_callback is scheduled with i=1;\n  ...\n\nAvoid this issue by rewriting outer loop as bpf_loop().\nUnfortunately', ' this adds a function call to a loop at runtime', ' which\nnegatively affects performance:\n\n            throughput               latency\n   before:  149.919 ± 0.168 M ops/s', ' 6.670 ns/op\n   after :  137.040 ± 0.187 M ops/s', ' 7.297 ns/op\n\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20231121020701.26440-4-eddyz87@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes bpf_loop_bench for the new callback verification mechanism in selftests.,"selftests, bpf, callback",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
87eb0152bcc102ecbda866978f4e54db5a3be1ef,87eb0152bcc102ecbda866978f4e54db5a3be1ef,Eduard Zingerman,eddyz87@gmail.com,1700532412,Alexei Starovoitov,ast@kernel.org,1700534015,25716ce657f2157c4a6fdf1dd0ecce6a1279f23b,977bc146d4eb7070118d8a974919b33bb52732b4,"selftests/bpf: track string payload offset as scalar in strobemeta

This change prepares strobemeta for update in callbacks verification
logic. To allow bpf_loop() verification converge when multiple
callback iterations are considered:
- track offset inside strobemeta_payload->payload directly as scalar
  value;
- at each iteration make sure that remaining
  strobemeta_payload->payload capacity is sufficient for execution of
  read_{map","str}_var functions;
- make sure that offset is tracked as unbound scalar between
  iterations","["" otherwise verifier won't be able infer that bpf_loop\n  callback reaches identical states.\n\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20231121020701.26440-3-eddyz87@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Track scalar offset of string payload in strobemeta for bpf_loop() iteration verification.,"strobemeta,scalar,offset",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
977bc146d4eb7070118d8a974919b33bb52732b4,977bc146d4eb7070118d8a974919b33bb52732b4,Eduard Zingerman,eddyz87@gmail.com,1700532411,Alexei Starovoitov,ast@kernel.org,1700534015,98441b21f88cf103aa0d88ba0f5c6ae3992b0d5b,fcb905d831336ee0a67dd953837a904173cf7390,"selftests/bpf: track tcp payload offset as scalar in xdp_synproxy

This change prepares syncookie_{tc","xdp} for update in callbakcs
verification logic. To allow bpf_loop() verification converge when
multiple callback itreations are considered:
- track offset inside TCP payload explicitly","[' not as a part of the\n  pointer;\n- make sure that offset does not exceed MAX_PACKET_OFF enforced by\n  verifier;\n- make sure that offset is tracked as unbound scalar between\n  iterations', "" otherwise verifier won't be able infer that bpf_loop\n  callback reaches identical states.\n\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20231121020701.26440-2-eddyz87@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Track TCP payload offset as a scalar in xdp_synproxy to improve bpf_loop() verification logic.,"tcp,payload,offset",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['xdp like programs', 'tc/netfilter like programs']"
57b97ecb40caeb116c22451bbdaaa9a1d12c0b43,57b97ecb40caeb116c22451bbdaaa9a1d12c0b43,Andrii Nakryiko,andrii@kernel.org,1700503492,Alexei Starovoitov,ast@kernel.org,1700513644,334ed292b96538b019c78471dcc594325f66025d,3e124aa6cb5e74308f5997f63ebd3e5badb5c4e7,"selftests/bpf: reduce verboseness of reg_bounds selftest logs

Reduce verboseness of test_progs' output in reg_bounds set of tests with
two changes.

First", instead of each different operator (<,"[' <=', ' >', "" ...) being it's own\nsubtest"", ' combine all different ops for the same (x', ' y', ' init_t', ' cond_t)\nvalues into single subtest. Instead of getting 6 subtests', ' we get one\ngeneric one', ' e.g.:\n\n  #192/53  reg_bounds_crafted/(s64)[0xffffffffffffffff; 0] (s64)<op> 0xffffffff00000000:OK\n\nSecond', ' for random generated test cases', "" treat all of them as a single\ntest to eliminate very verbose output with random values in them. So now\nwe'll just get one line per each combination of (init_t"", ' cond_t)', '\ninstead of 6 x 25 = 150 subtests before this change:\n\n  #225     reg_bounds_rand_consts_s32_s32:OK\n\nGiven we reduce verboseness so much', ' it makes sense to do a bit more\nrandom testing', ' so we also bump default number of random tests to 100', ""\nup from 25. This doesn't increase runtime significantly"", ' especially in\nparallelized mode.\n\nWith all the above changes we still make sure that we have all the\ninformation necessary for reproducing test case if it happens to fail.\nThat includes reporting random seed and specific operator that is\nfailing. Those will only be printed to console if related test/subtest\nfails', "" so it doesn't have any added verboseness implications.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231120180452.145849-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Reduce verbosity of reg_bounds selftest logs in bpf selftests.,"reduce verbosity,selftests,reg_bounds",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fcb905d831336ee0a67dd953837a904173cf7390,fcb905d831336ee0a67dd953837a904173cf7390,Martin KaFai Lau,martin.lau@kernel.org,1700504117,Martin KaFai Lau,martin.lau@kernel.org,1700504192,b9365cd2f303f48ceebf15bcb03b5e44fc6d735b,76df934c6d5f5c93ba7a0112b1818620ddc10b19 adfeae2d243d9e5b83d094af481d189156b11779,"Merge branch 'bpf_redirect_peer fixes'

Daniel Borkmann says:

====================
This fixes bpf_redirect_peer stats accounting for veth and netkit","
and adds tstats in the first place for the latter. Utilise indirect
call wrapper for bpf_redirect_peer","[' and improve test coverage of the\nlatter also for netkit devices. Details in the patches', ' thanks!\n\nThe series was targeted at bpf originally', ' and is done here as well', '\nso it can trigger BPF CI. Jakub', ' if you think directly going via net\nis better since the majority of the diff touches net anyway', ' that is\nfine', ' too.\n\nThanks!\n\nv2 -> v3:\n  - Add kdoc for pcpu_stat_type (Simon)\n  - Reject invalid type value in netdev_do_alloc_pcpu_stats (Simon)\n  - Add Reviewed-by tags from list\nv1 -> v2:\n  - Move stats allocation/freeing into net core (Jakub)\n  - As prepwork for the above', "" move vrf's dstats over into the core\n  - Add a check into stats alloc to enforce tstats upon\n    implementing ndo_get_peer_dev\n  - Add Acked-by tags from list\n\nDaniel Borkmann (6):\n  net"", ' vrf: Move dstats structure to core\n  net: Move {l', 't', 'd}stats allocation to core and convert veth & vrf\n  netkit: Add tstats per-CPU traffic counters\n  bpf', ' netkit: Add indirect call wrapper for fetching peer dev\n  selftests/bpf: De-veth-ize the tc_redirect test case\n  selftests/bpf: Add netkit to tc_redirect selftest\n====================\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Fixes bpf_redirect_peer stats accounting and adds tstats for veth and netkit.,"bpf_redirect_peer,veth,tstats",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
adfeae2d243d9e5b83d094af481d189156b11779,adfeae2d243d9e5b83d094af481d189156b11779,Daniel Borkmann,daniel@iogearbox.net,1699922540,Martin KaFai Lau,martin.lau@kernel.org,1700504116,b9365cd2f303f48ceebf15bcb03b5e44fc6d735b,eee82da79f036bb49ff80d3088b9530e3c2e57eb,"selftests/bpf: Add netkit to tc_redirect selftest

Extend the existing tc_redirect selftest to also cover netkit devices
for exercising the bpf_redirect_peer() code paths"," so that we have both
veth as well as netkit covered","[' all tests still pass after this change.\n\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nReviewed-by: Nikolay Aleksandrov <razor@blackwall.org>\nLink: https://lore.kernel.org/r/20231114004220.6495-9-daniel@iogearbox.net\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Extend tc_redirect selftest to include netkit devices for bpf_redirect_peer() path coverage.,"tc_redirect,selftests,netkit",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tc/netfilter like programs']
eee82da79f036bb49ff80d3088b9530e3c2e57eb,eee82da79f036bb49ff80d3088b9530e3c2e57eb,Daniel Borkmann,daniel@iogearbox.net,1699922539,Martin KaFai Lau,martin.lau@kernel.org,1700504116,9a3932c60b5b02cc4a12eaa0e89109c037b684b8,2c225425704078282e152ba692649237f78b3d7a,"selftests/bpf: De-veth-ize the tc_redirect test case

No functional changes to the test case", but just renaming various functions,"['\nvariables', ' etc', ' to remove veth part of their name for making it more generic\nand reusable later on (e.g. for netkit).\n\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nReviewed-by: Nikolay Aleksandrov <razor@blackwall.org>\nLink: https://lore.kernel.org/r/20231114004220.6495-8-daniel@iogearbox.net\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Renamed functions in the tc_redirect test case without functional changes.,"selftests,bpf,tc_redirect",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tc/netfilter like programs']
2c225425704078282e152ba692649237f78b3d7a,2c225425704078282e152ba692649237f78b3d7a,Daniel Borkmann,daniel@iogearbox.net,1699922538,Martin KaFai Lau,martin.lau@kernel.org,1700504116,4e96deef285ebb130c3d8904010d2920c81160c2,024ee930cb3c9ae49e4266aee89cfde0ebb407e1,bpf," netkit: Add indirect call wrapper for fetching peer dev

ndo_get_peer_dev is used in tcx BPF fast path","[' therefore make use of\nindirect call wrapper and therefore optimize the bpf_redirect_peer()\ninternal handling a bit. Add a small skb_get_peer_dev() wrapper which\nutilizes the INDIRECT_CALL_1() macro instead of open coding.\n\nFuture work could potentially add a peer pointer directly into struct\nnet_device in future and convert veth and netkit over to use it so\nthat eventually ndo_get_peer_dev can be removed.\n\nCo-developed-by: Nikolay Aleksandrov <razor@blackwall.org>\nSigned-off-by: Nikolay Aleksandrov <razor@blackwall.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nLink: https://lore.kernel.org/r/20231114004220.6495-7-daniel@iogearbox.net\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Add indirect call wrapper for fetching peer device in tcx BPF fast path.,"indirect, call, peer",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,['tc/netfilter like programs']
024ee930cb3c9ae49e4266aee89cfde0ebb407e1,024ee930cb3c9ae49e4266aee89cfde0ebb407e1,Peilin Ye,peilin.ye@bytedance.com,1699922537,Martin KaFai Lau,martin.lau@kernel.org,1700504116,06be9235f5eaf8e273fdaf855b488b83effb846d,6f2684bf2b4460c84d0d34612a939f78b96b03fc,"bpf: Fix dev's rx stats for bpf_redirect_peer traffic

Traffic redirected by bpf_redirect_peer() (used by recent CNIs like Cilium)
is not accounted for in the RX stats of supported devices (that is"," veth
and netkit)","[' confusing user space metrics collectors such as cAdvisor [0]', '\nas reported by Youlun.\n\nFix it by calling dev_sw_netstats_rx_add() in skb_do_redirect()', ' to update\nRX traffic counters. Devices that support ndo_get_peer_dev _must_ use the\n@tstats per-CPU counters (instead of @lstats', ' or @dstats).\n\nTo make this more fool-proof', ' error out when ndo_get_peer_dev is set but\n@tstats are not selected.\n\n  [0] Specifically', ' the ""container_network_receive_{byte', 'packet}s_total""\n      counters are affected.\n\nFixes: 9aa1206e8f48 (""bpf: Add redirect_peer helper"")\nReported-by: Youlun Zhang <zhangyoulun@bytedance.com>\nSigned-off-by: Peilin Ye <peilin.ye@bytedance.com>\nCo-developed-by: Daniel Borkmann <daniel@iogearbox.net>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Nikolay Aleksandrov <razor@blackwall.org>\nLink: https://lore.kernel.org/r/20231114004220.6495-6-daniel@iogearbox.net\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Fixes RX stats accounting for traffic redirected by bpf_redirect_peer on supported devices.,"bpf_redirect_peer,RX stats,traffic",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tc/netfilter like programs']
6f2684bf2b4460c84d0d34612a939f78b96b03fc,6f2684bf2b4460c84d0d34612a939f78b96b03fc,Peilin Ye,peilin.ye@bytedance.com,1699922536,Martin KaFai Lau,martin.lau@kernel.org,1700504116,83be66f79bbe1a74d7681580f68868a37fdccadf,ae1658272c6491a31ac968e39882fc569f312ac3,"veth: Use tstats per-CPU traffic counters

Currently veth devices use the lstats per-CPU traffic counters"," which only
cover TX traffic. veth_get_stats64() actually populates RX stats of a veth
device from its peer's TX counters","[' based on the assumption that a veth\ndevice can _only_ receive packets from its peer', ' which is no longer true:\n\nFor example', "" recent CNIs (like Cilium) can use the bpf_redirect_peer() BPF\nhelper to redirect traffic from NIC's tc ingress to veth's tc ingress (in\na different netns)"", "" skipping veth's peer device. Unfortunately"", "" this kind\nof traffic isn't currently accounted for in veth's RX stats.\n\nIn preparation for the fix"", "" use tstats (instead of lstats) to maintain\nboth RX and TX counters for each veth device. We'll use RX counters for\nbpf_redirect_peer() traffic"", ' and keep using TX counters for the usual\n""peer-to-peer"" traffic. In veth_get_stats64()', "" calculate RX stats by\n_adding_ RX count to peer's TX count"", ' in order to cover both kinds of\ntraffic.\n\nveth_stats_rx() might need a name change (perhaps to ""veth_stats_xdp()"")\nfor less confusion', "" but let's leave it to another patch to keep the fix\nminimal.\n\nSigned-off-by: Peilin Ye <peilin.ye@bytedance.com>\nCo-developed-by: Daniel Borkmann <daniel@iogearbox.net>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Nikolay Aleksandrov <razor@blackwall.org>\nLink: https://lore.kernel.org/r/20231114004220.6495-5-daniel@iogearbox.net\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n"", '']",Improve veth device traffic statistics by using tstats per-CPU counters for RX and TX.,"veth, per-CPU, traffic",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['other']
3e124aa6cb5e74308f5997f63ebd3e5badb5c4e7,3e124aa6cb5e74308f5997f63ebd3e5badb5c4e7,Alexei Starovoitov,ast@kernel.org,1700423025,Alexei Starovoitov,ast@kernel.org,1700423032,03207b5d4cbc3593a51decfb3dac6b755636f5b4,16b3129e14bf2e7505512568b11c437c840a0c19 ac8148d957f50434411a0c15a2e4f352b5bb4ff2,"Merge branch 'bpf-kernel-bpf-task_iter-c-don-t-abuse-next_thread'

Oleg Nesterov says:

====================
bpf: kernel/bpf/task_iter.c: don't abuse next_thread()

Compile tested.

Every lockless usage of next_thread() was wrong"," bpf/task_iter.c is
the last user and is no exception.

====================

Link: https://lore.kernel.org/r/20231114163211.GA874@redhat.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Fixes incorrect lockless usage of next_thread() in bpf/task_iter.c.,"bpf,task_iter,next_thread",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ac8148d957f50434411a0c15a2e4f352b5bb4ff2,ac8148d957f50434411a0c15a2e4f352b5bb4ff2,Oleg Nesterov,oleg@redhat.com,1699979559,Alexei Starovoitov,ast@kernel.org,1700423024,03207b5d4cbc3593a51decfb3dac6b755636f5b4,5a34f9dabd9aa567e2d37e1aa27a67f80acfaa1c,"bpf: bpf_iter_task_next: use next_task(kit->task) rather than next_task(kit->pos)

This looks more clear and simplifies the code. While at it"," remove the
unnecessary initialization of pos/task at the start of bpf_iter_task_new().

Note that we can even kill kit->task","[' we can just use pos->group_leader', ""\nbut I don't understand the BUILD_BUG_ON() checks in bpf_iter_task_new().\n\nSigned-off-by: Oleg Nesterov <oleg@redhat.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20231114163239.GA903@redhat.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Simplifies bpf_iter_task_next by using next_task(kit->task) and removing unnecessary initialization.,"simplifies,next_task,initialization",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
5a34f9dabd9aa567e2d37e1aa27a67f80acfaa1c,5a34f9dabd9aa567e2d37e1aa27a67f80acfaa1c,Oleg Nesterov,oleg@redhat.com,1699979557,Alexei Starovoitov,ast@kernel.org,1700423024,c070c12042571603f0516ae4a95be695cb98dc00,2d1618054f25e11c44d189dbff4a60342a4cfb4b,"bpf: bpf_iter_task_next: use __next_thread() rather than next_thread()

Lockless use of next_thread() should be avoided"," kernel/bpf/task_iter.c
is the last user and the usage is wrong.

bpf_iter_task_next() can loop forever","[' ""kit->pos == kit->task"" can never\nhappen if kit->pos execs. Change this code to use __next_thread().\n\nWith or without this change the usage of kit->pos/task and next_task()\ndoesn\'t look nice', ' see the next patch.\n\nSigned-off-by: Oleg Nesterov <oleg@redhat.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20231114163237.GA897@redhat.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit replaces next_thread() with __next_thread() in bpf_iter_task_next to prevent infinite loops.,"bpf_iter_task_next, next_thread, lockless",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2d1618054f25e11c44d189dbff4a60342a4cfb4b,2d1618054f25e11c44d189dbff4a60342a4cfb4b,Oleg Nesterov,oleg@redhat.com,1699979554,Alexei Starovoitov,ast@kernel.org,1700423024,f801475761d64aa6bdaed25a183a7cc23efbce55,16b3129e14bf2e7505512568b11c437c840a0c19,"bpf: task_group_seq_get_next: use __next_thread() rather than next_thread()

Lockless use of next_thread() should be avoided"," kernel/bpf/task_iter.c
is the last user and the usage is wrong.

task_group_seq_get_next() can return the group leader twice if it races
with mt-thread exec which changes the group->leader's pid.

Change the main loop to use __next_thread()","[' kill ""next_tid == common->pid""\ncheck.\n\n__next_thread() can\'t loop forever', ' we can also change this code to retry\nif next_tid == 0.\n\nSigned-off-by: Oleg Nesterov <oleg@redhat.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20231114163234.GA890@redhat.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit changes task_group_seq_get_next to use __next_thread() for thread iterating in BPF task iterator.,"next_thread, lockless, task_group_seq_get_next",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
16b3129e14bf2e7505512568b11c437c840a0c19,16b3129e14bf2e7505512568b11c437c840a0c19,Alexei Starovoitov,ast@kernel.org,1700336399,Alexei Starovoitov,ast@kernel.org,1700336400,c9df3007d849646ad84684b894fa8350a6d8e949,ff8867af01daa7ea770bebf5f91199b7434b74e5 46862ee854b4f5a315d63b677ca3af14a89aefeb,"Merge branch 'bpf-verifier-log-improvements'

Andrii Nakryiko says:

====================
BPF verifier log improvements

This patch set moves a big chunk of verifier log related code from gigantic
verifier.c file into more focused kernel/bpf/log.c. This is not essential to
the rest of functionality in this patch set", so I can undo it,"["" but it felt\nlike it's good to start chipping away from 20K+ verifier.c whenever we can.\n\nThe main purpose of the patch set"", ' though', "" is in improving verifier log\nfurther.\n\nPatches #3-#4 start printing out register state even if that register is\nspilled into stack slot. Previously we'd get only spilled register type"", ' but\nno additional information', "" like SCALAR_VALUE's ranges. Super limiting during\ndebugging. For cases of register spills smaller than 8 bytes"", ' we also print\nout STACK_MISC/STACK_ZERO/STACK_INVALID markers. This', ' among other things', '\nwill make it easier to write tests for these mixed spill/misc cases.\n\nPatch #5 prints map name for PTR_TO_MAP_VALUE/PTR_TO_MAP_KEY/CONST_PTR_TO_MAP\nregisters. In big production BPF programs', "" it's important to map assembly to\nactual map"", "" and it's often non-trivial. Having map name helps.\n\nPatch #6 just removes visual noise in form of ubiquitous imm=0 and off=0. They\nare default values"", ' omit them.\n\nPatch #7 is probably the most controversial', ' but it reworks how verifier log\nprints numbers. For small valued integers we use decimals', ' but for large ones\nwe switch to hexadecimal. From personal experience this is a much more useful\nconvention. We can tune what consitutes ""small value""', "" for now it's 16-bit\nrange.\n\nPatch #8 prints frame number for PTR_TO_CTX registers"", ' if that frame is\ndifferent from the ""current"" one. This removes ambiguity and confusion', '\nespecially in complicated cases with multiple subprogs passing around\npointers.\n\nv2->v3:\n  - adjust reg_bounds tester to parse hex form of reg state as well;\n  - print reg->range as unsigned (Alexei);\nv1->v2:\n  - use verbose_snum() for range and offset in register state (Eduard);\n  - fixed typos and added acks from Eduard and Stanislav.\n====================\n\nLink: https://lore.kernel.org/r/20231118034623.3320920-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Refactor verifier logs into separate log.c file for better code organization.,"verifier, log, refactor",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
46862ee854b4f5a315d63b677ca3af14a89aefeb,46862ee854b4f5a315d63b677ca3af14a89aefeb,Andrii Nakryiko,andrii@kernel.org,1700279183,Alexei Starovoitov,ast@kernel.org,1700336399,c9df3007d849646ad84684b894fa8350a6d8e949,0f8dbdbc641b45a5fa31d497f9fc83ffe1174fa3,"bpf: emit frameno for PTR_TO_STACK regs if it differs from current one

It's possible to pass a pointer to parent's stack to child subprogs. In
such case verifier state output is ambiguous not showing whether
register container a pointer to ""current"" stack"," belonging to current
subprog (frame)","["" or it's actually a pointer to one of parent frames.\n\nSo emit this information if frame number differs between the state which\nregister is part of. E.g."", ' if current state is in frame 2 and it has\na register pointing to stack in grand parent state (frame #0)', "" we'll see\nsomething like 'R1=fp[0]-16'"", ' while ""local stack pointer"" will be just\n\'R2=fp-16\'.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231118034623.3320920-9-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Emit frame number for PTR_TO_STACK registers when it differs from the current frame in eBPF verifier.,"PTR_TO_STACK,verifier,frame",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0f8dbdbc641b45a5fa31d497f9fc83ffe1174fa3,0f8dbdbc641b45a5fa31d497f9fc83ffe1174fa3,Andrii Nakryiko,andrii@kernel.org,1700279182,Alexei Starovoitov,ast@kernel.org,1700336399,61c1b84c3d0a9bf8c43a17438d126b24d53cbd8c,1db747d75b1dbe17bf4283ed87bd3b7a92010f34,"bpf: smarter verifier log number printing logic

Instead of always printing numbers as either decimals (and in some
cases"," like for ""imm=%llx""","[' in hexadecimals)', ' decide the form based on\nactual values. For numbers in a reasonably small range (currently', '\n[0', ' U16_MAX] for unsigned values', ' and [S16_MIN', ' S16_MAX] for signed ones)', '\nemit them as decimals. In all other cases', ' even for signed values', ""\nemit them in hexadecimals.\n\nFor large values hex form is often times way more useful: it's easier to\nsee an exact difference between 0xffffffff80000000 and 0xffffffff7fffffff"", '\nthan between 18446744071562067966 and 18446744071562067967', ' as one\nparticular example.\n\nSmall values representing small pointer offsets or application\nconstants', ' on the other hand', ' are way more useful to be represented in\ndecimal notation.\n\nAdjust reg_bounds register state parsing logic to take into account this\nchange.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231118034623.3320920-8-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Improve verifier log number printing logic for better readability and understanding.,"verifier,log,printing",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1db747d75b1dbe17bf4283ed87bd3b7a92010f34,1db747d75b1dbe17bf4283ed87bd3b7a92010f34,Andrii Nakryiko,andrii@kernel.org,1700279181,Alexei Starovoitov,ast@kernel.org,1700336399,d266e1595982f440d336448b39d0a3c26974ea6a,0c95c9fdb696f35c7864785ba84cb9a50152daff,"bpf: omit default off=0 and imm=0 in register state log

Simplify BPF verifier log further by omitting default (and frequently
irrelevant) off=0 and imm=0 parts for non-SCALAR_VALUE registers. As can
be seen from fixed tests"," this is often a visual noise for PTR_TO_CTX
register and even for PTR_TO_PACKET registers.

Omitting default values follows the rest of register state logic: we
omit default values to keep verifier log succinct and to highlight
interesting state that deviates from default one. E.g.","[' we do the same\nfor var_off', "" when it's unknown"", ' which gives no additional information.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231118034623.3320920-7-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Simplified BPF verifier log by omitting default off=0 and imm=0 for non-SCALAR_VALUE registers.,"BPF verifier, default, registers",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0c95c9fdb696f35c7864785ba84cb9a50152daff,0c95c9fdb696f35c7864785ba84cb9a50152daff,Andrii Nakryiko,andrii@kernel.org,1700279180,Alexei Starovoitov,ast@kernel.org,1700336399,909fcb7acbc43862d80a67c68c62e4b41b09b16d,67d43dfbb42d6575304daea67733c88fbf536a1c,"bpf: emit map name in register state if applicable and available

In complicated real-world applications"," whenever debugging some
verification error through verifier log","[' it often would be very useful\nto see map name for PTR_TO_MAP_VALUE register. Usually this needs to be\ninferred from key/value sizes and maybe trying to guess C code location', ""\nbut it's not always clear.\n\nGiven verifier has the name"", "" and it's never too long"", "" let's just emit it\nfor ptr_to_map_key"", ' ptr_to_map_value', ' and const_ptr_to_map registers. We\nreshuffle the order a bit', ' so that map name', ' key size', ' and value size\nappear before offset and immediate values', ' which seems like a more\nlogical order.\n\nCurrent output:\n\n  R1_w=map_ptr(map=array_map', 'ks=4', 'vs=8', 'off=0', ""imm=0)\n\nBut we'll get rid of useless off=0 and imm=0 parts in the next patch.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231118034623.3320920-6-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Emit the map name in the register state for better debugging in verifier logs.,"map name, register state, verifier",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
67d43dfbb42d6575304daea67733c88fbf536a1c,67d43dfbb42d6575304daea67733c88fbf536a1c,Andrii Nakryiko,andrii@kernel.org,1700279179,Alexei Starovoitov,ast@kernel.org,1700336399,0d7c2a45e9b36277fa9e1b6f0b09f5735b74617d,009f5465be3636e9ce795cfbd5d3109d8978774d,"bpf: print spilled register state in stack slot

Print the same register state representation when printing stack state","
as we do for normal registers. Note that if stack slot contains
subregister spill (1","[' 2', ' or 4 byte long)', ' we\'ll still emit ""m0?"" mask\nfor those bytes that are not part of spilled register.\n\nWhile means we can get something like fp-8=0000scalar() for a 4-byte\nspill with other 4 bytes still being STACK_ZERO.\n\nSome example before and after', ' taken from the log of\npyperf_subprogs.bpf.o:\n\n49: (7b) *(u64 *)(r10 -256) = r1      ; frame1: R1_w=ctx(off=0', 'imm=0) R10=fp0 fp-256_w=ctx\n49: (7b) *(u64 *)(r10 -256) = r1      ; frame1: R1_w=ctx(off=0', 'imm=0) R10=fp0 fp-256_w=ctx(off=0', 'imm=0)\n\n150: (7b) *(u64 *)(r10 -264) = r0     ; frame1: R0_w=map_value_or_null(id=6', 'off=0', 'ks=192', 'vs=4', 'imm=0) R10=fp0 fp-264_w=map_value_or_null\n150: (7b) *(u64 *)(r10 -264) = r0     ; frame1: R0_w=map_value_or_null(id=6', 'off=0', 'ks=192', 'vs=4', 'imm=0) R10=fp0 fp-264_w=map_value_or_null(id=6', 'off=0', 'ks=192', 'vs=4', 'imm=0)\n\n5192: (61) r1 = *(u32 *)(r10 -272)    ; frame1: R1_w=scalar(smin=smin32=0', 'smax=umax=smax32=umax32=15', 'var_off=(0x0; 0xf)) R10=fp0 fp-272=\n5192: (61) r1 = *(u32 *)(r10 -272)    ; frame1: R1_w=scalar(smin=smin32=0', 'smax=umax=smax32=umax32=15', 'var_off=(0x0; 0xf)) R10=fp0 fp-272=????scalar(smin=smin32=0', 'smax=umax=smax32=umax32=15', 'var_off=(0x0; 0xf))\n\nWhile at it', ' do a few other simple clean ups:\n  - skip slot if it\'s not scratched before detecting whether it\'s valid;\n  - move taking spilled_reg pointer outside of switch (only DYNPTR has\n    to adjust that to get to the ""main"" slot);\n  - don\'t recalculate types_buf second time for MISC/ZERO/default case.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231118034623.3320920-5-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Improve stack slot state printing in bpf to match register state representation.,"register, printing, stack",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
009f5465be3636e9ce795cfbd5d3109d8978774d,009f5465be3636e9ce795cfbd5d3109d8978774d,Andrii Nakryiko,andrii@kernel.org,1700279178,Alexei Starovoitov,ast@kernel.org,1700336399,002d13a634eec591e43f86ef1c86db862dd26eec,42feb6620accded89cad5f455665e21281813d79,"bpf: extract register state printing

Extract printing register state representation logic into a separate
helper"," as we are going to reuse it for spilled register state printing
in the next patch. This also nicely reduces code nestedness.

No functional changes.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Acked-by: Stanislav Fomichev <sdf@google.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231118034623.3320920-4-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Extract register state printing logic into a helper for reuse and code clarity.,"printing, helper, state",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
42feb6620accded89cad5f455665e21281813d79,42feb6620accded89cad5f455665e21281813d79,Andrii Nakryiko,andrii@kernel.org,1700279177,Alexei Starovoitov,ast@kernel.org,1700336399,10e86130a1ca8f75d94808db3f03ca7d14e06749,db840d389bad60ce6f3aadc1079da13e7e993a16,"bpf: move verifier state printing code to kernel/bpf/log.c

Move a good chunk of code from verifier.c to log.c: verifier state
verbose printing logic. This is an important and very much
logging/debugging oriented code. It fits the overlall log.c's focus on
verifier logging"," and moving it allows to keep growing it without
unnecessarily adding to verifier.c code that otherwise contains a core
verification logic.

There are not many shared dependencies between this code and the rest of
verifier.c code","[' except a few single-line helpers for various register\ntype checks and a bit of state ""scratching"" helpers. We move all such\ntrivial helpers into include/bpf/bpf_verifier.h as static inlines.\n\nNo functional changes in this patch.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231118034623.3320920-3-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Refactor verifier state verbose printing logic from verifier.c to log.c to improve focus on verifier logging without adding complexity.,"verifier, logging, refactor",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
db840d389bad60ce6f3aadc1079da13e7e993a16,db840d389bad60ce6f3aadc1079da13e7e993a16,Andrii Nakryiko,andrii@kernel.org,1700279176,Alexei Starovoitov,ast@kernel.org,1700336398,e9a49caa3606ba2d29c27cc6fc891be2b1656187,ff8867af01daa7ea770bebf5f91199b7434b74e5,"bpf: move verbose_linfo() into kernel/bpf/log.c

verifier.c is huge. Let's try to move out parts that are logging-related
into log.c"," as we previously did with bpf_log() and other related stuff.
This patch moves line info verbose output routines: it's pretty
self-contained and isolated code","[' so there is no problem with this.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231118034623.3320920-2-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Moved verbose logging functions from verifier.c to log.c to reduce file size.,"verbose logging, log, bpf",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ff8867af01daa7ea770bebf5f91199b7434b74e5,ff8867af01daa7ea770bebf5f91199b7434b74e5,Andrii Nakryiko,andrii@kernel.org,1700241244,Alexei Starovoitov,ast@kernel.org,1700245802,d298636c0a548e3c27bc8c18a645745f456c4fa2,5fa201f37c2ef58a0f821e656d794af89b3a1738,"bpf: rename BPF_F_TEST_SANITY_STRICT to BPF_F_TEST_REG_INVARIANTS

Rename verifier internal flag BPF_F_TEST_SANITY_STRICT to more neutral
BPF_F_TEST_REG_INVARIANTS. This is a follow up to [0].

A few selftests and veristat need to be adjusted in the same patch as
well.

  [0] https://patchwork.kernel.org/project/netdevbpf/patch/20231112010609.848406-5-andrii@kernel.org/

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231117171404.225508-1-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The commit renames an internal verifier flag and updates related selftests and veristat.,"rename, verifier, flag",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e9cdebbe23f1aa9a1caea169862f479ab3fa2773,e9cdebbe23f1aa9a1caea169862f479ab3fa2773,Jordan Rife,jrife@google.com,1699305878,David Teigland,teigland@redhat.com,1700157522,b27945908a655317eb50fbb3b459dc45b63eb686,b85ea95d086471afb4ad062012a4d73cd328fa86,"dlm: use kernel_connect() and kernel_bind()

Recent changes to kernel_connect() and kernel_bind() ensure that
callers are insulated from changes to the address parameter made by BPF
SOCK_ADDR hooks. This patch wraps direct calls to ops->connect() and
ops->bind() with kernel_connect() and kernel_bind() to protect callers
in such cases.

Link: https://lore.kernel.org/netdev/9944248dba1bce861375fcce9de663934d933ba9.camel@redhat.com/
Fixes: d74bad4e74ee (""bpf: Hooks for sys_connect"")
Fixes: 4fbac77d2d09 (""bpf: Hooks for sys_bind"")
Cc: stable@vger.kernel.org
Signed-off-by: Jordan Rife <jrife@google.com>
Signed-off-by: David Teigland <teigland@redhat.com>
",,Wraps direct calls to connect and bind operations with kernel_connect and kernel_bind for address parameter protection.,"kernel_connect,kernel_bind,BPF",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['socket like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7475e51b87969e01a6812eac713a1c8310372e8a,7475e51b87969e01a6812eac713a1c8310372e8a,Linus Torvalds,torvalds@linux-foundation.org,1700139086,Linus Torvalds,torvalds@linux-foundation.org,1700139086,350f6dcea18fb09fdb70179e8e7ae3e40d470896,6eb1acd9766a0dc9d85927843d85787408395e15 cff088d924df871296412e6b819823f42d1bb9a5,"Merge tag 'net-6.7-rc2' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Paolo Abeni:
 ""Including fixes from BPF and netfilter.

  Current release - regressions:

   - core: fix undefined behavior in netdev name allocation

   - bpf: do not allocate percpu memory at init stage

   - netfilter: nf_tables: split async and sync catchall in two
     functions

   - mptcp: fix possible NULL pointer dereference on close

  Current release - new code bugs:

   - eth: ice: dpll: fix initial lock status of dpll

  Previous releases - regressions:

   - bpf: fix precision backtracking instruction iteration

   - af_unix: fix use-after-free in unix_stream_read_actor()

   - tipc: fix kernel-infoleak due to uninitialized TLV value

   - eth: bonding: stop the device in bond_setup_by_slave()

   - eth: mlx5:
      - fix double free of encap_header
      - avoid referencing skb after free-ing in drop path

   - eth: hns3: fix VF reset

   - eth: mvneta: fix calls to page_pool_get_stats

  Previous releases - always broken:

   - core: set SOCK_RCU_FREE before inserting socket into hashtable

   - bpf: fix control-flow graph checking in privileged mode

   - eth: ppp: limit MRU to 64K

   - eth: stmmac: avoid rx queue overrun

   - eth: icssg-prueth: fix error cleanup on failing initialization

   - eth: hns3: fix out-of-bounds access may occur when coalesce info is
     read via debugfs

   - eth: cortina: handle large frames

  Misc:

   - selftests: gso: support CONFIG_MAX_SKB_FRAGS up to 45""

* tag 'net-6.7-rc2' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (78 commits)
  macvlan: Don't propagate promisc change to lower dev in passthru
  net: sched: do not offload flows with a helper in act_ct
  net/mlx5e: Check return value of snprintf writing to fw_version buffer for representors
  net/mlx5e: Check return value of snprintf writing to fw_version buffer
  net/mlx5e: Reduce the size of icosq_str
  net/mlx5: Increase size of irq name buffer
  net/mlx5e: Update doorbell for port timestamping CQ before the software counter
  net/mlx5e: Track xmit submission to PTP WQ after populating metadata map
  net/mlx5e: Avoid referencing skb after free-ing in drop path of mlx5e_sq_xmit_wqe
  net/mlx5e: Don't modify the peer sent-to-vport rules for IPSec offload
  net/mlx5e: Fix pedit endianness
  net/mlx5e: fix double free of encap_header in update funcs
  net/mlx5e: fix double free of encap_header
  net/mlx5: Decouple PHC .adjtime and .adjphase implementations
  net/mlx5: DR"," Allow old devices to use multi destination FTE
  net/mlx5: Free used cpus mask when an IRQ is released
  Revert ""net/mlx5: DR","[' Supporting inline WQE when possible""\n  bpf: Do not allocate percpu memory at init stage\n  net: Fix undefined behavior in netdev name allocation\n  dt-bindings: net: ethernet-controller: Fix formatting error\n  ...\n', '']","This commit merges networking fixes including BPF, netfilter, and other network driver issues.","networking, fixes, BPF",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a6a6a0a9fdb03af10513b5bb48e5419563f54413,a6a6a0a9fdb03af10513b5bb48e5419563f54413,Jakub Kicinski,kuba@kernel.org,1700116082,Jakub Kicinski,kuba@kernel.org,1700116082,08f030e7683a615060f4e43f86f6f508d73018e4,674e318089468ece99aef4796eaef7add57f36b2 1fda5bb66ad8fb24ecb3858e61a13a6548428898,"Merge https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Alexei Starovoitov says:

====================
pull-request: bpf 2023-11-15

We've added 7 non-merge commits during the last 6 day(s) which contain
a total of 9 files changed", 200 insertions(+),"[' 49 deletions(-).\n\nThe main changes are:\n\n1) Do not allocate bpf specific percpu memory unconditionally', ' from Yonghong.\n\n2) Fix precision backtracking instruction iteration', ' from Andrii.\n\n3) Fix control flow graph checking', ' from Andrii.\n\n4) Fix xskxceiver selftest build', ' from Anders.\n\n* https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  bpf: Do not allocate percpu memory at init stage\n  selftests/bpf: add more test cases for check_cfg()\n  bpf: fix control-flow graph checking in privileged mode\n  selftests/bpf: add edge case backtracking logic test\n  bpf: fix precision backtracking instruction iteration\n  bpf: handle ldimm64 properly in check_cfg()\n  selftests: bpf: xskxceiver: ksft_print_msg: fix format type error\n====================\n\nLink: https://lore.kernel.org/r/20231115214949.48854-1-alexei.starovoitov@gmail.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Merge pull request integrating 7 non-merge commits into BPF tree.,"merge,BPF,commits",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5fa201f37c2ef58a0f821e656d794af89b3a1738,5fa201f37c2ef58a0f821e656d794af89b3a1738,Puranjay Mohan,puranjay12@gmail.com,1699638710,Alexei Starovoitov,ast@kernel.org,1700081187,5e9c2c4777548cfeb8e111d7f71b6729b0be4284,9cea90c01f4bddfb4cea12a9c23eef6414714503,"bpf: Remove test for MOVSX32 with offset=32

MOVSX32 only supports sign extending 8-bit and 16-bit operands into 32
bit operands. The ""ALU_MOVSX | BPF_W"" test tries to sign extend a 32 bit
operand into a 32 bit operand which is equivalent to a normal BPF_MOV.

Remove this test as it tries to run an invalid instruction.

Fixes: daabb2b098e0 (""bpf/tests: add tests for cpuv4 instructions"")
Signed-off-by: Puranjay Mohan <puranjay12@gmail.com>
Reported-by: kernel test robot <oliver.sang@intel.com>
Closes: https://lore.kernel.org/oe-lkp/202310111838.46ff5b6a-oliver.sang@intel.com
Acked-by: Stanislav Fomichev <sdf@google.com>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20231110175150.87803-1-puranjay12@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Removed a test for an invalid MOVSX32 instruction with offset in BPF.,"MOVSX32, test, invalid",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9cea90c01f4bddfb4cea12a9c23eef6414714503,9cea90c01f4bddfb4cea12a9c23eef6414714503,Alexei Starovoitov,ast@kernel.org,1700078623,Alexei Starovoitov,ast@kernel.org,1700078623,53c9ef81ba24ac689a43f5309b6b4630df2eaefd,81427a62a22148cdc85db38a6fbe487d0d2044b6 882e3d873c2d8a2aebbc6c192aa1a2990b9d5b27,"Merge branch 'bpf-register-bounds-range-vs-range-support'

Andrii Nakryiko says:

====================
BPF register bounds range vs range support

This patch set is a continuation of work started in [0]. It adds a big set of
manual", auto-generated,"["" and now also random test cases validating BPF\nverifier's register bounds tracking and deduction logic.\n\nFirst few patches generalize verifier's logic to handle conditional jumps and\ncorresponding range adjustments in case when two non-const registers are\ncompared to each other. Patch #1 generalizes reg_set_min_max() portion"", ' while\npatch #2 does the same for is_branch_taken() part of the overall solution.\n\nPatch #3 improves equality and inequality for cases when BPF program code\nmixes 64-bit and 32-bit uses of the same register. Depending on specific\nsequence', "" it's possible to get to the point where u64/s64 bounds will be very\ngeneric (e.g."", ' after signed 32-bit comparison)', ' while we still keep pretty\ntight u32/s32 bounds. If in such state we proceed with 32-bit equality or\ninequality comparison', "" reg_set_min_max() might have to deal with adjusting s32\nbounds for two registers that don't overlap"", "" which breaks reg_set_min_max().\nThis doesn't manifest in <range> vs <const> cases"", ' because if that happens\nreg_set_min_max() in effect will force s32 bounds to be a new ""impossible""\nconstant (from original smin32/smax32 bounds point of view). Things get tricky\nwhen we have <range> vs <range> adjustments', ' so instead of trying to somehow\nmake sense out of such situations', "" it's best to detect such impossible\nsituations and prune the branch that can't be taken in is_branch_taken()\nlogic.  This equality/inequality was the only such category of situations with\nauto-generated tests added later in the patch set.\n\nBut when we start mixing arithmetic operations in different numeric domains\nand conditionals"", ' things get even hairier. So', ' patch #4 adds sanity checking\nlogic after all ALU/ALU64', ' JMP/JMP32', ' and LDX operations. By default', ' instead\nof failing verification', ' we conservatively reset range bounds to unknown\nvalues', ' reporting violation in verifier log (if verbose logs are requested).\nBut to aid development', ' detection', ' and debugging', ' we also introduce a new test\nflag', ' BPF_F_TEST_SANITY_STRICT', ' which triggers verification failure on range\nsanity violation.\n\nPatch #11 sets BPF_F_TEST_SANITY_STRICT by default for test_progs and\ntest_verifier. Patch #12 adds support for controlling this in veristat for\ntesting with production BPF object files.\n\nGetting back to BPF verifier', "" patches #5 and #6 complete verifier's range\ntracking logic clean up. See respective patches for details.\n\nWith kernel-side taken care of"", ' we move to testing. We start with building\na tester that validates existing <range> vs <scalar> verifier logic for range\nbounds. Patch #7 implements an initial version of such a tester. We guard\nmillions of generated tests behind SLOW_TESTS=1 envvar requirement', ' but also\nhave a relatively small number of tricky cases that came up during development\nand debugging of this work. Those will be executed as part of a normal\ntest_progs run.\n\nPatch #8 simulates more nuanced JEQ/JNE logic we added to verifier in patch #3.\nPatch #9 adds <range> vs <range> ""slow tests"".\n\nPatch #10 is a completely new one', ' it adds a bunch of randomly generated cases\nto be run normally', ' without SLOW_TESTS=1 guard. This should help to get\na bunch of cover', ' and hopefully find some remaining latent problems if\nverifier proactively as part of normal BPF CI runs.\n\nFinally', ' a tiny test which was', ' amazingly', ' an initial motivation for this\nwhole work', ' is added in lucky patch #13', "" demonstrating how verifier is now\nsmart enough to track actual number of elements in the array and won't require\nadditional checks on loop iteration variable inside the bpf_for() open-coded\niterator loop.\n\n  [0] https://patchwork.kernel.org/project/netdevbpf/list/?series=798308&state=*\n\nv1->v2:\n  - use x < y => y > x property to minimize reg_set_min_max (Eduard);\n  - fix for JEQ/JNE logic in reg_bounds.c (Eduard);\n  - split BPF_JSET and !BPF_JSET cases handling (Shung-Hsi);\n  - adjustments to reg_bounds.c to make it easier to follow (Alexei);\n  - added acks (Eduard"", ' Shung-Hsi).\n====================\n\nLink: https://lore.kernel.org/r/20231112010609.848406-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Merges changes related to BPF register bounds and range support.,"register bounds,range support,merge",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
882e3d873c2d8a2aebbc6c192aa1a2990b9d5b27,882e3d873c2d8a2aebbc6c192aa1a2990b9d5b27,Andrii Nakryiko,andrii@kernel.org,1699751169,Alexei Starovoitov,ast@kernel.org,1700078623,53c9ef81ba24ac689a43f5309b6b4630df2eaefd,a5c57f81eb2b5d6de4f46e47fd85be50d179bfd8,"selftests/bpf: add iter test requiring range x range logic

Add a simple verifier test that requires deriving reg bounds for one
register from another register that's not a constant. This is
a realistic example of iterating elements of an array with fixed maximum
number of elements"," but smaller actual number of elements.

This small example was an original motivation for doing this whole patch
set in the first place","[' yes.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231112010609.848406-14-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add a verifier test for range x range logic in selftests for BPF.,"verifier,test,selftests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8c5677f8b31e92b57be7d5d0fbb1ac66eedf4f91,8c5677f8b31e92b57be7d5d0fbb1ac66eedf4f91,Andrii Nakryiko,andrii@kernel.org,1699751167,Alexei Starovoitov,ast@kernel.org,1700078622,411aa72cc5b0e5744fc11a1b7dee8b7bcc2f8d21,dab16659c50e8c9c7c5d9584beacec28c769dcca,"selftests/bpf: set BPF_F_TEST_SANITY_SCRIPT by default

Make sure to set BPF_F_TEST_SANITY_STRICT program flag by default across
most verifier tests (and a bunch of others that set custom prog flags).

There are currently two tests that do fail validation"," if enforced
strictly: verifier_bounds/crossing_64_bit_signed_boundary_2 and
verifier_bounds/crossing_32_bit_signed_boundary_2. To accommodate them","['\nwe teach test_loader a flag negation:\n\n__flag(!<flagname>) will *clear* specified flag', ' allowing easy opt-out.\n\nWe apply __flag(!BPF_F_TEST_SANITY_STRICT) to these to tests.\n\nAlso sprinkle BPF_F_TEST_SANITY_STRICT everywhere where we already set\ntest-only BPF_F_TEST_RND_HI32 flag', ' for completeness.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231112010609.848406-12-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']","Default BPF_F_TEST_SANITY_STRICT flag across most verifier tests, except for two specific cases.","verifier, tests, flag",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
dab16659c50e8c9c7c5d9584beacec28c769dcca,dab16659c50e8c9c7c5d9584beacec28c769dcca,Andrii Nakryiko,andrii@kernel.org,1699751166,Alexei Starovoitov,ast@kernel.org,1700078622,dfa59728581e7002275803c164274e5f3e735580,2b0d204e368b306d4db894749947ed591b667ec5,"selftests/bpf: add randomized reg_bounds tests

Add random cases generation to reg_bounds.c and run them without
SLOW_TESTS=1 to increase a chance of BPF CI catching latent issues.

Suggested-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231112010609.848406-11-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add randomized test case generation to reg_bounds.c for better BPF CI coverage.,"randomized,reg_bounds,tests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2b0d204e368b306d4db894749947ed591b667ec5,2b0d204e368b306d4db894749947ed591b667ec5,Andrii Nakryiko,andrii@kernel.org,1699751165,Alexei Starovoitov,ast@kernel.org,1700078622,945d7b212d428d0d4100a89db98f5d8db96849b1,774f94c5e74d86d554c4fd1e97c517a1a7ee7fe0,"selftests/bpf: add range x range test to reg_bounds

Now that verifier supports range vs range bounds adjustments"," validate
that by checking each generated range against every other generated
range","["" across all supported operators (everything by JSET).\n\nWe also add few cases that were problematic during development either\nfor verifier or for selftest's range tracking implementation.\n\nNote that we utilize the same trick with splitting everything into\nmultiple independent parallelizable tests"", ' but init_t and cond_t. This\nbrings down verification time in parallel mode from more than 8 hours\ndown to less that 1.5 hours. 106 million cases were successfully\nvalidate for range vs range logic', ' in addition to about 7 million range\nvs const cases', ' added in earlier patch.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231112010609.848406-10-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Added a new range x range test case for reg_bounds in selftests to verify new verifier support.,"range,test,verifier",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
774f94c5e74d86d554c4fd1e97c517a1a7ee7fe0,774f94c5e74d86d554c4fd1e97c517a1a7ee7fe0,Andrii Nakryiko,andrii@kernel.org,1699751164,Alexei Starovoitov,ast@kernel.org,1700078622,b7a6bc96ec3eea83c9cd15bb719d98e1ae34483e,8863238993e23ccc6d5a9d4ff9f1c043f88f692e,"selftests/bpf: adjust OP_EQ/OP_NE handling to use subranges for branch taken

Similar to kernel-side BPF verifier logic enhancements"," use 32-bit
subrange knowledge for is_branch_taken() logic in reg_bounds selftests.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20231112010609.848406-9-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Adjusted BPF selftests to use subrange logic for branch conditions similar to kernel verifier.,"BPF selftests, subrange logic, verifier",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8863238993e23ccc6d5a9d4ff9f1c043f88f692e,8863238993e23ccc6d5a9d4ff9f1c043f88f692e,Andrii Nakryiko,andrii@kernel.org,1699751163,Alexei Starovoitov,ast@kernel.org,1700078622,465cff98a7ef8c4cd681b44cad142ca035b66b32,cf5fe3c71c5a34ac0108afc550407c672d0a032d,"selftests/bpf: BPF register range bounds tester

Add test to validate BPF verifier's register range bounds tracking logic.

The main bulk is a lot of auto-generated tests based on a small set of
seed values for lower and upper 32 bits of full 64-bit values.
Currently we validate only range vs const comparisons"," but the idea is
to start validating range over range comparisons in subsequent patch set.

When setting up initial register ranges we treat registers as one of
u64/s64/u32/s32 numeric types","[' and then independently perform conditional\ncomparisons based on a potentially different u64/s64/u32/s32 types. This\ntests lots of tricky cases of deriving bounds information across\ndifferent numeric domains.\n\nGiven there are lots of auto-generated cases', ' we guard them behind\nSLOW_TESTS=1 envvar requirement', ' and skip them altogether otherwise.\nWith current full set of upper/lower seed value', ' all supported\ncomparison operators and all the combinations of u64/s64/u32/s32 number\ndomains', ' we get about 7.7 million tests', ' which run in about 35 minutes\non my local qemu instance without parallelization. But we also split\nthose tests by init/cond numeric types', "" which allows to rely on\ntest_progs's parallelization of tests with `-j` option"", "" getting run time\ndown to about 5 minutes on 8 cores. It's still something that shouldn't\nbe run during normal test_progs run.  But we can run it a reasonable\ntime"", ' and so perhaps a nightly CI test run (once we have it) would be\na good option for this.\n\nWe also add a small set of tricky conditions that came up during\ndevelopment and triggered various bugs or corner cases in either\nselftest\'s reimplementation of range bounds logic or in verifier\'s logic\nitself. These are fast enough to be run as part of normal test_progs\ntest run and are great for a quick sanity checking.\n\nLet\'s take a look at test output to understand what\'s going on:\n\n  $ sudo ./test_progs -t reg_bounds_crafted\n  #191/1   reg_bounds_crafted/(u64)[0; 0xffffffff] (u64)< 0:OK\n  ...\n  #191/115 reg_bounds_crafted/(u64)[0; 0x17fffffff] (s32)< 0:OK\n  ...\n  #191/137 reg_bounds_crafted/(u64)[0xffffffff; 0x100000000] (u64)== 0:OK\n\nEach test case is uniquely and fully described by this generated string.\nE.g.: ""(u64)[0; 0x17fffffff] (s32)< 0"". This means that we\ninitialize a register (R6) in such a way that verifier knows that it can\nhave a value in [(u64)0; (u64)0x17fffffff] range. Another\nregister (R7) is also set up as u64', "" but this time a constant (zero in\nthis case). They then are compared using 32-bit signed < operation.\nResulting TRUE/FALSE branches are evaluated (including cases where it's\nknown that one of the branches will never be taken"", "" in which case we\nvalidate that verifier also determines this as a dead code). Test\nvalidates that verifier's final register state matches expected state\nbased on selftest's own reg_state logic"", ' implemented from scratch for\ncross-checking purposes.\n\nThese test names can be conveniently used for further debugging', ' and if -vv\nverboseness is requested we can get a corresponding verifier log (with\nmark_precise logs filtered out as irrelevant and distracting). Example below is\nslightly redacted for brevity', ' omitting irrelevant register output in\nsome places', "" marked with [...].\n\n  $ sudo ./test_progs -a 'reg_bounds_crafted/(u32)[0; U32_MAX] (s32)< -1' -vv\n  ...\n  VERIFIER LOG:\n  ========================\n  func#0 @0\n  0: R1=ctx(off=0"", 'imm=0) R10=fp0\n  0: (05) goto pc+2\n  3: (85) call bpf_get_current_pid_tgid#14      ; R0_w=scalar()\n  4: (bc) w6 = w0                       ; R0_w=scalar() R6_w=scalar(smin=0', 'smax=umax=4294967295', 'var_off=(0x0; 0xffffffff))\n  5: (85) call bpf_get_current_pid_tgid#14      ; R0_w=scalar()\n  6: (bc) w7 = w0                       ; R0_w=scalar() R7_w=scalar(smin=0', 'smax=umax=4294967295', 'var_off=(0x0; 0xffffffff))\n  7: (b4) w1 = 0                        ; R1_w=0\n  8: (b4) w2 = -1                       ; R2=4294967295\n  9: (ae) if w6 < w1 goto pc-9\n  9: R1=0 R6=scalar(smin=0', 'smax=umax=4294967295', 'var_off=(0x0; 0xffffffff))\n  10: (2e) if w6 > w2 goto pc-10\n  10: R2=4294967295 R6=scalar(smin=0', 'smax=umax=4294967295', 'var_off=(0x0; 0xffffffff))\n  11: (b4) w1 = -1                      ; R1_w=4294967295\n  12: (b4) w2 = -1                      ; R2_w=4294967295\n  13: (ae) if w7 < w1 goto pc-13        ; R1_w=4294967295 R7=4294967295\n  14: (2e) if w7 > w2 goto pc-14\n  14: R2_w=4294967295 R7=4294967295\n  15: (bc) w0 = w6                      ; [...] R6=scalar(id=1', 'smin=0', 'smax=umax=4294967295', 'var_off=(0x0; 0xffffffff))\n  16: (bc) w0 = w7                      ; [...] R7=4294967295\n  17: (ce) if w6 s< w7 goto pc+3        ; R6=scalar(id=1', 'smin=0', 'smax=umax=4294967295', 'smin32=-1', 'var_off=(0x0; 0xffffffff)) R7=4294967295\n  18: (bc) w0 = w6                      ; [...] R6=scalar(id=1', 'smin=0', 'smax=umax=4294967295', 'smin32=-1', 'var_off=(0x0; 0xffffffff))\n  19: (bc) w0 = w7                      ; [...] R7=4294967295\n  20: (95) exit\n\n  from 17 to 21: [...]\n  21: (bc) w0 = w6                      ; [...] R6=scalar(id=1', 'smin=umin=umin32=2147483648', 'smax=umax=umax32=4294967294', 'smax32=-2', 'var_off=(0x80000000; 0x7fffffff))\n  22: (bc) w0 = w7                      ; [...] R7=4294967295\n  23: (95) exit\n\n  from 13 to 1: [...]\n  1: [...]\n  1: (b7) r0 = 0                        ; R0_w=0\n  2: (95) exit\n  processed 24 insns (limit 1000000) max_states_per_insn 0 total_states 2 peak_states 2 mark_read 1\n  =====================\n\nVerifier log above is for `(u32)[0; U32_MAX] (s32)< -1` use cases', ' where u32\nrange is used for initialization', ' followed by signed < operator. Note\nhow we use w6/w7 in this case for register initialization (it would be\nR6/R7 for 64-bit types) and then `if w6 s< w7` for comparison at\ninstruction #17. It will be `if R6 < R7` for 64-bit unsigned comparison.\nAbove example gives a good impression of the overall structure of a BPF\nprograms generated for reg_bounds tests.\n\nIn the future', ' this ""framework"" can be extended to test not just\nconditional jumps', ' but also arithmetic operations. Adding randomized\ntesting is another possibility.\n\nSome implementation notes. We basically have our own generics-like\noperations on numbers', ' where all the numbers are stored in u64', ' but how\nthey are interpreted is passed as runtime argument enum num_t. Further', '\n`struct range` represents a bounds range', ' and those are collected\ntogether into a minimal `struct reg_state`', ' which collects range bounds\nacross all four numberical domains: u64', ' s64', ' u32', ' s64.\n\nBased on these primitives and `enum op` representing possible\nconditional operation (<', ' <=', ' >', ' >=', ' ==', ' !=)', ' there is a set of generic\nhelpers to perform ""range arithmetics""', ' which is used to maintain struct\nreg_state. We simulate what verifier will do for reg bounds of R6 and R7\nregisters using these range and reg_state primitives. Simulated\ninformation is used to determine branch taken conclusion and expected\nexact register state across all four number domains.\n\nImplementation of ""range arithmetics"" is more generic than what verifier\nis currently performing: it allows range over range comparisons and\nadjustments. This is the intended end goal of this patch set overall and verifier\nlogic is enhanced in subsequent patches in this series to handle range\nvs range operations', "" at which point selftests are extended to validate\nthese conditions as well. For now it's range vs const cases only.\n\nNote that tests are split into multiple groups by their numeric types\nfor initialization of ranges and for comparison operation. This allows\nto use test_progs's -j parallelization to speed up tests"", ' as we now have\n16 groups of parallel running tests. Overall reduction of running time\nthat allows is pretty good', ' we go down from more than 30 minutes to\nslightly less than 5 minutes running time.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nLink: https://lore.kernel.org/r/20231112010609.848406-8-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add a selftest for BPF verifier to test register range bounds logic.,"selftests, BPF, verifier",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
cf5fe3c71c5a34ac0108afc550407c672d0a032d,cf5fe3c71c5a34ac0108afc550407c672d0a032d,Andrii Nakryiko,andrii@kernel.org,1699751162,Alexei Starovoitov,ast@kernel.org,1700078622,e17967dade20f1734fcf5b357f76acb87152e752,3cf98cf594ea923b8b1e0385b580d3d8aae68c06,bpf: make __reg{32,"64}_deduce_bounds logic more robust

This change doesn't seem to have any effect on selftests and production
BPF object files","[' but we preemptively try to make it more robust.\n\nFirst', ' ""learn sign from signed bounds"" comment is misleading', ' as we are\nlearning not just sign', ' but also values.\n\nSecond', ' we simplify the check for determining whether entire range is\npositive or negative similarly to other checks added earlier', ' using\nappropriate u32/u64 cast and single comparisons. As explain in comments\nin __reg64_deduce_bounds()', ' the checks are equivalent.\n\nLast but not least', ' smin/smax and s32_min/s32_max reassignment based on\nmin/max of both umin/umax and smin/smax (and 32-bit equivalents) is hard\nto explain and justify. We are updating unsigned bounds from signed\nbounds', ' why would we update signed bounds at the same time? This might\nbe correct', "" but it's far from obvious why and the code or comments don't\ntry to justify this. Given we've added a separate deduction of signed\nbounds from unsigned bounds earlier"", ' this seems at least redundant', ' if\nnot just wrong.\n\nIn short', ' we remove doubtful pieces', ' and streamline the rest to follow\nthe logic and approach of the rest of reg_bounds_sync() checks.\n\nAcked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231112010609.848406-7-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']","The commit enhances the __reg{32, 64}_deduce_bounds logic for robustness without affecting existing tests and BPF object files.","robustness, deduction, logic",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3cf98cf594ea923b8b1e0385b580d3d8aae68c06,3cf98cf594ea923b8b1e0385b580d3d8aae68c06,Andrii Nakryiko,andrii@kernel.org,1699751161,Alexei Starovoitov,ast@kernel.org,1700078622,9a7b6da6a2bd2a9f6ca22b92a768151b5ce78acb,5f99f312bd3bedb3b266b0d26376a8c500cdc97f,bpf: remove redundant s{32,64} -> u{32,"['64} deduction logic\n\nEquivalent checks were recently added in more succinct and', ' arguably', '\nsafer form in:\n  - f188765f23a5 (""bpf: derive smin32/smax32 from umin32/umax32 bounds"");\n  - 2e74aef782d3 (""bpf: derive smin/smax from umin/max bounds"").\n\nThe checks we are removing in this patch set do similar checks to detect\nif entire u32/u64 range has signed bit set or not set', ' but does it with\ntwo separate checks.\n\nFurther', ' we forcefully overwrite either smin or smax (and 32-bit equvalents)\nwithout applying normal min/max intersection logic. It\'s not clear why\nthat would be correct in all cases and seems to work by accident. This\nlogic is also ""gated"" by previous signed -> unsigned derivation', ' which\nreturns early.\n\nAll this is quite confusing and seems error-prone', ' while we already have\nat least equivalent checks happening earlier. So remove this duplicate\nand error-prone logic to simplify things a bit.\n\nAcked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231112010609.848406-6-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit removes redundant code by replacing s32 with u32.,"remove,redundant,replace",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
5f99f312bd3bedb3b266b0d26376a8c500cdc97f,5f99f312bd3bedb3b266b0d26376a8c500cdc97f,Andrii Nakryiko,andrii@kernel.org,1699751160,Alexei Starovoitov,ast@kernel.org,1700078622,a76c53d6907a08551bb8ab200365e61c34123a03,be41a203bb9e0159099e189e510388fe61962eb8,"bpf: add register bounds sanity checks and sanitization

Add simple sanity checks that validate well-formed ranges (min <= max)
across u64", s64,"[' u32', ' and s32 ranges. Also for cases when the value is\nconstant (either 64-bit or 32-bit)', ' we validate that ranges and tnums\nare in agreement.\n\nThese bounds checks are performed at the end of BPF_ALU/BPF_ALU64\noperations', ' on conditional jumps', ' and for LDX instructions (where subreg\nzero/sign extension is probably the most important to check). This\ncovers most of the interesting cases.\n\nAlso', ' we validate the sanity of the return register when manually\nadjusting it for some special helpers.\n\nBy default', ' sanity violation will trigger a warning in verifier log and\nresetting register bounds to ""unbounded"" ones. But to aid development\nand debugging', ' BPF_F_TEST_SANITY_STRICT flag is added', ' which will\ntrigger hard failure of verification with -EFAULT on register bounds\nviolations. This allows selftests to catch such issues. veristat will\nalso gain a CLI option to enable this behavior.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nLink: https://lore.kernel.org/r/20231112010609.848406-5-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add sanity checks for register bounds to ensure well-formed ranges in u64.,"sanity, register, bounds",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
be41a203bb9e0159099e189e510388fe61962eb8,be41a203bb9e0159099e189e510388fe61962eb8,Andrii Nakryiko,andrii@kernel.org,1699751159,Alexei Starovoitov,ast@kernel.org,1700078622,f9a8178efe938167f5d297d0976fb54ff81607a3,96381879a370425a30b810906946f64c0726450e,"bpf: enhance BPF_JEQ/BPF_JNE is_branch_taken logic

Use 32-bit subranges to prune some 64-bit BPF_JEQ/BPF_JNE conditions
that otherwise would be ""inconclusive"" (i.e."," is_branch_taken() would
return -1). This can happen","[' for example', ' when registers are initialized\nas 64-bit u64/s64', ' then compared for inequality as 32-bit subregisters', '\nand then followed by 64-bit equality/inequality check. That 32-bit\ninequality can establish some pattern for lower 32 bits of a register\n(e.g.', ' s< 0 condition determines whether the bit #31 is zero or not)', '\nwhile overall 64-bit value could be anything (according to a value range\nrepresentation).\n\nThis is not a fancy quirky special case', "" but actually a handling that's\nnecessary to prevent correctness issue with BPF verifier's range\ntracking: set_range_min_max() assumes that register ranges are\nnon-overlapping"", ' and if that condition is not guaranteed by\nis_branch_taken() we can end up with invalid ranges', ' where min > max.\n\n  [0] https://lore.kernel.org/bpf/CACkBjsY2q1_fUohD7hRmKGqv1MV=eP2f6XK8kjkYNw7BaiF8iQ@mail.gmail.com/\n\nAcked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231112010609.848406-4-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Enhance the is_branch_taken logic for BPF_JEQ/BPF_JNE using 32-bit subranges to handle inconclusive conditions more effectively.,"BPF_JEQ,subranges,inconclusive",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
96381879a370425a30b810906946f64c0726450e,96381879a370425a30b810906946f64c0726450e,Andrii Nakryiko,andrii@kernel.org,1699751158,Alexei Starovoitov,ast@kernel.org,1700078621,39e967f766aef108d7709c951218a98a7bd5dbbb,67420501e8681ae18f9f0ea0a69cd2f432100e70,"bpf: generalize is_scalar_branch_taken() logic

Generalize is_branch_taken logic for SCALAR_VALUE register to handle
cases when both registers are not constants. Previously supported
<range> vs <scalar> cases are a natural subset of more generic <range>
vs <range> set of cases.

Generalized logic relies on straightforward segment intersection checks.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>
Link: https://lore.kernel.org/r/20231112010609.848406-3-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Generalize SCALAR_VALUE branch logic to handle non-constant registers in the eBPF verifier.,"generalize, SCALAR_VALUE, verifier",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
67420501e8681ae18f9f0ea0a69cd2f432100e70,67420501e8681ae18f9f0ea0a69cd2f432100e70,Andrii Nakryiko,andrii@kernel.org,1699751157,Alexei Starovoitov,ast@kernel.org,1700078621,379e259defda2c18d782b7cb5eba596a914ca2bb,81427a62a22148cdc85db38a6fbe487d0d2044b6,"bpf: generalize reg_set_min_max() to handle non-const register comparisons

Generalize bounds adjustment logic of reg_set_min_max() to handle not
just register vs constant case"," but in general any register vs any
register cases. For most of the operations it's trivial extension based
on range vs range comparison logic","[' we just need to properly pick\nmin/max of a range to compare against min/max of the other range.\n\nFor BPF_JSET we keep the original capabilities', ' just make sure JSET is\nintegrated in the common framework. This is manifested in the\ninternal-only BPF_JSET + BPF_X ""opcode"" to allow for simpler and more\nuniform rev_opcode() handling. See the code for details. This allows to\nreuse the same code exactly both for TRUE and FALSE branches without\nexplicitly handling both conditions with custom code.\n\nNote also that now we don\'t need a special handling of BPF_JEQ/BPF_JNE\ncase none of the registers are constants. This is now just a normal\ngeneric case handled by reg_set_min_max().\n\nTo make tnum handling cleaner', ' tnum_with_subreg() helper is added', "" as\nthat's a common operator when dealing with 32-bit subregister bounds.\nThis keeps the overall logic much less noisy when it comes to tnums.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nLink: https://lore.kernel.org/r/20231112010609.848406-2-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",Generalize reg_set_min_max() to handle register comparisons beyond constant comparisons in BPF.,"generalize, reg_set_min_max, register",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1fda5bb66ad8fb24ecb3858e61a13a6548428898,1fda5bb66ad8fb24ecb3858e61a13a6548428898,Yonghong Song,yonghong.song@linux.dev,1699666768,Alexei Starovoitov,ast@kernel.org,1700063466,056e9b6892e0f9f1299c143d85ec95554033c432,e2e57d637aa5da0a2f49d83ad44e9febf95df7b4,"bpf: Do not allocate percpu memory at init stage

Kirill Shutemov reported significant percpu memory consumption increase after
booting in 288-cpu VM ([1]) due to commit 41a5db8d8161 (""bpf: Add support for
non-fix-size percpu mem allocation""). The percpu memory consumption is
increased from 111MB to 969MB. The number is from /proc/meminfo.

I tried to reproduce the issue with my local VM which at most supports upto
255 cpus. With 252 cpus", without the above commit,"[' the percpu memory\nconsumption immediately after boot is 57MB while with the above commit the\npercpu memory consumption is 231MB.\n\nThis is not good since so far percpu memory from bpf memory allocator is not\nwidely used yet. Let us change pre-allocation in init stage to on-demand\nallocation when verifier detects there is a need of percpu memory for bpf\nprogram. With this change', ' percpu memory consumption after boot can be reduced\nsignicantly.\n\n  [1] https://lore.kernel.org/lkml/20231109154934.4saimljtqx625l3v@box.shutemov.name/\n\nFixes: 41a5db8d8161 (""bpf: Add support for non-fix-size percpu mem allocation"")\nReported-and-tested-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nAcked-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20231111013928.948838-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit addresses excessive percpu memory usage by avoiding allocation at the initialization stage.,"percpu, memory, optimization",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
81427a62a22148cdc85db38a6fbe487d0d2044b6,81427a62a22148cdc85db38a6fbe487d0d2044b6,Alexei Starovoitov,ast@kernel.org,1699981016,Alexei Starovoitov,ast@kernel.org,1699981183,b01a069094a5238f3a5e6dcf828870c7a3b6d4dd,727a92d62fd6a382b4c5972008e45667e707b0e4 360769233cc9c921e90ae387d167ea3cd3cbb04c,"Merge branch 'bpf-add-support-for-cgroup1-bpf-part'

Yafang Shao says:

====================
bpf: Add support for cgroup1"," BPF part

This is the BPF part of the series ""bpf","[' cgroup: Add BPF support for\ncgroup1 hierarchy"" with adjustment in the last two patches compared\nto the previous one.\n\nv3->v4:\n  - use subsys_name instead of cgrp_name in get_cgroup_hierarchy_id()\n    (Tejun)\n  - use local bpf_link instead of modifying the skeleton in the\n    selftests\nv3: https://lwn.net/Articles/949264/\n====================\n\nLink: https://lore.kernel.org/r/20231111090034.4248-1-laoar.shao@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add support for cgroup1 in BPF subsystem.,"support,cgroup1,BPF",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['cgroup like programs']
360769233cc9c921e90ae387d167ea3cd3cbb04c,360769233cc9c921e90ae387d167ea3cd3cbb04c,Yafang Shao,laoar.shao@gmail.com,1699693234,Alexei Starovoitov,ast@kernel.org,1699981163,b01a069094a5238f3a5e6dcf828870c7a3b6d4dd,bf47300b186facc8ae66a0e2aa89073565f82bb3,"selftests/bpf: Add selftests for cgroup1 hierarchy

Add selftests for cgroup1 hierarchy.
The result as follows","

  $ tools/testing/selftests/bpf/test_progs --name=cgroup1_hierarchy
  #36/1    cgroup1_hierarchy/test_cgroup1_hierarchy:OK
  #36/2    cgroup1_hierarchy/test_root_cgid:OK
  #36/3    cgroup1_hierarchy/test_invalid_level:OK
  #36/4    cgroup1_hierarchy/test_invalid_cgid:OK
  #36/5    cgroup1_hierarchy/test_invalid_hid:OK
  #36/6    cgroup1_hierarchy/test_invalid_cgrp_name:OK
  #36/7    cgroup1_hierarchy/test_invalid_cgrp_name2:OK
  #36/8    cgroup1_hierarchy/test_sleepable_prog:OK
  #36      cgroup1_hierarchy:OK
  Summary: 1/8 PASSED","[' 0 SKIPPED', ' 0 FAILED\n\nBesides', ' I also did some stress test similar to the patch #2 in this\nseries', ' as follows (with CONFIG_PROVE_RCU_LIST enabled):\n\n- Continuously mounting and unmounting named cgroups in some tasks', '\n  for example:\n\n  cgrp_name=$1\n  while true\n  do\n      mount -t cgroup -o none', 'name=$cgrp_name none /$cgrp_name\n      umount /$cgrp_name\n  done\n\n- Continuously run this selftest concurrently', '\n  while true; do ./test_progs --name=cgroup1_hierarchy; done\n\nThey can ran successfully without any RCU warnings in dmesg.\n\nSigned-off-by: Yafang Shao <laoar.shao@gmail.com>\nLink: https://lore.kernel.org/r/20231111090034.4248-7-laoar.shao@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit adds selftests for the cgroup1 hierarchy in the BPF selftests.,"selftests,cgroup1,hierarchy",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['cgroup like programs']
bf47300b186facc8ae66a0e2aa89073565f82bb3,bf47300b186facc8ae66a0e2aa89073565f82bb3,Yafang Shao,laoar.shao@gmail.com,1699693233,Alexei Starovoitov,ast@kernel.org,1699981016,8f0984c7aca61bf4943026890864568a0c41c065,c1dcc050aa648bb3b831030d547c3fcc1c68140c,"selftests/bpf: Add a new cgroup helper get_cgroup_hierarchy_id()

A new cgroup helper function", get_cgroup1_hierarchy_id(),"[' has been\nintroduced to obtain the ID of a cgroup1 hierarchy based on the provided\ncgroup name. This cgroup name can be obtained from the /proc/self/cgroup\nfile.\n\nSigned-off-by: Yafang Shao <laoar.shao@gmail.com>\nLink: https://lore.kernel.org/r/20231111090034.4248-6-laoar.shao@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit introduces a new cgroup helper function for obtaining cgroup hierarchy ID in selftests.,"cgroup, helper function, selftests",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['cgroup like programs']
c1dcc050aa648bb3b831030d547c3fcc1c68140c,c1dcc050aa648bb3b831030d547c3fcc1c68140c,Yafang Shao,laoar.shao@gmail.com,1699693232,Alexei Starovoitov,ast@kernel.org,1699981016,62fdc34855b8766b75200f068a76bf8f2f0826e6,f744d35ecf46f111bf9b54bfdbc89a28ee8b928a,"selftests/bpf: Add a new cgroup helper get_classid_cgroup_id()

Introduce a new helper function to retrieve the cgroup ID from a net_cls
cgroup directory.

Signed-off-by: Yafang Shao <laoar.shao@gmail.com>
Link: https://lore.kernel.org/r/20231111090034.4248-5-laoar.shao@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Introduce a new helper function to retrieve the cgroup ID from a net_cls cgroup directory in selftests/bpf.,"cgroup, helper, ID",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,['cgroup like programs']
f744d35ecf46f111bf9b54bfdbc89a28ee8b928a,f744d35ecf46f111bf9b54bfdbc89a28ee8b928a,Yafang Shao,laoar.shao@gmail.com,1699693231,Alexei Starovoitov,ast@kernel.org,1699981016,39232ed4ba0c9950a71741bbc426703936f0834e,4849775587844e44d215289c425bcd70f315efe7,"selftests/bpf: Add parallel support for classid

Include the current pid in the classid cgroup path. This way"," different
testers relying on classid-based configurations will have distinct classid
cgroup directories","[' enabling them to run concurrently. Additionally', ' we\nleverage the current pid as the classid', ' ensuring unique identification.\n\nSigned-off-by: Yafang Shao <laoar.shao@gmail.com>\nLink: https://lore.kernel.org/r/20231111090034.4248-4-laoar.shao@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add parallel support for classid by including current pid in cgroup path for distinct configurations.,"parallel,classid,cgroup",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['cgroup like programs']
4849775587844e44d215289c425bcd70f315efe7,4849775587844e44d215289c425bcd70f315efe7,Yafang Shao,laoar.shao@gmail.com,1699693230,Alexei Starovoitov,ast@kernel.org,1699981016,1c62c8b620c6e86fbd9c23c2086d1b6e355fa151,fe977716b40cb98cf9c91a66454adf3dc2f8c59a,"selftests/bpf: Fix issues in setup_classid_environment()

If the net_cls subsystem is already mounted"," attempting to mount it again
in setup_classid_environment() will result in a failure with the error code
EBUSY. Despite this","[' tmpfs will have been successfully mounted at\n/sys/fs/cgroup/net_cls. Consequently', ' the /sys/fs/cgroup/net_cls directory\nwill be empty', "" causing subsequent setup operations to fail.\n\nHere's an error log excerpt illustrating the issue when net_cls has already\nbeen mounted at /sys/fs/cgroup/net_cls prior to running\nsetup_classid_environment():\n\n- Before that change\n\n  $ tools/testing/selftests/bpf/test_progs --name=cgroup_v1v2\n  test_cgroup_v1v2:PASS:server_fd 0 nsec\n  test_cgroup_v1v2:PASS:client_fd 0 nsec\n  test_cgroup_v1v2:PASS:cgroup_fd 0 nsec\n  test_cgroup_v1v2:PASS:server_fd 0 nsec\n  run_test:PASS:skel_open 0 nsec\n  run_test:PASS:prog_attach 0 nsec\n  test_cgroup_v1v2:PASS:cgroup-v2-only 0 nsec\n  (cgroup_helpers.c:248: errno: No such file or directory) Opening Cgroup Procs: /sys/fs/cgroup/net_cls/cgroup.procs\n  (cgroup_helpers.c:540: errno: No such file or directory) Opening cgroup classid: /sys/fs/cgroup/net_cls/cgroup-test-work-dir/net_cls.classid\n  run_test:PASS:skel_open 0 nsec\n  run_test:PASS:prog_attach 0 nsec\n  (cgroup_helpers.c:248: errno: No such file or directory) Opening Cgroup Procs: /sys/fs/cgroup/net_cls/cgroup-test-work-dir/cgroup.procs\n  run_test:FAIL:join_classid unexpected error: 1 (errno 2)\n  test_cgroup_v1v2:FAIL:cgroup-v1v2 unexpected error: -1 (errno 2)\n  (cgroup_helpers.c:248: errno: No such file or directory) Opening Cgroup Procs: /sys/fs/cgroup/net_cls/cgroup.procs\n  #44      cgroup_v1v2:FAIL\n  Summary: 0/0 PASSED"", ' 0 SKIPPED', ' 1 FAILED\n\n- After that change\n  $ tools/testing/selftests/bpf/test_progs --name=cgroup_v1v2\n  #44      cgroup_v1v2:OK\n  Summary: 1/0 PASSED', ' 0 SKIPPED', ' 0 FAILED\n\nSigned-off-by: Yafang Shao <laoar.shao@gmail.com>\nLink: https://lore.kernel.org/r/20231111090034.4248-3-laoar.shao@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix issues in setup_classid_environment by handling EBUSY error when net_cls is already mounted in selftests.,"selftests,bpf,setup_classid_environment",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tc/netfilter like programs']
fe977716b40cb98cf9c91a66454adf3dc2f8c59a,fe977716b40cb98cf9c91a66454adf3dc2f8c59a,Yafang Shao,laoar.shao@gmail.com,1699693229,Alexei Starovoitov,ast@kernel.org,1699981016,928fa01e194fc04f3471c9e908d7c3fcd95e479b,727a92d62fd6a382b4c5972008e45667e707b0e4,"bpf: Add a new kfunc for cgroup1 hierarchy

A new kfunc is added to acquire cgroup1 of a task:

- bpf_task_get_cgroup1
  Acquires the associated cgroup of a task whithin a specific cgroup1
  hierarchy. The cgroup1 hierarchy is identified by its hierarchy ID.

This new kfunc enables the tracing of tasks within a designated
container or cgroup directory in BPF programs.

Suggested-by: Tejun Heo <tj@kernel.org>
Signed-off-by: Yafang Shao <laoar.shao@gmail.com>
Acked-by: Tejun Heo <tj@kernel.org>
Link: https://lore.kernel.org/r/20231111090034.4248-2-laoar.shao@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,A new kfunc for acquiring cgroup1 hierarchy of a task is added to BPF.,"kfunc,cgroup1,task",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['tracepoints like programs', 'kprobe/uprobe/ftrace like programs', 'cgroup like programs']"
727a92d62fd6a382b4c5972008e45667e707b0e4,727a92d62fd6a382b4c5972008e45667e707b0e4,Jordan Rome,linux@jordanrome.com,1699756210,Andrii Nakryiko,andrii@kernel.org,1699929578,bdf6000120c9329940c8ca3bca6fe8412bc340e9,100888fb6d8a185866b1520031ee7e3182b173de,"selftests/bpf: Add assert for user stacks in test_task_stack

This is a follow up to:
commit b8e3a87a627b (""bpf: Add crosstask check to __bpf_get_stack"").

This test ensures that the task iterator only gets a single
user stack (for the current task).

Signed-off-by: Jordan Rome <linux@jordanrome.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Stanislav Fomichev <sdf@google.com>
Link: https://lore.kernel.org/bpf/20231112023010.144675-1-linux@jordanrome.com
",,Add assertion for user stack checks in BPF selftests.,"selftests, BPF, user stack",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tracepoints like programs']
4eeee6636af819454d7c43702e77ec7857a63000,4eeee6636af819454d7c43702e77ec7857a63000,Linus Torvalds,torvalds@linux-foundation.org,1699815488,Linus Torvalds,torvalds@linux-foundation.org,1699815488,c3e3a4cb30f36e686c059d2cca646d208eabb6d4,5dd2020f335a7a60c154375a168791a2b87f35b5 1d375d65466e5c8d7a9406826d80d475a22e8c6d,"Merge tag 'loongarch-6.7' of git://git.kernel.org/pub/scm/linux/kernel/git/chenhuacai/linux-loongson

Pull LoongArch updates from Huacai Chen:

 - support PREEMPT_DYNAMIC with static keys

 - relax memory ordering for atomic operations

 - support BPF CPU v4 instructions for LoongArch

 - some build and runtime warning fixes

* tag 'loongarch-6.7' of git://git.kernel.org/pub/scm/linux/kernel/git/chenhuacai/linux-loongson:
  selftests/bpf: Enable cpu v4 tests for LoongArch
  LoongArch: BPF: Support signed mod instructions
  LoongArch: BPF: Support signed div instructions
  LoongArch: BPF: Support 32-bit offset jmp instructions
  LoongArch: BPF: Support unconditional bswap instructions
  LoongArch: BPF: Support sign-extension mov instructions
  LoongArch: BPF: Support sign-extension load instructions
  LoongArch: Add more instruction opcodes and emit_* helpers
  LoongArch/smp: Call rcutree_report_cpu_starting() earlier
  LoongArch: Relax memory ordering for atomic operations
  LoongArch: Mark __percpu functions as always inline
  LoongArch: Disable module from accessing external data directly
  LoongArch: Support PREEMPT_DYNAMIC with static keys
",,"Merge LoongArch updates to support new BPF CPU instructions, PREEMPT_DYNAMIC with static keys, and fix build warnings.","LoongArch,BPF instructions,PREEMPT_DYNAMIC",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
100888fb6d8a185866b1520031ee7e3182b173de,100888fb6d8a185866b1520031ee7e3182b173de,Yonghong Song,yonghong.song@linux.dev,1699645004,Andrii Nakryiko,andrii@kernel.org,1699733890,c899ca1b643264736455ba764f9c92c9c445ef7a,b8e3a87a627b575896e448021e5c2f8a3bc19931,"selftests/bpf: Fix pyperf180 compilation failure with clang18

With latest clang18 (main branch of llvm-project repo)", when building bpf selftests,"['\n    [~/work/bpf-next (master)]$ make -C tools/testing/selftests/bpf LLVM=1 -j\n\nThe following compilation error happens:\n    fatal error: error in backend: Branch target out of insn range\n    ...\n    Stack dump:\n    0.      Program arguments: clang -g -Wall -Werror -D__TARGET_ARCH_x86 -mlittle-endian\n      -I/home/yhs/work/bpf-next/tools/testing/selftests/bpf/tools/include\n      -I/home/yhs/work/bpf-next/tools/testing/selftests/bpf -I/home/yhs/work/bpf-next/tools/include/uapi\n      -I/home/yhs/work/bpf-next/tools/testing/selftests/usr/include -idirafter\n      /home/yhs/work/llvm-project/llvm/build.18/install/lib/clang/18/include -idirafter /usr/local/include\n      -idirafter /usr/include -Wno-compare-distinct-pointer-types -DENABLE_ATOMICS_TESTS -O2 --target=bpf\n      -c progs/pyperf180.c -mcpu=v3 -o /home/yhs/work/bpf-next/tools/testing/selftests/bpf/pyperf180.bpf.o\n    1.      <eof> parser at end of file\n    2.      Code generation\n    ...\n\nThe compilation failure only happens to cpu=v2 and cpu=v3. cpu=v4 is okay\nsince cpu=v4 supports 32-bit branch target offset.\n\nThe above failure is due to upstream llvm patch [1] where some inlining behavior\nare changed in clang18.\n\nTo workaround the issue', ' previously all 180 loop iterations are fully unrolled.\nThe bpf macro __BPF_CPU_VERSION__ (implemented in clang18 recently) is used to avoid\nunrolling changes if cpu=v4. If __BPF_CPU_VERSION__ is not available and the\ncompiler is clang18', ' the unrollng amount is unconditionally reduced.\n\n  [1] https://github.com/llvm/llvm-project/commit/1a2e77cf9e11dbf56b5720c607313a566eebb16e\n\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nTested-by: Alan Maguire <alan.maguire@oracle.com>\nLink: https://lore.kernel.org/bpf/20231110193644.3130906-1-yonghong.song@linux.dev\n', '']",Fixes a compilation failure in BPF selftests with pyperf180 using clang18.,"fix, pyperf180, clang18",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
b8e3a87a627b575896e448021e5c2f8a3bc19931,b8e3a87a627b575896e448021e5c2f8a3bc19931,Jordan Rome,jordalgo@meta.com,1699442614,Andrii Nakryiko,andrii@kernel.org,1699643170,1c1e6a05755fd36882c88249a9522848f5a3a861,92411764e3106f38ac815d2fb1ae011e7bbe2abc,"bpf: Add crosstask check to __bpf_get_stack

Currently get_perf_callchain only supports user stack walking for
the current task. Passing the correct *crosstask* param will return
0 frames if the task passed to __bpf_get_stack isn't the current
one instead of a single incorrect frame/address. This change
passes the correct *crosstask* param but also does a preemptive
check in __bpf_get_stack if the task is current and returns
-EOPNOTSUPP if it is not.

This issue was found using bpf_get_task_stack inside a BPF
iterator (""iter/task"")"," which iterates over all tasks.
bpf_get_task_stack works fine for fetching kernel stacks
but because get_perf_callchain relies on the caller to know
if the requested *task* is the current one (via *crosstask*)
it was failing in a confusing way.

It might be possible to get user stacks for all tasks utilizing
something like access_process_vm but that requires the bpf
program calling bpf_get_task_stack to be sleepable and would
therefore be a breaking change.

Fixes: fa28dcb82a38 (""bpf: Introduce helper bpf_get_task_stack()"")
Signed-off-by: Jordan Rome <jordalgo@meta.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20231108112334.3433136-1-jordalgo@meta.com
",[''],Add crosstask parameter check to bpf_get_task_stack for accurate user stack walking.,"crosstask, __bpf_get_stack, user stack",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
92411764e3106f38ac815d2fb1ae011e7bbe2abc,92411764e3106f38ac815d2fb1ae011e7bbe2abc,Alexei Starovoitov,ast@kernel.org,1699635733,Alexei Starovoitov,ast@kernel.org,1699635733,57ad832f318d1416d080c643b84cf4b57570503d,689b097a06bafb461ec162fc3b3ecc9765cea67b aecd408b7e50742868b3305c24325a89024e2a30,"Merge branch 'for-6.8-bpf' of https://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup into bpf-next

Merge cgroup prerequisite patches.

Link: https://lore.kernel.org/bpf/20231029061438.4215-1-laoar.shao@gmail.com/

Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Merged cgroup prerequisite patches from branch 'for-6.8-bpf'.,"merge,cgroup,prerequisite",It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
689b097a06bafb461ec162fc3b3ecc9765cea67b,689b097a06bafb461ec162fc3b3ecc9765cea67b,Yafang Shao,laoar.shao@gmail.com,1699240682,Alexei Starovoitov,ast@kernel.org,1699631599,b9d3b805cc81b2528bb1f533fb4e9dd6c3800f1f,155addf0814a92d08fce26a11b27e3315cdba977,"compiler-gcc: Suppress -Wmissing-prototypes warning for all supported GCC

The kernel supports a minimum GCC version of 5.1.0 for building. However","
the ""__diag_ignore_all"" directive only suppresses the
""-Wmissing-prototypes"" warning for GCC versions >= 8.0.0. As a result","[' when\nbuilding the kernel with older GCC versions', "" warnings may be triggered. The\nexample below illustrates the warnings reported by the kernel test robot\nusing GCC 7.5.0:\n\n  compiler: gcc-7 (Ubuntu 7.5.0-6ubuntu2) 7.5.0\n  All warnings (new ones prefixed by >>):\n\n   kernel/bpf/helpers.c:1893:19: warning: no previous prototype for 'bpf_obj_new_impl' [-Wmissing-prototypes]\n    __bpf_kfunc void *bpf_obj_new_impl(u64 local_type_id__k"", "" void *meta__ign)\n                      ^~~~~~~~~~~~~~~~\n   kernel/bpf/helpers.c:1907:19: warning: no previous prototype for 'bpf_percpu_obj_new_impl' [-Wmissing-prototypes]\n    __bpf_kfunc void *bpf_percpu_obj_new_impl(u64 local_type_id__k"", ' void *meta__ign)\n   [...]\n\nTo address this', ' we should also suppress the ""-Wmissing-prototypes"" warning\nfor older GCC versions. ""#pragma GCC diagnostic push"" is supported as\nof GCC 4.6', ' and both ""-Wmissing-prototypes"" and ""-Wmissing-declarations""\nare supported for all the GCC versions that we currently support.\nTherefore', ' it is reasonable to suppress these warnings for all supported\nGCC versions.\n\nWith this adjustment', ' it\'s important to note that after implementing\n""__diag_ignore_all""', ' it will effectively suppress warnings for all the\nsupported GCC versions.\n\nIn the future', ' if you wish to suppress warnings that are only supported on\nhigher GCC versions', ' it is advisable to explicitly use ""__diag_ignore"" to\nspecify the GCC version you are targeting.\n\nReported-by: kernel test robot <lkp@intel.com>\nCloses: https://lore.kernel.org/oe-kbuild-all/202311031651.A7crZEur-lkp@intel.com/\nSuggested-by: Arnd Bergmann <arnd@arndb.de>\nSigned-off-by: Yafang Shao <laoar.shao@gmail.com>\nCc: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nCc: Arnd Bergmann <arnd@arndb.de>\nAcked-by: Arnd Bergmann <arnd@arndb.de>\nLink: https://lore.kernel.org/r/20231106031802.4188-1-laoar.shao@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Suppress -Wmissing-prototypes warning for all supported GCC versions in the kernel build system.,"suppress, GCC, warnings",It's a build system or CI/CD change.,"Simple, can be used without much configuration. For example, a simple helper function.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
871019b22d1bcc9fab2d1feba1b9a564acbb6e99,871019b22d1bcc9fab2d1feba1b9a564acbb6e99,Stanislav Fomichev,sdf@google.com,1699478005,David S. Miller,davem@davemloft.net,1699605429,bf9b093f9a016bad95b1ec384123e6a4ab3d3555,8a4f030dbced6fc255cbe67b2d0a129947e18493,"net: set SOCK_RCU_FREE before inserting socket into hashtable

We've started to see the following kernel traces:

 WARNING: CPU: 83 PID: 0 at net/core/filter.c:6641 sk_lookup+0x1bd/0x1d0

 Call Trace:
  <IRQ>
  __bpf_skc_lookup+0x10d/0x120
  bpf_sk_lookup+0x48/0xd0
  bpf_sk_lookup_tcp+0x19/0x20
  bpf_prog_<redacted>+0x37c/0x16a3
  cls_bpf_classify+0x205/0x2e0
  tcf_classify+0x92/0x160
  __netif_receive_skb_core+0xe52/0xf10
  __netif_receive_skb_list_core+0x96/0x2b0
  napi_complete_done+0x7b5/0xb70
  <redacted>_poll+0x94/0xb0
  net_rx_action+0x163/0x1d70
  __do_softirq+0xdc/0x32e
  asm_call_irq_on_stack+0x12/0x20
  </IRQ>
  do_softirq_own_stack+0x36/0x50
  do_softirq+0x44/0x70

__inet_hash can race with lockless (rcu) readers on the other cpus:

  __inet_hash
    __sk_nulls_add_node_rcu
    <- (bpf triggers here)
    sock_set_flag(SOCK_RCU_FREE)

Let's move the SOCK_RCU_FREE part up a bit"," before we are inserting
the socket into hashtables. Note","["" that the race is really harmless;\nthe bpf callers are handling this situation (where listener socket\ndoesn't have SOCK_RCU_FREE set) correctly"", ' so the only\nannoyance is a WARN_ONCE.\n\nMore details from Eric regarding SOCK_RCU_FREE timeline:\n\nCommit 3b24d854cb35 (""tcp/dccp: do not touch listener sk_refcnt under\nsynflood"") added SOCK_RCU_FREE. At that time', ' the precise location of\nsock_set_flag(sk', ' SOCK_RCU_FREE) did not matter', ' because the thread calling\n__inet_hash() owns a reference on sk. SOCK_RCU_FREE was only tested\nat dismantle time.\n\nCommit 6acc9b432e67 (""bpf: Add helper to retrieve socket in BPF"")\nstarted checking SOCK_RCU_FREE _after_ the lookup to infer whether\nthe refcount has been taken care of.\n\nFixes: 6acc9b432e67 (""bpf: Add helper to retrieve socket in BPF"")\nReviewed-by: Eric Dumazet <edumazet@google.com>\nSigned-off-by: Stanislav Fomichev <sdf@google.com>\nReviewed-by: Kuniyuki Iwashima <kuniyu@amazon.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>\n', '']",Set SOCK_RCU_FREE before inserting socket into hashtable to prevent kernel trace warnings.,"SOCK_RCU_FREE, socket, hashtable",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The syscall interface,['tc/netfilter like programs']
e2e57d637aa5da0a2f49d83ad44e9febf95df7b4,e2e57d637aa5da0a2f49d83ad44e9febf95df7b4,Andrii Nakryiko,andrii@kernel.org,1699596851,Alexei Starovoitov,ast@kernel.org,1699599445,ceeeeee21f97b54a1901c97164463d1879503b48,10e14e9652bf9e8104151bfd9200433083deae3d,"selftests/bpf: add more test cases for check_cfg()

Add a few more simple cases to validate proper privileged vs unprivileged
loop detection behavior. conditional_loop2 is the one reported by Hao
Sun that triggered this set of fixes.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Suggested-by: Hao Sun <sunhao.th@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231110061412.2995786-2-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add more test cases for privileged vs unprivileged loop detection in BPF selftests.,"selftests,bpf,loop",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
10e14e9652bf9e8104151bfd9200433083deae3d,10e14e9652bf9e8104151bfd9200433083deae3d,Andrii Nakryiko,andrii@kernel.org,1699596850,Alexei Starovoitov,ast@kernel.org,1699599444,10b9609fd07778761b26a896197bf7fc9af8a4aa,8c74b27f4b30cd896ccf387102410a65b4a35c25,"bpf: fix control-flow graph checking in privileged mode

When BPF program is verified in privileged mode"," BPF verifier allows
bounded loops. This means that from CFG point of view there are
definitely some back-edges. Original commit adjusted check_cfg() logic
to not detect back-edges in control flow graph if they are resulting
from conditional jumps","[' which the idea that subsequent full BPF\nverification process will determine whether such loops are bounded or\nnot', "" and either accept or reject the BPF program. At least that's my\nreading of the intent.\n\nUnfortunately"", "" the implementation of this idea doesn't work correctly in\nall possible situations. Conditional jump might not result in immediate\nback-edge"", ' but just a few unconditional instructions later we can arrive\nat back-edge. In such situations check_cfg() would reject BPF program\neven in privileged mode', ' despite it might be bounded loop. Next patch\nadds one simple program demonstrating such scenario.\n\nTo keep things simple', ' instead of trying to detect back edges in\nprivileged mode', ' just assume every back edge is valid and let subsequent\nBPF verification prove or reject bounded loops.\n\nNote a few test changes. For unknown reason', ' we have a few tests that\nare specified to detect a back-edge in a privileged mode', ' but looking at\ntheir code it seems like the right outcome is passing check_cfg() and\nletting subsequent verification to make a decision about bounded or not\nbounded looping.\n\nBounded recursion case is also interesting. The example should pass', "" as\nrecursion is limited to just a few levels and so we never reach maximum\nnumber of nested frames and never exhaust maximum stack depth. But the\nway that max stack depth logic works today it falsely detects this as\nexceeding max nested frame count. This patch series doesn't attempt to\nfix this orthogonal problem"", ' so we just adjust expected verifier failure.\n\nSuggested-by: Alexei Starovoitov <ast@kernel.org>\nFixes: 2589726d12a1 (""bpf: introduce bounded loops"")\nReported-by: Hao Sun <sunhao.th@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231110061412.2995786-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes control-flow graph checking for BPF programs in privileged mode by adjusting treatment of back-edges from conditional jumps.,"control-flow, privileged, back-edges",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8c74b27f4b30cd896ccf387102410a65b4a35c25,8c74b27f4b30cd896ccf387102410a65b4a35c25,Alexei Starovoitov,ast@kernel.org,1699589480,Alexei Starovoitov,ast@kernel.org,1699589480,ef2e9a422ae611e616fd521fc59a6b3b1cb97db3,fe69a1b1b6ed9ffc2c578c63f526026a8ab74f0c 62ccdb11d3c63dc697dea1fd92b3496fe43dcc1e,"Merge branch 'bpf-control-flow-graph-and-precision-backtrack-fixes'

Andrii Nakryiko says:

====================
BPF control flow graph and precision backtrack fixes

A small fix to BPF verifier's CFG logic around handling and reporting ldimm64
instructions. Patch #1 was previously submitted separately ([0])"," and so this
patch set supersedes that patch.

Second patch is fixing obscure corner case in mark_chain_precise() logic. See
patch for details. Patch #3 adds a dedicated test","[' however fragile it might.\n\n  [0] https://patchwork.kernel.org/project/netdevbpf/patch/20231101205626.119243-1-andrii@kernel.org/\n====================\n\nLink: https://lore.kernel.org/r/20231110002638.4168352-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit merges fixes for BPF verifier's control flow graph and precision backtracking logic.,"BPF verifier, control flow, fixes",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
62ccdb11d3c63dc697dea1fd92b3496fe43dcc1e,62ccdb11d3c63dc697dea1fd92b3496fe43dcc1e,Andrii Nakryiko,andrii@kernel.org,1699575998,Alexei Starovoitov,ast@kernel.org,1699589480,ef2e9a422ae611e616fd521fc59a6b3b1cb97db3,4bb7ea946a370707315ab774432963ce47291946,"selftests/bpf: add edge case backtracking logic test

Add a dedicated selftests to try to set up conditions to have a state
with same first and last instruction index"," but it actually is a loop
3->4->1->2->3. This confuses mark_chain_precision() if verifier doesn't
take into account jump history.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231110002638.4168352-4-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Add a selftest to verify edge case handling in eBPF verifier regarding jump history and state consistency.,"selftest, edge case, verifier",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4bb7ea946a370707315ab774432963ce47291946,4bb7ea946a370707315ab774432963ce47291946,Andrii Nakryiko,andrii@kernel.org,1699575997,Alexei Starovoitov,ast@kernel.org,1699589480,c4aeda8d7dec289c11b5e7799567e07da7bf612d,3feb263bb516ee7e1da0acd22b15afbb9a7daa19,"bpf: fix precision backtracking instruction iteration

Fix an edge case in __mark_chain_precision() which prematurely stops
backtracking instructions in a state if it happens that state's first
and last instruction indexes are the same. This situations doesn't
necessarily mean that there were no instructions simulated in a state","
but rather that we starting from the instruction","[' jumped around a bit', '\nand then ended up at the same instruction before checkpointing or\nmarking precision.\n\nTo distinguish between these two possible situations', ' we need to consult\njump history. If it\'s empty or contain a single record ""bridging"" parent\nstate and first instruction of processed state', ' then we indeed\nbacktracked all instructions in this state. But if history is not empty', '\nwe are definitely not done yet.\n\nMove this logic inside get_prev_insn_idx() to contain it more nicely.\nUse -ENOENT return code to denote ""we are out of instructions""\nsituation.\n\nThis bug was exposed by verifier_loop1.c\'s bounded_recursion subtest', ' once\nthe next fix in this patch set is applied.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nFixes: b5dc0163d8fd (""bpf: precise scalar_value tracking"")\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231110002638.4168352-3-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes an edge case in the bpf verifier's precision backtracking logic.,"precision, backtracking, edge case",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3feb263bb516ee7e1da0acd22b15afbb9a7daa19,3feb263bb516ee7e1da0acd22b15afbb9a7daa19,Andrii Nakryiko,andrii@kernel.org,1699575996,Alexei Starovoitov,ast@kernel.org,1699589480,b29c0f1447aad1aca146c40769a05a39d420d71a,fe69a1b1b6ed9ffc2c578c63f526026a8ab74f0c,"bpf: handle ldimm64 properly in check_cfg()

ldimm64 instructions are 16-byte long"," and so have to be handled
appropriately in check_cfg()","[' just like the rest of BPF verifier does.\n\nThis has implications in three places:\n  - when determining next instruction for non-jump instructions;\n  - when determining next instruction for callback address ldimm64\n    instructions (in visit_func_call_insn());\n  - when checking for unreachable instructions', ' where second half of\n    ldimm64 is expected to be unreachable;\n\nWe take this also as an opportunity to report jump into the middle of\nldimm64. And adjust few test_verifier tests accordingly.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nReported-by: Hao Sun <sunhao.th@gmail.com>\nFixes: 475fb78fbf48 (""bpf: verifier (add branch/goto checks)"")\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231110002638.4168352-2-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix handling of ldimm64 instructions in check_cfg function for proper configuration checks.,"ldimm64,check_cfg,instructions",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fe69a1b1b6ed9ffc2c578c63f526026a8ab74f0c,fe69a1b1b6ed9ffc2c578c63f526026a8ab74f0c,Anders Roxell,anders.roxell@linaro.org,1699551808,Alexei Starovoitov,ast@kernel.org,1699586292,2447ed60aede14e0b8f34f398764b6d86f5c0555,89cdf9d556016a54ff6ddd62324aa5ec790c05cc,"selftests: bpf: xskxceiver: ksft_print_msg: fix format type error

Crossbuilding selftests/bpf for architecture arm64"," format specifies
type error show up like.

xskxceiver.c:912:34: error: format specifies type 'int' but the argument
has type '__u64' (aka 'unsigned long long') [-Werror","['-Wformat]\n ksft_print_msg(""[%s] expected meta_count [%d]', ' got meta_count [%d]\\n""', '\n                                                                ~~\n                                                                %llu\n                __func__', ' pkt->pkt_nb', "" meta->count);\n                                       ^~~~~~~~~~~\nxskxceiver.c:929:55: error: format specifies type 'unsigned long long' but\n the argument has type 'u64' (aka 'unsigned long') [-Werror"", '-Wformat]\n ksft_print_msg(""Frag invalid addr: %llx len: %u\\n""', ' addr', ' len);\n                                    ~~~~             ^~~~\n\nFixing the issues by casting to (unsigned long long) and changing the\nspecifiers to be %llu from %d and %u', ' since with u64s it might be %llx\nor %lx', ' depending on architecture.\n\nSigned-off-by: Anders Roxell <anders.roxell@linaro.org>\nLink: https://lore.kernel.org/r/20231109174328.1774571-1-anders.roxell@linaro.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes a format type error in the ksft_print_msg function of the xskxceiver selftest for arm64 architecture.,"format, ksft_print_msg, xskxceiver",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
155addf0814a92d08fce26a11b27e3315cdba977,155addf0814a92d08fce26a11b27e3315cdba977,Yonghong Song,yonghong.song@linux.dev,1699066140,Alexei Starovoitov,ast@kernel.org,1699585672,512cfc25c827d1ccb5958cca42fe67a65f782c2d,3f6d04d742d9fbd492a79e28e7cfe4e2a97c66e5,"bpf: Use named fields for certain bpf uapi structs

Martin and Vadim reported a verifier failure with bpf_dynptr usage.
The issue is mentioned but Vadim workarounded the issue with source
change ([1]). The below describes what is the issue and why there
is a verification failure.

  int BPF_PROG(skb_crypto_setup) {
    struct bpf_dynptr algo"," key;
    ...

    bpf_dynptr_from_mem(...","[' ...', ' 0', ' &algo);\n    ...\n  }\n\nThe bpf program is using vmlinux.h', ' so we have the following definition in\nvmlinux.h:\n  struct bpf_dynptr {\n        long: 64;\n        long: 64;\n  };\nNote that in uapi header bpf.h', ' we have\n  struct bpf_dynptr {\n        long: 64;\n        long: 64;\n} __attribute__((aligned(8)));\n\nSo we lost alignment information for struct bpf_dynptr by using vmlinux.h.\nLet us take a look at a simple program below:\n  $ cat align.c\n  typedef unsigned long long __u64;\n  struct bpf_dynptr_no_align {\n        __u64 :64;\n        __u64 :64;\n  };\n  struct bpf_dynptr_yes_align {\n        __u64 :64;\n        __u64 :64;\n  } __attribute__((aligned(8)));\n\n  void bar(void *', ' void *);\n  int foo() {\n    struct bpf_dynptr_no_align a;\n    struct bpf_dynptr_yes_align b;\n    bar(&a', ' &b);\n    return 0;\n  }\n  $ clang --target=bpf -O2 -S -emit-llvm align.c\n\nLook at the generated IR file align.ll:\n  ...\n  %a = alloca %struct.bpf_dynptr_no_align', ' align 1\n  %b = alloca %struct.bpf_dynptr_yes_align', ' align 8\n  ...\n\nThe compiler dictates the alignment for struct bpf_dynptr_no_align is 1 and\nthe alignment for struct bpf_dynptr_yes_align is 8. So theoretically compiler\ncould allocate variable %a with alignment 1 although in reallity the compiler\nmay choose a different alignment by considering other local variables.\n\nIn [1]', "" the verification failure happens because variable 'algo' is allocated\non the stack with alignment 4 (fp-28). But the verifer wants its alignment\nto be 8.\n\nTo fix the issue"", "" the RFC patch ([1]) tried to add '__attribute__((aligned(8)))'\nto struct bpf_dynptr plus other similar structs. Andrii suggested that\nwe could directly modify uapi struct with named fields like struct 'bpf_iter_num':\n  struct bpf_iter_num {\n        /* opaque iterator state; having __u64 here allows to preserve correct\n         * alignment requirements in vmlinux.h"", ' generated from BTF\n         */\n        __u64 __opaque[1];\n  } __attribute__((aligned(8)));\n\nIndeed', ' adding named fields for those affected structs in this patch can preserve\nalignment when bpf program references them in vmlinux.h. With this patch', '\nthe verification failure in [1] can also be resolved.\n\n  [1] https://lore.kernel.org/bpf/1b100f73-7625-4c1f-3ae5-50ecf84d3ff0@linux.dev/\n  [2] https://lore.kernel.org/bpf/20231103055218.2395034-1-yonghong.song@linux.dev/\n\nCc: Vadim Fedorenko <vadfed@meta.com>\nCc: Martin KaFai Lau <martin.lau@linux.dev>\nSuggested-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231104024900.1539182-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes a verifier failure by using named fields in certain bpf uapi structs.,"verifier failure, bpf_dynptr, uapi structs",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3f6d04d742d9fbd492a79e28e7cfe4e2a97c66e5,3f6d04d742d9fbd492a79e28e7cfe4e2a97c66e5,Alexei Starovoitov,ast@kernel.org,1699555545,Alexei Starovoitov,ast@kernel.org,1699585672,c234716003d73512a51a9e4e43b0a3cecf0c38ef,82ce364c6087e31ff9837380a4641a856284064c e9ed8df7187cfdce1075d0ee591544ac15d072f1,"Merge branch 'allow-bpf_refcount_acquire-of-mapval-obtained-via-direct-ld'

Dave Marchevsky says:

====================
Allow bpf_refcount_acquire of mapval obtained via direct LD

Consider this BPF program:

  struct cgv_node {
    int d;
    struct bpf_refcount r;
    struct bpf_rb_node rb;
  };

  struct val_stash {
    struct cgv_node __kptr *v;
  };

  struct {
    __uint(type"," BPF_MAP_TYPE_ARRAY);
    __type(key","[' int);\n    __type(value', ' struct val_stash);\n    __uint(max_entries', ' 10);\n  } array_map SEC("".maps"");\n\n  long bpf_program(void *ctx)\n  {\n    struct val_stash *mapval;\n    struct cgv_node *p;\n    int idx = 0;\n\n    mapval = bpf_map_lookup_elem(&array_map', ' &idx);\n    if (!mapval || !mapval->v) { /* omitted */ }\n\n    p = bpf_refcount_acquire(mapval->v); /* Verification FAILs here */\n\n    /* Add p to some tree */\n    return 0;\n  }\n\nVerification fails on the refcount_acquire:\n\n  160: (79) r1 = *(u64 *)(r8 +8)        ; R1_w=untrusted_ptr_or_null_cgv_node(id=11', 'off=0', 'imm=0) R8_w=map_value(id=10', 'off=0', 'ks=8', 'vs=16', ""imm=0) refs=6\n  161: (b7) r2 = 0                      ; R2_w=0 refs=6\n  162: (85) call bpf_refcount_acquire_impl#117824\n  arg#0 is neither owning or non-owning ref\n\nThe above verifier dump is actually from sched_ext's scx_flatcg [0]"", ""\nwhich is the motivating usecase for this series' changes. Specifically"", '\nscx_flatcg stashes a rb_node type w/ cgroup-specific info (struct\ncgv_node) in a map when the cgroup is created', "" then later puts that\ncgroup's node in a rbtree in .enqueue . Making struct cgv_node\nrefcounted would simplify the code a bit by virtue of allowing us to\nremove the kptr_xchg's"", ' but ""later puts that cgroups node in a rbtree""\nis not possible without a refcount_acquire', ' which suffers from the above\nverification failure.\n\nIf we get rid of PTR_UNTRUSTED flag', ' and add MEM_ALLOC | NON_OWN_REF', '\nmapval->v would be a non-owning ref and verification would succeed. Due\nto the most recent set of refcount changes [1]', "" which modified\nbpf_obj_drop behavior to not reuse refcounted graph node's underlying\nmemory until after RCU grace period"", ' this is safe to do. Once mapval->v\nhas the correct flags it _is_ a non-owning reference and verification of\nthe motivating example will succeed.\n\n  [0]: https://github.com/sched-ext/sched_ext/blob/52911e1040a0f94b9c426dddcc00be5364a7ae9f/tools/sched_ext/scx_flatcg.bpf.c#L275\n  [1]: https://lore.kernel.org/bpf/20230821193311.3290257-1-davemarchevsky@fb.com/\n\nSummary of patches:\n  * Patch 1 fixes an issue with bpf_refcount_acquire verification\n    letting MAYBE_NULL ptrs through\n    * Patch 2 tests Patch 1\'s fix\n  * Patch 3 broadens the use of ""free only after RCU GP"" to all\n    user-allocated types\n  * Patch 4 is a small nonfunctional refactoring\n  * Patch 5 changes verifier to mark direct LD of stashed graph node\n    kptr as non-owning ref\n    * Patch 6 tests Patch 5\'s verifier changes\n\nChangelog:\n\nv1 -> v2: https://lore.kernel.org/bpf/20231025214007.2920506-1-davemarchevsky@fb.com/\n\nSeries title changed to ""Allow bpf_refcount_acquire of mapval obtained via\ndirect LD"". V1\'s title was mistakenly truncated.\n\n  * Patch 5 (""bpf: Mark direct ld of stashed bpf_{rb', 'list}_node as non-owning ref"")\n    * Direct LD of percpu kptr should not have MEM_ALLOC flag (Yonghong)\n  * Patch 6 (""selftests/bpf: Test bpf_refcount_acquire of node obtained via direct ld"")\n    * Test read from stashed value as well\n====================\n\nLink: https://lore.kernel.org/r/20231107085639.3016113-1-davemarchevsky@fb.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit merges changes to allow bpf_refcount_acquire of map values obtained via direct load.,"bpf_refcount_acquire,mapval,direct LD",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
82ce364c6087e31ff9837380a4641a856284064c,82ce364c6087e31ff9837380a4641a856284064c,Shung-Hsi Yu,shung-hsi.yu@suse.com,1699452041,Alexei Starovoitov,ast@kernel.org,1699585671,4e57f84858fd1fa44c45412ad9f553c0d3dfb726,27007fae704eb12547b9b5c7b1005e11640d4f19,"bpf: replace register_is_const() with is_reg_const()

The addition of is_reg_const() in commit 171de12646d2 (""bpf: generalize
is_branch_taken to handle all conditional jumps in one place"") has made the
register_is_const() redundant. Give the former has more feature"," plus the
fact the latter is only used in one place","[' replace register_is_const() with\nis_reg_const()', ' and remove the definition of register_is_const.\n\nThis requires moving the definition of is_reg_const() further up. And since\nthe comment of reg_const_value() reference is_reg_const()', ' move it up as\nwell.\n\nSigned-off-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231108140043.12282-1-shung-hsi.yu@suse.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Replaced redundant register_is_const() with is_reg_const() for handling conditional jumps in eBPF.,register replacement redundancy,It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e9ed8df7187cfdce1075d0ee591544ac15d072f1,e9ed8df7187cfdce1075d0ee591544ac15d072f1,Dave Marchevsky,davemarchevsky@fb.com,1699347399,Alexei Starovoitov,ast@kernel.org,1699585671,c234716003d73512a51a9e4e43b0a3cecf0c38ef,1b12171533a9bb23cf6fba7262b479028b65e1e8,"selftests/bpf: Test bpf_refcount_acquire of node obtained via direct ld

This patch demonstrates that verifier changes earlier in this series
result in bpf_refcount_acquire(mapval->stashed_kptr) passing
verification. The added test additionally validates that stashing a kptr
in mapval and - in a separate BPF program - refcount_acquiring the kptr
without unstashing works as expected at runtime.

Signed-off-by: Dave Marchevsky <davemarchevsky@fb.com>
Link: https://lore.kernel.org/r/20231107085639.3016113-7-davemarchevsky@fb.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add test for verifier behavior with bpf_refcount_acquire on stashed kptr in selftests.,"bpf_refcount_acquire,selftests,verifier",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
27007fae704eb12547b9b5c7b1005e11640d4f19,27007fae704eb12547b9b5c7b1005e11640d4f19,Andrii Nakryiko,andrii@kernel.org,1699420470,Alexei Starovoitov,ast@kernel.org,1699585671,0b3c49f593dfae7c48163885366ed52bb5e03507,5d4a7aaca1ebcc7c864caec13203662a061c4f4f,"veristat: add ability to filter top N results

Add ability to filter top B results"," both in replay/verifier mode and
comparison mode. Just adding `-n10` will emit only first 10 rows","[' or\nless', ' if there is not enough rows.\n\nThis is not just a shortcut instead of passing veristat output through\n`head`', ' though. Filtering out all the other rows influences final table\nformatting', ' as table column widths are calculated based on actual\nemitted test.\n\nTo demonstrate the difference', ' compare two ""equivalent"" forms below', ' one\nusing head and another using -n argument.\n\nTOP N FEATURE\n=============\n[vmuser@archvm bpf]$ sudo ./veristat -C ~/baseline-results-selftests.csv ~/sanity2-results-selftests.csv -e file', 'prog', 'insns', ""states -s '|insns_diff|' -n10\nFile                                      Program                Insns (A)  Insns (B)  Insns (DIFF)  States (A)  States (B)  States (DIFF)\n----------------------------------------  ---------------------  ---------  ---------  ------------  ----------  ----------  -------------\ntest_seg6_loop.bpf.linked3.o              __add_egr_x                12440      12360  -80 (-0.64%)         364         357    -7 (-1.92%)\nasync_stack_depth.bpf.linked3.o           async_call_root_check        145        145   +0 (+0.00%)           3           3    +0 (+0.00%)\nasync_stack_depth.bpf.linked3.o           pseudo_call_check            139        139   +0 (+0.00%)           3           3    +0 (+0.00%)\natomic_bounds.bpf.linked3.o               sub                            7          7   +0 (+0.00%)           0           0    +0 (+0.00%)\nbench_local_storage_create.bpf.linked3.o  kmalloc                        5          5   +0 (+0.00%)           0           0    +0 (+0.00%)\nbench_local_storage_create.bpf.linked3.o  sched_process_fork            22         22   +0 (+0.00%)           2           2    +0 (+0.00%)\nbench_local_storage_create.bpf.linked3.o  socket_post_create            23         23   +0 (+0.00%)           2           2    +0 (+0.00%)\nbind4_prog.bpf.linked3.o                  bind_v4_prog                 358        358   +0 (+0.00%)          33          33    +0 (+0.00%)\nbind6_prog.bpf.linked3.o                  bind_v6_prog                 429        429   +0 (+0.00%)          37          37    +0 (+0.00%)\nbind_perm.bpf.linked3.o                   bind_v4_prog                  15         15   +0 (+0.00%)           1           1    +0 (+0.00%)\n\nPIPING TO HEAD\n==============\n[vmuser@archvm bpf]$ sudo ./veristat -C ~/baseline-results-selftests.csv ~/sanity2-results-selftests.csv -e file"", 'prog', 'insns', 'states -s \'|insns_diff|\' | head -n12\nFile                                                   Program                                               Insns (A)  Insns (B)  Insns (DIFF)  States (A)  States (B)  States (DIFF)\n-----------------------------------------------------  ----------------------------------------------------  ---------  ---------  ------------  ----------  ----------  -------------\ntest_seg6_loop.bpf.linked3.o                           __add_egr_x                                               12440      12360  -80 (-0.64%)         364         357    -7 (-1.92%)\nasync_stack_depth.bpf.linked3.o                        async_call_root_check                                       145        145   +0 (+0.00%)           3           3    +0 (+0.00%)\nasync_stack_depth.bpf.linked3.o                        pseudo_call_check                                           139        139   +0 (+0.00%)           3           3    +0 (+0.00%)\natomic_bounds.bpf.linked3.o                            sub                                                           7          7   +0 (+0.00%)           0           0    +0 (+0.00%)\nbench_local_storage_create.bpf.linked3.o               kmalloc                                                       5          5   +0 (+0.00%)           0           0    +0 (+0.00%)\nbench_local_storage_create.bpf.linked3.o               sched_process_fork                                           22         22   +0 (+0.00%)           2           2    +0 (+0.00%)\nbench_local_storage_create.bpf.linked3.o               socket_post_create                                           23         23   +0 (+0.00%)           2           2    +0 (+0.00%)\nbind4_prog.bpf.linked3.o                               bind_v4_prog                                                358        358   +0 (+0.00%)          33          33    +0 (+0.00%)\nbind6_prog.bpf.linked3.o                               bind_v6_prog                                                429        429   +0 (+0.00%)          37          37    +0 (+0.00%)\nbind_perm.bpf.linked3.o                                bind_v4_prog                                                 15         15   +0 (+0.00%)           1           1    +0 (+0.00%)\n\nNote all the wasted whitespace in the ""PIPING TO HEAD"" variant.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231108051430.1830950-2-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Added functionality to filter and display top N results in veristat.,"veristat,filter,top",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
1b12171533a9bb23cf6fba7262b479028b65e1e8,1b12171533a9bb23cf6fba7262b479028b65e1e8,Dave Marchevsky,davemarchevsky@fb.com,1699347398,Alexei Starovoitov,ast@kernel.org,1699585671,0dda88d7b7b23c360fafb186fb98762867bde06e,790ce3cfefb1b768dccd4eee324ddef0f0ce3db4,bpf: Mark direct ld of stashed bpf_{rb,"list}_node as non-owning ref

This patch enables the following pattern:

  /* mapval contains a __kptr pointing to refcounted local kptr */
  mapval = bpf_map_lookup_elem(&map","["" &idx);\n  if (!mapval || !mapval->some_kptr) { /* omitted */ }\n\n  p = bpf_refcount_acquire(&mapval->some_kptr);\n\nCurrently this doesn't work because bpf_refcount_acquire expects an\nowning or non-owning ref. The verifier defines non-owning ref as a type:\n\n  PTR_TO_BTF_ID | MEM_ALLOC | NON_OWN_REF\n\nwhile mapval->some_kptr is PTR_TO_BTF_ID | PTR_UNTRUSTED. It's possible\nto do the refcount_acquire by first bpf_kptr_xchg'ing mapval->some_kptr\ninto a temp kptr"", ' refcount_acquiring that', "" and xchg'ing back into\nmapval"", "" but this is unwieldy and shouldn't be necessary.\n\nThis patch modifies btf_ld_kptr_type such that user-allocated types are\nmarked MEM_ALLOC and if those types have a bpf_{rb"", ""list}_node they're\nmarked NON_OWN_REF as well. Additionally"", ' due to changes to\nbpf_obj_drop_impl earlier in this series', ' rcu_protected_object now\nreturns true for all user-allocated types', "" resulting in\nmapval->some_kptr being marked MEM_RCU.\n\nAfter this patch's changes"", ' mapval->some_kptr is now:\n\n  PTR_TO_BTF_ID | MEM_ALLOC | NON_OWN_REF | MEM_RCU\n\nwhich results in it passing the non-owning ref test', ' and the motivating\nexample passing verification.\n\nFuture work will likely get rid of special non-owning ref lifetime logic\nin the verifier', "" at which point we'll be able to delete the NON_OWN_REF\nflag entirely.\n\nSigned-off-by: Dave Marchevsky <davemarchevsky@fb.com>\nLink: https://lore.kernel.org/r/20231107085639.3016113-6-davemarchevsky@fb.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",This commit marks direct load of stashed bpf_map elements' node as non-owning references for eBPF programs.,"direct ld, non-owning ref, bpf_map",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
790ce3cfefb1b768dccd4eee324ddef0f0ce3db4,790ce3cfefb1b768dccd4eee324ddef0f0ce3db4,Dave Marchevsky,davemarchevsky@fb.com,1699347397,Alexei Starovoitov,ast@kernel.org,1699585671,a5fbb1da79ee98320e2d7622179b7fcd70ed05b0,649924b76ab151a96bdd22a97a993fb0421f134c,bpf: Move GRAPH_{ROOT,"NODE}_MASK macros into btf_field_type enum

This refactoring patch removes the unused BPF_GRAPH_NODE_OR_ROOT
btf_field_type and moves BPF_GRAPH_{NODE","['ROOT} macros into the\nbtf_field_type enum. Further patches in the series will use\nBPF_GRAPH_NODE', "" so let's move this useful definition out of btf.c.\n\nSigned-off-by: Dave Marchevsky <davemarchevsky@fb.com>\nLink: https://lore.kernel.org/r/20231107085639.3016113-5-davemarchevsky@fb.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",The commit refactors the code by moving certain macros into the btf_field_type enum and removing unused types.,"refactoring, macros, btf_field_type",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7f7c43693c1b46652cfafb7af67ba31726d6ec4e,7f7c43693c1b46652cfafb7af67ba31726d6ec4e,Yonghong Song,yonghong.song@linux.dev,1699388111,Alexei Starovoitov,ast@kernel.org,1699585671,229d54097510914a62b75a0bd050312769d58975,b0d1c7294671af02369d7a4feaa5a9bb472372c6,"libbpf: Fix potential uninitialized tail padding with LIBBPF_OPTS_RESET

Martin reported that there is a libbpf complaining of non-zero-value tail
padding with LIBBPF_OPTS_RESET macro if struct bpf_netkit_opts is modified
to have a 4-byte tail padding. This only happens to clang compiler.
The commend line is: ./test_progs -t tc_netkit_multi_links
Martin and I did some investigation and found this indeed the case and
the following are the investigation details.

Clang:
  clang version 18.0.0
  <I tried clang15/16/17 and they all have similar results>

tools/lib/bpf/libbpf_common.h:
  #define LIBBPF_OPTS_RESET(NAME"," ...)                                      \
        do {                                                                \
                memset(&NAME","[' 0', ' sizeof(NAME));                             \\\n                NAME = (typeof(NAME)) {                                     \\\n                        .sz = sizeof(NAME)', '                                 \\\n                        __VA_ARGS__                                         \\\n                };                                                          \\\n        } while (0)\n\n  #endif\n\ntools/lib/bpf/libbpf.h:\n  struct bpf_netkit_opts {\n        /* size of this struct', ' for forward/backward compatibility */\n        size_t sz;\n        __u32 flags;\n        __u32 relative_fd;\n        __u32 relative_id;\n        __u64 expected_revision;\n        size_t :0;\n  };\n  #define bpf_netkit_opts__last_field expected_revision\nIn the above struct bpf_netkit_opts', ' there is no tail padding.\n\nprog_tests/tc_netkit.c:\n  static void serial_test_tc_netkit_multi_links_target(int mode', ' int target)\n  {\n        ...\n        LIBBPF_OPTS(bpf_netkit_opts', ' optl);\n        ...\n        LIBBPF_OPTS_RESET(optl', '\n                .flags = BPF_F_BEFORE', '\n                .relative_fd = bpf_program__fd(skel->progs.tc1)', '\n        );\n        ...\n  }\n\nLet us make the following source change', ' note that we have a 4-byte\ntailing padding now.\n  diff --git a/tools/lib/bpf/libbpf.h b/tools/lib/bpf/libbpf.h\n  index 6cd9c501624f..0dd83910ae9a 100644\n  --- a/tools/lib/bpf/libbpf.h\n  +++ b/tools/lib/bpf/libbpf.h\n  @@ -803', '13 +803', '13 @@ bpf_program__attach_tcx(const struct bpf_program *prog', ' int ifindex', '\n   struct bpf_netkit_opts {\n        /* size of this struct', ' for forward/backward compatibility */\n        size_t sz;\n  -       __u32 flags;\n        __u32 relative_fd;\n        __u32 relative_id;\n        __u64 expected_revision;\n  +       __u32 flags;\n        size_t :0;\n   };\n  -#define bpf_netkit_opts__last_field expected_revision\n  +#define bpf_netkit_opts__last_field flags\n\nThe clang 18 generated asm code looks like below:\n    ;       LIBBPF_OPTS_RESET(optl', '\n    55e3: 48 8d 7d 98                   leaq    -0x68(%rbp)', ' %rdi\n    55e7: 31 f6                         xorl    %esi', ' %esi\n    55e9: ba 20 00 00 00                movl    $0x20', ' %edx\n    55ee: e8 00 00 00 00                callq   0x55f3 <serial_test_tc_netkit_multi_links_target+0x18d3>\n    55f3: 48 c7 85 10 fd ff ff 20 00 00 00      movq    $0x20', ' -0x2f0(%rbp)\n    55fe: 48 8b 85 68 ff ff ff          movq    -0x98(%rbp)', ' %rax\n    5605: 48 8b 78 18                   movq    0x18(%rax)', ' %rdi\n    5609: e8 00 00 00 00                callq   0x560e <serial_test_tc_netkit_multi_links_target+0x18ee>\n    560e: 89 85 18 fd ff ff             movl    %eax', ' -0x2e8(%rbp)\n    5614: c7 85 1c fd ff ff 00 00 00 00 movl    $0x0', ' -0x2e4(%rbp)\n    561e: 48 c7 85 20 fd ff ff 00 00 00 00      movq    $0x0', ' -0x2e0(%rbp)\n    5629: c7 85 28 fd ff ff 08 00 00 00 movl    $0x8', ' -0x2d8(%rbp)\n    5633: 48 8b 85 10 fd ff ff          movq    -0x2f0(%rbp)', ' %rax\n    563a: 48 89 45 98                   movq    %rax', ' -0x68(%rbp)\n    563e: 48 8b 85 18 fd ff ff          movq    -0x2e8(%rbp)', ' %rax\n    5645: 48 89 45 a0                   movq    %rax', ' -0x60(%rbp)\n    5649: 48 8b 85 20 fd ff ff          movq    -0x2e0(%rbp)', ' %rax\n    5650: 48 89 45 a8                   movq    %rax', ' -0x58(%rbp)\n    5654: 48 8b 85 28 fd ff ff          movq    -0x2d8(%rbp)', ' %rax\n    565b: 48 89 45 b0                   movq    %rax', ' -0x50(%rbp)\n    ;       link = bpf_program__attach_netkit(skel->progs.tc2', ' ifindex', ' &optl);\n\nAt -O0 level', "" the clang compiler creates an intermediate copy.\nWe have below to store 'flags' with 4-byte store and leave another 4 byte\nin the same 8-byte-aligned storage undefined"", '\n    5629: c7 85 28 fd ff ff 08 00 00 00 movl    $0x8', "" -0x2d8(%rbp)\nand later we store 8-byte to the original zero'ed buffer\n    5654: 48 8b 85 28 fd ff ff          movq    -0x2d8(%rbp)"", ' %rax\n    565b: 48 89 45 b0                   movq    %rax', ' -0x50(%rbp)\n\nThis caused a problem as the 4-byte value at [%rbp-0x2dc', ' %rbp-0x2e0)\nmay be garbage.\n\ngcc (gcc 11.4) does not have this issue as it does zeroing struct first before\ndoing assignments:\n  ;       LIBBPF_OPTS_RESET(optl', '\n    50fd: 48 8d 85 40 fc ff ff          leaq    -0x3c0(%rbp)', ' %rax\n    5104: ba 20 00 00 00                movl    $0x20', ' %edx\n    5109: be 00 00 00 00                movl    $0x0', ' %esi\n    510e: 48 89 c7                      movq    %rax', ' %rdi\n    5111: e8 00 00 00 00                callq   0x5116 <serial_test_tc_netkit_multi_links_target+0x1522>\n    5116: 48 8b 45 f0                   movq    -0x10(%rbp)', ' %rax\n    511a: 48 8b 40 18                   movq    0x18(%rax)', ' %rax\n    511e: 48 89 c7                      movq    %rax', ' %rdi\n    5121: e8 00 00 00 00                callq   0x5126 <serial_test_tc_netkit_multi_links_target+0x1532>\n    5126: 48 c7 85 40 fc ff ff 00 00 00 00      movq    $0x0', ' -0x3c0(%rbp)\n    5131: 48 c7 85 48 fc ff ff 00 00 00 00      movq    $0x0', ' -0x3b8(%rbp)\n    513c: 48 c7 85 50 fc ff ff 00 00 00 00      movq    $0x0', ' -0x3b0(%rbp)\n    5147: 48 c7 85 58 fc ff ff 00 00 00 00      movq    $0x0', ' -0x3a8(%rbp)\n    5152: 48 c7 85 40 fc ff ff 20 00 00 00      movq    $0x20', ' -0x3c0(%rbp)\n    515d: 89 85 48 fc ff ff             movl    %eax', ' -0x3b8(%rbp)\n    5163: c7 85 58 fc ff ff 08 00 00 00 movl    $0x8', ' -0x3a8(%rbp)\n  ;       link = bpf_program__attach_netkit(skel->progs.tc2', ' ifindex', ' &optl);\n\nIt is not clear how to resolve the compiler code generation as the compiler\ngenerates correct code w.r.t. how to handle unnamed padding in C standard.\nSo this patch changed LIBBPF_OPTS_RESET macro to avoid uninitialized tail\npadding. We already knows LIBBPF_OPTS macro works on both gcc and clang', '\neven with tail padding. So LIBBPF_OPTS_RESET is changed to be a\nLIBBPF_OPTS followed by a memcpy()', ' thus avoiding uninitialized tail padding.\n\nThe below is asm code generated with this patch and with clang compiler:\n    ;       LIBBPF_OPTS_RESET(optl', '\n    55e3: 48 8d bd 10 fd ff ff          leaq    -0x2f0(%rbp)', ' %rdi\n    55ea: 31 f6                         xorl    %esi', ' %esi\n    55ec: ba 20 00 00 00                movl    $0x20', ' %edx\n    55f1: e8 00 00 00 00                callq   0x55f6 <serial_test_tc_netkit_multi_links_target+0x18d6>\n    55f6: 48 c7 85 10 fd ff ff 20 00 00 00      movq    $0x20', ' -0x2f0(%rbp)\n    5601: 48 8b 85 68 ff ff ff          movq    -0x98(%rbp)', ' %rax\n    5608: 48 8b 78 18                   movq    0x18(%rax)', ' %rdi\n    560c: e8 00 00 00 00                callq   0x5611 <serial_test_tc_netkit_multi_links_target+0x18f1>\n    5611: 89 85 18 fd ff ff             movl    %eax', ' -0x2e8(%rbp)\n    5617: c7 85 1c fd ff ff 00 00 00 00 movl    $0x0', ' -0x2e4(%rbp)\n    5621: 48 c7 85 20 fd ff ff 00 00 00 00      movq    $0x0', ' -0x2e0(%rbp)\n    562c: c7 85 28 fd ff ff 08 00 00 00 movl    $0x8', ' -0x2d8(%rbp)\n    5636: 48 8b 85 10 fd ff ff          movq    -0x2f0(%rbp)', ' %rax\n    563d: 48 89 45 98                   movq    %rax', ' -0x68(%rbp)\n    5641: 48 8b 85 18 fd ff ff          movq    -0x2e8(%rbp)', ' %rax\n    5648: 48 89 45 a0                   movq    %rax', ' -0x60(%rbp)\n    564c: 48 8b 85 20 fd ff ff          movq    -0x2e0(%rbp)', ' %rax\n    5653: 48 89 45 a8                   movq    %rax', ' -0x58(%rbp)\n    5657: 48 8b 85 28 fd ff ff          movq    -0x2d8(%rbp)', ' %rax\n    565e: 48 89 45 b0                   movq    %rax', ' -0x50(%rbp)\n    ;       link = bpf_program__attach_netkit(skel->progs.tc2', ' ifindex', ' &optl);\n\nIn the above code', ' a temporary buffer is zeroed and then has proper value assigned.\nFinally', ' values in temporary buffer are copied to the original variable buffer', '\nhence tail padding is guaranteed to be 0.\n\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nTested-by: Martin KaFai Lau <martin.lau@kernel.org>\nLink: https://lore.kernel.org/bpf/20231107201511.2548645-1-yonghong.song@linux.dev\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix uninitialized tail padding issue in libbpf when using LIBBPF_OPTS_RESET macro with clang compiler.,"libbpf, uninitialized, clang",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
649924b76ab151a96bdd22a97a993fb0421f134c,649924b76ab151a96bdd22a97a993fb0421f134c,Dave Marchevsky,davemarchevsky@fb.com,1699347396,Alexei Starovoitov,ast@kernel.org,1699585671,fbe3b9142af1969a7597d03cb57261d23534f6ef,f460e7bdb027d1da93f0c5090b239889cd46a33d,"bpf: Use bpf_mem_free_rcu when bpf_obj_dropping non-refcounted nodes

The use of bpf_mem_free_rcu to free refcounted local kptrs was added
in commit 7e26cd12ad1c (""bpf: Use bpf_mem_free_rcu when
bpf_obj_dropping refcounted nodes""). In the cover letter for the
series containing that patch [0] I commented:

    Perhaps it makes sense to move to mem_free_rcu for _all_
    non-owning refs in the future"," not just refcounted. This might
    allow custom non-owning ref lifetime + invalidation logic to be
    entirely subsumed by MEM_RCU handling. IMO this needs a bit more
    thought and should be tackled outside of a fix series","[' so it\'s not\n    attempted here.\n\nIt\'s time to start moving in the ""non-owning refs have MEM_RCU\nlifetime"" direction. As mentioned in that comment', "" using\nbpf_mem_free_rcu for all local kptrs - not just refcounted - is\nnecessarily the first step towards that goal. This patch does so.\n\nAfter this patch the memory pointed to by all local kptrs will not be\nreused until RCU grace period elapses. The verifier's understanding of\nnon-owning ref validity and the clobbering logic it uses to enforce\nthat understanding are not changed here"", "" that'll happen gradually in\nfuture work"", ' including further patches in the series.\n\n  [0]: https://lore.kernel.org/all/20230821193311.3290257-1-davemarchevsky@fb.com/\n\nSigned-off-by: Dave Marchevsky <davemarchevsky@fb.com>\nLink: https://lore.kernel.org/r/20231107085639.3016113-4-davemarchevsky@fb.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Utilize bpf_mem_free_rcu for freeing non-refcounted nodes in bpf_obj_dropping to potentially streamline reference handling.,"bpf_mem_free_rcu,non-refcounted,nodes",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f460e7bdb027d1da93f0c5090b239889cd46a33d,f460e7bdb027d1da93f0c5090b239889cd46a33d,Dave Marchevsky,davemarchevsky@fb.com,1699347395,Alexei Starovoitov,ast@kernel.org,1699585671,463f36a4f1d9048c1710da3fe469a9dda318ae32,1500a5d9f49cb66906d3ea1c9158df25cc41dd40,"selftests/bpf: Add test passing MAYBE_NULL reg to bpf_refcount_acquire

The test added in this patch exercises the logic fixed in the previous
patch in this series. Before the previous patch's changes","
bpf_refcount_acquire accepts MAYBE_NULL local kptrs; after the change
the verifier correctly rejects the such a call.

Signed-off-by: Dave Marchevsky <davemarchevsky@fb.com>
Link: https://lore.kernel.org/r/20231107085639.3016113-3-davemarchevsky@fb.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Added a selftest for bpf_refcount_acquire handling of MAYBE_NULL reg in eBPF.,"selftest,bpf_refcount_acquire,MAYBE_NULL",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1500a5d9f49cb66906d3ea1c9158df25cc41dd40,1500a5d9f49cb66906d3ea1c9158df25cc41dd40,Dave Marchevsky,davemarchevsky@fb.com,1699347394,Alexei Starovoitov,ast@kernel.org,1699585671,e0fbb55fc5153e5187e424e4db11f2eb5aa889f4,82ce364c6087e31ff9837380a4641a856284064c,"bpf: Add KF_RCU flag to bpf_refcount_acquire_impl

Refcounted local kptrs are kptrs to user-defined types with a
bpf_refcount field. Recent commits ([0]"," [1]) modified the lifetime of
refcounted local kptrs such that the underlying memory is not reused
until RCU grace period has elapsed.

Separately","[' verification of bpf_refcount_acquire calls currently\nsucceeds for MAYBE_NULL non-owning reference input', ' which is a problem\nas bpf_refcount_acquire_impl has no handling for this case.\n\nThis patch takes advantage of aforementioned lifetime changes to tag\nbpf_refcount_acquire_impl kfunc KF_RCU', ' thereby preventing MAYBE_NULL\ninput to the kfunc. The KF_RCU flag applies to all kfunc params; it\'s\nfine for it to apply to the void *meta__ign param as that\'s populated by\nthe verifier and is tagged __ign regardless.\n\n  [0]: commit 7e26cd12ad1c (""bpf: Use bpf_mem_free_rcu when\n       bpf_obj_dropping refcounted nodes"") is the actual change to\n       allocation behaivor\n  [1]: commit 0816b8c6bf7f (""bpf: Consider non-owning refs to refcounted\n       nodes RCU protected"") modified verifier understanding of\n       refcounted local kptrs to match [0]\'s changes\n\nSigned-off-by: Dave Marchevsky <davemarchevsky@fb.com>\nFixes: 7c50b1cb76ac (""bpf: Add bpf_refcount_acquire kfunc"")\nLink: https://lore.kernel.org/r/20231107085639.3016113-2-davemarchevsky@fb.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Added KF_RCU flag to bpf_refcount_acquire_impl for refcounted local kptr memory handling.,"KF_RCU, bpf_refcount, kptrs",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b0d1c7294671af02369d7a4feaa5a9bb472372c6,b0d1c7294671af02369d7a4feaa5a9bb472372c6,Andrii Nakryiko,andrii@kernel.org,1699380278,Alexei Starovoitov,ast@kernel.org,1699585664,c43ffde215600c1540057a1cb6680d5ac23e90fd,9b75dbeb36fcd9fc7ed51d370310d0518a387769 045edee19d591e59ed53772bf6dfc9b1ed9577eb,"Merge branch 'bpf: __bpf_dynptr_data* and __str annotation'

Song Liu says:

====================
This set contains the first 3 patches of set [1]. Currently"," [1] is waiting
for [3] to be merged to bpf-next tree. So send these 3 patches first to
unblock other works","[' such as [2]. This set is verified with new version of\n[1] in CI run [4].\n\nChanges since v12 of [1]:\n1. Reuse bpf_dynptr_slice() in __bpf_dynptr_data(). (Andrii)\n2. Add Acked-by from Vadim Fedorenko.\n\n[1] https://lore.kernel.org/bpf/20231104001313.3538201-1-song@kernel.org/\n[2] https://lore.kernel.org/bpf/20231031134900.1432945-1-vadfed@meta.com/\n[3] https://lore.kernel.org/bpf/20231031215625.2343848-1-davemarchevsky@fb.com/\n[4] https://github.com/kernel-patches/bpf/actions/runs/6779945063/job/18427926114\n====================\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Merges initial set of patches related to __bpf_dynptr_data and __str annotation to unblock further developments.,"__bpf_dynptr_data, __str annotation, patches",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9b75dbeb36fcd9fc7ed51d370310d0518a387769,9b75dbeb36fcd9fc7ed51d370310d0518a387769,Florian Lehner,dev@der-flo.net,1699174681,Alexei Starovoitov,ast@kernel.org,1699585658,d7a194a3c697a90c9b404db8c9f4d000c00021de,f2d2c7e1b7c9e8847478769d6e1f8a76b5e91952,bpf," lpm: Fix check prefixlen before walking trie

When looking up an element in LPM trie","["" the condition 'matchlen ==\ntrie->max_prefixlen' will never return true"", ' if key->prefixlen is larger\nthan trie->max_prefixlen. Consequently all elements in the LPM trie will\nbe visited and no element is returned in the end.\n\nTo resolve this', ' check key->prefixlen first before walking the LPM trie.\n\nFixes: b95a5c4db09b (""bpf: add a longest prefix match trie map implementation"")\nSigned-off-by: Florian Lehner <dev@der-flo.net>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20231105085801.3742-1-dev@der-flo.net\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes prefix length check before traversing LPM trie in eBPF.,"prefixlen, trie, fix",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,['tc/netfilter like programs']
045edee19d591e59ed53772bf6dfc9b1ed9577eb,045edee19d591e59ed53772bf6dfc9b1ed9577eb,Song Liu,song@kernel.org,1699333045,Alexei Starovoitov,ast@kernel.org,1699585658,c43ffde215600c1540057a1cb6680d5ac23e90fd,0b51940729150e807fc4b7767164e6bb6cf4f7dd,"bpf: Introduce KF_ARG_PTR_TO_CONST_STR

Similar to ARG_PTR_TO_CONST_STR for BPF helpers"," KF_ARG_PTR_TO_CONST_STR
specifies kfunc args that point to const strings. Annotation ""__str"" is
used to specify kfunc arg of type KF_ARG_PTR_TO_CONST_STR. Also","[' add\ndocumentation for the ""__str"" annotation.\n\nbpf_get_file_xattr() will be the first kfunc that uses this type.\n\nSigned-off-by: Song Liu <song@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Vadim Fedorenko <vadim.fedorenko@linux.dev>\nLink: https://lore.kernel.org/bpf/20231107045725.2278852-4-song@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Introduce KF_ARG_PTR_TO_CONST_STR for specifying kfunc args pointing to constant strings in BPF.,"KF_ARG_PTR_TO_CONST_STR, kfunc, const strings",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f2d2c7e1b7c9e8847478769d6e1f8a76b5e91952,f2d2c7e1b7c9e8847478769d6e1f8a76b5e91952,Anders Roxell,anders.roxell@linaro.org,1699049352,Alexei Starovoitov,ast@kernel.org,1699585658,2c9f1ce28a74ed27676996dbf02342b531719c28,a46afaa03f6db8c65492302ffdafcb2e769e5667,"selftests/bpf: Disable CONFIG_DEBUG_INFO_REDUCED in config.aarch64

Building an arm64 kernel and seftests/bpf with defconfig +
selftests/bpf/config and selftests/bpf/config.aarch64 the fragment
CONFIG_DEBUG_INFO_REDUCED is enabled in arm64's defconfig"," it should be
disabled in file sefltests/bpf/config.aarch64 since if its not disabled
CONFIG_DEBUG_INFO_BTF wont be enabled.

Signed-off-by: Anders Roxell <anders.roxell@linaro.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20231103220912.333930-1-anders.roxell@linaro.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Disable CONFIG_DEBUG_INFO_REDUCED in config.aarch64 to ensure CONFIG_DEBUG_INFO_BTF can be enabled for selftests/bpf.,"selftests, CONFIG_DEBUG_INFO, aarch64",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0b51940729150e807fc4b7767164e6bb6cf4f7dd,0b51940729150e807fc4b7767164e6bb6cf4f7dd,Song Liu,song@kernel.org,1699333044,Alexei Starovoitov,ast@kernel.org,1699585658,4937cbe0b7a90c82ccf94fefa34244db49e3fa1e,74523c06ae20b83c5508a98af62393ac34913362,"bpf: Factor out helper check_reg_const_str()

ARG_PTR_TO_CONST_STR is used to specify constant string args for BPF
helpers. The logic that verifies a reg is ARG_PTR_TO_CONST_STR is
implemented in check_func_arg().

As we introduce kfuncs with constant string args"," it is necessary to
do the same check for kfuncs (in check_kfunc_args). Factor out the logic
for ARG_PTR_TO_CONST_STR to a new check_reg_const_str() so that it can be
reused.

check_func_arg() ensures check_reg_const_str() is only called with reg of
type PTR_TO_MAP_VALUE. Add a redundent type check in check_reg_const_str()
to avoid misuse in the future. Other than this redundent check","[' there is\nno change in behavior.\n\nSigned-off-by: Song Liu <song@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Vadim Fedorenko <vadim.fedorenko@linux.dev>\nLink: https://lore.kernel.org/bpf/20231107045725.2278852-3-song@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit refactors code to introduce a reusable function for constant string argument verification in BPF helpers and kfuncs.,"helper, check, refactor",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a46afaa03f6db8c65492302ffdafcb2e769e5667,a46afaa03f6db8c65492302ffdafcb2e769e5667,Artem Savkov,asavkov@redhat.com,1698999086,Alexei Starovoitov,ast@kernel.org,1699585658,7690701120b8ae403b9801c07a048bc14aa2aafe,b0cf0dcde8cae24571b1f382e81328229e475604,"bpftool: Fix prog object type in manpage

bpftool's man page lists ""program"" as one of possible values for OBJECT","
while in fact bpftool accepts ""prog"" instead.

Reported-by: Jerry Snitselaar <jsnitsel@redhat.com>
Signed-off-by: Artem Savkov <asavkov@redhat.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Acked-by: Quentin Monnet <quentin@isovalent.com>
Link: https://lore.kernel.org/bpf/20231103081126.170034-1-asavkov@redhat.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],"Corrects the bpftool man page to reflect the correct object type ""prog"" instead of ""program"".","bpftool,manpage,prog",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"[""It's not related to any of the above.""]"
74523c06ae20b83c5508a98af62393ac34913362,74523c06ae20b83c5508a98af62393ac34913362,Song Liu,song@kernel.org,1699333043,Alexei Starovoitov,ast@kernel.org,1699585658,fed41c7eb41d0ded5f654e08fc939648363ddae9,9b75dbeb36fcd9fc7ed51d370310d0518a387769,"bpf: Add __bpf_dynptr_data* for in kernel use

Different types of bpf dynptr have different internal data storage.
Specifically"," SKB and XDP type of dynptr may have non-continuous data.
Therefore","[' it is not always safe to directly access dynptr->data.\n\nAdd __bpf_dynptr_data and __bpf_dynptr_data_rw to replace direct access to\ndynptr->data.\n\nUpdate bpf_verify_pkcs7_signature to use __bpf_dynptr_data instead of\ndynptr->data.\n\nSigned-off-by: Song Liu <song@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Vadim Fedorenko <vadim.fedorenko@linux.dev>\nLink: https://lore.kernel.org/bpf/20231107045725.2278852-2-song@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add __bpf_dynptr_data* function for internal kernel use to handle bpf dynptr with non-continuous data storage.,"bpf,dynptr,kernel",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['xdp like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b0cf0dcde8cae24571b1f382e81328229e475604,b0cf0dcde8cae24571b1f382e81328229e475604,Manu Bretelle,chantr4@gmail.com,1698787637,Alexei Starovoitov,ast@kernel.org,1699585658,26980381c594711ab0e258deec05e2c30238816d,e3499962d836af085a621f005978fee20fc87276,"selftests/bpf: Consolidate VIRTIO/9P configs in config.vm file

Those configs are needed to be able to run VM somewhat consistently.
For instance", ATM,"[' s390x is missing the `CONFIG_VIRTIO_CONSOLE` which\nprevents s390x kernels built in CI to leverage qemu-guest-agent.\n\nBy moving them to `config', 'vm`', "" we should have selftest kernels which are\nequal in term of VM functionalities when they include this file.\n\nThe set of config unabled were picked using\n\n    grep -h -E '(_9P|_VIRTIO)' config.x86_64 config | sort | uniq\n\nadded to `config.vm` and then\n    grep -vE '(_9P|_VIRTIO)' config.{x86_64"", 'aarch64', 's390x}\n\nas a side-effect', ' some config may have disappeared to the aarch64 and\ns390x kernels', ' but they should not be needed. CI will tell.\n\nSigned-off-by: Manu Bretelle <chantr4@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20231031212717.4037892-1-chantr4@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Consolidate VIRTIO and 9P configuration settings in the config.vm file for consistent VM execution.,"configs, VM, VIRTIO",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"[""It's not related to any of the above.""]"
e3499962d836af085a621f005978fee20fc87276,e3499962d836af085a621f005978fee20fc87276,Andrii Nakryiko,andrii@kernel.org,1698943661,Alexei Starovoitov,ast@kernel.org,1699585583,989e0be5c06e56cf68317fbd3614ed9e2423d5b2,cd9c127069c040d6b022f1ff32fed4b52b9a4017 2f553b032cad4993969cab356b3b0e306fcd1cd1,"Merge branch 'selftests/bpf: Fixes for map_percpu_stats test'

Hou Tao says:

====================
From: Hou Tao <houtao1@huawei.com>

Hi","

BPF CI failed due to map_percpu_stats_percpu_hash from time to time [1].
It seems that the failure reason is per-cpu bpf memory allocator may not
be able to allocate per-cpu pointer successfully and it can not refill
free llist timely","[' and bpf_map_update_elem() will return -ENOMEM.\n\nPatch #1 fixes the size of value passed to per-cpu map update API. The\nproblem was found when fixing the ENOMEM problem', ' so also post it in\nthis patchset. Patch #2 & #3 mitigates the ENOMEM problem by retrying\nthe update operation for non-preallocated per-cpu map.\n\nPlease see individual patches for more details. And comments are always\nwelcome.\n\nRegards', '\nTao\n\n[1]: https://github.com/kernel-patches/bpf/actions/runs/6713177520/job/18244865326?pr=5909\n====================\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes allocation issues in map_percpu_stats test to address BPF CI failures.,"map_percpu_stats,test,allocation",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
cd9c127069c040d6b022f1ff32fed4b52b9a4017,cd9c127069c040d6b022f1ff32fed4b52b9a4017,Alexei Starovoitov,ast@kernel.org,1698940745,Alexei Starovoitov,ast@kernel.org,1699585120,61c346feb4d979fc120c6802a38104f14f948551,bf4a64b9323f181df8aba32d66cb37b9fa5df959 4621202adc5bc0d1006af37fe8b9aca131387d3c,"Merge branch 'bpf-register-bounds-logic-and-testing-improvements'

Andrii Nakryiko says:

====================
BPF register bounds logic and testing improvements

This patch set adds a big set of manual and auto-generated test cases
validating BPF verifier's register bounds tracking and deduction logic. See
details in the last patch.

We start with building a tester that validates existing <range> vs <scalar>
verifier logic for range bounds. To make all this work"," BPF verifier's logic
needed a bunch of improvements to handle some cases that previously were not
covered. This had no implications as to correctness of verifier logic","[' but it\nwas incomplete enough to cause significant disagreements with alternative\nimplementation of register bounds logic that tests in this patch set\nimplement. So we need BPF verifier logic improvements to make all the tests\npass. This is what we do in patches #3 through #9.\n\nThe end goal of this work', ' though', ' is to extend BPF verifier range state\ntracking such as to allow to derive new range bounds when comparing non-const\nregisters. There is some more investigative work required to investigate and\nfix existing potential issues with range tracking as part of ALU/ALU64\noperations', ' so <range> x <range> part of v5 patch set ([0]) is dropped until\nthese issues are sorted out.\n\nFor now', ' we include preparatory refactorings and clean ups', ' that set up BPF\nverifier code base to extend the logic to <range> vs <range> logic in\nsubsequent patch set. Patches #10-#16 perform preliminary refactorings without\nfunctionally changing anything. But they do clean up check_cond_jmp_op() logic\nand generalize a bunch of other pieces in is_branch_taken() logic.\n\n  [0] https://patchwork.kernel.org/project/netdevbpf/list/?series=797178&state=*\n\nv5->v6:\n  - dropped <range> vs <range> patches (original patches #18 through #23) to\n    add more register range sanity checks and fix preexisting issues;\n  - comments improvements', ' addressing other feedback on first 17 patches\n    (Eduard', ' Alexei);\nv4->v5:\n  - added entirety of verifier reg bounds tracking changes', ' now handling\n    <range> vs <range> cases (Alexei);\n  - added way more comments trying to explain why deductions added are\n    correct', ' hopefully they are useful and clarify things a bit (Daniel', '\n    Shung-Hsi);\n  - added two preliminary selftests fixes necessary for RELEASE=1 build to\n    work again', ' it keeps breaking.\nv3->v4:\n  - improvements to reg_bounds tester (progress report', ' split 32-bit and\n    64-bit ranges', ' fix various verbosity output issues', ' etc);\nv2->v3:\n  - fix a subtle little-endianness assumption inside parge_reg_state() (CI);\nv1->v2:\n  - fix compilation when building selftests with llvm-16 toolchain (CI).\n====================\n\nLink: https://lore.kernel.org/r/20231102033759.2541186-1-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Improves BPF verifier's register bounds logic and adds extensive testing.,"verifier,bounds,testing",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2f553b032cad4993969cab356b3b0e306fcd1cd1,2f553b032cad4993969cab356b3b0e306fcd1cd1,Hou Tao,houtao1@huawei.com,1698809095,Alexei Starovoitov,ast@kernel.org,1699585120,989e0be5c06e56cf68317fbd3614ed9e2423d5b2,b9b79553163788d3fc42e25c2662c0a46dc9a3c5,"selftsets/bpf: Retry map update for non-preallocated per-cpu map

BPF CI failed due to map_percpu_stats_percpu_hash from time to time [1].
It seems that the failure reason is per-cpu bpf memory allocator may not
be able to allocate per-cpu pointer successfully and it can not refill
free llist timely"," and bpf_map_update_elem() will return -ENOMEM.

So mitigate the problem by retrying the update operation for
non-preallocated per-cpu map.

[1]: https://github.com/kernel-patches/bpf/actions/runs/6713177520/job/18244865326?pr=5909

Signed-off-by: Hou Tao <houtao1@huawei.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20231101032455.3808547-4-houtao@huaweicloud.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Retry map update for non-preallocated per-cpu map to mitigate allocation failure issues.,"non-preallocated,map update,retry",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4621202adc5bc0d1006af37fe8b9aca131387d3c,4621202adc5bc0d1006af37fe8b9aca131387d3c,Andrii Nakryiko,andrii@kernel.org,1698896279,Alexei Starovoitov,ast@kernel.org,1699585120,61c346feb4d979fc120c6802a38104f14f948551,811476e9cc578cb6c776627ac069dc45a8431791,"bpf: generalize reg_set_min_max() to handle two sets of two registers

Change reg_set_min_max() to take FALSE/TRUE sets of two registers each","
instead of assuming that we are always comparing to a constant. For now
we still assume that right-hand side registers are constants (and make
sure that's the case by swapping src/dst regs","[' if necessary)', ' but\nsubsequent patches will remove this limitation.\n\nreg_set_min_max() is now called unconditionally for any register\ncomparison', ' so that might include pointer vs pointer. This makes it\nconsistent with is_branch_taken() generality. But we currently only\nsupport adjustments based on SCALAR vs SCALAR comparisons', ' so\nreg_set_min_max() has to guard itself againts pointers.\n\nTaking two by two registers allows to further unify and simplify\ncheck_cond_jmp_op() logic. We utilize fake register for BPF_K\nconditional jump case', ' just like with is_branch_taken() part.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231102033759.2541186-18-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Enhance reg_set_min_max to handle two register sets instead of constants in BPF.,"reg_set_min_max,registers,BPF",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b9b79553163788d3fc42e25c2662c0a46dc9a3c5,b9b79553163788d3fc42e25c2662c0a46dc9a3c5,Hou Tao,houtao1@huawei.com,1698809094,Alexei Starovoitov,ast@kernel.org,1699585120,91c95c77cc400268ee2518600f1add72c9f0357f,d79924ca579c647d5dc55f605899c98f7ea04d0f,"selftests/bpf: Export map_update_retriable()

Export map_update_retriable() to make it usable for other map_test
cases. These cases may only need retry for specific errno"," so add
a new callback parameter to let map_update_retriable() decide whether or
not the errno is retriable.

Signed-off-by: Hou Tao <houtao1@huawei.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20231101032455.3808547-3-houtao@huaweicloud.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Exported map_update_retriable() for use in other test cases with a new callback for custom errno retries.,"map_update_retriable, export, errno",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
811476e9cc578cb6c776627ac069dc45a8431791,811476e9cc578cb6c776627ac069dc45a8431791,Andrii Nakryiko,andrii@kernel.org,1698896278,Alexei Starovoitov,ast@kernel.org,1699585120,ddf66079d40143a52af6daa840aa17390d8d6cd7,4d345887d2e5a1915600cb5d37b16c4088c6ee1c,"bpf: prepare reg_set_min_max for second set of registers

Similarly to is_branch_taken()-related refactorings"," start preparing
reg_set_min_max() to handle more generic case of two non-const
registers. Start with renaming arguments to accommodate later addition
of second register as an input argument.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231102033759.2541186-17-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Refactoring reg_set_min_max function to accommodate handling two non-const registers.,"refactoring, reg_set_min_max, registers",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d79924ca579c647d5dc55f605899c98f7ea04d0f,d79924ca579c647d5dc55f605899c98f7ea04d0f,Hou Tao,houtao1@huawei.com,1698809093,Alexei Starovoitov,ast@kernel.org,1699585120,cebfdf98a2a67fd0a9dc9150db3e723e0c8dfa70,cd9c127069c040d6b022f1ff32fed4b52b9a4017,"selftests/bpf: Use value with enough-size when updating per-cpu map

When updating per-cpu map in map_percpu_stats test"," patch_map_thread()
only passes 4-bytes-sized value to bpf_map_update_elem(). The expected
size of the value is 8 * num_possible_cpus()","[' so fix it by passing a\nvalue with enough-size for per-cpu map update.\n\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20231101032455.3808547-2-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes the update of per-cpu map with correct value size in selftests for bpf.,"per-cpu map,bpf_map_update_elem,selftests",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tracepoints like programs']
4d345887d2e5a1915600cb5d37b16c4088c6ee1c,4d345887d2e5a1915600cb5d37b16c4088c6ee1c,Andrii Nakryiko,andrii@kernel.org,1698896277,Alexei Starovoitov,ast@kernel.org,1699585120,1a5b19342db6db72b1f6b5d2054ce9ad0a6ad193,b74c2a842bba941945279027083fcee1e9aaa73f,"bpf: unify 32-bit and 64-bit is_branch_taken logic

Combine 32-bit and 64-bit is_branch_taken logic for SCALAR_VALUE
registers. It makes it easier to see parallels between two domains
(32-bit and 64-bit)"," and makes subsequent refactoring more
straightforward.

No functional changes.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231102033759.2541186-16-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Combine 32-bit and 64-bit is_branch_taken logic for SCALAR_VALUE registers.,"unify, is_branch_taken, SCALAR_VALUE",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b74c2a842bba941945279027083fcee1e9aaa73f,b74c2a842bba941945279027083fcee1e9aaa73f,Andrii Nakryiko,andrii@kernel.org,1698896276,Alexei Starovoitov,ast@kernel.org,1699585120,b74a08de9ced5f5a686a7cbf080296652d03421b,c697289efe4ef38bc5c62f119cb74433f784b826,"bpf: generalize is_branch_taken to handle all conditional jumps in one place

Make is_branch_taken() a single entry point for branch pruning decision
making", handling both pointer vs pointer,"[' pointer vs scalar', ' and scalar\nvs scalar cases in one place. This also nicely cleans up check_cond_jmp_op().\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231102033759.2541186-15-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Generalized is_branch_taken function to handle all conditional jumps for branch pruning in BPF.,"is_branch_taken, branch, conditional",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c697289efe4ef38bc5c62f119cb74433f784b826,c697289efe4ef38bc5c62f119cb74433f784b826,Andrii Nakryiko,andrii@kernel.org,1698896275,Alexei Starovoitov,ast@kernel.org,1699585119,8d0218e3e7fb02b1647586e03d5ca0a01c133934,c31534267c180f7ed00288d239a501b554885300,"bpf: move is_branch_taken() down

Move is_branch_taken() slightly down. In subsequent patched we'll need
both flip_opcode() and is_pkt_ptr_branch_taken() for is_branch_taken()","
but instead of sprinkling forward declarations around","[' it makes more\nsense to move is_branch_taken() lower below is_pkt_ptr_branch_taken()', '\nand also keep it closer to very tightly related reg_set_min_max()', ' as\nthey are two critical parts of the same SCALAR range tracking logic.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231102033759.2541186-14-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Refactor to move is_branch_taken() function down for improved code organization.,"bpf,refactor,branching",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c31534267c180f7ed00288d239a501b554885300,c31534267c180f7ed00288d239a501b554885300,Andrii Nakryiko,andrii@kernel.org,1698896274,Alexei Starovoitov,ast@kernel.org,1699585119,a3ff31f785879c916863516a1f7aac825c2b9af3,c2a3ab094683ddc154879a1364fc7cb0228f96a6,"bpf: generalize is_branch_taken() to work with two registers

While still assuming that second register is a constant"," generalize
is_branch_taken-related code to accept two registers instead of register
plus explicit constant value. This also","[' as a side effect', ' allows to\nsimplify check_cond_jmp_op() by unifying BPF_K case with BPF_X case', "" for\nwhich we use a fake register to represent BPF_K's imm constant as\na register.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nLink: https://lore.kernel.org/r/20231102033759.2541186-13-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n"", '']",The commit generalizes the is_branch_taken() function to work with two registers instead of a register plus a constant.,"generalize, is_branch_taken, registers",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c2a3ab094683ddc154879a1364fc7cb0228f96a6,c2a3ab094683ddc154879a1364fc7cb0228f96a6,Andrii Nakryiko,andrii@kernel.org,1698896273,Alexei Starovoitov,ast@kernel.org,1699585119,321bea65b64e63097448f28288a2415342884092,9e314f5d8682e1fe6ac214fb34580a238b6fd3c4,"bpf: rename is_branch_taken reg arguments to prepare for the second one

Just taking mundane refactoring bits out into a separate patch. No
functional changes.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>
Link: https://lore.kernel.org/r/20231102033759.2541186-12-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Refactor bpf function is_branch_taken by renaming register arguments for future enhancements.,"refactor,bpf,function",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9e314f5d8682e1fe6ac214fb34580a238b6fd3c4,9e314f5d8682e1fe6ac214fb34580a238b6fd3c4,Andrii Nakryiko,andrii@kernel.org,1698896271,Alexei Starovoitov,ast@kernel.org,1699585119,eecf7eb66fe76017e0d040fb815a8dc9513e5d74,d7f00873817129e62f8c70891cb13c8eafe9feef,bpf: drop knowledge-losing __reg_combine_{32,64}_into_{64,"['32} logic\n\nWhen performing 32-bit conditional operation operating on lower 32 bits\nof a full 64-bit register', "" register full value isn't changed. We just\npotentially gain new knowledge about that register's lower 32 bits.\n\nUnfortunately"", ' __reg_combine_{32', '64}_into_{64', '32} logic that\nreg_set_min_max() performs as a last step', "" can lose information in some\ncases due to __mark_reg64_unbounded() and __reg_assign_32_into_64().\nThat's bad and completely unnecessary. Especially __reg_assign_32_into_64()\nlooks completely out of place here"", ' because we are not performing\nzero-extending subregister assignment during conditional jump.\n\nSo this patch replaced __reg_combine_* with just a normal\nreg_bounds_sync() which will do a proper job of deriving u64/s64 bounds\nfrom u32/s32', ' and vice versa (among all other combinations).\n\n__reg_combine_64_into_32() is also used in one more place', '\ncoerce_reg_to_size()', ' while handling 1- and 2-byte register loads.\nLooking into this', ' it seems like besides marking subregister as\nunbounded before performing reg_bounds_sync()', "" we were also performing\ndeduction of smin32/smax32 and umin32/umax32 bounds from respective\nsmin/smax and umin/umax bounds. It's now redundant as reg_bounds_sync()\nperforms all the same logic more generically (e.g."", ' without unnecessary\nassumption that upper 32 bits of full register should be zero).\n\nLong story short', ' we remove __reg_combine_64_into_32() completely', ' and\ncoerce_reg_to_size() now only does resetting subreg to unbounded and then\nperforming reg_bounds_sync() to recover as much information as possible\nfrom 64-bit umin/umax and smin/smax bounds', ' set explicitly in\ncoerce_reg_to_size() earlier.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nLink: https://lore.kernel.org/r/20231102033759.2541186-10-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Removed unnecessary knowledge-losing reg combine functions in eBPF verifier.,"knowledge-losing, reg combine, eBPF verifier",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d7f00873817129e62f8c70891cb13c8eafe9feef,d7f00873817129e62f8c70891cb13c8eafe9feef,Andrii Nakryiko,andrii@kernel.org,1698896270,Alexei Starovoitov,ast@kernel.org,1699585119,f3c7aaa04cdcf0cae9f89d0af97451977bffe74d,c51d5ad6543cc36334ef1fcd762d0df767a0bf7e,"bpf: try harder to deduce register bounds from different numeric domains

There are cases (caught by subsequent reg_bounds tests in selftests/bpf)
where performing one round of __reg_deduce_bounds() doesn't propagate
all the information from", say,"[' s32 to u32 bounds and than from newly\nlearned u32 bounds back to u64 and s64. So perform __reg_deduce_bounds()\ntwice to make sure such derivations are propagated fully after\nreg_bounds_sync().\n\nOne such example is test `(s64)[0xffffffff00000001; 0] (u64)<\n0xffffffff00000000` from selftest patch from this patch set. It demonstrates an\nintricate dance of u64 -> s64 -> u64 -> u32 bounds adjustments', ' which requires\ntwo rounds of __reg_deduce_bounds(). Here are corresponding refinement log from\nselftest', ' showing evolution of knowledge.\n\nREFINING (FALSE R1) (u64)SRC=[0xffffffff00000000; U64_MAX] (u64)DST_OLD=[0; U64_MAX] (u64)DST_NEW=[0xffffffff00000000; U64_MAX]\nREFINING (FALSE R1) (u64)SRC=[0xffffffff00000000; U64_MAX] (s64)DST_OLD=[0xffffffff00000001; 0] (s64)DST_NEW=[0xffffffff00000001; -1]\nREFINING (FALSE R1) (s64)SRC=[0xffffffff00000001; -1] (u64)DST_OLD=[0xffffffff00000000; U64_MAX] (u64)DST_NEW=[0xffffffff00000001; U64_MAX]\nREFINING (FALSE R1) (u64)SRC=[0xffffffff00000001; U64_MAX] (u32)DST_OLD=[0; U32_MAX] (u32)DST_NEW=[1; U32_MAX]\n\nR1 initially has smin/smax set to [0xffffffff00000001; -1]', ' while umin/umax is\nunknown. After (u64)< comparison', "" in FALSE branch we gain knowledge that\numin/umax is [0xffffffff00000000; U64_MAX]. That causes smin/smax to learn that\nzero can't happen and upper bound is -1. Then smin/smax is adjusted from\numin/umax improving lower bound from 0xffffffff00000000 to 0xffffffff00000001.\nAnd then eventually umin32/umax32 bounds are drived from umin/umax and become\n[1; U32_MAX].\n\nSelftest in the last patch is actually implementing a multi-round fixed-point\nconvergence logic"", ' but so far all the tests are handled by two rounds of\nreg_bounds_sync() on the verifier state', ' so we keep it simple for now.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231102033759.2541186-9-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Improve register bounds deduction in eBPF by enhancing boundary information propagation between numeric domains.,"register,bounds,reg_deduce_bounds",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c51d5ad6543cc36334ef1fcd762d0df767a0bf7e,c51d5ad6543cc36334ef1fcd762d0df767a0bf7e,Andrii Nakryiko,andrii@kernel.org,1698896269,Alexei Starovoitov,ast@kernel.org,1699585119,400e30036ffb1509ed621b4a781d87bdec4239e5,6593f2e6741f03b49bffc9d55ddd4c1c47853c39,"bpf: improve deduction of 64-bit bounds from 32-bit bounds

Add a few interesting cases in which we can tighten 64-bit bounds based
on newly learnt information about 32-bit bounds. E.g."," when full u64/s64
registers are used in BPF program","["" and then eventually compared as\nu32/s32. The latter comparison doesn't change the value of full\nregister"", ' but it does impose new restrictions on possible lower 32 bits\nof such full registers. And we can use that to derive additional full\nregister bounds information.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nLink: https://lore.kernel.org/r/20231102033759.2541186-8-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit improves deduction of 64-bit bounds from 32-bit bounds in BPF programs.,"bounds, 64-bit, 32-bit",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6593f2e6741f03b49bffc9d55ddd4c1c47853c39,6593f2e6741f03b49bffc9d55ddd4c1c47853c39,Andrii Nakryiko,andrii@kernel.org,1698896268,Alexei Starovoitov,ast@kernel.org,1699585119,07cd7d8ed54f76f13af7e6e856ab24ba4624ba36,c1efab6468fd5ef541d47d81dbb62cca27f8db3b,"bpf: add special smin32/smax32 derivation from 64-bit bounds

Add a special case where we can derive valid s32 bounds from umin/umax
or smin/smax by stitching together negative s32 subrange and
non-negative s32 subrange. That requires upper 32 bits to form a [N"," N+1]
range in u32 domain (taking into account wrap around","[' so 0xffffffff\nto 0x00000000 is a valid [N', ' N+1] range in this sense). See code comment\nfor concrete examples.\n\nEduard Zingerman also provided an alternative explanation ([0]) for more\nmathematically inclined readers:\n\nSuppose:\n. there are numbers a', ' b', ' c\n. 2**31 <= b < 2**32\n. 0 <= c < 2**31\n. umin = 2**32 * a + b\n. umax = 2**32 * (a + 1) + c\n\nThe number of values in the range represented by [umin; umax] is:\n. N = umax - umin + 1 = 2**32 + c - b + 1\n. min(N) = 2**32 + 0 - (2**32-1) + 1 = 2', ' with b = 2**32-1', ' c = 0\n. max(N) = 2**32 + (2**31 - 1) - 2**31 + 1 = 2**32', ' with b = 2**31', ' c = 2**31-1\n\nHence [(s32)b; (s32)c] forms a valid range.\n\n  [0] https://lore.kernel.org/bpf/d7af631802f0cfae20df77fe70068702d24bbd31.camel@gmail.com/\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231102033759.2541186-7-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit introduces special handling to derive 32-bit bounds from 64-bit bounds using negative and non-negative subranges in the BPF verifier.,"smin32,smax32,64-bit",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c1efab6468fd5ef541d47d81dbb62cca27f8db3b,c1efab6468fd5ef541d47d81dbb62cca27f8db3b,Andrii Nakryiko,andrii@kernel.org,1698896267,Alexei Starovoitov,ast@kernel.org,1699585119,2c94b1de813a6efbcfc76a724d2ee9c4f313b1b1,d540517990a9d105bf0312760665964916ac044f,"bpf: derive subreg bounds from full bounds when upper 32 bits are constant

Comments in code try to explain the idea behind why this is correct.
Please check the code and comments.

Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Acked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231102033759.2541186-6-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Improve subreg bounds derivation from full bounds when upper 32 bits are constant in BPF.,"subreg, bounds, constant",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d540517990a9d105bf0312760665964916ac044f,d540517990a9d105bf0312760665964916ac044f,Andrii Nakryiko,andrii@kernel.org,1698896266,Alexei Starovoitov,ast@kernel.org,1699585119,74d542816412d7d12aaf80c6ae442013ded48196,93f7378734b595fb61e89b802002fb7e3a1267d2,"bpf: derive smin32/smax32 from umin32/umax32 bounds

All the logic that applies to u64 vs s64"," equally applies for u32 vs s32
relationships (just taken in a smaller 32-bit numeric space). So do the
same deduction of smin32/smax32 from umin32/umax32","[' if we can.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231102033759.2541186-5-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit derives smin32/smax32 bounds from umin32/umax32 for 32-bit calculations.,"smin32, smax32, bounds",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
93f7378734b595fb61e89b802002fb7e3a1267d2,93f7378734b595fb61e89b802002fb7e3a1267d2,Andrii Nakryiko,andrii@kernel.org,1698896265,Alexei Starovoitov,ast@kernel.org,1699585119,4b91f51e3eb45a4ef49478481e261ed6d9529a1d,f4c7e887324f5776eef6e6e47a90e0ac8058a7a8,"bpf: derive smin/smax from umin/max bounds

Add smin/smax derivation from appropriate umin/umax values. Previously the
logic was surprisingly asymmetric"," trying to derive umin/umax from smin/smax
(if possible)","[' but not trying to do the same in the other direction. A simple\naddition to __reg64_deduce_bounds() fixes this.\n\nAdded also generic comment about u64/s64 ranges and their relationship.\nHopefully that helps readers to understand all the bounds deductions\na bit better.\n\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231102033759.2541186-4-andrii@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit improves the logic for deriving signed minimum and maximum from unsigned bounds in eBPF verifier.,"smin, smax, bounds",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
bf4a64b9323f181df8aba32d66cb37b9fa5df959,bf4a64b9323f181df8aba32d66cb37b9fa5df959,Yuran Pereira,yuran.pereira@hotmail.com,1698470654,Alexei Starovoitov,ast@kernel.org,1699585118,493a8cb1eef21a668f7533858d443663e0431a72,fac85c291e141a67fce46bdce01f9ee33aafabfe,"selftests/bpf: Add malloc failure checks in bpf_iter

Since some malloc calls in bpf_iter may at times fail","
this patch adds the appropriate fail checks","[' and ensures that\nany previously allocated resource is appropriately destroyed\nbefore returning the function.\n\nSigned-off-by: Yuran Pereira <yuran.pereira@hotmail.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nAcked-by: Kui-Feng Lee <thinker.li@gmail.com>\nLink: https://lore.kernel.org/r/DB3PR10MB6835F0ECA792265FA41FC39BE8A3A@DB3PR10MB6835.EURPRD10.PROD.OUTLOOK.COM\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit adds malloc failure checks to bpf_iter in selftests/bpf.,"malloc,failure,bpf_iter",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f4c7e887324f5776eef6e6e47a90e0ac8058a7a8,f4c7e887324f5776eef6e6e47a90e0ac8058a7a8,Andrii Nakryiko,andrii@kernel.org,1698896264,Alexei Starovoitov,ast@kernel.org,1699585118,c1f833d8ed02da325f5344ccd38c2705a217f6a2,2b62aa59d02ed281fa4fc218df3ca91b773e1e62,"selftests/bpf: satisfy compiler by having explicit return in btf test

Some compilers complain about get_pprint_mapv_size() not returning value
in some code paths. Fix with explicit return.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231102033759.2541186-3-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Added an explicit return statement in btf test to satisfy compiler requirements.,"compiler, return, btf",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fac85c291e141a67fce46bdce01f9ee33aafabfe,fac85c291e141a67fce46bdce01f9ee33aafabfe,Yuran Pereira,yuran.pereira@hotmail.com,1698470653,Alexei Starovoitov,ast@kernel.org,1699585118,d0878b9c891a817a0eaf9b0046239f37d338574f,89cdf9d556016a54ff6ddd62324aa5ec790c05cc,"selftests/bpf: Convert CHECK macros to ASSERT_* macros in bpf_iter

As it was pointed out by Yonghong Song [1]"," in the bpf selftests the use
of the ASSERT_* series of macros is preferred over the CHECK macro.
This patch replaces all CHECK calls in bpf_iter with the appropriate
ASSERT_* macros.

[1] https://lore.kernel.org/lkml/0a142924-633c-44e6-9a92-2dc019656bf2@linux.dev

Suggested-by: Yonghong Song <yonghong.song@linux.dev>
Signed-off-by: Yuran Pereira <yuran.pereira@hotmail.com>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Acked-by: Kui-Feng Lee <thinker.li@gmail.com>
Link: https://lore.kernel.org/r/DB3PR10MB6835E9C8DFCA226DD6FEF914E8A3A@DB3PR10MB6835.EURPRD10.PROD.OUTLOOK.COM
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Convert CHECK macros to ASSERT_* macros in bpf_iter selftests.,"selftests,bpf_iter,macros",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2b62aa59d02ed281fa4fc218df3ca91b773e1e62,2b62aa59d02ed281fa4fc218df3ca91b773e1e62,Andrii Nakryiko,andrii@kernel.org,1698896263,Alexei Starovoitov,ast@kernel.org,1699585118,686aacd80499a6a90b0418246cf7baab1be1b59f,bf4a64b9323f181df8aba32d66cb37b9fa5df959,"selftests/bpf: fix RELEASE=1 build for tc_opts

Compiler complains about malloc(). We also don't need to dynamically
allocate anything"," so make the life easier by using statically sized
buffer.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231102033759.2541186-2-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Fix static buffer allocation issue for tc_opts in bpf selftests to address malloc() compiler complaints.,"selftests,bpf,static buffer",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
89cdf9d556016a54ff6ddd62324aa5ec790c05cc,89cdf9d556016a54ff6ddd62324aa5ec790c05cc,Linus Torvalds,torvalds@linux-foundation.org,1699578575,Linus Torvalds,torvalds@linux-foundation.org,1699578575,5b5e5102c0d5f2977d4855b7761ed9efcecec2d3,3b220413438184b352b297e7cf593fa56999b5b3 83b9dda8afa4e968d9cce253f390b01c0612a2a5,"Merge tag 'net-6.7-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Jakub Kicinski:
 ""Including fixes from netfilter and bpf.

  Current release - regressions:

   - sched: fix SKB_NOT_DROPPED_YET splat under debug config

  Current release - new code bugs:

   - tcp:
       - fix usec timestamps with TCP fastopen
       - fix possible out-of-bounds reads in tcp_hash_fail()
       - fix SYN option room calculation for TCP-AO

   - tcp_sigpool: fix some off by one bugs

   - bpf: fix compilation error without CGROUPS

   - ptp:
       - ptp_read() should not release queue
       - fix tsevqs corruption

  Previous releases - regressions:

   - llc: verify mac len before reading mac header

  Previous releases - always broken:

   - bpf:
       - fix check_stack_write_fixed_off() to correctly spill imm
       - fix precision tracking for BPF_ALU | BPF_TO_BE | BPF_END
       - check map->usercnt after timer->timer is assigned

   - dsa: lan9303: consequently nested-lock physical MDIO

   - dccp/tcp: call security_inet_conn_request() after setting IP addr

   - tg3: fix the TX ring stall due to incorrect full ring handling

   - phylink: initialize carrier state at creation

   - ice: fix direction of VF rules in switchdev mode

  Misc:

   - fill in a bunch of missing MODULE_DESCRIPTION()s"," more to come""

* tag 'net-6.7-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (84 commits)
  net: ti: icss-iep: fix setting counter value
  ptp: fix corrupted list in ptp_open
  ptp: ptp_read should not release queue
  net_sched: sch_fq: better validate TCA_FQ_WEIGHTS and TCA_FQ_PRIOMAP
  net: kcm: fill in MODULE_DESCRIPTION()
  net/sched: act_ct: Always fill offloading tuple iifidx
  netfilter: nat: fix ipv6 nat redirect with mapped and scoped addresses
  netfilter: xt_recent: fix (increase) ipv6 literal buffer length
  ipvs: add missing module descriptions
  netfilter: nf_tables: remove catchall element in GC sync path
  netfilter: add missing module descriptions
  drivers/net/ppp: use standard array-copy-function
  net: enetc: shorten enetc_setup_xdp_prog() error message to fit NETLINK_MAX_FMTMSG_LEN
  virtio/vsock: Fix uninit-value in virtio_transport_recv_pkt()
  r8169: respect userspace disabling IFF_MULTICAST
  selftests/bpf: get trusted cgrp from bpf_iter__cgroup directly
  bpf: Let verifier consider {task","['cgroup} is trusted in bpf_iter_reg\n  net: phylink: initialize carrier state at creation\n  test/vsock: add dobule bind connect test\n  test/vsock: refactor vsock_accept\n  ...\n', '']","Merge networking fixes addressing regressions and bugs for netfilter, bpf, and tcp subsystems.","networking, fixes, bpf",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0008454e8fd30ed0017a9a35b8dd708f168931b8,0008454e8fd30ed0017a9a35b8dd708f168931b8,Yafang Shao,laoar.shao@gmail.com,1698560071,Tejun Heo,tj@kernel.org,1699572347,e1b0837749fe5823497f5206df8ebac983d1fe0d,9067d90006df089b9a1da0d74f0cad232a5d726a,"cgroup: Add annotation for holding namespace_sem in current_cgns_cgroup_from_root()

When I initially examined the function current_cgns_cgroup_from_root()"," I
was perplexed by its lack of holding cgroup_mutex. However","[' after Michal\nexplained the reason[0] to me', ' I realized that it already holds the\nnamespace_sem. I believe this intricacy could also confuse others', ' so it\nwould be advisable to include an annotation for clarification.\n\nAfter we replace the cgroup_mutex with RCU read lock', "" if current doesn't\nhold the namespace_sem"", "" the root cgroup will be NULL. So let's add a\nWARN_ON_ONCE() for it.\n\n[0]. https://lore.kernel.org/bpf/afdnpo3jz2ic2ampud7swd6so5carkilts2mkygcaw67vbw6yh@5b5mncf7qyet\n\nSigned-off-by: Yafang Shao <laoar.shao@gmail.com>\nCc: Michal Koutny <mkoutny@suse.com>\nSigned-off-by: Tejun Heo <tj@kernel.org>\n"", '']",Added annotation for holding namespace_sem in the cgroup function current_cgns_cgroup_from_root().,"annotation, cgroup, namespace_sem",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['cgroup like programs']
6512b6aa237db36d881a81cc312db39668e61853,6512b6aa237db36d881a81cc312db39668e61853,Ian Rogers,irogers@google.com,1698947814,Arnaldo Carvalho de Melo,acme@redhat.com,1699548573,c0776e9fde47d0c7f03b0f4b5c07d877e1ba80e3,6aad765d10c5cd8a62b258c359bae643ab2d45da,"perf bpf: Don't synthesize BPF events when disabled

If BPF sideband events are disabled on the command line"," don't
synthesize BPF events too.

Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Song Liu <song@kernel.org>
Cc: Adrian Hunter <adrian.hunter@intel.com>
Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
Cc: Andi Kleen <ak@linux.intel.com>
Cc: Athira Jajeev <atrajeev@linux.vnet.ibm.com>
Cc: Changbin Du <changbin.du@huawei.com>
Cc: Colin Ian King <colin.i.king@gmail.com>
Cc: Dmitrii Dolgov <9erthalion6@gmail.com>
Cc: German Gomez <german.gomez@arm.com>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Ingo Molnar <mingo@redhat.com>
Cc: James Clark <james.clark@arm.com>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: K Prateek Nayak <kprateek.nayak@amd.com>
Cc: Kajol Jain <kjain@linux.ibm.com>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: Leo Yan <leo.yan@linaro.org>
Cc: Li Dong <lidong@vivo.com>
Cc: Liam Howlett <liam.howlett@oracle.com>
Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Masami Hiramatsu <mhiramat@kernel.org>
Cc: Miguel Ojeda <ojeda@kernel.org>
Cc: Ming Wang <wangming01@loongson.cn>
Cc: Namhyung Kim <namhyung@kernel.org>
Cc: Nick Terrell <terrelln@fb.com>
Cc: Paolo Bonzini <pbonzini@redhat.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Sandipan Das <sandipan.das@amd.com>
Cc: Sean Christopherson <seanjc@google.com>
Cc: Steinar H. Gunderson <sesse@google.com>
Cc: Vincent Whitchurch <vincent.whitchurch@axis.com>
Cc: Wenyu Liu <liuwenyu7@huawei.com>
Cc: Yang Jihong <yangjihong1@huawei.com>
Link: https://lore.kernel.org/r/20231102175735.2272696-13-irogers@google.com
Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
",[''],Disable synthesis of BPF events in perf tool when sideband events are disabled via command line.,"BPF,perf,events",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
942b8b38de3fd38de1476b2abca562e729caa03d,942b8b38de3fd38de1476b2abca562e729caa03d,Jakub Kicinski,kuba@kernel.org,1699494973,Jakub Kicinski,kuba@kernel.org,1699494974,24c3eb7380b578562f307a09ad495391566e53bb,9bc64bd0cd765f696fcd40fc98909b1f7c73b2ba 8e1b802503bb630eafc3e97b2daf755368ec96e1,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf

Daniel Borkmann says:

====================
pull-request: bpf 2023-11-08

We've added 16 non-merge commits during the last 6 day(s) which contain
a total of 30 files changed", 341 insertions(+),"[' 130 deletions(-).\n\nThe main changes are:\n\n1) Fix a BPF verifier issue in precision tracking for BPF_ALU | BPF_TO_BE |\n   BPF_END where the source register was incorrectly marked as precise', '\n   from Shung-Hsi Yu.\n\n2) Fix a concurrency issue in bpf_timer where the former could still have\n   been alive after an application releases or unpins the map', ' from Hou Tao.\n\n3) Fix a BPF verifier issue where immediates are incorrectly cast to u32\n   before being spilled and therefore losing sign information', ' from Hao Sun.\n\n4) Fix a misplaced BPF_TRACE_ITER in check_css_task_iter_allowlist which\n   incorrectly compared bpf_prog_type with bpf_attach_type', ' from Chuyi Zhou.\n\n5) Add __bpf_hook_{start', 'end} as well as __bpf_kfunc_{start', 'end}_defs macros', '\n   migrate all BPF-related __diag callsites over to it', ' and add a new\n   __diag_ignore_all for -Wmissing-declarations to the macros to address\n   recent build warnings', ' from Dave Marchevsky.\n\n6) Fix broken BPF selftest build of xdp_hw_metadata test on architectures\n   where char is not signed', ' from Björn Töpel.\n\n7) Fix test_maps selftest to properly use LIBBPF_OPTS() macro to initialize\n   the bpf_map_create_opts', ' from Andrii Nakryiko.\n\n8) Fix bpffs selftest to avoid unmounting /sys/kernel/debug as it may have\n   been mounted and used by other applications already', ' from Manu Bretelle.\n\n9) Fix a build issue without CONFIG_CGROUPS wrt css_task open-coded\n   iterators', "" from Matthieu Baerts.\n\n* tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf:\n  selftests/bpf: get trusted cgrp from bpf_iter__cgroup directly\n  bpf: Let verifier consider {task"", ""cgroup} is trusted in bpf_iter_reg\n  selftests/bpf: Fix broken build where char is unsigned\n  selftests/bpf: precision tracking test for BPF_NEG and BPF_END\n  bpf: Fix precision tracking for BPF_ALU | BPF_TO_BE | BPF_END\n  selftests/bpf: Add test for using css_task iter in sleepable progs\n  selftests/bpf: Add tests for css_task iter combining with cgroup iter\n  bpf: Relax allowlist for css_task iter\n  selftests/bpf: fix test_maps' use of bpf_map_create_opts\n  bpf: Check map->usercnt after timer->timer is assigned\n  bpf: Add __bpf_hook_{start"", 'end} macros\n  bpf: Add __bpf_kfunc_{start', 'end}_defs macros\n  selftests/bpf: fix test_bpffs\n  selftests/bpf: Add test for immediate spilled to stack\n  bpf: Fix check_stack_write_fixed_off() to correctly spill imm\n  bpf: fix compilation error without CGROUPS\n====================\n\nLink: https://lore.kernel.org/r/20231108132448.1970-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",The commit merges the 'for-netdev' branch containing non-merge commits affecting 30 files into the main branch.,"merge, for-netdev, files",It's other type of commit.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1d375d65466e5c8d7a9406826d80d475a22e8c6d,1d375d65466e5c8d7a9406826d80d475a22e8c6d,Hengqi Chen,hengqi.chen@gmail.com,1699423941,Huacai Chen,chenhuacai@loongson.cn,1699423941,bbf1828064f0a2e4e88fca85f0dbedf1af5bb487,7b6b13d32965ad7f1eb889d1a7058868a88eb29f,"selftests/bpf: Enable cpu v4 tests for LoongArch

Enable the cpu v4 tests for LoongArch. Currently"," we don't have BPF
trampoline in LoongArch JIT","[' so the fentry test `test_ptr_struct_arg`\nstill failed', ' will followup.\n\nTest result attached below:\n\n  # ./test_progs -t verifier_sdiv', 'verifier_movsx', 'verifier_ldsx', 'verifier_gotol', 'verifier_bswap\n  #316/1   verifier_bswap/BSWAP', ' 16:OK\n  #316/2   verifier_bswap/BSWAP', ' 16 @unpriv:OK\n  #316/3   verifier_bswap/BSWAP', ' 32:OK\n  #316/4   verifier_bswap/BSWAP', ' 32 @unpriv:OK\n  #316/5   verifier_bswap/BSWAP', ' 64:OK\n  #316/6   verifier_bswap/BSWAP', ' 64 @unpriv:OK\n  #316     verifier_bswap:OK\n  #330/1   verifier_gotol/gotol', ' small_imm:OK\n  #330/2   verifier_gotol/gotol', ' small_imm @unpriv:OK\n  #330     verifier_gotol:OK\n  #338/1   verifier_ldsx/LDSX', ' S8:OK\n  #338/2   verifier_ldsx/LDSX', ' S8 @unpriv:OK\n  #338/3   verifier_ldsx/LDSX', ' S16:OK\n  #338/4   verifier_ldsx/LDSX', ' S16 @unpriv:OK\n  #338/5   verifier_ldsx/LDSX', ' S32:OK\n  #338/6   verifier_ldsx/LDSX', ' S32 @unpriv:OK\n  #338/7   verifier_ldsx/LDSX', ' S8 range checking', ' privileged:OK\n  #338/8   verifier_ldsx/LDSX', ' S16 range checking:OK\n  #338/9   verifier_ldsx/LDSX', ' S16 range checking @unpriv:OK\n  #338/10  verifier_ldsx/LDSX', ' S32 range checking:OK\n  #338/11  verifier_ldsx/LDSX', ' S32 range checking @unpriv:OK\n  #338     verifier_ldsx:OK\n  #349/1   verifier_movsx/MOV32SX', ' S8:OK\n  #349/2   verifier_movsx/MOV32SX', ' S8 @unpriv:OK\n  #349/3   verifier_movsx/MOV32SX', ' S16:OK\n  #349/4   verifier_movsx/MOV32SX', ' S16 @unpriv:OK\n  #349/5   verifier_movsx/MOV64SX', ' S8:OK\n  #349/6   verifier_movsx/MOV64SX', ' S8 @unpriv:OK\n  #349/7   verifier_movsx/MOV64SX', ' S16:OK\n  #349/8   verifier_movsx/MOV64SX', ' S16 @unpriv:OK\n  #349/9   verifier_movsx/MOV64SX', ' S32:OK\n  #349/10  verifier_movsx/MOV64SX', ' S32 @unpriv:OK\n  #349/11  verifier_movsx/MOV32SX', ' S8', ' range_check:OK\n  #349/12  verifier_movsx/MOV32SX', ' S8', ' range_check @unpriv:OK\n  #349/13  verifier_movsx/MOV32SX', ' S16', ' range_check:OK\n  #349/14  verifier_movsx/MOV32SX', ' S16', ' range_check @unpriv:OK\n  #349/15  verifier_movsx/MOV32SX', ' S16', ' range_check 2:OK\n  #349/16  verifier_movsx/MOV32SX', ' S16', ' range_check 2 @unpriv:OK\n  #349/17  verifier_movsx/MOV64SX', ' S8', ' range_check:OK\n  #349/18  verifier_movsx/MOV64SX', ' S8', ' range_check @unpriv:OK\n  #349/19  verifier_movsx/MOV64SX', ' S16', ' range_check:OK\n  #349/20  verifier_movsx/MOV64SX', ' S16', ' range_check @unpriv:OK\n  #349/21  verifier_movsx/MOV64SX', ' S32', ' range_check:OK\n  #349/22  verifier_movsx/MOV64SX', ' S32', ' range_check @unpriv:OK\n  #349/23  verifier_movsx/MOV64SX', ' S16', ' R10 Sign Extension:OK\n  #349/24  verifier_movsx/MOV64SX', ' S16', ' R10 Sign Extension @unpriv:OK\n  #349     verifier_movsx:OK\n  #361/1   verifier_sdiv/SDIV32', ' non-zero imm divisor', ' check 1:OK\n  #361/2   verifier_sdiv/SDIV32', ' non-zero imm divisor', ' check 1 @unpriv:OK\n  #361/3   verifier_sdiv/SDIV32', ' non-zero imm divisor', ' check 2:OK\n  #361/4   verifier_sdiv/SDIV32', ' non-zero imm divisor', ' check 2 @unpriv:OK\n  #361/5   verifier_sdiv/SDIV32', ' non-zero imm divisor', ' check 3:OK\n  #361/6   verifier_sdiv/SDIV32', ' non-zero imm divisor', ' check 3 @unpriv:OK\n  #361/7   verifier_sdiv/SDIV32', ' non-zero imm divisor', ' check 4:OK\n  #361/8   verifier_sdiv/SDIV32', ' non-zero imm divisor', ' check 4 @unpriv:OK\n  #361/9   verifier_sdiv/SDIV32', ' non-zero imm divisor', ' check 5:OK\n  #361/10  verifier_sdiv/SDIV32', ' non-zero imm divisor', ' check 5 @unpriv:OK\n  #361/11  verifier_sdiv/SDIV32', ' non-zero imm divisor', ' check 6:OK\n  #361/12  verifier_sdiv/SDIV32', ' non-zero imm divisor', ' check 6 @unpriv:OK\n  #361/13  verifier_sdiv/SDIV32', ' non-zero imm divisor', ' check 7:OK\n  #361/14  verifier_sdiv/SDIV32', ' non-zero imm divisor', ' check 7 @unpriv:OK\n  #361/15  verifier_sdiv/SDIV32', ' non-zero imm divisor', ' check 8:OK\n  #361/16  verifier_sdiv/SDIV32', ' non-zero imm divisor', ' check 8 @unpriv:OK\n  #361/17  verifier_sdiv/SDIV32', ' non-zero reg divisor', ' check 1:OK\n  #361/18  verifier_sdiv/SDIV32', ' non-zero reg divisor', ' check 1 @unpriv:OK\n  #361/19  verifier_sdiv/SDIV32', ' non-zero reg divisor', ' check 2:OK\n  #361/20  verifier_sdiv/SDIV32', ' non-zero reg divisor', ' check 2 @unpriv:OK\n  #361/21  verifier_sdiv/SDIV32', ' non-zero reg divisor', ' check 3:OK\n  #361/22  verifier_sdiv/SDIV32', ' non-zero reg divisor', ' check 3 @unpriv:OK\n  #361/23  verifier_sdiv/SDIV32', ' non-zero reg divisor', ' check 4:OK\n  #361/24  verifier_sdiv/SDIV32', ' non-zero reg divisor', ' check 4 @unpriv:OK\n  #361/25  verifier_sdiv/SDIV32', ' non-zero reg divisor', ' check 5:OK\n  #361/26  verifier_sdiv/SDIV32', ' non-zero reg divisor', ' check 5 @unpriv:OK\n  #361/27  verifier_sdiv/SDIV32', ' non-zero reg divisor', ' check 6:OK\n  #361/28  verifier_sdiv/SDIV32', ' non-zero reg divisor', ' check 6 @unpriv:OK\n  #361/29  verifier_sdiv/SDIV32', ' non-zero reg divisor', ' check 7:OK\n  #361/30  verifier_sdiv/SDIV32', ' non-zero reg divisor', ' check 7 @unpriv:OK\n  #361/31  verifier_sdiv/SDIV32', ' non-zero reg divisor', ' check 8:OK\n  #361/32  verifier_sdiv/SDIV32', ' non-zero reg divisor', ' check 8 @unpriv:OK\n  #361/33  verifier_sdiv/SDIV64', ' non-zero imm divisor', ' check 1:OK\n  #361/34  verifier_sdiv/SDIV64', ' non-zero imm divisor', ' check 1 @unpriv:OK\n  #361/35  verifier_sdiv/SDIV64', ' non-zero imm divisor', ' check 2:OK\n  #361/36  verifier_sdiv/SDIV64', ' non-zero imm divisor', ' check 2 @unpriv:OK\n  #361/37  verifier_sdiv/SDIV64', ' non-zero imm divisor', ' check 3:OK\n  #361/38  verifier_sdiv/SDIV64', ' non-zero imm divisor', ' check 3 @unpriv:OK\n  #361/39  verifier_sdiv/SDIV64', ' non-zero imm divisor', ' check 4:OK\n  #361/40  verifier_sdiv/SDIV64', ' non-zero imm divisor', ' check 4 @unpriv:OK\n  #361/41  verifier_sdiv/SDIV64', ' non-zero imm divisor', ' check 5:OK\n  #361/42  verifier_sdiv/SDIV64', ' non-zero imm divisor', ' check 5 @unpriv:OK\n  #361/43  verifier_sdiv/SDIV64', ' non-zero imm divisor', ' check 6:OK\n  #361/44  verifier_sdiv/SDIV64', ' non-zero imm divisor', ' check 6 @unpriv:OK\n  #361/45  verifier_sdiv/SDIV64', ' non-zero reg divisor', ' check 1:OK\n  #361/46  verifier_sdiv/SDIV64', ' non-zero reg divisor', ' check 1 @unpriv:OK\n  #361/47  verifier_sdiv/SDIV64', ' non-zero reg divisor', ' check 2:OK\n  #361/48  verifier_sdiv/SDIV64', ' non-zero reg divisor', ' check 2 @unpriv:OK\n  #361/49  verifier_sdiv/SDIV64', ' non-zero reg divisor', ' check 3:OK\n  #361/50  verifier_sdiv/SDIV64', ' non-zero reg divisor', ' check 3 @unpriv:OK\n  #361/51  verifier_sdiv/SDIV64', ' non-zero reg divisor', ' check 4:OK\n  #361/52  verifier_sdiv/SDIV64', ' non-zero reg divisor', ' check 4 @unpriv:OK\n  #361/53  verifier_sdiv/SDIV64', ' non-zero reg divisor', ' check 5:OK\n  #361/54  verifier_sdiv/SDIV64', ' non-zero reg divisor', ' check 5 @unpriv:OK\n  #361/55  verifier_sdiv/SDIV64', ' non-zero reg divisor', ' check 6:OK\n  #361/56  verifier_sdiv/SDIV64', ' non-zero reg divisor', ' check 6 @unpriv:OK\n  #361/57  verifier_sdiv/SMOD32', ' non-zero imm divisor', ' check 1:OK\n  #361/58  verifier_sdiv/SMOD32', ' non-zero imm divisor', ' check 1 @unpriv:OK\n  #361/59  verifier_sdiv/SMOD32', ' non-zero imm divisor', ' check 2:OK\n  #361/60  verifier_sdiv/SMOD32', ' non-zero imm divisor', ' check 2 @unpriv:OK\n  #361/61  verifier_sdiv/SMOD32', ' non-zero imm divisor', ' check 3:OK\n  #361/62  verifier_sdiv/SMOD32', ' non-zero imm divisor', ' check 3 @unpriv:OK\n  #361/63  verifier_sdiv/SMOD32', ' non-zero imm divisor', ' check 4:OK\n  #361/64  verifier_sdiv/SMOD32', ' non-zero imm divisor', ' check 4 @unpriv:OK\n  #361/65  verifier_sdiv/SMOD32', ' non-zero imm divisor', ' check 5:OK\n  #361/66  verifier_sdiv/SMOD32', ' non-zero imm divisor', ' check 5 @unpriv:OK\n  #361/67  verifier_sdiv/SMOD32', ' non-zero imm divisor', ' check 6:OK\n  #361/68  verifier_sdiv/SMOD32', ' non-zero imm divisor', ' check 6 @unpriv:OK\n  #361/69  verifier_sdiv/SMOD32', ' non-zero reg divisor', ' check 1:OK\n  #361/70  verifier_sdiv/SMOD32', ' non-zero reg divisor', ' check 1 @unpriv:OK\n  #361/71  verifier_sdiv/SMOD32', ' non-zero reg divisor', ' check 2:OK\n  #361/72  verifier_sdiv/SMOD32', ' non-zero reg divisor', ' check 2 @unpriv:OK\n  #361/73  verifier_sdiv/SMOD32', ' non-zero reg divisor', ' check 3:OK\n  #361/74  verifier_sdiv/SMOD32', ' non-zero reg divisor', ' check 3 @unpriv:OK\n  #361/75  verifier_sdiv/SMOD32', ' non-zero reg divisor', ' check 4:OK\n  #361/76  verifier_sdiv/SMOD32', ' non-zero reg divisor', ' check 4 @unpriv:OK\n  #361/77  verifier_sdiv/SMOD32', ' non-zero reg divisor', ' check 5:OK\n  #361/78  verifier_sdiv/SMOD32', ' non-zero reg divisor', ' check 5 @unpriv:OK\n  #361/79  verifier_sdiv/SMOD32', ' non-zero reg divisor', ' check 6:OK\n  #361/80  verifier_sdiv/SMOD32', ' non-zero reg divisor', ' check 6 @unpriv:OK\n  #361/81  verifier_sdiv/SMOD64', ' non-zero imm divisor', ' check 1:OK\n  #361/82  verifier_sdiv/SMOD64', ' non-zero imm divisor', ' check 1 @unpriv:OK\n  #361/83  verifier_sdiv/SMOD64', ' non-zero imm divisor', ' check 2:OK\n  #361/84  verifier_sdiv/SMOD64', ' non-zero imm divisor', ' check 2 @unpriv:OK\n  #361/85  verifier_sdiv/SMOD64', ' non-zero imm divisor', ' check 3:OK\n  #361/86  verifier_sdiv/SMOD64', ' non-zero imm divisor', ' check 3 @unpriv:OK\n  #361/87  verifier_sdiv/SMOD64', ' non-zero imm divisor', ' check 4:OK\n  #361/88  verifier_sdiv/SMOD64', ' non-zero imm divisor', ' check 4 @unpriv:OK\n  #361/89  verifier_sdiv/SMOD64', ' non-zero imm divisor', ' check 5:OK\n  #361/90  verifier_sdiv/SMOD64', ' non-zero imm divisor', ' check 5 @unpriv:OK\n  #361/91  verifier_sdiv/SMOD64', ' non-zero imm divisor', ' check 6:OK\n  #361/92  verifier_sdiv/SMOD64', ' non-zero imm divisor', ' check 6 @unpriv:OK\n  #361/93  verifier_sdiv/SMOD64', ' non-zero imm divisor', ' check 7:OK\n  #361/94  verifier_sdiv/SMOD64', ' non-zero imm divisor', ' check 7 @unpriv:OK\n  #361/95  verifier_sdiv/SMOD64', ' non-zero imm divisor', ' check 8:OK\n  #361/96  verifier_sdiv/SMOD64', ' non-zero imm divisor', ' check 8 @unpriv:OK\n  #361/97  verifier_sdiv/SMOD64', ' non-zero reg divisor', ' check 1:OK\n  #361/98  verifier_sdiv/SMOD64', ' non-zero reg divisor', ' check 1 @unpriv:OK\n  #361/99  verifier_sdiv/SMOD64', ' non-zero reg divisor', ' check 2:OK\n  #361/100 verifier_sdiv/SMOD64', ' non-zero reg divisor', ' check 2 @unpriv:OK\n  #361/101 verifier_sdiv/SMOD64', ' non-zero reg divisor', ' check 3:OK\n  #361/102 verifier_sdiv/SMOD64', ' non-zero reg divisor', ' check 3 @unpriv:OK\n  #361/103 verifier_sdiv/SMOD64', ' non-zero reg divisor', ' check 4:OK\n  #361/104 verifier_sdiv/SMOD64', ' non-zero reg divisor', ' check 4 @unpriv:OK\n  #361/105 verifier_sdiv/SMOD64', ' non-zero reg divisor', ' check 5:OK\n  #361/106 verifier_sdiv/SMOD64', ' non-zero reg divisor', ' check 5 @unpriv:OK\n  #361/107 verifier_sdiv/SMOD64', ' non-zero reg divisor', ' check 6:OK\n  #361/108 verifier_sdiv/SMOD64', ' non-zero reg divisor', ' check 6 @unpriv:OK\n  #361/109 verifier_sdiv/SMOD64', ' non-zero reg divisor', ' check 7:OK\n  #361/110 verifier_sdiv/SMOD64', ' non-zero reg divisor', ' check 7 @unpriv:OK\n  #361/111 verifier_sdiv/SMOD64', ' non-zero reg divisor', ' check 8:OK\n  #361/112 verifier_sdiv/SMOD64', ' non-zero reg divisor', ' check 8 @unpriv:OK\n  #361/113 verifier_sdiv/SDIV32', ' zero divisor:OK\n  #361/114 verifier_sdiv/SDIV32', ' zero divisor @unpriv:OK\n  #361/115 verifier_sdiv/SDIV64', ' zero divisor:OK\n  #361/116 verifier_sdiv/SDIV64', ' zero divisor @unpriv:OK\n  #361/117 verifier_sdiv/SMOD32', ' zero divisor:OK\n  #361/118 verifier_sdiv/SMOD32', ' zero divisor @unpriv:OK\n  #361/119 verifier_sdiv/SMOD64', ' zero divisor:OK\n  #361/120 verifier_sdiv/SMOD64', ' zero divisor @unpriv:OK\n  #361     verifier_sdiv:OK\n  Summary: 5/163 PASSED', ' 0 SKIPPED', "" 0 FAILED\n\n  # ./test_progs -t ldsx_insn\n  test_map_val_and_probed_memory:PASS:test_ldsx_insn__open 0 nsec\n  test_map_val_and_probed_memory:PASS:test_ldsx_insn__load 0 nsec\n  libbpf: prog 'test_ptr_struct_arg': failed to attach: ERROR: strerror_r(-524)=22\n  libbpf: prog 'test_ptr_struct_arg': failed to auto-attach: -524\n  test_map_val_and_probed_memory:FAIL:test_ldsx_insn__attach unexpected error: -524 (errno 524)\n  #116/1   ldsx_insn/map_val and probed_memory:FAIL\n  #116/2   ldsx_insn/ctx_member_sign_ext:OK\n  #116/3   ldsx_insn/ctx_member_narrow_sign_ext:OK\n  #116     ldsx_insn:FAIL\n\n  All error logs:\n  test_map_val_and_probed_memory:PASS:test_ldsx_insn__open 0 nsec\n  test_map_val_and_probed_memory:PASS:test_ldsx_insn__load 0 nsec\n  libbpf: prog 'test_ptr_struct_arg': failed to attach: ERROR: strerror_r(-524)=22\n  libbpf: prog 'test_ptr_struct_arg': failed to auto-attach: -524\n  test_map_val_and_probed_memory:FAIL:test_ldsx_insn__attach unexpected error: -524 (errno 524)\n  #116/1   ldsx_insn/map_val and probed_memory:FAIL\n  #116     ldsx_insn:FAIL\n  Summary: 0/2 PASSED"", ' 0 SKIPPED', ' 1 FAILED\n\nSigned-off-by: Hengqi Chen <hengqi.chen@gmail.com>\nSigned-off-by: Huacai Chen <chenhuacai@loongson.cn>\n', '']",Enable cpu v4 tests for LoongArch in the BPF selftests.,"cpu v4, LoongArch, selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
8e1b802503bb630eafc3e97b2daf755368ec96e1,8e1b802503bb630eafc3e97b2daf755368ec96e1,Martin KaFai Lau,martin.lau@kernel.org,1699392363,Martin KaFai Lau,martin.lau@kernel.org,1699399686,3de609f4f0ac0e64b1684ce0007776d92833b703,d84b139f53e8fa8048f16814c6b2a53d7bc15c3d 3c5864ba9cf912ff9809f315d28f296f21563cce,Merge branch 'Let BPF verifier consider {task,"cgroup} is trusted in bpf_iter_reg'

Chuyi Zhou says:

====================
The patchset aims to let the BPF verivier consider
bpf_iter__cgroup->cgroup and bpf_iter__task->task is trusted suggested by
Alexei[1].

Please see individual patches for more details. And comments are always
welcome.

Link[1]:https://lore.kernel.org/bpf/20231022154527.229117-1-zhouchuyi@bytedance.com/T/#mb57725edc8ccdd50a1b165765c7619b4d65ed1b0

v2->v1:
 * Patch #1: Add Yonghong's ack and add description of similar case in
   log.
 * Patch #2: Add Yonghong's ack
====================

Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Enhances the BPF verifier to trust specific cgroup and task iterators in bpf_iter_reg.,"BPF verifier, trusted, iterators",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3c5864ba9cf912ff9809f315d28f296f21563cce,3c5864ba9cf912ff9809f315d28f296f21563cce,Chuyi Zhou,zhouchuyi@bytedance.com,1699363324,Martin KaFai Lau,martin.lau@kernel.org,1699399686,3de609f4f0ac0e64b1684ce0007776d92833b703,0de4f50de25af79c2a46db55d70cdbd8f985c6d1,"selftests/bpf: get trusted cgrp from bpf_iter__cgroup directly

Commit f49843afde (selftests/bpf: Add tests for css_task iter combining
with cgroup iter) added a test which demonstrates how css_task iter can be
combined with cgroup iter. That test used bpf_cgroup_from_id() to convert
bpf_iter__cgroup->cgroup to a trusted ptr which is pointless now"," since
with the previous fix","[' we can get a trusted cgroup directly from\nbpf_iter__cgroup.\n\nSigned-off-by: Chuyi Zhou <zhouchuyi@bytedance.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20231107132204.912120-3-zhouchuyi@bytedance.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",The commit updates the test to retrieve the trusted cgroup from bpf_iter__cgroup directly.,"trusted cgroup, bpf_iter, selftests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['cgroup like programs']
0de4f50de25af79c2a46db55d70cdbd8f985c6d1,0de4f50de25af79c2a46db55d70cdbd8f985c6d1,Chuyi Zhou,zhouchuyi@bytedance.com,1699363323,Martin KaFai Lau,martin.lau@kernel.org,1699399465,02dcfa685f6f84672356ac0c8f1fe8716160eb77,d84b139f53e8fa8048f16814c6b2a53d7bc15c3d,bpf: Let verifier consider {task,"cgroup} is trusted in bpf_iter_reg

BTF_TYPE_SAFE_TRUSTED(struct bpf_iter__task) in verifier.c wanted to
teach BPF verifier that bpf_iter__task -> task is a trusted ptr. But it
doesn't work well.

The reason is","["" bpf_iter__task -> task would go through btf_ctx_access()\nwhich enforces the reg_type of 'task' is ctx_arg_info->reg_type"", ' and in\ntask_iter.c', ' we actually explicitly declare that the\nctx_arg_info->reg_type is PTR_TO_BTF_ID_OR_NULL.\n\nActually we have a previous case like this[1] where PTR_TRUSTED is added to\nthe arg flag for map_iter.\n\nThis patch sets ctx_arg_info->reg_type is PTR_TO_BTF_ID_OR_NULL |\nPTR_TRUSTED in task_reg_info.\n\nSimilarly', ' bpf_cgroup_reg_info -> cgroup is also PTR_TRUSTED since we are\nunder the protection of cgroup_mutex and we would check cgroup_is_dead()\nin __cgroup_iter_seq_show().\n\nThis patch is to improve the user experience of the newly introduced\nbpf_iter_css_task kfunc before hitting the mainline. The Fixes tag is\npointing to the commit introduced the bpf_iter_css_task kfunc.\n\nLink[1]:https://lore.kernel.org/all/20230706133932.45883-3-aspsk@isovalent.com/\n\nFixes: 9c66dc94b62a (""bpf: Introduce css_task open-coded iterator kfuncs"")\nSigned-off-by: Chuyi Zhou <zhouchuyi@bytedance.com>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nLink: https://lore.kernel.org/r/20231107132204.912120-2-zhouchuyi@bytedance.com\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Fix BPF verifier to correctly trust the task pointer in bpf_iter__task context.,"BPF verifier, trusted pointer, bpf_iter__task",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
707df298cbde200b939c70be2577b20775fe3345,707df298cbde200b939c70be2577b20775fe3345,Linus Torvalds,torvalds@linux-foundation.org,1699042059,Linus Torvalds,torvalds@linux-foundation.org,1699042059,b29f663dac88ac45d4f1d1465133c85439febe6c,6bdfe2d88b9ff8b0cce32ce87cd47c0e9d665f48 303d77a6e1707498f09c9d8ee91b1dc07ca315a5,"Merge tag 'powerpc-6.7-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux

Pull powerpc updates from Michael Ellerman:

 - Add support for KVM running as a nested hypervisor under development
   versions of PowerVM"," using the new PAPR nested virtualisation API

 - Add support for the BPF prog pack allocator

 - A rework of the non-server MMU handling to support execute-only on
   all platforms

 - Some optimisations & cleanups for the powerpc qspinlock code

 - Various other small features and fixes

Thanks to Aboorva Devarajan","[' Aditya Gupta', ' Amit Machhiwal', ' Benjamin\nGray', ' Christophe Leroy', ' Dr. David Alan Gilbert', ' Gaurav Batra', ' Gautam\nMenghani', ' Geert Uytterhoeven', ' Haren Myneni', ' Hari Bathini', ' Joel Stanley', '\nJordan Niethe', ' Julia Lawall', ' Kautuk Consul', ' Kuan-Wei Chiu', ' Michael\nNeuling', ' Minjie Du', ' Muhammad Muzammil', ' Naveen N Rao', ' Nicholas Piggin', '\nNick Child', ' Nysal Jan K.A', ' Peter Lafreniere', ' Rob Herring', ' Sachin Sant', '\nSebastian Andrzej Siewior', ' Shrikanth Hegde', ' Srikar Dronamraju', ' Stanislav\nKinsburskii', ' Vaibhav Jain', ' Wang Yufen', ' Yang Yingliang', ' and Yuan Tan.\n\n* tag \'powerpc-6.7-1\' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (100 commits)\n  powerpc/vmcore: Add MMU information to vmcoreinfo\n  Revert ""powerpc: add `cur_cpu_spec` symbol to vmcoreinfo""\n  powerpc/bpf: use bpf_jit_binary_pack_[alloc|finalize|free]\n  powerpc/bpf: rename powerpc64_jit_data to powerpc_jit_data\n  powerpc/bpf: implement bpf_arch_text_invalidate for bpf_prog_pack\n  powerpc/bpf: implement bpf_arch_text_copy\n  powerpc/code-patching: introduce patch_instructions()\n  powerpc/32s: Implement local_flush_tlb_page_psize()\n  powerpc/pseries: use kfree_sensitive() in plpks_gen_password()\n  powerpc/code-patching: Perform hwsync in __patch_instruction() in case of failure\n  powerpc/fsl_msi: Use device_get_match_data()\n  powerpc: Remove cpm_dp...() macros\n  powerpc/qspinlock: Rename yield_propagate_owner tunable\n  powerpc/qspinlock: Propagate sleepy if previous waiter is preempted\n  powerpc/qspinlock: don\'t propagate the not-sleepy state\n  powerpc/qspinlock: propagate owner preemptedness rather than CPU number\n  powerpc/qspinlock: stop queued waiters trying to set lock sleepy\n  powerpc/perf: Fix disabling BHRB and instruction sampling\n  powerpc/trace: Add support for HAVE_FUNCTION_ARG_ACCESS_API\n  powerpc/tools: Pass -mabi=elfv2 to gcc-check-mprofile-kernel.sh\n  ...\n', '']","This commit merges powerpc updates including nested KVM support, BPF prog pack allocator, MMU rework, and qspinlock optimizations.","nested KVM,BPF prog,optimizations",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,['other']
7ab89417ed235f56d84c7893d38d4905e38d2692,7ab89417ed235f56d84c7893d38d4905e38d2692,Linus Torvalds,torvalds@linux-foundation.org,1699035458,Linus Torvalds,torvalds@linux-foundation.org,1699035458,0980734f4e492a09e68d820fedce20465c69e3df,31e5f934ff962820995c82a6953176a1c7d18ff5 fed3a1be6433e15833068c701bfde7b422d8b988,"Merge tag 'perf-tools-for-v6.7-1-2023-11-01' of git://git.kernel.org/pub/scm/linux/kernel/git/perf/perf-tools

Pull perf tools updates from Namhyung Kim:
 ""Build:

   - Compile BPF programs by default if clang (>= 12.0.1) is available
     to enable more features like kernel lock contention"," off-cpu
     profiling","[' kwork', ' sample filtering and so on.\n\n     This can be disabled by passing BUILD_BPF_SKEL=0 to make.\n\n   - Produce better error messages for bison on debug build (make\n     DEBUG=1) by defining YYDEBUG symbol internally.\n\n  perf record:\n\n   - Track sideband events (like FORK/MMAP) from all CPUs even if perf\n     record targets a subset of CPUs only (using -C option). Otherwise\n     it may lose some information happened on a CPU out of the target\n     list.\n\n   - Fix checking raw sched_switch tracepoint argument using system BTF.\n     This affects off-cpu profiling which attaches a BPF program to the\n     raw tracepoint.\n\n  perf lock contention:\n\n   - Add --lock-cgroup option to see contention by cgroups. This should\n     be used with BPF only (using -b option).\n\n       $ sudo perf lock con -ab --lock-cgroup -- sleep 1\n        contended   total wait     max wait     avg wait   cgroup\n\n              835     14.06 ms     41.19 us     16.83 us   /system.slice/led.service\n               25    122.38 us     13.77 us      4.89 us   /\n               44     23.73 us      3.87 us       539 ns   /user.slice/user-657345.slice/session-c4.scope\n                1       491 ns       491 ns       491 ns   /system.slice/connectd.service\n\n   - Add -G/--cgroup-filter option to see contention only for given\n     cgroups.\n\n     This can be useful when you identified a cgroup in the above\n     command and want to investigate more on it. It also works with\n     other output options like -t/--threads and -l/--lock-addr.\n\n       $ sudo perf lock con -ab -G /user.slice/user-657345.slice/session-c4.scope -- sleep 1\n        contended   total wait     max wait     avg wait         type   caller\n\n                8     77.11 us     17.98 us      9.64 us     spinlock   futex_wake+0xc8\n                2     24.56 us     14.66 us     12.28 us     spinlock   tick_do_update_jiffies64+0x25\n                1      4.97 us      4.97 us      4.97 us     spinlock   futex_q_lock+0x2a\n\n   - Use per-cpu array for better spinlock tracking. This is to improve\n     performance of the BPF program and to avoid nested contention on a\n     lock in the BPF hash map.\n\n   - Update callstack check for PowerPC. To find a representative caller\n     of a lock', ' it needs to look up the call stacks. It ends the lookup\n     when it sees 0 in the call stack buffer. However', "" PowerPC call\n     stacks can have 0 values in the beginning so skip them when it\n     expects valid call stacks after.\n\n  perf kwork:\n\n   - Support 'sched' class (for -k option) so that it can see task\n     scheduling event (using sched_switch tracepoint) as well as irq and\n     workqueue items.\n\n   - Add perf kwork top subcommand to show more accurate cpu utilization\n     with sched class above. It works both with a recorded data (using\n     perf kwork record command) and BPF (using -b option). Unlike perf\n     top command"", ' it does not support interactive mode (yet).\n\n       $ sudo perf kwork top -b -k sched\n       Starting trace', ' Hit <Ctrl+C> to stop and report\n       ^C\n       Total  : 160702.425 ms', ' 8 cpus\n       %Cpu(s):  36.00% id', '   0.00% hi', '   0.00% si\n       %Cpu0   [||||||||||||||||||              61.66%]\n       %Cpu1   [||||||||||||||||||              61.27%]\n       %Cpu2   [|||||||||||||||||||             66.40%]\n       %Cpu3   [||||||||||||||||||              61.28%]\n       %Cpu4   [||||||||||||||||||              61.82%]\n       %Cpu5   [|||||||||||||||||||||||         77.41%]\n       %Cpu6   [||||||||||||||||||              61.73%]\n       %Cpu7   [||||||||||||||||||              63.25%]\n\n             PID     SPID    %CPU           RUNTIME  COMMMAND\n         -------------------------------------------------------------\n               0        0   38.72       8089.463 ms  [swapper/1]\n               0        0   38.71       8084.547 ms  [swapper/3]\n               0        0   38.33       8007.532 ms  [swapper/0]\n               0        0   38.26       7992.985 ms  [swapper/6]\n               0        0   38.17       7971.865 ms  [swapper/4]\n               0        0   36.74       7447.765 ms  [swapper/7]\n               0        0   33.59       6486.942 ms  [swapper/2]\n               0        0   22.58       3771.268 ms  [swapper/5]\n            9545     9351    2.48        447.136 ms  sched-messaging\n            9574     9351    2.09        418.583 ms  sched-messaging\n            9724     9351    2.05        372.407 ms  sched-messaging\n            9531     9351    2.01        368.804 ms  sched-messaging\n            9512     9351    2.00        362.250 ms  sched-messaging\n            9514     9351    1.95        357.767 ms  sched-messaging\n            9538     9351    1.86        384.476 ms  sched-messaging\n            9712     9351    1.84        386.490 ms  sched-messaging\n            9723     9351    1.83        380.021 ms  sched-messaging\n            9722     9351    1.82        382.738 ms  sched-messaging\n            9517     9351    1.81        354.794 ms  sched-messaging\n            9559     9351    1.79        344.305 ms  sched-messaging\n            9725     9351    1.77        365.315 ms  sched-messaging\n       <SNIP>\n\n   - Add hard/soft-irq statistics to perf kwork top. This will show the\n     total CPU utilization with IRQ stats like below:\n\n       $ sudo perf kwork top -b -k sched', 'irq', 'softirq\n       Starting trace', ' Hit <Ctrl+C> to stop and report\n       ^C\n       Total  :  12554.889 ms', ' 8 cpus\n       %Cpu(s):  96.23% id', '   0.10% hi', '   0.19% si      <---- here\n       %Cpu0   [|                                4.60%]\n       %Cpu1   [|                                4.59%]\n       %Cpu2   [                                 2.73%]\n       %Cpu3   [|                                3.81%]\n       <SNIP>\n\n  perf bench:\n\n   - Add -G/--cgroups option to perf bench sched pipe. The pipe bench is\n     good to measure context switch overhead. With this option', ' it puts\n     the reader and writer tasks in separate cgroups to enforce context\n     switch between two different cgroups.\n\n     Also it needs to set CPU affinity of the tasks in a CPU to\n     accurately measure the impact of cgroup context switches.\n\n       $ sudo perf stat -e context-switches', ""cgroup-switches -- \\\n       > taskset -c 0 perf bench sched pipe -l 100000\n       # Running 'sched/pipe' benchmark:\n       # Executed 100000 pipe operations between two processes\n\n            Total time: 0.307 [sec]\n\n              3.078180 usecs/op\n                324867 ops/sec\n\n        Performance counter stats for 'taskset -c 0 perf bench sched pipe -l 100000':\n\n                  200"", '026      context-switches\n                       63      cgroup-switches\n\n              0.321637922 seconds time elapsed\n\n     You can see small number of cgroup-switches because both write and\n     read tasks are in the same cgroup.\n\n       $ sudo mkdir /sys/fs/cgroup/{AAA', 'BBB}\n\n       $ sudo perf stat -e context-switches', 'cgroup-switches -- \\\n       > taskset -c 0 perf bench sched pipe -l 100000 -G AAA', ""BBB\n       # Running 'sched/pipe' benchmark:\n       # Executed 100000 pipe operations between two processes\n\n            Total time: 0.351 [sec]\n\n              3.512990 usecs/op\n                284657 ops/sec\n\n        Performance counter stats for 'taskset -c 0 perf bench sched pipe -l 100000 -G AAA"", ""BBB':\n\n                  200"", '020      context-switches\n                  200', ""019      cgroup-switches\n\n              0.365034567 seconds time elapsed\n\n     Now context-switches and cgroup-switches are almost same. And you\n     can see the pipe operation took little more.\n\n   - Kill child processes when perf bench sched messaging exited\n     abnormally. Otherwise it'd leave the child doing unnecessary work.\n\n  perf test:\n\n   - Fix various shellcheck issues on the tests written in shell script.\n\n   - Skip tests when condition is not satisfied:\n      - object code reading test for non-text section addresses.\n      - CoreSight test if cs_etm// event is not available.\n      - lock contention test if not enough CPUs.\n\n  Event parsing:\n\n   - Make PMU alias name loading lazy to reduce the startup time in the\n     event parsing code for perf record"", ' stat and others in the general\n     case.\n\n   - Lazily compute PMU default config. In the same sense', "" delay PMU\n     initialization until it's really needed to reduce the startup cost.\n\n   - Fix event term values that are raw events. The event specification\n     can have several terms including event name. But sometimes it\n     clashes with raw event encoding which starts with 'r' and has\n     hex-digits.\n\n     For example"", "" an event named 'read' should be processed as a normal\n     event but it was mis-treated as a raw encoding and caused a\n     failure.\n\n       $ perf stat -e 'uncore_imc_free_running/event=read/' -a sleep 1\n       event syntax error: '..nning/event=read/'\n                                         \\___ parser error\n       Run 'perf list' for a list of valid events\n\n        Usage: perf stat [<options>] [<command>]\n\n           -e"", ' --event <event> event selector. use \'perf list\' to list available events\n\n  Event metrics:\n\n   - Add ""Compat"" regex to match event with multiple identifiers.\n\n   - Usual updates for Intel', ' Power10', ' Arm telemetry/CMN and AmpereOne.\n\n  Misc:\n\n   - Assorted memory leak fixes and footprint reduction.\n\n   - Add ""bpf_skeletons"" to perf version --build-options so that users\n     can check whether their perf tools have BPF support easily.\n\n   - Fix unaligned access in Intel-PT packet decoder found by\n     undefined-behavior sanitizer.\n\n   - Avoid frequency mode for the dummy event. Surprisingly it\'d impact\n     kernel timer tick handler performance by force iterating all PMU\n     events.\n\n   - Update bash shell completion for events and metrics""\n\n* tag \'perf-tools-for-v6.7-1-2023-11-01\' of git://git.kernel.org/pub/scm/linux/kernel/git/perf/perf-tools: (187 commits)\n  perf vendor events intel: Update tsx_cycles_per_elision metrics\n  perf vendor events intel: Update bonnell version number to v5\n  perf vendor events intel: Update westmereex events to v4\n  perf vendor events intel: Update meteorlake events to v1.06\n  perf vendor events intel: Update knightslanding events to v16\n  perf vendor events intel: Add typo fix for ivybridge FP\n  perf vendor events intel: Update a spelling in haswell/haswellx\n  perf vendor events intel: Update emeraldrapids to v1.01\n  perf vendor events intel: Update alderlake/alderlake events to v1.23\n  perf build: Disable BPF skeletons if clang version is < 12.0.1\n  perf callchain: Fix spelling mistake ""statisitcs"" -> ""statistics""\n  perf report: Fix spelling mistake ""heirachy"" -> ""hierarchy""\n  perf python: Fix binding linkage due to rename and move of evsel__increase_rlimit()\n  perf tests: test_arm_coresight: Simplify source iteration\n  perf vendor events intel: Add tigerlake two metrics\n  perf vendor events intel: Add broadwellde two metrics\n  perf vendor events intel: Fix broadwellde tma_info_system_dram_bw_use metric\n  perf mem_info: Add and use map_symbol__exit and addr_map_symbol__exit\n  perf callchain: Minor layout changes to callchain_list\n  perf callchain: Make brtype_stat in callchain_list optional\n  ...\n', '']",Merge updates to perf tools for enabling BPF program compilation with clang if available.,"perf tools, BPF, clang",It's a build system or CI/CD change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The bpftool utility,"['tracepoints like programs', 'profile like programs']"
851bbccf6b0c152d98ecf0ec83d75fc97aebf43c,851bbccf6b0c152d98ecf0ec83d75fc97aebf43c,Arnaldo Carvalho de Melo,acme@redhat.com,1697058892,Arnaldo Carvalho de Melo,acme@redhat.com,1699025158,105cee1261cb0773b3626609643b824fd7b99f7d,c8e3ade38bc6545faece71cc6c642ad744d4cea3,"perf build: Warn about missing libelf before warning about missing libbpf

As libelf is a requirement for libbpf if it is not available"," as in some
container build tests where NO_LIBELF=1 is used","[' then better warn about\nthe most basic library first.\n\nDitto for libz', ' check its availability before libbpf too.\n\nCc: Adrian Hunter <adrian.hunter@intel.com>\nCc: Ian Rogers <irogers@google.com>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: Namhyung Kim <namhyung@kernel.org>\nLink: https://lore.kernel.org/lkml/ZUEehyDk0FkPnvMR@kernel.org\nSigned-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>\n', '']",Update perf build script to warn about missing libelf before missing libbpf.,"perf,libelf,libbpf",It's a build system or CI/CD change.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
d84b139f53e8fa8048f16814c6b2a53d7bc15c3d,d84b139f53e8fa8048f16814c6b2a53d7bc15c3d,Björn Töpel,bjorn@rivosinc.com,1698921337,Alexei Starovoitov,ast@kernel.org,1698937041,7a2fe59a181f0c1ac1070327cc757bbbfbbdeb51,94e88b8a3e50d3e60c3ba6a5c316729587595210,"selftests/bpf: Fix broken build where char is unsigned

There are architectures where char is not signed. If so"," the following
error is triggered:

  | xdp_hw_metadata.c:435:42: error: result of comparison of constant -1 \
  |   with expression of type 'char' is always true \
  |   [-Werror","['-Wtautological-constant-out-of-range-compare]\n  |   435 |         while ((opt = getopt(argc', ' argv', ' ""mh"")) != -1) {\n  |       |                ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^  ~~\n  | 1 error generated.\n\nCorrect by changing the char to int.\n\nFixes: bb6a88885fde (""selftests/bpf: Add options and frags to xdp_hw_metadata"")\nSigned-off-by: Björn Töpel <bjorn@rivosinc.com>\nAcked-by: Larysa Zaremba <larysa.zaremba@intel.com>\nTested-by: Anders Roxell <anders.roxell@linaro.org>\nLink: https://lore.kernel.org/r/20231102103537.247336-1-bjorn@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix build error in selftests/bpf due to unsigned char architecture issue.,"selftests,bpf,unsigned",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['xdp like programs', 'other']"
94e88b8a3e50d3e60c3ba6a5c316729587595210,94e88b8a3e50d3e60c3ba6a5c316729587595210,Alexei Starovoitov,ast@kernel.org,1698904468,Alexei Starovoitov,ast@kernel.org,1698904468,168c8cc8161f049ccfa8fb6f39ff3f6a0d8454bf,698b8c5e3b5505ac00102caf9e4843b71192b586 3c41971550f58f2e006c58aa71e8c23ad312110f,"Merge branch 'bpf-fix-precision-tracking-for-bpf_alu-bpf_to_be-bpf_end'

Shung-Hsi Yu says:

====================
bpf: Fix precision tracking for BPF_ALU | BPF_TO_BE | BPF_END

Changes since v1:
- add test for negation and bswap (Alexei"," Eduard)
- add test for BPF_TO_LE as well to cover all types of BPF_END opcode
- remove vals map and trigger backtracking with jump instead","["" based of\n  Eduard's code\n- v1 at https://lore.kernel.org/bpf/20231030132145.20867-1-shung-hsi.yu@suse.com\n\nThis patchset fixes and adds selftest for the issue reported by Mohamed\nMahmoud and Toke Høiland-Jørgensen where the kernel can run into a\nverifier bug during backtracking of BPF_ALU | BPF_TO_BE | BPF_END\ninstruction[0]. As seen in the verifier log below"", "" r0 was incorrectly\nmarked as precise even tough its value was not being used.\n\nPatch 1 fixes the issue based on Andrii's analysis"", ' and patch 2 adds a\nselftest for such case using inline assembly. Please see individual\npatch for detail.\n\n    ...\n\tmark_precise: frame2: regs=r2 stack= before 1891: (77) r2 >>= 56\n\tmark_precise: frame2: regs=r2 stack= before 1890: (dc) r2 = be64 r2\n\tmark_precise: frame2: regs=r0', 'r2 stack= before 1889: (73) *(u8 *)(r1 +47) = r3\n\t...\n\tmark_precise: frame2: regs=r0 stack= before 212: (85) call pc+1617\n\tBUG regs 1\n\tprocessed 5112 insns (limit 1000000) max_states_per_insn 4 total_states 92 peak_states 90 mark_read 20\n\n0: https://lore.kernel.org/r/87jzrrwptf.fsf@toke.dk\n\nShung-Hsi Yu (2):\n  bpf: Fix precision tracking for BPF_ALU | BPF_TO_BE | BPF_END\n  selftests/bpf: precision tracking test for BPF_NEG and BPF_END\n\n kernel/bpf/verifier.c                         |  7 +-\n .../selftests/bpf/prog_tests/verifier.c       |  2 +\n .../selftests/bpf/progs/verifier_precision.c  | 93 +++++++++++++++++++\n 3 files changed', ' 101 insertions(+)', ' 1 deletion(-)\n create mode 100644 tools/testing/selftests/bpf/progs/verifier_precision.c\n\nbase-commit: c17cda15cc86e65e9725641daddcd7a63cc9ad01\n====================\n\nLink: https://lore.kernel.org/r/20231102053913.12004-1-shung-hsi.yu@suse.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']","The commit fixes precision tracking for BPF_ALU, BPF_TO_BE, BPF_END and adds relevant tests.","precision, BPF_ALU, BPF_END",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3c41971550f58f2e006c58aa71e8c23ad312110f,3c41971550f58f2e006c58aa71e8c23ad312110f,Shung-Hsi Yu,shung-hsi.yu@suse.com,1698903545,Alexei Starovoitov,ast@kernel.org,1698904468,168c8cc8161f049ccfa8fb6f39ff3f6a0d8454bf,291d044fd51f8484066300ee42afecf8c8db7b3a,"selftests/bpf: precision tracking test for BPF_NEG and BPF_END

As seen from previous commit that fix backtracking for BPF_ALU | BPF_TO_BE
| BPF_END"," both BPF_NEG and BPF_END require special handling. Add tests
written with inline assembly to check that the verifier does not incorrecly
use the src_reg field of BPF_NEG and BPF_END (including bswap added in v4).

Suggested-by: Eduard Zingerman <eddyz87@gmail.com>
Signed-off-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>
Link: https://lore.kernel.org/r/20231102053913.12004-4-shung-hsi.yu@suse.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Add tests for precision tracking of BPF_NEG and BPF_END handling in verifier.,"precision tracking,test cases,BPF_NEG",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
291d044fd51f8484066300ee42afecf8c8db7b3a,291d044fd51f8484066300ee42afecf8c8db7b3a,Shung-Hsi Yu,shung-hsi.yu@suse.com,1698903543,Alexei Starovoitov,ast@kernel.org,1698904467,c89109320ecb69c5eea9fdb3cd4580dbf031ddae,698b8c5e3b5505ac00102caf9e4843b71192b586,"bpf: Fix precision tracking for BPF_ALU | BPF_TO_BE | BPF_END

BPF_END and BPF_NEG has a different specification for the source bit in
the opcode compared to other ALU/ALU64 instructions"," and is either
reserved or use to specify the byte swap endianness. In both cases the
source bit does not encode source operand location","[' and src_reg is a\nreserved field.\n\nbacktrack_insn() currently does not differentiate BPF_END and BPF_NEG\nfrom other ALU/ALU64 instructions', ' which leads to r0 being incorrectly\nmarked as precise when processing BPF_ALU | BPF_TO_BE | BPF_END\ninstructions. This commit teaches backtrack_insn() to correctly mark\nprecision for such case.\n\nWhile precise tracking of BPF_NEG and other BPF_END instructions are\ncorrect and does not need fixing', ' this commit opt to process all BPF_NEG\nand BPF_END instructions within the same if-clause to better align with\ncurrent convention used in the verifier (e.g. check_alu_op).\n\nFixes: b5dc0163d8fd (""bpf: precise scalar_value tracking"")\nCc: stable@vger.kernel.org\nReported-by: Mohamed Mahmoud <mmahmoud@redhat.com>\nCloses: https://lore.kernel.org/r/87jzrrwptf.fsf@toke.dk\nTested-by: Toke Høiland-Jørgensen <toke@redhat.com>\nTested-by: Tao Lyu <tao.lyu@epfl.ch>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nSigned-off-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nLink: https://lore.kernel.org/r/20231102053913.12004-2-shung-hsi.yu@suse.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']","Fixed precision tracking for BPF_ALU, BPF_TO_BE, and BPF_END instructions in eBPF.","precision tracking, BPF_ALU, BPF_END",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
698b8c5e3b5505ac00102caf9e4843b71192b586,698b8c5e3b5505ac00102caf9e4843b71192b586,Alexei Starovoitov,ast@kernel.org,1698904160,Alexei Starovoitov,ast@kernel.org,1698904160,b34584327520a6b746403e0b2583fd875f29d177,9af3775962afa8b5cd0cc30c1e454405a650c1f3 d8234d47c4aa494d789b85562fa90e837b4575f9,"Merge branch 'relax-allowlist-for-open-coded-css_task-iter'

Chuyi Zhou says:

====================
Relax allowlist for open-coded css_task iter

Hi","
The patchset aims to relax the allowlist for open-coded css_task iter
suggested by Alexei[1].

Please see individual patches for more details. And comments are always
welcome.

Patch summary:
 * Patch #1: Relax the allowlist and let css_task iter can be used in
   bpf iters and any sleepable progs.
 * Patch #2: Add a test in cgroup_iters.c which demonstrates how
   css_task iters can be combined with cgroup iter.
 * Patch #3: Add a test to prove css_task iter can be used in normal
 * sleepable progs.
link[1]:https://lore.kernel.org/lkml/CAADnVQKafk_junRyE=-FVAik4hjTRDtThymYGEL8hGTuYoOGpA@mail.gmail.com/
---

Changes in v2:
 * Fix the incorrect logic in check_css_task_iter_allowlist. Use
   expected_attach_type to check whether we are using bpf_iters.
 * Link to v1:https://lore.kernel.org/bpf/20231022154527.229117-1-zhouchuyi@bytedance.com/T/#m946f9cde86b44a13265d9a44c5738a711eb578fd
Changes in v3:
 * Add a testcase to prove css_task can be used in fentry.s
 * Link to v2:https://lore.kernel.org/bpf/20231024024240.42790-1-zhouchuyi@bytedance.com/T/#m14a97041ff56c2df21bc0149449abd275b73f6a3
Changes in v4:
 * Add Yonghong's ack for patch #1 and patch #2.
 * Solve Yonghong's comments for patch #2
 * Move prog 'iter_css_task_for_each_sleep' from iters_task_failure.c to
   iters_css_task.c. Use RUN_TESTS to prove we can load this prog.
 * Link to v3:https://lore.kernel.org/bpf/20231025075914.30979-1-zhouchuyi@bytedance.com/T/#m3200d8ad29af4ffab97588e297361d0a45d7585d

---
====================

Link: https://lore.kernel.org/r/20231031050438.93297-1-zhouchuyi@bytedance.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The commit relaxes the allowlist for open-coded css_task iter in BPF iters and introduces associated tests.,"allowlist, css_task, bpf iters",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['cgroup like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d8234d47c4aa494d789b85562fa90e837b4575f9,d8234d47c4aa494d789b85562fa90e837b4575f9,Chuyi Zhou,zhouchuyi@bytedance.com,1698728678,Alexei Starovoitov,ast@kernel.org,1698904160,b34584327520a6b746403e0b2583fd875f29d177,f49843afde6771ef6ed5d021eacafacfc98a58bf,"selftests/bpf: Add test for using css_task iter in sleepable progs

This Patch add a test to prove css_task iter can be used in normal
sleepable progs.

Signed-off-by: Chuyi Zhou <zhouchuyi@bytedance.com>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20231031050438.93297-4-zhouchuyi@bytedance.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Adds a test to validate the use of css_task iter in sleepable eBPF programs.,"selftests, css_task, sleepable",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).', ""It's not related to any of the above.""]"
f49843afde6771ef6ed5d021eacafacfc98a58bf,f49843afde6771ef6ed5d021eacafacfc98a58bf,Chuyi Zhou,zhouchuyi@bytedance.com,1698728677,Alexei Starovoitov,ast@kernel.org,1698904160,0cb994bfda2cbc5b435bff4513c41ae622264af2,3091b667498b0a212e760e1033e5f9b8c33a948f,"selftests/bpf: Add tests for css_task iter combining with cgroup iter

This patch adds a test which demonstrates how css_task iter can be combined
with cgroup iter and it won't cause deadlock"," though cgroup iter is not
sleepable.

Signed-off-by: Chuyi Zhou <zhouchuyi@bytedance.com>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20231031050438.93297-3-zhouchuyi@bytedance.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Add selftests demonstrating the combination of css_task iter with cgroup iter to avoid deadlock.,"css_task iter,cgroup iter,selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['cgroup like programs']
3091b667498b0a212e760e1033e5f9b8c33a948f,3091b667498b0a212e760e1033e5f9b8c33a948f,Chuyi Zhou,zhouchuyi@bytedance.com,1698728676,Alexei Starovoitov,ast@kernel.org,1698904160,64e1da0f69e939ed6c28ea8b5d32ee3b35033549,9af3775962afa8b5cd0cc30c1e454405a650c1f3,"bpf: Relax allowlist for css_task iter

The newly added open-coded css_task iter would try to hold the global
css_set_lock in bpf_iter_css_task_new"," so the bpf side has to be careful in
where it allows to use this iter. The mainly concern is dead locking on
css_set_lock. check_css_task_iter_allowlist() in verifier enforced css_task
can only be used in bpf_lsm hooks and sleepable bpf_iter.

This patch relax the allowlist for css_task iter. Any lsm and any iter
(even non-sleepable) and any sleepable are safe since they would not hold
the css_set_lock before entering BPF progs context.

This patch also fixes the misused BPF_TRACE_ITER in
check_css_task_iter_allowlist which compared bpf_prog_type with
bpf_attach_type.

Fixes: 9c66dc94b62ae (""bpf: Introduce css_task open-coded iterator kfuncs"")
Signed-off-by: Chuyi Zhou <zhouchuyi@bytedance.com>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20231031050438.93297-2-zhouchuyi@bytedance.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The commit relaxes the allowlist for css_task iterator to prevent deadlocks on css_set_lock in BPF programs.,relax allowlist css_task,It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['LSM like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9af3775962afa8b5cd0cc30c1e454405a650c1f3,9af3775962afa8b5cd0cc30c1e454405a650c1f3,Andrii Nakryiko,andrii@kernel.org,1698542109,Alexei Starovoitov,ast@kernel.org,1698903758,582bbd2b8038cd7d5403059664349cc503d87742,fd381ce60a2d79cc967506208085336d3d268ae0,"selftests/bpf: fix test_maps' use of bpf_map_create_opts

Use LIBBPF_OPTS() macro to properly initialize bpf_map_create_opts in
test_maps' tests.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Yonghong Song <yonghong.song@linux.dev>
Link: https://lore.kernel.org/r/20231029011509.2479232-1-andrii@kernel.org
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Fixes initialization of bpf_map_create_opts in selftests/bpf using LIBBPF_OPTS() macro.,"selftests,bpf,LIBBPF_OPTS",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
fd381ce60a2d79cc967506208085336d3d268ae0,fd381ce60a2d79cc967506208085336d3d268ae0,Hou Tao,houtao1@huawei.com,1698647776,Alexei Starovoitov,ast@kernel.org,1698903451,fe69f57901645c230fa71f0a90e8d9644492165e,15fb6f2b6c4c3c129adc2412ae12ec15e60a6adb,"bpf: Check map->usercnt after timer->timer is assigned

When there are concurrent uref release and bpf timer init operations","
the following sequence diagram is possible. It will break the guarantee
provided by bpf_timer: bpf_timer will still be alive after userspace
application releases or unpins the map. It also will lead to kmemleak
for old kernel version which doesn't release bpf_timer when map is
released.

bpf program X:

bpf_timer_init()
  lock timer->lock
    read timer->timer as NULL
    read map->usercnt != 0

                process Y:

                close(map_fd)
                  // put last uref
                  bpf_map_put_uref()
                    atomic_dec_and_test(map->usercnt)
                      array_map_free_timers()
                        bpf_timer_cancel_and_free()
                          // just return
                          read timer->timer is NULL

    t = bpf_map_kmalloc_node()
    timer->timer = t
  unlock timer->lock

Fix the problem by checking map->usercnt after timer->timer is assigned","['\nso when there are concurrent uref release and bpf timer init', ' either\nbpf_timer_cancel_and_free() from uref release reads a no-NULL timer\nor the newly-added atomic64_read() returns a zero usercnt.\n\nBecause atomic_dec_and_test(map->usercnt) and READ_ONCE(timer->timer)\nin bpf_timer_cancel_and_free() are not protected by a lock', ' so add\na memory barrier to guarantee the order between map->usercnt and\ntimer->timer. Also use WRITE_ONCE(timer->timer', ' x) to match the lockless\nread of timer->timer in bpf_timer_cancel_and_free().\n\nReported-by: Hsin-Wei Hung <hsinweih@uci.edu>\nCloses: https://lore.kernel.org/bpf/CABcoxUaT2k9hWsS1tNgXyoU3E-=PuOgMn737qK984fbFmfYixQ@mail.gmail.com\nFixes: b00628b1c7d5 (""bpf: Introduce bpf timers."")\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20231030063616.1653024-1-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes a race condition between BPF timer initialization and user reference release leading to memory leak in bpf programs.,"bpf,timer,map",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
15fb6f2b6c4c3c129adc2412ae12ec15e60a6adb,15fb6f2b6c4c3c129adc2412ae12ec15e60a6adb,Dave Marchevsky,davemarchevsky@fb.com,1698789385,Alexei Starovoitov,ast@kernel.org,1698903233,03f6aca296ff77a4608cbb68663a7415b72f29b1,391145ba2accc48b596f3d438af1a6255b62a555,bpf: Add __bpf_hook_{start,"end} macros

Not all uses of __diag_ignore_all(...) in BPF-related code in order to
suppress warnings are wrapping kfunc definitions. Some ""hook point""
definitions - small functions meant to be used as attach points for
fentry and similar BPF progs - need to suppress -Wmissing-declarations.

We could use __bpf_kfunc_{start","['end}_defs added in the previous patch in\nsuch cases', ' but this might be confusing to someone unfamiliar with BPF\ninternals. Instead', ' this patch adds __bpf_hook_{start', 'end} macros', '\ncurrently having the same effect as __bpf_kfunc_{start', 'end}_defs', ' then\nuses them to suppress warnings for two hook points in the kernel itself\nand some bpf_testmod hook points as well.\n\nSigned-off-by: Dave Marchevsky <davemarchevsky@fb.com>\nCc: Yafang Shao <laoar.shao@gmail.com>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nAcked-by: Yafang Shao <laoar.shao@gmail.com>\nLink: https://lore.kernel.org/r/20231031215625.2343848-2-davemarchevsky@fb.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Add macros for suppressing missing declaration warnings in BPF-related hook point definitions.,"macros,suppress,warnings",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,['kprobe/uprobe/ftrace like programs']
391145ba2accc48b596f3d438af1a6255b62a555,391145ba2accc48b596f3d438af1a6255b62a555,Dave Marchevsky,davemarchevsky@fb.com,1698789384,Alexei Starovoitov,ast@kernel.org,1698903233,f529f9f2ea3b0c8ad83a4e37a10c00cafa511295,cd60f410ddc0cd663045d15936155421b6f708fd,bpf: Add __bpf_kfunc_{start,"end}_defs macros

BPF kfuncs are meant to be called from BPF programs. Accordingly","[' most\nkfuncs are not called from anywhere in the kernel', ' which the\n-Wmissing-prototypes warning is unhappy about. We\'ve peppered\n__diag_ignore_all(""-Wmissing-prototypes""', ' ... everywhere kfuncs are\ndefined in the codebase to suppress this warning.\n\nThis patch adds two macros meant to bound one or many kfunc definitions.\nAll existing kfunc definitions which use these __diag calls to suppress\n-Wmissing-prototypes are migrated to use the newly-introduced macros.\nA new __diag_ignore_all - for ""-Wmissing-declarations"" - is added to the\n__bpf_kfunc_start_defs macro based on feedback from Andrii on an earlier\nversion of this patch [0] and another recent mailing list thread [1].\n\nIn the future we might need to ignore different warnings or do other\nkfunc-specific things. This change will make it easier to make such\nmodifications for all kfunc defs.\n\n  [0]: https://lore.kernel.org/bpf/CAEf4BzaE5dRWtK6RPLnjTW-MW9sx9K3Fn6uwqCTChK2Dcb1Xig@mail.gmail.com/\n  [1]: https://lore.kernel.org/bpf/ZT+2qCc%2FaXep0%2FLf@krava/\n\nSigned-off-by: Dave Marchevsky <davemarchevsky@fb.com>\nSuggested-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nCc: Jiri Olsa <olsajiri@gmail.com>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nAcked-by: David Vernet <void@manifault.com>\nAcked-by: Yafang Shao <laoar.shao@gmail.com>\nLink: https://lore.kernel.org/r/20231031215625.2343848-1-davemarchevsky@fb.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit introduces macros for BPF kfunc definitions to support calling them from BPF programs.,"kfuncs,macros,BPF",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
cd60f410ddc0cd663045d15936155421b6f708fd,cd60f410ddc0cd663045d15936155421b6f708fd,Manu Bretelle,chantr4@gmail.com,1698791766,Alexei Starovoitov,ast@kernel.org,1698903101,4cecd389d12844b66902c0d784b39f726698dfd6,b479d38ba959a8e3ffc4d9f760a9f2e4b9027e66,"selftests/bpf: fix test_bpffs

Currently this tests tries to umount /sys/kernel/debug (TDIR) but the
system it is running on may have mounts below.

For example"," danobi/vmtest [0] VMs have
    mount -t tracefs tracefs /sys/kernel/debug/tracing
as part of their init.

This change instead creates a ""random"" directory under /tmp and uses this
as TDIR.
If the directory already exists","[' ignore the error and keep moving on.\n\nTest:\n\nOriginally:\n\n    $ vmtest -k $KERNEL_REPO/arch/x86_64/boot/bzImage ""./test_progs -vv -a test_bpffs""\n    => bzImage\n    ===> Booting\n    ===> Setting up VM\n    ===> Running command\n    [    2.138818] bpf_testmod: loading out-of-tree module taints kernel.\n    [    2.140913] bpf_testmod: module verification failed: signature and/or required key missing - tainting kernel\n    bpf_testmod.ko is already unloaded.\n    Loading bpf_testmod.ko...\n    Successfully loaded bpf_testmod.ko.\n    test_test_bpffs:PASS:clone 0 nsec\n    fn:PASS:unshare 0 nsec\n    fn:PASS:mount / 0 nsec\n    fn:FAIL:umount /sys/kernel/debug unexpected error: -1 (errno 16)\n    bpf_testmod.ko is already unloaded.\n    Loading bpf_testmod.ko...\n    Successfully loaded bpf_testmod.ko.\n    test_test_bpffs:PASS:clone 0 nsec\n    test_test_bpffs:PASS:waitpid 0 nsec\n    test_test_bpffs:FAIL:bpffs test  failed 255#282     test_bpffs:FAIL\n    Summary: 0/0 PASSED', ' 0 SKIPPED', "" 1 FAILED\n    Successfully unloaded bpf_testmod.ko.\n    Command failed with exit code: 1\n\nAfter this change:\n\n    $ vmtest -k $(make image_name) 'cd tools/testing/selftests/bpf && ./test_progs -vv -a test_bpffs'\n    => bzImage\n    ===> Booting\n    ===> Setting up VM\n    ===> Running command\n    [    2.295696] bpf_testmod: loading out-of-tree module taints kernel.\n    [    2.296468] bpf_testmod: module verification failed: signature and/or required key missing - tainting kernel\n    bpf_testmod.ko is already unloaded.\n    Loading bpf_testmod.ko...\n    Successfully loaded bpf_testmod.ko.\n    test_test_bpffs:PASS:clone 0 nsec\n    fn:PASS:unshare 0 nsec\n    fn:PASS:mount / 0 nsec\n    fn:PASS:mount tmpfs 0 nsec\n    fn:PASS:mkdir /tmp/test_bpffs_testdir/fs1 0 nsec\n    fn:PASS:mkdir /tmp/test_bpffs_testdir/fs2 0 nsec\n    fn:PASS:mount bpffs /tmp/test_bpffs_testdir/fs1 0 nsec\n    fn:PASS:mount bpffs /tmp/test_bpffs_testdir/fs2 0 nsec\n    fn:PASS:reading /tmp/test_bpffs_testdir/fs1/maps.debug 0 nsec\n    fn:PASS:reading /tmp/test_bpffs_testdir/fs2/progs.debug 0 nsec\n    fn:PASS:creating /tmp/test_bpffs_testdir/fs1/a 0 nsec\n    fn:PASS:creating /tmp/test_bpffs_testdir/fs1/a/1 0 nsec\n    fn:PASS:creating /tmp/test_bpffs_testdir/fs1/b 0 nsec\n    fn:PASS:create_map(ARRAY) 0 nsec\n    fn:PASS:pin map 0 nsec\n    fn:PASS:stat(/tmp/test_bpffs_testdir/fs1/a) 0 nsec\n    fn:PASS:renameat2(/fs1/a"", ' /fs1/b', "" RENAME_EXCHANGE) 0 nsec\n    fn:PASS:stat(/tmp/test_bpffs_testdir/fs1/b) 0 nsec\n    fn:PASS:b should have a's inode 0 nsec\n    fn:PASS:access(/tmp/test_bpffs_testdir/fs1/b/1) 0 nsec\n    fn:PASS:stat(/tmp/test_bpffs_testdir/fs1/map) 0 nsec\n    fn:PASS:renameat2(/fs1/c"", ' /fs1/b', "" RENAME_EXCHANGE) 0 nsec\n    fn:PASS:stat(/tmp/test_bpffs_testdir/fs1/b) 0 nsec\n    fn:PASS:b should have c's inode 0 nsec\n    fn:PASS:access(/tmp/test_bpffs_testdir/fs1/c/1) 0 nsec\n    fn:PASS:renameat2(RENAME_NOREPLACE) 0 nsec\n    fn:PASS:access(/tmp/test_bpffs_testdir/fs1/b) 0 nsec\n    bpf_testmod.ko is already unloaded.\n    Loading bpf_testmod.ko...\n    Successfully loaded bpf_testmod.ko.\n    test_test_bpffs:PASS:clone 0 nsec\n    test_test_bpffs:PASS:waitpid 0 nsec\n    test_test_bpffs:PASS:bpffs test  0 nsec\n    #282     test_bpffs:OK\n    Summary: 1/0 PASSED"", ' 0 SKIPPED', ' 0 FAILED\n    Successfully unloaded bpf_testmod.ko.\n\n[0] https://github.com/danobi/vmtest\n\nThis is a follow-up of https://lore.kernel.org/bpf/20231024201852.1512720-1-chantr4@gmail.com/T/\n\nv1 -> v2:\n  - use a TDIR name that is related to test\n  - use C-style comments\n\nSigned-off-by: Manu Bretelle <chantr4@gmail.com>\nAcked-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/r/20231031223606.2927976-1-chantr4@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes the test_bpffs by using a temporary directory instead of umounting /sys/kernel/debug.,"selftests,bpf,test_bpffs",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b479d38ba959a8e3ffc4d9f760a9f2e4b9027e66,b479d38ba959a8e3ffc4d9f760a9f2e4b9027e66,Alexei Starovoitov,ast@kernel.org,1698903027,Alexei Starovoitov,ast@kernel.org,1698903028,fb460b6b1633d37877ab1ffe856a8d9ca5b30d21,05670f81d1287c40ec861186e4c4e3401013e7fb 85eb035e6cfd615071256592e1dbe72c1d99c24b,"Merge branch 'bpf-fix-incorrect-immediate-spill'

Hao Sun says:

====================
bpf: Fix incorrect immediate spill

Immediate is incorrectly cast to u32 before being spilled"," losing sign
information. The range information is incorrect after load again. Fix
immediate spill by remove the cast. The second patch add a test case
for this.

Signed-off-by: Hao Sun <sunhao.th@gmail.com>
---
Changes in v3:
- Change the expected log to fix the test case
- Link to v2: https://lore.kernel.org/r/20231101-fix-check-stack-write-v2-0-cb7c17b869b0@gmail.com

Changes in v2:
- Add fix and cc tags.
- Link to v1: https://lore.kernel.org/r/20231026-fix-check-stack-write-v1-0-6b325ef3ce7e@gmail.com

---
====================

Link: https://lore.kernel.org/r/20231101-fix-check-stack-write-v3-0-f05c2b1473d5@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],This commit fixes an issue with immediate value spill and adds a test case to validate the correction.,"fix, immediate, spill",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
85eb035e6cfd615071256592e1dbe72c1d99c24b,85eb035e6cfd615071256592e1dbe72c1d99c24b,Hao Sun,sunhao.th@gmail.com,1698842032,Alexei Starovoitov,ast@kernel.org,1698903027,fb460b6b1633d37877ab1ffe856a8d9ca5b30d21,811c363645b33e6e22658634329e95f383dfc705,"selftests/bpf: Add test for immediate spilled to stack

Add a test to check if the verifier correctly reason about the sign
of an immediate spilled to stack by BPF_ST instruction.

Signed-off-by: Hao Sun <sunhao.th@gmail.com>
Link: https://lore.kernel.org/r/20231101-fix-check-stack-write-v3-2-f05c2b1473d5@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add a test case to verify immediate spill to stack in eBPF selftests.,"test, immediate, stack",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
811c363645b33e6e22658634329e95f383dfc705,811c363645b33e6e22658634329e95f383dfc705,Hao Sun,sunhao.th@gmail.com,1698842031,Alexei Starovoitov,ast@kernel.org,1698903027,48076af7e2c013e22f467140a05fe89fc61cd29c,05670f81d1287c40ec861186e4c4e3401013e7fb,"bpf: Fix check_stack_write_fixed_off() to correctly spill imm

In check_stack_write_fixed_off()"," imm value is cast to u32 before being
spilled to the stack. Therefore","[' the sign information is lost', ' and the\nrange information is incorrect when load from the stack again.\n\nFor the following prog:\n0: r2 = r10\n1: *(u64*)(r2 -40) = -44\n2: r0 = *(u64*)(r2 - 40)\n3: if r0 s<= 0xa goto +2\n4: r0 = 1\n5: exit\n6: r0  = 0\n7: exit\n\nThe verifier gives:\nfunc#0 @0\n0: R1=ctx(off=0', 'imm=0) R10=fp0\n0: (bf) r2 = r10                      ; R2_w=fp0 R10=fp0\n1: (7a) *(u64 *)(r2 -40) = -44        ; R2_w=fp0 fp-40_w=4294967252\n2: (79) r0 = *(u64 *)(r2 -40)         ; R0_w=4294967252 R2_w=fp0\nfp-40_w=4294967252\n3: (c5) if r0 s< 0xa goto pc+2\nmark_precise: frame0: last_idx 3 first_idx 0 subseq_idx -1\nmark_precise: frame0: regs=r0 stack= before 2: (79) r0 = *(u64 *)(r2 -40)\n3: R0_w=4294967252\n4: (b7) r0 = 1                        ; R0_w=1\n5: (95) exit\nverification time 7971 usec\nstack depth 40\nprocessed 6 insns (limit 1000000) max_states_per_insn 0 total_states 0\npeak_states 0 mark_read 0\n\nSo remove the incorrect cast', ' since imm field is declared as s32', ' and\n__mark_reg_known() takes u64', ' so imm would be correctly sign extended\nby compiler.\n\nFixes: ecdf985d7615 (""bpf: track immediate values written to stack by BPF_ST instruction"")\nCc: stable@vger.kernel.org\nSigned-off-by: Hao Sun <sunhao.th@gmail.com>\nAcked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20231101-fix-check-stack-write-v3-1-f05c2b1473d5@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixed the check_stack_write_fixed_off function to properly cast and spill imm values to the stack.,"bpf, fix, spill",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
05670f81d1287c40ec861186e4c4e3401013e7fb,05670f81d1287c40ec861186e4c4e3401013e7fb,Matthieu Baerts,matttbe@kernel.org,1698862561,Alexei Starovoitov,ast@kernel.org,1698902905,f8b1c7408591fccad68ac32a2a7bee01c52fc64c,2b7ac0c87d985c92e519995853c52b9649ea4b07,"bpf: fix compilation error without CGROUPS

Our MPTCP CI complained [1] -- and KBuild too -- that it was no longer
possible to build the kernel without CONFIG_CGROUPS:

  kernel/bpf/task_iter.c: In function 'bpf_iter_css_task_new':
  kernel/bpf/task_iter.c:919:14: error: 'CSS_TASK_ITER_PROCS' undeclared (first use in this function)
    919 |         case CSS_TASK_ITER_PROCS | CSS_TASK_ITER_THREADED:
        |              ^~~~~~~~~~~~~~~~~~~
  kernel/bpf/task_iter.c:919:14: note: each undeclared identifier is reported only once for each function it appears in
  kernel/bpf/task_iter.c:919:36: error: 'CSS_TASK_ITER_THREADED' undeclared (first use in this function)
    919 |         case CSS_TASK_ITER_PROCS | CSS_TASK_ITER_THREADED:
        |                                    ^~~~~~~~~~~~~~~~~~~~~~
  kernel/bpf/task_iter.c:927:60: error: invalid application of 'sizeof' to incomplete type 'struct css_task_iter'
    927 |         kit->css_it = bpf_mem_alloc(&bpf_global_ma"," sizeof(struct css_task_iter));
        |                                                            ^~~~~~
  kernel/bpf/task_iter.c:930:9: error: implicit declaration of function 'css_task_iter_start'; did you mean 'task_seq_start'? [-Werror=implicit-function-declaration]
    930 |         css_task_iter_start(css","[' flags', "" kit->css_it);\n        |         ^~~~~~~~~~~~~~~~~~~\n        |         task_seq_start\n  kernel/bpf/task_iter.c: In function 'bpf_iter_css_task_next':\n  kernel/bpf/task_iter.c:940:16: error: implicit declaration of function 'css_task_iter_next'; did you mean 'class_dev_iter_next'? [-Werror=implicit-function-declaration]\n    940 |         return css_task_iter_next(kit->css_it);\n        |                ^~~~~~~~~~~~~~~~~~\n        |                class_dev_iter_next\n  kernel/bpf/task_iter.c:940:16: error: returning 'int' from a function with return type 'struct task_struct *' makes pointer from integer without a cast [-Werror=int-conversion]\n    940 |         return css_task_iter_next(kit->css_it);\n        |                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n  kernel/bpf/task_iter.c: In function 'bpf_iter_css_task_destroy':\n  kernel/bpf/task_iter.c:949:9: error: implicit declaration of function 'css_task_iter_end' [-Werror=implicit-function-declaration]\n    949 |         css_task_iter_end(kit->css_it);\n        |         ^~~~~~~~~~~~~~~~~\n\nThis patch simply surrounds with a #ifdef the new code requiring CGroups\nsupport. It seems enough for the compiler and this is similar to\nbpf_iter_css_{new"", 'next', 'destroy}() functions where no other #ifdef have\nbeen added in kernel/bpf/helpers.c and in the selftests.\n\nFixes: 9c66dc94b62a (""bpf: Introduce css_task open-coded iterator kfuncs"")\nLink: https://github.com/multipath-tcp/mptcp_net-next/actions/runs/6665206927\nReported-by: kernel test robot <lkp@intel.com>\nCloses: https://lore.kernel.org/oe-kbuild-all/202310260528.aHWgVFqq-lkp@intel.com/\nSigned-off-by: Matthieu Baerts <matttbe@kernel.org>\n[ added missing ifdefs for BTF_ID cgroup definitions ]\nSigned-off-by: Jiri Olsa <jolsa@kernel.org>\nLink: https://lore.kernel.org/r/20231101181601.1493271-1-jolsa@kernel.org\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fix compilation error in BPF task iterator when CONFIG_CGROUPS is not enabled in kernel build.,"BPF, compilation, CONFIG_CGROUPS",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f5277ad1e9768dbd05b1ae8dcdba690215d8c5b7,f5277ad1e9768dbd05b1ae8dcdba690215d8c5b7,Linus Torvalds,torvalds@linux-foundation.org,1698873394,Linus Torvalds,torvalds@linux-foundation.org,1698873394,ea59567723c4892f202596efeeaaaa6aafb72808,ffa059b262ba72571e7fefe7fa2b4ebb6776b277 b9ec913212e6e91efa5a0a612c4a8ec4cf5da896,"Merge tag 'for-6.7/io_uring-sockopt-2023-10-30' of git://git.kernel.dk/linux

Pull io_uring {get","set}sockopt support from Jens Axboe:
 ""This adds support for using getsockopt and setsockopt via io_uring.

  The main use cases for this is to enable use of direct descriptors","['\n  rather than first instantiating a normal file descriptor', ' doing the\n  option tweaking needed', ' then turning it into a direct descriptor. With\n  this support', ' we can avoid needing a regular file descriptor\n  completely.\n\n  The net and bpf bits have been signed off on their side""\n\n* tag \'for-6.7/io_uring-sockopt-2023-10-30\' of git://git.kernel.dk/linux:\n  selftests/bpf/sockopt: Add io_uring support\n  io_uring/cmd: Introduce SOCKET_URING_OP_SETSOCKOPT\n  io_uring/cmd: Introduce SOCKET_URING_OP_GETSOCKOPT\n  io_uring/cmd: return -EOPNOTSUPP if net is disabled\n  selftests/net: Extract uring helpers to be reusable\n  tools headers: Grab copy of io_uring.h\n  io_uring/cmd: Pass compat mode in issue_flags\n  net/socket: Break down __sys_getsockopt\n  net/socket: Break down __sys_setsockopt\n  bpf: Add sockptr support for setsockopt\n  bpf: Add sockptr support for getsockopt\n', '']",Merge io_uring getsockopt and setsockopt support for direct descriptors.,"io_uring, getsockopt, setsockopt",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a6bdc082ad1c91d389a6ba0c7a1945818f732114,a6bdc082ad1c91d389a6ba0c7a1945818f732114,Huacai Chen,chenhuacai@loongson.cn,1698807300,Huacai Chen,chenhuacai@loongson.cn,1698807300,fa630701d5d2a8bc1ab8c4abf759663bbb81aeeb,ffc253263a1375a65fa6c9f62a893e9767fbebfa 99c9991f4e5d77328187187d0c921a3b62bfa998,"Merge 'bpf-next 2023-10-16' into loongarch-next

LoongArch architecture changes for 6.7 (BPF CPU v4 support) depend on
the bpf changes to fix conflictions in selftests and work"," so merge them
to create a base.
",[''],Merge LoongArch architecture changes with bpf-next tree for conflict resolution in selftests.,"Merge, LoongArch, selftests",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
89ed67ef126c4160349c1b96fdb775ea6170ac90,89ed67ef126c4160349c1b96fdb775ea6170ac90,Linus Torvalds,torvalds@linux-foundation.org,1698765011,Linus Torvalds,torvalds@linux-foundation.org,1698765011,98caaf8bba44b21f9345a0af1dd2bd9987764e27,5a6a09e97199d6600d31383055f9d43fbbcbe86f f1c73396133cb3d913e2075298005644ee8dfade,"Merge tag 'net-next-6.7' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net-next

Pull networking updates from Jakub Kicinski:
 ""Core & protocols:

   - Support usec resolution of TCP timestamps"," enabled selectively by a
     route attribute.

   - Defer regular TCP ACK while processing socket backlog","[' try to send\n     a cumulative ACK at the end. Increase single TCP flow performance\n     on a 200Gbit NIC by 20% (100Gbit -> 120Gbit).\n\n   - The Fair Queuing (FQ) packet scheduler:\n       - add built-in 3 band prio / WRR scheduling\n       - support bypass if the qdisc is mostly idle (5% speed up for TCP RR)\n       - improve inactive flow reporting\n       - optimize the layout of structures for better cache locality\n\n   - Support TCP Authentication Option (RFC 5925', ' TCP-AO)', ' a more modern\n     replacement for the old MD5 option.\n\n   - Add more retransmission timeout (RTO) related statistics to\n     TCP_INFO.\n\n   - Support sending fragmented skbs over vsock sockets.\n\n   - Make sure we send SIGPIPE for vsock sockets if socket was\n     shutdown().\n\n   - Add sysctl for ignoring lower limit on lifetime in Router\n     Advertisement PIO', ' based on an in-progress IETF draft.\n\n   - Add sysctl to control activation of TCP ping-pong mode.\n\n   - Add sysctl to make connection timeout in MPTCP configurable.\n\n   - Support rcvlowat and notsent_lowat on MPTCP sockets', ' to help apps\n     limit the number of wakeups.\n\n   - Support netlink GET for MDB (multicast forwarding)', ' allowing user\n     space to request a single MDB entry instead of dumping the entire\n     table.\n\n   - Support selective FDB flushing in the VXLAN tunnel driver.\n\n   - Allow limiting learned FDB entries in bridges', ' prevent OOM attacks.\n\n   - Allow controlling via configfs netconsole targets which were\n     created via the kernel cmdline at boot', ' rather than via configfs at\n     runtime.\n\n   - Support multiple PTP timestamp event queue readers with different\n     filters.\n\n   - MCTP over I3C.\n\n  BPF:\n\n   - Add new veth-like netdevice where BPF program defines the logic of\n     the xmit routine. It can operate in L3 and L2 mode.\n\n   - Support exceptions - allow asserting conditions which should never\n     be true but are hard for the verifier to infer. With some extra\n     flexibility around handling of the exit / failure:\n\n          https://lwn.net/Articles/938435/\n\n   - Add support for local per-cpu kptr', ' allow allocating and storing\n     per-cpu objects in maps. Access to those objects operates on the\n     value for the current CPU.\n\n     This allows to deprecate local one-off implementations of per-CPU\n     storage like BPF_MAP_TYPE_PERCPU_CGROUP_STORAGE maps.\n\n   - Extend cgroup BPF sockaddr hooks for UNIX sockets. The use case is\n     for systemd to re-implement the LogNamespace feature which allows\n     running multiple instances of systemd-journald to process the logs\n     of different services.\n\n   - Enable open-coded task_vma iteration', ' after maple tree conversion\n     made it hard to directly walk VMAs in tracing programs.\n\n   - Add open-coded task', ' css_task and css iterator support. One of the\n     use cases is customizable OOM victim selection via BPF.\n\n   - Allow source address selection with bpf_*_fib_lookup().\n\n   - Add ability to pin BPF timer to the current CPU.\n\n   - Prevent creation of infinite loops by combining tail calls and\n     fentry/fexit programs.\n\n   - Add missed stats for kprobes to retrieve the number of missed\n     kprobe executions and subsequent executions of BPF programs.\n\n   - Inherit system settings for CPU security mitigations.\n\n   - Add BPF v4 CPU instruction support for arm32 and s390x.\n\n  Changes to common code:\n\n   - overflow: add DEFINE_FLEX() for on-stack definition of structs with\n     flexible array members.\n\n   - Process doc update with more guidance for reviewers.\n\n  Driver API:\n\n   - Simplify locking in WiFi (cfg80211 and mac80211 layers)', ' use wiphy\n     mutex in most places and remove a lot of smaller locks.\n\n   - Create a common DPLL configuration API. Allow configuring and\n     querying state of PLL circuits used for clock syntonization', ' in\n     network time distribution.\n\n   - Unify fragmented and full page allocation APIs in page pool code.\n     Let drivers be ignorant of PAGE_SIZE.\n\n   - Rework PHY state machine to avoid races with calls to phy_stop().\n\n   - Notify DSA drivers of MAC address changes on user ports', ' improve\n     correctness of offloads which depend on matching port MAC\n     addresses.\n\n   - Allow antenna control on injected WiFi frames.\n\n   - Reduce the number of variants of napi_schedule().\n\n   - Simplify error handling when composing devlink health messages.\n\n  Misc:\n\n   - A lot of KCSAN data race ""fixes""', ' from Eric.\n\n   - A lot of __counted_by() annotations', ' from Kees.\n\n   - A lot of strncpy -> strscpy and printf format fixes.\n\n   - Replace master/slave terminology with conduit/user in DSA drivers.\n\n   - Handful of KUnit tests for netdev and WiFi core.\n\n  Removed:\n\n   - AppleTalk COPS.\n\n   - AppleTalk ipddp.\n\n   - TI AR7 CPMAC Ethernet driver.\n\n  Drivers:\n\n   - Ethernet high-speed NICs:\n      - Intel (100G', ' ice', ' idpf):\n         - add a driver for the Intel E2000 IPUs\n         - make CRC/FCS stripping configurable\n         - cross-timestamping for E823 devices\n         - basic support for E830 devices\n         - use aux-bus for managing client drivers\n         - i40e: report firmware versions via devlink\n      - nVidia/Mellanox:\n         - support 4-port NICs\n         - increase max number of channels to 256\n         - optimize / parallelize SF creation flow\n      - Broadcom (bnxt):\n         - enhance NIC temperature reporting\n         - support PAM4 speeds and lane configuration\n      - Marvell OcteonTX2:\n         - PTP pulse-per-second output support\n         - enable hardware timestamping for VFs\n      - Solarflare/AMD:\n         - conntrack NAT offload and offload for tunnels\n      - Wangxun (ngbe/txgbe):\n         - expose HW statistics\n      - Pensando/AMD:\n         - support PCI level reset\n         - narrow down the condition under which skbs are linearized\n      - Netronome/Corigine (nfp):\n         - support CHACHA20-POLY1305 crypto in IPsec offload\n\n   - Ethernet NICs embedded', ' slower', ' virtual:\n      - Synopsys (stmmac):\n         - add Loongson-1 SoC support\n         - enable use of HW queues with no offload capabilities\n         - enable PPS input support on all 5 channels\n         - increase TX coalesce timer to 5ms\n      - RealTek USB (r8152): improve efficiency of Rx by using GRO frags\n      - xen: support SW packet timestamping\n      - add drivers for implementations based on TI\'s PRUSS (AM64x EVM)\n\n   - nVidia/Mellanox Ethernet datacenter switches:\n      - avoid poor HW resource use on Spectrum-4 by better block\n        selection for IPv6 multicast forwarding and ordering of blocks\n        in ACL region\n\n   - Ethernet embedded switches:\n      - Microchip:\n         - support configuring the drive strength for EMI compliance\n         - ksz9477: partial ACL support\n         - ksz9477: HSR offload\n         - ksz9477: Wake on LAN\n      - Realtek:\n         - rtl8366rb: respect device tree config of the CPU port\n\n   - Ethernet PHYs:\n      - support Broadcom BCM5221 PHYs\n      - TI dp83867: support hardware LED blinking\n\n   - CAN:\n      - add support for Linux-PHY based CAN transceivers\n      - at91_can: clean up and use rx-offload helpers\n\n   - WiFi:\n      - MediaTek (mt76):\n         - new sub-driver for mt7925 USB/PCIe devices\n         - HW wireless <> Ethernet bridging in MT7988 chips\n         - mt7603/mt7628 stability improvements\n      - Qualcomm (ath12k):\n         - WCN7850:\n            - enable 320 MHz channels in 6 GHz band\n            - hardware rfkill support\n            - enable IEEE80211_HW_SINGLE_SCAN_ON_ALL_BANDS to\n              make scan faster\n            - read board data variant name from SMBIOS\n        - QCN9274: mesh support\n      - RealTek (rtw89):\n         - TDMA-based multi-channel concurrency (MCC)\n      - Silicon Labs (wfx):\n         - Remain-On-Channel (ROC) support\n\n   - Bluetooth:\n      - ISO: many improvements for broadcast support\n      - mark BCM4378/BCM4387 as BROKEN_LE_CODED\n      - add support for QCA2066\n      - btmtksdio: enable Bluetooth wakeup from suspend""\n\n* tag \'net-next-6.7\' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net-next: (1816 commits)\n  net: pcs: xpcs: Add 2500BASE-X case in get state for XPCS drivers\n  net: bpf: Use sockopt_lock_sock() in ip_sock_set_tos()\n  net: mana: Use xdp_set_features_flag instead of direct assignment\n  vxlan: Cleanup IFLA_VXLAN_PORT_RANGE entry in vxlan_get_size()\n  iavf: delete the iavf client interface\n  iavf: add a common function for undoing the interrupt scheme\n  iavf: use unregister_netdev\n  iavf: rely on netdev\'s own registered state\n  iavf: fix the waiting time for initial reset\n  iavf: in iavf_down', ' don\'t queue watchdog_task if comms failed\n  iavf: simplify mutex_trylock+sleep loops\n  iavf: fix comments about old bit locks\n  doc/netlink: Update schema to support cmd-cnt-name and cmd-max-name\n  tools: ynl: introduce option to process unknown attributes or types\n  ipvlan: properly track tx_errors\n  netdevsim: Block until all devices are released\n  nfp: using napi_build_skb() to replace build_skb()\n  net: dsa: microchip: ksz9477: Fix spelling mistake ""Enery"" -> ""Energy""\n  net: dsa: microchip: Ensure Stable PME Pin State for Wake-on-LAN\n  net: dsa: microchip: Refactor switch shutdown routine for WoL preparation\n  ...\n', '']",Merge networking updates including TCP timestamp resolution enhancements.,"networking,TCP,updates",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,['socket like programs']
14ab6d425e80674b6a0145f05719b11e82e64824,14ab6d425e80674b6a0145f05719b11e82e64824,Linus Torvalds,torvalds@linux-foundation.org,1698695233,Linus Torvalds,torvalds@linux-foundation.org,1698695233,77384bc0eb40848f3df30f0d6f9d05e2d9c68627,7352a6765cf5d95888b3952ac89efbb817b4c3cf 12cd44023651666bd44baa36a5c999698890debb,"Merge tag 'vfs-6.7.ctime' of gitolite.kernel.org:pub/scm/linux/kernel/git/vfs/vfs

Pull vfs inode time accessor updates from Christian Brauner:
 ""This finishes the conversion of all inode time fields to accessor
  functions as discussed on list. Changing timestamps manually as we
  used to do before is error prone. Using accessors function makes this
  robust.

  It does not contain the switch of the time fields to discrete 64 bit
  integers to replace struct timespec and free up space in struct inode.
  But after this"," the switch can be trivially made and the patch should
  only affect the vfs if we decide to do it""

* tag 'vfs-6.7.ctime' of gitolite.kernel.org:pub/scm/linux/kernel/git/vfs/vfs: (86 commits)
  fs: rename inode i_atime and i_mtime fields
  security: convert to new timestamp accessors
  selinux: convert to new timestamp accessors
  apparmor: convert to new timestamp accessors
  sunrpc: convert to new timestamp accessors
  mm: convert to new timestamp accessors
  bpf: convert to new timestamp accessors
  ipc: convert to new timestamp accessors
  linux: convert to new timestamp accessors
  zonefs: convert to new timestamp accessors
  xfs: convert to new timestamp accessors
  vboxsf: convert to new timestamp accessors
  ufs: convert to new timestamp accessors
  udf: convert to new timestamp accessors
  ubifs: convert to new timestamp accessors
  tracefs: convert to new timestamp accessors
  sysv: convert to new timestamp accessors
  squashfs: convert to new timestamp accessors
  server: convert to new timestamp accessors
  client: convert to new timestamp accessors
  ...
",[''],"This merge updates inode time fields to use accessor functions, enhancing robustness and reducing errors.","inode,timestamp,accessors",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1768d3a0144c7aae55b9cee66dabf94946eec01e,1768d3a0144c7aae55b9cee66dabf94946eec01e,Arnaldo Carvalho de Melo,acme@kernel.org,1698416327,Namhyung Kim,namhyung@kernel.org,1698460053,7f5cda791e29d327821e3462fed1a9d391a3d632,ee40490dd7cdcda38ece6d081f63ecddd3fdbe25,"perf build: Disable BPF skeletons if clang version is < 12.0.1

While building on a wide range of distros and clang versions it was
noticed that at least version 12.0.1 (noticed on Alpine 3.15 with
""Alpine clang version 12.0.1"") is needed to not fail with BTF generation
errors such as:

Debian:10

  Debian clang version 11.0.1-2~deb10u1:

    CLANG   /tmp/build/perf/util/bpf_skel/.tmp/sample_filter.bpf.o
  <SNIP>
    GENSKEL /tmp/build/perf/util/bpf_skel/sample_filter.skel.h
  libbpf: failed to find BTF for extern 'bpf_cast_to_kern_ctx' [21] section: -2
  Error: failed to open BPF object file: No such file or directory
  make[2]: *** [Makefile.perf:1121: /tmp/build/perf/util/bpf_skel/sample_filter.skel.h] Error 254
  make[2]: *** Deleting file '/tmp/build/perf/util/bpf_skel/sample_filter.skel.h'

Amazon Linux 2:

  clang version 11.1.0 (Amazon Linux 2 11.1.0-1.amzn2.0.2)

    GENSKEL /tmp/build/perf/util/bpf_skel/sample_filter.skel.h
  libbpf: elf: skipping unrecognized data section(18) .eh_frame
  libbpf: elf: skipping relo section(19) .rel.eh_frame for section(18) .eh_frame
  libbpf: failed to find BTF for extern 'bpf_cast_to_kern_ctx' [21] section: -2
  Error: failed to open BPF object file: No such file or directory
  make[2]: *** [/tmp/build/perf/util/bpf_skel/sample_filter.skel.h] Error 254
  make[2]: *** Deleting file `/tmp/build/perf/util/bpf_skel/sample_filter.skel.h'

Ubuntu 20.04:

  clang version 10.0.0-4ubuntu1

    CLANG   /tmp/build/perf/util/bpf_skel/.tmp/augmented_raw_syscalls.bpf.o
    GENSKEL /tmp/build/perf/util/bpf_skel/bench_uprobe.skel.h
    GENSKEL /tmp/build/perf/util/bpf_skel/bperf_leader.skel.h
  libbpf: sec '.reluprobe': corrupted symbol #27 pointing to invalid section #65522 for relo #0
    GENSKEL /tmp/build/perf/util/bpf_skel/bperf_follower.skel.h
  Error: failed to open BPF object file: BPF object format invalid
  make[2]: *** [Makefile.perf:1121: /tmp/build/perf/util/bpf_skel/bench_uprobe.skel.h] Error 95
  make[2]: *** Deleting file '/tmp/build/perf/util/bpf_skel/bench_uprobe.skel.h'

So check if the version is at least 12.0.1 otherwise disable building
BPF skels and provide a message about it"," continuing the build.

The message","[' when running on amazonlinux:2:\n\n  Makefile.config:698: Warning: Disabled BPF skeletons as reliable BTF generation needs at least clang version 12.0.1\n\nSigned-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>\nReviewed-by: Ian Rogers <irogers@google.com>\nLink: https://lore.kernel.org/r/ZTvGx/Ou6BVnYBqi@kernel.org\nSigned-off-by: Namhyung Kim <namhyung@kernel.org>\n', '']",Disable building BPF skeletons in perf if using a clang version older than 12.0.1 to avoid BTF generation errors.,"BPF skeletons, clang version, BTF errors",It's a build system or CI/CD change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"[""It's not related to any of the above.""]"
06497763c8f15d08c0e356e651a61f2930a8987c,06497763c8f15d08c0e356e651a61f2930a8987c,Yonghong Song,yonghong.song@linux.dev,1698431064,Jakub Kicinski,kuba@kernel.org,1698446488,99b59e9c88460e2d61a4ef42a6feac4f37943c4b,f5247a6ed5b5bbaa609f97049de868974eb7a7c2,"net: bpf: Use sockopt_lock_sock() in ip_sock_set_tos()

With latest sync from net-next tree"," bpf-next has a bpf selftest failure:
  [root@arch-fb-vm1 bpf]# ./test_progs -t setget_sockopt
  ...
  [   76.194349] ============================================
  [   76.194682] WARNING: possible recursive locking detected
  [   76.195039] 6.6.0-rc7-g37884503df08-dirty #67 Tainted: G        W  OE
  [   76.195518] --------------------------------------------
  [   76.195852] new_name/154 is trying to acquire lock:
  [   76.196159] ffff8c3e06ad8d30 (sk_lock-AF_INET){+.+.}-{0:0}","[' at: ip_sock_set_tos+0x19/0x30\n  [   76.196669]\n  [   76.196669] but task is already holding lock:\n  [   76.197028] ffff8c3e06ad8d30 (sk_lock-AF_INET){+.+.}-{0:0}', ' at: inet_listen+0x21/0x70\n  [   76.197517]\n  [   76.197517] other info that might help us debug this:\n  [   76.197919]  Possible unsafe locking scenario:\n  [   76.197919]\n  [   76.198287]        CPU0\n  [   76.198444]        ----\n  [   76.198600]   lock(sk_lock-AF_INET);\n  [   76.198831]   lock(sk_lock-AF_INET);\n  [   76.199062]\n  [   76.199062]  *** DEADLOCK ***\n  [   76.199062]\n  [   76.199420]  May be due to missing lock nesting notation\n  [   76.199420]\n  [   76.199879] 2 locks held by new_name/154:\n  [   76.200131]  #0: ffff8c3e06ad8d30 (sk_lock-AF_INET){+.+.}-{0:0}', ' at: inet_listen+0x21/0x70\n  [   76.200644]  #1: ffffffff90f96a40 (rcu_read_lock){....}-{1:2}', ' at: __cgroup_bpf_run_filter_sock_ops+0x55/0x290\n  [   76.201268]\n  [   76.201268] stack backtrace:\n  [   76.201538] CPU: 4 PID: 154 Comm: new_name Tainted: G        W  OE      6.6.0-rc7-g37884503df08-dirty #67\n  [   76.202134] Hardware name: QEMU Standard PC (i440FX + PIIX', ' 1996)', ' BIOS 1.13.0-1ubuntu1.1 04/01/2014\n  [   76.202699] Call Trace:\n  [   76.202858]  <TASK>\n  [   76.203002]  dump_stack_lvl+0x4b/0x80\n  [   76.203239]  __lock_acquire+0x740/0x1ec0\n  [   76.203503]  lock_acquire+0xc1/0x2a0\n  [   76.203766]  ? ip_sock_set_tos+0x19/0x30\n  [   76.204050]  ? sk_stream_write_space+0x12a/0x230\n  [   76.204389]  ? lock_release+0xbe/0x260\n  [   76.204661]  lock_sock_nested+0x32/0x80\n  [   76.204942]  ? ip_sock_set_tos+0x19/0x30\n  [   76.205208]  ip_sock_set_tos+0x19/0x30\n  [   76.205452]  do_ip_setsockopt+0x4b3/0x1580\n  [   76.205719]  __bpf_setsockopt+0x62/0xa0\n  [   76.205963]  bpf_sock_ops_setsockopt+0x11/0x20\n  [   76.206247]  bpf_prog_630217292049c96e_bpf_test_sockopt_int+0xbc/0x123\n  [   76.206660]  bpf_prog_493685a3bae00bbd_bpf_test_ip_sockopt+0x49/0x4b\n  [   76.207055]  bpf_prog_b0bcd27f269aeea0_skops_sockopt+0x44c/0xec7\n  [   76.207437]  __cgroup_bpf_run_filter_sock_ops+0xda/0x290\n  [   76.207829]  __inet_listen_sk+0x108/0x1b0\n  [   76.208122]  inet_listen+0x48/0x70\n  [   76.208373]  __sys_listen+0x74/0xb0\n  [   76.208630]  __x64_sys_listen+0x16/0x20\n  [   76.208911]  do_syscall_64+0x3f/0x90\n  [   76.209174]  entry_SYSCALL_64_after_hwframe+0x6e/0xd8\n  ...\n\nBoth ip_sock_set_tos() and inet_listen() calls lock_sock(sk) which\ncaused a dead lock.\n\nTo fix the issue', ' use sockopt_lock_sock() in ip_sock_set_tos()\ninstead. sockopt_lock_sock() will avoid lock_sock() if it is in bpf\ncontext.\n\nFixes: 878d951c6712 (""inet: lock the socket in ip_sock_set_tos()"")\nSuggested-by: Martin KaFai Lau <martin.lau@kernel.org>\nSigned-off-by: Yonghong Song <yonghong.song@linux.dev>\nReviewed-by: Eric Dumazet <edumazet@google.com>\nLink: https://lore.kernel.org/r/20231027182424.1444845-1-yonghong.song@linux.dev\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",The commit updates the net bpf code to use sockopt_lock_sock in ip_sock_set_tos to avoid recursive locking issues.,"sockopt_lock_sock, ip_sock_set_tos, recursive locking",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['socket like programs', 'other']"
c6f9b7138bf5c6b826175c9e0ad5f5dbfff4fa36,c6f9b7138bf5c6b826175c9e0ad5f5dbfff4fa36,Jakub Kicinski,kuba@kernel.org,1698375760,Jakub Kicinski,kuba@kernel.org,1698375761,c7bf02f5524d49f829258fbda2cedab62e25efbd,cc33a80b816406f900a53c7f98a50f6eacdd2e31 ea41b880cc85f0a992571f66e4554a69f7806246,"Merge tag 'for-netdev' of ssh://gitolite.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next

Daniel Borkmann says:

====================
pull-request: bpf-next 2023-10-26

We've added 51 non-merge commits during the last 10 day(s) which contain
a total of 75 files changed", 5037 insertions(+),"[' 200 deletions(-).\n\nThe main changes are:\n\n1) Add open-coded task', ' css_task and css iterator support.\n   One of the use cases is customizable OOM victim selection via BPF', ""\n   from Chuyi Zhou.\n\n2) Fix BPF verifier's iterator convergence logic to use exact states\n   comparison for convergence checks"", ' from Eduard Zingerman', '\n   Andrii Nakryiko and Alexei Starovoitov.\n\n3) Add BPF programmable net device where bpf_mprog defines the logic\n   of its xmit routine. It can operate in L3 and L2 mode', '\n   from Daniel Borkmann and Nikolay Aleksandrov.\n\n4) Batch of fixes for BPF per-CPU kptr and re-enable unit_size checking\n   for global per-CPU allocator', ' from Hou Tao.\n\n5) Fix libbpf which eagerly assumed that SHT_GNU_verdef ELF section\n   was going to be present whenever a binary has SHT_GNU_versym section', '\n   from Andrii Nakryiko.\n\n6) Fix BPF ringbuf correctness to fold smp_mb__before_atomic() into\n   atomic_set_release()', ' from Paul E. McKenney.\n\n7) Add a warning if NAPI callback missed xdp_do_flush() under\n   CONFIG_DEBUG_NET which helps checking if drivers were missing\n   the former', ' from Sebastian Andrzej Siewior.\n\n8) Fix missed RCU read-lock in bpf_task_under_cgroup() which was throwing\n   a warning under sleepable programs', ' from Yafang Shao.\n\n9) Avoid unnecessary -EBUSY from htab_lock_bucket by disabling IRQ before\n   checking map_locked', ' from Song Liu.\n\n10) Make BPF CI linked_list failure test more robust', '\n    from Kumar Kartikeya Dwivedi.\n\n11) Enable samples/bpf to be built as PIE in Fedora', ' from Viktor Malik.\n\n12) Fix xsk starving when multiple xsk sockets were associated with\n    a single xsk_buff_pool', ' from Albert Huang.\n\n13) Clarify the signed modulo implementation for the BPF ISA standardization\n    document that it uses truncated division', "" from Dave Thaler.\n\n14) Improve BPF verifier's JEQ/JNE branch taken logic to also consider\n    signed bounds knowledge"", ' from Andrii Nakryiko.\n\n15) Add an option to XDP selftests to use multi-buffer AF_XDP\n    xdp_hw_metadata and mark used XDP programs as capable to use frags', ""\n    from Larysa Zaremba.\n\n16) Fix bpftool's BTF dumper wrt printing a pointer value and another\n    one to fix struct_ops dump in an array"", "" from Manu Bretelle.\n\n* tag 'for-netdev' of ssh://gitolite.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next: (51 commits)\n  netkit: Remove explicit active/peer ptr initialization\n  selftests/bpf: Fix selftests broken by mitigations=off\n  samples/bpf: Allow building with custom bpftool\n  samples/bpf: Fix passing LDFLAGS to libbpf\n  samples/bpf: Allow building with custom CFLAGS/LDFLAGS\n  bpf: Add more WARN_ON_ONCE checks for mismatched alloc and free\n  selftests/bpf: Add selftests for netkit\n  selftests/bpf: Add netlink helper library\n  bpftool: Extend net dump with netkit progs\n  bpftool: Implement link show support for netkit\n  libbpf: Add link-based API for netkit\n  tools: Sync if_link uapi header\n  netkit"", ' bpf: Add bpf programmable net device\n  bpf: Improve JEQ/JNE branch taken logic\n  bpf: Fold smp_mb__before_atomic() into atomic_set_release()\n  bpf: Fix unnecessary -EBUSY from htab_lock_bucket\n  xsk: Avoid starving the xsk further down the list\n  bpf: print full verifier states on infinite loop detection\n  selftests/bpf: test if state loops are detected in a tricky case\n  bpf: correct loop detection for iterators convergence\n  ...\n====================\n\nLink: https://lore.kernel.org/r/20231026150509.2824-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Merge commit integrating 51 non-merge commits from bpf-next branch.,"merge, bpf-next, commits",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ea41b880cc85f0a992571f66e4554a69f7806246,ea41b880cc85f0a992571f66e4554a69f7806246,Nikolay Aleksandrov,razor@blackwall.org,1698313265,Daniel Borkmann,daniel@iogearbox.net,1698328719,4da532cc1563b5b01e1b792438edcd0cbc7301d8,399f6185a1c02f39bcadb8749bc2d9d48685816f,"netkit: Remove explicit active/peer ptr initialization

Remove the explicit NULLing of active/peer pointers and rely on the
implicit one done at net device allocation.

Suggested-by: Jiri Pirko <jiri@resnulli.us>
Signed-off-by: Nikolay Aleksandrov <razor@blackwall.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Reviewed-by: Jiri Pirko <jiri@nvidia.com>
Acked-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20231026094106.1505892-2-razor@blackwall.org
",,The commit removes explicit pointer initialization and relies on implicit initialization during net device allocation.,"pointer initialization, net device, implicit nulling",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
399f6185a1c02f39bcadb8749bc2d9d48685816f,399f6185a1c02f39bcadb8749bc2d9d48685816f,Yafang Shao,laoar.shao@gmail.com,1698203504,Daniel Borkmann,daniel@iogearbox.net,1698327723,8e0f5a2c26af71dadb9713ce7cf2c65d8da398fb,37db10bc247d5d0b448babd7ff386f092246e732,"selftests/bpf: Fix selftests broken by mitigations=off

When we configure the kernel command line with 'mitigations=off' and set
the sysctl knob 'kernel.unprivileged_bpf_disabled' to 0"," the commit
bc5bc309db45 (""bpf: Inherit system settings for CPU security mitigations"")
causes issues in the execution of `test_progs -t verifier`. This is
because 'mitigations=off' bypasses Spectre v1 and Spectre v4 protections.

Currently","[' when a program requests to run in unprivileged mode\n(kernel.unprivileged_bpf_disabled = 0)', "" the BPF verifier may prevent\nit from running due to the following conditions not being enabled:\n\n  - bypass_spec_v1\n  - bypass_spec_v4\n  - allow_ptr_leaks\n  - allow_uninit_stack\n\nWhile 'mitigations=off' enables the first two conditions"", ' it does not\nenable the latter two. As a result', "" some test cases in\n'test_progs -t verifier' that were expected to fail to run may run\nsuccessfully"", ' while others still fail but with different error messages.\nThis makes it challenging to address them comprehensively.\n\nMoreover', ' in the future', ' we may introduce more fine-grained control over\nCPU mitigations', ' such as enabling only bypass_spec_v1 or bypass_spec_v4.\n\nGiven the complexity of the situation', ' rather than fixing each broken test\ncase individually', "" it's preferable to skip them when 'mitigations=off' is\nin effect and introduce specific test cases for the new 'mitigations=off'\nscenario. For instance"", "" we can introduce new BTF declaration tags like\n'__failure__nospec'"", "" '__failure_nospecv1' and '__failure_nospecv4'.\n\nIn this patch"", "" the approach is to simply skip the broken test cases when\n'mitigations=off' is enabled. The result of `test_progs -t verifier` as\nfollows after this commit"", ""\n\nBefore this commit\n==================\n\n- without 'mitigations=off'\n  - kernel.unprivileged_bpf_disabled = 2\n    Summary: 74/948 PASSED"", ' 388 SKIPPED', ' 0 FAILED\n  - kernel.unprivileged_bpf_disabled = 0\n    Summary: 74/1336 PASSED', ' 0 SKIPPED', "" 0 FAILED    <<<<\n- with 'mitigations=off'\n  - kernel.unprivileged_bpf_disabled = 2\n    Summary: 74/948 PASSED"", ' 388 SKIPPED', ' 0 FAILED\n  - kernel.unprivileged_bpf_disabled = 0\n    Summary: 63/1276 PASSED', ' 0 SKIPPED', "" 11 FAILED   <<<< 11 FAILED\n\nAfter this commit\n=================\n\n- without 'mitigations=off'\n  - kernel.unprivileged_bpf_disabled = 2\n    Summary: 74/948 PASSED"", ' 388 SKIPPED', ' 0 FAILED\n  - kernel.unprivileged_bpf_disabled = 0\n    Summary: 74/1336 PASSED', ' 0 SKIPPED', ' 0 FAILED    <<<<\n- with this patch', "" with 'mitigations=off'\n  - kernel.unprivileged_bpf_disabled = 2\n    Summary: 74/948 PASSED"", ' 388 SKIPPED', ' 0 FAILED\n  - kernel.unprivileged_bpf_disabled = 0\n    Summary: 74/948 PASSED', ' 388 SKIPPED', ' 0 FAILED   <<<< SKIPPED\n\nFixes: bc5bc309db45 (""bpf: Inherit system settings for CPU security mitigations"")\nReported-by: Alexei Starovoitov <alexei.starovoitov@gmail.com>\nSigned-off-by: Yafang Shao <laoar.shao@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nCloses: https://lore.kernel.org/bpf/CAADnVQKUBJqg+hHtbLeeC2jhoJAWqnmRAzXW3hmUCNSV9kx4sQ@mail.gmail.com\nLink: https://lore.kernel.org/bpf/20231025031144.5508-1-laoar.shao@gmail.com\n', '']",Fixes broken eBPF selftests when kernel configured with 'mitigations=off' affecting test execution.,"selftests, mitigations, verifier",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
37db10bc247d5d0b448babd7ff386f092246e732,37db10bc247d5d0b448babd7ff386f092246e732,Viktor Malik,vmalik@redhat.com,1698214754,Daniel Borkmann,daniel@iogearbox.net,1698327133,571972ac5c029ce9bc18352630b1de1084a751a0,f56bcfadf7d6d56b099726df4fc262b76486b0e0,"samples/bpf: Allow building with custom bpftool

samples/bpf build its own bpftool boostrap to generate vmlinux.h as well
as some BPF objects. This is a redundant step if bpftool has been
already built"," so update samples/bpf/Makefile such that it accepts a
path to bpftool passed via the BPFTOOL variable. The approach is
practically the same as tools/testing/selftests/bpf/Makefile uses.

Signed-off-by: Viktor Malik <vmalik@redhat.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/bd746954ac271b02468d8d951ff9f11e655d485b.1698213811.git.vmalik@redhat.com
",[''],This commit allows samples/bpf to build with a custom bpftool by modifying the Makefile.,"samples,bpf,Makefile",It's a build system or CI/CD change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"[""It's not related to any of the above.""]"
f56bcfadf7d6d56b099726df4fc262b76486b0e0,f56bcfadf7d6d56b099726df4fc262b76486b0e0,Viktor Malik,vmalik@redhat.com,1698214753,Daniel Borkmann,daniel@iogearbox.net,1698327133,98811e1bdf503a94fcb7ec28ef1ce5e3736bc6e0,870f09f1ba3014e2c157b14299c172b4bb716638,"samples/bpf: Fix passing LDFLAGS to libbpf

samples/bpf/Makefile passes LDFLAGS=$(TPROGS_LDFLAGS) to libbpf build
without surrounding quotes"," which may cause compilation errors when
passing custom TPROGS_USER_LDFLAGS.

For example:

    $ make -C samples/bpf/ TPROGS_USER_LDFLAGS=""-Wl","['--as-needed -specs=/usr/lib/gcc/x86_64-redhat-linux/13/libsanitizer.spec""\n    make: Entering directory \'./samples/bpf\'\n    make -C ../../ M=./samples/bpf BPF_SAMPLES_PATH=./samples/bpf\n    make[1]: Entering directory \'.\'\n    make -C ./samples/bpf/../../tools/lib/bpf RM=\'rm -rf\' EXTRA_CFLAGS=""-Wall -O2 -Wmissing-prototypes -Wstrict-prototypes  -I./usr/include -I./tools/testing/selftests/bpf/ -I./samples/bpf/libbpf/include -I./tools/include -I./tools/perf -I./tools/lib -DHAVE_ATTR_TEST=0"" \\\n            LDFLAGS=-Wl', ""--as-needed -specs=/usr/lib/gcc/x86_64-redhat-linux/13/libsanitizer.spec srctree=./samples/bpf/../../ \\\n            O= OUTPUT=./samples/bpf/libbpf/ DESTDIR=./samples/bpf/libbpf prefix= \\\n            ./samples/bpf/libbpf/libbpf.a install_headers\n    make: invalid option -- 'c'\n    make: invalid option -- '='\n    make: invalid option -- '/'\n    make: invalid option -- 'u'\n    make: invalid option -- '/'\n    [...]\n\nFix the error by properly quoting $(TPROGS_LDFLAGS).\n\nSuggested-by: Donald Zickus <dzickus@redhat.com>\nSigned-off-by: Viktor Malik <vmalik@redhat.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/c690de6671cc6c983d32a566d33fd7eabd18b526.1698213811.git.vmalik@redhat.com\n"", '']",Fixes LDFLAGS passing issue in samples/bpf Makefile to prevent compilation errors.,"LDFLAGS, Makefile, compilation",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
870f09f1ba3014e2c157b14299c172b4bb716638,870f09f1ba3014e2c157b14299c172b4bb716638,Viktor Malik,vmalik@redhat.com,1698214752,Daniel Borkmann,daniel@iogearbox.net,1698327132,eccba13e343802ae0bef8d186d918062e1634396,c421c12586b3f00fb96b5c9af15c9a051a9090b1,"samples/bpf: Allow building with custom CFLAGS/LDFLAGS

Currently"," it is not possible to specify custom flags when building
samples/bpf. The flags are defined in TPROGS_CFLAGS/TPROGS_LDFLAGS
variables","[' however', ' when trying to override those from the make command', '\ncompilation fails.\n\nFor example', ' when trying to build with PIE:\n\n    $ make -C samples/bpf TPROGS_CFLAGS=""-fpie"" TPROGS_LDFLAGS=""-pie""\n\nThis is because samples/bpf/Makefile updates these variables', ' especially\nappends include paths to TPROGS_CFLAGS and these updates are overridden\nby setting the variables from the make command.\n\nThis patch introduces variables TPROGS_USER_CFLAGS/TPROGS_USER_LDFLAGS\nfor this purpose', ' which can be set from the make command and their\nvalues are propagated to TPROGS_CFLAGS/TPROGS_LDFLAGS.\n\nSigned-off-by: Viktor Malik <vmalik@redhat.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/2d81100b830a71f0e72329cc7781edaefab75f62.1698213811.git.vmalik@redhat.com\n', '']",The commit allows building samples/bpf with custom CFLAGS/LDFLAGS.,custom CFLAGS LDFLAGS,It's a build system or CI/CD change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
c421c12586b3f00fb96b5c9af15c9a051a9090b1,c421c12586b3f00fb96b5c9af15c9a051a9090b1,Hou Tao,houtao1@huawei.com,1697852999,Daniel Borkmann,daniel@iogearbox.net,1698323013,93527c11d4684d0c5dc602a575bd7dc90d2cf320,22360fad5889cbefe1eca695b0cc0273ab280b56,"bpf: Add more WARN_ON_ONCE checks for mismatched alloc and free

There are two possible mismatched alloc and free cases in BPF memory
allocator:

1) allocate from cache X but free by cache Y with a different unit_size
2) allocate from per-cpu cache but free by kmalloc cache or vice versa

So add more WARN_ON_ONCE checks in free_bulk() and __free_by_rcu() to
spot these mismatched alloc and free early.

Signed-off-by: Hou Tao <houtao1@huawei.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20231021014959.3563841-1-houtao@huaweicloud.com
",,Add checks to detect mismatched allocation and freeing in the BPF memory allocator.,memory allocator checks,It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e56808fef8f71a192b2740c0b6ea8be7ab865d54,e56808fef8f71a192b2740c0b6ea8be7ab865d54,Roman Gushchin,roman.gushchin@linux.dev,1697756026,Andrew Morton,akpm@linux-foundation.org,1698277631,e33f1ca3bd268eb5e707e0cb801aaf7cd3d4d02e,c63b835d0eafc956c43b8c6605708240ac52b8cd,"mm: kmem: reimplement get_obj_cgroup_from_current()

Reimplement get_obj_cgroup_from_current() using current_obj_cgroup(). 
get_obj_cgroup_from_current() and current_obj_cgroup() share 80% of the
code"," so the new implementation is almost trivial.

get_obj_cgroup_from_current() is a convenient function used by the
bpf subsystem","[' so there is no reason to get rid of it completely.\n\nLink: https://lkml.kernel.org/r/20231019225346.1822282-7-roman.gushchin@linux.dev\nSigned-off-by: Roman Gushchin (Cruise) <roman.gushchin@linux.dev>\nReviewed-by: Vlastimil Babka <vbabka@suse.cz>\nAcked-by: Shakeel Butt <shakeelb@google.com>\nCc: David Rientjes <rientjes@google.com>\nCc: Dennis Zhou <dennis@kernel.org>\nCc: Johannes Weiner <hannes@cmpxchg.org>\nCc: Michal Hocko <mhocko@kernel.org>\nCc: Muchun Song <muchun.song@linux.dev>\nCc: Naresh Kamboju <naresh.kamboju@linaro.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\n', '']",Reimplemented get_obj_cgroup_from_current() using existing common code in current_obj_cgroup() to reduce redundancy.,"reimplement, obj_cgroup, bpf",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b5711042a1c8cc88ed40a5ebf612b36e83a4e2e4,b5711042a1c8cc88ed40a5ebf612b36e83a4e2e4,Namhyung Kim,namhyung@kernel.org,1697834861,Namhyung Kim,namhyung@kernel.org,1698253375,d2c57c3531da558d0d3c94ceee311c29e03f38e7,6a070573f290f99a6129ac3e13b9df521a1a65de,"perf lock contention: Use per-cpu array map for spinlocks

Currently lock contention timestamp is maintained in a hash map keyed by
pid.  That means it needs to get and release a map element (which is
proctected by spinlock!) on each contention begin and end pair.  This
can impact on performance if there are a lot of contention (usually from
spinlocks).

It used to go with task local storage but it had an issue on memory
allocation in some critical paths.  Although it's addressed in recent
kernels IIUC"," the tool should support old kernels too.  So it cannot
simply switch to the task local storage at least for now.

As spinlocks create lots of contention and they disabled preemption
during the spinning","[' it can use per-cpu array to keep the timestamp to\navoid overhead in hashmap update and delete.\n\nIn contention_begin', "" it's easy to check the lock types since it can see\nthe flags.  But contention_end cannot see it.  So let's try to per-cpu\narray first (unconditionally) if it has an active element (lock != 0).\nThen it should be used and per-task tstamp map should not be used until\nthe per-cpu array element is cleared which means nested spinlock\ncontention (if any) was finished and it nows see (the outer) lock.\n\nSigned-off-by: Namhyung Kim <namhyung@kernel.org>\nAcked-by: Ian Rogers <irogers@google.com>\nCc: Hao Luo <haoluo@google.com>\nCc: Song Liu <song@kernel.org>\nCc: bpf@vger.kernel.org\nLink: https://lore.kernel.org/r/20231020204741.1869520-3-namhyung@kernel.org\n"", '']",Optimized lock contention handling by using per-cpu array map instead of hash map for spinlocks in perf tool.,"lock contention, spinlocks, per-cpu",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6a070573f290f99a6129ac3e13b9df521a1a65de,6a070573f290f99a6129ac3e13b9df521a1a65de,Namhyung Kim,namhyung@kernel.org,1697834860,Namhyung Kim,namhyung@kernel.org,1698253367,61889f17e90cc264f7645ecbdf1a5065622a68eb,d99317f214ca3d381f7b17a75c41263885664e06,"perf lock contention: Check race in tstamp elem creation

When pelem is NULL"," it'd create a new entry with zero data.  But it
might be preempted by IRQ/NMI just before calling bpf_map_update_elem()
then there's a chance to call it twice for the same pid.  So it'd be
better to use BPF_NOEXIST flag and check the return value to prevent
the race.

Signed-off-by: Namhyung Kim <namhyung@kernel.org>
Acked-by: Ian Rogers <irogers@google.com>
Cc: Hao Luo <haoluo@google.com>
Cc: Song Liu <song@kernel.org>
Cc: bpf@vger.kernel.org
Link: https://lore.kernel.org/r/20231020204741.1869520-2-namhyung@kernel.org
",[''],Implement BPF_NOEXIST flag to prevent race conditions in perf lock contention element creation.,"race, BPF_NOEXIST, contention",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,['tracepoints like programs']
d99317f214ca3d381f7b17a75c41263885664e06,d99317f214ca3d381f7b17a75c41263885664e06,Namhyung Kim,namhyung@kernel.org,1697834859,Namhyung Kim,namhyung@kernel.org,1698253354,3cbd12b10993be639766354b360519081709388e,e093a222d7cba1eb6c36887e58ce8a4ff249f1c6,"perf lock contention: Clear lock addr after use

It checks the current lock to calculated the delta of contention time.
The address is saved in the tstamp map which is allocated at begining of
contention and released at end of contention.

But it's possible for bpf_map_delete_elem() to fail.  In that case"," the
element in the tstamp map kept for the current lock and it makes the
next contention for the same lock tracked incorrectly.  Specificially
the next contention begin will see the existing element for the task and
it'd just return.  Then the next contention end will see the element and
calculate the time using the timestamp for the previous begin.

This can result in a large value for two small contentions happened from
time to time.  Let's clear the lock address so that it can be updated
next time even if the bpf_map_delete_elem() failed.

Signed-off-by: Namhyung Kim <namhyung@kernel.org>
Acked-by: Ian Rogers <irogers@google.com>
Cc: Hao Luo <haoluo@google.com>
Cc: Song Liu <song@kernel.org>
Cc: bpf@vger.kernel.org
Link: https://lore.kernel.org/r/20231020204741.1869520-1-namhyung@kernel.org
",[''],Fix contention time tracking in perf lock by clearing lock address after use.,"perf,lock,contention",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
22360fad5889cbefe1eca695b0cc0273ab280b56,22360fad5889cbefe1eca695b0cc0273ab280b56,Martin KaFai Lau,martin.lau@kernel.org,1698188702,Martin KaFai Lau,martin.lau@kernel.org,1698188868,33ca776f10feda7e38956dc26edf74fd1bbc88da,42d31dd601fa43b9afdf069d1ba410b2306a4c76 ace15f91e569172dac71ae0aeb3a2e76d1ce1b17,"Merge branch 'Add bpf programmable net device'

Daniel Borkmann says:

====================
This work adds a BPF programmable device which can operate in L3 or L2
mode where the BPF program is part of the xmit routine. It's program
management is done via bpf_mprog and it comes with BPF link support.
For details see patch 1 and following. Thanks!

v3 -> v4:
  - Moved netkit_release_all() into ndo_uninit (Stan)
  - Two small commit msg corrections (Toke)
  - Added Acked/Reviewed-by
v2 -> v3:
  - Remove setting dev->min_mtu to ETH_MIN_MTU (Andrew)
  - Do not populate ethtool info->version (Andrew)
  - Populate netdev private data before register_netdevice (Andrew)
  - Use strscpy for ifname template (Jakub)
  - Use GFP_KERNEL_ACCOUNT for link kzalloc (Jakub)
  - Carry and dump link attach type for bpftool (Toke)
v1 -> v2:
  - Rename from meta (Toke", Andrii,"[' Alexei)\n  - Reuse skb_scrub_packet (Stan)\n  - Remove IFF_META and use netdev_ops (Toke)\n  - Add comment to multicast handler (Toke)\n  - Remove silly version info (Toke)\n  - Fix attach_type_name (Quentin)\n  - Rework libbpf link attach api to be similar\n    as tcx (Andrii)\n  - Move flags last for bpf_netkit_opts (Andrii)\n  - Rebased to bpf_mprog query api changes\n  - Folded link support patch into main one\n====================\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Added a BPF programmable net device with L2/L3 mode and BPF link support via bpf_mprog.,"BPF programmable, net device, bpf_mprog",It's a new feature.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['xdp like programs', 'tracepoints like programs']"
ace15f91e569172dac71ae0aeb3a2e76d1ce1b17,ace15f91e569172dac71ae0aeb3a2e76d1ce1b17,Daniel Borkmann,daniel@iogearbox.net,1698184144,Martin KaFai Lau,martin.lau@kernel.org,1698188863,33ca776f10feda7e38956dc26edf74fd1bbc88da,51f1892b5289f0c09745d3bedb36493555d6d90c,"selftests/bpf: Add selftests for netkit

Add a bigger batch of test coverage to assert correct operation of
netkit devices and their BPF program management:

  # ./test_progs -t tc_netkit
  [...]
  [    1.166267] bpf_testmod: loading out-of-tree module taints kernel.
  [    1.166831] bpf_testmod: module verification failed: signature and/or required key missing - tainting kernel
  [    1.270957] tsc: Refined TSC clocksource calibration: 3407.988 MHz
  [    1.272579] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x311fc932722"," max_idle_ns: 440795381586 ns
  [    1.275336] clocksource: Switched to clocksource tsc
  #257     tc_netkit_basic:OK
  #258     tc_netkit_device:OK
  #259     tc_netkit_multi_links:OK
  #260     tc_netkit_multi_opts:OK
  #261     tc_netkit_neigh_links:OK
  Summary: 5/0 PASSED","[' 0 SKIPPED', ' 0 FAILED\n  [...]\n\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Martin KaFai Lau <martin.lau@kernel.org>\nLink: https://lore.kernel.org/r/20231024214904.29825-8-daniel@iogearbox.net\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Add selftests to ensure netkit devices and BPF program management function correctly.,"selftests, netkit, tc_netkit",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['tc/netfilter like programs']
51f1892b5289f0c09745d3bedb36493555d6d90c,51f1892b5289f0c09745d3bedb36493555d6d90c,Daniel Borkmann,daniel@iogearbox.net,1698184143,Martin KaFai Lau,martin.lau@kernel.org,1698188859,57d2cc0251bbd51cbfbbeb1a234bcf34eb9c951e,bec981a4add6dd6a63065e54e2b2e67c2af6c3fa,"selftests/bpf: Add netlink helper library

Add a minimal netlink helper library for the BPF selftests. This has been
taken and cut down and cleaned up from iproute2. This covers basics such
as netdevice creation which we need for BPF selftests / BPF CI given
iproute2 package cannot cover it yet.

Stanislav Fomichev suggested that this could be replaced in future by ynl
tool generated C code once it has RTNL support to create devices. Once we
get to this point the BPF CI would also need to add libmnl. If no further
extensions are needed"," a second option could be that we remove this code
again once iproute2 package has support.

Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Martin KaFai Lau <martin.lau@kernel.org>
Link: https://lore.kernel.org/r/20231024214904.29825-7-daniel@iogearbox.net
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],"This commit adds a minimal netlink helper library for BPF selftests, derived from iproute2, to support BPF CI.","netlink, helper library, selftests",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
bec981a4add6dd6a63065e54e2b2e67c2af6c3fa,bec981a4add6dd6a63065e54e2b2e67c2af6c3fa,Daniel Borkmann,daniel@iogearbox.net,1698184142,Martin KaFai Lau,martin.lau@kernel.org,1698188852,acd73a5086c3e112b9673d2ec175ee8a8441c6e5,92a85e18ad4705c66ace55a19f4f8301ef0eb59f,"bpftool: Extend net dump with netkit progs

Add support to dump BPF programs on netkit via bpftool. This includes both
the BPF link and attach ops programs. Dumped information contain the attach
location", function entry name,"[' program ID and link ID when applicable.\n\nExample with tc BPF link:\n\n  # ./bpftool net\n  xdp:\n\n  tc:\n  nk1(22) netkit/peer tc1 prog_id 43 link_id 12\n\n  [...]\n\nExample with json dump:\n\n  # ./bpftool net --json | jq\n  [\n    {\n      ""xdp"": []', '\n      ""tc"": [\n        {\n          ""devname"": ""nk1""', '\n          ""ifindex"": 18', '\n          ""kind"": ""netkit/primary""', '\n          ""name"": ""tc1""', '\n          ""prog_id"": 29', '\n          ""prog_flags"": []', '\n          ""link_id"": 8', '\n          ""link_flags"": []\n        }\n      ]', '\n      ""flow_dissector"": []', '\n      ""netfilter"": []\n    }\n  ]\n\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Quentin Monnet <quentin@isovalent.com>\nAcked-by: Martin KaFai Lau <martin.lau@kernel.org>\nLink: https://lore.kernel.org/r/20231024214904.29825-6-daniel@iogearbox.net\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']","Extend bpftool to support dumping BPF programs on netkit, including link and attach ops programs.","bpftool, netkit, dump",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The bpftool utility,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
92a85e18ad4705c66ace55a19f4f8301ef0eb59f,92a85e18ad4705c66ace55a19f4f8301ef0eb59f,Daniel Borkmann,daniel@iogearbox.net,1698184141,Martin KaFai Lau,martin.lau@kernel.org,1698188844,6e30487e1da0904bf48de205ec3658e94be426ac,05c31b4ab20527c4d1695130aaecc54ef59a0e54,"bpftool: Implement link show support for netkit

Add support to dump netkit link information to bpftool in similar way as
we have for XDP. The netkit link info only exposes the ifindex and the
attach_type.

Below shows an example link dump output"," and a cgroup link is included for
comparison","[' too:\n\n  # bpftool link\n  [...]\n  10: cgroup  prog 2466\n        cgroup_id 1  attach_type cgroup_inet6_post_bind\n  [...]\n  8: netkit  prog 35\n        ifindex nk1(18)  attach_type netkit_primary\n  [...]\n\nEquivalent json output:\n\n  # bpftool link --json\n  [...]\n  {\n    ""id"": 10', '\n    ""type"": ""cgroup""', '\n    ""prog_id"": 2466', '\n    ""cgroup_id"": 1', '\n    ""attach_type"": ""cgroup_inet6_post_bind""\n  }', '\n  [...]\n  {\n    ""id"": 12', '\n    ""type"": ""netkit""', '\n    ""prog_id"": 61', '\n    ""devname"": ""nk1""', '\n    ""ifindex"": 21', '\n    ""attach_type"": ""netkit_primary""\n  }\n  [...]\n\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Quentin Monnet <quentin@isovalent.com>\nAcked-by: Martin KaFai Lau <martin.lau@kernel.org>\nLink: https://lore.kernel.org/r/20231024214904.29825-5-daniel@iogearbox.net\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",Implement support for displaying netkit link information in bpftool.,"bpftool, netkit, link",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The bpftool utility,"['tracepoints like programs', 'cgroup like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
05c31b4ab20527c4d1695130aaecc54ef59a0e54,05c31b4ab20527c4d1695130aaecc54ef59a0e54,Daniel Borkmann,daniel@iogearbox.net,1698184140,Martin KaFai Lau,martin.lau@kernel.org,1698188818,9a4322a3c4028b65257b7798a5409b8e8bbecfde,5c1b994de4be8a27afa3281be2ff58b38e8bc50c,"libbpf: Add link-based API for netkit

This adds bpf_program__attach_netkit() API to libbpf. Overall it is very
similar to tcx. The API looks as following:

  LIBBPF_API struct bpf_link *
  bpf_program__attach_netkit(const struct bpf_program *prog", int ifindex,"['\n                             const struct bpf_netkit_opts *opts);\n\nThe struct bpf_netkit_opts is done in similar way as struct bpf_tcx_opts\nfor supporting bpf_mprog control parameters. The attach location for the\nprimary and peer device is derived from the program section ""netkit/primary""\nand ""netkit/peer""', ' respectively.\n\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Martin KaFai Lau <martin.lau@kernel.org>\nLink: https://lore.kernel.org/r/20231024214904.29825-4-daniel@iogearbox.net\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']","This commit introduces a new link-based API, bpf_program__attach_netkit, to libbpf for attaching eBPF programs.","libbpf, link-based API, netkit",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
35dfaad7188cdc043fde31709c796f5a692ba2bd,35dfaad7188cdc043fde31709c796f5a692ba2bd,Daniel Borkmann,daniel@iogearbox.net,1698184138,Martin KaFai Lau,martin.lau@kernel.org,1698188763,53a88f1799ac38892434318a47278de4a255bc19,42d31dd601fa43b9afdf069d1ba410b2306a4c76,netkit," bpf: Add bpf programmable net device

This work adds a new","[' minimal BPF-programmable device called ""netkit""\n(former PoC code-name ""meta"") we recently presented at LSF/MM/BPF. The\ncore idea is that BPF programs are executed within the drivers xmit routine\nand therefore e.g. in case of containers/Pods moving BPF processing closer\nto the source.\n\nOne of the goals was that in case of Pod egress traffic', ' this allows to\nmove BPF programs from hostns tcx ingress into the device itself', ' providing\nearlier drop or forward mechanisms', ' for example', ' if the BPF program\ndetermines that the skb must be sent out of the node', ' then a redirect to\nthe physical device can take place directly without going through per-CPU\nbacklog queue. This helps to shift processing for such traffic from softirq\nto process context', ' leading to better scheduling decisions/performance (see\nmeasurements in the slides).\n\nIn this initial version', ' the netkit device ships as a pair', ' but we plan to\nextend this further so it can also operate in single device mode. The pair\ncomes with a primary and a peer device. Only the primary device', ' typically\nresiding in hostns', ' can manage BPF programs for itself and its peer. The\npeer device is designated for containers/Pods and cannot attach/detach\nBPF programs. Upon the device creation', "" the user can set the default policy\nto 'pass' or 'drop' for the case when no BPF program is attached.\n\nAdditionally"", ' the device can be operated in L3 (default) or L2 mode. The\nmanagement of BPF programs is done via bpf_mprog', ' so that multi-attach is\nsupported right from the beginning with similar API and dependency controls\nas tcx. For details on the latter see commit 053c8e1f235d (""bpf: Add generic\nattach/detach/query API for multi-progs""). tc BPF compatibility is provided', '\nso that existing programs can be easily migrated.\n\nGoing forward', "" we plan to use netkit devices in Cilium as the main device\ntype for connecting Pods. They will be operated in L3 mode in order to\nsimplify a Pod's neighbor management and the peer will operate in default\ndrop mode"", ' so that no traffic is leaving between the time when a Pod is\nbrought up by the CNI plugin and programs attached by the agent.\nAdditionally', ' the programs we attach via tcx on the physical devices are\nusing bpf_redirect_peer() for inbound traffic into netkit device', ' hence the\nlatter is also supporting the ndo_get_peer_dev callback. Similarly', ' we use\nbpf_redirect_neigh() for the way out', ' pushing from netkit peer to phys device\ndirectly. Also', ' BIG TCP is supported on netkit device. For the follow-up\nwork in single device mode', "" we plan to convert Cilium's cilium_host/_net\ndevices into a single one.\n\nAn extensive test suite for checking device operations and the BPF program\nand link management API comes as BPF selftests in this series.\n\nCo-developed-by: Nikolay Aleksandrov <razor@blackwall.org>\nSigned-off-by: Nikolay Aleksandrov <razor@blackwall.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Toke Høiland-Jørgensen <toke@redhat.com>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nAcked-by: Martin KaFai Lau <martin.lau@kernel.org>\nLink: https://github.com/borkmann/iproute2/tree/pr/netkit\nLink: http://vger.kernel.org/bpfconf2023_material/tcx_meta_netdev_borkmann.pdf (24ff.)\nLink: https://lore.kernel.org/r/20231024214904.29825-2-daniel@iogearbox.net\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n"", '']",Add a BPF programmable network device in the Linux kernel.,"BPF, network, device",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['socket like programs', 'tc/netfilter like programs', 'other']"
42d31dd601fa43b9afdf069d1ba410b2306a4c76,42d31dd601fa43b9afdf069d1ba410b2306a4c76,Andrii Nakryiko,andrii@kernel.org,1698008257,Daniel Borkmann,daniel@iogearbox.net,1698151551,e018bf2cea6bc60112aef36047781ccb59c31f1f,06646da01458682023321bdc7553b8140e95d077,"bpf: Improve JEQ/JNE branch taken logic

When determining if an if/else branch will always or never be taken"," use
signed range knowledge in addition to currently used unsigned range knowledge.
If either signed or unsigned range suggests that condition is always/never
taken","[' return corresponding branch_taken verdict.\n\nCurrent use of unsigned range for this seems arbitrary and unnecessarily\nincomplete. It is possible for *signed* operations to be performed on\nregister', ' which could ""invalidate"" unsigned range for that register. In such\ncase branch_taken will be artificially useless', ' even if we can still tell\nthat some constant is outside of register value range based on its signed\nbounds.\n\nveristat-based validation shows zero differences across selftests', ' Cilium', '\nand Meta-internal BPF object files.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Shung-Hsi Yu <shung-hsi.yu@suse.com>\nLink: https://lore.kernel.org/bpf/20231022205743.72352-2-andrii@kernel.org\n', '']",The commit improves the logic for determining JEQ/JNE branch conditions using both signed and unsigned range knowledge.,"JEQ,JNE,branch",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
06646da01458682023321bdc7553b8140e95d077,06646da01458682023321bdc7553b8140e95d077,Paul E. McKenney,paulmck@kernel.org,1697668112,Daniel Borkmann,daniel@iogearbox.net,1698150367,31454fa3d9494e804d54f3a6fc986be93ebca2dc,d35381aa73f7e1e8b25f3ed5283287a64d9ddff5,"bpf: Fold smp_mb__before_atomic() into atomic_set_release()

The bpf_user_ringbuf_drain() BPF_CALL function uses an atomic_set()
immediately preceded by smp_mb__before_atomic() so as to order storing
of ring-buffer consumer and producer positions prior to the atomic_set()
call's clearing of the ->busy flag"," as follows:

        smp_mb__before_atomic();
        atomic_set(&rb->busy","[' 0);\n\nAlthough this works given current architectures and implementations', ' and\ngiven that this only needs to order prior writes against a later write.\nHowever', ' it does so by accident because the smp_mb__before_atomic()\nis only guaranteed to work with read-modify-write atomic operations', ' and\nnot at all with things like atomic_set() and atomic_read().\n\nNote especially that smp_mb__before_atomic() will not', ' repeat *not*', '\norder the prior write to ""a"" before the subsequent non-read-modify-write\natomic read from ""b""', ' even on strongly ordered systems such as x86:\n\n        WRITE_ONCE(a', ' 1);\n        smp_mb__before_atomic();\n        r1 = atomic_read(&b);\n\nTherefore', ' replace the smp_mb__before_atomic() and atomic_set() with\natomic_set_release() as follows:\n\n        atomic_set_release(&rb->busy', ' 0);\n\nThis is no slower (and sometimes is faster) than the original', ' and also\nprovides a formal guarantee of ordering that the original lacks.\n\nSigned-off-by: Paul E. McKenney <paulmck@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: David Vernet <void@manifault.com>\nLink: https://lore.kernel.org/bpf/ec86d38e-cfb4-44aa-8fdb-6c925922d93c@paulmck-laptop\n', '']",The commit folds smp_mb__before_atomic() into atomic_set_release() in bpf_user_ringbuf_drain() for ring-buffer ordering.,"smp_mb_before_atomic,atomic_set_release,ring-buffer",It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d35381aa73f7e1e8b25f3ed5283287a64d9ddff5,d35381aa73f7e1e8b25f3ed5283287a64d9ddff5,Song Liu,song@kernel.org,1697090261,Daniel Borkmann,daniel@iogearbox.net,1698150355,2e3c4cd03ad2acc9f2c5b5b47b2383c69d9ec037,99b29a499b5fdfb7ab274835b8e4d4c11df2f6d7,"bpf: Fix unnecessary -EBUSY from htab_lock_bucket

htab_lock_bucket uses the following logic to avoid recursion:

1. preempt_disable();
2. check percpu counter htab->map_locked[hash] for recursion;
   2.1. if map_lock[hash] is already taken"," return -BUSY;
3. raw_spin_lock_irqsave();

However","[' if an IRQ hits between 2 and 3', ' BPF programs attached to the IRQ\nlogic will not able to access the same hash of the hashtab and get -EBUSY.\n\nThis -EBUSY is not really necessary. Fix it by disabling IRQ before\nchecking map_locked:\n\n1. preempt_disable();\n2. local_irq_save();\n3. check percpu counter htab->map_locked[hash] for recursion;\n   3.1. if map_lock[hash] is already taken', ' return -BUSY;\n4. raw_spin_lock().\n\nSimilarly', ' use raw_spin_unlock() and local_irq_restore() in\nhtab_unlock_bucket().\n\nFixes: 20b6cc34ea74 (""bpf: Avoid hashtab deadlock with map_locked"")\nSuggested-by: Tejun Heo <tj@kernel.org>\nSigned-off-by: Song Liu <song@kernel.org>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/7a9576222aa40b1c84ad3a9ba3e64011d1a04d41.camel@linux.ibm.com\nLink: https://lore.kernel.org/bpf/20231012055741.3375999-1-song@kernel.org\n', '']",Fixes erroneous -EBUSY error from htab_lock_bucket in eBPF maps.,"fix, htab_lock_bucket, eBPF",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
99b29a499b5fdfb7ab274835b8e4d4c11df2f6d7,99b29a499b5fdfb7ab274835b8e4d4c11df2f6d7,Albert Huang,huangjie.albert@bytedance.com,1698065851,Daniel Borkmann,daniel@iogearbox.net,1698141336,1d4aa58f8b314eabe16eb93feaa6a1fe4cbbdb8e,dedd6c894110371d3c218cf24ecca2f0730408ac,"xsk: Avoid starving the xsk further down the list

In the previous implementation"," when multiple xsk sockets were
associated with a single xsk_buff_pool","[' a situation could arise\nwhere the xsk_tx_list maintained data at the front for one xsk\nsocket while starving the xsk sockets at the back of the list.\nThis could result in issues such as the inability to transmit packets', '\nincreased latency', ' and jitter. To address this problem', ' we introduce\na new variable called tx_budget_spent', ' which limits each xsk to transmit\na maximum of MAX_PER_SOCKET_BUDGET tx descriptors. This allocation ensures\nequitable opportunities for subsequent xsk sockets to send tx descriptors.\nThe value of MAX_PER_SOCKET_BUDGET is set to 32.\n\nSigned-off-by: Albert Huang <huangjie.albert@bytedance.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Magnus Karlsson <magnus.karlsson@intel.com>\nLink: https://lore.kernel.org/bpf/20231023125732.82261-1-huangjie.albert@bytedance.com\n', '']",Optimize XSK socket handling to prevent resource starvation in shared buffer pools.,"xsk,starvation,buffer",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['socket like programs']
dedd6c894110371d3c218cf24ecca2f0730408ac,dedd6c894110371d3c218cf24ecca2f0730408ac,Alexei Starovoitov,ast@kernel.org,1698122972,Alexei Starovoitov,ast@kernel.org,1698122972,3dc1fcf7ed24072d47e2cab602fda5476f7171b7,b63dadd6f97522513fe9497b5fde84a154e39a0b b4d8239534fddc036abe4a0fdbf474d9894d4641,"Merge branch 'exact-states-comparison-for-iterator-convergence-checks'

Eduard Zingerman says:

====================
exact states comparison for iterator convergence checks

Iterator convergence logic in is_state_visited() uses state_equals()
for states with branches counter > 0 to check if iterator based loop
converges. This is not fully correct because state_equals() relies on
presence of read and precision marks on registers. These marks are not
guaranteed to be finalized while state has branches.
Commit message for patch #3 describes a program that exhibits such
behavior.

This patch-set aims to fix iterator convergence logic by adding notion
of exact states comparison. Exact comparison does not rely on presence
of read or precision marks and thus is more strict.
As explained in commit message for patch #3 exact comparisons require
addition of speculative register bounds widening. The end result for
BPF verifier users could be summarized as follows:

(!) After this update verifier would reject programs that conjure an
    imprecise value on the first loop iteration and use it as precise
    on the second (for iterator based loops).

I urge people to at least skim over the commit message for patch #3.

Patches are organized as follows:
- patches #1","2: moving/extracting utility functions;
- patch #3: introduces exact mode for states comparison and adds
  widening heuristic;
- patch #4: adds test-cases that demonstrate why the series is
  necessary;
- patch #5: extends patch #3 with a notion of state loop entries","['\n  these entries have to be tracked to correctly identify that\n  different verifier states belong to the same states loop;\n- patch #6: adds a test-case that demonstrates a program\n  which requires loop entry tracking for correct verification;\n- patch #7: just adds a few debug prints.\n\nThe following actions are planned as a followup for this patch-set:\n- implementation has to be adapted for callbacks handling logic as a\n  part of a fix for [1];\n- it is necessary to explore ways to improve widening heuristic to\n  handle iters_task_vma test w/o need to insert barrier_var() calls;\n- explored states eviction logic on cache miss has to be extended\n  to either:\n  - allow eviction of checkpoint states -or-\n  - be sped up in case if there are many active checkpoints associated\n    with the same instruction.\n\nThe patch-set is a followup for mailing list discussion [1].\n\nChangelog:\n- V2 [3] -> V3:\n  - correct check for stack spills in widen_imprecise_scalars()', '\n    added test case progs/iters.c:widen_spill to check the behavior\n    (suggested by Andrii);\n  - allow eviction of checkpoint states in is_state_visited() to avoid\n    pathological verifier performance when iterator based loop does not\n    converge (discussion with Alexei).\n- V1 [2] -> V2', ' applied changes suggested by Alexei offlist:\n  - __explored_state() function removed;\n  - same_callsites() function is now used in clean_live_states();\n  - patches #1', '2 are added as preparatory code movement;\n  - in process_iter_next_call() a safeguard is added to verify that\n    cur_st->parent exists and has expected insn index / call sites.\n\n[1] https://lore.kernel.org/bpf/97a90da09404c65c8e810cf83c94ac703705dc0e.camel@gmail.com/\n[2] https://lore.kernel.org/bpf/20231021005939.1041-1-eddyz87@gmail.com/\n[3] https://lore.kernel.org/bpf/20231022010812.9201-1-eddyz87@gmail.com/\n====================\n\nLink: https://lore.kernel.org/r/20231024000917.12153-1-eddyz87@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit enhances iterator convergence checks in the BPF verifier by implementing exact states comparison.,"iterator, convergence, verifier",It's a bug fix.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b4d8239534fddc036abe4a0fdbf474d9894d4641,b4d8239534fddc036abe4a0fdbf474d9894d4641,Eduard Zingerman,eddyz87@gmail.com,1698106157,Alexei Starovoitov,ast@kernel.org,1698122972,3dc1fcf7ed24072d47e2cab602fda5476f7171b7,64870feebecb7130291a55caf0ce839a87405a70,"bpf: print full verifier states on infinite loop detection

Additional logging in is_state_visited(): if infinite loop is detected
print full verifier state for both current and equivalent states.

Acked-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20231024000917.12153-8-eddyz87@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Add logging to print full verifier states when an infinite loop is detected in eBPF programs.,"verifier,logging,infinite loop",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
64870feebecb7130291a55caf0ce839a87405a70,64870feebecb7130291a55caf0ce839a87405a70,Eduard Zingerman,eddyz87@gmail.com,1698106156,Alexei Starovoitov,ast@kernel.org,1698122972,ccce1bb46ed7a2690431d43bdf0563d00c4e6249,2a0992829ea3864939d917a5c7b48be6629c6217,"selftests/bpf: test if state loops are detected in a tricky case

A convoluted test case for iterators convergence logic that
demonstrates that states with branch count equal to 0 might still be
a part of not completely explored loop.

E.g. consider the following state diagram:

               initial     Here state 'succ' was processed first","
                 |         it was eventually tracked to produce a
                 V         state identical to 'hdr'.
    .---------> hdr        All branches from 'succ' had been explored
    |            |         and thus 'succ' has its .branches == 0.
    |            V
    |    .------...        Suppose states 'cur' and 'succ' correspond
    |    |       |         to the same instruction + callsites.
    |    V       V         In such case it is necessary to check
    |   ...     ...        whether 'succ' and 'cur' are identical.
    |    |       |         If 'succ' and 'cur' are a part of the same loop
    |    V       V         they have to be compared exactly.
    |   succ <- cur
    |    |
    |    V
    |   ...
    |    |
    '----'

Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20231024000917.12153-7-eddyz87@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The commit adds a test to ensure state loops are detected in complex cases within eBPF selftests.,"state loops,test case,iterators",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2a0992829ea3864939d917a5c7b48be6629c6217,2a0992829ea3864939d917a5c7b48be6629c6217,Eduard Zingerman,eddyz87@gmail.com,1698106155,Alexei Starovoitov,ast@kernel.org,1698122972,98866f206e4d928574a096f12956cce039718a25,389ede06c2974b2f878a7ebff6b0f4f707f9db74,"bpf: correct loop detection for iterators convergence

It turns out that .branches > 0 in is_state_visited() is not a
sufficient condition to identify if two verifier states form a loop
when iterators convergence is computed. This commit adds logic to
distinguish situations like below:

 (I)            initial       (II)            initial
                  |                             |
                  V                             V
     .---------> hdr                           ..
     |            |                             |
     |            V                             V
     |    .------...                    .------..
     |    |       |                     |       |
     |    V       V                     V       V
     |   ...     ...               .-> hdr     ..
     |    |       |                |    |       |
     |    V       V                |    V       V
     |   succ <- cur               |   succ <- cur
     |    |                        |    |
     |    V                        |    V
     |   ...                       |   ...
     |    |                        |    |
     '----'                        '----'

For both (I) and (II) successor 'succ' of the current state 'cur' was
previously explored and has branches count at 0. However"," loop entry
'hdr' corresponding to 'succ' might be a part of current DFS path.
If that is the case 'succ' and 'cur' are members of the same loop
and have to be compared exactly.

Co-developed-by: Andrii Nakryiko <andrii.nakryiko@gmail.com>
Co-developed-by: Alexei Starovoitov <alexei.starovoitov@gmail.com>
Reviewed-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20231024000917.12153-6-eddyz87@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Correct loop detection logic for iterators convergence in the eBPF verifier.,"loop detection, iterators, verifier",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
389ede06c2974b2f878a7ebff6b0f4f707f9db74,389ede06c2974b2f878a7ebff6b0f4f707f9db74,Eduard Zingerman,eddyz87@gmail.com,1698106154,Alexei Starovoitov,ast@kernel.org,1698122971,4c5c43fff63b6efb7702fae5cd86aba8a1034cfa,2793a8b015f7f1caadb9bce9c63dc659f7522676,"selftests/bpf: tests with delayed read/precision makrs in loop body

These test cases try to hide read and precision marks from loop
convergence logic: marks would only be assigned on subsequent loop
iterations or after exploring states pushed to env->head stack first.
Without verifier fix to use exact states comparison logic for
iterators convergence these tests (except 'triple_continue') would be
errorneously marked as safe.

Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20231024000917.12153-5-eddyz87@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Introduce selftests for BPF validating delayed read and precision marks in loop convergence logic.,"selftests,loop,verifier",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
2793a8b015f7f1caadb9bce9c63dc659f7522676,2793a8b015f7f1caadb9bce9c63dc659f7522676,Eduard Zingerman,eddyz87@gmail.com,1698106153,Alexei Starovoitov,ast@kernel.org,1698122971,2ea57178a4460bd2260f768da748d77bf5fa6150,4c97259abc9bc8df7712f76f58ce385581876857,"bpf: exact states comparison for iterator convergence checks

Convergence for open coded iterators is computed in is_state_visited()
by examining states with branches count > 1 and using states_equal().
states_equal() computes sub-state relation using read and precision marks.
Read and precision marks are propagated from children states","
thus are not guaranteed to be complete inside a loop when branches
count > 1. This could be demonstrated using the following unsafe program:

     1. r7 = -16
     2. r6 = bpf_get_prandom_u32()
     3. while (bpf_iter_num_next(&fp[-8])) {
     4.   if (r6 != 42) {
     5.     r7 = -32
     6.     r6 = bpf_get_prandom_u32()
     7.     continue
     8.   }
     9.   r0 = r10
    10.   r0 += r7
    11.   r8 = *(u64 *)(r0 + 0)
    12.   r6 = bpf_get_prandom_u32()
    13. }

Here verifier would first visit path 1-3","[' create a checkpoint at 3\nwith r7=-16', ' continue to 4-7', '3 with r7=-32.\n\nBecause instructions at 9-12 had not been visitied yet existing\ncheckpoint at 3 does not have read or precision mark for r7.\nThus states_equal() would return true and verifier would discard\ncurrent state', ' thus unsafe memory access at 11 would not be caught.\n\nThis commit fixes this loophole by introducing exact state comparisons\nfor iterator convergence logic:\n- registers are compared using regs_exact() regardless of read or\n  precision marks;\n- stack slots have to have identical type.\n\nUnfortunately', ' this is too strict even for simple programs like below:\n\n    i = 0;\n    while(iter_next(&it))\n      i++;\n\nAt each iteration step i++ would produce a new distinct state and\neventually instruction processing limit would be reached.\n\nTo avoid such behavior speculatively forget (widen) range for\nimprecise scalar registers', ' if those registers were not precise at the\nend of the previous iteration and do not match exactly.\n\nThis a conservative heuristic that allows to verify wide range of\nprograms', ' however it precludes verification of programs that conjure\nan imprecise value on the first loop iteration and use it as precise\non the second.\n\nTest case iter_task_vma_for_each() presents one of such cases:\n\n        unsigned int seen = 0;\n        ...\n        bpf_for_each(task_vma', ' vma', ' task', "" 0) {\n                if (seen >= 1000)\n                        break;\n                ...\n                seen++;\n        }\n\nHere clang generates the following code:\n\n<LBB0_4>:\n      24:       r8 = r6                          ; stash current value of\n                ... body ...                       'seen'\n      29:       r1 = r10\n      30:       r1 += -0x8\n      31:       call bpf_iter_task_vma_next\n      32:       r6 += 0x1                        ; seen++;\n      33:       if r0 == 0x0 goto +0x2 <LBB0_6>  ; exit on next() == NULL\n      34:       r7 += 0x10\n      35:       if r8 < 0x3e7 goto -0xc <LBB0_4> ; loop on seen < 1000\n\n<LBB0_6>:\n      ... exit ...\n\nNote that counter in r6 is copied to r8 and then incremented"", '\nconditional jump is done using r8. Because of this precision mark for\nr6 lags one state behind of precision mark on r8 and widening logic\nkicks in.\n\nAdding barrier_var(seen) after conditional is sufficient to force\nclang use the same register for both counting and conditional jump.\n\nThis issue was discussed in the thread [1] which was started by\nAndrew Werner <awerner32@gmail.com> demonstrating a similar bug\nin callback functions handling. The callbacks would be addressed\nin a followup patch.\n\n[1] https://lore.kernel.org/bpf/97a90da09404c65c8e810cf83c94ac703705dc0e.camel@gmail.com/\n\nCo-developed-by: Andrii Nakryiko <andrii.nakryiko@gmail.com>\nCo-developed-by: Alexei Starovoitov <alexei.starovoitov@gmail.com>\nSigned-off-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/r/20231024000917.12153-4-eddyz87@gmail.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Enhanced state comparison for open coded iterator convergence checks in the BPF verifier.,"exact state comparison, convergence, iterators",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4c97259abc9bc8df7712f76f58ce385581876857,4c97259abc9bc8df7712f76f58ce385581876857,Eduard Zingerman,eddyz87@gmail.com,1698106152,Alexei Starovoitov,ast@kernel.org,1698122971,641861689622e60a92fdf40f3774ba9c5e02b72c,3c4e420cb6536026ddd50eaaff5f30e4f144200d,"bpf: extract same_callsites() as utility function

Extract same_callsites() from clean_live_states() as a utility function.
This function would be used by the next patch in the set.

Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20231024000917.12153-3-eddyz87@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Extracted same_callsites() as a utility function for reuse.,"utility,function,extraction",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3c4e420cb6536026ddd50eaaff5f30e4f144200d,3c4e420cb6536026ddd50eaaff5f30e4f144200d,Eduard Zingerman,eddyz87@gmail.com,1698106151,Alexei Starovoitov,ast@kernel.org,1698122971,d2bd537839a20ad819db7be96be34f0e3cee9ae9,b63dadd6f97522513fe9497b5fde84a154e39a0b,"bpf: move explored_state() closer to the beginning of verifier.c

Subsequent patches would make use of explored_state() function.
Move it up to avoid adding unnecessary prototype.

Signed-off-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/r/20231024000917.12153-2-eddyz87@gmail.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,The explored_state() function is moved to the beginning of verifier.c for upcoming patches.,"explored_state, verifier, function",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
efb3e0e1649f944c032095e3f0533a235a7477d3,efb3e0e1649f944c032095e3f0533a235a7477d3,Jakub Kicinski,kuba@kernel.org,1698113691,Jakub Kicinski,kuba@kernel.org,1698113691,d80ad1aec6a538e50e841ec15360276fed7e6ed6,f4dbc2bb7a54d3bff234a9f1915f1b7187bedb1f 2d0de67da51a90c6acf7bf08d7b0501f45408002,"Merge branch 'introduce-page_pool_alloc-related-api'

Yunsheng Lin says:

====================
introduce page_pool_alloc() related API

In [1] & [2] & [3]"," there are usecases for veth and virtio_net
to use frag support in page pool to reduce memory usage","[' and it\nmay request different frag size depending on the head/tail\nroom space for xdp_frame/shinfo and mtu/packet size. When the\nrequested frag size is large enough that a single page can not\nbe split into more than one frag', "" using frag support only have\nperformance penalty because of the extra frag count handling\nfor frag support.\n\nSo this patchset provides a page pool API for the driver to\nallocate memory with least memory utilization and performance\npenalty when it doesn't know the size of memory it need\nbeforehand.\n\n1. https://patchwork.kernel.org/project/netdevbpf/patch/d3ae6bd3537fbce379382ac6a42f67e22f27ece2.1683896626.git.lorenzo@kernel.org/\n2. https://patchwork.kernel.org/project/netdevbpf/patch/20230526054621.18371-3-liangchen.linux@gmail.com/\n3. https://github.com/alobakin/linux/tree/iavf-pp-frag\n====================\n\nLink: https://lore.kernel.org/r/20231020095952.11055-1-linyunsheng@huawei.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n"", '']","Introduce page_pool_alloc related API to support fragmentation in page pool, optimizing memory usage.","page_pool_alloc, API, memory",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b63dadd6f97522513fe9497b5fde84a154e39a0b,b63dadd6f97522513fe9497b5fde84a154e39a0b,Daniel Borkmann,daniel@iogearbox.net,1698087015,Martin KaFai Lau,martin.lau@kernel.org,1698098513,d8d7dd10c79c522b20ce21d29aa06115424cc4f3,69a19170303ff2f802049be94cfcf62f714002a3,bpf," tcx: Get rid of tcx_link_const

Small clean up to get rid of the extra tcx_link_const() and only retain
the tcx_link().

Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/r/20231023185015.21152-1-daniel@iogearbox.net
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Remove redundant tcx_link_const() to simplify code by retaining only tcx_link() usage.,"cleanup, tcx_link, simplification",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['tc/netfilter like programs']
69a19170303ff2f802049be94cfcf62f714002a3,69a19170303ff2f802049be94cfcf62f714002a3,Denys Zagorui,dzagorui@cisco.com,1697715321,Andrii Nakryiko,andrii@kernel.org,1698080295,3ba34c839669e39d7c8b9efd24f809e2e75e6f58,cf559a416f9bc061f3b96f8afc6ceae5eec9b2b0,"samples: bpf: Fix syscall_tp openat argument

This modification doesn't change behaviour of the syscall_tp
But such code is often used as a reference so it should be
correct anyway

Signed-off-by: Denys Zagorui <dzagorui@cisco.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20231019113521.4103825-1-dzagorui@cisco.com
",,Corrected the syscall_tp openat argument in BPF samples for improved reference accuracy.,"syscall_tp, openat, BPF",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tracepoints like programs']
90d862f370b6e9de1b5d607843c5a2f9823990f3,90d862f370b6e9de1b5d607843c5a2f9823990f3,Hari Bathini,hbathini@linux.ibm.com,1697811238,Michael Ellerman,mpe@ellerman.id.au,1698053599,08937d5801a92b65d281a4ffa62d3c37c3fa427c,de04e40600ae15fa5e484be242e74aad6de7418f,"powerpc/bpf: use bpf_jit_binary_pack_[alloc|finalize|free]

Use bpf_jit_binary_pack_alloc in powerpc jit. The jit engine first
writes the program to the rw buffer. When the jit is done"," the program
is copied to the final location with bpf_jit_binary_pack_finalize.
With multiple jit_subprogs","[' bpf_jit_free is called on some subprograms\nthat haven\'t got bpf_jit_binary_pack_finalize() yet. Implement custom\nbpf_jit_free() like in commit 1d5f82d9dd47 (""bpf', ' x86: fix freeing of\nnot-finalized bpf_prog_pack"") to call bpf_jit_binary_pack_finalize()', '\nif necessary. As bpf_flush_icache() is not needed anymore', ' remove it.\n\nSigned-off-by: Hari Bathini <hbathini@linux.ibm.com>\nAcked-by: Song Liu <song@kernel.org>\nSigned-off-by: Michael Ellerman <mpe@ellerman.id.au>\nLink: https://msgid.link/20231020141358.643575-6-hbathini@linux.ibm.com\n\n', '']",Enable bpf_jit_binary_pack_usage in PowerPC JIT engine for enhanced program execution.,"PowerPC,JIT,bpf_jit_binary_pack",It's a performance optimization.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
de04e40600ae15fa5e484be242e74aad6de7418f,de04e40600ae15fa5e484be242e74aad6de7418f,Hari Bathini,hbathini@linux.ibm.com,1697811237,Michael Ellerman,mpe@ellerman.id.au,1698053599,fb9e4c5ec6d84398f5f2b691d580686b51b58709,033ffaf0af1f974ecf401db3f70aae6fe1a90fc5,"powerpc/bpf: rename powerpc64_jit_data to powerpc_jit_data

powerpc64_jit_data is a misnomer as it is meant for both ppc32 and
ppc64. Rename it to powerpc_jit_data.

Signed-off-by: Hari Bathini <hbathini@linux.ibm.com>
Acked-by: Song Liu <song@kernel.org>
Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
Link: https://msgid.link/20231020141358.643575-5-hbathini@linux.ibm.com

",,The commit renames powerpc64_jit_data to powerpc_jit_data for consistency across ppc32 and ppc64.,"renaming, powerpc, jit",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The JIT compiler,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
033ffaf0af1f974ecf401db3f70aae6fe1a90fc5,033ffaf0af1f974ecf401db3f70aae6fe1a90fc5,Hari Bathini,hbathini@linux.ibm.com,1697811236,Michael Ellerman,mpe@ellerman.id.au,1698053599,38d47ece63167b26626246fb3531ab1ccc4247fe,6efc1675acb88eef45ef0156b93f95d66a8ee759,"powerpc/bpf: implement bpf_arch_text_invalidate for bpf_prog_pack

Implement bpf_arch_text_invalidate and use it to fill unused part of
the bpf_prog_pack with trap instructions when a BPF program is freed.

Signed-off-by: Hari Bathini <hbathini@linux.ibm.com>
Acked-by: Song Liu <song@kernel.org>
Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
Link: https://msgid.link/20231020141358.643575-4-hbathini@linux.ibm.com

",,Implement bpf_arch_text_invalidate to manage unused areas in bpf_prog_pack for powerpc.,"powerpc,bpf_arch_text_invalidate,bpf_prog_pack",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6efc1675acb88eef45ef0156b93f95d66a8ee759,6efc1675acb88eef45ef0156b93f95d66a8ee759,Hari Bathini,hbathini@linux.ibm.com,1697811235,Michael Ellerman,mpe@ellerman.id.au,1698053599,9e43c538e8fc92f7ffcf1ae2bcbc96c673310381,465cabc97b42405eb89380ea6ba8d8b03e4ae1a2,"powerpc/bpf: implement bpf_arch_text_copy

bpf_arch_text_copy is used to dump JITed binary to RX page"," allowing
multiple BPF programs to share the same page. Use the newly introduced
patch_instructions() to implement it.

Signed-off-by: Hari Bathini <hbathini@linux.ibm.com>
Acked-by: Song Liu <song@kernel.org>
Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
Link: https://msgid.link/20231020141358.643575-3-hbathini@linux.ibm.com

",[''],Implement bpf_arch_text_copy for dumping JITed binary to RX page in powerpc architecture.,"powerpc,JITed binary,bpf_arch_text_copy",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9c5d00cb7b6bbc5a7965d9ab7d223b5402d1f02c,9c5d00cb7b6bbc5a7965d9ab7d223b5402d1f02c,Linus Torvalds,torvalds@linux-foundation.org,1697838564,Linus Torvalds,torvalds@linux-foundation.org,1697838564,f8b4492cf7127f5af61f3bd97f4f210b393f8d74,444ccf1b11a0dbc54e789d6d2634c2649dc27498 4fa008a2db484024a5cb52676a1b1534dc82330c,"Merge tag 'perf-tools-fixes-for-v6.6-2-2023-10-20' of git://git.kernel.org/pub/scm/linux/kernel/git/perf/perf-tools

Pull perf tools fixes from Arnaldo Carvalho de Melo:

 - Fix regression in reading scale and unit files from sysfs for PMU
   events"," so that we can use that info to pretty print instead of
   printing raw numbers:

     # perf stat -e power/energy-ram/","['power/energy-gpu/ sleep 2\n\n      Performance counter stats for \'system wide\':\n\n                 1.64 Joules power/energy-ram/\n                 0.20 Joules power/energy-gpu/\n\n          2.001228914 seconds time elapsed\n     #\n     # grep -m1 ""model name"" /proc/cpuinfo\n     model name\t: Intel(R) Core(TM) i7-8650U CPU @ 1.90GHz\n     #\n\n - The small llvm.cpp file used to check if the llvm devel files are\n   present was incorrectly deleted when removing the BPF event in \'perf\n   trace\'', ' put it back as it is also used by tools/bpf/bpftool', ' that\n   uses llvm routines to do disassembly of BPF object files.\n\n - Fix use of addr_location__exit() in dlfilter__object_code()', "" making\n   sure that it is only used to pair a previous addr_location__init()\n   call.\n\n* tag 'perf-tools-fixes-for-v6.6-2-2023-10-20' of git://git.kernel.org/pub/scm/linux/kernel/git/perf/perf-tools:\n  tools build: Fix llvm feature detection"", ' still used by bpftool\n  perf dlfilter: Add a test for object_code()\n  perf dlfilter: Fix use of addr_location__exit() in dlfilter__object_code()\n  perf pmu: Fix perf stat output with correct scale and unit\n', '']",Merge perf tool fixes for improved PMU event parsing from sysfs to enhance pretty printing in perf stat outputs.,"perf tools, regression, PMU",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['other']
cf559a416f9bc061f3b96f8afc6ceae5eec9b2b0,cf559a416f9bc061f3b96f8afc6ceae5eec9b2b0,Alexei Starovoitov,ast@kernel.org,1697821975,Alexei Starovoitov,ast@kernel.org,1697836513,e00e8bcbaedd9a6bc3783abe6edcb71b3c2ac382,da1055b673f3baac2249571c9882ce767a0aa746 d440ba91ca4d3004709876779d40713a99e21f6a,"Merge branch 'bpf-fixes-for-per-cpu-kptr'

Hou Tao says:

====================
bpf: Fixes for per-cpu kptr

From: Hou Tao <houtao1@huawei.com>

Hi","

The patchset aims to fix the problems found in the review of per-cpu
kptr patch-set [0]. Patch #1 moves pcpu_lock after the invocation of
pcpu_chunk_addr_search() and it is a micro-optimization for
free_percpu(). The reason includes it in the patch is that the same
logic is used in newly-added API pcpu_alloc_size(). Patch #2 introduces
pcpu_alloc_size() for dynamic per-cpu area. Patch #2 and #3 use
pcpu_alloc_size() to check whether or not unit_size matches with the
size of underlying per-cpu area and to select a matching bpf_mem_cache.
Patch #4 fixes the freeing of per-cpu kptr when these kptrs are freed by
map destruction. The last patch adds test cases for these problems.

Please see individual patches for details. And comments are always
welcome.

Change Log:
v3:
 * rebased on bpf-next
 * patch 2: update API document to note that pcpu_alloc_size() doesn't
            support statically allocated per-cpu area. (Dennis)
 * patch 1 & 2: add Acked-by from Dennis

v2: https://lore.kernel.org/bpf/20231018113343.2446300-1-houtao@huaweicloud.com/
  * add a new patch ""don't acquire pcpu_lock for pcpu_chunk_addr_search()""
  * patch 2: change type of bit_off and end to unsigned long (Andrew)
  * patch 2: rename the new API as pcpu_alloc_size and follow 80-column convention (Dennis)
  * patch 5: move the common declaration into bpf.h (Stanislav","[' Alxei)\n\nv1: https://lore.kernel.org/bpf/20231007135106.3031284-1-houtao@huaweicloud.com/\n\n[0]: https://lore.kernel.org/bpf/20230827152729.1995219-1-yonghong.song@linux.dev\n====================\n\nLink: https://lore.kernel.org/r/20231020133202.4043247-1-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']","This commit addresses fixes for per-cpu kptr handling in eBPF, including a micro-optimization and test cases addition.","per-cpu,kptr,fixed",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
d440ba91ca4d3004709876779d40713a99e21f6a,d440ba91ca4d3004709876779d40713a99e21f6a,Hou Tao,houtao1@huawei.com,1697808722,Alexei Starovoitov,ast@kernel.org,1697836513,e00e8bcbaedd9a6bc3783abe6edcb71b3c2ac382,e383a45902337356d9ccad797094a27c6b2150f9,"selftests/bpf: Add more test cases for bpf memory allocator

Add the following 3 test cases for bpf memory allocator:
1) Do allocation in bpf program and free through map free
2) Do batch per-cpu allocation and per-cpu free in bpf program
3) Do per-cpu allocation in bpf program and free through map free

For per-cpu allocation"," because per-cpu allocation can not refill timely
sometimes","[' so test 2) and test 3) consider it is OK for\nbpf_percpu_obj_new_impl() to return NULL.\n\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20231020133202.4043247-8-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Added test cases for memory allocation and management in bpf programs.,"bpf,test cases,allocator",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e383a45902337356d9ccad797094a27c6b2150f9,e383a45902337356d9ccad797094a27c6b2150f9,Hou Tao,houtao1@huawei.com,1697808721,Alexei Starovoitov,ast@kernel.org,1697836513,4d1e5d7c3b683f1bc68676182c98843fdac5db59,e581a3461de3f129cfe888a67d9f31086328271f,"bpf: Use bpf_global_percpu_ma for per-cpu kptr in __bpf_obj_drop_impl()

The following warning was reported when running ""./test_progs -t
test_bpf_ma/percpu_free_through_map_free"":

  ------------[ cut here ]------------
  WARNING: CPU: 1 PID: 68 at kernel/bpf/memalloc.c:342
  CPU: 1 PID: 68 Comm: kworker/u16:2 Not tainted 6.6.0-rc2+ #222
  Hardware name: QEMU Standard PC (i440FX + PIIX"," 1996)
  Workqueue: events_unbound bpf_map_free_deferred
  RIP: 0010:bpf_mem_refill+0x21c/0x2a0
  ......
  Call Trace:
   <IRQ>
   ? bpf_mem_refill+0x21c/0x2a0
   irq_work_single+0x27/0x70
   irq_work_run_list+0x2a/0x40
   irq_work_run+0x18/0x40
   __sysvec_irq_work+0x1c/0xc0
   sysvec_irq_work+0x73/0x90
   </IRQ>
   <TASK>
   asm_sysvec_irq_work+0x1b/0x20
  RIP: 0010:unit_free+0x50/0x80
   ......
   bpf_mem_free+0x46/0x60
   __bpf_obj_drop_impl+0x40/0x90
   bpf_obj_free_fields+0x17d/0x1a0
   array_map_free+0x6b/0x170
   bpf_map_free_deferred+0x54/0xa0
   process_scheduled_works+0xba/0x370
   worker_thread+0x16d/0x2e0
   kthread+0x105/0x140
   ret_from_fork+0x39/0x60
   ret_from_fork_asm+0x1b/0x30
   </TASK>
  ---[ end trace 0000000000000000 ]---

The reason is simple: __bpf_obj_drop_impl() does not know the freeing
field is a per-cpu pointer and it uses bpf_global_ma to free the
pointer. Because bpf_global_ma is not a per-cpu allocator","["" so ksize() is\nused to select the corresponding cache. The bpf_mem_cache with 16-bytes\nunit_size will always be selected to do the unmatched free and it will\ntrigger the warning in free_bulk() eventually.\n\nBecause per-cpu kptr doesn't support list or rb-tree now"", ' so fix the\nproblem by only checking whether or not the type of kptr is per-cpu in\nbpf_obj_free_fields()', ' and using bpf_global_percpu_ma to these kptrs.\n\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20231020133202.4043247-7-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Fixes per-cpu kptr allocation issue in __bpf_obj_drop_impl related to bpf_global_percpu_ma.,"per-cpu,kptr,bpf_global_percpu_ma",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
e581a3461de3f129cfe888a67d9f31086328271f,e581a3461de3f129cfe888a67d9f31086328271f,Hou Tao,houtao1@huawei.com,1697808720,Alexei Starovoitov,ast@kernel.org,1697836513,469fb6cee50b375b8c58ba71f315bcd20849457c,3f2189e4f77b7a3e979d143dc4ff586488c7e8a5,"bpf: Move the declaration of __bpf_obj_drop_impl() to bpf.h

both syscall.c and helpers.c have the declaration of
__bpf_obj_drop_impl()"," so just move it to a common header file.

Signed-off-by: Hou Tao <houtao1@huawei.com>
Link: https://lore.kernel.org/r/20231020133202.4043247-6-houtao@huaweicloud.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],The declaration of __bpf_obj_drop_impl() is moved to a common header file bpf.h.,"declaration, bpf_obj_drop_impl, header",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3f2189e4f77b7a3e979d143dc4ff586488c7e8a5,3f2189e4f77b7a3e979d143dc4ff586488c7e8a5,Hou Tao,houtao1@huawei.com,1697808719,Alexei Starovoitov,ast@kernel.org,1697836513,d2b472bb05a3c5e94c26e69d30c09dc91139bf00,baa8fdecd87bb8751237b45e3bcb5a179e5a12ca,"bpf: Use pcpu_alloc_size() in bpf_mem_free{_rcu}()

For bpf_global_percpu_ma"," the pointer passed to bpf_mem_free_rcu() is
allocated by kmalloc() and its size is fixed (16-bytes on x86-64). So
no matter which cache allocates the dynamic per-cpu area","[' on x86-64\ncache[2] will always be used to free the per-cpu area.\n\nFix the unbalance by checking whether the bpf memory allocator is\nper-cpu or not and use pcpu_alloc_size() instead of ksize() to\nfind the correct cache for per-cpu free.\n\nSigned-off-by: Hou Tao <houtao1@huawei.com>\nLink: https://lore.kernel.org/r/20231020133202.4043247-5-houtao@huaweicloud.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Optimize memory allocation in bpf_mem_free_rcu using pcpu_alloc_size.,"pcpu_alloc_size, bpf_mem_free_rcu, optimization",It's a performance optimization.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
baa8fdecd87bb8751237b45e3bcb5a179e5a12ca,baa8fdecd87bb8751237b45e3bcb5a179e5a12ca,Hou Tao,houtao1@huawei.com,1697808718,Alexei Starovoitov,ast@kernel.org,1697836513,14af489ff503a3e305ad87c77fbb35a434c24e4a,b460bc8302f222d346f0c15bba980eb8c36d6278,"bpf: Re-enable unit_size checking for global per-cpu allocator

With pcpu_alloc_size() in place"," check whether or not the size of
the dynamic per-cpu area is matched with unit_size.

Signed-off-by: Hou Tao <houtao1@huawei.com>
Link: https://lore.kernel.org/r/20231020133202.4043247-4-houtao@huaweicloud.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Re-enable unit size checking for global per-cpu allocator in eBPF.,"unit size, per-cpu allocator, checking",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF maps,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
b460bc8302f222d346f0c15bba980eb8c36d6278,b460bc8302f222d346f0c15bba980eb8c36d6278,Hou Tao,houtao1@huawei.com,1697808717,Alexei Starovoitov,ast@kernel.org,1697836506,73bd8effe56c8dcae3d9bfd166ff6772d5abb604,394e6869f0185e89cb815db29bf819474df858ae,"mm/percpu.c: introduce pcpu_alloc_size()

Introduce pcpu_alloc_size() to get the size of the dynamic per-cpu
area. It will be used by bpf memory allocator in the following patches.
BPF memory allocator maintains per-cpu area caches for multiple area
sizes and its free API only has the to-be-freed per-cpu pointer"," so it
needs the size of dynamic per-cpu area to select the corresponding cache
when bpf program frees the dynamic per-cpu pointer.

Acked-by: Dennis Zhou <dennis@kernel.org>
Signed-off-by: Hou Tao <houtao1@huawei.com>
Link: https://lore.kernel.org/r/20231020133202.4043247-3-houtao@huaweicloud.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Introduce pcpu_alloc_size() to assist BPF memory allocator in managing per-cpu area caches.,"pcpu_alloc_size,dynamic,per-cpu",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
da1055b673f3baac2249571c9882ce767a0aa746,da1055b673f3baac2249571c9882ce767a0aa746,Kumar Kartikeya Dwivedi,memxor@gmail.com,1697813319,Andrii Nakryiko,andrii@kernel.org,1697819379,090defa9c2720728459a37c332274a8a085fce4b,bab8ac3c5339d7ec5312dcd836cfa8645edb954f,"selftests/bpf: Make linked_list failure test more robust

The linked list failure test 'pop_front_off' and 'pop_back_off'
currently rely on matching exact instruction and register values.  The
purpose of the test is to ensure the offset is correctly incremented for
the returned pointers from list pop helpers"," which can then be used with
container_of to obtain the real object. Hence","[' somehow obtaining the\ninformation that the offset is 48 will work for us. Make the test more\nrobust by relying on verifier error string of bpf_spin_lock and remove\ndependence on fragile instruction index or register number', ' which can be\naffected by different clang versions used to build the selftests.\n\nFixes: 300f19dcdb99 (""selftests/bpf: Add BPF linked list API tests"")\nReported-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Kumar Kartikeya Dwivedi <memxor@gmail.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20231020144839.2734006-1-memxor@gmail.com\n', '']",Improved robustness of linked list failure test in selftests/bpf by ensuring accurate offset increment for list pop helpers.,"linked list,test robustness,selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
5069211e2f0b47e75119805e23ae6352d871e263,5069211e2f0b47e75119805e23ae6352d871e263,Thomas Richter,tmricht@linux.ibm.com,1697704002,Namhyung Kim,namhyung@kernel.org,1697780506,14b6e75d750f70a3ce8558e0e3fca7bd74727f24,1f36b190ad2dea68e3a7e84b7b2f24ce8c4063ea,"perf trace: Use the right bpf_probe_read(_str) variant for reading user data

Perf test case 111 Check open filename arg using perf trace + vfs_getname
fails on s390. This is caused by a failing function
bpf_probe_read() in file util/bpf_skel/augmented_raw_syscalls.bpf.c.

The root cause is the lookup by address. Function bpf_probe_read()
is used. This function works only for architectures
with ARCH_HAS_NON_OVERLAPPING_ADDRESS_SPACE.

On s390 is not possible to determine from the address to which
address space the address belongs to (user or kernel space).

Replace bpf_probe_read() by bpf_probe_read_kernel()
and bpf_probe_read_str() by bpf_probe_read_user_str() to
explicity specify the address space the address refers to.

Output before:
 # ./perf trace -eopen","openat -- touch /tmp/111
 libbpf: prog 'sys_enter': BPF program load failed: Invalid argument
 libbpf: prog 'sys_enter': -- BEGIN PROG LOAD LOG --
 reg type unsupported for arg#0 function sys_enter#75
 0: R1=ctx(off=0","['imm=0) R10=fp0\n ; int sys_enter(struct syscall_enter_args *args)\n 0: (bf) r6 = r1           ; R1=ctx(off=0', 'imm=0) R6_w=ctx(off=0', 'imm=0)\n ; return bpf_get_current_pid_tgid();\n 1: (85) call bpf_get_current_pid_tgid#14      ; R0_w=scalar()\n 2: (63) *(u32 *)(r10 -8) = r0 ; R0_w=scalar() R10=fp0 fp-8=????mmmm\n 3: (bf) r2 = r10              ; R2_w=fp0 R10=fp0\n ;\n .....\n lines deleted here\n .....\n 23: (bf) r3 = r6              ; R3_w=ctx(off=0', 'imm=0) R6=ctx(off=0', ""imm=0)\n 24: (85) call bpf_probe_read#4\n unknown func bpf_probe_read#4\n processed 23 insns (limit 1000000) max_states_per_insn 0 \\\n\t total_states 2 peak_states 2 mark_read 2\n -- END PROG LOAD LOG --\n libbpf: prog 'sys_enter': failed to load: -22\n libbpf: failed to load object 'augmented_raw_syscalls_bpf'\n libbpf: failed to load BPF skeleton 'augmented_raw_syscalls_bpf': -22\n ....\n\nOutput after:\n # ./perf test -Fv 111\n 111: Check open filename arg using perf trace + vfs_getname          :\n --- start ---\n     1.085 ( 0.011 ms): touch/320753 openat(dfd: CWD"", ' filename: \\\n\t""/tmp/temporary_file.SWH85""', ' \\\n\tflags: CREAT|NOCTTY|NONBLOCK|WRONLY', ' mode: IRUGO|IWUGO) = 3\n ---- end ----\n Check open filename arg using perf trace + vfs_getname: Ok\n #\n\nTest with the sleep command shows:\nOutput before:\n # ./perf trace -e *sleep sleep 1.234567890\n     0.000 (1234.681 ms): sleep/63114 clock_nanosleep(rqtp: \\\n         { .tv_sec: 0', ' .tv_nsec: 0 }', ' rmtp: 0x3ffe0979720) = 0\n #\n\nOutput after:\n # ./perf trace -e *sleep sleep 1.234567890\n     0.000 (1234.686 ms): sleep/64277 clock_nanosleep(rqtp: \\\n         { .tv_sec: 1', ' .tv_nsec: 234567890 }', ' rmtp: 0x3fff3df9ea0) = 0\n #\n\nFixes: 14e4b9f4289a (""perf trace: Raw augmented syscalls fix libbpf 1.0+ compatibility"")\nSigned-off-by: Thomas Richter <tmricht@linux.ibm.com>\nCo-developed-by: Arnaldo Carvalho de Melo <acme@redhat.com>\nAcked-by: Ilya Leoshkevich <iii@linux.ibm.com>\nTested-by: Arnaldo Carvalho de Melo <acme@redhat.com>\nCc: Ian Rogers <irogers@google.com>\nCc: gor@linux.ibm.com\nCc: hca@linux.ibm.com\nCc: sumanthk@linux.ibm.com\nCc: svens@linux.ibm.com\nLink: https://lore.kernel.org/r/20231019082642.3286650-1-tmricht@linux.ibm.com\nSigned-off-by: Namhyung Kim <namhyung@kernel.org>\n', '']",Fix bpf_probe_read variant usage for user data reading in perf tool on s390 architecture.,"perf,bpf_probe_read,s390",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,['kprobe/uprobe/ftrace like programs']
4fa008a2db484024a5cb52676a1b1534dc82330c,4fa008a2db484024a5cb52676a1b1534dc82330c,Arnaldo Carvalho de Melo,acme@redhat.com,1697749773,Arnaldo Carvalho de Melo,acme@redhat.com,1697765638,b3928a05c873d290e0aa8e6d0145bcc26a821577,f38f547314b858b94d36aeb9a4401f0aade7d1af,tools build: Fix llvm feature detection," still used by bpftool

When removing the BPF event for perf a feature test that checks if the
llvm devel files are availabe was removed but that is also used by
bpftool.

bpftool uses it to decide what kind of disassembly it will use: llvm or
binutils based.

Removing the tools/build/feature/test-llvm.cpp file made bpftool to
always fallback to binutils disassembly","[' even with the llvm devel files\ninstalled', ' fix it by restoring just that small test-llvm.cpp test file.\n\nFixes: 56b11a2126bf2f42 (""perf bpf: Remove support for embedding clang for compiling BPF events (-e foo.c)"")\nReported-by: Manu Bretelle <chantr4@gmail.com>\nReviewed-by: Ian Rogers <irogers@google.com>\nReviewed-by: Manu Bretelle <chantr4@gmail.com>\nAcked-by: Quentin Monnet <quentin@isovalent.com>\nCc: Adrian Hunter <adrian.hunter@intel.com>\nCc: Alexander Shishkin <alexander.shishkin@linux.intel.com>\nCc: Andi Kleen <ak@linux.intel.com>\nCc: Andrii Nakryiko <andrii@kernel.org>\nCc: Anshuman Khandual <anshuman.khandual@arm.com>\nCc: Carsten Haitzler <carsten.haitzler@arm.com>\nCc: Eduard Zingerman <eddyz87@gmail.com>\nCc: Fangrui Song <maskray@google.com>\nCc: He Kuang <hekuang@huawei.com>\nCc: Ingo Molnar <mingo@redhat.com>\nCc: James Clark <james.clark@arm.com>\nCc: Jiri Olsa <jolsa@kernel.org>\nCc: Kan Liang <kan.liang@linux.intel.com>\nCc: Leo Yan <leo.yan@linaro.org>\nCc: Madhavan Srinivasan <maddy@linux.ibm.com>\nCc: Mark Rutland <mark.rutland@arm.com>\nCc: Namhyung Kim <namhyung@kernel.org>\nCc: Nathan Chancellor <nathan@kernel.org>\nCc: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>\nCc: Nick Desaulniers <ndesaulniers@google.com>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Ravi Bangoria <ravi.bangoria@amd.com>\nCc: Rob Herring <robh@kernel.org>\nCc: Tiezhu Yang <yangtiezhu@loongson.cn>\nCc: Tom Rix <trix@redhat.com>\nCc: Wang Nan <wangnan0@huawei.com>\nCc: Wang ShaoBo <bobo.shaobowang@huawei.com>\nCc: Yang Jihong <yangjihong1@huawei.com>\nCc: Yonghong Song <yhs@fb.com>\nCc: YueHaibing <yuehaibing@huawei.com>\nLink: https://lore.kernel.org/lkml/ZTGa0Ukt7QyxWcVy@kernel.org\nSigned-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>\n', '']",Fixes llvm feature detection in tools build affecting bpftool disassembly selection.,"llvm,bpftool,disassembly",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The bpftool utility,"[""It's not related to any of the above.""]"
bab8ac3c5339d7ec5312dcd836cfa8645edb954f,bab8ac3c5339d7ec5312dcd836cfa8645edb954f,Alexei Starovoitov,ast@kernel.org,1697760167,Alexei Starovoitov,ast@kernel.org,1697760167,11630b18cf327fe18688c437a20edaa9acfe364d,6bd5e167af2e9d1aa79e4a1a2598abcdc8fafd59 130e0f7af9fc7388b90fb016ca13ff3840c48d4a,"Merge branch 'add-open-coded-task-css_task-and-css-iters'

Chuyi Zhou says:

====================
Add Open-coded task"," css_task and css iters

This is version 6 of task","[' css_task and css iters support.\n\n--- Changelog ---\n\nv5 -> v6:\n\nPatch #3:\n * In bpf_iter_task_next', ' return pos rather than goto out. (Andrii)\nPatch #2', ' #3', ' #4:\n * Add the missing __diag_ignore_all to avoid kernel build warning\nPatch #5', ' #6', "" #7:\n * Add Andrii's ack\n\nPatch #8:\n * In BPF prog iter_css_task_for_each"", ' return -EPERM rather than 0', ' and\n   ensure stack_mprotect() in iters.c not success. If not', "" it would cause\n   the subsequent 'test_lsm' fail"", ' since the \'is_stack\' check in\n   test_int_hook(lsm.c) would not be guaranteed.\n   (https://github.com/kernel-patches/bpf/actions/runs/6489662214/job/17624665086?pr=5790)\n\nv4 -> v5:https://lore.kernel.org/lkml/20231007124522.34834-1-zhouchuyi@bytedance.com/\n\nPatch 3~4:\n * Relax the BUILD_BUG_ON check in bpf_iter_task_new and bpf_iter_css_new to avoid\n   netdev/build_32bit CI error.\n   (https://netdev.bots.linux.dev/static/nipa/790929/13412333/build_32bit/stderr)\nPatch 8:\n * Initialize skel pointer to fix the LLVM-16 build CI error\n   (https://github.com/kernel-patches/bpf/actions/runs/6462875618/job/17545170863)\n\nv3 -> v4:https://lore.kernel.org/all/20230925105552.817513-1-zhouchuyi@bytedance.com/\n\n* Address all the comments from Andrii in patch-3 ~ patch-6\n* Collect Tejun\'s ack\n* Add a extra patch to rename bpf_iter_task.c to bpf_iter_tasks.c\n* Seperate three BPF program files for selftests (iters_task.c iters_css_task.c iters_css.c)\n\nv2 -> v3:https://lore.kernel.org/lkml/20230912070149.969939-1-zhouchuyi@bytedance.com/\n\nPatch 1 (cgroup: Prepare for using css_task_iter_*() in BPF)\n  * Add tj\'s ack and Alexei\'s suggest-by.\nPatch 2 (bpf: Introduce css_task open-coded iterator kfuncs)\n  * Use bpf_mem_alloc/bpf_mem_free rather than kzalloc()\n  * Add KF_TRUSTED_ARGS for bpf_iter_css_task_new (Alexei)\n  * Move bpf_iter_css_task\'s definition from uapi/linux/bpf.h to\n    kernel/bpf/task_iter.c and we can use it from vmlinux.h\n  * Move bpf_iter_css_task_XXX\'s declaration from bpf_helpers.h to\n    bpf_experimental.h\nPatch 3 (Introduce task open coded iterator kfuncs)\n  * Change th API design keep consistent with SEC(""iter/task"")', "" support\n    iterating all threads(BPF_TASK_ITERATE_ALL) and threads of a\n    specific task (BPF_TASK_ITERATE_THREAD).（Andrii)\n  * Move bpf_iter_task's definition from uapi/linux/bpf.h to\n    kernel/bpf/task_iter.c and we can use it from vmlinux.h\n  * Move bpf_iter_task_XXX's declaration from bpf_helpers.h to\n    bpf_experimental.h\nPatch 4 (Introduce css open-coded iterator kfuncs)\n  * Change th API design keep consistent with cgroup_iters"", "" reuse\n    BPF_CGROUP_ITER_DESCENDANTS_PRE/BPF_CGROUP_ITER_DESCENDANTS_POST\n    /BPF_CGROUP_ITER_ANCESTORS_UP(Andrii)\n  * Add KF_TRUSTED_ARGS for bpf_iter_css_new\n  * Move bpf_iter_css's definition from uapi/linux/bpf.h to\n    kernel/bpf/task_iter.c and we can use it from vmlinux.h\n  * Move bpf_iter_css_XXX's declaration from bpf_helpers.h to\n    bpf_experimental.h\nPatch 5 (teach the verifier to enforce css_iter and task_iter in RCU CS)\n  * Add KF flag KF_RCU_PROTECTED to maintain kfuncs which need RCU CS.(Andrii)\n  * Consider STACK_ITER when using bpf_for_each_spilled_reg.\nPatch 6 (Let bpf_iter_task_new accept null task ptr)\n  * Add this extra patch to let bpf_iter_task_new accept a 'nullable'\n  * task pointer(Andrii)\nPatch 7 (selftests/bpf: Add tests for open-coded task and css iter)\n  * Add failure testcase(Alexei)\n\nChanges from v1(https://lore.kernel.org/lkml/20230827072057.1591929-1-zhouchuyi@bytedance.com/):\n- Add a pre-patch to make some preparations before supporting css_task\n  iters.(Alexei)\n- Add an allowlist for css_task iters(Alexei)\n- Let bpf progs do explicit bpf_rcu_read_lock() when using process\n  iters and css_descendant iters.(Alexei)\n---------------------\n\nIn some BPF usage scenarios"", "" it will be useful to iterate the process and\ncss directly in the BPF program. One of the expected scenarios is\ncustomizable OOM victim selection via BPF[1].\n\nInspired by Dave's task_vma iter[2]"", ' this patchset adds three types of\nopen-coded iterator kfuncs:\n\n1. bpf_task_iters. It can be used to\n1) iterate all process in the system', ' like for_each_forcess() in kernel.\n2) iterate all threads in the system.\n3) iterate all threads of a specific task\n\n2. bpf_css_iters. It works like css_task_iter_{start', ' next', ' end} and would\nbe used to iterating tasks/threads under a css.\n\n3. css_iters. It works like css_next_descendant_{pre', ' post} to iterating all\ndescendant css.\n\nBPF programs can use these kfuncs directly or through bpf_for_each macro.\n\nlink[1]: https://lore.kernel.org/lkml/20230810081319.65668-1-zhouchuyi@bytedance.com/\nlink[2]: https://lore.kernel.org/all/20230810183513.684836-1-davemarchevsky@fb.com/\n====================\n\nLink: https://lore.kernel.org/r/20231018061746.111364-1-zhouchuyi@bytedance.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']","This commit merges changes introducing open-coded task iterations, adding new task and CSS iteration features.","open-coded, task, CSS",It's a new feature.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.","The attach events and bpf link. e.g. perf events, tracepoints, etc.","['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
130e0f7af9fc7388b90fb016ca13ff3840c48d4a,130e0f7af9fc7388b90fb016ca13ff3840c48d4a,Chuyi Zhou,zhouchuyi@bytedance.com,1697609866,Alexei Starovoitov,ast@kernel.org,1697760167,11630b18cf327fe18688c437a20edaa9acfe364d,ddab78cbb52f81f7f7598482602342955b2ff8b8,"selftests/bpf: Add tests for open-coded task and css iter

This patch adds 4 subtests to demonstrate these patterns and validating
correctness.

subtest1:

1) We use task_iter to iterate all process in the system and search for the
current process with a given pid.

2) We create some threads in current process context"," and use
BPF_TASK_ITER_PROC_THREADS to iterate all threads of current process. As
expected","[' we would find all the threads of current process.\n\n3) We create some threads and use BPF_TASK_ITER_ALL_THREADS to iterate all\nthreads in the system. As expected', ' we would find all the threads which was\ncreated.\n\nsubtest2:\n\nWe create a cgroup and add the current task to the cgroup. In the\nBPF program', ' we would use bpf_for_each(css_task', ' task', ' css) to iterate all\ntasks under the cgroup. As expected', ' we would find the current process.\n\nsubtest3:\n\n1) We create a cgroup tree. In the BPF program', ' we use\nbpf_for_each(css', ' pos', ' root', ' XXX) to iterate all descendant under the root\nwith pre and post order. As expected', ' we would find all descendant and the\nlast iterating cgroup in post-order is root cgroup', ' the first iterating\ncgroup in pre-order is root cgroup.\n\n2) We wse BPF_CGROUP_ITER_ANCESTORS_UP to traverse the cgroup tree starting\nfrom leaf and root separately', ' and record the height. The diff of the\nhights would be the total tree-high - 1.\n\nsubtest4:\n\nAdd some failure testcase when using css_task', ' task and css iters', ' e.g', '\nunlock when using task-iters to iterate tasks.\n\nSigned-off-by: Chuyi Zhou <zhouchuyi@bytedance.com>\nLink: https://lore.kernel.org/r/20231018061746.111364-9-zhouchuyi@bytedance.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit introduces four subtests for open-coded task and CSS iterator patterns in selftests for BPF.,"tests,selftests,BPF",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['kprobe/uprobe/ftrace like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ddab78cbb52f81f7f7598482602342955b2ff8b8,ddab78cbb52f81f7f7598482602342955b2ff8b8,Chuyi Zhou,zhouchuyi@bytedance.com,1697609865,Alexei Starovoitov,ast@kernel.org,1697760167,1277c81e699ed02d528aa169954c6eac98da52e8,cb3ecf7915a1d7ce5304402f4d8616d9fa5193f7,"selftests/bpf: rename bpf_iter_task.c to bpf_iter_tasks.c

The newly-added struct bpf_iter_task has a name collision with a selftest
for the seq_file task iter's bpf skel"," so the selftests/bpf/progs file is
renamed in order to avoid the collision.

Signed-off-by: Chuyi Zhou <zhouchuyi@bytedance.com>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/r/20231018061746.111364-8-zhouchuyi@bytedance.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",[''],Renamed bpf_iter_task.c to bpf_iter_tasks.c in selftests to avoid a name collision.,"rename, selftests, collision",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['tracepoints like programs']
cb3ecf7915a1d7ce5304402f4d8616d9fa5193f7,cb3ecf7915a1d7ce5304402f4d8616d9fa5193f7,Chuyi Zhou,zhouchuyi@bytedance.com,1697609864,Alexei Starovoitov,ast@kernel.org,1697760166,9ee9742addacbd0b553396aeae598823aae8cf0a,dfab99df147b0d364f0c199f832ff2aedfb2265a,"bpf: Let bpf_iter_task_new accept null task ptr

When using task_iter to iterate all threads of a specific task"," we enforce
that the user must pass a valid task pointer to ensure safety. However","['\nwhen iterating all threads/process in the system', ' BPF verifier still\nrequire a valid ptr instead of ""nullable"" pointer', "" even though it's\npointless"", ' which is a kind of surprising from usability standpoint. It\nwould be nice if we could let that kfunc accept a explicit null pointer\nwhen we are using BPF_TASK_ITER_ALL_{PROCS', ' THREADS} and a valid pointer\nwhen using BPF_TASK_ITER_THREAD.\n\nGiven a trival kfunc:\n\t__bpf_kfunc void FN(struct TYPE_A *obj);\n\nBPF Prog would reject a nullptr for obj. The error info is:\n""arg#x pointer type xx xx must point to scalar', ' or struct with scalar""\nreported by get_kfunc_ptr_arg_type(). The reg->type is SCALAR_VALUE and\nthe btf type of ref_t is not scalar or scalar_struct which leads to the\nrejection of get_kfunc_ptr_arg_type.\n\nThis patch add ""__nullable"" annotation:\n\t__bpf_kfunc void FN(struct TYPE_A *obj__nullable);\nHere __nullable indicates obj can be optional', ' user can pass a explicit\nnullptr or a normal TYPE_A pointer. In get_kfunc_ptr_arg_type()', ' we will\ndetect whether the current arg is optional and register is null', ' If so', '\nreturn a new kfunc_ptr_arg_type KF_ARG_PTR_TO_NULL and skip to the next\narg in check_kfunc_args().\n\nSigned-off-by: Chuyi Zhou <zhouchuyi@bytedance.com>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231018061746.111364-7-zhouchuyi@bytedance.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit allows bpf_iter_task_new to accept a null task pointer for iterating threads.,"bpf, task_ptr, iter",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
dfab99df147b0d364f0c199f832ff2aedfb2265a,dfab99df147b0d364f0c199f832ff2aedfb2265a,Chuyi Zhou,zhouchuyi@bytedance.com,1697609863,Alexei Starovoitov,ast@kernel.org,1697760166,6bbe3fa26b07cf39eaa8a0657f03079be79c85ef,7251d0905e7518bcb990c8e9a3615b1bb23c78f2,"bpf: teach the verifier to enforce css_iter and task_iter in RCU CS

css_iter and task_iter should be used in rcu section. Specifically"," in
sleepable progs explicit bpf_rcu_read_lock() is needed before use these
iters. In normal bpf progs that have implicit rcu_read_lock()","["" it's OK to\nuse them directly.\n\nThis patch adds a new a KF flag KF_RCU_PROTECTED for bpf_iter_task_new and\nbpf_iter_css_new. It means the kfunc should be used in RCU CS. We check\nwhether we are in rcu cs before we want to invoke this kfunc. If the rcu\nprotection is guaranteed"", ' we would let st->type = PTR_TO_STACK | MEM_RCU.\nOnce user do rcu_unlock during the iteration', ' state MEM_RCU of regs would\nbe cleared. is_iter_reg_valid_init() will reject if reg->type is UNTRUSTED.\n\nIt is worth noting that currently', ' bpf_rcu_read_unlock does not\nclear the state of the STACK_ITER reg', ' since bpf_for_each_spilled_reg\nonly considers STACK_SPILL. This patch also let bpf_for_each_spilled_reg\nsearch STACK_ITER.\n\nSigned-off-by: Chuyi Zhou <zhouchuyi@bytedance.com>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/r/20231018061746.111364-6-zhouchuyi@bytedance.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",The commit enforces css_iter and task_iter usage in RCU critical sections within BPF programs.,"verifier,css_iter,RCU",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
7251d0905e7518bcb990c8e9a3615b1bb23c78f2,7251d0905e7518bcb990c8e9a3615b1bb23c78f2,Chuyi Zhou,zhouchuyi@bytedance.com,1697609862,Alexei Starovoitov,ast@kernel.org,1697760166,28cbfe76ea2eff8d6ae5cd09f32c732a1cdd6e80,c68a78ffe2cb4207f64fd0f4262818c728c67be0,"bpf: Introduce css open-coded iterator kfuncs

This Patch adds kfuncs bpf_iter_css_{new",next,"['destroy} which allow\ncreation and manipulation of struct bpf_iter_css in open-coded iterator\nstyle. These kfuncs actually wrapps css_next_descendant_{pre', ' post}.\ncss_iter can be used to:\n\n1) iterating a sepcific cgroup tree with pre/post/up order\n\n2) iterating cgroup_subsystem in BPF Prog', ' like\nfor_each_mem_cgroup_tree/cpuset_for_each_descendant_pre in kernel.\n\nThe API design is consistent with cgroup_iter. bpf_iter_css_new accepts\nparameters defining iteration order and starting css. Here we also reuse\nBPF_CGROUP_ITER_DESCENDANTS_PRE', ' BPF_CGROUP_ITER_DESCENDANTS_POST', '\nBPF_CGROUP_ITER_ANCESTORS_UP enums.\n\nSigned-off-by: Chuyi Zhou <zhouchuyi@bytedance.com>\nAcked-by: Tejun Heo <tj@kernel.org>\nLink: https://lore.kernel.org/r/20231018061746.111364-5-zhouchuyi@bytedance.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",This commit introduces kfuncs for open-coded iterator in eBPF.,"kfuncs, iterator, bpf",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
c68a78ffe2cb4207f64fd0f4262818c728c67be0,c68a78ffe2cb4207f64fd0f4262818c728c67be0,Chuyi Zhou,zhouchuyi@bytedance.com,1697609861,Alexei Starovoitov,ast@kernel.org,1697760166,6a95dc7b2480bb918ba7c3e0eaa96da6ad67c18f,9c66dc94b62aef23300f05f63404afb8990920b4,"bpf: Introduce task open coded iterator kfuncs

This patch adds kfuncs bpf_iter_task_{new",next,"['destroy} which allow\ncreation and manipulation of struct bpf_iter_task in open-coded iterator\nstyle. BPF programs can use these kfuncs or through bpf_for_each macro to\niterate all processes in the system.\n\nThe API design keep consistent with SEC(""iter/task""). bpf_iter_task_new()\naccepts a specific task and iterating type which allows:\n\n1. iterating all process in the system (BPF_TASK_ITER_ALL_PROCS)\n\n2. iterating all threads in the system (BPF_TASK_ITER_ALL_THREADS)\n\n3. iterating all threads of a specific task (BPF_TASK_ITER_PROC_THREADS)\n\nSigned-off-by: Chuyi Zhou <zhouchuyi@bytedance.com>\nLink: https://lore.kernel.org/r/20231018061746.111364-4-zhouchuyi@bytedance.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Introduces task open coded iterator kfuncs for eBPF.,"bpf, task, kfuncs",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9c66dc94b62aef23300f05f63404afb8990920b4,9c66dc94b62aef23300f05f63404afb8990920b4,Chuyi Zhou,zhouchuyi@bytedance.com,1697609860,Alexei Starovoitov,ast@kernel.org,1697760166,9df3e5be227342647a1815c62ac0567d9bebbf61,6da88306811b40a207c94c9da9faf07bdb20776e,"bpf: Introduce css_task open-coded iterator kfuncs

This patch adds kfuncs bpf_iter_css_task_{new",next,"['destroy} which allow\ncreation and manipulation of struct bpf_iter_css_task in open-coded\niterator style. These kfuncs actually wrapps css_task_iter_{start', 'next', '\nend}. BPF programs can use these kfuncs through bpf_for_each macro for\niteration of all tasks under a css.\n\ncss_task_iter_*() would try to get the global spin-lock *css_set_lock*', ' so\nthe bpf side has to be careful in where it allows to use this iter.\nCurrently we only allow it in bpf_lsm and bpf iter-s.\n\nSigned-off-by: Chuyi Zhou <zhouchuyi@bytedance.com>\nAcked-by: Tejun Heo <tj@kernel.org>\nLink: https://lore.kernel.org/r/20231018061746.111364-3-zhouchuyi@bytedance.com\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\n', '']",Introduce open-coded iterator kfuncs for css_task in bpf.,"bpf, kfuncs, iterator",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
6da88306811b40a207c94c9da9faf07bdb20776e,6da88306811b40a207c94c9da9faf07bdb20776e,Chuyi Zhou,zhouchuyi@bytedance.com,1697609859,Alexei Starovoitov,ast@kernel.org,1697760166,810c25824382b03274431b9670f419b2650af7ae,6bd5e167af2e9d1aa79e4a1a2598abcdc8fafd59,"cgroup: Prepare for using css_task_iter_*() in BPF

This patch makes some preparations for using css_task_iter_*() in BPF
Program.

1. Flags CSS_TASK_ITER_* are #define-s and it's not easy for bpf prog to
use them. Convert them to enum so bpf prog can take them from vmlinux.h.

2. In the next patch we will add css_task_iter_*() in common kfuncs which
is not safe. Since css_task_iter_*() does spin_unlock_irq() which might
screw up irq flags depending on the context where bpf prog is running.
So we should use irqsave/irqrestore here and the switching is harmless.

Suggested-by: Alexei Starovoitov <ast@kernel.org>
Signed-off-by: Chuyi Zhou <zhouchuyi@bytedance.com>
Acked-by: Tejun Heo <tj@kernel.org>
Link: https://lore.kernel.org/r/20231018061746.111364-2-zhouchuyi@bytedance.com
Signed-off-by: Alexei Starovoitov <ast@kernel.org>
",,Prepare for using css_task_iter functions in BPF by converting defines to enums and addressing irq issues.,"css_task_iter, BPF, preparation",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The helper and kfuncs,['cgroup like programs']
b9ec913212e6e91efa5a0a612c4a8ec4cf5da896,b9ec913212e6e91efa5a0a612c4a8ec4cf5da896,Breno Leitao,leitao@debian.org,1697464069,Jens Axboe,axboe@kernel.dk,1697755324,6cea837326eae4029a0e8afefcb1527115d75dfe,4232c6e349f3a591fd0f432e6b858d32095adce6,"selftests/bpf/sockopt: Add io_uring support

Expand the sockopt test to use also check for io_uring {g","s}etsockopt
commands operations.

This patch starts by marking each test if they support io_uring support
or not.

Right now","[' io_uring cmd getsockopt() has a limitation of only\naccepting level == SOL_SOCKET', "" otherwise it returns -EOPNOTSUPP. Since\nthere aren't any test exercising getsockopt(level == SOL_SOCKET)"", ' this\npatch changes two tests to use level == SOL_SOCKET', ' they are\n""getsockopt: support smaller ctx->optlen"" and ""getsockopt: read\nctx->optlen"".\nThere is no limitation for the setsockopt() part.\n\nLater', ' each test runs using regular {g', 's}etsockopt systemcalls', ' and', ' if\nliburing is supported', ' execute the same test (again)', ' but calling\nliburing {g', 's}setsockopt commands.\n\nThis patch also changes the level of two tests to use SOL_SOCKET for the\nfollowing two tests. This is going to help to exercise the io_uring\nsubsystem:\n * getsockopt: read ctx->optlen\n * getsockopt: support smaller ctx->optlen\n\nSigned-off-by: Breno Leitao <leitao@debian.org>\nLink: https://lore.kernel.org/r/20231016134750.1381153-12-leitao@debian.org\nAcked-by: Martin KaFai Lau <martin.lau@kernel.org>\nSigned-off-by: Jens Axboe <axboe@kernel.dk>\n', '']",The commit adds io_uring support to the sockopt selftests for checking setsockopt commands operations.,"io_uring,sockopt,selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['socket like programs']
7746a6adfc81e2e0386a85117d5e8fd824da367b,7746a6adfc81e2e0386a85117d5e8fd824da367b,Breno Leitao,leitao@debian.org,1697464064,Jens Axboe,axboe@kernel.dk,1697755323,b7f5439e621d5aaf8162b28177cbe1e40bcda77c,5fea44a6e05b86bf49019fbbf2ab30098d03e0dc,"tools headers: Grab copy of io_uring.h

This file will be used by mini_uring.h and allow tests to run without
the need of installing liburing to run the tests.

This is needed to run io_uring tests in BPF"," such as
(tools/testing/selftests/bpf/prog_tests/sockopt.c).

Signed-off-by: Breno Leitao <leitao@debian.org>
Link: https://lore.kernel.org/r/20231016134750.1381153-7-leitao@debian.org
Signed-off-by: Jens Axboe <axboe@kernel.dk>
",[''],This commit grabs a copy of io_uring.h for running io_uring tests without liburing installation.,"io_uring,h,tests",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
3f31e0d14d44ad491a81b7c1f83f32fbc300a867,3f31e0d14d44ad491a81b7c1f83f32fbc300a867,Breno Leitao,leitao@debian.org,1697464060,Jens Axboe,axboe@kernel.dk,1697745937,e69d7c1110eef9f75be5837577e5ba0df99cfd8a,a615f67e1a426f35366b8398c11f31c148e7df48,"bpf: Add sockptr support for setsockopt

The whole network stack uses sockptr"," and while it doesn't move to
something more modern","["" let's use sockptr in setsockptr BPF hooks"", ' so', ' it\ncould be used by other callers.\n\nThe main motivation for this change is to use it in the io_uring\n{g', 's}etsockopt()', ' which will use a userspace pointer for *optval', ' but', ' a\nkernel value for optlen.\n\nLink: https://lore.kernel.org/all/ZSArfLaaGcfd8LH8@gmail.com/\n\nSigned-off-by: Breno Leitao <leitao@debian.org>\nAcked-by: Martin KaFai Lau <martin.lau@kernel.org>\nLink: https://lore.kernel.org/r/20231016134750.1381153-3-leitao@debian.org\nSigned-off-by: Jens Axboe <axboe@kernel.dk>\n', '']",Add support for sockptr in the bpf setsockopt function.,"sockptr, setsockopt, network",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The syscall interface,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
a615f67e1a426f35366b8398c11f31c148e7df48,a615f67e1a426f35366b8398c11f31c148e7df48,Breno Leitao,leitao@debian.org,1697464059,Jens Axboe,axboe@kernel.dk,1697745928,4e4f6688f2ea831ce503599d3880f73d60e026db,6ce4a93dbb5bd93bc2bdf14da63f9360a4dcd6a1,"bpf: Add sockptr support for getsockopt

The whole network stack uses sockptr"," and while it doesn't move to
something more modern","["" let's use sockptr in getsockptr BPF hooks"", ' so', ' it\ncould be used by other callers.\n\nThe main motivation for this change is to use it in the io_uring\n{g', 's}etsockopt()', ' which will use a userspace pointer for *optval', ' but', ' a\nkernel value for optlen.\n\nLink: https://lore.kernel.org/all/ZSArfLaaGcfd8LH8@gmail.com/\n\nSigned-off-by: Breno Leitao <leitao@debian.org>\nAcked-by: Martin KaFai Lau <martin.lau@kernel.org>\nLink: https://lore.kernel.org/r/20231016134750.1381153-2-leitao@debian.org\nSigned-off-by: Jens Axboe <axboe@kernel.dk>\n', '']",The commit adds sockptr support for getsockopt in the BPF subsystem.,"bpf,sockptr,getsockopt",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The syscall interface,['socket like programs']
ce55c22ec8b223a90ff3e084d842f73cfba35588,ce55c22ec8b223a90ff3e084d842f73cfba35588,Linus Torvalds,torvalds@linux-foundation.org,1697742498,Linus Torvalds,torvalds@linux-foundation.org,1697742498,919fc51c26a8b5f57b3c89f6a62d0f3bb1bdfd2c,74e9347ebc5be452935fe4f3eddb150aa5a6f4fe 524515020f2552759a7ef1c9d03e7dac9b1ff3c2,"Merge tag 'net-6.6-rc7' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Jakub Kicinski:
 ""Including fixes from bluetooth", netfilter,"[' WiFi.\n\n  Feels like an up-tick in regression fixes', ' mostly for older releases.\n  The hfsc fix', ' tcp_disconnect() and Intel WWAN fixes stand out as\n  fairly clear-cut user reported regressions. The mlx5 DMA bug was\n  causing strife for 390x folks. The fixes themselves are not\n  particularly scary', ' tho. No open investigations / outstanding reports\n  at the time of writing.\n\n  Current release - regressions:\n\n   - eth: mlx5: perform DMA operations in the right locations', ' make\n     devices usable on s390x', "" again\n\n   - sched: sch_hfsc: upgrade 'rt' to 'sc' when it becomes a inner\n     curve"", ' previous fix of rejecting invalid config broke some scripts\n\n   - rfkill: reduce data->mtx scope in rfkill_fop_open', ' avoid deadlock\n\n   - revert ""ethtool: Fix mod state of verbose no_mask bitset""', ' needs\n     more work\n\n  Current release - new code bugs:\n\n   - tcp: fix listen() warning with v4-mapped-v6 address\n\n  Previous releases - regressions:\n\n   - tcp: allow tcp_disconnect() again when threads are waiting', ' it was\n     denied to plug a constant source of bugs but turns out .NET depends\n     on it\n\n   - eth: mlx5: fix double-free if buffer refill fails under OOM\n\n   - revert ""net: wwan: iosm: enable runtime pm support for 7560""', "" it's\n     causing regressions and the WWAN team at Intel disappeared\n\n   - tcp: tsq: relax tcp_small_queue_check() when rtx queue contains a\n     single skb"", ' fix single-stream perf regression on some devices\n\n  Previous releases - always broken:\n\n   - Bluetooth:\n      - fix issues in legacy BR/EDR PIN code pairing\n      - correctly bounds check and pad HCI_MON_NEW_INDEX name\n\n   - netfilter:\n      - more fixes / follow ups for the large ""commit protocol"" rework', '\n        which went in as a fix to 6.5\n      - fix null-derefs on netlink attrs which user may not pass in\n\n   - tcp: fix excessive TLP and RACK timeouts from HZ rounding (bless\n     Debian for keeping HZ=250 alive)\n\n   - net: more strict VIRTIO_NET_HDR_GSO_UDP_L4 validation', ' prevent\n     letting frankenstein UDP super-frames from getting into the stack\n\n   - net: fix interface altnames when ifc moves to a new namespace\n\n   - eth: qed: fix the size of the RX buffers\n\n   - mptcp: avoid sending RST when closing the initial subflow""\n\n* tag \'net-6.6-rc7\' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (94 commits)\n  Revert ""ethtool: Fix mod state of verbose no_mask bitset""\n  selftests: mptcp: join: no RST when rm subflow/addr\n  mptcp: avoid sending RST when closing the initial subflow\n  mptcp: more conservative check for zero probes\n  tcp: check mptcp-level constraints for backlog coalescing\n  selftests: mptcp: join: correctly check for no RST\n  net: ti: icssg-prueth: Fix r30 CMDs bitmasks\n  selftests: net: add very basic test for netdev names and namespaces\n  net: move altnames together with the netdevice\n  net: avoid UAF on deleted altname\n  net: check for altname conflicts when changing netdev\'s netns\n  net: fix ifname in netlink ntf during netns move\n  net: ethernet: ti: Fix mixed module-builtin object\n  net: phy: bcm7xxx: Add missing 16nm EPHY statistics\n  ipv4: fib: annotate races around nh->nh_saddr_genid and nh->nh_saddr\n  tcp_bpf: properly release resources on error paths\n  net/sched: sch_hfsc: upgrade \'rt\' to \'sc\' when it becomes a inner curve\n  net: mdio-mux: fix C45 access returning -EIO after API change\n  tcp: tsq: relax tcp_small_queue_check() when rtx queue contains a single skb\n  octeon_ep: update BQL sent bytes before ringing doorbell\n  ...\n', '']","Merge network-related fixes for the Linux kernel, including updates from bluetooth.","networking, fixes, bluetooth",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
6bd5e167af2e9d1aa79e4a1a2598abcdc8fafd59,6bd5e167af2e9d1aa79e4a1a2598abcdc8fafd59,Manu Bretelle,chantr4@gmail.com,1697670093,Daniel Borkmann,daniel@iogearbox.net,1697725815,26269f8535c6e4ab0da210d580c6c4f7a6c3da8a,90704b4be0b0d6d0a7a9369d4b9aae6a579602c7,"bpftool: Wrap struct_ops dump in an array

When dumping a struct_ops"," 2 dictionaries are emitted.

When using `name`","[' they were already wrapped in an array', ' but not when\nusing `id`. Causing `jq` to fail at parsing the payload as it reached\nthe comma following the first dict.\n\nThis change wraps those dictionaries in an array so valid json is emitted.\n\nBefore', "" jq fails to parse the output:\n```\n $ sudo bpftool struct_ops dump id 1523612 | jq . > /dev/null\nparse error: Expected value before '"", ""' at line 19"", ' column 2\n```\n\nAfter', ' no error parsing the output:\n```\nsudo ./bpftool  struct_ops dump id 1523612 | jq . > /dev/null\n```\n\nSigned-off-by: Manu Bretelle <chantr4@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Quentin Monnet <quentin@isovalent.com>\nLink: https://lore.kernel.org/bpf/20231018230133.1593152-3-chantr4@gmail.com\n', '']",Wraps struct_ops dump in an array within bpftool utility.,"bpftool,struct_ops,array",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"[""It's not related to any of the above.""]"
90704b4be0b0d6d0a7a9369d4b9aae6a579602c7,90704b4be0b0d6d0a7a9369d4b9aae6a579602c7,Manu Bretelle,chantr4@gmail.com,1697670092,Daniel Borkmann,daniel@iogearbox.net,1697725776,b7a572801da28d3dc213446b5e72b63c76986f67,0e133a13370389d3894891eafe54fec2c44ad735,"bpftool: Fix printing of pointer value

When printing a pointer value"," ""%p"" will either print the hexadecimal
value of the pointer (e.g `0x1234`)","[' or `(nil)` when NULL.\n\nBoth of those are invalid json ""integer"" values and need to be wrapped\nin quotes.\n\nBefore:\n```\n$ sudo bpftool struct_ops dump  name ned_dummy_cca | grep next\n                    ""next"": (nil)', ""\n$ sudo bpftool struct_ops dump  name ned_dummy_cca | \\\n    jq '.[1].bpf_struct_ops_tcp_congestion_ops.data.list.next'\nparse error: Invalid numeric literal at line 29"", ' column 34\n```\n\nAfter:\n```\n$ sudo ./bpftool struct_ops dump  name ned_dummy_cca | grep next\n                    ""next"": ""(nil)""', '\n$ sudo ./bpftool struct_ops dump  name ned_dummy_cca | \\\n    jq \'.[1].bpf_struct_ops_tcp_congestion_ops.data.list.next\'\n""(nil)""\n```\n\nSigned-off-by: Manu Bretelle <chantr4@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nAcked-by: Quentin Monnet <quentin@isovalent.com>\nLink: https://lore.kernel.org/bpf/20231018230133.1593152-2-chantr4@gmail.com\n', '']",This commit fixes the way bpftool prints pointer values to display them in hexadecimal format.,"bpftool,pointer printing,bug fix",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,['other']
68b54aeff804acceb02f228ea2e28419272c1fb9,68b54aeff804acceb02f228ea2e28419272c1fb9,Paolo Abeni,pabeni@redhat.com,1697557791,Jakub Kicinski,kuba@kernel.org,1697677771,2ee3946a361acf50f951e4b6bda9cbaad27e0d49,a13b67c9a015c4e21601ef9aa4ec9c5d972df1b4,"tcp_bpf: properly release resources on error paths

In the blamed commit below"," I completely forgot to release the acquired
resources before erroring out in the TCP BPF code","[' as reported by Dan.\n\nAddress the issues by replacing the bogus return with a jump to the\nrelevant cleanup code.\n\nFixes: 419ce133ab92 (""tcp: allow again tcp_disconnect() when threads are waiting"")\nReported-by: Dan Carpenter <dan.carpenter@linaro.org>\nSigned-off-by: Paolo Abeni <pabeni@redhat.com>\nAcked-by: Jakub Sitnicki <jakub@cloudflare.com>\nReviewed-by: Eric Dumazet <edumazet@google.com>\nReviewed-by: John Fastabend <john.fastabend@gmail.com>\nLink: https://lore.kernel.org/r/8f99194c698bcef12666f0a9a999c58f8b1cb52c.1697557782.git.pabeni@redhat.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",This commit fixes resource release on error paths in the TCP BPF code.,"TCP BPF,release,errorpaths",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,['socket like programs']
bdcb37a5d8de3253da48b120e3f10863696fb654,bdcb37a5d8de3253da48b120e3f10863696fb654,Arnd Bergmann,arnd@arndb.de,1697553238,Yury Norov,yury.norov@gmail.com,1697677677,cec6ecddbcd76119e0e2097b28ab42c7483022d0,6cb42f91aa6dfd10fd847c469caebe63b35141ff,"buildid: reduce header file dependencies for module

The vmlinux decompressor code intentionally has only a limited set of
included header files"," but this started running into a build failure
because of the bitmap logic needing linux/errno.h:

In file included from include/linux/cpumask.h:12","['\n                 from include/linux/mm_types_task.h:14', '\n                 from include/linux/mm_types.h:5', '\n                 from include/linux/buildid.h:5', '\n                 from include/linux/module.h:14', '\n                 from arch/arm/boot/compressed/../../../../lib/lz4/lz4_decompress.c:39', '\n                 from arch/arm/boot/compressed/../../../../lib/decompress_unlz4.c:10', ""\n                 from arch/arm/boot/compressed/decompress.c:60:\ninclude/linux/bitmap.h: In function 'bitmap_allocate_region':\ninclude/linux/bitmap.h:527:25: error: 'EBUSY' undeclared (first use in this function)\n  527 |                 return -EBUSY;\n      |                         ^~~~~\ninclude/linux/bitmap.h:527:25: note: each undeclared identifier is reported only once for each function it appears in\ninclude/linux/bitmap.h: In function 'bitmap_find_free_region':\ninclude/linux/bitmap.h:554:17: error: 'ENOMEM' undeclared (first use in this function)\n  554 |         return -ENOMEM;\n      |                 ^~~~~~\n\nThis is easily avoided by changing linux/buildid.h to no longer depend on\nlinux/mm_types.h"", ' a header that pulls in a huge number of indirect dependencies.\n\nFixes: b9c957f554442 (""bitmap: move bitmap_*_region() functions to bitmap.h"")\nFixes: bd7525dacd7e2 (""bpf: Move stack_map_get_build_id into lib"")\nSigned-off-by: Arnd Bergmann <arnd@arndb.de>\nSigned-off-by: Yury Norov <yury.norov@gmail.com>\n', '']",The commit reduces header file dependencies for the vmlinux decompressor module to fix build failures.,"header, dependencies, module",It's a build system or CI/CD change.,"Simple, can be used without much configuration. For example, a simple helper function.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
0e133a13370389d3894891eafe54fec2c44ad735,0e133a13370389d3894891eafe54fec2c44ad735,Dave Thaler,dthaler@microsoft.com,1697574620,Daniel Borkmann,daniel@iogearbox.net,1697672172,54f3b6815025572d7a5bcf028caf6a37bce626c3,bb6a88885fde24835afdaa1c5bb976a1bf5c5d71,bpf," docs: Define signed modulo as using truncated division

There's different mathematical definitions (truncated","[' floored', ' rounded', '\netc.) and different languages have chosen different definitions [0][1].\nE.g.', ' languages/libraries that follow Knuth use a different mathematical\ndefinition than C uses. This patch specifies which definition BPF uses', '\nas verified by Eduard [2] and others.\n\n  [0] https://en.wikipedia.org/wiki/Modulo#Variants_of_the_definition\n  [1] https://torstencurdt.com/tech/posts/modulo-of-negative-numbers/\n  [2] https://lore.kernel.org/bpf/57e6fefadaf3b2995bb259fa8e711c7220ce5290.camel@gmail.com/\n\nSigned-off-by: Dave Thaler <dthaler@microsoft.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: David Vernet <void@manifault.com>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/bpf/20231017203020.1500-1-dthaler1968@googlemail.com\n', '']",Clarified the definition of signed modulo using truncated division in documentation.,"signed modulo, truncated division, documentation",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
b5c532e90478e134b66b067c2b0487526ac4161e,b5c532e90478e134b66b067c2b0487526ac4161e,Jiri Olsa,jolsa@kernel.org,1696800171,Namhyung Kim,namhyung@kernel.org,1697668187,35aec88f528685a6d724023cf3a550ac512a6ca0,d9997f7ffb137447aa2f820c26cb1e6f5890d978,"tools/build: Fix -s detection code in tools/scripts/Makefile.include

As Dmitry described in [1] changelog the current way of detecting
-s option is broken for new make.

Changing the tools/build -s option detection the same way as it was
fixed for root Makefile in [1].

[1] 4bf73588165b (""kbuild: Port silent mode detection to future gnu make."")

Cc: Dmitry Goncharov <dgoncharov@users.sf.net>
Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
Cc: KP Singh <kpsingh@chromium.org>
Cc: Martin KaFai Lau <kafai@fb.com>
Cc: Song Liu <songliubraving@fb.com>
Cc: Yonghong Song <yhs@fb.com>
Cc: John Fastabend <john.fastabend@gmail.com>
Cc: Hao Luo <haoluo@google.com>
Cc: Ian Rogers <irogers@google.com>
Cc: Stanislav Fomichev <sdf@google.com>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Quentin Monnet <quentin@isovalent.com>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Andrii Nakryiko <andrii@kernel.org>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Ingo Molnar <mingo@kernel.org>
Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
Cc: bpf@vger.kernel.org
Cc: linux-perf-users@vger.kernel.org
Link: https://lore.kernel.org/r/20231008212251.236023-3-jolsa@kernel.org
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
",,Fix detection of the -s option in Makefile for compatibility with new versions of GNU make.,"detection, Makefile, compatibility",It's a build system or CI/CD change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
d9997f7ffb137447aa2f820c26cb1e6f5890d978,d9997f7ffb137447aa2f820c26cb1e6f5890d978,Jiri Olsa,jolsa@kernel.org,1696800170,Namhyung Kim,namhyung@kernel.org,1697668175,e398c50eb44f433bcdcb920d61c034e71777d8d2,9a13ee457a6e7a850ac1d145b0731b1d729b8f42,"tools/build: Fix -s detection code in tools/build/Makefile.build

As Dmitry described in [1] changelog the current way of detecting
-s option is broken for new make.

Changing the tools/build -s option detection the same way as it was
fixed for root Makefile in [1].

[1] 4bf73588165b (""kbuild: Port silent mode detection to future gnu make."")

Cc: Dmitry Goncharov <dgoncharov@users.sf.net>
Signed-off-by: Jiri Olsa <jolsa@kernel.org>
Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
Cc: KP Singh <kpsingh@chromium.org>
Cc: Martin KaFai Lau <kafai@fb.com>
Cc: Song Liu <songliubraving@fb.com>
Cc: Yonghong Song <yhs@fb.com>
Cc: John Fastabend <john.fastabend@gmail.com>
Cc: Hao Luo <haoluo@google.com>
Cc: Ian Rogers <irogers@google.com>
Cc: Stanislav Fomichev <sdf@google.com>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Quentin Monnet <quentin@isovalent.com>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Andrii Nakryiko <andrii@kernel.org>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Ingo Molnar <mingo@kernel.org>
Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
Cc: bpf@vger.kernel.org
Cc: linux-perf-users@vger.kernel.org
Link: https://lore.kernel.org/r/20231008212251.236023-2-jolsa@kernel.org
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
",,Fix the -s option detection in tools/build/Makefile.build for compatibility with new make versions.,"Fix, Makefile, tools",It's a build system or CI/CD change.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
71ca5ee18708c1f9f086e20ac0a657009bcfe43a,71ca5ee18708c1f9f086e20ac0a657009bcfe43a,Joe Perches,joe@perches.com,1696541717,Andrew Morton,akpm@linux-foundation.org,1697665402,36c6ff15df35b963ea6755bef7bdd4c3adb7e3c5,ead5a727739fa63b94ccd281d848a503032444ee,"get_maintainer: add --keywords-in-file option

There were some recent attempts [1] [2] to make the K: field less noisy
and its behavior more obvious.  Ultimately"," a shift in the default
behavior and an associated command line flag is the best choice.

Currently","[' K: will match keywords found in both patches and files.\n\nMatching content from entire files is (while documented) not obvious\nbehavior and is usually not wanted by maintainers.\n\nNow only patch content will be matched against unless --keywords-in-file\nis also provided as an argument to get_maintainer.\n\nAdd the actual keyword matched to the role or rolestats as well.\n\nFor instance given the diff below that removes clang:\n\n:   diff --git a/drivers/hid/bpf/entrypoints/README b/drivers/hid/bpf/entrypoints/README\n:    index 147e0d41509f..f88eb19e8ef2 100644\n:    --- a/drivers/hid/bpf/entrypoints/README\n:    +++ b/drivers/hid/bpf/entrypoints/README\n:    @@ -1', '4 +1', '4 @@\n:     WARNING:\n:     If you change ""entrypoints.bpf.c"" do ""make -j"" in this directory to rebuild ""entrypoints.skel.h"".\n:    -Make sure to have clang 10 installed.\n:    +Make sure to have 10 installed.\n:     See Documentation/bpf/bpf_devel_QA.rst\n\nThe new role/rolestats output includes "":Keyword:\\b(?i:clang|llvm)\\b""\n\n$ git diff drivers/hid/bpf/entrypoints/README | .scripts/get_maintainer.pl\nJiri Kosina <jikos@kernel.org> (maintainer:HID CORE LAYER', 'commit_signer:1/1=100%)\nBenjamin Tissoires <benjamin.tissoires@redhat.com> (maintainer:HID CORE LAYER', 'commit_signer:1/1=100%', 'authored:1/1=100%', 'added_lines:4/4=100%)\nNathan Chancellor <nathan@kernel.org> (supporter:CLANG/LLVM BUILD SUPPORT:Keyword:\\b(?i:clang|llvm)\\b)\nNick Desaulniers <ndesaulniers@google.com> (supporter:CLANG/LLVM BUILD SUPPORT:Keyword:\\b(?i:clang|llvm)\\b)\nTom Rix <trix@redhat.com> (reviewer:CLANG/LLVM BUILD SUPPORT:Keyword:\\b(?i:clang|llvm)\\b)\nGreg Kroah-Hartman <gregkh@linuxfoundation.org> (commit_signer:1/1=100%)\nlinux-input@vger.kernel.org (open list:HID CORE LAYER)\nlinux-kernel@vger.kernel.org (open list)\nllvm@lists.linux.dev (open list:CLANG/LLVM BUILD SUPPORT:Keyword:\\b(?i:clang|llvm)\\b)\n\nLink: https://lore.kernel.org/r/20231004-get_maintainer_change_k-v1-1-ac7ced18306a@google.com\nLink: https://lore.kernel.org/all/20230928-get_maintainer_add_d-v2-0-8acb3f394571@google.com\nLink: https://lore.kernel.org/all/3dca40b677dd2fef979a5a581a2db91df2c21801.camel@perches.com\nOriginal-patch-by: Justin Stitt <justinstitt@google.com>\nLink: https://lkml.kernel.org/r/01fe46f0c58aa8baf92156ae2bdccfb2bf0cb48e.camel@perches.com\nSigned-off-by: Joe Perches <joe@perches.com>\nTested-by: Justin Stitt <justinstitt@google.com>\nCc: Kees Cook <keescook@chromium.org>\nCc: Nick Desaulniers <ndesaulniers@google.com>\n\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\n', '']",Added an option to get_maintainer for filtering with keywords in the file.,"get_maintainer, keywords, filtering",It's a new feature.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
1bc628a756d93a7bed2f80914b15821bb9a4369c,1bc628a756d93a7bed2f80914b15821bb9a4369c,Jeff Layton,jlayton@kernel.org,1696445586,Christian Brauner,brauner@kernel.org,1697630910,0ade6c2274eba788c9928e9f6c302031d6a47c9d,d162a3cf6ee1a64417e11693c1410d79878c9917,"bpf: convert to new timestamp accessors

Convert to using the new inode timestamp accessor functions.

Signed-off-by: Jeff Layton <jlayton@kernel.org>
Link: https://lore.kernel.org/r/20231004185347.80880-79-jlayton@kernel.org
Signed-off-by: Christian Brauner <brauner@kernel.org>
",,The commit updates BPF code to use new inode timestamp accessors.,"bpf, timestamp, accessors",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4b47b0fa4b15e0de916e7dd93cd787fdab208ff2,4b47b0fa4b15e0de916e7dd93cd787fdab208ff2,Muhammad Muzammil,m.muzzammilashraf@gmail.com,1697175078,Michael Ellerman,mpe@ellerman.id.au,1697628420,c9db4f51c53caac0f3c8897a821721a73ac12e22,1c7b4bc375c2a235e3dcb53c46111883df838e42,"powerpc/bpf: Fixed 'instead' typo in bpf_jit_build_body()

Fixed 'instead' typo.

Signed-off-by: Muhammad Muzammil <m.muzzammilashraf@gmail.com>
Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
Link: https://msgid.link/20231013053118.11221-1-m.muzzammilashraf@gmail.com

",,Corrected a typo in the bpf_jit_build_body function for PowerPC architecture.,"typo, bpf, PowerPC",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The JIT compiler,"[""It's not related to any of the above.""]"
bb6a88885fde24835afdaa1c5bb976a1bf5c5d71,bb6a88885fde24835afdaa1c5bb976a1bf5c5d71,Larysa Zaremba,larysa.zaremba@intel.com,1697560077,Daniel Borkmann,daniel@iogearbox.net,1697616508,fb6d11350096d03d673f7389b7922b1484ed85a4,24516309e330cd592c04d0467313d885584af4e8,"selftests/bpf: Add options and frags to xdp_hw_metadata

This is a follow-up to the commit 9b2b86332a9b (""bpf: Allow to use kfunc
XDP hints and frags together"").

The are some possible implementations problems that may arise when providing
metadata specifically for multi-buffer packets"," therefore there must be a
possibility to test such option separately.

Add an option to use multi-buffer AF_XDP xdp_hw_metadata and mark used XDP
program as capable to use frags.

As for now","[' xdp_hw_metadata accepts no options', ' so add simple option\nparsing logic and a help message.\n\nFor quick reference', ' also add an ingress packet generation command to the\nhelp message. The command comes from [0].\n\nExample of output for multi-buffer packet:\n\n  xsk_ring_cons__peek: 1\n  0xead018: rx_desc[15]->addr=10000000000f000 addr=f100 comp_addr=f000\n  rx_hash: 0x5789FCBB with RSS type:0x29\n  rx_timestamp:  1696856851535324697 (sec:1696856851.5353)\n  XDP RX-time:   1696856843158256391 (sec:1696856843.1583)\n  \tdelta sec:-8.3771 (-8377068.306 usec)\n  AF_XDP time:   1696856843158413078 (sec:1696856843.1584)\n  \tdelta sec:0.0002 (156.687 usec)\n  0xead018: complete idx=23 addr=f000\n  xsk_ring_cons__peek: 1\n  0xead018: rx_desc[16]->addr=100000000008000 addr=8100 comp_addr=8000\n  0xead018: complete idx=24 addr=8000\n  xsk_ring_cons__peek: 1\n  0xead018: rx_desc[17]->addr=100000000009000 addr=9100 comp_addr=9000 EoP\n  0xead018: complete idx=25 addr=9000\n\nMetadata is printed for the first packet only.\n\n  [0] https://lore.kernel.org/all/20230119221536.3349901-18-sdf@google.com/\n\nSigned-off-by: Larysa Zaremba <larysa.zaremba@intel.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nLink: https://lore.kernel.org/bpf/20231017162800.24080-1-larysa.zaremba@intel.com\n', '']",Add an option to test XDP hardware metadata with multi-buffer and frags support in selftests.,"XDP, metadata, selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,['xdp like programs']
24516309e330cd592c04d0467313d885584af4e8,24516309e330cd592c04d0467313d885584af4e8,Daniel Borkmann,daniel@iogearbox.net,1697530648,Andrii Nakryiko,andrii@kernel.org,1697572663,5d37875e4ec423afdc1a97121c1576790c5351a3,44cb03f19b38c11cfc5bf76ea6d6885da210ded2,"selftests/bpf: Add additional mprog query test coverage

Add several new test cases which assert corner cases on the mprog query
mechanism", for example,"[' around passing in a too small or a larger array\nthan the current count.\n\n  ./test_progs -t tc_opts\n  #252     tc_opts_after:OK\n  #253     tc_opts_append:OK\n  #254     tc_opts_basic:OK\n  #255     tc_opts_before:OK\n  #256     tc_opts_chain_classic:OK\n  #257     tc_opts_chain_mixed:OK\n  #258     tc_opts_delete_empty:OK\n  #259     tc_opts_demixed:OK\n  #260     tc_opts_detach:OK\n  #261     tc_opts_detach_after:OK\n  #262     tc_opts_detach_before:OK\n  #263     tc_opts_dev_cleanup:OK\n  #264     tc_opts_invalid:OK\n  #265     tc_opts_max:OK\n  #266     tc_opts_mixed:OK\n  #267     tc_opts_prepend:OK\n  #268     tc_opts_query:OK\n  #269     tc_opts_query_attach:OK\n  #270     tc_opts_replace:OK\n  #271     tc_opts_revision:OK\n  Summary: 20/0 PASSED', ' 0 SKIPPED', ' 0 FAILED\n\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nReviewed-by: Alan Maguire <alan.maguire@oracle.com>\nLink: https://lore.kernel.org/bpf/20231017081728.24769-1-daniel@iogearbox.net\n', '']",Add new test cases for mprog query to cover corner cases in selftests for BPF.,"selftests, mprog, query",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
eff65ee26ed73f3ca635bac13c386a4538a608d8,eff65ee26ed73f3ca635bac13c386a4538a608d8,Athira Rajeev,atrajeev@linux.vnet.ibm.com,1697182220,Namhyung Kim,namhyung@kernel.org,1697571651,7a43c152bdec47af92bbd25586fbbadce2e2f73b,47f5693c4ce9b2bf2364303a531423e43278d3b6,"perf tests: Fix shellcheck warning in record_sideband.sh

Running shellcheck on record_sideband.sh throws below
warning:

	In tests/shell/record_sideband.sh line 25:
	  if ! perf record -o ${perfdata} -BN --no-bpf-event -C $1 true 2>&1 >/dev/null
	    ^--^ SC2069: To redirect stdout+stderr"," 2>&1 must be last (or use '{ cmd > file; } 2>&1' to clarify).

This shows shellcheck warning SC2069 where the redirection
order needs to be fixed. Use ""cmd > /dev/null 2>&1"" to fix
the redirection of perf record output

Fixes: 23b97c7ee963 (""perf test: Add test case for record sideband events"")
Signed-off-by: Athira Rajeev <atrajeev@linux.vnet.ibm.com>
Reviewed-by: Kajol Jain <kjain@linux.ibm.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: disgoel@linux.vnet.ibm.com
Link: https://lore.kernel.org/r/20231013073021.99794-3-atrajeev@linux.vnet.ibm.com
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
",[''],Fixes shellcheck warnings by correcting stdout and stderr redirection in record_sideband.sh script.,"shellcheck, redirection, record_sideband.sh",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
44cb03f19b38c11cfc5bf76ea6d6885da210ded2,44cb03f19b38c11cfc5bf76ea6d6885da210ded2,Yafang Shao,laoar.shao@gmail.com,1696687185,Daniel Borkmann,daniel@iogearbox.net,1697560287,0efa05d493d5d29421eaf690db7f32fc5c3cc855,29a7e00ffadddd8d68eff311de1bf12ae10687bb,"selftests/bpf: Add selftest for bpf_task_under_cgroup() in sleepable prog

The result is as follows:

  $ tools/testing/selftests/bpf/test_progs --name=task_under_cgroup
  #237     task_under_cgroup:OK
  Summary: 1/0 PASSED", 0 SKIPPED,"[' 0 FAILED\n\nWithout the previous patch', ' there will be RCU warnings in dmesg when\nCONFIG_PROVE_RCU is enabled. While with the previous patch', ' there will\nbe no warnings.\n\nSigned-off-by: Yafang Shao <laoar.shao@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nLink: https://lore.kernel.org/bpf/20231007135945.4306-2-laoar.shao@gmail.com\n', '']",Added selftest for the bpf_task_under_cgroup function in sleepable program.,"selftest,bpf_task_under_cgroup,sleepable",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
29a7e00ffadddd8d68eff311de1bf12ae10687bb,29a7e00ffadddd8d68eff311de1bf12ae10687bb,Yafang Shao,laoar.shao@gmail.com,1696687184,Daniel Borkmann,daniel@iogearbox.net,1697560061,042ee90bd69658a8806b2ff4324e8c3ef48a6d0b,9a675ba55a96a45a9fb69e6a5c43f80c6682e541,"bpf: Fix missed rcu read lock in bpf_task_under_cgroup()

When employed within a sleepable program not under RCU protection"," the
use of 'bpf_task_under_cgroup()' may trigger a warning in the kernel log","['\nparticularly when CONFIG_PROVE_RCU is enabled:\n\n  [ 1259.662357] WARNING: suspicious RCU usage\n  [ 1259.662358] 6.5.0+ #33 Not tainted\n  [ 1259.662360] -----------------------------\n  [ 1259.662361] include/linux/cgroup.h:423 suspicious rcu_dereference_check() usage!\n\nOther info that might help to debug this:\n\n  [ 1259.662366] rcu_scheduler_active = 2', ' debug_locks = 1\n  [ 1259.662368] 1 lock held by trace/72954:\n  [ 1259.662369]  #0: ffffffffb5e3eda0 (rcu_read_lock_trace){....}-{0:0}', ' at: __bpf_prog_enter_sleepable+0x0/0xb0\n\nStack backtrace:\n\n  [ 1259.662385] CPU: 50 PID: 72954 Comm: trace Kdump: loaded Not tainted 6.5.0+ #33\n  [ 1259.662391] Call Trace:\n  [ 1259.662393]  <TASK>\n  [ 1259.662395]  dump_stack_lvl+0x6e/0x90\n  [ 1259.662401]  dump_stack+0x10/0x20\n  [ 1259.662404]  lockdep_rcu_suspicious+0x163/0x1b0\n  [ 1259.662412]  task_css_set.part.0+0x23/0x30\n  [ 1259.662417]  bpf_task_under_cgroup+0xe7/0xf0\n  [ 1259.662422]  bpf_prog_7fffba481a3bcf88_lsm_run+0x5c/0x93\n  [ 1259.662431]  bpf_trampoline_6442505574+0x60/0x1000\n  [ 1259.662439]  bpf_lsm_bpf+0x5/0x20\n  [ 1259.662443]  ? security_bpf+0x32/0x50\n  [ 1259.662452]  __sys_bpf+0xe6/0xdd0\n  [ 1259.662463]  __x64_sys_bpf+0x1a/0x30\n  [ 1259.662467]  do_syscall_64+0x38/0x90\n  [ 1259.662472]  entry_SYSCALL_64_after_hwframe+0x6e/0xd8\n  [ 1259.662479] RIP: 0033:0x7f487baf8e29\n  [...]\n  [ 1259.662504]  </TASK>\n\nThis issue can be reproduced by executing a straightforward program', ' as\ndemonstrated below:\n\nSEC(""lsm.s/bpf"")\nint BPF_PROG(lsm_run', ' int cmd', ' union bpf_attr *attr', ' unsigned int size)\n{\n        struct cgroup *cgrp = NULL;\n        struct task_struct *task;\n        int ret = 0;\n\n        if (cmd != BPF_LINK_CREATE)\n                return 0;\n\n        // The cgroup2 should be mounted first\n        cgrp = bpf_cgroup_from_id(1);\n        if (!cgrp)\n                goto out;\n        task = bpf_get_current_task_btf();\n        if (bpf_task_under_cgroup(task', ' cgrp))\n                ret = -1;\n        bpf_cgroup_release(cgrp);\n\nout:\n        return ret;\n}\n\nAfter running the program', ' if you subsequently execute another BPF program', ""\nyou will encounter the warning.\n\nIt's worth noting that task_under_cgroup_hierarchy() is also utilized by\nbpf_current_task_under_cgroup(). However"", ' bpf_current_task_under_cgroup()\ndoesn\'t exhibit this issue because it cannot be used in sleepable BPF\nprograms.\n\nFixes: b5ad4cdc46c7 (""bpf: Add bpf_task_under_cgroup() kfunc"")\nSigned-off-by: Yafang Shao <laoar.shao@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Stanislav Fomichev <sdf@google.com>\nCc: Feng Zhou <zhoufeng.zf@bytedance.com>\nCc: KP Singh <kpsingh@kernel.org>\nLink: https://lore.kernel.org/bpf/20231007135945.4306-1-laoar.shao@gmail.com\n', '']",Fixes a missing RCU read lock in bpf_task_under_cgroup for sleepable programs.,"RCU, bpf_task_under_cgroup, fix",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The helper and kfuncs,"['cgroup like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
9a675ba55a96a45a9fb69e6a5c43f80c6682e541,9a675ba55a96a45a9fb69e6a5c43f80c6682e541,Sebastian Andrzej Siewior,bigeasy@linutronix.de,1697461058,Daniel Borkmann,daniel@iogearbox.net,1697547723,c7d9260fe55b9ee3be40aae411dcba0a91556e1f,137df1189d128a6b5dee2f653e054b40ef36b94c,net," bpf: Add a warning if NAPI cb missed xdp_do_flush().

A few drivers were missing a xdp_do_flush() invocation after
XDP_REDIRECT.

Add three helper functions each for one of the per-CPU lists. Return
true if the per-CPU list is non-empty and flush the list.

Add xdp_do_check_flushed() which invokes each helper functions and
creates a warning if one of the functions had a non-empty list.

Hide everything behind CONFIG_DEBUG_NET.

Suggested-by: Jesper Dangaard Brouer <hawk@kernel.org>
Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Reviewed-by: Toke Høiland-Jørgensen <toke@redhat.com>
Acked-by: Jakub Kicinski <kuba@kernel.org>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/bpf/20231016125738.Yt79p1uF@linutronix.de
",[''],Add warning for missed xdp_do_flush invocation in NAPI callbacks for XDP_REDIRECT.,"xdp_do_flush,NAPI,warning",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['xdp like programs']
137df1189d128a6b5dee2f653e054b40ef36b94c,137df1189d128a6b5dee2f653e054b40ef36b94c,Andrii Nakryiko,andrii@kernel.org,1697480920,Daniel Borkmann,daniel@iogearbox.net,1697535800,63414cb538d83336a18287774f062f2f0df1eb2e,a3c2dd96487f1dd734c9443a3472c8dafa689813,"libbpf: Don't assume SHT_GNU_verdef presence for SHT_GNU_versym section

Fix too eager assumption that SHT_GNU_verdef ELF section is going to be
present whenever binary has SHT_GNU_versym section. It seems like either
SHT_GNU_verdef or SHT_GNU_verneed can be used"," so failing on missing
SHT_GNU_verdef actually breaks use cases in production.

One specific reported issue","[' which was used to manually test this fix', '\nwas trying to attach to `readline` function in BASH binary.\n\nFixes: bb7fa09399b9 (""libbpf: Support symbol versioning for uprobe"")\nReported-by: Liam Wisehart <liamwisehart@meta.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nTested-by: Manu Bretelle <chantr4@gmail.com>\nReviewed-by: Fangrui Song <maskray@google.com>\nAcked-by: Hengqi Chen <hengqi.chen@gmail.com>\nLink: https://lore.kernel.org/bpf/20231016182840.4033346-1-andrii@kernel.org\n', '']",Fix assumption regarding SHT_GNU_verdef and SHT_GNU_versym ELF sections in libbpf.,"SHT_GNU_verdef,SHT_GNU_versym,libbpf",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,"[""It's not related to any of the above.""]"
a3c2dd96487f1dd734c9443a3472c8dafa689813,a3c2dd96487f1dd734c9443a3472c8dafa689813,Jakub Kicinski,kuba@kernel.org,1697515532,Jakub Kicinski,kuba@kernel.org,1697515533,8e8df48280355e3bcd331ab12aeafb0121970cf0,90de47f020db086f7929e09f64efd0cf627d6869 99c9991f4e5d77328187187d0c921a3b62bfa998,"Merge tag 'for-netdev' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next

Daniel Borkmann says:

====================
pull-request: bpf-next 2023-10-16

We've added 90 non-merge commits during the last 25 day(s) which contain
a total of 120 files changed", 3519 insertions(+),"[' 895 deletions(-).\n\nThe main changes are:\n\n1) Add missed stats for kprobes to retrieve the number of missed kprobe\n   executions and subsequent executions of BPF programs', ' from Jiri Olsa.\n\n2) Add cgroup BPF sockaddr hooks for unix sockets. The use case is\n   for systemd to reimplement the LogNamespace feature which allows\n   running multiple instances of systemd-journald to process the logs\n   of different services', ' from Daan De Meyer.\n\n3) Implement BPF CPUv4 support for s390x BPF JIT', ' from Ilya Leoshkevich.\n\n4) Improve BPF verifier log output for scalar registers to better\n   disambiguate their internal state wrt defaults vs min/max values\n   matching', ' from Andrii Nakryiko.\n\n5) Extend the BPF fib lookup helpers for IPv4/IPv6 to support retrieving\n   the source IP address with a new BPF_FIB_LOOKUP_SRC flag', '\n   from Martynas Pumputis.\n\n6) Add support for open-coded task_vma iterator to help with symbolization\n   for BPF-collected user stacks', ' from Dave Marchevsky.\n\n7) Add libbpf getters for accessing individual BPF ring buffers which\n   is useful for polling them individually', ' for example', ' from Martin Kelly.\n\n8) Extend AF_XDP selftests to validate the SHARED_UMEM feature', '\n   from Tushar Vyavahare.\n\n9) Improve BPF selftests cross-building support for riscv arch', '\n   from Björn Töpel.\n\n10) Add the ability to pin a BPF timer to the same calling CPU', ""\n   from David Vernet.\n\n11) Fix libbpf's bpf_tracing.h macros for riscv to use the generic\n   implementation of PT_REGS_SYSCALL_REGS() to access syscall arguments"", '\n   from Alexandre Ghiti.\n\n12) Extend libbpf to support symbol versioning for uprobes', "" from Hengqi Chen.\n\n13) Fix bpftool's skeleton code generation to guarantee that ELF data\n    is 8 byte aligned"", ' from Ian Rogers.\n\n14) Inherit system-wide cpu_mitigations_off() setting for Spectre v1/v4\n    security mitigations in BPF verifier', ' from Yafang Shao.\n\n15) Annotate struct bpf_stack_map with __counted_by attribute to prepare\n    BPF side for upcoming __counted_by compiler support', ' from Kees Cook.\n\n* tag \'for-netdev\' of https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next: (90 commits)\n  bpf: Ensure proper register state printing for cond jumps\n  bpf: Disambiguate SCALAR register state output in verifier logs\n  selftests/bpf: Make align selftests more robust\n  selftests/bpf: Improve missed_kprobe_recursion test robustness\n  selftests/bpf: Improve percpu_alloc test robustness\n  selftests/bpf: Add tests for open-coded task_vma iter\n  bpf: Introduce task_vma open-coded iterator kfuncs\n  selftests/bpf: Rename bpf_iter_task_vma.c to bpf_iter_task_vmas.c\n  bpf: Don\'t explicitly emit BTF for struct btf_iter_num\n  bpf: Change syscall_nr type to int in struct syscall_tp_t\n  net/bpf: Avoid unused ""sin_addr_len"" warning when CONFIG_CGROUP_BPF is not set\n  bpf: Avoid unnecessary audit log for CPU security mitigations\n  selftests/bpf: Add tests for cgroup unix socket address hooks\n  selftests/bpf: Make sure mount directory exists\n  documentation/bpf: Document cgroup unix socket address hooks\n  bpftool: Add support for cgroup unix socket address hooks\n  libbpf: Add support for cgroup unix socket address hooks\n  bpf: Implement cgroup sockaddr hooks for unix sockets\n  bpf: Add bpf_sock_addr_set_sun_path() to allow writing unix sockaddr from bpf\n  bpf: Propagate modified uaddrlen from cgroup sockaddr programs\n  ...\n====================\n\nLink: https://lore.kernel.org/r/20231016204803.30153-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n', '']",Merged 90 non-merge commits from the 'bpf-next' branch containing 120 files changed.,"merge,bpf-next,files",It's other type of commit.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
54a59aed395ce0f4177b5212e5746a6462de3ad9,54a59aed395ce0f4177b5212e5746a6462de3ad9,Daniel Borkmann,daniel@iogearbox.net,1696843614,Jakub Kicinski,kuba@kernel.org,1697476056,52bd084eaf68223e5246f2b4b859cb567608f65a,dccce1d7c04051bc25d3abbe7716d0ae7af9c28a,net," sched: Make tc-related drop reason more flexible

Currently","[' the kfree_skb_reason() in sch_handle_{ingress', 'egress}() can only\nexpress a basic SKB_DROP_REASON_TC_INGRESS or SKB_DROP_REASON_TC_EGRESS reason.\n\nVictor kicked-off an initial proposal to make this more flexible by disambiguating\nverdict from return code by moving the verdict into struct tcf_result and\nletting tcf_classify() return a negative error. If hit', ' then two new drop\nreasons were added in the proposal', ' that is SKB_DROP_REASON_TC_INGRESS_ERROR\nas well as SKB_DROP_REASON_TC_EGRESS_ERROR. Further analysis of the actual\nerror codes would have required to attach to tcf_classify via kprobe/kretprobe\nto more deeply debug skb and the returned error.\n\nIn order to make the kfree_skb_reason() in sch_handle_{ingress', 'egress}() more\nextensible', ' it can be addressed in a more straight forward way', ' that is: Instead\nof placing the verdict into struct tcf_result', ' we can just put the drop reason\nin there', ' which does not require changes throughout various classful schedulers\ngiven the existing verdict logic can stay as is.\n\nThen', ' SKB_DROP_REASON_TC_ERROR{', '_*} can be added to the enum skb_drop_reason\nto disambiguate between an error or an intentional drop. New drop reason error\ncodes can be added successively to the tc code base.\n\nFor internal error locations which have not yet been annotated with a\nSKB_DROP_REASON_TC_ERROR{', '_*}', ' the fallback is SKB_DROP_REASON_TC_INGRESS and\nSKB_DROP_REASON_TC_EGRESS', ' respectively. Generic errors could be marked with a\nSKB_DROP_REASON_TC_ERROR code until they are converted to more specific ones\nif it is found that they would be useful for troubleshooting.\n\nWhile drop reasons have infrastructure for subsystem specific error codes which\nare currently used by mac80211 and ovs', ' Jakub mentioned that it is preferred\nfor tc to use the enum skb_drop_reason core codes given it is a better fit and\ncurrently the tooling support is better', "" too.\n\nWith regards to the latter:\n\n  [...] I think Alastair (bpftrace) is working on auto-prettifying enums when\n  bpftrace outputs maps. So we can do something like:\n\n  $ bpftrace -e 'tracepoint:skb:kfree_skb { @[args->reason] = count(); }'\n  Attaching 1 probe...\n  ^C\n\n  @[SKB_DROP_REASON_TC_INGRESS]: 2\n  @[SKB_CONSUMED]: 34\n\n  ^^^^^^^^^^^^ names!!\n\n  Auto-magically. [...]\n\nAdd a small helper tcf_set_drop_reason() which can be used to set the drop reason\ninto the tcf_result.\n\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nCc: Jamal Hadi Salim <jhs@mojatatu.com>\nCc: Victor Nogueira <victor@mojatatu.com>\nLink: https://lore.kernel.org/netdev/20231006063233.74345d36@kernel.org\nReviewed-by: Jakub Kicinski <kuba@kernel.org>\nLink: https://lore.kernel.org/r/20231009092655.22025-1-daniel@iogearbox.net\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>\n"", '']",Refactor tc-related drop reasons for increased flexibility in network scheduling.,tc drop flexible,It's a cleanup or refactoring in the code.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['tc/netfilter like programs']
99c9991f4e5d77328187187d0c921a3b62bfa998,99c9991f4e5d77328187187d0c921a3b62bfa998,Daniel Borkmann,daniel@iogearbox.net,1697456958,Daniel Borkmann,daniel@iogearbox.net,1697456981,d014e32adee15b58cb3d80b86c39d4cb09c90a7d,0e10fd4b7a6dd03cf6d1da293d5d50082917f0e0 1a8a315f008a58f54fecb012b928aa6a494435b3,"Merge branch 'bpf-log-improvements'

Andrii Nakryiko says:

====================
This patch set fixes ambiguity in BPF verifier log output of SCALAR register
in the parts that emit umin/umax", smin/smax,"[' etc ranges. See patch #4 for\ndetails.\n\nAlso', "" patch #5 fixes an issue with verifier log missing instruction context\n(state) output for conditionals that trigger precision marking. See details in\nthe patch.\n\nFirst two patches are just improvements to two selftests that are very flaky\nlocally when run in parallel mode.\n\nPatch #3 changes 'align' selftest to be less strict about exact verifier log\noutput (which patch #4 changes"", ' breaking lots of align tests as written). Now\ntest does more of a register substate checks', "" mostly around expected var_off()\nvalues. This 'align' selftests is one of the more brittle ones and requires\nconstant adjustment when verifier log output changes"", ' without really catching\nany new issues. So hopefully these changes can minimize future support efforts\nfor this specific set of tests.\n====================\n\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\n', '']",Improves BPF verifier log output for scalar register to fix umin/umax ambiguity.,"BPF verifier, log, scalar",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
1a8a315f008a58f54fecb012b928aa6a494435b3,1a8a315f008a58f54fecb012b928aa6a494435b3,Andrii Nakryiko,andrii@kernel.org,1697063848,Daniel Borkmann,daniel@iogearbox.net,1697456958,d014e32adee15b58cb3d80b86c39d4cb09c90a7d,72f8a1de4a7ecb23393a920dface58d5a96f42d8,"bpf: Ensure proper register state printing for cond jumps

Verifier emits relevant register state involved in any given instruction
next to it after `;` to the right", if possible. Or,"[' worst case', ' on the\nseparate line repeating instruction index.\n\nE.g.', ' a nice and simple case would be:\n\n  2: (d5) if r0 s<= 0x0 goto pc+1       ; R0_w=0\n\nBut if there is some intervening extra output (e.g.', ' precision\nbacktracking log) involved', ' we are supposed to see the state after the\nprecision backtrack log:\n\n  4: (75) if r0 s>= 0x0 goto pc+1\n  mark_precise: frame0: last_idx 4 first_idx 0 subseq_idx -1\n  mark_precise: frame0: regs=r0 stack= before 2: (d5) if r0 s<= 0x0 goto pc+1\n  mark_precise: frame0: regs=r0 stack= before 1: (b7) r0 = 0\n  6: R0_w=0\n\nFirst off', ' note that in `6: R0_w=0` instruction index corresponds to the\nnext instruction', ' not to the conditional jump instruction itself', "" which\nis wrong and we'll get to that.\n\nBut besides that"", ' the above is a happy case that does work today. Yet', '\nif it so happens that precision backtracking had to traverse some of the\nparent states', ' this `6: R0_w=0` state output would be missing.\n\nThis is due to a quirk of print_verifier_state() routine', ' which performs\nmark_verifier_state_clean(env) at the end. This marks all registers as\n""non-scratched""', ' which means that subsequent logic to print *relevant*\nregisters (that is', ' ""scratched ones"") fails and doesn\'t see anything\nrelevant to print and skips the output altogether.\n\nprint_verifier_state() is used both to print instruction context', ' but\nalso to print an **entire** verifier state indiscriminately', ' e.g.', '\nduring precision backtracking (and in a few other situations', ' like\nduring entering or exiting subprogram).  Which means if we have to print\nentire parent state before getting to printing instruction context\nstate', ' instruction context is marked as clean and is omitted.\n\nLong story short', ' this is definitely not intentional. So we fix this\nbehavior in this patch by teaching print_verifier_state() to clear\nscratch state only if it was used to print instruction state', ' not the\nparent/callback state. This is determined by print_all option', "" so if\nit's not set"", "" we don't clear scratch state. This fixes missing\ninstruction state for these cases.\n\nAs for the mismatched instruction index"", ' we fix that by making sure we\ncall print_insn_state() early inside check_cond_jmp_op() before we\nadjusted insn_idx based on jump branch taken logic. And with that we get\ndesired correct information:\n\n  9: (16) if w4 == 0x1 goto pc+9\n  mark_precise: frame0: last_idx 9 first_idx 9 subseq_idx -1\n  mark_precise: frame0: parent state regs=r4 stack=: R2_w=1944 R4_rw=P1 R10=fp0\n  mark_precise: frame0: last_idx 8 first_idx 0 subseq_idx 9\n  mark_precise: frame0: regs=r4 stack= before 8: (66) if w4 s> 0x3 goto pc+5\n  mark_precise: frame0: regs=r4 stack= before 7: (b7) r4 = 1\n  9: R4=1\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/bpf/20231011223728.3188086-6-andrii@kernel.org\n', '']",Ensure correct register state printing for conditional jumps in the eBPF verifier.,"register, verifier, cond jumps",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
72f8a1de4a7ecb23393a920dface58d5a96f42d8,72f8a1de4a7ecb23393a920dface58d5a96f42d8,Andrii Nakryiko,andrii@kernel.org,1697063847,Daniel Borkmann,daniel@iogearbox.net,1697456958,b730458fbe6bbbdc115084173c05a75e00b835d4,cde785142885e1fc62a9ae92e7aae90285ed3d79,"bpf: Disambiguate SCALAR register state output in verifier logs

Currently the way that verifier prints SCALAR_VALUE register state (and
PTR_TO_PACKET"," which can have var_off and ranges info as well) is very
ambiguous.

In the name of brevity we are trying to eliminate ""unnecessary"" output
of umin/umax","[' smin/smax', ' u32_min/u32_max', ' and s32_min/s32_max values', ' if\npossible. Current rules are that if any of those have their default\nvalue (which for mins is the minimal value of its respective types: 0', '\nS32_MIN', ' or S64_MIN', "" while for maxs it's U32_MAX"", ' S32_MAX', ' S64_MAX', ' or\nU64_MAX) *OR* if there is another min/max value that as matching value.\nE.g.', ' if smin=100 and umin=100', "" we'll emit only umin=10"", ' omitting smin\naltogether. This approach has a few problems', ' being both ambiguous and\nsort-of incorrect in some cases.\n\nAmbiguity is due to missing value could be either default value or value\nof umin/umax or smin/smax. This is especially confusing when we mix\nsigned and unsigned ranges. Quite often', ' umin=0 and smin=0', "" and so we'll\nhave only `umin=0` leaving anyone reading verifier log to guess whether\nsmin is actually 0 or it's actually -9223372036854775808 (S64_MIN). And\noften times it's important to know"", ' especially when debugging tricky\nissues.\n\n""Sort-of incorrectness"" comes from mixing negative and positive values.\nE.g.', ' if umin is some large positive number', ' it can be equal to smin\nwhich is', ' interpreted as signed value', ' is actually some negative value.\nCurrently', ' that smin will be omitted and only umin will be emitted with\na large positive value', ' giving an impression that smin is also positive.\n\nAnyway', ' ambiguity is the biggest issue making it impossible to have an\nexact understanding of register state', ' preventing any sort of automated\ntesting of verifier state based on verifier log. This patch is\nattempting to rectify the situation by removing ambiguity', ' while\nminimizing the verboseness of register state output.\n\nThe rules are straightforward:\n  - if some of the values are missing', ' then it definitely has a default\n  value. I.e.', ' `umin=0` means that umin is zero', ' but smin is actually\n  S64_MIN;\n  - all the various boundaries that happen to have the same value are\n  emitted in one equality separated sequence. E.g.', ' if umin and smin are\n  both 100', "" we'll emit `smin=umin=100`"", ' making this explicit;\n  - we do not mix negative and positive values together', ' and even if\n  they happen to have the same bit-level value', ' they will be emitted\n  separately with proper sign. I.e.', ' if both umax and smax happen to be\n  0xffffffffffffffff', "" we'll emit them both separately as\n  `smax=-1"", 'umax=18446744073709551615`;\n  - in the name of a bit more uniformity and consistency', '\n  {u32', 's32}_{min', 'max} are renamed to {s', 'u}{min', 'max}32', ' which seems to\n  improve readability.\n\nThe above means that in case of all 4 ranges being', ' say', ' [50', ' 100] range', ""\nwe'd previously see hugely ambiguous:\n\n    R1=scalar(umin=50"", 'umax=100)\n\nNow', "" we'll be more explicit:\n\n    R1=scalar(smin=umin=smin32=umin32=50"", 'smax=umax=smax32=umax32=100)\n\nThis is slightly more verbose', "" but distinct from the case when we don't\nknow anything about signed boundaries and 32-bit boundaries"", ' which under\nnew rules will match the old case:\n\n    R1=scalar(umin=50', 'umax=100)\n\nAlso', ' in the name of simplicity of implementation and consistency', ' order\nfor {s', 'u}32_{min', 'max} are emitted *before* var_off. Previously they were\nemitted afterwards', ' for unclear reasons.\n\nThis patch also includes a few fixes to selftests that expect exact\nregister state to accommodate slight changes to verifier format. You can\nsee that the changes are pretty minimal in common cases.\n\nNote', "" the special case when SCALAR_VALUE register is a known constant\nisn't changed"", "" we'll emit constant value once"", ' interpreted as signed\nvalue.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/bpf/20231011223728.3188086-5-andrii@kernel.org\n', '']",Improve the clarity of SCALAR register state outputs in bpf verifier logs.,"verifier, SCALAR, disambiguate",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF verifier,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
cde785142885e1fc62a9ae92e7aae90285ed3d79,cde785142885e1fc62a9ae92e7aae90285ed3d79,Andrii Nakryiko,andrii@kernel.org,1697063846,Daniel Borkmann,daniel@iogearbox.net,1697456958,76e6915d8e60cff8dde4f818c88c23fd6e632712,08a7078feacf419305d86d36b974c48347f3abb0,"selftests/bpf: Make align selftests more robust

Align subtest is very specific and finicky about expected verifier log
output and format. This is often completely unnecessary as in a bunch of
situations test actually cares about var_off part of register state. But
given how exact it is right now"," any tiny verifier log changes can lead
to align tests failures","[' requiring constant adjustment.\n\nThis patch tries to make this a bit more robust by making logic first\nsearch for specified register and then allowing to match only portion of\nregister state', ' not everything exactly. This will come handly with\nfollow up changes to SCALAR register output disambiguation.\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nAcked-by: Eduard Zingerman <eddyz87@gmail.com>\nLink: https://lore.kernel.org/bpf/20231011223728.3188086-4-andrii@kernel.org\n', '']",Improves robustness of align selftests by focusing on var_off part of register state in verifier logs.,"selftests, align, verifier",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
08a7078feacf419305d86d36b974c48347f3abb0,08a7078feacf419305d86d36b974c48347f3abb0,Andrii Nakryiko,andrii@kernel.org,1697063845,Daniel Borkmann,daniel@iogearbox.net,1697456958,c881e184693c4e36f3bd40fee50138a1b21bff77,2d78928c9cf7bee08c3e2344e6e1755412855448,"selftests/bpf: Improve missed_kprobe_recursion test robustness

Given missed_kprobe_recursion is non-serial and uses common testing
kfuncs to count number of recursion misses it's possible that some other
parallel test can trigger extraneous recursion misses. So we can't
expect exactly 1 miss. Relax conditions and expect at least one.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Jiri Olsa <jolsa@kernel.org>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/bpf/20231011223728.3188086-3-andrii@kernel.org
",,Improves robustness of missed_kprobe_recursion test by relaxing conditions on recursion misses.,"robustness,test,recursion",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,['kprobe/uprobe/ftrace like programs']
2d78928c9cf7bee08c3e2344e6e1755412855448,2d78928c9cf7bee08c3e2344e6e1755412855448,Andrii Nakryiko,andrii@kernel.org,1697063844,Daniel Borkmann,daniel@iogearbox.net,1697456958,d94e87cd0f8b942aabce0c87eff573704774dd01,0e10fd4b7a6dd03cf6d1da293d5d50082917f0e0,"selftests/bpf: Improve percpu_alloc test robustness

Make these non-serial tests filter BPF programs by intended PID of
a test runner process. This makes it isolated from other parallel tests
that might interfere accidentally.

Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: John Fastabend <john.fastabend@gmail.com>
Acked-by: Eduard Zingerman <eddyz87@gmail.com>
Link: https://lore.kernel.org/bpf/20231011223728.3188086-2-andrii@kernel.org
",,The commit improves robustness of the percpu_alloc test by isolating BPF programs using intended PID to avoid interference.,"percpu_alloc, BPF programs, robustness",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
0e10fd4b7a6dd03cf6d1da293d5d50082917f0e0,0e10fd4b7a6dd03cf6d1da293d5d50082917f0e0,Andrii Nakryiko,andrii@kernel.org,1697237339,Andrii Nakryiko,andrii@kernel.org,1697237369,f8e5d4265acfb8d1a0d074ca8188cbd8e86c4105,ba8ea72388a192c10f1ee5f5a4a32332e7cced76 e0e1a7a5fc377d54bd792c6368a375d41fc316ef,"Merge branch 'Open-coded task_vma iter'

Dave Marchevsky says:

====================
At Meta we have a profiling daemon which periodically collects
information on many hosts. This collection usually involves grabbing
stacks (user and kernel) using perf_event BPF progs and later symbolicating
them. For user stacks we try to use BPF_F_USER_BUILD_ID and rely on
remote symbolication"," but BPF_F_USER_BUILD_ID doesn't always succeed. In
those cases we must fall back to digging around in /proc/PID/maps to map
virtual address to (binary","[' offset). The /proc/PID/maps digging does not\noccur synchronously with stack collection', ' so the process might already\nbe gone', "" in which case it won't have /proc/PID/maps and we will fail to\nsymbolicate.\n\nThis 'exited process problem' doesn't occur very often as\nmost of the prod services we care to profile are long-lived daemons"", ' but\nthere are enough usecases to warrant a workaround: a BPF program which\ncan be optionally loaded at data collection time and essentially walks\n/proc/PID/maps. Currently this is done by walking the vma list:\n\n  struct vm_area_struct* mmap = BPF_CORE_READ(mm', ' mmap);\n  mmap_next = BPF_CORE_READ(rmap', ' vm_next); /* in a loop */\n\nSince commit 763ecb035029 (""mm: remove the vma linked list"") there\'s no\nlonger a vma linked list to walk. Walking the vma maple tree is not as\nsimple as hopping struct vm_area_struct->vm_next. Luckily', '\ncommit f39af05949a4 (""mm: add VMA iterator"")', ' another commit in that series', '\nadded struct vma_iterator and for_each_vma macro for easy vma iteration. If\nsimilar functionality was exposed to BPF programs', ' it would be perfect for our\nusecase.\n\nThis series adds such functionality', ' specifically a BPF equivalent of\nfor_each_vma using the open-coded iterator style.\n\nNotes:\n  * This approach was chosen after discussion on a previous series [0] which\n    attempted to solve the same problem by adding a BPF_F_VMA_NEXT flag to\n    bpf_find_vma.\n  * Unlike the task_vma bpf_iter', "" the open-coded iterator kfuncs here do not\n    drop the vma read lock between iterations. See Alexei's response in [0].\n  * The [vsyscall] page isn't really part of task->mm's vmas"", ' but\n    /proc/PID/maps returns information about it anyways. The vma iter added\n    here does not do the same. See comment on selftest in patch 3.\n  * bpf_iter_task_vma allocates a _data struct which contains - among other\n    things - struct vma_iterator', ' using BPF allocator and keeps a pointer to\n    the bpf_iter_task_vma_data. This is done in order to prevent changes to\n    struct ma_state - which is wrapped by struct vma_iterator - from\n    necessitating changes to uapi struct bpf_iter_task_vma.\n\nChangelog:\n\nv6 -> v7: https://lore.kernel.org/bpf/20231010185944.3888849-1-davemarchevsky@fb.com/\n\nPatch numbers correspond to their position in v6\n\nPatch 2 (""selftests/bpf: Rename bpf_iter_task_vma.c to bpf_iter_task_vmas.c"")\n  * Add Andrii ack\nPatch 3 (""bpf: Introduce task_vma open-coded iterator kfuncs"")\n  * Add Andrii ack\n  * Add missing __diag_ignore_all for -Wmissing-prototypes (Song)\nPatch 4 (""selftests/bpf: Add tests for open-coded task_vma iter"")\n  * Remove two unnecessary header includes (Andrii)\n  * Remove extraneous !vmas_seen check (Andrii)\nNew Patch (""bpf: Add BPF_KFUNC_{START', 'END}_defs macros"")\n  * After talking to Andrii', ' this is an attempt to clean up __diag_ignore_all\n    spam everywhere kfuncs are defined. If nontrivial changes are needed', '\n    let\'s apply the other 4 and I\'ll respin as a standalone patch.\n\nv5 -> v6: https://lore.kernel.org/bpf/20231010175637.3405682-1-davemarchevsky@fb.com/\n\nPatch 4 (""selftests/bpf: Add tests for open-coded task_vma iter"")\n  * Remove extraneous blank line. I did this manually to the .patch file\n    for v5', ' which caused BPF CI to complain about failing to apply the\n    series\n\nv4 -> v5: https://lore.kernel.org/bpf/20231002195341.2940874-1-davemarchevsky@fb.com/\n\nPatch numbers correspond to their position in v4\n\nNew Patch (""selftests/bpf: Rename bpf_iter_task_vma.c to bpf_iter_task_vmas.c"")\n  * Patch 2\'s renaming of this selftest', ' and associated changes in the\n    userspace runner', ' are split out into this separate commit (Andrii)\n\nPatch 2 (""bpf: Introduce task_vma open-coded iterator kfuncs"")\n  * Remove bpf_iter_task_vma kfuncs from libbpf\'s bpf_helpers.h', ' they\'ll be\n    added to selftests\' bpf_experimental.h in selftests patch below (Andrii)\n  * Split bpf_iter_task_vma.c renaming into separate commit (Andrii)\n\nPatch 3 (""selftests/bpf: Add tests for open-coded task_vma iter"")\n  * Add bpf_iter_task_vma kfuncs to bpf_experimental.h (Andrii)\n  * Remove \'?\' from prog SEC', ' open_and_load the skel in one operation (Andrii)\n  * Ensure that fclose() always happens in test runner (Andrii)\n  * Use global var w/ 1000 (vm_start', ' vm_end) structs instead of two\n    MAP_TYPE_ARRAY\'s w/ 1k u64s each (Andrii)\n\nv3 -> v4: https://lore.kernel.org/bpf/20230822050558.2937659-1-davemarchevsky@fb.com/\n\nPatch 1 (""bpf: Don\'t explicitly emit BTF for struct btf_iter_num"")\n  * Add Andrii ack\nPatch 2 (""bpf: Introduce task_vma open-coded iterator kfuncs"")\n  * Mark bpf_iter_task_vma_new args KF_RCU and remove now-unnecessary !task\n    check (Yonghong)\n    * Although KF_RCU is a function-level flag', ' in reality it only applies to\n      the task_struct *task parameter', ' as the other two params are a scalar int\n      and a specially-handled KF_ARG_PTR_TO_ITER\n   * Remove struct bpf_iter_task_vma definition from uapi headers', ' define in\n     kernel/bpf/task_iter.c instead (Andrii)\nPatch 3 (""selftests/bpf: Add tests for open-coded task_vma iter"")\n  * Use a local var when looping over vmas to track map idx. Update vmas_seen\n    global after done iterating. Don\'t start iterating or update vmas_seen if\n    vmas_seen global is nonzero. (Andrii)\n  * Move getpgid() call to correct spot - above skel detach. (Andrii)\n\nv2 -> v3: https://lore.kernel.org/bpf/20230821173415.1970776-1-davemarchevsky@fb.com/\n\nPatch 1 (""bpf: Don\'t explicitly emit BTF for struct btf_iter_num"")\n  * Add Yonghong ack\n\nPatch 2 (""bpf: Introduce task_vma open-coded iterator kfuncs"")\n  * UAPI bpf header and tools/ version should match\n  * Add bpf_iter_task_vma_kern_data which bpf_iter_task_vma_kern points to', ""\n    bpf_mem_alloc/free it instead of just vma_iterator. (Alexei)\n    * Inner data ptr == NULL implies initialization failed\n\nv1 -> v2: https://lore.kernel.org/bpf/20230810183513.684836-1-davemarchevsky@fb.com/\n  * Patch 1\n    * Now removes the unnecessary BTF_TYPE_EMIT instead of changing the\n      type (Yonghong)\n  * Patch 2\n    * Don't do unnecessary BTF_TYPE_EMIT (Yonghong)\n    * Bump task refcount to prevent ->mm reuse (Yonghong)\n    * Keep a pointer to vma_iterator in bpf_iter_task_vma"", ' alloc/free\n      via BPF mem allocator (Yonghong', ' Stanislav)\n  * Patch 3\n\n  [0]: https://lore.kernel.org/bpf/20230801145414.418145-1-davemarchevsky@fb.com/\n====================\n\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\n', '']",Integration of 'Open-coded task_vma iter' for improved profiling with perf_event BPF programs.,"profiling, perf_event, task_vma",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['profile like programs']
e0e1a7a5fc377d54bd792c6368a375d41fc316ef,e0e1a7a5fc377d54bd792c6368a375d41fc316ef,Dave Marchevsky,davemarchevsky@fb.com,1697229865,Andrii Nakryiko,andrii@kernel.org,1697237338,f8e5d4265acfb8d1a0d074ca8188cbd8e86c4105,4ac4546821584736798aaa9e97da9f6eaf689ea3,"selftests/bpf: Add tests for open-coded task_vma iter

The open-coded task_vma iter added earlier in this series allows for
natural iteration over a task's vmas using existing open-coded iter
infrastructure"," specifically bpf_for_each.

This patch adds a test demonstrating this pattern and validating
correctness. The vma->vm_start and vma->vm_end addresses of the first
1000 vmas are recorded and compared to /proc/PID/maps output. As
expected","[' both see the same vmas and addresses - with the exception of\nthe [vsyscall] vma - which is explained in a comment in the prog_tests\nprogram.\n\nSigned-off-by: Dave Marchevsky <davemarchevsky@fb.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20231013204426.1074286-5-davemarchevsky@fb.com\n', '']",This commit adds tests for open-coded task_vma iterator in selftests/bpf.,"task_vma, iterator, selftests",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['tracepoints like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
4ac4546821584736798aaa9e97da9f6eaf689ea3,4ac4546821584736798aaa9e97da9f6eaf689ea3,Dave Marchevsky,davemarchevsky@fb.com,1697229864,Andrii Nakryiko,andrii@kernel.org,1697237338,afa500eeb71da22784f72b1caa74a3b47dc35319,45b38941c81f16bb2e9b0115f03e164a3576ea8b,"bpf: Introduce task_vma open-coded iterator kfuncs

This patch adds kfuncs bpf_iter_task_vma_{new",next,"[""destroy} which allow\ncreation and manipulation of struct bpf_iter_task_vma in open-coded\niterator style. BPF programs can use these kfuncs directly or through\nbpf_for_each macro for natural-looking iteration of all task vmas.\n\nThe implementation borrows heavily from bpf_find_vma helper's locking -\ndiffering only in that it holds the mmap_read lock for all iterations\nwhile the helper only executes its provided callback on a maximum of 1\nvma. Aside from locking"", ' struct vma_iterator and vma_next do all the\nheavy lifting.\n\nA pointer to an inner data struct', ' struct bpf_iter_task_vma_data', ' is the\nonly field in struct bpf_iter_task_vma. This is because the inner data\nstruct contains a struct vma_iterator (not ptr)', "" whose size is likely to\nchange under us. If bpf_iter_task_vma_kern contained vma_iterator directly\nsuch a change would require change in opaque bpf_iter_task_vma struct's\nsize. So better to allocate vma_iterator using BPF allocator"", ' and since\nthat alloc must already succeed', ' might as well allocate all iter fields', '\nthereby freezing struct bpf_iter_task_vma size.\n\nSigned-off-by: Dave Marchevsky <davemarchevsky@fb.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20231013204426.1074286-4-davemarchevsky@fb.com\n', '']",Introduces task_vma open-coded iterator kernel functions for BPF.,"task_vma, iterator, kfuncs",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,['other']
45b38941c81f16bb2e9b0115f03e164a3576ea8b,45b38941c81f16bb2e9b0115f03e164a3576ea8b,Dave Marchevsky,davemarchevsky@fb.com,1697229863,Andrii Nakryiko,andrii@kernel.org,1697237338,a34707d943d092d59b5be69f83e88add89bc27f9,f10ca5da5bd71e5cefed7995e75a7c873ce3816e,"selftests/bpf: Rename bpf_iter_task_vma.c to bpf_iter_task_vmas.c

Further patches in this series will add a struct bpf_iter_task_vma","
which will result in a name collision with the selftest prog renamed in
this patch. Rename the selftest to avoid the collision.

Signed-off-by: Dave Marchevsky <davemarchevsky@fb.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Acked-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/20231013204426.1074286-3-davemarchevsky@fb.com
",[''],Rename bpf_iter_task_vma.c to bpf_iter_task_vmas.c to avoid name collision with future patches in selftests.,"rename,selftests,collision",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
f10ca5da5bd71e5cefed7995e75a7c873ce3816e,f10ca5da5bd71e5cefed7995e75a7c873ce3816e,Dave Marchevsky,davemarchevsky@fb.com,1697229862,Andrii Nakryiko,andrii@kernel.org,1697237338,4c7ea8cb4ca5de5d5dab49142931fc55b0794e33,ba8ea72388a192c10f1ee5f5a4a32332e7cced76,"bpf: Don't explicitly emit BTF for struct btf_iter_num

Commit 6018e1f407cc (""bpf: implement numbers iterator"") added the
BTF_TYPE_EMIT line that this patch is modifying. The struct btf_iter_num
doesn't exist"," so only a forward declaration is emitted in BTF:

  FWD 'btf_iter_num' fwd_kind=struct

That commit was probably hoping to ensure that struct bpf_iter_num is
emitted in vmlinux BTF. A previous version of this patch changed the
line to emit the correct type","[' but Yonghong confirmed that it would\ndefinitely be emitted regardless in [0]', ' so this patch simply removes\nthe line.\n\nThis isn\'t marked ""Fixes"" because the extraneous btf_iter_num FWD wasn\'t\ncausing any issues that I noticed', ' aside from mild confusion when I\nlooked through the code.\n\n  [0]: https://lore.kernel.org/bpf/25d08207-43e6-36a8-5e0f-47a913d4cda5@linux.dev/\n\nSigned-off-by: Dave Marchevsky <davemarchevsky@fb.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Yonghong Song <yonghong.song@linux.dev>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nLink: https://lore.kernel.org/bpf/20231013204426.1074286-2-davemarchevsky@fb.com\n', '']",The commit modifies BTF emission for struct btf_iter_num to only emit a forward declaration.,"BTF, emit, forward declaration",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The BPF Type Format (BTF),"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
ba8ea72388a192c10f1ee5f5a4a32332e7cced76,ba8ea72388a192c10f1ee5f5a4a32332e7cced76,Artem Savkov,asavkov@redhat.com,1697175739,Andrii Nakryiko,andrii@kernel.org,1697225976,f6b556d3e5fb7351d63c793c75e30def44909994,9c1292eca243821249fa99f40175b0660d9329e3,"bpf: Change syscall_nr type to int in struct syscall_tp_t

linux-rt-devel tree contains a patch (b1773eac3f29c (""sched: Add support
for lazy preemption"")) that adds an extra member to struct trace_entry.
This causes the offset of args field in struct trace_event_raw_sys_enter
be different from the one in struct syscall_trace_enter:

struct trace_event_raw_sys_enter {
        struct trace_entry         ent;                  /*     0    12 */

        /* XXX last struct has 3 bytes of padding */
        /* XXX 4 bytes hole"," try to pack */

        long int                   id;                   /*    16     8 */
        long unsigned int          args[6];              /*    24    48 */
        /* --- cacheline 1 boundary (64 bytes) was 8 bytes ago --- */
        char                       __data[];             /*    72     0 */

        /* size: 72","[' cachelines: 2', ' members: 4 */\n        /* sum members: 68', ' holes: 1', ' sum holes: 4 */\n        /* paddings: 1', ' sum paddings: 3 */\n        /* last cacheline: 8 bytes */\n};\n\nstruct syscall_trace_enter {\n        struct trace_entry         ent;                  /*     0    12 */\n\n        /* XXX last struct has 3 bytes of padding */\n\n        int                        nr;                   /*    12     4 */\n        long unsigned int          args[];               /*    16     0 */\n\n        /* size: 16', ' cachelines: 1', ' members: 3 */\n        /* paddings: 1', ' sum paddings: 3 */\n        /* last cacheline: 16 bytes */\n};\n\nThis', ' in turn', ' causes perf_event_set_bpf_prog() fail while running bpf\ntest_profiler testcase because max_ctx_offset is calculated based on the\nformer struct', ' while off on the latter:\n\n  10488         if (is_tracepoint || is_syscall_tp) {\n  10489                 int off = trace_event_get_offsets(event->tp_event);\n  10490\n  10491                 if (prog->aux->max_ctx_offset > off)\n  10492                         return -EACCES;\n  10493         }\n\nWhat bpf program is actually getting is a pointer to struct\nsyscall_tp_t', ' defined in kernel/trace/trace_syscalls.c. This patch fixes\nthe problem by aligning struct syscall_tp_t with struct\nsyscall_trace_(enter|exit) and changing the tests to use these structs\nto dereference context.\n\nSigned-off-by: Artem Savkov <asavkov@redhat.com>\nSigned-off-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Steven Rostedt (Google) <rostedt@goodmis.org>\nLink: https://lore.kernel.org/bpf/20231013054219.172920-1-asavkov@redhat.com\n', '']",The commit changes the syscall_nr type to int in struct syscall_tp_t to ensure compatibility with trace_event_raw_sys_enter.,"syscall_nr,type,trace_event",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The syscall interface,"[""It's not related to any of the above.""]"
9c1292eca243821249fa99f40175b0660d9329e3,9c1292eca243821249fa99f40175b0660d9329e3,Martin KaFai Lau,martin.lau@kernel.org,1697223422,Andrii Nakryiko,andrii@kernel.org,1697225743,64e64477ba943941f8cf56e3dd7962e6c30f54ed,236334aeec0f93217cf9235f2004e61a0a1a5985,"net/bpf: Avoid unused ""sin_addr_len"" warning when CONFIG_CGROUP_BPF is not set

It was reported that there is a compiler warning on the unused variable
""sin_addr_len"" in af_inet.c when CONFIG_CGROUP_BPF is not set.
This patch is to address it similar to the ipv6 counterpart
in inet6_getname(). It is to ""return sin_addr_len;""
instead of ""return sizeof(*sin);"".

Fixes: fefba7d1ae19 (""bpf: Propagate modified uaddrlen from cgroup sockaddr programs"")
Reported-by: Stephen Rothwell <sfr@canb.auug.org.au>
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Reviewed-by: Kuniyuki Iwashima <kuniyu@amazon.com>
Link: https://lore.kernel.org/bpf/20231013185702.3993710-1-martin.lau@linux.dev

Closes: https://lore.kernel.org/bpf/20231013114007.2fb09691@canb.auug.org.au/
",,Fixes unused variable warning in net/bpf related to CONFIG_CGROUP_BPF.,"warning, sin_addr_len, CONFIG_CGROUP_BPF",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The eBPF maps,['cgroup like programs']
236334aeec0f93217cf9235f2004e61a0a1a5985,236334aeec0f93217cf9235f2004e61a0a1a5985,Yafang Shao,laoar.shao@gmail.com,1697186356,Andrii Nakryiko,andrii@kernel.org,1697225601,2752c8b15edaa537be81e3beca7460a9eb0222c0,d2dc885b8c9ddb6fc374d93a87f8f2d1b97d2caf,"bpf: Avoid unnecessary audit log for CPU security mitigations

Check cpu_mitigations_off() first to avoid calling capable() if it is off.
This can avoid unnecessary audit log.

Fixes: bc5bc309db45 (""bpf: Inherit system settings for CPU security mitigations"")
Suggested-by: Andrii Nakryiko <andrii.nakryiko@gmail.com>
Signed-off-by: Yafang Shao <laoar.shao@gmail.com>
Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
Link: https://lore.kernel.org/bpf/CAEf4Bza6UVUWqcWQ-66weZ-nMDr+TFU3Mtq=dumZFD-pSqU7Ow@mail.gmail.com/
Link: https://lore.kernel.org/bpf/20231013083916.4199-1-laoar.shao@gmail.com
",,This commit prevents unnecessary audit logs by checking cpu_mitigations_off() before calling capable() for CPU security mitigations.,"audit log, CPU security, mitigations",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
0e6bb5b7f4c8e6665e76bdafce37ad4a8daf83c5,0e6bb5b7f4c8e6665e76bdafce37ad4a8daf83c5,Jakub Kicinski,kuba@kernel.org,1697152666,Jakub Kicinski,kuba@kernel.org,1697155654,6f71fc5628f01bcf9d2dc6eceb3000ee4e73c79a,2f0968a030f2a5dd4897a0151c8395bf5babe5b0 e8c127b0576660da9195504fe8393fe9da3de9ce,"Merge git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Cross-merge networking fixes after downstream PR.

No conflicts.

Adjacent changes:

kernel/bpf/verifier.c
  829955981c55 (""bpf: Fix verifier log for async callback return values"")
  a923819fb2c5 (""bpf: Treat first argument as return value for bpf_throw"")

Signed-off-by: Jakub Kicinski <kuba@kernel.org>
",,Merge networking fixes from upstream into the current branch without conflicts.,"networking, fixes, merge",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
e8c127b0576660da9195504fe8393fe9da3de9ce,e8c127b0576660da9195504fe8393fe9da3de9ce,Linus Torvalds,torvalds@linux-foundation.org,1697141220,Linus Torvalds,torvalds@linux-foundation.org,1697141220,bcd572a15b68db3e1639d2298703aed23d123d1a,9a5a14948574ee09f339990cab69b4ab997d2f7d b91e8403373cab79375a65f5cf3495e2cd0bbdfa,"Merge tag 'net-6.6-rc6' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net

Pull networking fixes from Paolo Abeni:
 ""Including fixes from CAN and BPF.

  We have a regression in TC currently under investigation"," otherwise
  the things that stand off most are probably the TCP and AF_PACKET
  fixes","[' with both issues coming from 6.5.\n\n  Previous releases - regressions:\n\n   - af_packet: fix fortified memcpy() without flex array.\n\n   - tcp: fix crashes trying to free half-baked MTU probes\n\n   - xdp: fix zero-size allocation warning in xskq_create()\n\n   - can: sja1000: always restart the tx queue after an overrun\n\n   - eth: mlx5e: again mutually exclude RX-FCS and RX-port-timestamp\n\n   - eth: nfp: avoid rmmod nfp crash issues\n\n   - eth: octeontx2-pf: fix page pool frag allocation warning\n\n  Previous releases - always broken:\n\n   - mctp: perform route lookups under a RCU read-side lock\n\n   - bpf: s390: fix clobbering the caller\'s backchain in the trampoline\n\n   - phy: lynx-28g: cancel the CDR check work item on the remove path\n\n   - dsa: qca8k: fix qca8k driver for Turris 1.x\n\n   - eth: ravb: fix use-after-free issue in ravb_tx_timeout_work()\n\n   - eth: ixgbe: fix crash with empty VF macvlan list""\n\n* tag \'net-6.6-rc6\' of git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net: (54 commits)\n  rswitch: Fix imbalance phy_power_off() calling\n  rswitch: Fix renesas_eth_sw_remove() implementation\n  octeontx2-pf: Fix page pool frag allocation warning\n  nfc: nci: assert requested protocol is valid\n  af_packet: Fix fortified memcpy() without flex array.\n  net: tcp: fix crashes trying to free half-baked MTU probes\n  net/smc: Fix pos miscalculation in statistics\n  nfp: flower: avoid rmmod nfp crash issues\n  net: usb: dm9601: fix uninitialized variable use in dm9601_mdio_read\n  ethtool: Fix mod state of verbose no_mask bitset\n  net: nfc: fix races in nfc_llcp_sock_get() and nfc_llcp_sock_get_sn()\n  mctp: perform route lookups under a RCU read-side lock\n  net: skbuff: fix kernel-doc typos\n  s390/bpf: Fix unwinding past the trampoline\n  s390/bpf: Fix clobbering the caller\'s backchain in the trampoline\n  net/mlx5e: Again mutually exclude RX-FCS and RX-port-timestamp\n  net/smc: Fix dependency of SMC on ISM\n  ixgbe: fix crash with empty VF macvlan list\n  net/mlx5e: macsec: use update_pn flag instead of PN comparation\n  net: phy: mscc: macsec: reject PN update requests\n  ...\n', '']","Merge networking fixes for CAN, BPF, and address regression in TC subsystem.","networking, CAN, BPF",It's other type of commit.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.",Other component related to eBPF but not listed above.,"['tc/netfilter like programs', 'It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).', ""It's not related to any of the above.""]"
3fec323339a4a9801a54e8b282eb571965b67b23,3fec323339a4a9801a54e8b282eb571965b67b23,Alexandre Ghiti,alexghiti@rivosinc.com,1696580410,Palmer Dabbelt,palmer@rivosinc.com,1697136395,79b9a7bde60978a2dcb69a62f6d024c11cfe419e,a87e7d3e8832271ecb7d5eaaabc5b49fe25a469b,"drivers: perf: Fix panic in riscv SBI mmap support

The following panic can happen when mmap is called before the pmu add
callback which sets the hardware counter index: this happens for example
with the following command `perf record --no-bpf-event -n kill`.

[   99.461486] CPU: 1 PID: 1259 Comm: perf Tainted: G            E      6.6.0-rc4ubuntu-defconfig #2
[   99.461669] Hardware name: riscv-virtio","qemu (DT)
[   99.461748] epc : pmu_sbi_set_scounteren+0x42/0x44
[   99.462337]  ra : smp_call_function_many_cond+0x126/0x5b0
[   99.462369] epc : ffffffff809f9d24 ra : ffffffff800f93e0 sp : ff60000082153aa0
[   99.462407]  gp : ffffffff82395c98 tp : ff6000009a218040 t0 : ff6000009ab3a4f0
[   99.462425]  t1 : 0000000000000004 t2 : 0000000000000100 s0 : ff60000082153ab0
[   99.462459]  s1 : 0000000000000000 a0 : ff60000098869528 a1 : 0000000000000000
[   99.462473]  a2 : 000000000000001f a3 : 0000000000f00000 a4 : fffffffffffffff8
[   99.462488]  a5 : 00000000000000cc a6 : 0000000000000000 a7 : 0000000000735049
[   99.462502]  s2 : 0000000000000001 s3 : ffffffff809f9ce2 s4 : ff60000098869528
[   99.462516]  s5 : 0000000000000002 s6 : 0000000000000004 s7 : 0000000000000001
[   99.462530]  s8 : ff600003fec98bc0 s9 : ffffffff826c5890 s10: ff600003fecfcde0
[   99.462544]  s11: ff600003fec98bc0 t3 : ffffffff819e2558 t4 : ff1c000004623840
[   99.462557]  t5 : 0000000000000901 t6 : ff6000008feeb890
[   99.462570] status: 0000000200000100 badaddr: 0000000000000000 cause: 0000000000000003
[   99.462658] [<ffffffff809f9d24>] pmu_sbi_set_scounteren+0x42/0x44
[   99.462979] Code: 1060 4785 97bb 00d7 8fd9 9073 1067 6422 0141 8082 (9002) 0013
[   99.463335] Kernel BUG [#2]

To circumvent this","[' try to enable userspace access to the hardware counter\nwhen it is selected in addition to when the event is mapped. And vice-versa\nwhen the event is stopped/unmapped.\n\nFixes: cc4c07c89aad (""drivers: perf: Implement perf event mmap support in the SBI backend"")\nSigned-off-by: Alexandre Ghiti <alexghiti@rivosinc.com>\nLink: https://lore.kernel.org/r/20231006082010.11963-1-alexghiti@rivosinc.com\nCc: stable@vger.kernel.org\nSigned-off-by: Palmer Dabbelt <palmer@rivosinc.com>\n', '']",This commit fixes a panic in the RISC-V SBI mmap support by addressing a hardware counter index issue.,"panic,RISC-V,mmap",It's a bug fix.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
b84b3f47921568a8172bec77d0370268e9fc62a2,b84b3f47921568a8172bec77d0370268e9fc62a2,Ian Rogers,irogers@google.com,1696876760,Namhyung Kim,namhyung@kernel.org,1697130117,c59394afeb79e3a925c5c6acb20c61ea303886b8,105254501770c8952e50c71618fca6a8b63890f1,"perf bpf_counter: Fix a few memory leaks

Memory leaks were detected by clang-tidy.

Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Nick Desaulniers <ndesaulniers@google.com>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Nathan Chancellor <nathan@kernel.org>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: llvm@lists.linux.dev
Cc: Ming Wang <wangming01@loongson.cn>
Cc: Tom Rix <trix@redhat.com>
Cc: bpf@vger.kernel.org
Link: https://lore.kernel.org/r/20231009183920.200859-20-irogers@google.com
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
",,Fix memory leaks in the perf bpf_counter component.,"memory leaks, perf, bpf_counter",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"['It improves the overall eBPF infrastructure (e.g., verifier, runtime, etc.).']"
105254501770c8952e50c71618fca6a8b63890f1,105254501770c8952e50c71618fca6a8b63890f1,Ian Rogers,irogers@google.com,1696876759,Namhyung Kim,namhyung@kernel.org,1697130117,d6905cc51dedbd790835d8e22ebdb5e3272bfe3d,97fe038374bdf43fd025ac0e7aebf8bfbdd6d54f,"perf header: Fix various error path memory leaks

Memory leaks were detected by clang-tidy.

Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Nick Desaulniers <ndesaulniers@google.com>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Nathan Chancellor <nathan@kernel.org>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: llvm@lists.linux.dev
Cc: Ming Wang <wangming01@loongson.cn>
Cc: Tom Rix <trix@redhat.com>
Cc: bpf@vger.kernel.org
Link: https://lore.kernel.org/r/20231009183920.200859-19-irogers@google.com
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
",,Fixes memory leaks in perf header error paths identified by clang-tidy.,"memory leaks, clang-tidy, perf header",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
97fe038374bdf43fd025ac0e7aebf8bfbdd6d54f,97fe038374bdf43fd025ac0e7aebf8bfbdd6d54f,Ian Rogers,irogers@google.com,1696876758,Namhyung Kim,namhyung@kernel.org,1697130117,5528b486ab4e61879a00083f6f95ffeebafa5b0c,c4b5140c6eac2f757d9706c6c783b60554c48cb7,"perf trace-event-info: Avoid passing NULL value to closedir

If opendir failed then closedir was passed NULL which is
erroneous. Caught by clang-tidy.

Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Nick Desaulniers <ndesaulniers@google.com>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Nathan Chancellor <nathan@kernel.org>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: llvm@lists.linux.dev
Cc: Ming Wang <wangming01@loongson.cn>
Cc: Tom Rix <trix@redhat.com>
Cc: bpf@vger.kernel.org
Link: https://lore.kernel.org/r/20231009183920.200859-18-irogers@google.com
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
",,Fixed erroneous passing of NULL value to closedir in perf trace-event-info.,"NULL,closedir,clang-tidy",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
c4b5140c6eac2f757d9706c6c783b60554c48cb7,c4b5140c6eac2f757d9706c6c783b60554c48cb7,Ian Rogers,irogers@google.com,1696876757,Namhyung Kim,namhyung@kernel.org,1697130117,c4020b92d38b6393b1e4e7666cd322b719d197cc,7875c72c8b0566590c888a2420d7e8fc12f67154,"tools api: Avoid potential double free

io__getline will free the line on error but it doesn't clear the out
argument. This may lead to the line being freed twice"," like in
tools/perf/util/srcline.c as detected by clang-tidy.

Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Nick Desaulniers <ndesaulniers@google.com>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Nathan Chancellor <nathan@kernel.org>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: llvm@lists.linux.dev
Cc: Ming Wang <wangming01@loongson.cn>
Cc: Tom Rix <trix@redhat.com>
Cc: bpf@vger.kernel.org
Link: https://lore.kernel.org/r/20231009183920.200859-17-irogers@google.com
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
",[''],Fixes a potential double free issue in tools API related to error handling in io__getline function.,"double free,error,io__getline",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
7875c72c8b0566590c888a2420d7e8fc12f67154,7875c72c8b0566590c888a2420d7e8fc12f67154,Ian Rogers,irogers@google.com,1696876756,Namhyung Kim,namhyung@kernel.org,1697130117,2cf6fe16b40715c86608ae78baaaf31396f35d9d,1370406d35b45457aae295a6cfce9fae2bbd785e,"perf parse-events: Fix unlikely memory leak when cloning terms

Add missing free on an error path as detected by clang-tidy.

Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Nick Desaulniers <ndesaulniers@google.com>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Nathan Chancellor <nathan@kernel.org>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: llvm@lists.linux.dev
Cc: Ming Wang <wangming01@loongson.cn>
Cc: Tom Rix <trix@redhat.com>
Cc: bpf@vger.kernel.org
Link: https://lore.kernel.org/r/20231009183920.200859-16-irogers@google.com
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
",,Fix a memory leak in perf parse-events by adding a missing free on an error path.,"memory leak, perf, free",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
1370406d35b45457aae295a6cfce9fae2bbd785e,1370406d35b45457aae295a6cfce9fae2bbd785e,Ian Rogers,irogers@google.com,1696876755,Namhyung Kim,namhyung@kernel.org,1697130117,e12948eeb5df492a42ab8363c08a2d22782467b6,63d471979e49148e59eae0b33a57c12d535e20c6,"perf lock: Fix a memory leak on an error path

If a memory allocation fails then the strdup-ed string needs
freeing. Detected by clang-tidy.

Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Nick Desaulniers <ndesaulniers@google.com>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Nathan Chancellor <nathan@kernel.org>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: llvm@lists.linux.dev
Cc: Ming Wang <wangming01@loongson.cn>
Cc: Tom Rix <trix@redhat.com>
Cc: bpf@vger.kernel.org
Link: https://lore.kernel.org/r/20231009183920.200859-15-irogers@google.com
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
",,Fixes a memory leak in perf lock by freeing strdup-ed string on error path.,"memory leak, error path, strdup",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
63d471979e49148e59eae0b33a57c12d535e20c6,63d471979e49148e59eae0b33a57c12d535e20c6,Ian Rogers,irogers@google.com,1696876754,Namhyung Kim,namhyung@kernel.org,1697130116,72aaee5f7698ac004f2fca03bcdde4ed316b5802,ef1aec6000a7364a6c1ef0a6f9cbf8b98b685255,"perf svghelper: Avoid memory leak

On success path the sib_core and sib_thr values weren't being
freed. Detected by clang-tidy.

Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Nick Desaulniers <ndesaulniers@google.com>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Nathan Chancellor <nathan@kernel.org>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: llvm@lists.linux.dev
Cc: Ming Wang <wangming01@loongson.cn>
Cc: Tom Rix <trix@redhat.com>
Cc: bpf@vger.kernel.org
Link: https://lore.kernel.org/r/20231009183920.200859-14-irogers@google.com
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
",,The commit addresses a memory leak in the perf svghelper by ensuring sib_core and sib_thr values are freed.,"perf,memory leak,clang-tidy",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
ef1aec6000a7364a6c1ef0a6f9cbf8b98b685255,ef1aec6000a7364a6c1ef0a6f9cbf8b98b685255,Ian Rogers,irogers@google.com,1696876753,Namhyung Kim,namhyung@kernel.org,1697130116,63c15ba57b31848c44dc2bf496d816bdb29d2c13,51e9ea99f9bfe6a9c283d041dbc2c1c0be9c3a0f,"perf hists browser: Avoid potential NULL dereference

On other code paths browser->he_selection is NULL checked"," add a
missing case reported by clang-tidy.

Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Nick Desaulniers <ndesaulniers@google.com>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Nathan Chancellor <nathan@kernel.org>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: llvm@lists.linux.dev
Cc: Ming Wang <wangming01@loongson.cn>
Cc: Tom Rix <trix@redhat.com>
Cc: bpf@vger.kernel.org
Link: https://lore.kernel.org/r/20231009183920.200859-13-irogers@google.com
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
",[''],The commit fixes a potential NULL dereference in the perf hists browser code.,"NULL dereference, perf, browser",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
51e9ea99f9bfe6a9c283d041dbc2c1c0be9c3a0f,51e9ea99f9bfe6a9c283d041dbc2c1c0be9c3a0f,Ian Rogers,irogers@google.com,1696876752,Namhyung Kim,namhyung@kernel.org,1697130116,e4b2cf6dca2b048504834e7783ae8509b96bb4cb,52a5ad12f2147506899ee83e680ea2a1d763adeb,"perf hists browser: Reorder variables to reduce padding

Address clang-tidy warning:
```
tools/perf/ui/browsers/hists.c:2416:8: warning: Excessive padding in 'struct popup_action' (8 padding bytes"," where 0 is optimal).
Optimal fields order:
time","['\nthread', '\nevsel', '\nfn', '\nms', '\nsocket', '\nrstype', '\n```\n\nSigned-off-by: Ian Rogers <irogers@google.com>\nAcked-by: Namhyung Kim <namhyung@kernel.org>\nCc: Ravi Bangoria <ravi.bangoria@amd.com>\nCc: Nick Desaulniers <ndesaulniers@google.com>\nCc: Yang Jihong <yangjihong1@huawei.com>\nCc: Huacai Chen <chenhuacai@kernel.org>\nCc: Nathan Chancellor <nathan@kernel.org>\nCc: Kan Liang <kan.liang@linux.intel.com>\nCc: llvm@lists.linux.dev\nCc: Ming Wang <wangming01@loongson.cn>\nCc: Tom Rix <trix@redhat.com>\nCc: bpf@vger.kernel.org\nLink: https://lore.kernel.org/r/20231009183920.200859-12-irogers@google.com\nSigned-off-by: Namhyung Kim <namhyung@kernel.org>\n', '']",This commit reorders variables in perf hists browser to address a clang-tidy padding warning.,"variable reordering, clang-tidy, padding",It's a cleanup or refactoring in the code.,"Simple, can be used without much configuration. For example, a simple helper function.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
52a5ad12f2147506899ee83e680ea2a1d763adeb,52a5ad12f2147506899ee83e680ea2a1d763adeb,Ian Rogers,irogers@google.com,1696876751,Namhyung Kim,namhyung@kernel.org,1697130116,a8691f5434924f2251e136779eaf2ac60b4c62bd,85f73c377b2ac9988a204b119aebb33ca5c60083,"perf dlfilter: Be defensive against potential NULL dereference

In the unlikely case of having a symbol without a mapping"," avoid a
NULL dereference that clang-tidy warns about.

Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Nick Desaulniers <ndesaulniers@google.com>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Nathan Chancellor <nathan@kernel.org>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: llvm@lists.linux.dev
Cc: Ming Wang <wangming01@loongson.cn>
Cc: Tom Rix <trix@redhat.com>
Cc: bpf@vger.kernel.org
Link: https://lore.kernel.org/r/20231009183920.200859-11-irogers@google.com
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
",[''],The commit addresses a NULL dereference issue in perf dlfilter to improve stability and avoid clang-tidy warnings.,"NULL dereference, perf dlfilter, clang-tidy",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
85f73c377b2ac9988a204b119aebb33ca5c60083,85f73c377b2ac9988a204b119aebb33ca5c60083,Ian Rogers,irogers@google.com,1696876750,Namhyung Kim,namhyung@kernel.org,1697130116,9839b95859a13c6e4dfaa11dd563a23f556cb1a7,b3aa09ee78defd3d2e5f7debb5279f8a92b69749,"perf mem-events: Avoid uninitialized read

pmu should be initialized to NULL before perf_pmus__scan loop. Fix and
shrink the scope of pmu at the same time. Issue detected by clang-tidy.

Fixes: 5752c20f3787 (""perf mem: Scan all PMUs instead of just core ones"")
Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Nick Desaulniers <ndesaulniers@google.com>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Nathan Chancellor <nathan@kernel.org>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: llvm@lists.linux.dev
Cc: Ming Wang <wangming01@loongson.cn>
Cc: Tom Rix <trix@redhat.com>
Cc: bpf@vger.kernel.org
Link: https://lore.kernel.org/r/20231009183920.200859-10-irogers@google.com
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
",,Initialize pmu to NULL to prevent uninitialized read in perf mem-events and reduce its scope.,"uninitialized read, clang-tidy, pmu",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
b3aa09ee78defd3d2e5f7debb5279f8a92b69749,b3aa09ee78defd3d2e5f7debb5279f8a92b69749,Ian Rogers,irogers@google.com,1696876749,Namhyung Kim,namhyung@kernel.org,1697130116,77cb7946474a482be45699c5df4fbe51c6636f8f,e2372136700d460276ca7ff07da523e8f61b69c7,"perf jitdump: Avoid memory leak

jit_repipe_unwinding_info is called in a loop by jit_process_dump","
avoid leaking unwinding_data by free-ing before overwriting. Error
detected by clang-tidy.

Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Nick Desaulniers <ndesaulniers@google.com>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Nathan Chancellor <nathan@kernel.org>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: llvm@lists.linux.dev
Cc: Ming Wang <wangming01@loongson.cn>
Cc: Tom Rix <trix@redhat.com>
Cc: bpf@vger.kernel.org
Link: https://lore.kernel.org/r/20231009183920.200859-9-irogers@google.com
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
",[''],"Fix memory leak in perf jitdump by freeing unwinding_data before overwriting it, as identified by clang-tidy.","perf,jitdump,memory leak",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['other']
e2372136700d460276ca7ff07da523e8f61b69c7,e2372136700d460276ca7ff07da523e8f61b69c7,Ian Rogers,irogers@google.com,1696876748,Namhyung Kim,namhyung@kernel.org,1697130116,14e147b5c01139a99c225443fcc266b14360e177,319d459898ce507dba58c28c17610314d16b7beb,"perf env: Remove unnecessary NULL tests

clang-tidy was warning:
```
util/env.c:334:23: warning: Access to field 'nr_pmu_mappings' results in a dereference of a null pointer (loaded from variable 'env') [clang-analyzer-core.NullDereference]
        env->nr_pmu_mappings = pmu_num;
```

As functions are called potentially when !env was true. This condition
could never be true as it would produce a segv"," so remove the
unnecessary NULL tests and silence clang-tidy.

Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Nick Desaulniers <ndesaulniers@google.com>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Nathan Chancellor <nathan@kernel.org>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: llvm@lists.linux.dev
Cc: Ming Wang <wangming01@loongson.cn>
Cc: Tom Rix <trix@redhat.com>
Cc: bpf@vger.kernel.org
Link: https://lore.kernel.org/r/20231009183920.200859-8-irogers@google.com
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
",[''],Remove unnecessary NULL pointer checks in perf environment code to prevent segfaults and silence clang-tidy warnings.,"NULL tests, clang-tidy, segfault",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",The bpftool utility,"[""It's not related to any of the above.""]"
319d459898ce507dba58c28c17610314d16b7beb,319d459898ce507dba58c28c17610314d16b7beb,Ian Rogers,irogers@google.com,1696876747,Namhyung Kim,namhyung@kernel.org,1697130116,131c9f1b1b8f97f8333cc04464e2f50f8712047d,da0c884b0756fc97a1c15f4cdb81e0a8490a6d7e,"perf buildid-cache: Fix use of uninitialized value

The buildid filename is first determined and then from this the
buildid read. If getting the filename fails then the buildid will be
used for a later memcmp uninitialized. Detected by clang-tidy.

Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Nick Desaulniers <ndesaulniers@google.com>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Nathan Chancellor <nathan@kernel.org>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: llvm@lists.linux.dev
Cc: Ming Wang <wangming01@loongson.cn>
Cc: Tom Rix <trix@redhat.com>
Cc: bpf@vger.kernel.org
Link: https://lore.kernel.org/r/20231009183920.200859-7-irogers@google.com
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
",,Fix uninitialized value usage in perf buildid-cache to prevent memcmp issues.,"uninitialized value, buildid-cache, memcmp",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
da0c884b0756fc97a1c15f4cdb81e0a8490a6d7e,da0c884b0756fc97a1c15f4cdb81e0a8490a6d7e,Ian Rogers,irogers@google.com,1696876746,Namhyung Kim,namhyung@kernel.org,1697130115,abea99d02dc1db1279da8bfce1a011bebee8df84,b24520ffa9695c7249bdd181cf10bc0a3e365019,"perf bench uprobe: Fix potential use of memory after free

Found by clang-tidy:
```
bench/uprobe.c:98:3: warning: Use of memory after it is freed [clang-analyzer-unix.Malloc]
                bench_uprobe_bpf__destroy(skel);
```

Signed-off-by: Ian Rogers <irogers@google.com>
Acked-by: Namhyung Kim <namhyung@kernel.org>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Nick Desaulniers <ndesaulniers@google.com>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Nathan Chancellor <nathan@kernel.org>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: llvm@lists.linux.dev
Cc: Ming Wang <wangming01@loongson.cn>
Cc: Tom Rix <trix@redhat.com>
Cc: bpf@vger.kernel.org
Link: https://lore.kernel.org/r/20231009183920.200859-6-irogers@google.com
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
",,Fixes use-after-free issue in uprobe benchmarking tool detected by clang-tidy.,"memory leak, clang-tidy, uprobe",It's a bug fix.,"Simple, can be used without much configuration. For example, a simple helper function.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.",['other']
b24520ffa9695c7249bdd181cf10bc0a3e365019,b24520ffa9695c7249bdd181cf10bc0a3e365019,Ian Rogers,irogers@google.com,1696876744,Namhyung Kim,namhyung@kernel.org,1697130115,b01f7e73708287e92e0e76e73eaa2db3f76ab1a5,9e56d3be4bfd2ec6433a7c44195bd1e687b8ed2e,"run-clang-tools: Add pass through checks and and header-filter arguments

Add a -checks argument to allow the checks passed to the clang-tool to
be set on the command line.

Add a pass through -header-filter option.

Don't run analysis on non-C or CPP files.

Signed-off-by: Ian Rogers <irogers@google.com>
Reviewed-by: Nick Desaulniers <ndesaulniers@google.com>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Adrian Hunter <adrian.hunter@intel.com>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Nathan Chancellor <nathan@kernel.org>
Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: llvm@lists.linux.dev
Cc: Ming Wang <wangming01@loongson.cn>
Cc: Ingo Molnar <mingo@redhat.com>
Cc: Tom Rix <trix@redhat.com>
Cc: bpf@vger.kernel.org
Cc: linux-kernel@vger.kernel.org
Cc: linux-perf-users@vger.kernel.org
Link: https://lore.kernel.org/r/20231009183920.200859-4-irogers@google.com
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
",,"Enhance run-clang-tools with command-line options for checks and header filtering, excluding non-C/CPP files.","clang-tools, header-filter, checks",It's a build system or CI/CD change.,"Simple, can be used without much configuration. For example, a simple helper function.","It's not related to any of the above, it's not related to bpf subsystem in Linux kernel, may be wrong data.","[""It's not related to any of the above.""]"
9e56d3be4bfd2ec6433a7c44195bd1e687b8ed2e,9e56d3be4bfd2ec6433a7c44195bd1e687b8ed2e,Ian Rogers,irogers@google.com,1696876743,Namhyung Kim,namhyung@kernel.org,1697130115,e7a96bbb49e0f6bbbfe68f685c0fd410bcc13bdd,52c15e7e792857c42b4a926e45228e981c5a5f13,"gen_compile_commands: Sort output compile commands by file name

Make the output more stable and deterministic.

Signed-off-by: Ian Rogers <irogers@google.com>
Reviewed-by: Nick Desaulniers <ndesaulniers@google.com>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Adrian Hunter <adrian.hunter@intel.com>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Nathan Chancellor <nathan@kernel.org>
Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: llvm@lists.linux.dev
Cc: Ming Wang <wangming01@loongson.cn>
Cc: Ingo Molnar <mingo@redhat.com>
Cc: Tom Rix <trix@redhat.com>
Cc: bpf@vger.kernel.org
Cc: linux-kernel@vger.kernel.org
Cc: linux-perf-users@vger.kernel.org
Link: https://lore.kernel.org/r/20231009183920.200859-3-irogers@google.com
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
",,The commit updates gen_compile_commands to sort output compile commands by file name for stability and determinism.,"gen_compile_commands, sort, stability",It's a build system or CI/CD change.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
52c15e7e792857c42b4a926e45228e981c5a5f13,52c15e7e792857c42b4a926e45228e981c5a5f13,Ian Rogers,irogers@google.com,1696876742,Namhyung Kim,namhyung@kernel.org,1697130115,443ff6afb0ba82302acf7cc44c906df2426e299e,b20576fd7fe39554b212095c3c0d7a3dff512515,"gen_compile_commands: Allow the line prefix to still be cmd_

Builds in tools still use the cmd_ prefix in .cmd files"," so don't
require the saved part. Name the groups in the line pattern match so
that changing the regular expression is more robust and works with the
addition of a new match group.

Signed-off-by: Ian Rogers <irogers@google.com>
Reviewed-by: Nick Desaulniers <ndesaulniers@google.com>
Cc: Ravi Bangoria <ravi.bangoria@amd.com>
Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Yang Jihong <yangjihong1@huawei.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Adrian Hunter <adrian.hunter@intel.com>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Huacai Chen <chenhuacai@kernel.org>
Cc: Jiri Olsa <jolsa@kernel.org>
Cc: Nathan Chancellor <nathan@kernel.org>
Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
Cc: Kan Liang <kan.liang@linux.intel.com>
Cc: llvm@lists.linux.dev
Cc: Ming Wang <wangming01@loongson.cn>
Cc: Ingo Molnar <mingo@redhat.com>
Cc: Tom Rix <trix@redhat.com>
Cc: bpf@vger.kernel.org
Cc: linux-kernel@vger.kernel.org
Cc: linux-perf-users@vger.kernel.org
Link: https://lore.kernel.org/r/20231009183920.200859-2-irogers@google.com
Signed-off-by: Namhyung Kim <namhyung@kernel.org>
",[''],The commit allows the gen_compile_commands to maintain the cmd_ prefix for robustness with new match groups.,"gen_compile_commands, cmd_prefix, robustness",It's a build system or CI/CD change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",Other component related to eBPF but not listed above.,"[""It's not related to any of the above.""]"
d2dc885b8c9ddb6fc374d93a87f8f2d1b97d2caf,d2dc885b8c9ddb6fc374d93a87f8f2d1b97d2caf,Martin KaFai Lau,martin.lau@kernel.org,1697055860,Martin KaFai Lau,martin.lau@kernel.org,1697070476,6d8e18abf80ef20cdea6a941fc05c032b19190a9,1ef09e1281a1add0a86ecd594f748d7fb8bfd78e 82ab6b505e8199cc4537f00025a7391973c3847e,"Merge branch 'Add cgroup sockaddr hooks for unix sockets'

Daan De Meyer says:

====================
Changes since v10:

* Removed extra check from bpf_sock_addr_set_sun_path() again in favor of
  calling unix_validate_addr() everywhere in af_unix.c before calling the hooks.

Changes since v9:

* Renamed bpf_sock_addr_set_unix_addr() to bpf_sock_addr_set_sun_path() and
  rennamed arguments to match the new name.
* Added an extra check to bpf_sock_addr_set_sun_path() to disallow changing the
  address of an unnamed unix socket.
* Removed unnecessary NULL check on uaddrlen in
  __cgroup_bpf_run_filter_sock_addr().

Changes since v8:

* Added missing test programs to last patch

Changes since v7:

* Fixed formatting nit in comment
* Renamed from cgroup/connectun to cgroup/connect_unix (and similar for all
  other hooks)

Changes since v6:

* Actually removed bpf_bind() helper for AF_UNIX hooks.
* Fixed merge conflict
* Updated comment to mention uaddrlen is read-only for AF_INET[6]
* Removed unnecessary forward declaration of struct sock_addr_test
* Removed unused BPF_CGROUP_RUN_PROG_UNIX_CONNECT()
* Fixed formatting nit reported by checkpatch
* Added more information to commit message about recvmsg() on connected socket

Changes since v5:

* Fixed kernel version in bpftool documentation (6.3 => 6.7).
* Added connection mode socket recvmsg() test.
* Removed bpf_bind() helper for AF_UNIX hooks.
* Added missing getpeernameun and getsocknameun BPF test programs.
* Added note for bind() test being unused currently.

Changes since v4:

* Dropped support for intercepting bind() as when using bind() with unix sockets
  and a pathname sockaddr"," bind() will create an inode in the filesystem that
  needs to be cleaned up. If the address is rewritten","[' users might try to clean\n  up the wrong file and leak the actual socket file in the filesystem.\n* Changed bpf_sock_addr_set_unix_addr() to use BTF_KFUNC_HOOK_CGROUP_SKB instead\n  of BTF_KFUNC_HOOK_COMMON.\n* Removed unix socket related changes from BPF_CGROUP_PRE_CONNECT_ENABLED() as\n  unix sockets do not support pre-connect.\n* Added tests for getpeernameun and getsocknameun hooks.\n* We now disallow an empty sockaddr in bpf_sock_addr_set_unix_addr() similar to\n  unix_validate_addr().\n* Removed unnecessary cgroup_bpf_enabled() checks\n* Removed unnecessary error checks\n\nChanges since v3:\n\n* Renamed bpf_sock_addr_set_addr() to bpf_sock_addr_set_unix_addr() and\n  made it only operate on AF_UNIX sockaddrs. This is because for the other\n  families', ' users usually want to configure more than just the address so\n  a generic interface will not fit the bill here. e.g. for AF_INET and AF_INET6', ""\n  users would generally also want to be able to configure the port which the\n  current interface doesn't support. So we expose an AF_UNIX specific function\n  instead.\n* Made the tests in the new sock addr tests more generic (similar to test_sock_addr.c)"", '\n  this should make it easier to migrate the other sock addr tests in the future.\n* Removed the new kfunc hook and attached to BTF_KFUNC_HOOK_COMMON instead\n* Set uaddrlen to 0 when the family is AF_UNSPEC\n* Pass in the addrlen to the hook from IPv6 code\n* Fixed mount directory mkdir() to ignore EEXIST\n\nChanges since v2:\n\n* Configuring the sock addr is now done via a new kfunc bpf_sock_addr_set()\n* The addrlen is exposed as u32 in bpf_sock_addr_kern\n* Selftests are updated to use the new kfunc\n* Selftests are now added as a new sock_addr test in prog_tests/\n* Added BTF_KFUNC_HOOK_SOCK_ADDR for BPF_PROG_TYPE_CGROUP_SOCK_ADDR\n* __cgroup_bpf_run_filter_sock_addr() now returns the modified addrlen\n\nChanges since v1:\n\n* Split into multiple patches instead of one single patch\n* Added unix support for all socket address hooks instead of only connect()\n* Switched approach to expose the socket address length to the bpf hook\ninstead of recalculating the socket address length in kernelspace to\nproperly support abstract unix socket addresses\n* Modified socket address hook tests to calculate the socket address length\nonce and pass it around everywhere instead of recalculating the actual unix\nsocket address length on demand.\n* Added some missing section name tests for getpeername()/getsockname()\n\nThis patch series extends the cgroup sockaddr hooks to include support for unix\nsockets. To add support for unix sockets', ' struct bpf_sock_addr_kern is extended\nto expose the socket address length to the bpf program. Along with that', ' a new\nkfunc bpf_sock_addr_set_unix_addr() is added to safely allow modifying an\nAF_UNIX sockaddr from bpf programs.\n\nI intend to use these new hooks in systemd to reimplement the LogNamespace=\nfeature', ' which allows running multiple instances of systemd-journald to\nprocess the logs of different services. systemd-journald also processes\nsyslog messages', ' so currently', "" using log namespaces means all services running\nin the same log namespace have to live in the same private mount namespace\nso that systemd can mount the journal namespace's associated syslog socket\nover /dev/log to properly direct syslog messages from all services running\nin that log namespace to the correct systemd-journald instance. We want to\nrelax this requirement so that processes running in disjoint mount namespaces\ncan still run in the same log namespace. To achieve this"", ' we can use these\nnew hooks to rewrite the socket address of any connect()', ' sendto()', "" ...\nsyscalls to /dev/log to the socket address of the journal namespace's syslog\nsocket instead"", ' which will transparently do the redirection without requiring\nuse of a mount namespace and mounting over /dev/log.\n\nAside from the above usecase', ' these hooks can more generally be used to\ntransparently redirect unix sockets to different addresses as required by\nservices.\n====================\n\nSigned-off-by: Martin KaFai Lau <martin.lau@kernel.org>\n', '']",This commit adds cgroup sockaddr hooks for Unix sockets and includes various fixes and renamings from previous versions.,"cgroup, unix sockets, hooks",It's a new feature.,"Complex, needs expert knowledge or significant changes to existing systems. Like adding a completely new subsystem support or a completely new program type don't exist before.","The attach events and bpf link. e.g. perf events, tracepoints, etc.",['cgroup like programs']
82ab6b505e8199cc4537f00025a7391973c3847e,82ab6b505e8199cc4537f00025a7391973c3847e,Daan De Meyer,daan.j.demeyer@gmail.com,1697050271,Martin KaFai Lau,martin.lau@kernel.org,1697070475,6d8e18abf80ef20cdea6a941fc05c032b19190a9,af2752ed450e71fc0bd596d0b4b9b805a64ae2c1,"selftests/bpf: Add tests for cgroup unix socket address hooks

These selftests are written in prog_tests style instead of adding
them to the existing test_sock_addr tests. Migrating the existing
sock addr tests to prog_tests style is left for future work. This
commit adds support for testing bind() sockaddr hooks"," even though
there's no unix socket sockaddr hook for bind(). We leave this code
intact for when the INET and INET6 tests are migrated in the future
which do support intercepting bind().

Signed-off-by: Daan De Meyer <daan.j.demeyer@gmail.com>
Link: https://lore.kernel.org/r/20231011185113.140426-10-daan.j.demeyer@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",[''],Add selftests for cgroup unix socket address hooks in prog_tests style.,"selftests,cgroup,socket",It's a test case or test infrastructure change.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The test cases and makefiles,"['socket like programs', 'cgroup like programs']"
af2752ed450e71fc0bd596d0b4b9b805a64ae2c1,af2752ed450e71fc0bd596d0b4b9b805a64ae2c1,Daan De Meyer,daan.j.demeyer@gmail.com,1697050270,Martin KaFai Lau,martin.lau@kernel.org,1697070475,4bf1a4389986554336461f4c19d057bd791d6ecf,3243fef6a4c0db2dbb01ee3cf30bd787e65b8d56,"selftests/bpf: Make sure mount directory exists

The mount directory for the selftests cgroup tree might
not exist so let's make sure it does exist by creating
it ourselves if it doesn't exist.

Signed-off-by: Daan De Meyer <daan.j.demeyer@gmail.com>
Link: https://lore.kernel.org/r/20231011185113.140426-9-daan.j.demeyer@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,Ensure selftests create necessary mount directories for cgroup trees if not present.,"selftests, cgroup, directory",It's a test case or test infrastructure change.,"Simple, can be used without much configuration. For example, a simple helper function.",The test cases and makefiles,"[""It's not related to any of the above.""]"
3243fef6a4c0db2dbb01ee3cf30bd787e65b8d56,3243fef6a4c0db2dbb01ee3cf30bd787e65b8d56,Daan De Meyer,daan.j.demeyer@gmail.com,1697050269,Martin KaFai Lau,martin.lau@kernel.org,1697070475,a1b9c995e514da7a48507e4d10e0ed66b4703c72,8b3cba987e6d9464bb533d957de923f891b57bf8,"documentation/bpf: Document cgroup unix socket address hooks

Update the documentation to mention the new cgroup unix sockaddr
hooks.

Signed-off-by: Daan De Meyer <daan.j.demeyer@gmail.com>
Link: https://lore.kernel.org/r/20231011185113.140426-8-daan.j.demeyer@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,The commit updates documentation to include cgroup unix socket address hooks.,"documentation,cgroup,socket",It's a documentation change or typo fix.,"Simple, can be used without much configuration. For example, a simple helper function.",Other component related to eBPF but not listed above.,['cgroup like programs']
8b3cba987e6d9464bb533d957de923f891b57bf8,8b3cba987e6d9464bb533d957de923f891b57bf8,Daan De Meyer,daan.j.demeyer@gmail.com,1697050268,Martin KaFai Lau,martin.lau@kernel.org,1697070475,1a03ce1f2f0ad0ca81cd2d68a690dac5fd76ecbf,bf90438c78df885c17a3474276ed39abb4a7c026,"bpftool: Add support for cgroup unix socket address hooks

Add the necessary plumbing to hook up the new cgroup unix sockaddr
hooks into bpftool.

Signed-off-by: Daan De Meyer <daan.j.demeyer@gmail.com>
Acked-by: Quentin Monnet <quentin@isovalent.com>
Link: https://lore.kernel.org/r/20231011185113.140426-7-daan.j.demeyer@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,This commit adds support for cgroup unix socket address hooks into bpftool.,"bpftool,cgroup,unix",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The bpftool utility,['cgroup like programs']
bf90438c78df885c17a3474276ed39abb4a7c026,bf90438c78df885c17a3474276ed39abb4a7c026,Daan De Meyer,daan.j.demeyer@gmail.com,1697050267,Martin KaFai Lau,martin.lau@kernel.org,1697070475,b06ea6a79a254d7547802f4795df2603762d7280,859051dd165ec6cc915f0f2114699021144fd249,"libbpf: Add support for cgroup unix socket address hooks

Add the necessary plumbing to hook up the new cgroup unix sockaddr
hooks into libbpf.

Signed-off-by: Daan De Meyer <daan.j.demeyer@gmail.com>
Link: https://lore.kernel.org/r/20231011185113.140426-6-daan.j.demeyer@gmail.com
Signed-off-by: Martin KaFai Lau <martin.lau@kernel.org>
",,libbpf gains support for hooking cgroup unix socket address operations.,"libbpf,cgroup,socket",It's a new feature.,"Moderate, requires some setup or understanding of the system. For example, a new map type or a new link type.",The libbpf library,['cgroup like programs']
